{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e7a1c0b6-7832-4d9f-8b38-b4efcdf6f9c8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Scientific Publications Data Warehouse\n",
    "\n",
    "## Project 1: A Data cube on top of Delta lake (ETL)\n",
    "\n",
    "### Purpose\n",
    "\n",
    "The purpose is to extract data about scientific publications from JSON data that describe, title, topic,\n",
    "authors, etc. about a huge number of papers and populate a data warehouse in order to issue analytics\n",
    "queries using SQL.\n",
    "\n",
    "### Usage\n",
    "\n",
    "Upload this notebook or DBC archive on databricks platform\n",
    "\n",
    "---------------\n",
    "\n",
    "##  Task1.  Extract \n",
    "### a. Fetching The 7z archive\n",
    "\n",
    "**Skip this Section if you already have performed the extraction process and jump to checkpoint for pulling data from split json files.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "209e2881-3ee4-42bd-a7f9-5770d551f82a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Checking if archive is downloaded in memory.\n",
    "try:\n",
    "    dbutils.fs.ls(\"file:/databricks/driver/dblp.v13.7z\")\n",
    "    print(\"Archive in filesystem (file:/databricks/driver/dblp.v13.7z)\")\n",
    "except:\n",
    "    # If archive is not in memory, Checking databricks store for cached version and pulling into memory.\n",
    "    try:\n",
    "        dbutils.fs.ls(\"dbfs:/FileStore/data/dblp.v13.7z\")\n",
    "        print(\"Archive located in FileStore. Copying into local store..\")\n",
    "        dbutils.fs.cp(\"dbfs:/FileStore/data/dblp.v13.7z\", \"file:/databricks/driver/dblp.v13.7z\")\n",
    "        print(\"Completed\")\n",
    "    except:\n",
    "        # If archive is not cached, downloading and storing in databricks store.\n",
    "        print(\"7z archive not found. Fetching from URL...\")\n",
    "        !wget https://originalstatic.aminer.cn/misc/dblp.v13.7z\n",
    "        print(\"7z archive Downloaded. Moving archive to FileStore..\")\n",
    "        dbutils.fs.mkdirs(\"dbfs:/FileStore/data\")\n",
    "        dbutils.fs.cp(\"file:/databricks/driver/dblp.v13.7z\", \"dbfs:/FileStore/data/dblp.v13.7z\")\n",
    "        print(\"Completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8651e6a8-f236-486a-87bb-4d97b0fdb151",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The returned array should have one object of FileInfo with size =2568255035\n",
    "\n",
    "dbutils.fs.ls(\"file:/databricks/driver/dblp.v13.7z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f06f2189-223f-4267-9d22-ae64722c6fc6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### b. Extracting Archive into json chunks\n",
    "\n",
    "#### b1. Extracting 7zip file into json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "ad2f9d88-78a5-40de-8ef6-6bb19c52ecd0",
     "showTitle": false,
     "title": ""
    },
    "id": "6rihFnHHC36O"
   },
   "outputs": [],
   "source": [
    "!pip install py7zr -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5ac74aa7-da2a-40af-918a-f6e5e3b7a545",
     "showTitle": false,
     "title": ""
    },
    "id": "xaE3ZCOyyQd6"
   },
   "outputs": [],
   "source": [
    "import py7zr\n",
    "\n",
    "archive = py7zr.SevenZipFile('dblp.v13.7z', mode='r')\n",
    "archive.extractall()\n",
    "archive.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "db87c2a2-2100-4620-b777-6c0ef4418461",
     "showTitle": false,
     "title": ""
    },
    "id": "6O-F875qxq7o"
   },
   "outputs": [],
   "source": [
    "dbutils.fs.ls(\"file:/databricks/driver/dblpv13.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e806a652-8fcb-4de7-a022-8c05edaeab37",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### b2. Cleaning NumberInt(#) tags\n",
    "\n",
    "The json data contains non-confirming tags, and so cannot be parsed as it is. We will read each line and substitute the tag. (This should take about 25 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e278afc1-eae9-49a1-86f0-1a791561cfa2",
     "showTitle": false,
     "title": ""
    },
    "id": "Wud9Kr2_bd4A"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Cleaning the `NumberInt` tag\n",
    "fin = open(f\"dblpv13.json\")\n",
    "fout = open(f\"dblpv13_clean.json\", \"wt\")\n",
    "for line in fin:\n",
    "    fout.write(re.sub(r\"NumberInt\\([\\d]*\\)\", lambda x: \"\".join(re.findall(r\"\\d\", x.group(0))), line))\n",
    "fin.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "60c2947a-fc81-404c-be15-fe9d8cd0d002",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### b3. Partitioning Dataset into JSON files\n",
    "Since the whopping 16 GB of json data cannot be loaded into memory directly, we need to partition the data into smaller chunks (300k objects per chunk) for processing.  \n",
    "We also parse data encoded as Decimal data with DecimalEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2e5bafdf-1fa6-4e11-92b6-63fc4cfd23df",
     "showTitle": false,
     "title": ""
    },
    "id": "PqBCNju720aq"
   },
   "outputs": [],
   "source": [
    "%mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a33aec68-5fbe-4029-8d0e-defb4b409a42",
     "showTitle": false,
     "title": ""
    },
    "id": "uiAqyHl-TGfI"
   },
   "outputs": [],
   "source": [
    "import ijson\n",
    "import json\n",
    "import decimal\n",
    "\n",
    "class DecimalEncoder(json.JSONEncoder):\n",
    "    def default(self, o):\n",
    "        if isinstance(o, decimal.Decimal):\n",
    "            return str(o)\n",
    "        return super(DecimalEncoder, self).default(o)\n",
    "\n",
    "data_dir = 'data/'\n",
    "with open('dblpv13_clean.json', 'r') as f:\n",
    "    counter, file_id = 0, 0\n",
    "    file_buffer = []\n",
    "    for obj_data in ijson.items(f, 'item'):\n",
    "        file_buffer.append(obj_data)\n",
    "        counter += 1\n",
    "        if counter % 300000 == 0:\n",
    "            print(f\" Saving, data_PART_{file_id}.json in {data_dir}\")\n",
    "            f = open(f'{data_dir}data_PART_{file_id}.json', 'w')\n",
    "            dump = json.dumps(file_buffer, cls=DecimalEncoder)\n",
    "            f.write(dump)\n",
    "            f.close()\n",
    "            file_id += 1\n",
    "            file_buffer = []\n",
    "f = open(f'{data_dir}data_PART_{file_id}.json', 'w')\n",
    "dump = json.dumps(file_buffer, cls=DecimalEncoder)\n",
    "print(f\" Saving, data_PART_{file_id}.json in {data_dir}\")\n",
    "f.write(dump)\n",
    "f.close()\n",
    "file_id += 1\n",
    "file_buffer = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "38b56dde-5178-4dd3-931f-d6955577b8ea",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### b4. Moving files to dbfs FileStore from instance storage. Building Checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "7857b3ee-940d-4f3b-ae81-35268e1a7178",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# removing old json stored in filestore.\n",
    "dbutils.fs.rm(\"dbfs:/FileStore/data/split_data/\", recurse = True)\n",
    "# Creating dir to store json in filestore..\n",
    "dbutils.fs.mkdirs(\"dbfs:/FileStore/data/split_data\")\n",
    "# confirming dir is empty\n",
    "dbutils.fs.ls(\"dbfs:/FileStore/data/split_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "8a9dc2df-6d86-44f1-837f-e0f94fc85844",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Copying all json parts into filestore.\n",
    "dbutils.fs.cp(\"file:/databricks/driver/data/\", \"dbfs:/FileStore/data/split_data\", recurse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4a08e500-0a30-4c03-a776-58f12706a511",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Task2. Transform\n",
    "\n",
    "#### Goal: Read data from databricks Filestore into dataframes (Checkpoint after data load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d4483af4-3011-4b5b-bc35-6bea560fdba0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "from functools import reduce\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, ArrayType, StringType, LongType, StructField, IntegerType\n",
    "from typing import List\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "# Here Path indicates input file path, and delta_dir points to file\n",
    "path = \"dbfs:/FileStore/data/split_data/\"\n",
    "delta_dir = \"dbfs:/delta/tables/\"\n",
    "\n",
    "# There should be 18 files each with 300 k records. This would change if you change split value.\n",
    "file_count = len(dbutils.fs.ls(path))\n",
    "assert file_count == 18, \"Data not found. You may want to check the path or run the notebook from start again. If you updated the split value, ignore this assertion error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "0f774643-8974-4f92-953a-9e735689d61d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Build map of spark dataframes by reading json partition chunk files\n",
    "dataframes_map = map(lambda r: spark.read.option(\"inferSchema\", True).json(r), [f\"{path}data_PART_{num}.json\" for num in range(file_count)])\n",
    "# reduce the dataframes into single dataframe by performing union over the mapped frames.\n",
    "union = reduce(lambda df1, df2: df1.unionByName(df2, allowMissingColumns=True), dataframes_map)\n",
    "\n",
    "# Reading first chunk for Testing\n",
    "# union = spark.read.option(\"inferSchema\", True).json(f\"{path}data_PART_0.json\")\n",
    "\n",
    "# jsonSchema = StructType([\n",
    "# \t\tStructField(\"_id\", StringType(), True),\n",
    "# \t\tStructField(\"abstract\", StringType(), True),\n",
    "# \t\tStructField(\"authors\", ArrayType(StructType([\n",
    "# \t\t\tStructField(\"_id\", StringType(), True),\n",
    "# \t\t\tStructField(\"bio\", StringType(), True),\n",
    "# \t\t\tStructField(\"email\", StringType(), True),\n",
    "# \t\t\tStructField(\"gid\", StringType(), True),\n",
    "# \t\t\tStructField(\"name\", StringType(), True),\n",
    "# \t\t\tStructField(\"name_zh\", StringType(), True),\n",
    "# \t\t\tStructField(\"oid\", StringType(), True),\n",
    "# \t\t\tStructField(\"oid_zh\", StringType(), True),\n",
    "# \t\t\tStructField(\"orcid\", StringType(), True),\n",
    "# \t\t\tStructField(\"org\", StringType(), True),\n",
    "# \t\t\tStructField(\"org_zh\", StringType(), True),\n",
    "# \t\t\tStructField(\"orgid\", StringType(), True),\n",
    "# \t\t\tStructField(\"orgs\", ArrayType(StringType(), True), True),\n",
    "# \t\t\tStructField(\"orgs_zh\", ArrayType(StringType(), True), True),\n",
    "# \t\t\tStructField(\"sid\", StringType(), True)\n",
    "# \t\t]), True), True),\n",
    "# \t\tStructField(\"doi\", StringType(), True),\n",
    "# \t\tStructField(\"fos\", ArrayType(StringType(), True), True),\n",
    "# \t\tStructField(\"isbn\", StringType(), True),\n",
    "# \t\tStructField(\"issn\", StringType(), True),\n",
    "# \t\tStructField(\"issue\", StringType(), True),\n",
    "# \t\tStructField(\"keywords\", ArrayType(StringType(), True), True),\n",
    "# \t\tStructField(\"lang\", StringType(), True),\n",
    "# \t\tStructField(\"n_citation\", LongType(), True),\n",
    "# \t\tStructField(\"page_end\", StringType(), True),\n",
    "# \t\tStructField(\"page_start\", StringType(), True),\n",
    "# \t\tStructField(\"pdf\", StringType(), True),\n",
    "# \t\tStructField(\"references\", ArrayType(StringType(), True), True),\n",
    "# \t\tStructField(\"title\", StringType(), True),\n",
    "# \t\tStructField(\"url\", ArrayType(StringType(), True), True),\n",
    "# \t\tStructField(\"venue\", StructType([\n",
    "# \t\t\tStructField(\"_id\", StringType(), True),\n",
    "# \t\t\tStructField(\"issn\", StringType(), True),\n",
    "# \t\t\tStructField(\"name\", StringType(), True),\n",
    "# \t\t\tStructField(\"name_d\", StringType(), True),\n",
    "# \t\t\tStructField(\"name_s\", StringType(), True),\n",
    "# \t\t\tStructField(\"online_issn\", StringType(), True),\n",
    "# \t\t\tStructField(\"publisher\", StringType(), True),\n",
    "# \t\t\tStructField(\"raw\", StringType(), True),\n",
    "# \t\t\tStructField(\"raw_zh\", StringType(), True),\n",
    "# \t\t\tStructField(\"sid\", StringType(), True),\n",
    "# \t\t\tStructField(\"src\", StringType(), True),\n",
    "# \t\t\tStructField(\"t\", StringType(), True),\n",
    "# \t\t\tStructField(\"type\", LongType(), True)\n",
    "# \t\t]), True),\n",
    "# \t\tStructField(\"volume\", StringType(), True),\n",
    "# \t\tStructField(\"year\", LongType(), True)\n",
    "# \t])\n",
    "\n",
    "\n",
    "# union = spark.readStream.schema(jsonSchema).option(\"maxFilesPerTrigger\", 1).json(path)\n",
    "\n",
    "union = union.na.drop(subset=[\"authors\"])\n",
    "union = union.dropDuplicates([\"_id\"])\n",
    "union = union.filter(union.lang == 'en')\n",
    "union.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "725a5e73-1686-417e-879a-e7ee8551958e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Cleaning bad records (empty author lists, small titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1de93512-60bb-4f58-bc94-f6fbbc254992",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Deleting entries with small Titles (less than 3 words) and empty author list\n",
    "size_ = udf(lambda s: len(s.split()), IntegerType())\n",
    "\n",
    "union = union.na.drop(subset=[\"title\", \"authors\"])\n",
    "union = union.filter(size_(F.col(\"Title\")) > 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "646c365c-c1a0-45ec-a168-42bede44787a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Reading the dataframe by merging the previously created chunks.\n",
    "Alternatively, we can process single chunk to see what outcome may look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "eae675b0-6dc9-481a-9459-d2facb3d2a97",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def save_delta_frame(frame, alias, clean = False):\n",
    "    # pull required Fields\n",
    "    delta_path=f\"{delta_dir}{alias}\"\n",
    "       \n",
    "    # Clean (delete dups, Fill NaN values?, ...)\n",
    "    if clean:\n",
    "        frame = frame.distinct()\n",
    "       \n",
    "    # Save delta Frame\n",
    "    frame.write.format('delta').mode('overwrite').save(delta_path)\n",
    "    \n",
    "    # frame.writeStream.format('delta').option(\"checkpointLocation\", f\"/delta/{alias}/_checkpoints/etl-from-json\").outputMode('append').start(delta_path)\n",
    "    # pull appeneded delta file and return\n",
    "    # frame = spark.read.format('delta').load(delta_path)\n",
    "    return frame\n",
    "\n",
    "def distinct_frame_from_cols(frame, columns):\n",
    "    # get distinct records for col\n",
    "    frame = frame.select(*columns).distinct()\n",
    "    # frame = frame.select(\"*\").withColumn(\"id\", F.monotonically_increasing_id() + 1)\n",
    "    frame = frame.select(\"*\").withColumn(\"id\", F.expr(\"uuid()\"))\n",
    "    # return the indexed Table\n",
    "    return frame.select(\"id\", *columns)\n",
    "\n",
    "def map_rdd_to_id(rdd):\n",
    "    def map_rdd2_id_(col):\n",
    "        if col == \"null\" or col == \"\" or not col:\n",
    "            return None\n",
    "        try:\n",
    "            return [rddTuple[0] for rddTuple in list(rdd.items()) if rddTuple[1] == col][0]\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return udf(map_rdd2_id_, LongType())\n",
    "\n",
    "# UDF to get relevant publication's citation counts\n",
    "def cite_count(countMapper):\n",
    "    def cite_count_(col):\n",
    "        if col == \"null\" or col == \"\" or not col:\n",
    "            return \"Unknown\"\n",
    "        return countMapper.get(col)\n",
    "    return udf(cite_count_, StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "df6875e8-8fed-4efa-af2e-836ed3ba9b99",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Language Table\n",
    "\n",
    "- Counting number of distinct languages.\n",
    "- Building new table.\n",
    "- Saving Table to Delta lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "cf0c36be-cbb4-4aa1-933d-3c089635b185",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "lang_frame = distinct_frame_from_cols(union, ['lang']).withColumnRenamed(\"lang\", \"Text\")\n",
    "save_delta_frame(lang_frame, \"Language\")\n",
    "lang_rdd = lang_frame.rdd.collectAsMap()\n",
    "\n",
    "union = union.select(\"*\", map_rdd_to_id(lang_rdd)(\"lang\").alias(\"Lang_ID\")).drop(\"lang\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f4946017-a53d-451e-af02-89ef1f95d83c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Publication Table\n",
    "\n",
    "- Counting number of citations.\n",
    "- Building new table for Title, abstract, volume, Number of citations, references and more.\n",
    "- Saving Table to delta lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a40dfe1c-58c9-460d-ada7-ef8fd7d0aa68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# building a Citation counter dictionary\n",
    "citation_frame = union.select(F.explode_outer(\"references\").alias(\"reference_countmap\"))\n",
    "citation_frame = citation_frame.groupBy(\"reference_countmap\").count()\n",
    "citation_frame = citation_frame.rdd.map(lambda row: row.asDict(True))\n",
    "citation_counts = citation_frame.collect()\n",
    "citation_counter = {}\n",
    "for citation_count in citation_counts:\n",
    "    citation_counter[citation_count['reference_countmap']] = citation_count['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "df3e4406-4f68-4a71-8621-8eee5f7aa50d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Building Publication Frame\n",
    "publication_frame = union.select(\"_id\", \"title\", \"volume\", \"issue\", \"abstract\", \"pdf\", \"isbn\", \"issn\", \"doi\", \"url\", cite_count(citation_counter)(\"_id\").alias(\"NumberOfCitations\"))\n",
    "publication_frame = publication_frame.withColumn(\"issn\", F.when(publication_frame.issn.rlike(\"[1-9]*-[1-9]*\"), F.col(\"issn\")).otherwise(None))\n",
    "# Removing extracted fields from the main schema \n",
    "union = union.drop(\"title\", \"abstract\", \"pdf\", \"isbn\", \"issn\", \"doi\", \"url\", \"references\", \"page_start\", \"page_end\", \"n_citation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5a0dbeee-d1b4-447a-b2de-5746a56af1c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Saving the table\n",
    "publication_frame = save_delta_frame(publication_frame, \"Publication\", clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "4ffd9fd7-9bad-4560-bb4c-a62897ffb0f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "### Future Steps:\n",
    "# 1. API lookup to fill in missing data in issn, isbn, pdf columns\n",
    "# 2. Extract distinct from doc_type into Type frame and map ID for the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "32cddc8a-4c19-4084-ac25-7c3d08389dfd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### FieldOfStudy table. \n",
    "\n",
    "- To generalize desciplines, initialize CountMapper and decipline_mapper.\n",
    "- Map relevant `Field of study` topic for each record \n",
    "    - If the decipline is found in the generalized mapper, we use that item to map the Field of Study list. \n",
    "    - Otherwise we use counts of occurances of each item from the list in the whole database, and pick the one with most frequent occurance as a suitable discipline.\n",
    "\n",
    "We used [Suggested](https://confluence.egi.eu/display/EGIG/Scientific+Disciplines) Descipline mappings to build a relevant datastructure to replace the specific field to generalized descipline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1294fe6a-de77-4455-a0b3-a8c5578c5bbd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Building countmap structure\n",
    "countMapFos = union.select(F.explode(\"fos\").alias(\"fos2\"))\n",
    "countMapFos = countMapFos.groupBy(\"fos2\").count()\n",
    "countMapperRdd = countMapFos.rdd.map(lambda row: row.asDict(True))\n",
    "\n",
    "countMapperList = countMapperRdd.collect()\n",
    "\n",
    "count_mapper = {}\n",
    "for countMapperItem in countMapperList:\n",
    "    count_mapper[countMapperItem['fos2']] = countMapperItem['count']\n",
    "\n",
    "decipline_mapper = {\n",
    "\t# 1 Natural Sciences\n",
    "\t\"Mathematics\": \"Mathematics\", \"Applied mathematics\": \"Mathematics\", \"Pure mathematics\": \"Mathematics\", \"Statistics and probability\": \"Mathematics\",\n",
    "\t\"Computer Science\": \"Computer Sciences\", \"Computer Sciences\": \"Computer Sciences\", \"Algorithms\": \"Computer Sciences\", \"Artificial Intelligence (expert systems, machine learning, robotics)\": \"Computer Sciences\", \"Computer architecture\": \"Computer Sciences\", \"Computer communications\": \"Computer Sciences\", \"Computer graphics\": \"Computer Sciences\", \"Computer security and reliability\": \"Computer Sciences\", \"Data structures\": \"Computer Sciences\", \"Distributed computing\": \"Computer Sciences\", \"Human-computer interaction\": \"Computer Sciences\", \"Operating systems\": \"Computer Sciences\", \"Parallel computing\": \"Computer Sciences\", \"Programming languages\": \"Computer Sciences\", \"Quantum computing\": \"Computer Sciences\", \"Software engineering\": \"Computer Sciences\", \"Theory of computation\": \"Computer Sciences\",\n",
    "\t\"Information sciences\": \"Information sciences\", \"Information science\": \"Information sciences\", \"Data management\": \"Information sciences\", \"Data mining\": \"Information sciences\", \"Information retrieval\": \"Information sciences\", \"Information management\": \"Information sciences\", \"Knowledge management\": \"Information sciences\", \"Multimedia, hypermedia\": \"Information sciences\",\n",
    "\t\"Earth Sciences\": \"Earth Sciences\", \"Earth Science\": \"Earth Sciences\", \"Atmospheric science\": \"Earth Sciences\", \"Climate research\": \"Earth Sciences\", \"Geochemistry\": \"Earth Sciences\", \"Geology\": \"Earth Sciences\", \"Geophysics\": \"Earth Sciences\", \"Hydrology\": \"Earth Sciences\", \"Mineralogy\": \"Earth Sciences\", \"Oceanography\": \"Earth Sciences\", \"Palaeontology\": \"Earth Sciences\", \"Physical geography\": \"Earth Sciences\", \"Seismology\": \"Earth Sciences\", \"Volcanology\": \"Earth Sciences\", \n",
    "\t\"Biology Science\": \"Biology Science\", \"Aerobiology\": \"Biology Science\", \"Bacteriology\": \"Biology Science\", \"Behavioural biology\": \"Biology Science\", \"Biochemistry and molecular biology\": \"Biology Science\", \"Biodiversity conservation\": \"Biology Science\", \"Bioinformatics\": \"Biology Science\", \"Biological rhythm\": \"Biology Science\", \"Biology\": \"Biology Science\", \"Biophysics\": \"Biology Science\", \"Botany\": \"Biology Science\", \"Cell biology\": \"Biology Science\", \"Computational biology\": \"Biology Science\", \"Cryobiology\": \"Biology Science\", \"Developmental biology\": \"Biology Science\", \"Ecology\": \"Biology Science\", \"Evolutionary biology\": \"Biology Science\", \"Genetics and heredity\": \"Biology Science\", \"Marine and Freshwater biology\": \"Biology Science\", \"Mathematical biology\": \"Biology Science\", \"Microbiology\": \"Biology Science\", \"Mycology\": \"Biology Science\", \"Plant science\": \"Biology Science\", \"Reproductive biology\": \"Biology Science\", \"Structural biology\": \"Biology Science\", \"Taxonomy\": \"Biology Science\", \"Theoretical biology\": \"Biology Science\", \"Thermal biology\": \"Biology Science\", \"Virology\": \"Biology Science\", \"Zoology\": \"Biology Science\", \n",
    "\t\"Physical sciences\": \"Physical sciences\", \"Physical science\": \"Physical sciences\", \"Accelerator physics\": \"Physical sciences\", \"Acoustics\": \"Physical sciences\", \"Aerosol physics\": \"Physical sciences\", \"Astrobiology\": \"Physical sciences\", \"Astronomy\": \"Physical sciences\", \"Astroparticle physics\": \"Physical sciences\", \"Astrophysics\": \"Physical sciences\", \"Atomic\": \"Physical sciences\", \"Chemical physics\": \"Physical sciences\", \"Computational physics\": \"Physical sciences\", \"Condensed matter physics\": \"Physical sciences\", \"Cryogenics\": \"Physical sciences\", \"Fluid Mechanics\": \"Physical sciences\", \"Fusion\": \"Physical sciences\", \"High energy physics\": \"Physical sciences\", \"Mathematical physics\": \"Physical sciences\", \"Medical physics\": \"Physical sciences\", \"Molecular physics\": \"Physical sciences\", \"Nuclear physics\": \"Physical sciences\", \"Optics\": \"Physical sciences\", \"Particle physics\": \"Physical sciences\", \"Physics\": \"Physical sciences\", \"Planetary science\": \"Physical sciences\", \"Plasma physics\": \"Physical sciences\", \"Space science\": \"Physical sciences\", \"Quantum physics\": \"Physical sciences\",\n",
    "\t\"Chemical science\": \"Chemical sciences\", \"Chemical sciences\": \"Chemical sciences\", \"Analytical chemistry\": \"Chemical sciences\", \"Chemistry\": \"Chemical sciences\", \"Colloid chemistry\": \"Chemical sciences\", \"Computational chemistry\": \"Chemical sciences\", \"Electrochemistry\": \"Chemical sciences\", \"Inorganic and nuclear chemistry\": \"Chemical sciences\", \"Mathematical chemistry\": \"Chemical sciences\", \"Organic chemistry\": \"Chemical sciences\", \"Physical chemistry\": \"Chemical sciences\", \"Polymer science\": \"Chemical sciences\", \n",
    "\n",
    "\t# 2 Engineering and Technology\n",
    "\t\"Civil engineering\": \"Civil engineering\", \"Architecture engineering\": \"Civil engineering\", \"Civil engineering\": \"Civil engineering\", \"Civil Protection\": \"Civil engineering\", \"Construction/Structural engineering\": \"Civil engineering\", \"Transport engineering\": \"Civil engineering\",\n",
    "\t\"Electrical, electronic and information engineering\": \"Electrical, electronic and information engineering\", \"Communication engineering and systems\": \"Electrical, electronic and information engineering\", \"Computer hardware and architecture\": \"Electrical, electronic and information engineering\", \"Electrical and electronic engineering\": \"Electrical, electronic and information engineering\", \"Robotics, Automation and Control Systems\": \"Electrical, electronic and information engineering\",\n",
    "\t\"Mechanical engineering\": \"Mechanical engineering\", \"Applied mechanics\": \"Mechanical engineering\", \"Audio engineering\": \"Mechanical engineering\", \"Nuclear related engineering\": \"Mechanical engineering\", \"Reliability analysis\": \"Mechanical engineering\", \"Thermodynamics\": \"Mechanical engineering\",\n",
    "\t\"Aerospace engineering\": \"Aerospace engineering\", \"Aeronautical engineering\": \"Aerospace engineering\", \"Astronautical engineering\": \"Aerospace engineering\",\n",
    "\t\"Chemical engineering\": \"Chemical engineering\", \"Chemical engineering (plants, products)\": \"Chemical engineering\", \"Chemical process engineering\": \"Chemical engineering\",\n",
    "\t\"Materials engineering\": \"Materials engineering\", \"Ceramics\": \"Materials engineering\", \"Coating and films\": \"Materials engineering\", \"Composites\": \"Materials engineering\", \"Paper and wood\": \"Materials engineering\", \"Textiles\": \"Materials engineering\",\n",
    "\t\"Bioengineering and Biomedical engineering\": \"Bioengineering and Biomedical engineering\", \"Bioengineering\": \"Bioengineering and Biomedical engineering\", \"Biomedical engineering\": \"Bioengineering and Biomedical engineering\",\n",
    "\t\"Environmental engineering\": \"Environmental engineering\", \"Energy and fuels\": \"Environmental engineering\", \"Geological engineering\": \"Environmental engineering\", \"Geotechnics\": \"Environmental engineering\", \"Ocean engineering\": \"Environmental engineering\", \"Mining and mineral processing\": \"Environmental engineering\", \"Petroleum engineering\": \"Environmental engineering\", \"Remote sensing\": \"Environmental engineering\", \"Sea vessels\": \"Environmental engineering\",\n",
    "\t\"Environmental biotechnology\": \"Environmental biotechnology\", \"Bioremediation\": \"Environmental biotechnology\", \"Diagnostic biotechnologies\": \"Environmental biotechnology\",\n",
    "\t \"Industrial biotechnology\":  \"Industrial biotechnology\", \"Bio-derived novel materials\": \"Industrial biotechnology\", \"Biocatalysis\": \"Industrial biotechnology\", \"Bioderived bulk and fine chemicals\": \"Industrial biotechnology\", \"Biofuels\": \"Industrial biotechnology\", \"Biomaterials\": \"Industrial biotechnology\", \"Bioprocessing technologies\": \"Industrial biotechnology\", \"Bioproducts\": \"Industrial biotechnology\", \"Fermentation\": \"Industrial biotechnology\",\n",
    "\t \"Nano-technology\":  \"Nano-technology\", \"Nano-materials\": \"Nano-technology\", \"Nano-processes\": \"Nano-technology\",\n",
    "\n",
    "\t# 3 Medical and Health Sciences\n",
    "\t\"Basic medicine\": \"Basic medicine\", \"Anatomy and morphology\": \"Basic medicine\", \"Human genetics\": \"Basic medicine\", \"Immunology\": \"Basic medicine\", \"Medicinal chemistry\": \"Basic medicine\", \"Neuroscience\": \"Basic medicine\", \"Pathology\": \"Basic medicine\", \"Pharmacology and pharmacy\": \"Basic medicine\", \"Physiology\": \"Basic medicine\", \"Toxicology\": \"Basic medicine\",\n",
    "\t\"Clinical medicine\": \"Clinical medicine\", \"Allergy\": \"Clinical medicine\", \"Anaesthesiology\": \"Clinical medicine\", \"Andrology\": \"Clinical medicine\", \"Cardiac and Cardiovascular systems\": \"Clinical medicine\", \"Critical care/Emergency medicine\": \"Clinical medicine\", \"Dentistry, oral surgery/medicine\": \"Clinical medicine\", \"Dermatology and venereal diseases\": \"Clinical medicine\", \"Gastroenterology and hepatology\": \"Clinical medicine\", \"General and internal medicine\": \"Clinical medicine\", \"Geriatrics and gerontology\": \"Clinical medicine\", \"Hematology\": \"Clinical medicine\", \"Integrative and Complementary medicine\": \"Clinical medicine\", \"Medical imaging\": \"Clinical medicine\", \"Nuclear medicine\": \"Clinical medicine\", \"Obstetrics and gynaecology\": \"Clinical medicine\", \"Oncology\": \"Clinical medicine\", \"Ophthalmology\": \"Clinical medicine\", \"Optometry\": \"Clinical medicine\", \"Orthopaedics\": \"Clinical medicine\", \"Otorhinolaryngolog\": \"Clinical medicine\", \"Paediatrics\": \"Clinical medicine\", \"Peripheral vascular disease\": \"Clinical medicine\", \"Psychiatry\": \"Clinical medicine\", \"Radiology\": \"Clinical medicine\", \"Respiratory systems\": \"Clinical medicine\", \"Rheumatology\": \"Clinical medicine\", \"Surgery\": \"Clinical medicine\", \"Transplantation\": \"Clinical medicine\", \"Urology and nephrology\": \"Clinical medicine\",\n",
    "\t\"Health science\": \"Health sciences\", \"Health sciences\": \"Health sciences\", \"Epidemiology\": \"Health sciences\", \"Health care science and services\": \"Health sciences\", \"Health policy and services\": \"Health sciences\", \"Infectious diseases\": \"Health sciences\", \"Medical ethics\": \"Health sciences\", \"Nursing\": \"Health sciences\", \"Nutrition and Dietetics\": \"Health sciences\", \"Occupational health\": \"Health sciences\", \"Parasitology\": \"Health sciences\", \"Public and environmental health\": \"Health sciences\", \"Social biomedical science\": \"Health sciences\", \"Sport and fitness science\": \"Health sciences\", \"Substance abuse\": \"Health sciences\", \"Tropical medicine\": \"Health sciences\",\n",
    "\t\"Medical biotechnology\": \"Medical biotechnology\", \"Biomedical devices\": \"Medical biotechnology\", \"Health-related biotechnology\": \"Medical biotechnology\", \"Pharmaceutical biotechnology\": \"Medical biotechnology\", \"Biotechnology and medical ethics\": \"Medical biotechnology\", \"Molecular diagnostics\": \"Medical biotechnology\", \"Biophysical manipulation\": \"Medical biotechnology\", \"Agricultural Sciences\": \"Medical biotechnology\",\n",
    "\n",
    "\t# 4 Agricultural Sciences\n",
    "\t\"Agriculture, forestry, and fisheries\": \"Agriculture, forestry, and fisheries\", \"Agriculture\": \"Agriculture, forestry, and fisheries\", \"Agronomy, plant breeding, plant protection\": \"Agriculture, forestry, and fisheries\", \"Fishery\": \"Agriculture, forestry, and fisheries\", \"Forestry\": \"Agriculture, forestry, and fisheries\", \"Horticulture and viticulture\": \"Agriculture, forestry, and fisheries\", \"Soil science\": \"Agriculture, forestry, and fisheries\",\n",
    "\t\"Animal and dairy sciences\": \"Animal and dairy sciences\", \"Animal science\": \"Animal and dairy sciences\", \"Dairy science\": \"Animal and dairy sciences\", \"Husbandry\": \"Animal and dairy sciences\", \"Pets\": \"Animal and dairy sciences\",\n",
    "\t\"Veterinary sciences\": \"Veterinary sciences\", \"Veterinary anaesthesiology\": \"Veterinary sciences\", \"Veterinary medicine\": \"Veterinary sciences\", \"Veterinary ophthalmology\": \"Veterinary sciences\", \"Veterinary pathobiology\": \"Veterinary sciences\", \"Veterinary radiology\": \"Veterinary sciences\", \"Veterinary reproduction\": \"Veterinary sciences\", \"Veterinary surgery\": \"Veterinary sciences\",\n",
    "\t\"Agricultural biotechnology\": \"Agricultural biotechnology\", \"Biomass feedstock production tech\": \"Agricultural biotechnology\", \"Biopharming\": \"Agricultural biotechnology\", \"Diagnostics\": \"Agricultural biotechnology\", \"Food biotechnology\": \"Agricultural biotechnology\", \"GM technology (crops, livestock)\": \"Agricultural biotechnology\", \"Livestock cloning\": \"Agricultural biotechnology\", \"Marker assisted selection\": \"Agricultural biotechnology\",\n",
    "\n",
    "\t# 5 Social Sciences\n",
    "\t\"Psychology\": \"Psychology\", \"Biological Psychology\": \"Psychology\", \"Clinical Psychology\": \"Psychology\", \"Cognitive Psychology\": \"Psychology\", \"Comparative Psychology\": \"Psychology\", \"Developmental Psychology\": \"Psychology\", \"Educational and School Psychology\": \"Psychology\", \"Evolutionary Psychology\": \"Psychology\", \"Industrialâ€“organisational Psychology\": \"Psychology\", \"Personality Psychology\": \"Psychology\", \"Positive Psychology\": \"Psychology\", \"Social Psychology\": \"Psychology\",\n",
    "\t\"Economics, finance and business\": \"Economics, finance and business\", \"Business and Management\": \"Economics, finance and business\", \"Economics and Econometrics\": \"Economics, finance and business\", \"Finance\": \"Economics, finance and business\", \"Industrial relations\": \"Economics, finance and business\",\n",
    "\t\"Educational sciences\": \"Educational sciences\", \"Educational science\": \"Educational sciences\", \"General Education\": \"Educational sciences\",  \"Special Education (learning disabilities)\": \"Educational sciences\",\n",
    "\t\"Sociology\": \"Sociology\", \"Anthropology\": \"Sociology\", \"Demography\": \"Sociology\", \"Ethnology\": \"Sociology\", \"Family studies\": \"Sociology\", \"Social issues\": \"Sociology\", \"Social work\": \"Sociology\", \"Sociology\": \"Sociology\", \"Women's and gender studie\": \"Sociology\",\n",
    "\t\"Law\": \"Law\", \"Canon Law\": \"Law\", \"Civil Law\": \"Law\", \"Comparative Law\": \"Law\", \"Competition Law\": \"Law\", \"Constitutional Law\": \"Law\", \"Criminal Law\": \"Law\", \"Islamic Law\": \"Law\", \"Jewish Law\": \"Law\", \"Jurisprudence (Philosophy of Law)\": \"Law\",\n",
    "\t\"Political sciences\": \"Political sciences\", \"Political science\": \"Political sciences\", \"Comparative politics\": \"Political sciences\", \"Empirical pata analysis\": \"Political sciences\", \"International relations\": \"Political sciences\", \"Organisation theory\": \"Political sciences\", \"Political economy\": \"Political sciences\", \"Political philosophy\": \"Political sciences\", \"Public administration\": \"Political sciences\", \"Theories of the state\": \"Political sciences\",\n",
    "\t\"Social and economic geography\": \"Social and economic geography\", \"Cultural and economic geography\": \"Social and economic geography\", \"Transport planning\": \"Social and economic geography\", \"Urban studies\": \"Social and economic geography\",\n",
    "\t\"Media and communications\": \"Media and communications\", \"Information science - social\": \"Media and communications\", \"Journalism\": \"Media and communications\", \"Library science\": \"Media and communications\", \"Media and socio-cultural communication\": \"Media and communications\",\n",
    "\n",
    "\t# 6 \"Humanities\",\n",
    "\t\"History and Archaeology\": \"History and Archaeology\", \"Archaeology\": \"History and Archaeology\", \"History (Prehistory; Ancient; Modern world)\": \"History and Archaeology\",\n",
    "\t\"Languages and literature\": \"Languages and literature\", \"General language studies\": \"Languages and literature\", \"General literature studies\": \"Languages and literature\", \"Linguistics\": \"Languages and literature\", \"Literary theory\": \"Languages and literature\", \"Specific languages\": \"Languages and literature\", \"Specific literatures\": \"Languages and literature\",\n",
    "\t\"Philosophy, ethics and religion\": \"Philosophy, ethics and religion\", \"Ethics\": \"Philosophy, ethics and religion\", \"Philosophy of science/technology\": \"Philosophy, ethics and religion\", \"Philosophy\": \"Philosophy, ethics and religion\", \"Religious studies\": \"Philosophy, ethics and religion\", \"Theology\": \"Philosophy, ethics and religion\",\n",
    "\t\"Arts\": \"Arts\", \"Architectural design\": \"Arts\", \"Folklore studies\": \"Arts\", \"Media Studies (Film, Radio, TV)\": \"Arts\", \"Musicology\": \"Arts\", \"Performing arts studies\": \"Arts\",\n",
    "\n",
    "\t# 7 \"Support Activities\"\n",
    "\t\"Archives\": \"Support Activities\", \"Development\": \"Support Activities\", \"Urban planning\": \"Support Activities\"\n",
    "} \n",
    "\n",
    "def map_fos(mapper, count_mapper):\n",
    "    def map_fos_(col):\n",
    "        if col == \"\" or not col:\n",
    "            return None\n",
    "        fields = list(filter(None, [mapper.get(t) for t in col]))\n",
    "        if len(fields):\n",
    "            return fields[0]\n",
    "        else:\n",
    "            col_count = [count_mapper[x] for x in col]\n",
    "            return col[col_count.index(max(col_count))]\n",
    "    return udf(map_fos_, StringType())\n",
    "\n",
    "def map_fos_id(rdd):\n",
    "    def map_fos_id_(col):\n",
    "        if col == \"null\" or col == \"\" or not col:\n",
    "            return None\n",
    "        try:\n",
    "            matches = [fosTuple[0] for fosTuple in list(rdd.items()) if fosTuple[1] == col]\n",
    "            if len(matches):\n",
    "                return matches[0]\n",
    "            else:\n",
    "                return None\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return udf(map_fos_id_, LongType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bb688248-acab-40ca-a1a9-59e5c4d108e6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Finding relevant `Field_of_Study` from `fos` list with mapped value with `translate` udf into \"Field_of_Study\" column.\n",
    "union = union.select(\"*\", F.col(\"fos\"), map_fos(decipline_mapper, count_mapper)(\"fos\").alias(\"Text\"))\n",
    "# Dropping `fos` column\n",
    "union = union.drop(\"fos\")\n",
    "\n",
    "# Building Frame of distinct disciplines out of \"Field_of_Study\" column.\n",
    "FoS_frame = distinct_frame_from_cols(union, [\"Text\"])\n",
    "save_delta_frame(FoS_frame, \"FieldOfStudy\")\n",
    "\n",
    "# Reading Mapping field of study to id, wuth RDD map for replacing \"Field_of_Study\" to relevant ID in the union table.\n",
    "FoSrdd = FoS_frame.rdd.collectAsMap()\n",
    "\n",
    "union = union.withColumn(\"FOS_ID\", map_fos_id(FoSrdd)(\"Text\")).drop(\"Text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "68d19eef-95b2-4fe8-bfba-c4c923555e58",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Venue Table (Conference/Workshop where article was presneted/cited)\n",
    "\n",
    "- Extract and flatten structure from main record\n",
    "- Clean raw data and fetch Name, acronym and relevant url\n",
    "- Remove Duplicates\n",
    "- Save table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "d20e1afa-a307-4b4c-9163-7bd9503c05cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "def venue_API(venue_string):\n",
    "    if venue_string and venue_string != '':\n",
    "        venue_string = venue_string.split(' ')[0]\n",
    "        URL = \"http://dblp.org/search/venue/api?q=\" + venue_string + \"%3A$&format=json\"\n",
    "        try:\n",
    "            r = requests.get(url = URL)\n",
    "            if r.status_code == 200:\n",
    "                data = r.json()\n",
    "                coAuths=[]\n",
    "                joursConfs=[]\n",
    "                data = data['result']['hits']\n",
    "                if int(data['@total']) > 0:\n",
    "                    return data['hit'][0]['info']['venue'], data['hit'][0]['info']['acronym'], data['hit'][0]['info']['url']\n",
    "        except:\n",
    "            pass\n",
    "    return None, None, None\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"acronym\", StringType(), True),\n",
    "    StructField(\"src\", StringType(), True),\n",
    "])\n",
    "\n",
    "venue_query_udf = udf(venue_API, schema)\n",
    "\n",
    "# Exploding a column returns a new row for each element in the given array or map type. \n",
    "# For each item in the map/array of data it creates a copy of the row and with that element in new column.\n",
    "# Here, We only select the exploded column, and so we only get row with author object in the generated frame.\n",
    "\n",
    "venue_frame = union.select(\"venue\")\n",
    "\n",
    "venue_frame = venue_frame.selectExpr(\"venue.*\")\n",
    "\n",
    "venue_frame = venue_frame.dropDuplicates([\"_id\"])\n",
    "venue_frame = venue_frame.select(\"*\", F.when(venue_frame.raw.isNotNull(), venue_query_udf(F.col(\"raw\"))).alias(\"query_results\"))\n",
    "venue_frame = venue_frame.drop('name_d', 'raw', 'name_s', 'name', 'sid', 'issn', 'online_issn', 'publisher', 'type', 'src', 'raw_zh', 't')\n",
    "venue_frame = venue_frame.select(\"*\", \"query_results.*\")\n",
    "venue_frame = venue_frame.drop(\"query_results\")\n",
    "\n",
    "venue_frame.drop(\"all\", subset=[\"name\", \"name_s\", \"url\"])\n",
    "\n",
    "save_delta_frame(venue_frame, \"Venue\", clean=True)\n",
    "\n",
    "## TODO: \n",
    "# 1. Pull more info before save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "3a625b76-62b2-4a67-bb00-2cb17246dd2f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Author and Organization Tables\n",
    "\n",
    "- Explode (with posexplode to get AuthorRank)author details from main record\n",
    "- Extract and flatten Organization for each author\n",
    "- Clean the data and split Name\n",
    "- Remove Duplicates\n",
    "- Save table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "32a34b07-f881-4e4e-9a9e-e4b100f63944",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# !pip install geograpy3 nltk -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "88a9a139-3dfb-4e38-a950-cfbac1fd694f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#import geograpy\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('maxent_ne_chunker')\n",
    "#nltk.download('words')\n",
    "\n",
    "#str(geograpy.locateCity(\"Michigan\"))\n",
    "#geograpy.get_place_context(text=\"University of Michigan, USA\")\n",
    "\n",
    "#print(geograpy.get_place_context(text=\"University of Tartu, Estonia\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "be77b338-09c4-4f19-afce-e8f7f0d2038d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Extracting Authors from the dataset\n",
    "\n",
    "# Exploding a column returns a new row for each element in the given array or map type. \n",
    "# For each item in the map/array of data it creates a copy of the row and with that element in new column.\n",
    "# Here, We only select the exploded column, and so we only get row with author object in the generated frame.\n",
    "\n",
    "union = union.select(\"*\", F.posexplode(\"authors\").alias(\"AuthorRank\", \"author\")).drop(\"authors\")\n",
    "authors_frame = union.selectExpr(\"author.*\")\n",
    "authors_frame = authors_frame.dropDuplicates([\"_id\"])\n",
    "\n",
    "# selectExpr Projects a set of SQL expressions and returns a new DataFrame. e.g. (authors['name', 'email'] => [authors.name, authors.email])\n",
    "authors_frame = authors_frame.drop(\"org_zh\", \"orgs_zh\", \"orcid\", \"oid\")\n",
    "authors_frame.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "734a0db3-557f-4571-8596-5d84ed8153a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "org_frame = authors_frame.select(\"_id\", \"org\", \"orgs\").withColumnRenamed(\"_id\", \"Author_ID\")\n",
    "org_frame = org_frame.na.drop(\"all\").distinct()\n",
    "org_frame = org_frame.withColumn(\"Organization\", F.when(F.col(\"org\").isNotNull(), F.col(\"org\")).otherwise(F.col(\"orgs\")[0])).select(\"Organization\", \"Author_ID\")\n",
    "\n",
    "org_frame = distinct_frame_from_cols(org_frame, [\"Organization\", \"Author_ID\"])\n",
    "save_delta_frame(org_frame, \"Organization\", clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2d28e23f-8e6b-4d23-a692-143724ecb377",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# 1. Extract Org, Country and city for each ORG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "45e2b3c5-88bc-4131-a1bc-af3c88aec3f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def author_name(name):\n",
    "    if name:\n",
    "        name = name.split()\n",
    "        if len(name) > 1:\n",
    "            if len(name) == 1:\n",
    "                return (name[0], None, None)\n",
    "            return (name[0], ' '.join(name[1:-1]), name[-1])\n",
    "    return None, None, None\n",
    "\n",
    "author_name_schema = StructType([\n",
    "    StructField(\"FirstName\", StringType(), True),\n",
    "    StructField(\"MiddleName\", StringType(), True),\n",
    "    StructField(\"LastName\", StringType(), True),\n",
    "])\n",
    "\n",
    "author_name_udf = udf(author_name, author_name_schema)\n",
    "\n",
    "authors_frame = authors_frame.select(\"*\", author_name_udf(\"name\").alias(\"author_name\"))\n",
    "authors_frame = authors_frame.select(\"*\", \"author_name.*\")\n",
    "authors_frame = authors_frame.drop(\"name\", \"author_name\", \"name_zh\", \"bio\", \"sid\", \"position\", \"avatar\", \"homepage\", \"oid\", \"orcid\", \"oid_zh\", \"orgs_zh\", \"orgs\", \"orgid\", \"org\", \"gid\")\n",
    "\n",
    "authors_frame = save_delta_frame(authors_frame, \"Author\", clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e8a107f1-5d77-4591-aca9-7905df8c23c5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "union = union.withColumn('doc_type', F.when(union.venue.raw.contains(\"@\"), 'workshop').when(union.volume.isNotNull(), 'journal').when(union.issue.isNotNull(), 'journal').otherwise('conference'))\n",
    "type_frame = distinct_frame_from_cols(union, [\"doc_type\"]).withColumnRenamed(\"doc_type\", \"Description\")\n",
    "type_rdd = type_frame.rdd.collectAsMap()\n",
    "\n",
    "union = union.withColumn(\"Type_ID\", map_fos_id(type_rdd)(\"doc_type\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "70769199-9d47-43c8-8fa9-070bd7c35019",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "union = union.withColumn(\"venue\", union.venue._id)\n",
    "union = union.withColumn(\"author\", union.author._id)\n",
    "\n",
    "union = union.withColumnRenamed(\"_id\", \"Publication_ID\")\n",
    "union = union.withColumnRenamed(\"author\", \"Author_ID\")\n",
    "union = union.withColumnRenamed(\"venue\", \"Venue_ID\")\n",
    "union = union.withColumn(\"AuthorRank\", F.col(\"AuthorRank\") + F.lit(1)).drop(\"doc_type\", \"volume\", \"issue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5eb7e0bc-d81b-4afc-bb67-7cea2f7fed8f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Keyword Lookup (Partially Implemented*)\n",
    "\n",
    "- Count keyword occurances to device a threshold for mapping\n",
    "- Remove keywords below threshold\n",
    "- Explode into fact table\n",
    "- Extract distinct and map unique ID in fact table in place of exploded keyword\n",
    "- Save table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "96661a54-c862-41ab-94f9-0dccb5f29d45",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# keyword_frame = union.select(F.explode_outer(\"keywords\").alias(\"key_countmap\"))\n",
    "# key_countmap = keyword_frame.groupBy(\"key_countmap\").count()\n",
    "# key_countmap = key_countmap.rdd.map(lambda row: row.asDict(True))\n",
    "# # union = union.drop(\"key_countmap\")\n",
    "# keyword_counts = key_countmap.collect()\n",
    "# keyword_counter = {}\n",
    "# for keyword_count in keyword_counts:\n",
    "#     keyword_counter[keyword_count['key_countmap']] = keyword_count['count']\n",
    "    \n",
    "# keyword_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5a4df416-1b68-4709-ad3e-08ba60f8e728",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Saving Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "5adebbea-5666-49a9-aad6-75a261352c1d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "save_delta_frame(union, \"FactTable\", clean=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "f77f9895-fa7a-4563-b3e7-014393d04965",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### LOAD\n",
    "\n",
    "#### Loading saved Tables back\n",
    "\n",
    "Future tasks: Update code for streaming write and read of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "860cf389-55db-4a5a-b9a8-16f5cd2a9146",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "language = spark.read.format('delta').load(f'{delta_dir}Language')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "a7c0b84c-7fde-413a-879e-6713d543f353",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "field_of_study = spark.read.format('delta').load(f'{delta_dir}FieldOfStudy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "dab63689-bbe6-4b9f-881f-be1e21fc74f4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "publications = spark.read.format('delta').load(f'{delta_dir}Publication')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2fda1d41-1ffd-4dfc-aa91-5fba18be8b67",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "venues = spark.read.format('delta').load(f'{delta_dir}Venue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "2598a85d-871c-4770-b31b-8496695383fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "authors = spark.read.format('delta').load(f'{delta_dir}Author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1b7efd18-d7da-49da-9ddb-61ccae1c6f37",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "organizations = spark.read.format('delta').load(f'{delta_dir}Organization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1d43689c-a207-4ecb-88ee-a6cad0bd46b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "factTable = spark.read.format('delta').load(f'{delta_dir}FactTable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "bdf7a89a-c264-4d04-92ba-2ef78344ff70",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Operations\n",
    "\n",
    "- H-Index [Reference](https://docs.microsoft.com/en-us/academic-services/graph/tutorial-databricks-hindex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "df0bd792-30ee-46a0-9409-1ecd5aff29c9",
     "showTitle": false,
     "title": ""
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "joined = factTable.join(publications, factTable.Publication_ID == publications._id).drop(\"_id\").withColumn(\"NumberOfCitations\", F.col(\"NumberOfCitations\").cast('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "1d773005-625e-43bf-b60f-0b058317d62f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "countFrame = joined.groupBy(\"Author_ID\").agg(\n",
    "        F.sum(\"NumberOfCitations\").alias(\"TotalCitations\"), \n",
    "        F.count(\"Publication_ID\").alias(\"PaperCount\"),\n",
    "    ).select(\"Author_ID\", \"TotalCitations\", \"PaperCount\")\n",
    "\n",
    "countFrame = authors.join(countFrame, countFrame.Author_ID == authors._id).withColumn(\"Name\", F.concat(\"FirstName\", F.lit(\" \"), \"LastName\")).drop(\"_id\", \"email\", \"FirstName\", \"MiddleName\", \"LastName\")\n",
    "display(countFrame.orderBy(F.col(\"PaperCount\").desc()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "88e7c2d0-e7d4-44d9-8bfa-cb27de6acadd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "h_index_frame = joined.join(countFrame, joined.Author_ID == joined.Author_ID).drop(joined.Author_ID)\n",
    "h_index_frame = h_index_frame.groupBy(\"Author_ID\").agg(\n",
    "        F.min(F.when(h_index_frame.NumberOfCitations >= h_index_frame.PaperCount, h_index_frame.PaperCount).otherwise(0)).alias('HIndex')\n",
    ")\n",
    "h_index_frame = authors.join(h_index_frame, h_index_frame.Author_ID == authors._id).withColumn(\"Name\", F.concat(\"FirstName\", F.lit(\" \"), \"LastName\")).drop(\"_id\", \"email\", \"FirstName\", \"MiddleName\", \"LastName\")\n",
    "display(h_index_frame.orderBy(F.col(\"HIndex\").desc()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "e7ed129f-2cb7-438d-b292-89ccce4c1537",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Checking output correctness for Author 'Diane Tang' with ID: 53f4cadadabfaee57c780346\n",
    "display(joined.filter(F.col('Author_ID') == '53f4cadadabfaee57c780346').select(\"publication_ID\", \"Author_ID\", \"NumberOfCitations\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "inputWidgets": {},
     "nuid": "42d178ad-1300-48d0-a678-43d983e96119",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Project 1",
   "notebookOrigID": 2835494419911001,
   "widgets": {}
  },
  "colab": {
   "collapsed_sections": [],
   "name": "Proj 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
