{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcd0271e-ff7f-469c-b8a3-45681e1074cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10062/98045 [00:00<00:02, 34246.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: \"Proceedings of the 8th Workshop on Online Abuse and Harms (WOAH 2024)\"\n",
      "Abstract: \n",
      "Matches query: False\n",
      "Pages:  -> Page Count: 0\n",
      "Year from URL: 2024\n",
      "------\n",
      "Title: \"Investigating radicalisation indicators in online extremist communities\"\n",
      "Abstract: \"We identify and analyse three sociolinguistic indicators of radicalisation within online extremist forums: hostility, longevity and social connectivity. We develop models to predict the maximum degree of each indicator measured over an individual{'}s lifetime, based on a minimal number of initial interactions. Drawing on data from two diverse extremist communities, our results demonstrate that NLP methods are effective at prioritising at-risk users. This work offers practical insights for intervention strategies and policy development, and highlights an important but under-studied research direction.\"\n",
      "Matches query: False\n",
      "Pages: \"1--12\" -> Page Count: 12\n",
      "Year from URL: 2024\n",
      "------\n",
      "Title: \"Detection of Conspiracy Theories Beyond Keyword Bias in {G}erman-Language Telegram Using Large Language Models\"\n",
      "Abstract: \"To protect users from massive hateful content, existing works studied automated hate speech detection. Despite the existing efforts, one question remains: do automated hate speech detectors conform to social media content policies? A platform{'}s content policies are a checklist of content moderated by the social media platform. Because content moderation rules are often uniquely defined, existing hate speech datasets cannot directly answer this question. This work seeks to answer this question by creating HateModerate, a dataset for testing the behaviors of automated content moderators against content policies. First, we engage 28 annotators and GPT in a six-step annotation process, resulting in a list of hateful and non-hateful test suites matching each of Facebook{'}s 41 hate speech policies. Second, we test the performance of state-of-the-art hate speech detectors against HateModerate, revealing substantial failures these models have in their conformity to the policies. Third, using HateModerate, we augment the training data of a top-downloaded hate detector on HuggingFace. We observe significant improvement in the models{'} conformity to content policies while having comparable scores on the original test data. Our dataset and code can be found in the attachment.\"\n",
      "Matches query: False\n",
      "Pages: \"13--27\" -> Page Count: 15\n",
      "Year from URL: 2024\n",
      "------\n",
      "Title: \"{E}ko{H}ate: Abusive Language and Hate Speech Detection for Code-switched Political Discussions on {N}igerian {T}witter\"\n",
      "Abstract: \"Nigerians have a notable online presence and actively discuss political and topical matters. This was particularly evident throughout the 2023 general election, where Twitter was used for campaigning, fact-checking and verification, and even positive and negative discourse. However, little or none has been done in the detection of abusive language and hate speech in Nigeria. In this paper, we curated code-switched Twitter data directed at three musketeers of the governorship election on the most populous and economically vibrant state in Nigeria; Lagos state, with the view to detect offensive speech in political discussions. We developed EkoHate{---}an abusive language and hate speech dataset for political discussions between the three candidates and their followers using a binary (normal vs offensive) and fine-grained four-label annotation scheme. We analysed our dataset and provided an empirical evaluation of state-of-the-art methods across both supervised and cross-lingual transfer learning settings. In the supervised setting, our evaluation results in both binary and four-label annotation schemes show that we can achieve 95.1 and 70.3 F1 points respectively. Furthermore, we show that our dataset adequately transfers very well to three publicly available offensive datasets (OLID, HateUS2020, and FountaHate), generalizing to political discussions in other regions like the US.\"\n",
      "Matches query: False\n",
      "Pages: \"28--37\" -> Page Count: 10\n",
      "Year from URL: 2024\n",
      "------\n",
      "Title: \"A Study of the Class Imbalance Problem in Abusive Language Detection\"\n",
      "Abstract: \"Abusive language detection has drawn increasing interest in recent years. However, a less systematically explored obstacle is label imbalance, i.e., the amount of abusive data is much lower than non-abusive data, leading to performance issues. The aim of this work is to conduct a comprehensive comparative study of popular methods for addressing the class imbalance issue. We explore 10 well-known approaches on 8 datasets with distinct characteristics: binary or multi-class, moderately or largely imbalanced, focusing on various types of abuse, etc. Additionally, we pro-pose two novel methods specialized for abuse detection: AbusiveLexiconAug and ExternalDataAug, which enrich the training data using abusive lexicons and external abusive datasets, respectively. We conclude that: 1) our AbusiveLexiconAug approach, random oversampling, and focal loss are the most versatile methods on various datasets; 2) focal loss tends to yield peak model performance; 3) oversampling and focal loss provide promising results for binary datasets and small multi-class sets, while undersampling and weighted cross-entropy are more suitable for large multi-class sets; 4) most methods are sensitive to hyperparameters, yet our suggested choice of hyperparameters provides a good starting point.\"\n",
      "Matches query: False\n",
      "Pages: \"38--51\" -> Page Count: 14\n",
      "Year from URL: 2024\n",
      "------\n",
      "Title: \"{H}ausa{H}ate: An Expert Annotated Corpus for {H}ausa Hate Speech Detection\"\n",
      "Abstract: \"We introduce the first expert annotated corpus of Facebook comments for Hausa hate speech detection. The corpus titled HausaHate comprises 2,000 comments extracted from Western African Facebook pages and manually annotated by three Hausa native speakers, who are also NLP experts. Our corpus was annotated using two different layers. We first labeled each comment according to a binary classification: offensive versus non-offensive. Then, offensive comments were also labeled according to hate speech targets: race, gender and none. Lastly, a baseline model using fine-tuned LLM for Hausa hate speech detection is presented, highlighting the challenges of hate speech detection tasks for indigenous languages in Africa, as well as future advances.\"\n",
      "Matches query: False\n",
      "Pages: \"52--58\" -> Page Count: 7\n",
      "Year from URL: 2024\n",
      "------\n",
      "Title: \"{VIDA}: The Visual Incel Data Archive. A Theory-oriented Annotated Dataset To Enhance Hate Detection Through Visual Culture\"\n",
      "Abstract: \"Images increasingly constitute a larger portion of internet content, encoding even more complex meanings. Recent studies have highlight the pivotal role of visual communication in the spread of extremist content, particularly that associated with right-wing political ideologies. However, the capability of machine learning systems to recognize such meanings, sometimes implicit, remains limited. To enable future research in this area, we introduce and release VIDA, the Visual Incel Data Archive, a multimodal dataset comprising visual material and internet memes collected from two main Incel communities (Italian and Anglophone) known for their extremist misogynistic content. Following the analytical framework of Shifman (2014), we propose a new taxonomy for annotation across three main levels of analysis: content, form, and stance (hate). This allows for the association of images with fine-grained contextual information that help to identify the presence of offensiveness and a broader set of cultural references, enhancing the understanding of more nuanced aspects in visual communication. In this work we present a statistical analysis of the annotated dataset as well as discuss annotation examples and future line of research.\"\n",
      "Matches query: False\n",
      "Pages: \"59--67\" -> Page Count: 9\n",
      "Year from URL: 2024\n",
      "------\n",
      "Title: \"Towards a Unified Framework for Adaptable Problematic Content Detection via Continual Learning\"\n",
      "Abstract: \"Detecting problematic content, such as hate speech, is a multifaceted and ever-changing task, influenced by social dynamics, user populations, diversity of sources, and evolving language. There has been significant efforts, both in academia and in industry, to develop annotated resources that capture various aspects of problematic content. Due to researchers{'} diverse objectives, these annotations are often inconsistent and hence, reports of progress on the detection of problematic content are fragmented. This pattern is expected to persist unless we pool these resources, taking into account the dynamic nature of this issue. In this paper, we propose integrating the available resources, leveraging their dynamic nature to break this pattern, and introduce a continual learning framework and benchmark for problematic content detection. Our benchmark, comprising 84 related tasks, creates a novel measure of progress: prioritizing the adaptability of classifiers to evolving tasks over excelling in specific tasks. To ensure continuous relevance, our benchmark is designed for seamless integration of new tasks. Our results demonstrate that continual learning methods outperform static approaches by up to 17{\\%} and 4{\\%} AUC in capturing the evolving content and adapting to novel forms of problematic content\"\n",
      "Matches query: False\n",
      "Pages: \"68--109\" -> Page Count: 42\n",
      "Year from URL: 2024\n",
      "------\n",
      "Title: \"From Linguistics to Practice: a Case Study of Offensive Language Taxonomy in {H}ebrew\"\n",
      "Abstract: \"The perception of offensive language varies based on cultural, social, and individual perspectives. With the spread of social media, there has been an increase in offensive content online, necessitating advanced solutions for its identification and moderation. This paper addresses the practical application of an offensive language taxonomy, specifically targeting Hebrew social media texts. By introducing a newly annotated dataset, modeled after the taxonomy of explicit offensive language of (Lewandowska-Tomaszczyk et al., 2023)„ we provide a comprehensive examination of various degrees and aspects of offensive language. Our findings indicate the complexities involved in the classification of such content. We also outline the implications of relying on fixed taxonomies for Hebrew.\"\n",
      "Matches query: False\n",
      "Pages: \"110--117\" -> Page Count: 8\n",
      "Year from URL: 2024\n",
      "------\n",
      "Title: \"Estimating the Emotion of Disgust in {G}reek Parliament Records\"\n",
      "Abstract: \"We present an analysis of the sentiment in Greek political speech, by focusing on the most frequently occurring emotion in electoral data, the emotion of {``}disgust{''}. We show that emotion classification is generally tough, but high accuracy can be achieved for that particular emotion. Using our best-performing model to classify political records of the Greek Parliament Corpus from 1989 to 2020, we studied the points in time when this emotion was frequently occurring and we ranked the Greek political parties based on their estimated score. We then devised an algorithm to investigate the emotional context shift of words that describe specific conditions and that can be used to stigmatise. Given that early detection of such word usage is essential for policy-making, we report two words we found being increasingly used in a negative emotional context, and one that is likely to be carrying stigma, in the studied parliamentary records.\"\n",
      "Matches query: False\n",
      "Pages: \"118--135\" -> Page Count: 18\n",
      "Year from URL: 2024\n",
      "------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 98045/98045 [00:01<00:00, 49706.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of final papers: 79\n",
      "                                               title  \\\n",
      "0  \"Calibration-Tuning: Teaching Large Language M...   \n",
      "1  \"Cross-Task Defense: Instruction-Tuning {LLM}s...   \n",
      "2  \"{B}ad{R}ock at {S}em{E}val-2024 Task 8: {D}is...   \n",
      "3  \"Team Innovative at {S}em{E}val-2024 Task 8: M...   \n",
      "4  \"Mast Kalandar at {S}em{E}val-2024 Task 8: On ...   \n",
      "\n",
      "                                               url doi  \\\n",
      "0  \"https://aclanthology.org/2024.uncertainlp-1.1\"       \n",
      "1     \"https://aclanthology.org/2024.trustnlp-1.9\"       \n",
      "2     \"https://aclanthology.org/2024.semeval-1.37\"       \n",
      "3    \"https://aclanthology.org/2024.semeval-1.171\"       \n",
      "4    \"https://aclanthology.org/2024.semeval-1.231\"       \n",
      "\n",
      "                                            abstract  # pages     paper_type  \\\n",
      "0  \"Large language models are increasingly deploy...       14  inproceedings   \n",
      "1  \"Recent studies reveal that Large Language Mod...        9  inproceedings   \n",
      "2  \"The rise of Large Language Models (LLMs) has ...        7  inproceedings   \n",
      "3  \"With the widespread adoption of large languag...        5  inproceedings   \n",
      "4  \"Large Language Models (LLMs) have showcased i...        7  inproceedings   \n",
      "\n",
      "   year                                             bibtex  \n",
      "0  2024  @inproceedings{kapoor-etal-2024-calibration,\\n...  \n",
      "1  2024  @inproceedings{fu-etal-2024-cross,\\n    title ...  \n",
      "2  2024  @inproceedings{siino-2024-badrock,\\n    title ...  \n",
      "3  2024  @inproceedings{sharma-mansuri-2024-team,\\n    ...  \n",
      "4  2024  @inproceedings{bafna-etal-2024-mast,\\n    titl...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "# Function to parse .bib entries\n",
    "def parse_bib_entry(entry):\n",
    "    entry_dict = {}\n",
    "    lines = entry.strip().split('\\n')\n",
    "    if lines and '{' in lines[0]:\n",
    "        entry_dict['type'] = lines[0].split('{')[0].strip('@')\n",
    "        key = lines[0].split('{')[1].strip(',').strip('}')\n",
    "        entry_dict['key'] = key\n",
    "        for line in lines[1:]:\n",
    "            if '=' in line:\n",
    "                k, v = line.split('=', 1)\n",
    "                entry_dict[k.strip()] = v.strip().strip('{},')\n",
    "    return entry_dict\n",
    "\n",
    "# Function to convert page range to number of pages using regex\n",
    "def page_count(pages):\n",
    "    match = re.search(r'(\\d+)\\s*--\\s*(\\d+)', pages)\n",
    "    if match:\n",
    "        try:\n",
    "            start = int(match.group(1))\n",
    "            end = int(match.group(2))\n",
    "            return end - start + 1\n",
    "        except ValueError:\n",
    "            return 0\n",
    "    return 0\n",
    "\n",
    "# Function to find year using regex from URL\n",
    "def find_year_from_url(url):\n",
    "    match = re.search(r'https://aclanthology.org/(\\d{4})', url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return ''\n",
    "\n",
    "# Read the .bib file\n",
    "file_path = './anthology+abstracts.bib'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Split content into individual entries\n",
    "entries = content.split('@')[1:]\n",
    "data = [parse_bib_entry('@' + entry) for entry in entries if parse_bib_entry('@' + entry)]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Fill NaN values with empty strings\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Define the search terms\n",
    "#keywords = [\"software engineering\", \"programming\", \"software development\", \"computer science\", \"computer engineering\"]\n",
    "education_terms = [\"education\", \"teaching\"]\n",
    "model_terms = [\"LLM\", \"large language model\"]\n",
    "\n",
    "# Function to check if an entry matches the search query\n",
    "def matches_query(entry, keywords, education_terms, model_terms):\n",
    "    title = entry.get('title', '').lower()\n",
    "    abstract = entry.get('abstract', '').lower()\n",
    "    #keywords_match = any(kw in title or kw in abstract for kw in keywords)\n",
    "    education_match = any(term in title or term in abstract for term in education_terms)\n",
    "    model_match = any(term in title or term in abstract for term in model_terms)\n",
    "    return education_match and model_match\n",
    "\n",
    "# Search for matching entries\n",
    "matching_entries = []\n",
    "for index, entry in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "    if matches_query(entry, keywords, education_terms, model_terms):\n",
    "        matching_entries.append(entry)\n",
    "    # Log some entries for manual check\n",
    "    if index < 10:\n",
    "        print(f\"Title: {entry.get('title', '')}\")\n",
    "        print(f\"Abstract: {entry.get('abstract', '')}\")\n",
    "        print(f\"Matches query: {matches_query(entry, keywords, education_terms, model_terms)}\")\n",
    "        print(f\"Pages: {entry.get('pages', '')} -> Page Count: {page_count(entry.get('pages', ''))}\")\n",
    "        print(f\"Year from URL: {find_year_from_url(entry.get('url', ''))}\")\n",
    "        print(\"------\")\n",
    "\n",
    "# Extract required information\n",
    "final_data = []\n",
    "for entry in matching_entries:\n",
    "    page_count_value = page_count(entry.get('pages', ''))\n",
    "    if page_count_value == 0 and '--' in entry.get('pages', ''):\n",
    "        print(f\"Error in page count conversion for entry: {entry.get('pages', '')}\")\n",
    "    final_data.append({\n",
    "        'title': entry.get('title', ''),\n",
    "        'url': entry.get('url', ''),\n",
    "        'doi': entry.get('doi', '') or entry.get('URL', ''),  # Attempt to extract DOI or URL\n",
    "        'abstract': entry.get('abstract', ''),\n",
    "        '# pages': page_count_value,\n",
    "        'paper_type': entry.get('type', ''),\n",
    "        'year': find_year_from_url(entry.get('url', '')),\n",
    "        'bibtex': '@' + entry.get('type', '') + '{' + entry.get('key', '') + ',\\n' + '\\n'.join([f'    {k} = {{{v}}},' for k, v in entry.items() if k not in ['type', 'key']]) + '\\n}'\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the final data\n",
    "final_df = pd.DataFrame(final_data)\n",
    "\n",
    "# Save the final results to a CSV file\n",
    "csv_file_path = './ACL.csv'\n",
    "final_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "# Print the number of final papers\n",
    "print(f\"Number of final papers: {len(final_df)}\")\n",
    "\n",
    "# Print the first few matching entries\n",
    "if len(final_df) > 0:\n",
    "    print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571c4eab-7e50-48ff-81fc-e6384e8e033c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
