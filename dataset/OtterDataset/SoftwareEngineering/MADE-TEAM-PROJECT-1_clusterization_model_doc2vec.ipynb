{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Doc2Vec on scientific articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook replicates the **Document Embedding with Paragraph Vectors** paper, http://arxiv.org/abs/1507.07998.\n",
    "\n",
    "In that paper, the authors only showed results from the DBOW (\"distributed bag of words\") mode, trained on the article dataset. Here we replicate this experiment using not only DBOW, but also the DM (\"distributed memory\") mode of the Paragraph Vector algorithm aka Doc2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the necessary modules and set up logging. The code below assumes Python 3.7+ and Gensim 4.0+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import multiprocessing\n",
    "from pprint import pprint\n",
    "\n",
    "import smart_open\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "from collections import Counter\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_DROP = ['year', 'n_citation', 'references', 'authors','venue', 'lang', 'page_start', 'page_end', 'volume',\n",
    "       'issue', 'issn', 'isbn', 'doi', 'pdf', 'url']\n",
    "RANDOM_STATE = 47\n",
    "NUM_PARTS = 8\n",
    "\n",
    "def get_text_data(file_path):\n",
    "    \n",
    "    data = pd.read_json(file_path, dtype={'title': 'string', 'abstract': 'string'})\n",
    "    data.drop(COLUMNS_TO_DROP, axis=1, inplace=True)\n",
    "    data['abstract'].replace('', np.nan, inplace=True)\n",
    "    data['title'].replace('', np.nan, inplace=True)\n",
    "    data['fos'].replace([], np.nan, inplace=True)\n",
    "    data = data.dropna(subset=['keywords', 'abstract', 'title', 'fos'])\n",
    "    data['text'] = data[['title', 'abstract']].apply(lambda row: '  '.join(row.astype(str)), axis=1).astype('string')\n",
    "    data.drop(['title', 'abstract'], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 13:34:13,515 : INFO : Note: NumExpr detected 32 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "2022-10-27 13:34:13,516 : INFO : NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1824173 entries, 0 to 1824172\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   _id       object\n",
      " 1   keywords  object\n",
      " 2   fos       object\n",
      " 3   text      object\n",
      "dtypes: object(4)\n",
      "memory usage: 69.6+ MB\n"
     ]
    }
   ],
   "source": [
    "articles = pd.concat(get_text_data(f'data/part_{i+1}.json') for i in range(NUM_PARTS))\n",
    "articles.reset_index(drop=True, inplace=True)\n",
    "articles.to_json('articles.json')\n",
    "articles.to_csv('articles.csv')\n",
    "articles = pd.read_json('articles.json')\n",
    "\n",
    "articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 258469 entries, 0 to 258468\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   _id       258469 non-null  object\n",
      " 1   keywords  258469 non-null  object\n",
      " 2   fos       258469 non-null  object\n",
      " 3   text      258469 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 9.9+ MB\n"
     ]
    }
   ],
   "source": [
    "test_articles = get_text_data('data/part_10.json')\n",
    "test_articles.reset_index(drop=True, inplace=True)\n",
    "test_articles.to_json('articles.json')\n",
    "test_articles = pd.read_json('articles.json')\n",
    "\n",
    "test_articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>keywords</th>\n",
       "      <th>fos</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>558332610cf2485614700b00</td>\n",
       "      <td>[adaptive control, control system synthesis, h...</td>\n",
       "      <td>[Adaptability, Simulation, Terrain, Systems de...</td>\n",
       "      <td>An adaptive mobility system for the disabled  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>558331150cf2320d1b9975fe</td>\n",
       "      <td>[integrated services digital networks]</td>\n",
       "      <td>[Signal processing, Intersymbol interference, ...</td>\n",
       "      <td>Modeling and Analysis of Error Probability Per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>558332640cf2320d1b99763a</td>\n",
       "      <td>[computational complexity, computational geome...</td>\n",
       "      <td>[Motion planning, Discrete mathematics, Polyhe...</td>\n",
       "      <td>Interference detection between non-convex poly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>558331180cf2485614700ac3</td>\n",
       "      <td>[mobile robots, position control, climbing rob...</td>\n",
       "      <td>[Robot control, Computer vision, Simulation, B...</td>\n",
       "      <td>A climbing robot with continuous motion  A wal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>558331250cf2485614700ac4</td>\n",
       "      <td>[electric sensing devices, feedback, mobile ro...</td>\n",
       "      <td>[Teleoperation, Robot control, Simulation, Sup...</td>\n",
       "      <td>Stabilization of a mobile robot climbing stair...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  558332610cf2485614700b00   \n",
       "1  558331150cf2320d1b9975fe   \n",
       "2  558332640cf2320d1b99763a   \n",
       "3  558331180cf2485614700ac3   \n",
       "4  558331250cf2485614700ac4   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [adaptive control, control system synthesis, h...   \n",
       "1             [integrated services digital networks]   \n",
       "2  [computational complexity, computational geome...   \n",
       "3  [mobile robots, position control, climbing rob...   \n",
       "4  [electric sensing devices, feedback, mobile ro...   \n",
       "\n",
       "                                                 fos  \\\n",
       "0  [Adaptability, Simulation, Terrain, Systems de...   \n",
       "1  [Signal processing, Intersymbol interference, ...   \n",
       "2  [Motion planning, Discrete mathematics, Polyhe...   \n",
       "3  [Robot control, Computer vision, Simulation, B...   \n",
       "4  [Teleoperation, Robot control, Simulation, Sup...   \n",
       "\n",
       "                                                text  \n",
       "0  An adaptive mobility system for the disabled  ...  \n",
       "1  Modeling and Analysis of Error Probability Per...  \n",
       "2  Interference detection between non-convex poly...  \n",
       "3  A climbing robot with continuous motion  A wal...  \n",
       "4  Stabilization of a mobile robot climbing stair...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_articles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f53ef0e94a45a6985bba1d3fb43e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=456044), Label(value='0 / 456044')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.4 s, sys: 24.4 s, total: 1min 23s\n",
      "Wall time: 7min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def normalize(sentence):\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    porter = PorterStemmer()\n",
    "    if isinstance(sentence, list):\n",
    "        return [word.lower() for word in sentence]\n",
    "        #return [porter.stem(word) for word in sentence]\n",
    "    return ' '.join(porter.stem(word) for word in sentence.split())\n",
    "\n",
    "articles = articles.parallel_applymap(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('computer science', 1127637),\n",
       " ('mathematics', 413745),\n",
       " ('artificial intelligence', 341173),\n",
       " ('algorithm', 165940),\n",
       " ('computer network', 120221),\n",
       " ('computer vision', 117480),\n",
       " ('discrete mathematics', 114166),\n",
       " ('engineering', 110202),\n",
       " ('distributed computing', 104010),\n",
       " ('mathematical optimization', 99134),\n",
       " ('combinatorics', 96472),\n",
       " ('theoretical computer science', 93219),\n",
       " ('pattern recognition', 86478),\n",
       " ('data mining', 85147),\n",
       " ('control theory', 75038),\n",
       " ('world wide web', 72621),\n",
       " ('machine learning', 67116),\n",
       " ('programming language', 62127),\n",
       " ('information retrieval', 55339),\n",
       " ('multimedia', 54431),\n",
       " ('software', 53105),\n",
       " ('computer security', 52954),\n",
       " ('knowledge management', 50674),\n",
       " ('software engineering', 49672),\n",
       " ('human–computer interaction', 48856),\n",
       " ('parallel computing', 48698),\n",
       " ('electronic engineering', 47390),\n",
       " ('the internet', 46992),\n",
       " ('real-time computing', 44455),\n",
       " ('natural language processing', 44397),\n",
       " ('artificial neural network', 42081),\n",
       " ('embedded system', 40862),\n",
       " ('speech recognition', 39771),\n",
       " ('mathematical analysis', 39574),\n",
       " ('computation', 36223),\n",
       " ('simulation', 35372),\n",
       " ('communication channel', 32935),\n",
       " ('cluster analysis', 32486),\n",
       " ('scheduling (computing)', 31660),\n",
       " ('database', 31189),\n",
       " ('scalability', 30610),\n",
       " ('psychology', 29666),\n",
       " ('applied mathematics', 29642),\n",
       " ('robustness (computer science)', 28294),\n",
       " ('nonlinear system', 26817),\n",
       " ('wireless sensor network', 26674),\n",
       " ('fuzzy logic', 26522),\n",
       " ('architecture', 26369),\n",
       " ('information system', 26354),\n",
       " ('graph', 26330)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_freq = Counter()\n",
    "for index, doc in articles.iterrows():\n",
    "    tag_freq.update(Counter(doc['fos']))\n",
    "    #tag_freq.update(Counter(doc['keywords']))\n",
    "\n",
    "tag_freq.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data mining', 44934),\n",
       " ('computer science', 33771),\n",
       " ('internet', 33656),\n",
       " ('real time', 30102),\n",
       " ('satisfiability', 26700),\n",
       " ('feature extraction', 25331),\n",
       " ('computational complexity', 24608),\n",
       " ('neural network', 22856),\n",
       " ('indexing terms', 22481),\n",
       " ('protocols', 21203),\n",
       " ('computational modeling', 20720),\n",
       " ('algorithm design and analysis', 20581),\n",
       " ('algorithms', 20108),\n",
       " ('information retrieval', 19584),\n",
       " ('mathematical model', 19269),\n",
       " ('quality of service', 19064),\n",
       " ('optimization', 18836),\n",
       " ('computer architecture', 17998),\n",
       " ('indexation', 17877),\n",
       " ('genetic algorithm', 17351),\n",
       " ('software engineering', 17316),\n",
       " ('testing', 17162),\n",
       " ('wireless sensor networks', 17078),\n",
       " ('machine learning', 17042),\n",
       " ('hardware', 16453),\n",
       " ('scheduling', 16304),\n",
       " ('image segmentation', 16014),\n",
       " ('robustness', 15982),\n",
       " ('bandwidth', 15756),\n",
       " ('application software', 15547),\n",
       " ('security', 14338),\n",
       " ('computer vision', 14031),\n",
       " ('image processing', 13973),\n",
       " ('real time systems', 13919),\n",
       " ('information technology', 13898),\n",
       " ('routing', 13673),\n",
       " ('chip', 13615),\n",
       " ('data structure', 13285),\n",
       " ('bioinformatics', 12854),\n",
       " ('probability', 12839),\n",
       " ('wireless sensor network', 12837),\n",
       " ('information system', 12827),\n",
       " ('signal processing', 12800),\n",
       " ('simulation', 12709),\n",
       " ('case study', 12702),\n",
       " ('decoding', 12670),\n",
       " ('mobile computing', 12628),\n",
       " ('wireless communication', 12580),\n",
       " ('signal to noise ratio', 12502),\n",
       " ('throughput', 12349)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_freq_kw = Counter()\n",
    "for index, doc in articles.iterrows():\n",
    "    tag_freq_kw.update(Counter(doc['keywords']))\n",
    "\n",
    "tag_freq_kw.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130119"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tag_freq)\n",
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14869"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_freq_tags = {tag:tag_freq[tag] for tag in tag_freq if tag_freq[tag] > 99}\n",
    "len(most_freq_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaggedCorpus:\n",
    "    def __init__(self, dataframe, min_freq=99):\n",
    "        self.df = dataframe\n",
    "        self.min_freq = min_freq\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for index, row in self.df.iterrows():\n",
    "            kws = {kw for kw in row['fos'] if tag_freq[kw] > self.min_freq}\n",
    "            kws.discard('computer science')\n",
    "            if len(kws) < 2:\n",
    "                continue\n",
    "            yield TaggedDocument(words=row['text'].split(), tags=list(kws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents399 = TaggedCorpus(articles, min_freq=399)\n",
    "documents99 = TaggedCorpus(articles, min_freq=99)\n",
    "documents1499 = TaggedCorpus(articles, min_freq=1499)\n",
    "#documents = [TaggedDocument(row['text'], [row['_id']]) for index, row in articles.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hydrology', 'irrigation', 'environmental science', 'canopy', 'moisture', 'agronomy', 'water content', 'soil water'] :  ['the', 'relationship', 'between', 'canopi', 'paramet', 'and', 'spectrum', 'of', 'winter', 'wheat', 'under', 'differ', 'irrig', 'in', 'hebei', 'province.', 'drought', 'is', 'the', 'first', 'place', 'in', 'all', 'the', 'natur', 'disast', 'in', 'the', 'world.', 'It', 'is', 'especi', 'seriou', 'in', 'north', 'china', 'plain.', 'In', 'thi', 'paper,', 'differ', 'soil', 'water', 'content', 'control', 'level', 'at', 'winter', 'wheat', 'growth', 'stage', 'are', 'perform', 'on', 'gucheng', 'ecological-meteorolog', 'integr', 'observ', 'experi', 'station', 'of', 'cams,', 'china.', 'some', 'canopi', 'parameters,', 'includ', 'growth', 'conditions,', 'dri', 'weight,', 'physiolog', 'paramet', 'and', 'hyperspectr', 'reflectance,', 'are', 'measur', 'from', 'erect', 'stage', 'to', 'milk', 'stage', 'for', 'winter', 'wheat', 'in', '2009.', 'the', 'relationship', 'between', 'canopi', 'paramet', 'and', 'soil', 'rel', 'moisture,', 'canopi', 'water', 'content', 'and', 'water', 'indic', 'of', 'winter', 'wheat', 'are', 'established.', 'the', 'result', 'show', 'that', 'some', 'parameters,', 'such', 'as', 'spad', 'and', 'dri', 'weight', 'of', 'leaves,', 'decreas', 'with', 'the', 'increas', 'of', 'soil', 'rel', 'moisture,', 'while', 'other', 'parameters,', 'includ', 'dri', 'weight', 'of', 'caudexes,', 'abov', 'ground', 'dri', 'weight,', 'height,', 'photosynthesi', 'rate,', 'intercellular', 'CO', '2', 'concentration,', 'stomat', 'conduct', 'and', 'transpir', 'rate,', 'increas', 'correspond', 'to', 'the', 'soil', 'rel', 'moisture.', 'obviou', 'linear', 'relationship', 'between', 'stomat', 'conduct', 'and', 'transpir', 'rate', 'is', 'establish', 'with', '45', 'samples,', 'which', 'R2', 'reach', 'to', '0.6152.', 'finally,', 'the', 'fit', 'equat', 'between', 'canopi', 'water', 'content', 'and', 'water', 'indic', 'are', 'regress', 'with', 'b5,', 'b6', 'and', 'b7', 'of', 'modi', 'bands.', 'the', 'equat', 'are', 'best', 'with', 'b7', 'and', 'worst', 'with', 'b5.', 'So', 'the', 'fit', 'equat', 'with', 'b7', 'can', 'be', 'use', 'to', 'invers', 'the', 'canopi', 'water', 'content', 'of', 'winter', 'wheat', 'use', 'modi', 'or', 'other', 'remot', 'sens', 'imag', 'with', 'similar', 'band', 'rang', 'to', 'modi', 'in', 'hebei', 'province.', '©', '2011', 'ieee.']\n"
     ]
    }
   ],
   "source": [
    "# Load and print the first preprocessed document, as a sanity check = \"input eyeballing\".\n",
    "first_doc = next(iter(documents99))\n",
    "print(first_doc.tags, ': ', first_doc.words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algorithm', 'shortest path problem', 'statistics', 'sequential logic', 'monte carlo method'] :  ['time', 'yield', 'estim', 'use', 'statist', 'static', 'time', 'analysi', 'As', 'process', 'variat', 'becom', 'a', 'signific', 'problem', 'in', 'deep', 'sub-micron', 'technology,', 'a', 'shift', 'from', 'determinist', 'static', 'time', 'analysi', 'to', 'statist', 'static', 'time', 'analysi', 'for', 'high-perform', 'circuit', 'design', 'could', 'reduc', 'the', 'excess', 'conservat', 'that', 'is', 'built', 'into', 'current', 'time', 'design', 'methods.', 'We', 'address', 'the', 'time', 'yield', 'problem', 'for', 'sequenti', 'circuit', 'and', 'propos', 'a', 'statist', 'approach', 'to', 'handl', 'it.', 'We', 'consid', 'the', 'spatial', 'and', 'path', 'reconverg', 'correl', 'between', 'path', 'delays,', 'set-up', 'time', 'and', 'hold', 'time', 'constraints,', 'and', 'clock', 'skew', 'due', 'to', 'process', 'variations.', 'We', 'propos', 'a', 'method', 'to', 'get', 'the', 'time', 'yield', 'base', 'on', 'the', 'delay', 'distribut', 'of', 'register-to-regist', 'path', 'in', 'the', 'circuit', 'On', 'average,', 'the', 'time', 'yield', 'result', 'obtain', 'by', 'our', 'approach', 'have', 'averag', 'error', 'of', 'less', 'than', '1.0%', 'in', 'comparison', 'with', 'mont', 'carlo', 'simulation.', 'experiment', 'result', 'show', 'that', 'shortest', 'path', 'variat', 'and', 'clock', 'skew', 'due', 'to', 'process', 'variat', 'have', 'consider', 'impact', 'on', 'circuit', 'timing,', 'which', 'could', 'bia', 'the', 'time', 'yield', 'results.', 'In', 'addition,', 'the', 'correl', 'between', 'longest', 'and', 'shortest', 'path', 'delay', 'is', 'not', 'significant.']\n"
     ]
    }
   ],
   "source": [
    "# Load and print the first preprocessed document, as a sanity check = \"input eyeballing\".\n",
    "first_doc = next(iter(documents1499))\n",
    "print(first_doc.tags, ': ', first_doc.words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document seems legit so let's move on to finally training some Doc2vec models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Doc2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original paper had a vocabulary size of 915,715 word types, so we'll try to match it by setting `max_final_vocab` to 1,000,000 in the Doc2vec constructor.\n",
    "\n",
    "Other critical parameters were left unspecified in the paper, so we'll go with a window size of eight (a prediction window of 8 tokens to either side). It looks like the authors tried vector dimensionality of 100, 300, 1,000 & 10,000 in the paper (with 10k dims performing the best), but I'll only train with 200 dimensions here, to keep the RAM in check on my laptop.\n",
    "\n",
    "Feel free to tinker with these values yourself if you like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 14:08:57,006 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>', 'datetime': '2022-10-27T14:08:56.973874', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'created'}\n",
      "2022-10-27 14:08:57,007 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>', 'datetime': '2022-10-27T14:08:57.007875', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'created'}\n",
      "2022-10-27 14:08:57,008 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>', 'datetime': '2022-10-27T14:08:57.008944', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "workers = multiprocessing.cpu_count() - 2  # leave one core for the OS & other stuff\n",
    "\n",
    "\n",
    "# PV-DBOW: paragraph vector in distributed bag of words mode\n",
    "model_dbow99 = Doc2Vec(\n",
    "    dm=0, dbow_words=1,  # dbow_words=1 to train word vectors at the same time too, not only DBOW\n",
    "    vector_size=200, window=8, epochs=12, workers=workers, max_final_vocab=1000000,\n",
    ")\n",
    "\n",
    "# PV-DBOW: paragraph vector in distributed bag of words mode\n",
    "model_dbow399 = Doc2Vec(\n",
    "    dm=0, dbow_words=1,  # dbow_words=1 to train word vectors at the same time too, not only DBOW\n",
    "    vector_size=200, window=8, epochs=12, workers=workers, max_final_vocab=1000000,\n",
    ")\n",
    "\n",
    "# PV-DBOW: paragraph vector in distributed bag of words mode\n",
    "model_dbow1499 = Doc2Vec(\n",
    "    dm=0, dbow_words=1,  # dbow_words=1 to train word vectors at the same time too, not only DBOW\n",
    "    vector_size=200, window=8, epochs=12, workers=workers, max_final_vocab=1000000,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 14:15:00,203 : INFO : collecting all words and their counts\n",
      "2022-10-27 14:15:00,205 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2022-10-27 14:15:12,819 : INFO : PROGRESS: at example #100000, processed 13844549 words (1097663 words/s), 381145 word types, 5708 tags\n",
      "2022-10-27 14:15:25,343 : INFO : PROGRESS: at example #200000, processed 27386108 words (1081320 words/s), 627224 word types, 5708 tags\n",
      "2022-10-27 14:15:37,949 : INFO : PROGRESS: at example #300000, processed 41843358 words (1146934 words/s), 840040 word types, 5708 tags\n",
      "2022-10-27 14:15:50,623 : INFO : PROGRESS: at example #400000, processed 56246304 words (1136493 words/s), 1030567 word types, 5708 tags\n",
      "2022-10-27 14:16:03,363 : INFO : PROGRESS: at example #500000, processed 70637102 words (1129619 words/s), 1209311 word types, 5708 tags\n",
      "2022-10-27 14:16:16,090 : INFO : PROGRESS: at example #600000, processed 85030601 words (1131102 words/s), 1377326 word types, 5708 tags\n",
      "2022-10-27 14:16:28,897 : INFO : PROGRESS: at example #700000, processed 99519294 words (1131353 words/s), 1538155 word types, 5708 tags\n",
      "2022-10-27 14:16:41,649 : INFO : PROGRESS: at example #800000, processed 113827610 words (1122202 words/s), 1693379 word types, 5708 tags\n",
      "2022-10-27 14:16:54,374 : INFO : PROGRESS: at example #900000, processed 127894053 words (1105466 words/s), 1843009 word types, 5708 tags\n",
      "2022-10-27 14:17:07,176 : INFO : PROGRESS: at example #1000000, processed 142168050 words (1115053 words/s), 1988069 word types, 5708 tags\n",
      "2022-10-27 14:17:19,944 : INFO : PROGRESS: at example #1100000, processed 156313918 words (1108010 words/s), 2130569 word types, 5708 tags\n",
      "2022-10-27 14:17:32,770 : INFO : PROGRESS: at example #1200000, processed 170803711 words (1129885 words/s), 2268805 word types, 5708 tags\n",
      "2022-10-27 14:17:45,732 : INFO : PROGRESS: at example #1300000, processed 185314872 words (1119574 words/s), 2405454 word types, 5708 tags\n",
      "2022-10-27 14:17:58,508 : INFO : PROGRESS: at example #1400000, processed 199468925 words (1107916 words/s), 2536778 word types, 5708 tags\n",
      "2022-10-27 14:18:11,416 : INFO : PROGRESS: at example #1500000, processed 214057680 words (1130287 words/s), 2664605 word types, 5708 tags\n",
      "2022-10-27 14:18:24,274 : INFO : PROGRESS: at example #1600000, processed 228546090 words (1126865 words/s), 2789993 word types, 5708 tags\n",
      "2022-10-27 14:18:37,265 : INFO : PROGRESS: at example #1700000, processed 243022095 words (1114439 words/s), 2912130 word types, 5708 tags\n",
      "2022-10-27 14:18:49,940 : INFO : PROGRESS: at example #1800000, processed 257507682 words (1142948 words/s), 3031855 word types, 5708 tags\n",
      "2022-10-27 14:18:51,078 : INFO : collected 3043085 word types and 5708 unique tags from a corpus of 1808237 examples and 258838695 words\n",
      "2022-10-27 14:18:52,359 : INFO : Doc2Vec lifecycle event {'msg': 'max_final_vocab=1000000 and min_count=5 resulted in calc_min_count=3, effective_min_count=5', 'datetime': '2022-10-27T14:18:52.359507', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-27 14:18:52,360 : INFO : Creating a fresh vocabulary\n",
      "2022-10-27 14:18:54,861 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 403737 unique words (13.27% of original 3043085, drops 2639348)', 'datetime': '2022-10-27T14:18:54.861031', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-27 14:18:54,862 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 255183854 word corpus (98.59% of original 258838695, drops 3654841)', 'datetime': '2022-10-27T14:18:54.862116', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-27 14:18:57,176 : INFO : deleting the raw counts dictionary of 3043085 items\n",
      "2022-10-27 14:18:57,226 : INFO : sample=0.001 downsamples 35 most-common words\n",
      "2022-10-27 14:18:57,226 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 198198843.80770236 word corpus (77.7%% of prior 255183854)', 'datetime': '2022-10-27T14:18:57.226954', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-27 14:19:00,844 : INFO : estimated required memory for 403737 words and 200 dimensions: 853555700 bytes\n",
      "2022-10-27 14:19:00,845 : INFO : resetting layer weights\n",
      "2022-10-27 14:19:01,207 : INFO : collecting all words and their counts\n",
      "2022-10-27 14:19:01,208 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 14:19:13,736 : INFO : PROGRESS: at example #100000, processed 13843077 words (1105020 words/s), 379074 word types, 1727 tags\n",
      "2022-10-27 14:19:26,326 : INFO : PROGRESS: at example #200000, processed 27463509 words (1081920 words/s), 624307 word types, 1727 tags\n",
      "2022-10-27 14:19:39,135 : INFO : PROGRESS: at example #300000, processed 41922887 words (1128905 words/s), 835516 word types, 1727 tags\n",
      "2022-10-27 14:19:51,890 : INFO : PROGRESS: at example #400000, processed 56307686 words (1127874 words/s), 1024516 word types, 1727 tags\n",
      "2022-10-27 14:20:04,634 : INFO : PROGRESS: at example #500000, processed 70683572 words (1128112 words/s), 1201732 word types, 1727 tags\n",
      "2022-10-27 14:20:17,543 : INFO : PROGRESS: at example #600000, processed 85086720 words (1115877 words/s), 1368075 word types, 1727 tags\n",
      "2022-10-27 14:20:30,546 : INFO : PROGRESS: at example #700000, processed 99588058 words (1115303 words/s), 1528559 word types, 1727 tags\n",
      "2022-10-27 14:20:43,307 : INFO : PROGRESS: at example #800000, processed 113887516 words (1120647 words/s), 1682832 word types, 1727 tags\n",
      "2022-10-27 14:20:56,092 : INFO : PROGRESS: at example #900000, processed 127952675 words (1100242 words/s), 1831003 word types, 1727 tags\n",
      "2022-10-27 14:21:08,995 : INFO : PROGRESS: at example #1000000, processed 142210503 words (1105002 words/s), 1974854 word types, 1727 tags\n",
      "2022-10-27 14:21:21,998 : INFO : PROGRESS: at example #1100000, processed 156382234 words (1089984 words/s), 2116938 word types, 1727 tags\n",
      "2022-10-27 14:21:35,132 : INFO : PROGRESS: at example #1200000, processed 170926878 words (1107467 words/s), 2255427 word types, 1727 tags\n",
      "2022-10-27 14:21:48,131 : INFO : PROGRESS: at example #1300000, processed 185397919 words (1113311 words/s), 2389067 word types, 1727 tags\n",
      "2022-10-27 14:22:01,023 : INFO : PROGRESS: at example #1400000, processed 199601236 words (1101775 words/s), 2519591 word types, 1727 tags\n",
      "2022-10-27 14:22:13,999 : INFO : PROGRESS: at example #1500000, processed 214149800 words (1121246 words/s), 2646754 word types, 1727 tags\n",
      "2022-10-27 14:22:26,881 : INFO : PROGRESS: at example #1600000, processed 228639371 words (1124920 words/s), 2771070 word types, 1727 tags\n",
      "2022-10-27 14:22:39,781 : INFO : PROGRESS: at example #1700000, processed 243166244 words (1126224 words/s), 2892998 word types, 1727 tags\n",
      "2022-10-27 14:22:50,585 : INFO : collected 2993111 word types and 1727 unique tags from a corpus of 1783457 examples and 255365971 words\n",
      "2022-10-27 14:22:51,888 : INFO : Doc2Vec lifecycle event {'msg': 'max_final_vocab=1000000 and min_count=5 resulted in calc_min_count=3, effective_min_count=5', 'datetime': '2022-10-27T14:22:51.888820', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-27 14:22:51,889 : INFO : Creating a fresh vocabulary\n",
      "2022-10-27 14:22:54,344 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 397201 unique words (13.27% of original 2993111, drops 2595910)', 'datetime': '2022-10-27T14:22:54.344319', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-27 14:22:54,345 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 251770880 word corpus (98.59% of original 255365971, drops 3595091)', 'datetime': '2022-10-27T14:22:54.345232', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-27 14:22:56,600 : INFO : deleting the raw counts dictionary of 2993111 items\n",
      "2022-10-27 14:22:56,648 : INFO : sample=0.001 downsamples 35 most-common words\n",
      "2022-10-27 14:22:56,649 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 195516966.58604908 word corpus (77.7%% of prior 251770880)', 'datetime': '2022-10-27T14:22:56.649330', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-27 14:23:00,215 : INFO : estimated required memory for 397201 words and 200 dimensions: 835849100 bytes\n",
      "2022-10-27 14:23:00,215 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n"
     ]
    }
   ],
   "source": [
    "model_dbow99.build_vocab(documents99, progress_per=100000, )\n",
    "print(model_dbow99)\n",
    "print('---------------------------------------')\n",
    "\n",
    "model_dbow399.build_vocab(documents399, progress_per=100000)\n",
    "print(model_dbow399)\n",
    "print('---------------------------------------')\n",
    "\n",
    "model_dbow1499.build_vocab(documents1499, progress_per=100000)\n",
    "print(model_dbow1499)\n",
    "\n",
    "# Save some time by copying the vocabulary structures from the DBOW model to the DM model.\n",
    "# Both models are built on top of exactly the same data, so there's no need to repeat the vocab-building step.\n",
    "#model_dm.reset_from(model_dbow)\n",
    "#print(model_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 14:23:00,569 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 30 workers on 403737 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=8 shrink_windows=True', 'datetime': '2022-10-27T14:23:00.568981', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "2022-10-27 14:23:02,540 : INFO : EPOCH 0 - PROGRESS: at 0.00% examples, 4157 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 14:33:02,541 : INFO : EPOCH 0 - PROGRESS: at 45.20% examples, 158004 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 14:43:02,572 : INFO : EPOCH 0 - PROGRESS: at 89.91% examples, 157977 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 14:45:19,124 : INFO : EPOCH 0: training on 258838695 raw words (211614412 effective words) took 1338.5s, 158096 effective words/s\n",
      "2022-10-27 14:45:21,046 : INFO : EPOCH 1 - PROGRESS: at 0.00% examples, 4217 words/s, in_qsize 59, out_qsize 1\n",
      "2022-10-27 14:55:21,052 : INFO : EPOCH 1 - PROGRESS: at 45.31% examples, 158377 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 15:05:21,193 : INFO : EPOCH 1 - PROGRESS: at 90.04% examples, 158203 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 15:07:35,866 : INFO : EPOCH 1: training on 258838695 raw words (211615313 effective words) took 1336.7s, 158308 effective words/s\n",
      "2022-10-27 15:07:37,743 : INFO : EPOCH 2 - PROGRESS: at 0.00% examples, 4389 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 15:17:37,809 : INFO : EPOCH 2 - PROGRESS: at 45.32% examples, 158438 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 15:27:37,843 : INFO : EPOCH 2 - PROGRESS: at 90.23% examples, 158544 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 15:29:49,766 : INFO : EPOCH 2: training on 258838695 raw words (211614375 effective words) took 1333.9s, 158645 effective words/s\n",
      "2022-10-27 15:29:51,430 : INFO : EPOCH 3 - PROGRESS: at 0.00% examples, 4965 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 15:39:51,452 : INFO : EPOCH 3 - PROGRESS: at 45.18% examples, 158007 words/s, in_qsize 60, out_qsize 1\n",
      "2022-10-27 15:49:51,459 : INFO : EPOCH 3 - PROGRESS: at 90.17% examples, 158474 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 15:52:03,794 : INFO : EPOCH 3: training on 258838695 raw words (211615908 effective words) took 1334.0s, 158631 effective words/s\n",
      "2022-10-27 15:52:05,522 : INFO : EPOCH 4 - PROGRESS: at 0.00% examples, 4712 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 16:02:05,526 : INFO : EPOCH 4 - PROGRESS: at 45.48% examples, 159047 words/s, in_qsize 59, out_qsize 1\n",
      "2022-10-27 16:12:05,585 : INFO : EPOCH 4 - PROGRESS: at 90.45% examples, 158949 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 16:14:14,219 : INFO : EPOCH 4: training on 258838695 raw words (211611633 effective words) took 1330.4s, 159057 effective words/s\n",
      "2022-10-27 16:14:15,865 : INFO : EPOCH 5 - PROGRESS: at 0.00% examples, 5031 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 16:24:15,886 : INFO : EPOCH 5 - PROGRESS: at 45.41% examples, 158799 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 16:34:15,901 : INFO : EPOCH 5 - PROGRESS: at 90.36% examples, 158812 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 16:36:26,290 : INFO : EPOCH 5: training on 258838695 raw words (211614696 effective words) took 1332.0s, 158865 effective words/s\n",
      "2022-10-27 16:36:27,851 : INFO : EPOCH 6 - PROGRESS: at 0.00% examples, 5186 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 16:46:27,872 : INFO : EPOCH 6 - PROGRESS: at 45.43% examples, 158888 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 16:56:27,875 : INFO : EPOCH 6 - PROGRESS: at 90.38% examples, 158859 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 16:58:37,725 : INFO : EPOCH 6: training on 258838695 raw words (211618187 effective words) took 1331.4s, 158941 effective words/s\n",
      "2022-10-27 16:58:39,453 : INFO : EPOCH 7 - PROGRESS: at 0.00% examples, 4685 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 17:08:39,478 : INFO : EPOCH 7 - PROGRESS: at 45.31% examples, 158430 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 17:18:39,531 : INFO : EPOCH 7 - PROGRESS: at 90.10% examples, 158328 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 17:20:53,473 : INFO : EPOCH 7: training on 258838695 raw words (211610548 effective words) took 1335.7s, 158423 effective words/s\n",
      "2022-10-27 17:20:55,334 : INFO : EPOCH 8 - PROGRESS: at 0.00% examples, 4316 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 17:30:55,349 : INFO : EPOCH 8 - PROGRESS: at 45.10% examples, 157684 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 17:40:55,366 : INFO : EPOCH 8 - PROGRESS: at 89.98% examples, 158117 words/s, in_qsize 59, out_qsize 1\n",
      "2022-10-27 17:43:11,008 : INFO : EPOCH 8: training on 258838695 raw words (211620293 effective words) took 1337.5s, 158218 effective words/s\n",
      "2022-10-27 17:43:12,810 : INFO : EPOCH 9 - PROGRESS: at 0.00% examples, 4505 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 17:53:12,885 : INFO : EPOCH 9 - PROGRESS: at 45.31% examples, 158416 words/s, in_qsize 60, out_qsize 1\n",
      "2022-10-27 18:03:12,930 : INFO : EPOCH 9 - PROGRESS: at 90.07% examples, 158272 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 18:05:27,238 : INFO : EPOCH 9: training on 258838695 raw words (211612482 effective words) took 1336.2s, 158367 effective words/s\n",
      "2022-10-27 18:05:28,963 : INFO : EPOCH 10 - PROGRESS: at 0.00% examples, 4716 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 18:15:29,097 : INFO : EPOCH 10 - PROGRESS: at 45.22% examples, 158105 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 18:25:29,108 : INFO : EPOCH 10 - PROGRESS: at 89.97% examples, 158111 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 18:27:45,021 : INFO : EPOCH 10: training on 258838695 raw words (211621613 effective words) took 1337.8s, 158190 effective words/s\n",
      "2022-10-27 18:27:46,825 : INFO : EPOCH 11 - PROGRESS: at 0.00% examples, 4510 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 18:37:47,002 : INFO : EPOCH 11 - PROGRESS: at 45.13% examples, 157757 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 18:47:47,112 : INFO : EPOCH 11 - PROGRESS: at 89.95% examples, 158031 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 18:50:03,605 : INFO : EPOCH 11: training on 258838695 raw words (211617364 effective words) took 1338.6s, 158092 effective words/s\n",
      "2022-10-27 18:50:03,606 : INFO : Doc2Vec lifecycle event {'msg': 'training on 3106064340 raw words (2539386824 effective words) took 16023.0s, 158483 effective words/s', 'datetime': '2022-10-27T18:50:03.606643', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "# Train DBOW doc2vec 399\n",
    "# Report progress every 10 min.\n",
    "model_dbow399.train(documents399, total_examples=model_dbow399.corpus_count, epochs=model_dbow399.epochs, report_delay=10*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 18:50:03,613 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 30 workers on 405281 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=8 shrink_windows=True', 'datetime': '2022-10-27T18:50:03.612981', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "2022-10-27 18:50:05,539 : INFO : EPOCH 0 - PROGRESS: at 0.00% examples, 4262 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 19:00:05,584 : INFO : EPOCH 0 - PROGRESS: at 42.82% examples, 151284 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 19:10:05,660 : INFO : EPOCH 0 - PROGRESS: at 85.27% examples, 151350 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 19:13:36,152 : INFO : EPOCH 0: training on 259498691 raw words (213950041 effective words) took 1412.5s, 151466 effective words/s\n",
      "2022-10-27 19:13:38,132 : INFO : EPOCH 1 - PROGRESS: at 0.00% examples, 4191 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 19:23:38,156 : INFO : EPOCH 1 - PROGRESS: at 42.70% examples, 150823 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 19:33:38,171 : INFO : EPOCH 1 - PROGRESS: at 85.28% examples, 151381 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 19:37:08,078 : INFO : EPOCH 1: training on 259498691 raw words (213951222 effective words) took 1411.9s, 151533 effective words/s\n",
      "2022-10-27 19:37:09,874 : INFO : EPOCH 2 - PROGRESS: at 0.00% examples, 4545 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 19:47:09,908 : INFO : EPOCH 2 - PROGRESS: at 43.02% examples, 152025 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 19:57:09,939 : INFO : EPOCH 2 - PROGRESS: at 85.61% examples, 151991 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 20:00:35,117 : INFO : EPOCH 2: training on 259498691 raw words (213941812 effective words) took 1407.0s, 152053 effective words/s\n",
      "2022-10-27 20:00:36,891 : INFO : EPOCH 3 - PROGRESS: at 0.00% examples, 4697 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 20:10:37,001 : INFO : EPOCH 3 - PROGRESS: at 42.93% examples, 151713 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 20:20:37,128 : INFO : EPOCH 3 - PROGRESS: at 85.59% examples, 151944 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 20:24:02,313 : INFO : EPOCH 3: training on 259498691 raw words (213947179 effective words) took 1407.2s, 152040 effective words/s\n",
      "2022-10-27 20:24:04,045 : INFO : EPOCH 4 - PROGRESS: at 0.00% examples, 4819 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 20:34:04,076 : INFO : EPOCH 4 - PROGRESS: at 42.95% examples, 151802 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 20:44:04,139 : INFO : EPOCH 4 - PROGRESS: at 85.59% examples, 151956 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 20:47:29,921 : INFO : EPOCH 4: training on 259498691 raw words (213948491 effective words) took 1407.6s, 151996 effective words/s\n",
      "2022-10-27 20:47:31,725 : INFO : EPOCH 5 - PROGRESS: at 0.00% examples, 4627 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 20:57:31,729 : INFO : EPOCH 5 - PROGRESS: at 42.98% examples, 151895 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 21:07:31,750 : INFO : EPOCH 5 - PROGRESS: at 85.57% examples, 151925 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 21:10:57,164 : INFO : EPOCH 5: training on 259498691 raw words (213948168 effective words) took 1407.2s, 152035 effective words/s\n",
      "2022-10-27 21:10:58,995 : INFO : EPOCH 6 - PROGRESS: at 0.00% examples, 4480 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 21:20:59,070 : INFO : EPOCH 6 - PROGRESS: at 42.93% examples, 151706 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 21:30:59,131 : INFO : EPOCH 6 - PROGRESS: at 85.34% examples, 151499 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 21:34:28,420 : INFO : EPOCH 6: training on 259498691 raw words (213953813 effective words) took 1411.2s, 151607 effective words/s\n",
      "2022-10-27 21:34:30,225 : INFO : EPOCH 7 - PROGRESS: at 0.00% examples, 4578 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 21:44:30,250 : INFO : EPOCH 7 - PROGRESS: at 42.96% examples, 151813 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 21:54:30,418 : INFO : EPOCH 7 - PROGRESS: at 85.60% examples, 151954 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 21:57:55,855 : INFO : EPOCH 7: training on 259498691 raw words (213950693 effective words) took 1407.4s, 152016 effective words/s\n",
      "2022-10-27 21:57:57,583 : INFO : EPOCH 8 - PROGRESS: at 0.00% examples, 4792 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 22:07:57,643 : INFO : EPOCH 8 - PROGRESS: at 42.99% examples, 151959 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 22:17:57,645 : INFO : EPOCH 8 - PROGRESS: at 85.44% examples, 151688 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 22:21:25,913 : INFO : EPOCH 8: training on 259498691 raw words (213949907 effective words) took 1410.0s, 151733 effective words/s\n",
      "2022-10-27 22:21:27,822 : INFO : EPOCH 9 - PROGRESS: at 0.00% examples, 4310 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 22:31:27,824 : INFO : EPOCH 9 - PROGRESS: at 42.85% examples, 151410 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 22:41:27,856 : INFO : EPOCH 9 - PROGRESS: at 85.33% examples, 151459 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 22:44:57,322 : INFO : EPOCH 9: training on 259498691 raw words (213944598 effective words) took 1411.4s, 151584 effective words/s\n",
      "2022-10-27 22:44:59,108 : INFO : EPOCH 10 - PROGRESS: at 0.00% examples, 4565 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 22:54:59,152 : INFO : EPOCH 10 - PROGRESS: at 42.94% examples, 151777 words/s, in_qsize 59, out_qsize 1\n",
      "2022-10-27 23:04:59,270 : INFO : EPOCH 10 - PROGRESS: at 85.43% examples, 151660 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 23:08:27,295 : INFO : EPOCH 10: training on 259498691 raw words (213956255 effective words) took 1410.0s, 151746 effective words/s\n",
      "2022-10-27 23:08:29,135 : INFO : EPOCH 11 - PROGRESS: at 0.00% examples, 4425 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 23:18:29,246 : INFO : EPOCH 11 - PROGRESS: at 42.68% examples, 150767 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 23:28:29,247 : INFO : EPOCH 11 - PROGRESS: at 84.79% examples, 150497 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 23:32:11,458 : INFO : EPOCH 11: training on 259498691 raw words (213947740 effective words) took 1424.1s, 150229 effective words/s\n",
      "2022-10-27 23:32:11,459 : INFO : Doc2Vec lifecycle event {'msg': 'training on 3113984292 raw words (2567389919 effective words) took 16927.8s, 151667 effective words/s', 'datetime': '2022-10-27T23:32:11.459643', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "# Train DBOW doc2vec 99\n",
    "# Report progress every 10 min.\n",
    "model_dbow99.train(documents99, total_examples=model_dbow99.corpus_count, epochs=model_dbow99.epochs, report_delay=10*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-27 23:32:11,464 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 30 workers on 397201 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=8 shrink_windows=True', 'datetime': '2022-10-27T23:32:11.464899', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "2022-10-27 23:32:13,237 : INFO : EPOCH 0 - PROGRESS: at 0.00% examples, 4482 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-27 23:42:13,270 : INFO : EPOCH 0 - PROGRESS: at 49.85% examples, 169377 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 23:52:13,304 : INFO : EPOCH 0 - PROGRESS: at 98.94% examples, 169435 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-27 23:52:25,964 : INFO : EPOCH 0: training on 255365971 raw words (205897723 effective words) took 1214.5s, 169535 effective words/s\n",
      "2022-10-27 23:52:27,542 : INFO : EPOCH 1 - PROGRESS: at 0.00% examples, 5048 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 00:02:27,613 : INFO : EPOCH 1 - PROGRESS: at 49.89% examples, 169541 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 00:12:27,630 : INFO : EPOCH 1 - PROGRESS: at 98.78% examples, 169183 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 00:12:42,402 : INFO : EPOCH 1: training on 255365971 raw words (205901264 effective words) took 1216.4s, 169268 effective words/s\n",
      "2022-10-28 00:12:44,046 : INFO : EPOCH 2 - PROGRESS: at 0.00% examples, 4733 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 00:22:44,060 : INFO : EPOCH 2 - PROGRESS: at 49.90% examples, 169573 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 00:32:44,119 : INFO : EPOCH 2 - PROGRESS: at 99.03% examples, 169601 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 00:32:55,819 : INFO : EPOCH 2: training on 255365971 raw words (205893581 effective words) took 1213.4s, 169683 effective words/s\n",
      "2022-10-28 00:32:57,548 : INFO : EPOCH 3 - PROGRESS: at 0.00% examples, 4620 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 00:42:57,554 : INFO : EPOCH 3 - PROGRESS: at 49.96% examples, 169742 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 00:52:57,568 : INFO : EPOCH 3 - PROGRESS: at 98.98% examples, 169523 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 00:53:09,854 : INFO : EPOCH 3: training on 255365971 raw words (205899970 effective words) took 1214.0s, 169601 effective words/s\n",
      "2022-10-28 00:53:11,498 : INFO : EPOCH 4 - PROGRESS: at 0.00% examples, 4876 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 01:03:11,576 : INFO : EPOCH 4 - PROGRESS: at 49.83% examples, 169321 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 01:13:11,664 : INFO : EPOCH 4 - PROGRESS: at 98.68% examples, 168990 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 01:13:27,687 : INFO : EPOCH 4: training on 255365971 raw words (205901347 effective words) took 1217.8s, 169074 effective words/s\n",
      "2022-10-28 01:13:29,240 : INFO : EPOCH 5 - PROGRESS: at 0.00% examples, 5145 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 01:23:29,370 : INFO : EPOCH 5 - PROGRESS: at 49.93% examples, 169655 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 01:33:29,424 : INFO : EPOCH 5 - PROGRESS: at 99.11% examples, 169761 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 01:33:39,849 : INFO : EPOCH 5: training on 255365971 raw words (205904425 effective words) took 1212.1s, 169867 effective words/s\n",
      "2022-10-28 01:33:41,683 : INFO : EPOCH 6 - PROGRESS: at 0.00% examples, 4343 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 01:43:41,749 : INFO : EPOCH 6 - PROGRESS: at 49.91% examples, 169535 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 01:53:41,798 : INFO : EPOCH 6 - PROGRESS: at 98.90% examples, 169345 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 01:53:55,262 : INFO : EPOCH 6: training on 255365971 raw words (205897424 effective words) took 1215.4s, 169407 effective words/s\n",
      "2022-10-28 01:53:56,947 : INFO : EPOCH 7 - PROGRESS: at 0.00% examples, 4746 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 02:03:57,061 : INFO : EPOCH 7 - PROGRESS: at 49.82% examples, 169240 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 02:13:57,064 : INFO : EPOCH 7 - PROGRESS: at 98.81% examples, 169218 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 02:14:11,457 : INFO : EPOCH 7: training on 255365971 raw words (205902480 effective words) took 1216.2s, 169302 effective words/s\n",
      "2022-10-28 02:14:13,158 : INFO : EPOCH 8 - PROGRESS: at 0.00% examples, 4718 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 02:24:13,224 : INFO : EPOCH 8 - PROGRESS: at 49.83% examples, 169308 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 02:34:13,280 : INFO : EPOCH 8 - PROGRESS: at 98.86% examples, 169288 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 02:34:27,081 : INFO : EPOCH 8: training on 255365971 raw words (205893999 effective words) took 1215.6s, 169375 effective words/s\n",
      "2022-10-28 02:34:28,696 : INFO : EPOCH 9 - PROGRESS: at 0.00% examples, 4980 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 02:44:28,737 : INFO : EPOCH 9 - PROGRESS: at 49.76% examples, 169094 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 02:54:28,744 : INFO : EPOCH 9 - PROGRESS: at 98.90% examples, 169397 words/s, in_qsize 59, out_qsize 1\n",
      "2022-10-28 02:54:41,967 : INFO : EPOCH 9: training on 255365971 raw words (205902776 effective words) took 1214.9s, 169485 effective words/s\n",
      "2022-10-28 02:54:43,476 : INFO : EPOCH 10 - PROGRESS: at 0.00% examples, 5270 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 03:04:43,600 : INFO : EPOCH 10 - PROGRESS: at 49.60% examples, 168566 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 03:14:43,605 : INFO : EPOCH 10 - PROGRESS: at 98.57% examples, 168822 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 03:15:01,097 : INFO : EPOCH 10: training on 255365971 raw words (205911389 effective words) took 1219.1s, 168902 effective words/s\n",
      "2022-10-28 03:15:02,725 : INFO : EPOCH 11 - PROGRESS: at 0.00% examples, 4977 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 03:25:02,742 : INFO : EPOCH 11 - PROGRESS: at 49.78% examples, 169174 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 03:35:02,759 : INFO : EPOCH 11 - PROGRESS: at 98.82% examples, 169258 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 03:35:16,878 : INFO : EPOCH 11: training on 255365971 raw words (205902922 effective words) took 1215.8s, 169360 effective words/s\n",
      "2022-10-28 03:35:16,879 : INFO : Doc2Vec lifecycle event {'msg': 'training on 3064391652 raw words (2470809300 effective words) took 14585.4s, 169403 effective words/s', 'datetime': '2022-10-28T03:35:16.879903', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "# Train DBOW doc2vec 1499\n",
    "# Report progress every 10 min.\n",
    "model_dbow1499.train(documents1499, total_examples=model_dbow1499.corpus_count, epochs=model_dbow1499.epochs, report_delay=10*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 03:35:16,887 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>', 'datetime': '2022-10-28T03:35:16.887666', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'created'}\n",
      "2022-10-28 03:35:16,888 : INFO : collecting all words and their counts\n",
      "2022-10-28 03:35:16,889 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2022-10-28 03:35:29,665 : INFO : PROGRESS: at example #100000, processed 13832088 words (1082698 words/s), 373187 word types, 789 tags\n",
      "2022-10-28 03:35:42,461 : INFO : PROGRESS: at example #200000, processed 27545553 words (1071778 words/s), 614343 word types, 789 tags\n",
      "2022-10-28 03:35:55,412 : INFO : PROGRESS: at example #300000, processed 42001821 words (1116280 words/s), 822074 word types, 789 tags\n",
      "2022-10-28 03:36:08,248 : INFO : PROGRESS: at example #400000, processed 56376101 words (1119989 words/s), 1008923 word types, 789 tags\n",
      "2022-10-28 03:36:21,203 : INFO : PROGRESS: at example #500000, processed 70733193 words (1108249 words/s), 1183297 word types, 789 tags\n",
      "2022-10-28 03:36:34,157 : INFO : PROGRESS: at example #600000, processed 85179196 words (1115288 words/s), 1347708 word types, 789 tags\n",
      "2022-10-28 03:36:47,230 : INFO : PROGRESS: at example #700000, processed 99629198 words (1105416 words/s), 1505932 word types, 789 tags\n",
      "2022-10-28 03:37:00,198 : INFO : PROGRESS: at example #800000, processed 113910700 words (1101348 words/s), 1658359 word types, 789 tags\n",
      "2022-10-28 03:37:13,046 : INFO : PROGRESS: at example #900000, processed 127910374 words (1089754 words/s), 1804066 word types, 789 tags\n",
      "2022-10-28 03:37:25,931 : INFO : PROGRESS: at example #1000000, processed 142226265 words (1111070 words/s), 1945499 word types, 789 tags\n",
      "2022-10-28 03:37:38,924 : INFO : PROGRESS: at example #1100000, processed 156494981 words (1098294 words/s), 2085714 word types, 789 tags\n",
      "2022-10-28 03:37:51,942 : INFO : PROGRESS: at example #1200000, processed 171044060 words (1117651 words/s), 2222990 word types, 789 tags\n",
      "2022-10-28 03:38:04,905 : INFO : PROGRESS: at example #1300000, processed 185367648 words (1105073 words/s), 2353686 word types, 789 tags\n",
      "2022-10-28 03:38:17,888 : INFO : PROGRESS: at example #1400000, processed 199781185 words (1110284 words/s), 2482841 word types, 789 tags\n",
      "2022-10-28 03:38:30,859 : INFO : PROGRESS: at example #1500000, processed 214287398 words (1118347 words/s), 2608308 word types, 789 tags\n",
      "2022-10-28 03:38:43,836 : INFO : PROGRESS: at example #1600000, processed 228729795 words (1113036 words/s), 2729673 word types, 789 tags\n",
      "2022-10-28 03:38:56,923 : INFO : PROGRESS: at example #1700000, processed 243292288 words (1112803 words/s), 2850568 word types, 789 tags\n",
      "2022-10-28 03:39:01,438 : INFO : collected 2891758 word types and 789 unique tags from a corpus of 1734781 examples and 248396459 words\n",
      "2022-10-28 03:39:02,665 : INFO : Doc2Vec lifecycle event {'msg': 'max_final_vocab=1000000 and min_count=5 resulted in calc_min_count=3, effective_min_count=5', 'datetime': '2022-10-28T03:39:02.665809', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-28 03:39:02,666 : INFO : Creating a fresh vocabulary\n",
      "2022-10-28 03:39:05,084 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 retains 384266 unique words (13.29% of original 2891758, drops 2507492)', 'datetime': '2022-10-28T03:39:05.084515', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-28 03:39:05,085 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 244923321 word corpus (98.60% of original 248396459, drops 3473138)', 'datetime': '2022-10-28T03:39:05.085424', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-28 03:39:07,293 : INFO : deleting the raw counts dictionary of 2891758 items\n",
      "2022-10-28 03:39:07,342 : INFO : sample=0.001 downsamples 36 most-common words\n",
      "2022-10-28 03:39:07,343 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 190114915.471612 word corpus (77.6%% of prior 244923321)', 'datetime': '2022-10-28T03:39:07.343468', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'prepare_vocab'}\n",
      "2022-10-28 03:39:10,767 : INFO : estimated required memory for 384266 words and 200 dimensions: 807747600 bytes\n",
      "2022-10-28 03:39:10,768 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n"
     ]
    }
   ],
   "source": [
    "documents2999 = TaggedCorpus(articles, min_freq=2999)\n",
    "# PV-DBOW: paragraph vector in distributed bag of words mode\n",
    "model_dbow2999 = Doc2Vec(\n",
    "    dm=0, dbow_words=1,  # dbow_words=1 to train word vectors at the same time too, not only DBOW\n",
    "    vector_size=200, window=8, epochs=12, workers=workers, max_final_vocab=1000000,\n",
    ")\n",
    "model_dbow2999.build_vocab(documents2999, progress_per=100000)\n",
    "print(model_dbow2999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 03:39:11,107 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 30 workers on 384266 vocabulary and 200 features, using sg=1 hs=0 sample=0.001 negative=5 window=8 shrink_windows=True', 'datetime': '2022-10-28T03:39:11.107801', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'train'}\n",
      "2022-10-28 03:39:12,883 : INFO : EPOCH 0 - PROGRESS: at 0.00% examples, 4400 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 03:49:13,060 : INFO : EPOCH 0 - PROGRESS: at 54.01% examples, 176917 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 03:57:53,274 : INFO : EPOCH 0: training on 248396459 raw words (198492524 effective words) took 1122.2s, 176885 effective words/s\n",
      "2022-10-28 03:57:54,902 : INFO : EPOCH 1 - PROGRESS: at 0.00% examples, 4892 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 04:07:54,906 : INFO : EPOCH 1 - PROGRESS: at 53.97% examples, 176870 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 04:16:34,404 : INFO : EPOCH 1: training on 248396459 raw words (198492381 effective words) took 1121.1s, 177049 effective words/s\n",
      "2022-10-28 04:16:35,986 : INFO : EPOCH 2 - PROGRESS: at 0.00% examples, 4973 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 04:26:36,030 : INFO : EPOCH 2 - PROGRESS: at 54.15% examples, 177431 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 04:35:12,380 : INFO : EPOCH 2: training on 248396459 raw words (198491134 effective words) took 1118.0s, 177547 effective words/s\n",
      "2022-10-28 04:35:14,045 : INFO : EPOCH 3 - PROGRESS: at 0.00% examples, 4862 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 04:45:14,074 : INFO : EPOCH 3 - PROGRESS: at 53.87% examples, 176506 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 04:53:54,272 : INFO : EPOCH 3: training on 248396459 raw words (198487565 effective words) took 1121.9s, 176924 effective words/s\n",
      "2022-10-28 04:53:55,920 : INFO : EPOCH 4 - PROGRESS: at 0.00% examples, 4840 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 05:03:56,100 : INFO : EPOCH 4 - PROGRESS: at 54.18% examples, 177480 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 05:12:32,671 : INFO : EPOCH 4: training on 248396459 raw words (198490941 effective words) took 1118.4s, 177480 effective words/s\n",
      "2022-10-28 05:12:34,338 : INFO : EPOCH 5 - PROGRESS: at 0.00% examples, 4868 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 05:22:34,528 : INFO : EPOCH 5 - PROGRESS: at 54.11% examples, 177246 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 05:31:10,404 : INFO : EPOCH 5: training on 248396459 raw words (198486623 effective words) took 1117.7s, 177582 effective words/s\n",
      "2022-10-28 05:31:12,097 : INFO : EPOCH 6 - PROGRESS: at 0.00% examples, 4704 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 05:41:12,103 : INFO : EPOCH 6 - PROGRESS: at 54.17% examples, 177488 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 05:49:48,052 : INFO : EPOCH 6: training on 248396459 raw words (198490359 effective words) took 1117.6s, 177598 effective words/s\n",
      "2022-10-28 05:49:49,493 : INFO : EPOCH 7 - PROGRESS: at 0.00% examples, 5516 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 05:59:49,495 : INFO : EPOCH 7 - PROGRESS: at 54.07% examples, 177258 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 06:08:26,376 : INFO : EPOCH 7: training on 248396459 raw words (198502667 effective words) took 1118.3s, 177502 effective words/s\n",
      "2022-10-28 06:08:31,417 : INFO : EPOCH 8 - PROGRESS: at 0.00% examples, 1566 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 06:18:31,487 : INFO : EPOCH 8 - PROGRESS: at 54.21% examples, 176632 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 06:27:06,708 : INFO : EPOCH 8: training on 248396459 raw words (198490020 effective words) took 1120.3s, 177173 effective words/s\n",
      "2022-10-28 06:27:08,347 : INFO : EPOCH 9 - PROGRESS: at 0.00% examples, 4772 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 06:37:08,358 : INFO : EPOCH 9 - PROGRESS: at 54.06% examples, 177156 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 06:45:46,115 : INFO : EPOCH 9: training on 248396459 raw words (198498947 effective words) took 1119.4s, 177327 effective words/s\n",
      "2022-10-28 06:45:47,808 : INFO : EPOCH 10 - PROGRESS: at 0.00% examples, 4638 words/s, in_qsize 59, out_qsize 0\n",
      "2022-10-28 06:55:47,810 : INFO : EPOCH 10 - PROGRESS: at 54.16% examples, 177454 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 07:04:25,540 : INFO : EPOCH 10: training on 248396459 raw words (198493938 effective words) took 1119.4s, 177320 effective words/s\n",
      "2022-10-28 07:04:27,144 : INFO : EPOCH 11 - PROGRESS: at 0.00% examples, 4901 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 07:14:27,257 : INFO : EPOCH 11 - PROGRESS: at 53.96% examples, 176822 words/s, in_qsize 60, out_qsize 0\n",
      "2022-10-28 07:23:07,048 : INFO : EPOCH 11: training on 248396459 raw words (198497625 effective words) took 1121.5s, 176994 effective words/s\n",
      "2022-10-28 07:23:07,049 : INFO : Doc2Vec lifecycle event {'msg': 'training on 2980757508 raw words (2381914724 effective words) took 13435.9s, 177279 effective words/s', 'datetime': '2022-10-28T07:23:07.049260', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "# Train DBOW doc2vec 2999\n",
    "# Report progress every 10 min.\n",
    "model_dbow2999.train(documents2999, total_examples=model_dbow2999.corpus_count, epochs=model_dbow2999.epochs, report_delay=10*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model_dbow99, model_dbow399, model_dbow1499, model_dbow2999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "[('q-learning', 0.9321299195289612),\n",
      " ('temporal difference learning', 0.8832590579986572),\n",
      " ('reinforcement learning algorithm', 0.8621841669082642),\n",
      " ('error-driven learning', 0.8326339721679688),\n",
      " ('learning classifier system', 0.8043680191040039),\n",
      " ('action selection', 0.773815929889679),\n",
      " ('reinforcement', 0.7714371085166931),\n",
      " ('learning agent', 0.7500354051589966),\n",
      " ('markov decision process', 0.728828489780426),\n",
      " ('multiagent learning', 0.7118377089500427),\n",
      " ('robot learning', 0.6870455741882324),\n",
      " ('partially observable markov decision process', 0.6772484183311462),\n",
      " ('sequential decision', 0.6734935641288757),\n",
      " ('bellman equation', 0.6446964144706726),\n",
      " ('instance-based learning', 0.6378455758094788)]\n",
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "[('q-learning', 0.9268630743026733),\n",
      " ('temporal difference learning', 0.8876643776893616),\n",
      " ('error-driven learning', 0.8351960778236389),\n",
      " ('learning classifier system', 0.7971616387367249),\n",
      " ('action selection', 0.7847582101821899),\n",
      " ('reinforcement', 0.7765026688575745),\n",
      " ('markov decision process', 0.7361605763435364),\n",
      " ('robot learning', 0.6913911700248718),\n",
      " ('partially observable markov decision process', 0.6893896460533142),\n",
      " ('bellman equation', 0.6598688364028931),\n",
      " ('instance-based learning', 0.6239364743232727),\n",
      " ('multi-task learning', 0.6210029125213623),\n",
      " ('online machine learning', 0.6192531585693359),\n",
      " ('function approximation', 0.6164807677268982),\n",
      " ('active learning (machine learning)', 0.6140730381011963)]\n",
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "[('learning classifier system', 0.8110169768333435),\n",
      " ('markov decision process', 0.7337304949760437),\n",
      " ('robot learning', 0.7013905644416809),\n",
      " ('instance-based learning', 0.6411325931549072),\n",
      " ('active learning (machine learning)', 0.6374473571777344),\n",
      " ('unsupervised learning', 0.6059063673019409),\n",
      " ('autonomous agent', 0.5843579173088074),\n",
      " ('semi-supervised learning', 0.5244489908218384),\n",
      " ('observable', 0.516920268535614),\n",
      " ('state space', 0.5167517066001892),\n",
      " ('multi-agent system', 0.5127934813499451),\n",
      " ('supervised learning', 0.5104182362556458),\n",
      " ('planner', 0.5007034540176392),\n",
      " ('intelligent agent', 0.49982765316963196),\n",
      " ('autonomous system (mathematics)', 0.4846164286136627)]\n",
      "Doc2Vec<dbow+w,d200,n5,w8,mc5,s0.001,t30>\n",
      "[('unsupervised learning', 0.5881819725036621),\n",
      " ('state space', 0.511859655380249),\n",
      " ('intelligent agent', 0.5037089586257935),\n",
      " ('supervised learning', 0.5016931295394897),\n",
      " ('multi-agent system', 0.5000223517417908),\n",
      " ('semi-supervised learning', 0.49913203716278076),\n",
      " ('adaptive system', 0.4746206998825073),\n",
      " ('robot control', 0.4528624415397644),\n",
      " ('optimal control', 0.44386813044548035),\n",
      " ('robotics', 0.4431641101837158),\n",
      " ('machine learning', 0.4420945346355438),\n",
      " ('software agent', 0.4374045133590698),\n",
      " ('robot', 0.42586755752563477),\n",
      " ('motion planning', 0.41620171070098877),\n",
      " ('mobile robot', 0.4143287241458893)]\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(model)\n",
    "    pprint(model.dv.most_similar(positive=[\"reinforcement learning\"], topn=15))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Saving\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 13:59:44,698 : INFO : Doc2Vec lifecycle event {'fname_or_handle': 'doc2vec_dbow399.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-10-28T13:59:44.698903', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'saving'}\n",
      "2022-10-28 13:59:44,700 : INFO : storing np array 'vectors' to doc2vec_dbow399.model.wv.vectors.npy\n",
      "2022-10-28 13:59:44,879 : INFO : storing np array 'syn1neg' to doc2vec_dbow399.model.syn1neg.npy\n",
      "2022-10-28 13:59:45,049 : INFO : not storing attribute cum_table\n",
      "2022-10-28 13:59:45,258 : INFO : saved doc2vec_dbow399.model\n",
      "2022-10-28 13:59:45,259 : INFO : Doc2Vec lifecycle event {'fname_or_handle': 'doc2vec_dbow99.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-10-28T13:59:45.259126', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'saving'}\n",
      "2022-10-28 13:59:45,260 : INFO : storing np array 'vectors' to doc2vec_dbow99.model.wv.vectors.npy\n",
      "2022-10-28 13:59:45,438 : INFO : storing np array 'syn1neg' to doc2vec_dbow99.model.syn1neg.npy\n",
      "2022-10-28 13:59:45,616 : INFO : not storing attribute cum_table\n",
      "2022-10-28 13:59:45,836 : INFO : saved doc2vec_dbow99.model\n",
      "2022-10-28 13:59:45,837 : INFO : Doc2Vec lifecycle event {'fname_or_handle': 'doc2vec_dbow1499.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-10-28T13:59:45.837295', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'saving'}\n",
      "2022-10-28 13:59:45,838 : INFO : storing np array 'vectors' to doc2vec_dbow1499.model.wv.vectors.npy\n",
      "2022-10-28 13:59:45,992 : INFO : storing np array 'syn1neg' to doc2vec_dbow1499.model.syn1neg.npy\n",
      "2022-10-28 13:59:46,141 : INFO : not storing attribute cum_table\n",
      "2022-10-28 13:59:46,349 : INFO : saved doc2vec_dbow1499.model\n",
      "2022-10-28 13:59:46,350 : INFO : Doc2Vec lifecycle event {'fname_or_handle': 'doc2vec_dbow2999.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-10-28T13:59:46.350536', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'saving'}\n",
      "2022-10-28 13:59:46,351 : INFO : storing np array 'vectors' to doc2vec_dbow2999.model.wv.vectors.npy\n",
      "2022-10-28 13:59:46,504 : INFO : storing np array 'syn1neg' to doc2vec_dbow2999.model.syn1neg.npy\n",
      "2022-10-28 13:59:46,658 : INFO : not storing attribute cum_table\n",
      "2022-10-28 13:59:46,860 : INFO : saved doc2vec_dbow2999.model\n"
     ]
    }
   ],
   "source": [
    "model_dbow399.save(f'doc2vec_dbow399.model')\n",
    "model_dbow99.save(f'doc2vec_dbow99.model')\n",
    "model_dbow1499.save(f'doc2vec_dbow1499.model')\n",
    "model_dbow2999.save(f'doc2vec_dbow2999.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-28 16:07:06,678 : INFO : loading Doc2Vec object from doc2vec_dbow99.model\n",
      "2022-10-28 16:07:06,831 : INFO : loading dv recursively from doc2vec_dbow99.model.dv.* with mmap=None\n",
      "2022-10-28 16:07:06,832 : INFO : loading wv recursively from doc2vec_dbow99.model.wv.* with mmap=None\n",
      "2022-10-28 16:07:06,833 : INFO : loading vectors from doc2vec_dbow99.model.wv.vectors.npy with mmap=None\n",
      "2022-10-28 16:07:06,906 : INFO : loading syn1neg from doc2vec_dbow99.model.syn1neg.npy with mmap=None\n",
      "2022-10-28 16:07:06,978 : INFO : setting ignored attribute cum_table to None\n",
      "2022-10-28 16:07:10,138 : INFO : Doc2Vec lifecycle event {'fname': 'doc2vec_dbow99.model', 'datetime': '2022-10-28T16:07:10.138734', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'loaded'}\n",
      "2022-10-28 16:07:10,139 : INFO : loading Doc2Vec object from doc2vec_dbow399.model\n",
      "2022-10-28 16:07:10,270 : INFO : loading dv recursively from doc2vec_dbow399.model.dv.* with mmap=None\n",
      "2022-10-28 16:07:10,271 : INFO : loading wv recursively from doc2vec_dbow399.model.wv.* with mmap=None\n",
      "2022-10-28 16:07:10,272 : INFO : loading vectors from doc2vec_dbow399.model.wv.vectors.npy with mmap=None\n",
      "2022-10-28 16:07:10,347 : INFO : loading syn1neg from doc2vec_dbow399.model.syn1neg.npy with mmap=None\n",
      "2022-10-28 16:07:10,422 : INFO : setting ignored attribute cum_table to None\n",
      "2022-10-28 16:07:13,670 : INFO : Doc2Vec lifecycle event {'fname': 'doc2vec_dbow399.model', 'datetime': '2022-10-28T16:07:13.670351', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'loaded'}\n",
      "2022-10-28 16:07:13,696 : INFO : loading Doc2Vec object from doc2vec_dbow1499.model\n",
      "2022-10-28 16:07:13,844 : INFO : loading dv recursively from doc2vec_dbow1499.model.dv.* with mmap=None\n",
      "2022-10-28 16:07:13,845 : INFO : loading wv recursively from doc2vec_dbow1499.model.wv.* with mmap=None\n",
      "2022-10-28 16:07:13,845 : INFO : loading vectors from doc2vec_dbow1499.model.wv.vectors.npy with mmap=None\n",
      "2022-10-28 16:07:13,921 : INFO : loading syn1neg from doc2vec_dbow1499.model.syn1neg.npy with mmap=None\n",
      "2022-10-28 16:07:13,995 : INFO : setting ignored attribute cum_table to None\n",
      "2022-10-28 16:07:17,196 : INFO : Doc2Vec lifecycle event {'fname': 'doc2vec_dbow1499.model', 'datetime': '2022-10-28T16:07:17.196196', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'loaded'}\n",
      "2022-10-28 16:07:17,197 : INFO : loading Doc2Vec object from doc2vec_dbow2999.model\n",
      "2022-10-28 16:07:17,324 : INFO : loading dv recursively from doc2vec_dbow2999.model.dv.* with mmap=None\n",
      "2022-10-28 16:07:17,325 : INFO : loading wv recursively from doc2vec_dbow2999.model.wv.* with mmap=None\n",
      "2022-10-28 16:07:17,326 : INFO : loading vectors from doc2vec_dbow2999.model.wv.vectors.npy with mmap=None\n",
      "2022-10-28 16:07:17,396 : INFO : loading syn1neg from doc2vec_dbow2999.model.syn1neg.npy with mmap=None\n",
      "2022-10-28 16:07:17,467 : INFO : setting ignored attribute cum_table to None\n",
      "2022-10-28 16:07:20,573 : INFO : Doc2Vec lifecycle event {'fname': 'doc2vec_dbow2999.model', 'datetime': '2022-10-28T16:07:20.573571', 'gensim': '4.2.0', 'python': '3.8.5 (default, Sep  4 2020, 07:30:14) \\n[GCC 7.3.0]', 'platform': 'Linux-5.11.0-34-generic-x86_64-with-glibc2.10', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "model_dbow99 = Doc2Vec.load(f'doc2vec_dbow99.model')\n",
    "model_dbow399 = Doc2Vec.load(f'doc2vec_dbow399.model')\n",
    "model_dbow1499 = Doc2Vec.load(f'doc2vec_dbow1499.model')\n",
    "model_dbow2999 = Doc2Vec.load(f'doc2vec_dbow2999.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Model(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, models, treshholds=None, repeat=5):\n",
    "        self.models = models\n",
    "        self.repeat = repeat\n",
    "        if treshholds is None:\n",
    "            self.treshholds = [3] * len(models)\n",
    "        else:\n",
    "            self.treshholds  = treshholds\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        pass\n",
    "                                      \n",
    "    def predict(self, text):\n",
    "        infer = set()\n",
    "        for _ in range(self.repeat):\n",
    "            for idx, model in enumerate(self.models):\n",
    "                doc_vector = model.infer_vector(text.split())\n",
    "                tegs = {teg for teg, _ in\n",
    "                    model.dv.most_similar([doc_vector], topn=self.treshholds[idx])}\n",
    "                infer.update(tegs)\n",
    "        return sorted(infer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Model(models=models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "with open(\"doc2vec_model_v2.pkl\", \"wb\") as fp:\n",
    "    dill.dump(estimator, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 bps voice digitizer  This paper presents an analysis/synthesis method whereby speech may be transmitted at 600 bps, a data rate which is less than 1 percent of the PCM transmission rate for original speech sounds. This R&D effort was motivated by the pressing need for very-low-data rate (VLDR) voice digitizers to meet some of the current military voice communication requirements. The use of a VLDR voice digitizer makes it possible to transmit speech signals over adverse channels which support data rates of only a few hundred bps, or to transmit speech signals over more favorable channels with redundancies for error protection and other useful applications. The 600 bps synthesized speech loses some of its original speech quality, but the intelligibility is sufficiently high to permit the use of the system in certain specialized military applications. One of the most attractive features of the 600 bps voice digitizer is that it is a simple extension of the 2400 bps linear predictive encoder (LPE) which has been under intensive investigation by various government agencies, including the Navy, and is presently entering advanced development. In essence, the 600 bps voice digitizer is a combination of an LPE and a format vocoder, which is realized by adding a processor to the existing 2400 bps LPE. This add-on processor converts the 2400 bps speech data to 600 bps speech data at the transmitter, and reconverts the data to 2400 bps at the receiver.\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "adaptive multi-rate audio codec\n",
      "baseband\n",
      "codec\n",
      "data transmission\n",
      "digital signal processing\n",
      "full rate\n",
      "pulse-code modulation\n",
      "signal processing\n",
      "signal-to-noise ratio\n",
      "speech coding\n",
      "speech technology\n",
      "\n",
      "Original fos:\n",
      "\n",
      "speech processing\n",
      "transmitter\n",
      "speech synthesis\n",
      "computer science\n",
      "voice activity detection\n",
      "filter (signal processing)\n",
      "communication channel\n",
      "speech recognition\n",
      "encoder\n",
      "intelligibility (communication)\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Delay-insensitive pipelined communication on parallel buses  Consider a communication channel that consists of several sub-channels transmitting simultaneously and asynchronously. The receiver acknowledges reception of the message before the transmitter sends the following message. Namely, pipelined utilization of the channel is not possible. The main contribution of the paper is a scheme that enables to transmit without an acknowledgement of the message, therefore enabling pipelined communication and providing a higher bandwidth. Moreover, the scheme allows for a certain number of transitions from a second message to arrive before reception of the current message has been completed, a condition that the authors call skew. They have derived necessary and sufficient conditions for codes that can tolerate a certain amount of skew among adjacent messages, (therefore, allowing for continuous operation), and detect a larger amount of skew when the original skew is exceeded. Potential applications are in on-chip, on-board and board to board communications, enabling much higher communication bandwidth\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "bandwidth (signal processing)\n",
      "clock rate\n",
      "computer hardware\n",
      "data rate\n",
      "data transmission\n",
      "multiprocessing\n",
      "real-time communication\n",
      "\n",
      "Original fos:\n",
      "\n",
      "asynchronous communication\n",
      "data transmission\n",
      "parallel communication\n",
      "computer science\n",
      "computer network\n",
      "communication channel\n",
      "error detection and correction\n",
      "bandwidth (signal processing)\n",
      "skew\n",
      "decoding methods\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Temperature insensitive and low cost transversal filters based on uniform fibre Bragg gratings  We present temperature insensitive and low cost transversal filters based on uniform fibre Bragg gratings used as slicing elements of a broadband optical source. The performance of these filters is compared to the laser array approach.\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "antenna array\n",
      "aperture\n",
      "array processing\n",
      "broadband\n",
      "electronic engineering\n",
      "modulation\n",
      "narrowband\n",
      "optics\n",
      "signal processing\n",
      "telecommunications\n",
      "wideband\n",
      "\n",
      "Original fos:\n",
      "\n",
      "memetic algorithm\n",
      "single assignment\n",
      "heuristic\n",
      "mathematical optimization\n",
      "general problem\n",
      "theoretical computer science\n",
      "heuristics\n",
      "local search (optimization)\n",
      "mathematics\n",
      "the internet\n",
      "scalability\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Design of deep sub-micron CMOS circuits  Scaling down of device sizes and supply voltage requires a commensurate scaling of transistorthreshold voltage to maintain high performance. Such scaling leads to exponential increase inleakage current, decreased noise immunity for high speed circuits, and increased defects. In thistutorial we will present design and test techniques to combat these problems in the deep sub-micronregime for bulk, SOI and future technologies. We will consider the following issues in turn:1. Device scaling and its impact on sub-threshold and gate leakage current, interconnects, andnoise immunity2. Low voltage circuit design under high intrinsic leakage, leakage monitoring and controltechniques, effective transistor stacking, multi-threshold CMOS, dynamic threshold CMOS,SOI implications. Design of low leakage data-paths and caches.3. SOI design - comparison with bulk, logic and memory design, asynchronous design4. Copper, Low k, and impact of Low k on performance5. Future technologies - Double gate fully depleted SOI, FIN FET, and 3-D SOI6. Noise modeling and analysis for high-speed precharge-evaluate circuits such as domino.Noise tolerant circuit design styles: skewed CMOS, noise tolerant domino, layout styles forhigh noise immunity7. Iddq testing of circuits with high intrinsic leakage: delta Iddq, two parameter tests. Iddwaveform analysisThis course will be useful for VLSI design engineers, managers, technologists, students, professorswho are actively involved in VLSI design or to those who need to spread their knowledge acrossmulti-disciplines. The tutorial is also intended for those who would like to know new developmentsin this field.\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "circuit design\n",
      "electronic circuit\n",
      "integrated circuit\n",
      "integrated circuit design\n",
      "integrated injection logic\n",
      "nmos logic\n",
      "transistor\n",
      "\n",
      "Original fos:\n",
      "\n",
      "leakage (electronics)\n",
      "circuit design\n",
      "electronic engineering\n",
      "cmos\n",
      "integrated circuit design\n",
      "low voltage\n",
      "engineering\n",
      "transistor\n",
      "threshold voltage\n",
      "electrical engineering\n",
      "low-power electronics\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "2- and 3-D Nonlinear predictors  The performance of both intraframe and interframe quadratic Volterra predictors is considered and compared to that of classical linear operators. A design LMS optimization algorithm is described.\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "algebra\n",
      "algorithmics\n",
      "combinatorics\n",
      "constant coefficients\n",
      "discrete mathematics\n",
      "integer\n",
      "isomorphism\n",
      "linear equation\n",
      "numerical analysis\n",
      "operator (computer programming)\n",
      "operator theory\n",
      "polynomial\n",
      "theory of computation\n",
      "\n",
      "Original fos:\n",
      "\n",
      "least squares\n",
      "applied mathematics\n",
      "nonlinear system\n",
      "algorithm design\n",
      "linear filter\n",
      "control theory\n",
      "infinite impulse response\n",
      "quadratic equation\n",
      "adaptive filter\n",
      "mathematics\n",
      "filter design\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Fractal based image coding using the sharp edge treatment  A sharp edge treatment for the original fractal based image coding is proposed. By adopting this new algorithm, the choice of optimal trigger function (TF) becomes less important. That is, image data compression can be performed with high visual quality using a fixed length yardstick for various picture only at the cost of a little increase in the data rate\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "edge detection\n",
      "edge enhancement\n",
      "geometry\n",
      "image compression\n",
      "image gradient\n",
      "image processing\n",
      "image quality\n",
      "image restoration\n",
      "image scaling\n",
      "interpolation\n",
      "spatial frequency\n",
      "trilinear interpolation\n",
      "\n",
      "Original fos:\n",
      "\n",
      "computer vision\n",
      "computer science\n",
      "fractal\n",
      "image coding\n",
      "artificial intelligence\n",
      "fractal transform\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Accuracy of speaker verification via orthogonal parameters for noisy speech  An important problem in speaker verification systems arises, when the speech inputs are noise corrupted with signal to noise ratios in the range of 10 to 30 dB (noise assumed to be zero mean and white). This paper deals with the accuracy of speaker verification algorithms derived from an orthogonal parameter representation of speech. Initially, the investigations are directed to evaluate the sensitivity of orthogonal parameters to the level of noise in the speech signal. The accuracy of verification is then determined, using only those parameters that are least sensitive to additive noise. The influence of the order of the linear prediction model on verification is also studied. The verification algorithm is based on the distance measure used by Sambur. Finally thresholds are established to determine the proper choice of orthogonal parameters (used in distance computation) and the order of the linear prediction model for a given signal to noise ratio in the speech signal. The above study is then used to evaluate the accuracy of verification when speech inputs are obtained from a noisy telephone channel.\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "adaptive filter\n",
      "colors of noise\n",
      "estimation theory\n",
      "gaussian noise\n",
      "linear prediction\n",
      "minimum phase\n",
      "signal-to-noise ratio\n",
      "speech processing\n",
      "white noise\n",
      "\n",
      "Original fos:\n",
      "\n",
      "noise\n",
      "speech enhancement\n",
      "noise floor\n",
      "noise measurement\n",
      "noise (signal processing)\n",
      "computer science\n",
      "signal-to-noise ratio\n",
      "speech recognition\n",
      "gaussian noise\n",
      "gradient noise\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Exact fast digital convolution by using P-adic numbers and polynomial transformations  In this paper, an efficient method to do the digital convolution of rational numbers is proposed. The inefficient P-adic arithmetic is replaced by the integer arithmetic, in this new approach. Furthermore, since rational number are exactly representable, error-free results of the convolution of two rational sequences can be obtained by this method very efficiently.\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "adaptive filter\n",
      "algebra\n",
      "arithmetic\n",
      "digital filter\n",
      "discrete cosine transform\n",
      "discrete-time signal\n",
      "filter design\n",
      "finite impulse response\n",
      "harmonic wavelet transform\n",
      "humanities\n",
      "integer\n",
      "linear equation\n",
      "orthonormal basis\n",
      "signal processing\n",
      "\n",
      "Original fos:\n",
      "\n",
      "discrete mathematics\n",
      "arithmetic function\n",
      "rational number\n",
      "convolution\n",
      "circular convolution\n",
      "p-adic number\n",
      "rational point\n",
      "convolution power\n",
      "overlap–add method\n",
      "mathematics\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "New stochastic realization algorithms for identification of ARMA models  Autoregressive moving-average (ARMA) models are of great interest in speech processing. This paper presents new stochastic realization algorithms for identification of such models, by use of a special canonical filter form in the state space, directly and simply connected with ARMA models. We take advantage of certain matrix properties to develop algorithms, which eliminate a matrix inversion, using either the autoeorrelation function of the signal , or the autocorrelation function of a pseudo-innovation sequence , or a cross-correlation function between and . We also present a new algorithm for optimal joint state and parameter estimation in the important case of autoregressive (AR) models. Results obtained with all these algorithms are given for simulated examples.\n",
      "\n",
      "Predict tags:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applied mathematics\n",
      "combinatorics\n",
      "covariance\n",
      "finite set\n",
      "inverse\n",
      "linear form\n",
      "linear map\n",
      "matrix (mathematics)\n",
      "orthonormal basis\n",
      "rational function\n",
      "state-transition matrix\n",
      "unit circle\n",
      "\n",
      "Original fos:\n",
      "\n",
      "autoregressive model\n",
      "matrix (mathematics)\n",
      "algorithm\n",
      "stochastic process\n",
      "white noise\n",
      "transfer function\n",
      "estimation theory\n",
      "state space\n",
      "mathematics\n",
      "autocorrelation\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Video synthesis of arbitrary views for approximately planar scenes  In this paper, we propose a method to synthesize arbitrary views of a planar scene, given a monocular video sequence. The method is based on the availability of knowledge of the angle between the original and synthesized views. Such a method has many impor- tant applications, one of them being gait recognition. Gait recog- nition algorithms rely on the availability of an approximate side- view of the person. From a realistic viewpoint, such an assumption is impractical in surveillance applications and it is of interest to develop methods to synthesize a side view of the person, given an arbitrary view. For large distances from the camera, a planar ap- proximation for the individual can be assumed. In this paper, we propose a perspective projection approach for recovering the direc- tion of motion of the person purely from the video data, followed by synthesis of a new video sequence at a different angle. The al- gorithm works purely in the image and video domain, though D structure plays an implicit role in its theoretical justification. Ex- amples of synthesized views using our method and performance evaluation are presented.\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "camera resectioning\n",
      "image sequence\n",
      "iterative reconstruction\n",
      "motion compensation\n",
      "motion estimation\n",
      "motion field\n",
      "multiple view\n",
      "video sequence\n",
      "video tracking\n",
      "\n",
      "Original fos:\n",
      "\n",
      "computer vision\n",
      "block-matching algorithm\n",
      "computer science\n",
      "motion compensation\n",
      "multiview video coding\n",
      "perspective (graphical)\n",
      "video tracking\n",
      "planar\n",
      "artificial intelligence\n",
      "motion estimation\n",
      "video compression picture types\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Distributed binary hypothesis testing with feedback  The problem of binary hypothesis testing is revisited in the context of distributed detection with feedback. Two basic distributed structures with decision feedback are considered. The first structure is the fusion center network, with decision feedback connections from the fusion center element to each one of the subordinate decisionmakers. The second structure consists of a set of detectors that are fully interconnected via decision feedback. Both structures are optimized in the Neyman-Pearson sense by optimizing each decision-maker individually. Then, the time evolution of the power of the tests is derived. Definite conclusions regarding the gain induced by the feedback process and direct comparisons between the two structures and the optimal centralized scheme are obtained through asymptotic studies (that is, assuming the presence of asymptotically many local detectors). The behavior of these structures is also examined in the presence of variations in the statistical description of the hypotheses. Specific robust designs are proposed and the benefits from robust operations are established. Numerical results provide additional support to the theoretical arguments\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "decentralised system\n",
      "evidential reasoning approach\n",
      "fusion center\n",
      "interdependence\n",
      "knowledge management\n",
      "management science\n",
      "organizational learning\n",
      "project success\n",
      "sensor fusion\n",
      "situated\n",
      "\n",
      "Original fos:\n",
      "\n",
      "control theory\n",
      "sensor fusion\n",
      "robustness (computer science)\n",
      "time evolution\n",
      "decision theory\n",
      "fusion center\n",
      "binary hypothesis testing\n",
      "detector\n",
      "statistical hypothesis testing\n",
      "mathematics\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Approximate computation of signal characteristics of on-chip RC interconnect trees  Fast and efficient computation of signal characteristics such as delay, slew etc. play a key role in design and analysis of high performance VLSI circuits. Elmore approximation may not be accurate when resistive components of the interconnect significantly affect signal characteristics. An efficient mechanism to compute the driving point admittance of a resistive interconnect tree exists, in which the tree is traversed bottom-up to compute the driving point admittance (DPA). An approximation technique is proposed in this paper which involves traversing an interconnect RC tree top-down to compute the signal characteristics, by exploiting already calculated admittance at every node. A piecewise linear approximation obtained from the analytical expression for voltage at every node is used to compute voltages at subsequent nodes in the tree. The advantage of the proposed technique is efficient and fast computation of interconnect signal characteristics from already computed admittance information. Results comparing the proposed technique with RICE and Elmore on representative RC trees of antifuse based FPGA interconnect are presented\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "circuit design\n",
      "integrated circuit\n",
      "interconnection\n",
      "rc circuit\n",
      "rlc circuit\n",
      "very-large-scale integration\n",
      "waveform\n",
      "\n",
      "Original fos:\n",
      "\n",
      "topology\n",
      "computer science\n",
      "antifuse\n",
      "field-programmable gate array\n",
      "electronic engineering\n",
      "rc circuit\n",
      "integrated circuit design\n",
      "interconnection\n",
      "admittance\n",
      "very-large-scale integration\n",
      "computation\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "An improved, highly parallel rank-one eigenvector update method with signal processing applications  In this paper, we discuss rank-one eigenvector updating schemes that are appropriate for tracking time-varying, narrow-band signals in noise. We show that significant reductions in computation are achieved by updating the eigenvalue decomposition (EVD) of a reduced rank version of the data covariance matrix, and that reduced rank updating yields a lower threshold breakdown than full rank updating. We also show that previously published eigenvector updating algorithms [1], [10], suffer from a linear build-up of roundoff error which becomes significant when large numbers of recursive updates are performed. We then show that exponential weighting together with pairwise Gram Schmidt partial orthogonalization at each update virtually eliminates the build-up of error making the rank-one update a useful numerical tool for recursive updating. Finally, we compare the frequency estimation performance of reduced rank weighted linear prediction and the LMS algorithm.\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "covariance matrix\n",
      "eigendecomposition of a matrix\n",
      "eigenvalues and eigenvectors\n",
      "linear algebra\n",
      "matrix (mathematics)\n",
      "matrix decomposition\n",
      "qr algorithm\n",
      "qr decomposition\n",
      "rank (linear algebra)\n",
      "singular value decomposition\n",
      "\n",
      "Original fos:\n",
      "\n",
      "least mean squares filter\n",
      "rank (linear algebra)\n",
      "mathematical optimization\n",
      "round-off error\n",
      "algorithm\n",
      "linear prediction\n",
      "eigendecomposition of a matrix\n",
      "covariance matrix\n",
      "orthogonalization\n",
      "mathematics\n",
      "eigenvalues and eigenvectors\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Incorporating a measure of local scale in voxel-based 3-D image registration.  We present a new class of approaches for rigid-body registration and their evaluation in studying multiple sclerosis (MS) via multiprotocol magnetic resonance imaging (MRI). Three pairs of rigid-body registration algorithms were implemented, using cross-correlation and mutual information (MI), operating on original gray-level images, and utilizing the intermediate images resulting from our new scale-based method. In the scale image, every voxel has the local \"scale\" value assigned to it, defined as the radius of the largest ball centered at the voxel with homogeneous intensities. Three-dimensional image data of the head were acquired from ten MS patients for each of six MRI protocols. Images in some of the protocols were acquired in registration. The registered pairs were used as ground truth. Accuracy and consistency of the six registration methods were measured within and between protocols for known amounts of misregistrations. Our analysis indicates that there is no \"best\" method. For medium misregistration, the method using MI, for small add large misregistration the method using normalized cross-correlation performs best. For high-resolution data the correlation method and for low-resolution data the MI method, both using the original gray-level images, are the most consistent. We have previously demonstrated the use of local scale information in fuzzy connectedness segmentation and image filtering. Scale may also have potential for image registration as suggested by this work.\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "computer vision\n",
      "gray level\n",
      "image registration\n",
      "mr images\n",
      "pixel\n",
      "segmentation\n",
      "thresholding\n",
      "voxel\n",
      "\n",
      "Original fos:\n",
      "\n",
      "voxel\n",
      "computer vision\n",
      "computer science\n",
      "segmentation\n",
      "image processing\n",
      "filter (signal processing)\n",
      "ground truth\n",
      "artificial intelligence\n",
      "mutual information\n",
      "image resolution\n",
      "image registration\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "A linear phase maximally flat low-pass FIR filter  The design of a linear phase FIR filter is formulated as a constrained minimization problem. The constraints express the maximally flat pass band frequency response requirement. The objective function is formed as a convex combination of two objective functions representing the energy of the error between the frequency responses of the desired and designed filters in both the stop and pass bands. This extends the results obtained where the mean squares error was minimized only over the stop band\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "algorithm\n",
      "band-pass filter\n",
      "digital filter\n",
      "filter (signal processing)\n",
      "filter design\n",
      "finite impulse response\n",
      "frequency response\n",
      "linear phase\n",
      "low-pass filter\n",
      "modulation\n",
      "passband\n",
      "signal-to-noise ratio\n",
      "\n",
      "Original fos:\n",
      "\n",
      "linear phase\n",
      "topology\n",
      "digital filter\n",
      "linear filter\n",
      "control theory\n",
      "prototype filter\n",
      "constant k filter\n",
      "low-pass filter\n",
      "adaptive filter\n",
      "m-derived filter\n",
      "mathematics\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Subjective quality of several 9.6-32 kb/s speech coders  Ratings obtained from subjective tests indicate that for single encodings of speech, near equivalence to 64 kb/s PCM is obtained at 32 kb/s with ADPCM/AP and SBC, and at 24 kb/s with APC and ATC/VD. Tandem encodings of 32 kb/s ADPCM/AP are significantly better than 16 kb/s APC and SEC. Eight synchronous encodings of 32 kb/s ADPCM/AP are rated about the same as eight asynchronous encodings of 64 kb/s PCM. The subjective test results are used to develop preliminary coder performance functions in terms of Q (subjective ratio of speech power and speech-dependent noise power) in terms consistent with a previously reported quantization distortion opinion model. These relations, in conjunction with a proposed CCITT planning rule, indicate that a 32 kb/s ADPCM/AP coder can be allowed in each of the national extensions of an international connection. Reported results apply only to coder quantization effects on speech quality; other signals (e.g., voiceband data, signaling tones) and impact of coder delay on echo performance are not covered.\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "adaptive multi-rate audio codec\n",
      "code-excited linear prediction\n",
      "harmonic vector excitation coding\n",
      "linear predictive coding\n",
      "psqm\n",
      "pulse-code modulation\n",
      "quantization (signal processing)\n",
      "sound quality\n",
      "speech coding\n",
      "speech processing\n",
      "speech recognition\n",
      "wideband\n",
      "\n",
      "Original fos:\n",
      "\n",
      "asynchronous communication\n",
      "noise power\n",
      "band-pass filter\n",
      "computer science\n",
      "speech recognition\n",
      "equivalence (measure theory)\n",
      "cutoff frequency\n",
      "telephony\n",
      "quantization (signal processing)\n",
      "encoding (memory)\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Iterative design of one-dimensional efficient seismic Lp infinite impulse response f-x digital filters  This study proposes a new technique, the Lp iterative reweighted least-square (IRLS) algorithm, to design efficient and accurate non-causal complex-valued seismic infinite impulse response (IIR) frequency-space (f-x) digital filters. Unlike earlier works where the problem is prefiltered and linearised, through this technique, the weights are updated by the trust-region-reflection (TRR) optimisation method, and the non-linear-weighted least-square IIR filter design problem is solved directly. The results of this study show smooth convergence empirically of the proposed IRLS-TRR algorithm for designing efficient complex-valued IIR f-x filter coefficients. Using the same specification parameters, the design for an IIR f-x filter of the order of N=2, a requirement needed for seismic wavefield extrapolation filters, outperforms the same filter designed using the IRLS prefiltering linearised algorithm at the expense of a few additional iterations and a justified running design time.\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "adaptive filter\n",
      "digital filter\n",
      "filter (signal processing)\n",
      "filter design\n",
      "finite impulse response\n",
      "infinite impulse response\n",
      "signal processing\n",
      "\n",
      "Original fos:\n",
      "\n",
      "convergence (routing)\n",
      "digital filter\n",
      "control theory\n",
      "infinite impulse response\n",
      "algorithm\n",
      "2d filters\n",
      "extrapolation\n",
      "iterative design\n",
      "finite impulse response\n",
      "mathematics\n",
      "filter design\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "An experimental investigation of the optimal filter as an area function perdictor  In order to test the accuracy of the optimal filter as an area function predictor, the technique is applied to data derived from stepped cylindrical cavities of known dimension. The impulse response of the cavities is measured and an optimal filter is derived from the data. The area function derived from the optimal filter is then compared to the actual cavity area function. In addition, an optimal filter is derived from the theoretically calculated cavity response and the area function derived from this filter is compared to the original cavity area function. Results are presented for several different cavity configurations.\n",
      "\n",
      "Predict tags:\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adaptive filter\n",
      "digital filter\n",
      "filter (signal processing)\n",
      "filter design\n",
      "interpolation\n",
      "kernel adaptive filter\n",
      "linear filter\n",
      "recursive filter\n",
      "smoothing\n",
      "\n",
      "Original fos:\n",
      "\n",
      "raised-cosine filter\n",
      "digital filter\n",
      "root-raised-cosine filter\n",
      "mathematical analysis\n",
      "control theory\n",
      "sinc filter\n",
      "low-pass filter\n",
      "kernel adaptive filter\n",
      "adaptive filter\n",
      "mathematics\n",
      "filter design\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Efficient Detection Technique for Multiple Packet Collisions in OFDM Systems  Whenever there is a collision involving several transmitted packets, the traditional approach for MAC (Medium Access Control) protocols is to discard all packets involved and request their retransmission, with a consequent loss in the overall throughput. Based on conventional Multiple Input Multiple Output (MIMO) techniques, in this paper we propose a multipacket detector for OFDM schemes (Orthogonal Frequency Division Multiplexing) that allows an efficient packet separation in the presence of collisions and can achieve high throughputs. We show that reliable detection is possible as long as different interleavers are used for different retransmissions. We also include a method to estimate the users involved in the collision, as well as well as the corresponding channel characteristics.\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "capture effect\n",
      "communication channel\n",
      "network packet\n",
      "packet transmission\n",
      "retransmission\n",
      "throughput\n",
      "time division multiple access\n",
      "\n",
      "Original fos:\n",
      "\n",
      "frequency response\n",
      "retransmission\n",
      "computer science\n",
      "network packet\n",
      "communication channel\n",
      "computer network\n",
      "mimo\n",
      "throughput\n",
      "detector\n",
      "orthogonal frequency-division multiplexing\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Estimating and comparing entropies across written natural languages using PPM compression  Summary form only given. The measurement of the entropy of written English is extended to include the following written natural languages: Arabic, Chinese, French, Japanese, Korean, Russian, and Spanish. It was observed that translations of the same document have approximately the same size when compressed even though they have widely varying uncompressed sizes. In the experiment, an efficient compression algorithm was used. It utilized PPMD+, PPMZ, and BZIP2 to compress the given texts and compare the resulting sizes. Similar experiments with machine translations were also performed. Based on the findings, it suggests that compression can be used as a tool to find poor translations. The results of these experiments, while preliminary, support the hypothesis that translation preserves information content. This analysis opens new horizons for future research concerning the relationship between compression and translation.\n",
      "\n",
      "Predict tags:\n",
      "\n",
      "english language\n",
      "first language\n",
      "foreign language\n",
      "linguistics\n",
      "natural language processing\n",
      "phrase\n",
      "sentence\n",
      "speech recognition\n",
      "word lists by frequency\n",
      "\n",
      "Original fos:\n",
      "\n",
      "entropy estimation\n",
      "compression (physics)\n",
      "language translation\n",
      "computer science\n",
      "machine translation\n",
      "natural language\n",
      "natural language processing\n",
      "artificial intelligence\n",
      "data compression\n",
      "entropy (information theory)\n",
      "uncompressed video\n",
      "\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "indexes = [random.choice(range(1,10000)) for _ in range(20)]\n",
    "for idx in indexes:\n",
    "    text = test_articles.text[idx]\n",
    "    print(text + '\\n')\n",
    "    print('Predict tags:\\n')\n",
    "    print('\\n'.join(estimator.predict(text)) + '\\n')\n",
    "    print('Original fos:\\n')\n",
    "    print('\\n'.join(topic.lower() for topic in test_articles.fos[idx]))\n",
    "    print('\\n----------------------------------------------------------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To continue your doc2vec explorations, refer to the official API documentation in Gensim: https://radimrehurek.com/gensim/models/doc2vec.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
