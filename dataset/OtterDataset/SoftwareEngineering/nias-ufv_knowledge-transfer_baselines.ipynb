{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baselines\n",
    "\n",
    "> *It can scarcely be denied that the supreme goal of all theory is to make the irreducible basic elements as simple and as few as possible without having to surrender the adequate representation of a single datum of experience*.\n",
    "> \n",
    "> \\- Albert Einstein,\n",
    "[*often quoted as ‘Everything should be made as simple as possible, but not simpler’*, *‘On the Method of Theoretical Physics’, lecture delivered at Oxford, 10 June 1933*](https://www.oxfordreference.com/view/10.1093/acref/9780191826719.001.0001/q-oro-ed4-00003988#:~:text=It%20can%20scarcely%20be%20denied,a%20single%20datum%20of%20experience.&text=The%20eternal%20mystery%20of%20the%20world%20is%20its%20comprehensibility%E2%80%A6)\n",
    "\n",
    " Alguns padrões de projeto para solução de competições que o NIASIA identificou até agora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Faça rápido um modelo ruim, aprenda devagar a melhorá-lo, e ganhe competições!\n",
    "\n",
    "Um bom resumo deste notebook talvez seja [este post no blog do Emmanuel Ameisen: \"Always start with a stupid model, no exceptions.\"](https://mlpowered.com/posts/start-with-a-stupid-model/), autor do livro 'Building Machine Learning Powered Applications: Going from Idea to Product', ou também esse artigo da Google: [Rules of ML](https://developers.google.com/machine-learning/guides/rules-of-ml) (\"Keep the first model simple and get the infrastructure right\").\n",
    "\n",
    "Neste notebook apresentamos argumentos e uma metodologia de errar rápido para conseguir acertar em competições de Inteligência Artificial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nesse notebook o foco não será em aprofundar em ideias ou códigos, nem na validação matemática das propostas feitas aqui. \n",
    "\n",
    "#### Ao contrário, aqui serão apresentados exemplos de como muitos livros, autores e Kagglers encaram  e resolvem problemas de IA e atingem performances iguais ou acima do estado da arte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolvendo problemas com IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na maioria dos livros, cursos e até frameworks de implementação de soluções em IA, discute-se uma visão geral de como resolver problemas com IA. Essencialmente, modelos de aprendizado de máquina são métodos matemáticos (frequentemente com forte embasamento estatístico) que tomam entradas numéricas e predizem uma saída, seja ela uma determinada classe ou um número.\n",
    "\n",
    "Normalmente, o processo para treinar esses modelos consiste em:\n",
    "\n",
    "    1. Adquirir dados (que acreditamos ter potencial para prever *algo*)\n",
    "\n",
    "    2. Identificar características estatísticas, anomalias e os tipos desses dados\n",
    "\n",
    "    3. Transformar os dados em uma coleção de números com alguma relação com *algo* que queremos prever\n",
    "    \n",
    "    4. Escolher um modelo de aprendizado que seja capaz de eventualmente prever esses dados\n",
    "\n",
    "    5. Medir a performance desse modelo\n",
    "\n",
    "    6. Melhorar a performance do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padrão de projeto em IA:\n",
    "\n",
    "Agora, veja o índice de um dos capítulos do livro 'Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow](./imgs/handson_ml_overview.png) -->\n",
    "\n",
    "<div style = \"height:520px\">\n",
    "    <img src=\"./imgs/handson_ml_overview.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dê uma olhada agora nos componentes do ciclo de MLOps da Google, no livro 'Practical MLOps\n",
    "Operationalizing Machine Learning Models':\n",
    "\n",
    ">[(MLOps ou ML Ops é um conjunto de práticas que visa implantar e manter modelos de machine learning em produção de forma confiável e eficiente. A palavra é um composto de \"machine learning\" e a prática de desenvolvimento contínuo de DevOps na área de software.)](https://www.google.com/search?q=mlops&sxsrf=ALiCzsYlr6Lajbj_pnIRMp_EcUHZJYf8_A:1658366859510&source=lnms&tbm=isch&sa=X&ved=2ahUKEwjBssX86Yj5AhXdSLgEHQ3CClsQ_AUoAXoECAIQAw&biw=1360&bih=699&dpr=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![](./imgs/google_mlops.png) -->\n",
    "\n",
    "<div style = \"height:520px\" >\n",
    "    <img src=\"./imgs/google_mlops.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, veja o ciclo de vida de soluções de aprendizado de máquina, apresentado no livro 'Machine Learning Design Patterns Solutions to Common Challenges in Data Preparation, Model Building, and MLOps':"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./imgs/ml_life_cycle_ml_design_patterns.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takeaway:\n",
    "\n",
    "E então? Notou algum padrão?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem, diante dos livros e também de competições (como vou mostrar a seguir), existe uma forte tendencia no mercado e na academia de transformar a proposta, treino e predição de modelos de IA em uma *pipeline* automática, composta de:\n",
    "\n",
    "    1. EDA (análise exploratória de dados, *exploratory data analysis*)\n",
    "\n",
    "    2. Engenharia de Características\n",
    "\n",
    "    3. Seleção de Modelo(s)\n",
    "\n",
    "    4. Treino\n",
    "\n",
    "    5. Predição\n",
    "\n",
    "    6. Retreino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare a lista de passos acima com as imagens e com a lista de passos no início dessa seção. Estes passos são a essência (automatizável!) do aprendizado de máquina.\n",
    "\n",
    "### Seu papel então como pesquisador, desenvolvedor e competidor é fazer isso tão rápido e tão bom quanto possível!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Competindo no Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. Vimos que *nos livros* esses métodos são usados. Mas e no Kaggle?\n",
    "\n",
    "Dê uma olhada rápida nas seções [deste notebook](). Não se preocupe neste primeiro momento em entender os dados ou os resultados. O foco aqui é na metodologia deste autor. Notou um padrão relacionado à seção anterior?\n",
    "\n",
    "No notebook, em linhas gerais, o autor:\n",
    "\n",
    "    1. Importou e visualizou distribuições dos dados\n",
    "\n",
    "    2. Limpou e selecionou aqueles que mais importavam para seu contexto/problema\n",
    "\n",
    "    3. Escolheu não UM mas DOZE modelos diferentes, sendo eles:\n",
    "        - Florestas aleatórias:\n",
    "            1. Linear Regression, \n",
    "            2. Ridge Regression, \n",
    "            3. Support Vector Regression, \n",
    "            4. Random Forest Regressor, \n",
    "            5. Gradient Boosting Regressor, \n",
    "            6. AdaBoost Regressor, \n",
    "            7. XGBoost Regressor.\n",
    "        - Modelos Neurais Profundos:\n",
    "            9. Simple RNN, \n",
    "            10. LSTM, \n",
    "            11. Bidirectional RNN\n",
    "        - Transformers:\n",
    "            11. BERT\n",
    "\n",
    "    4. Treinou todos estes modelos \n",
    "\n",
    "    5. Previu as saídas em banco de validação\n",
    "\n",
    "    6. Escolheu o melhor modelo e utilizou ele para submissão.\n",
    "\n",
    "Tudo isso, em um notebook que executa por completo em 1789.1 segundos (30 minutos)!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beleza, um monstro da IA. Como faço isso? Baby steps. Com certeza esse cara não nasceu escrevendo notebooks Kaggle com 12 modelos treinados, ele aprendeu e realizou cada uma das etapas separadamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de Problemas em IA:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Academia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eis algumas áreas e problemas que modelos de IA são utilizados para resolver, de acordo com os filtros [no famoso hub de soluções Open Source https://huggingface.co/](https://huggingface.co/):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![](./imgs/ml_tasks_huggingface.png) -->\n",
    "\n",
    "<div style = \"max-height:520px\">\n",
    "    <img src=\"./imgs/ml_tasks_huggingface.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarmente, acessando o também famoso site agregador de artigos científicos com códigos de implementações e datasets [https://paperswithcode.com/sota](https://paperswithcode.com/sota), você encontrá centenas de tarefas, agrupadas em:\n",
    "\n",
    "    - Computer Vision\n",
    "    - Natural Language Processing\n",
    "    - Methodology\n",
    "    - Miscellaneous\n",
    "    - Time Series\n",
    "    - Graphs \n",
    "    - Speech\n",
    "    - Playing Games\n",
    "    - Audio\n",
    "    - Computer Code\n",
    "    - Adversarial\n",
    "    - Robots\n",
    "    - Reasoning\n",
    "    - Knowledge Base\n",
    "    - Music\n",
    "\n",
    "Todos estes agrupamentos de tarefas possuem diversas soluções, empregando modelos com diferentes parâmetros, que normalmente tem aplicação interdisciplinar e para diferentes tarefas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mercado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Além dos agrupamentos de tarefas com base em estratégias acadêmicas, no repositório [Awesome Artificial Intelligence use cases](https://github.com/JosPolfliet/awesome-ai-usecases#contents) existem listas de links e recursos agregando problemas de mercado atuais, resolvidos através de inteligência artificial:\n",
    "\n",
    "    Use cases by department\n",
    "\n",
    "    - Call center\n",
    "    - Human Resources\n",
    "    - Finance\n",
    "    - IT\n",
    "    - Marketing\n",
    "    - Sales\n",
    "    - Supply chain\n",
    "\n",
    "    \n",
    "    Use cases by industry\n",
    "\n",
    "    - Banking\n",
    "    - Healthcare\n",
    "    - Insurance\n",
    "    - Life sciences\n",
    "    - Manufacturing\n",
    "    - Public Safety\n",
    "    - Retail\n",
    "    - Telecommunications\n",
    "    - Travel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Takeaway:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deve-se ter cuidado com a curva do Hype, como apresentado em [CLEMMEDSSON, Elin. Identifying pitfalls in machine learning implementation projects: a case study of four technology-intensive organizations. 2018.](http://www.diva-portal.org/smash/record.jsf?pid=diva2%3A1230169&dswid=6169):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height:520px\">\n",
    "    <img src=\"./imgs/hype_curve_2017.png\",style=\"height:520px\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nas competições, frequentemente temos ideias mirabolantes de execução difícil e validação ainda mais difícil. Busque implementar melhorias pequenas, cuja contribuição seja mensurável, para ter controle do impacto que as mudanças que você propôs teve sobre a sua *pipeline* de preprocessamento, treino ou inferência. Faça mudanças pequenas, rápidas, o tempo todo, até que seu modelo inicial não-tão-bom se torne um modelo final vencedor de competições."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resumindo: \n",
    "\n",
    "#### Use ao máximo tecnologias prontas, confiáveis, de comportamento conhecido e que você domina. Se você não domina nenhuma, escolha alguma que não seja tão complexa e tenha certeza que a entendeu. Passo a passo, aprendemos juntos e atingimos resultados melhores!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se quiser ainda mais recursos e informações, considere ler os links listados no repositório [Awesome AI Awesomeness](https://github.com/amusi/awesome-ai-awesomeness#table-of-contents), onde são agrupadas algumas das tarefas e casos de usos dicutidas aqui, além de muitas que nem comentei."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Como começar?\n",
    "\n",
    "> Qual modelo faz o que? Quando uso cada um? O que preciso para treiná-los?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidentemente, não existe resposta exata e completa para nenhuma destas perguntas. Mas assumindo o escopo dos problemas que buscamos resolver atualmente em competições de Kaggle, aqui estão alguns recursos e sugestões (🔨MARRETAS!) de onde eu comecei, que talvez possam te ajudar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. RTFD (READ THE FUCKING DOCS)\n",
    "\n",
    "> Respire fundo e estude um exemplo antes de desistir de uma abordagem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leia sempre as documentações. Grande parte das respostas à suas perguntas vão estar descritas em exemplos e documentações de sites como o da biblioteca [Scikit-Learn](https://scikit-learn.org/stable/index.html):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![Sklearn LP](./imgs/sklearn_frontpage.png) -->\n",
    "\n",
    "<div>\n",
    "    <img src=\"./imgs/sklearn_frontpage.png\", alt = 'Sklearn LP',height='520px'>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Já na sua página inicial a sklearn nos dá algumas lições:\n",
    "\n",
    "- Existem 2 tipos principais de problemas: Classifição e Regressão.\n",
    "- Muitas vezes não temos etiquetas (labels) para saber o que deveriamos prever. Para isso, Clustering.\n",
    "- Às vezes temos dados demais (muitas dimensões) e precisaremos de métodos para reduzí-las (exemplo: PCA).\n",
    "- Seleção de modelos é importante e existem métodos automáticos (mas lentos) para isso.\n",
    "- Preprocessamento (limpeza, normalização e extração de características de dados) é essencial!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Então, antes de desesperar ('Don't panic!' - The Hitchhiker's Guide to the Galaxy), tente buscar no Google: 'sklearn regression example', quando estiver com um problema de regressão. E claro, antes de abrir 327 abas da Wikipedia indo de \"Regressão\" até \"Física Quântica\", considere executar passo a passo um exemplo da biblioteca sklearn. Você vai se surpreender com quão simples é usar as ferramentas de lá!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forests e Boosting\n",
    "\n",
    "> Florestas marreteiras dão baseline pra te ajudar a decidir se seu preprocessamento está minimamente aceitável\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Florestas aleatórias são bastante tendenciosas e podem sofrer com bancos de dados desbalanceados. Mas treiná-las é rápido, fácil e frequentemente é a primeira na maioria das submissões \"baseline\" em competições Kaggle.\n",
    "\n",
    "Elas recebem como entrada uma tabela com features (características) em colunas, e cada entrada (instância de dados) em linhas, sempre numéricas. \n",
    "\n",
    "Logo, se você tem features categóricas (texto, por exemplo), vai precisar transformá-las em números de alguma forma!\n",
    "\n",
    "Como saída, estas redes normalmente possuem implementações para tarefas de regressão ou classificação. \n",
    "\n",
    "Aqui alguns links (com exemplos para classificação) de bibliotecas de Random Forests muito usadas:\n",
    "\n",
    "- [lightgbm.LGBMClassifier — LightGBM 3.3.2.99 documentation](https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html)\n",
    "- [XGBoost Documentation — xgboost 1.6.1 documentation](https://xgboost.readthedocs.io/en/stable/)\n",
    "- [sklearn.ensemble.RandomForestClassifier — scikit-learn 1.1.1 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "- [sklearn.multiclass.OneVsRestClassifier — scikit-learn 1.1.1 documentation](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html)\n",
    "- [LightGBM Classifier in Python | Kaggle](https://www.kaggle.com/code/prashant111/lightgbm-classifier-in-python/notebook)\n",
    "\n",
    "\n",
    "Dica: XGBoost tem treino normalmente mais lento que o LGBM, e nem sempre tem uma performance melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perceptron Multicamadas (MLP)\n",
    "\n",
    "> Neurônios são difíceis de treinar mas podem abstrair padrões, diferente das florestas marreteiras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferente das florestas aleatórias, as redes neurais artificiais com base em perceptron multicamadas têm a vantagem de serem altamente flexíveis e abstrair padrões a partir dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn.neural_network.MLPClassifier — scikit-learn 1.1.1 documentation\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um problema para se atentar treinando redes neurais artificiais, é a generalização de padrões não desejados, como exemplificado em [GEIRHOS, Robert et al. Shortcut learning in deep neural networks. Nature Machine Intelligence, v. 2, n. 11, p. 665-673, 2020](https://www.nature.com/articles/s42256-020-00257-z):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-height:520px\">\n",
    "    <img src=\"./imgs/dll_unintended_abstractions.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, MLPs rasas e profundas se caracterizam como ferramentas poderosas mas escorregadias. Têm potencial de atingir aquele 2% a mais que traz a vitória na competição, mas seu treinamento está longe de ser trivial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Redes Convolucionais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kkkkkkk boa sorte, ainda não tive tempo de escrever essa parte (WIP TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Outros métodos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "kkkkkkk boa sorte, ainda não tive tempo de escrever essa parte (WIP TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Mais recursos e links com exemplos para começar:\n",
    "\n",
    "> OK Boomer. Falou muito, mas onde encontro exemplos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existe uma gama enorme de exemplos de preprocessamento, treino de modelos e otimização notebooks excelentes disponíveis na própria plataforma [Kaggle](https://www.kaggle.com/). Escolha um tópico simples por dia, quando menos perceber, vai estar lidando com problemas e resultados bem próximos do estado da arte!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algumas instâncias de tarefas comuns em IA, exemplificadas e discutidas no livro \"Building Machine Learning Powered Applications: Going from Idea to Product\" estão disponíveis no repositório: [ml-powered-applications/notebooks at master · hundredblocks/ml-powered-applications]\n",
    "(https://github.com/hundredblocks/ml-powered-applications/tree/master/notebooks).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem diversos repositórios com nome \"awesome\" listando recursos para determinadas áreas de conhecimento: \n",
    "\n",
    "- Em \"[Awesome Machine Learning](https://github.com/josephmisiti/awesome-machine-learning#table-of-contents)\", você encontrará exemplos de implementação e uso de diversas metodologias em aprendizado de máquinas, para as linguagens mais populares;\n",
    "\n",
    "- Ainda em \"Awesome Machine Learning\", dê uma olhada em livros grátis lidando com diferentes tarefas necessárias para construir modelos, listadas nesse link: [https://github.com/josephmisiti/awesome-machine-learning/blob/master/books.md](https://github.com/josephmisiti/awesome-machine-learning/blob/master/books.md);\n",
    "\n",
    "- Em \"[Awesome AI](https://github.com/MRCIEU/awesome-ai#awesome-ai)\", você encontrará tutoriais, ferramentas e até artigos científicos explicando diversos conceitos e tecnologias úteis para aprender a trabalhar com inteligência artificial.\n",
    "\n",
    "- Em \"[Awesome Software Engineering for Machine Learning](https://github.com/SE-ML/awesome-seml#contents)\", você encontrará ferramentas, exemplos, tutoriais e artigos para obter uma visão geral do panorama de Aprendizado de Máquina visando construir modelos para aplicações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erros comuns e como escapar deles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em termos de nomenclatura quais [tipos de erros existem](https://www.expii.com/t/types-of-error-overview-comparison-8112)?\n",
    "\n",
    "<div style=\"height:520px\">\n",
    "    <img src=\"./imgs/types_of_error.jpeg\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui queremos diminuir os erros sistemáticos teóricos (seleção de modelos), observacionais (seleção de features) e instrumentais (treinamento e emprego de modelos). Mas como?\n",
    "\n",
    "Na documentação da biblioteca sklearn, existe um artigo interessante sobre [erros comuns e práticas recomendadas](https://scikit-learn.org/stable/common_pitfalls.html), frequentemente discutidos em cursos sobre IA. Você pode ler com mais detalhes no link, mas alguns pontos importantes são:\n",
    "\n",
    "- Preprocesse com pipelines, sempre da mesma maneira, para controlar melhor os ajustes que você aplica ao seu modelo.\n",
    "- Atente-se para separar bem a saída e entrada do modelo! \n",
    "- Controle as seeds aleatórias para obter reproducibilidade.\n",
    "- Use validação cruzada para verificar com precisão a performance do seu modelo.\n",
    "\n",
    "É importante também conhecer alguns detalhes importantes ao se trabalhar com medidas e transformações estatísticas, para se interpretar corretamente a sua EDA. Leia [neste documento](https://scikit-learn.org/stable/auto_examples/inspection/plot_linear_model_coefficient_interpretation.html) um relatório sobre interpretação de correlação, escala, variância, entre outros. [Um outro artigo interessante na biblioteca sklearn](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py) trata do impacto e comportamento da normalização de escala e processamento de outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caso tenha mais interesse em estudar erros comuns para se preparar para evitá-los (ou enfrentá-los), dê uma olhada no artigo [LONES, Michael A. How to avoid machine learning pitfalls: a guide for academic researchers. arXiv preprint arXiv:2108.02497, 2021](https://arxiv.org/pdf/2108.02497.pdf), abaixo o sumário dos tópicos analisados no trabalho:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"height:520px\">\n",
    "    <img src=\"./imgs/avoid_pitfalls_paper.png\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outros recursos e referências:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CommonLit: EDA + (Most) NLP Techniques📚 | Kaggle\n",
    "https://www.kaggle.com/code/utcarshagrawal/commonlit-eda-most-nlp-techniques/notebook\n",
    "\n",
    "List of datasets for machine-learning research - Wikipedia\n",
    "https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research#Human\n",
    "\n",
    "Outline of machine learning - Wikipedia\n",
    "https://en.wikipedia.org/wiki/Outline_of_machine_learning\n",
    "\n",
    "Models - Hugging Face\n",
    "https://huggingface.co/models?sort=downloads\n",
    "\n",
    "scikit-learn: machine learning in Python — scikit-learn 1.1.1 documentation\n",
    "https://scikit-learn.org/stable/index.html\n",
    "\n",
    "Ensemble deep learning in bioinformatics | Nature Machine Intelligence\n",
    "https://www.nature.com/articles/s42256-020-0217-y\n",
    "\n",
    "A Brief Introduction to Probability & Statistics\n",
    "https://betterexplained.com/articles/a-brief-introduction-to-probability-statistics/\n",
    "\n",
    "Shanky-21/Data_visualization\n",
    "https://github.com/Shanky-21/Data_visualization\n",
    "\n",
    "The Intuition Behind Correlation – Time Series Analysis, Regression and Forecasting\n",
    "https://timeseriesreasoning.com/contents/correlation/#:~:text=In%20the%20most%20general%20sense,manner%2C%20most%20of%20the%20time.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5dd76241fa2ee905525e0a1efacb16294be0e14843e7f10299cba718b3e5fb2a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
