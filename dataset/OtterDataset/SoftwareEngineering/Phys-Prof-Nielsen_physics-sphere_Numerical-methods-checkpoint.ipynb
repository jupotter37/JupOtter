{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A1.2 Numerical Integration: Finite Difference Methods\n",
    "<hr style=\"height:2px;border-width:0;color:gray;background-color:gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1.2.1 Motivation\n",
    "\n",
    "We will see that many examples encountered in Physics I \n",
    "come with assumptions that makes them less applicable to everyday life.\n",
    "While these examples are great at illustrating important concepts, they fail\n",
    "in providing accurate prediction for real-life examples. When these\n",
    "assumptions are not valid, our problems often become too difficult to obtain\n",
    "exact solutions for, and our best effort is to provide approximate solutions\n",
    "that are correct to within a set acceptable error margin.\n",
    "\n",
    "As an example, Newton's second law is a second order differential equation, which in many real-life applications is non-linear and only solveable through numerical methods. Under certain situations, we can transform it into coupled first order differential equations that can be solved by numerical integration methods. The objective of this note is to obtain these numerical integration schemes known as **finite difference methods**. \n",
    "\n",
    "<hr style=\"height:2px;border-width:0;color:gray;background-color:gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1.2.2 Linearization\n",
    "\n",
    "Let us consider the graphical setup below. Assume that we have\n",
    "knowledge of a data point with\n",
    "coordinates $[x_0,f(x_0)]$ of a function\n",
    "$f(x)$, and we desire knowledge about\n",
    "a point P with coordinates $[x, f(x)]$ in\n",
    "close proximity to the data point. \n",
    "\n",
    "<img src=\"A1-fig1.png\" width=\"400\">\n",
    "\n",
    "In the Figure, the blue line represents the function $f(x)$ and the red line is the tangent line at point $[x_0,f(x_0)]$, which is the best linear\n",
    "representation of the function at that point. The tangent line is represented\n",
    "by the linear equation (think of the intercept/rise form: $y = A + Bx$):\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "$$ L(x) = f(x_0) + \\left.\\frac{df}{dx}\\right|_{x = x_0}(x - x_0) \\tag{1}$$\n",
    "</div>\n",
    "\n",
    "If we use this equation to approximate the function $f(x)$ at point P, we call $L(x)$ **the\n",
    "linearization** or the linear approximation of $f(x)$. From the figure, we can see\n",
    "that our guess $L(x)$ for $f(x)$ at point P is only an approximation and we introduce an\n",
    "error with this approximation. A good, and very important, question would\n",
    "be: how big is this error? We will provide a more rigorous approach next that will help us answer that question.\n",
    "\n",
    "<hr style=\"height:2px;border-width:0;color:gray;background-color:gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1.2.3 Taylor Series\n",
    "\n",
    "Calculus tells us that if we have a well-behaved function, the function can be written as the sum of an infinite series of polynomials called the **Taylor series** provided we have information about the function at some point $x = a$:\n",
    "\n",
    "$$ f(x) = f(a) + (x-a)\\left.\\frac{df}{dx}\\right |_{x = a} + \\frac{(x-a)^2}{2!}\\left.\\frac{d^{2}f}{dx^2}\\right|_{x = a}\n",
    "+ \\frac{(x-a)^3}{3!}\\left.\\frac{d^{3}f}{dx^3}\\right |_{x = a} + \\cdots $$\n",
    "\n",
    "With our notation in the above discussion of linearization, we have information about a point $x = x_0$, so let us re-write the Taylor series using $x_0$ insted of $a$:\n",
    "\n",
    "$$ f(x) = f(x_0) + (x-x_0)\\left.\\frac{df}{dx}\\right |_{x = x_0} + \\frac{(x-x_0)^2}{2!}\\left.\\frac{d^{2}f}{dx^2}\\right|_{x = x_0}\n",
    "+ \\frac{(x-x_0)^3}{3!}\\left.\\frac{d^{3}f}{dx^3}\\right |_{x = x_0} + \\cdots $$\n",
    "\n",
    "I am introducing this notation, since we are more familiar with writing the difference in $x$ as $\\Delta x = x - x_0$. If we introduce this notation into our Taylor series, we get (note: $x = x_0 + \\Delta x$):\n",
    "\n",
    "$$ f(x_0 + \\Delta x) = f(x_0) + (\\Delta x)\\left.\\frac{df}{dx}\\right |_{x = x_0} + \\frac{(\\Delta x)^2}{2!}\\left.\\frac{d^{2}f}{dx^2}\\right|_{x = x_0}\n",
    "+ \\frac{(\\Delta x)^3}{3!}\\left.\\frac{d^{3}f}{dx^3}\\right |_{x = x_0} + \\cdots $$\n",
    "\n",
    "At this point, we have not done anything other than re-write the Taylor series using different notation. However, it may be more evident now **that our left hand-side of the equation is the function $f(x)$ evaluated at a point ahead of $x$ by using information about the function at $x_0$ only**. That is actually pretty cool!\n",
    "\n",
    "If the above feels overwhelming, please do not panic! I am only showing these steps towards our numericale scheme such that those of you with the mathematical confidence can see what is behind the door. The focus in the class will be on applying the numerical scheme, which is ahead of us yet.\n",
    "\n",
    "### Mathematical Trick\n",
    "We will now make some tricks, or just plain arithmetic: subract $f(x_0)$ on both sides of the equation and divide by $\\Delta x$ through all terms:\n",
    "\n",
    "$$ \\frac{f(x_0 + \\Delta x) - f(x_0)}{\\Delta x} = \\left.\\frac{df}{dx}\\right |_{x = x_0} + \\frac{(\\Delta x)}{2!}\\left.\\frac{d^{2}f}{dx^2}\\right|_{x = x_0}\n",
    "+ \\frac{(\\Delta x)^2}{3!}\\left.\\frac{d^{3}f}{dx^3}\\right |_{x = x_0} + \\cdots $$\n",
    "\n",
    "### Truncation\n",
    "The next step is to truncate the expression to only include the first derivative term (truncation simply refers to the fact that we are only considering a limited number of terms in the infinite series):\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "$$ \\frac{f(x_0 + \\Delta x) - f(x_0)}{\\Delta x} \\sim \\left.\\frac{df}{dx}\\right |_{x = x_0} \\tag{2}$$\n",
    "</div>\n",
    "\n",
    "Notice that we change the \"=\" to \"~\" since we are now approximating it. We also notice that this approximation is similar to the linearization in Equation (1). However, there is one important element that sets the two\n",
    "approaches apart. Whereas the error in the linearization was unknown,\n",
    "the Taylor expansion approach provides us with an order of magnitude\n",
    "estimation of the error! \n",
    "\n",
    "Each successive term in the Taylor\n",
    "expansion is smaller than the previous (a requirement for mathematical convergence), and\n",
    "as such, our largest term that we ignored in the approximation above was \n",
    "\n",
    "$$ \\frac{(\\Delta x)}{2!}\\left.\\frac{d^{2}f}{dx^2}\\right|_{x = x_0} $$\n",
    "\n",
    "**Hence, the error in our approximation is $\\mathcal{O}(\\Delta x)$** (read as: order of magnitude $\\Delta x$).\n",
    "\n",
    "### Question\n",
    "Professor, why go through these lengthy steps to obtain our rise/run\n",
    "approximation for the derivative?\n",
    "\n",
    "### Answer\n",
    "This is the simplest approximation\n",
    "(linear), but we could have truncated the Taylor expansion further down\n",
    "and obtained more accurate approximations (for example $\\mathcal{O}(\\Delta x)^2$. We will do that as a box\n",
    "exercise. **The above processes in using Taylor expansions to obtain approximations for derivatives are called finite difference methods**.\n",
    "\n",
    "### Question\n",
    "This is not in my textbook and I do not feel this is physics. Why do I need to know this?\n",
    "\n",
    "### Answer\n",
    "Because it is an important element to solve realistic physics problems, and often the only way of doing it. As physicists and engineers, you do not get very far in real life by always ignoring friction or non-linear properties of materials. In software engineering, you will have to deal with discrete math and solving methods. A game engine, for example, is full of numerical methods.\n",
    "\n",
    "<hr style=\"height:2px;border-width:0;color:gray;background-color:gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A1.2.4 First Order Forward Finite Difference Method\n",
    "\n",
    "The approximation for the derivative we obtained in Equation (2) is known\n",
    "as the **first order derivative forward finite difference method**. It is forward since we are applying knowledge\n",
    "of our data point $x_0$ to obtain information about a point $x$ laying ahead (or forward) of\n",
    "$x_0$ (see figure in section 1).\n",
    "\n",
    "When we apply this method to update the value $f(x)$ based on the known\n",
    "value $f(x_0)$, it is often more convenient to write it in subscript form (this\n",
    "notation is also more intuitive with respect to implementing it into a\n",
    "computer script):\n",
    "\n",
    "$$ \\frac{f(x_0 + \\Delta x) - f(x_0)}{\\Delta x} \\sim \\left.\\frac{df}{dx}\\right |_{x = x_0} $$\n",
    "\n",
    "$$ \\frac{f(x_{i+1}) - f(x_i)}{x_{i+1}- x_i} \\sim \\left.\\frac{df}{dx}\\right |_{x = x_i} $$\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "$$ \\frac{f_{i+1} - f_i}{x_{i+1}- x_i} \\sim \\left.\\frac{df}{dx}\\right |_{x = x_i} \\tag{3} $$\n",
    "</div>\n",
    "\n",
    "Equation (3) is the form we will implement as our numerical tool. While it would be great if you understand all the steps above, it is certainly not a requirement in this course. The applications are the essential and we will see some examples now.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "Given a single data point $[x_0, f(x_0)]$ and a **model** for the derivative, we can make discrete **linear** steps to obtain a solution:\n",
    "    \n",
    "$$ f_{i+1} = f_i + f_{i}'\\Delta x$$\n",
    "</div>\n",
    "\n",
    "<hr style=\"height:2px;border-width:0;color:gray;background-color:gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D0D0D0 ; padding: 10px; border: 1px solid black;\">       \n",
    "<header>\n",
    "<h3> Example 1</h3>\n",
    "    </header>\n",
    "    \n",
    "We will consider a simple differential equation that we can solve analytical\n",
    "as well to demonstrate the use of the forward finite difference method.\n",
    "Consider the following differential equation with the condition that $(y_0, x_0)\n",
    "= (0,0)$:\n",
    "\n",
    "$$ \\frac{dy}{dx} = x^2 $$\n",
    "\n",
    "**Question**: Find the solution $y(x)$ at $x = 5$.\n",
    "\n",
    "We can utilize differentials to cast it into integration form with solution\n",
    "\n",
    "$$ y(x) = \\frac{x^3}{3} $$\n",
    "\n",
    "If we evaluate at $x = 5$ we get: \n",
    "\n",
    "<img src=\"A1-fig2.png\" width=\"300\">\n",
    "\n",
    "\n",
    "Now let us try and solve it through numerical integration!\n",
    "\n",
    "According to Equation (3), we can approximate the derivative by\n",
    "\n",
    "$$ \\left.\\frac{df}{dx}\\right |_{x = x_i} \\sim \\frac{f_{i+1} - f_i}{x_{i+1}- x_i} $$\n",
    "\n",
    "In our case, the dependent variable is $y$ and not $f$:\n",
    "\n",
    "$$ \\left.\\frac{dy}{dx}\\right |_{x = x_i} \\sim \\frac{y_{i+1} - y_i}{x_{i+1}- x_i} $$\n",
    "\n",
    "In the numerical approach, we will start at our initial data point $(y_0, x_0)\n",
    "= (0,0)$ and progress towards $x = 5$ in chosen steps of $\\Delta x = x_{i+1} - x_i$. We call $\\Delta x$ the **step size** and the process is called an **iterative process**. \n",
    "\n",
    "Note: in a computational physics\n",
    "course, we would learn more about how to make a proper choice regarding\n",
    "this step size to obtain the most accurate solution without jeopardizing computer speed, but it is beyond the scope of this course.\n",
    "\n",
    "The next step is to replace the derivative in our differential equation with the approximation:\n",
    "\n",
    "$$ \\frac{y_{i+1} - y_i}{x_{i+1}- x_i} =  x_{i}^2$$\n",
    "\n",
    "**Important: the variable $x$ on the right side of the equation now got a subscript \"i\" attached to it. The reason is that we assume knowledge of $x$ and $y$ at our initial point. We must have this initial point to start the iteration**!\n",
    "\n",
    "We have now converted a differential equation (continuous) into discrete equation that can be solved by arithmetic. Solving for our next $y$ value:\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "$$ y_{i+1} = y_i +  x_{i}^{2}\\Delta x$$\n",
    "</div>\n",
    "\n",
    "We call this our **iterative equation** and is the equation we will use to step forward in $x$ until we reach $x = 5$. \n",
    "Let’s try and iterate it in the interval $x = [0,5]$ in step sizes of 1:\n",
    "\n",
    "| x | y |\n",
    "| :-- | :-- |\n",
    "| <img width=100/> | <img width=600/> |\n",
    "| $x_0 = 0$ | $y_0 = 0$ |\n",
    "| $x_1 = 1$ | $y_1 = y_0 + x_{0}^2\\Delta t = 0 + (0)^2(1) = 0 $ |\n",
    "| $x_2 = 2$ | $y_2 = y_1 + x_{1}^2\\Delta t = 0 + (1)^2(1) = 1 $ |\n",
    "| $x_3 = 3$ | $y_3 = y_2 + x_{2}^2\\Delta t = 1 + (2)^2(1) = 5 $ |\n",
    "| $x_4 = 4$ | $y_4 = y_3 + x_{3}^2\\Delta t = 5 + (3)^2(1) = 14 $ |\n",
    "| $x_5 = 5$ | $y_5 = y_4 + x_{4}^2\\Delta t = 14 + (4)^2(1) = 30 $ |\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "Our numerical solution is $y = 30$ at $x = 5$\n",
    "</div>\n",
    "\n",
    "A quick comparison between the analytical solution (42) and the numerical (30) will tell us that we are quite\n",
    "a bit off. However, we used a large step\n",
    "size ($\\Delta x = 1$), and the function is changing\n",
    "significantly over this large step size. **We\n",
    "should choice a step size over which the function is not varying significantly**. Let us try and repeat the process with a stepsize of $\\Delta x = 0.1$:\n",
    "\n",
    "| x | y |\n",
    "| :-- |  :-- |\n",
    "| <img width=100/> | <img width=600/> |\n",
    "| $x_0 = 0$ |  $y_0 = 0$ |\n",
    "| $x_1 = 0.1$ |  $y_1 = y_0 + x_{0}^2\\Delta t = 0 + (0)^2(1) = 0 $ |\n",
    "| $x_2 = 0.2$ | $y_2 = y_1 + x_{1}^2\\Delta t = 0 + (0.1)^2(1) = 0.01 $ |\n",
    "\n",
    "Hold on! I will have to do this about 50 times. No way, dude! Python to the rescue:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Solution: 40.42500000000002\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "x = 0\n",
    "y = 0\n",
    "\n",
    "dx = 0.1\n",
    "\n",
    "x_f = 5.\n",
    "nSteps = int(x_f/dx)\n",
    "\n",
    "for i in range(nSteps):\n",
    "    y = y + (x**2)*dx\n",
    "    x = x + dx\n",
    "print('Numerical Solution: '+str(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D0D0D0 ; padding: 10px; border: 1px solid black;\">       \n",
    "\n",
    "That is pretty close. In fact, the percent error is:\n",
    "\n",
    "$$\\textrm{percent error} = \\frac{|\\textrm{Numerical} - \\textrm{Analytic}|}{\\textrm{Analytic}}\\times 100\\% = \\frac{|40.425 - 42|}{42}*100\\% = 3.8\\%$$\n",
    "\n",
    "We could anticipate this great result since we know the error is comparable to $\\Delta x$ (we know this from the Taylor truncation error), and since we chose $\\Delta x = 0.1$, we would anticipate an error of the order of $\\sim 1\\%$.\n",
    "\n",
    "Let us visualize the analytic and numerical solutions:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Solution: 40.42500000000002\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Analytic solution\n",
    "t = np.arange(0,5.1,0.1)\n",
    "f = t**3/3.\n",
    "\n",
    "# Numerical solution\n",
    "\n",
    "x = [0]\n",
    "y = [0]\n",
    "\n",
    "dx = 0.1\n",
    "\n",
    "x_f = 5.\n",
    "nSteps = int(x_f/dx)\n",
    "\n",
    "for i in range(nSteps):\n",
    "    y.append(y[i] + (x[i]**2)*dx)\n",
    "    x.append(x[i] + dx)\n",
    "print('Numerical Solution: '+str(y[nSteps]))\n",
    "\n",
    "# Plotting\n",
    "\n",
    "plt.figure()\n",
    "plt.ylabel('y(x)')\n",
    "plt.xlabel('x')\n",
    "ax = plt.gca()\n",
    "ax.plot(x,y,'b')\n",
    "ax.plot(t,f, 'r')\n",
    "\n",
    "ax.set_xlim([np.min(x), np.max(x)])\n",
    "ax.set_ylim([np.min(y), np.max(y)])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #D0D0D0 ; padding: 10px; border: 1px solid black;\">       \n",
    "\n",
    "Here we can see how good our numerical solution (blue) is compared to the actual solution (red). Isn't this amazing? We can apply this approach to a variety of complex physics problems, that we otherwise could not cover in Physics I. We will get practice using this approach and by the end of the semester, I hope we have a much better appreciation for it.\n",
    "\n",
    "Now it is your turn to try it! Below is one Box problem for you to test your skills on this subject. I will make a separate note, where there is a brief summary and some sort of guide on how to approach these problems. I guess we can call it a solving strategy :)\n",
    "\n",
    "As a final note: the approach above is the **first order forward finite difference method**. We could also work backwards with the Taylor expansion to obtain the **backward finite difference method**. This method is used when we need to gain information about points prior to our known data point. Finally, we can combine the two and obtain the **central finite difference method**, which differ by having an order of magnitude smaller error. We will not be employing either of the two, but if you are curious, check out \n",
    "\n",
    "* [Finite Difference](https://en.wikipedia.org/wiki/Finite_difference)\n",
    "* [Finite Difference Method](https://en.wikipedia.org/wiki/Finite_difference_method)\n",
    "</div>\n",
    "<hr style=\"height:2px;border-width:0;color:gray;background-color:gray\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>Box 1</b><br>\n",
    "    \n",
    "Consider the differential equation\n",
    "    \n",
    "$$ \\frac{dy}{dx} = x^3 $$ \n",
    "  \n",
    "Find the solution $y(x)$ at $x = 5$ if we know that $(x_0, y_0) = (0,2)$. What is the percent error between the analytical and numerical solutions? Create a plot showing the analytical and numerical solution.\n",
    "</div>\n",
    "\n",
    "<hr style=\"height:2px;border-width:0;color:gray;background-color:gray\">"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
