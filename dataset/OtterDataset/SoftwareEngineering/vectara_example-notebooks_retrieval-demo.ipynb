{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c4d6137",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vectara/example-notebooks/blob/main/notebooks/retrieval-demo.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988c68a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings, CohereEmbeddings\n",
    "from langchain.chat_models.openai import ChatOpenAI\n",
    "\n",
    "from llama_index import ServiceContext\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.node_parser import SentenceWindowNodeParser\n",
    "from llama_index import VectorStoreIndex\n",
    "from llama_index.indices import VectaraIndex\n",
    "from llama_index.indices.postprocessor import MetadataReplacementPostProcessor\n",
    "from llama_index.schema import Document\n",
    "\n",
    "from deep_translator import GoogleTranslator\n",
    "from functools import cache\n",
    "from ratelimiter import RateLimiter\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from pathlib import Path\n",
    "from llama_hub.file.unstructured.base import UnstructuredReader\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb54a7d7",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6f73ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '../data/llama2.pdf'\n",
    "llm = ChatOpenAI(model_name='gpt-3.5-turbo-16k', temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f95e074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default pyPDF fails miserably on llama2.pdf so we're using custom code to load the text properly\n",
    "def read_file(fname):\n",
    "    loader = UnstructuredReader()\n",
    "    documents = loader.load_data(file=Path(fname))\n",
    "    return documents\n",
    "    \n",
    "def get_index(documents, embedding):\n",
    "    node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "        window_size=3,\n",
    "        window_metadata_key=\"window\",\n",
    "        original_text_metadata_key=\"original_text\",\n",
    "    )\n",
    "    ctx = ServiceContext.from_defaults(llm=llm, embed_model=embedding, \n",
    "                                       node_parser=node_parser)\n",
    "    nodes = node_parser.get_nodes_from_documents(documents)\n",
    "    index = VectorStoreIndex(nodes, service_context=ctx)\n",
    "    return index\n",
    "\n",
    "def get_vectara_index(documents):\n",
    "    index = VectaraIndex.from_documents(documents)\n",
    "    return index\n",
    "\n",
    "def get_answer(index, query):\n",
    "    query_engine = index.as_query_engine(similarity_top_k=5,\n",
    "        node_postprocessors=[\n",
    "            MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "        ],\n",
    "    )\n",
    "    response = str(query_engine.query(query))\n",
    "    return response\n",
    "\n",
    "def get_vectara_answer(index, query):\n",
    "    response = str(index.as_query_engine(similarity_top_k=5, n_sentences_before=3, n_sentences_after=3).query(query))\n",
    "    return response\n",
    "\n",
    "def get_context(index, query_tr):\n",
    "    query_engine = index.as_query_engine(similarity_top_k=5,\n",
    "        node_postprocessors=[\n",
    "            MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "        ],\n",
    "    )\n",
    "    response = query_engine.query(query)\n",
    "    txt_and_window = [(t.node.metadata['original_text'], t.node.metadata['window']) for t in response.source_nodes]\n",
    "    return txt_and_window\n",
    "\n",
    "def get_vectara_context(index, query_tr):\n",
    "    response = index.as_query_engine(similarity_top_k=5, n_sentences_before=1, n_sentences_after=1).query(query)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fe15199",
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_limiter = RateLimiter(max_calls=1, period=2)\n",
    "\n",
    "@cache\n",
    "def translate(s, lang):\n",
    "    with rate_limiter:\n",
    "        return GoogleTranslator(source='auto', target=lang).translate(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30fc86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    'What learning rate was used for pre-training?',\n",
    "    'Was RLHF used?',\n",
    "    'which models are released for commercial use?',\n",
    "    'was red teaming used?', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d29cc3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = {\n",
    "    'en': 'English',\n",
    "    'iw': 'Hebrew',\n",
    "    'tr': 'Turkish',\n",
    "    'ar': 'Arabic',\n",
    "    'de': 'German',\n",
    "    'ur': 'Urdu',\n",
    "    'ja': 'Japanese',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a9247e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ofer/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/ofer/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "documents = read_file(file_name)\n",
    "\n",
    "openai_index = get_index(documents, OpenAIEmbeddings())\n",
    "cohere_index = get_index(documents, CohereEmbeddings())\n",
    "vectara_index = get_vectara_index(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25206430",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lang = en, query = What learning rate was used for pre-training?\n",
      "Lang = en, query = Was RLHF used?\n",
      "Lang = en, query = which models are released for commercial use?\n",
      "Lang = en, query = was red teaming used?\n",
      "Lang = iw, query = באיזה קצב למידה נעשה שימוש בהכשרה מוקדמת?\n",
      "Lang = iw, query = האם נעשה שימוש ב-RLHF?\n",
      "Lang = iw, query = אילו דגמים משוחררים לשימוש מסחרי?\n",
      "Lang = iw, query = האם נעשה שימוש בצוות אדום?\n",
      "Lang = tr, query = Ön eğitim için hangi öğrenme oranı kullanıldı?\n",
      "Lang = tr, query = RLHF kullanıldı mı?\n",
      "Lang = tr, query = Hangi modeller ticari kullanıma sunuluyor?\n",
      "Lang = tr, query = kırmızı takım kullanıldı mı?\n",
      "Lang = ar, query = ما هو معدل التعلم الذي تم استخدامه للتدريب المسبق؟\n",
      "Lang = ar, query = هل تم استخدام RLHF؟\n",
      "Lang = ar, query = ما هي النماذج التي تم إصدارها للاستخدام التجاري؟\n",
      "Lang = ar, query = هل تم استخدام الفريق الأحمر؟\n",
      "Lang = de, query = Welche Lernrate wurde für das Vortraining verwendet?\n",
      "Lang = de, query = Wurde RLHF verwendet?\n",
      "Lang = de, query = Welche Modelle sind für den kommerziellen Einsatz freigegeben?\n",
      "Lang = de, query = Wurde Red Teaming verwendet?\n",
      "Lang = ur, query = پری ٹریننگ کے لیے سیکھنے کی کیا شرح استعمال کی گئی؟\n",
      "Lang = ur, query = کیا RLHF استعمال کیا گیا تھا؟\n",
      "Lang = ur, query = کون سے ماڈل تجارتی استعمال کے لیے جاری کیے گئے ہیں؟\n",
      "Lang = ur, query = کیا ریڈ ٹیمنگ کا استعمال کیا گیا تھا؟\n",
      "Lang = ja, query = 事前トレーニングにはどのような学習率が使用されましたか?\n",
      "Lang = ja, query = RLHFは使用されましたか?\n",
      "Lang = ja, query = 商用利用可能なモデルはどれですか?\n",
      "Lang = ja, query = レッドチームが使われたのか？\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for lang in languages.keys():\n",
    "    for q in queries:\n",
    "\n",
    "        time.sleep(5)\n",
    "        if lang != 'en':\n",
    "            q_tr = translate(q, lang)\n",
    "        else:\n",
    "            q_tr = q\n",
    "        print(f\"Lang = {lang}, query = {q_tr}\")\n",
    "                \n",
    "        r = get_answer(openai_index, q_tr)\n",
    "        data.append(['openai', lang, q_tr, r])\n",
    "\n",
    "        r = get_answer(cohere_index, q_tr)\n",
    "        data.append(['cohere', lang, q_tr, r])\n",
    "\n",
    "        r = get_vectara_answer(vectara_index, q_tr)\n",
    "        data.append(['vectara', lang, q_tr, r])\n",
    "\n",
    "df = pd.DataFrame(data, columns = ['vendor', 'lang', 'question', 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4c9b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('retrieval-demo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "791d1fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_per_lang(lang: str):\n",
    "    df1 = df[df['lang']==lang].drop('lang', axis=1)\n",
    "    df2 = df1.pivot(index='question', columns='vendor', values='answer')\n",
    "    for col in ['cohere', 'openai', 'vectara']:\n",
    "        df2[col] = df2[col].map(lambda x: translate(x, 'en'))\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "985f714a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>vendor</th>\n",
       "      <th>cohere</th>\n",
       "      <th>openai</th>\n",
       "      <th>vectara</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Was RLHF used?</th>\n",
       "      <td>Yes, RLHF (Reinforcement Learning from Human Feedback) was used in the study mentioned in the context information.</td>\n",
       "      <td>Yes, RLHF (Reinforcement Learning from Human Feedback) was used in the study mentioned in the context information.</td>\n",
       "      <td>Yes, RLHF (Reinforcement Learning from Human Feedback) was used in the earlier versions of the model, up to RLHF V3.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>What learning rate was used for pre-training?</th>\n",
       "      <td>The learning rate used for pre-training is a constant learning rate of 10^-6.</td>\n",
       "      <td>The learning rate used for pre-training is not mentioned in the given context information.</td>\n",
       "      <td>The learning rate used for pre-training was 5 × 10−6 for the 70B parameter Llama 2-Chat and 1 × 10−5 for the rest.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>was red teaming used?</th>\n",
       "      <td>Yes, red teaming was used in the study.</td>\n",
       "      <td>Yes, red teaming was used as a proactive risk identification method in the development of the LLMs.</td>\n",
       "      <td>Yes, red teaming was used in the process.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>which models are released for commercial use?</th>\n",
       "      <td>Llama 2 is the model that has been released for commercial use.</td>\n",
       "      <td>Llama 2 is the model that is released for commercial use.</td>\n",
       "      <td>Llama 2 is the model that is released for commercial use.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "vendor                                                                                                                                                     cohere  \\\n",
       "question                                                                                                                                                            \n",
       "Was RLHF used?                                 Yes, RLHF (Reinforcement Learning from Human Feedback) was used in the study mentioned in the context information.   \n",
       "What learning rate was used for pre-training?                                       The learning rate used for pre-training is a constant learning rate of 10^-6.   \n",
       "was red teaming used?                                                                                                     Yes, red teaming was used in the study.   \n",
       "which models are released for commercial use?                                                     Llama 2 is the model that has been released for commercial use.   \n",
       "\n",
       "vendor                                                                                                                                                     openai  \\\n",
       "question                                                                                                                                                            \n",
       "Was RLHF used?                                 Yes, RLHF (Reinforcement Learning from Human Feedback) was used in the study mentioned in the context information.   \n",
       "What learning rate was used for pre-training?                          The learning rate used for pre-training is not mentioned in the given context information.   \n",
       "was red teaming used?                                         Yes, red teaming was used as a proactive risk identification method in the development of the LLMs.   \n",
       "which models are released for commercial use?                                                           Llama 2 is the model that is released for commercial use.   \n",
       "\n",
       "vendor                                                                                                                                                      vectara  \n",
       "question                                                                                                                                                             \n",
       "Was RLHF used?                                 Yes, RLHF (Reinforcement Learning from Human Feedback) was used in the earlier versions of the model, up to RLHF V3.  \n",
       "What learning rate was used for pre-training?    The learning rate used for pre-training was 5 × 10−6 for the 70B parameter Llama 2-Chat and 1 × 10−5 for the rest.  \n",
       "was red teaming used?                                                                                                     Yes, red teaming was used in the process.  \n",
       "which models are released for commercial use?                                                             Llama 2 is the model that is released for commercial use.  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_per_lang('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63ec6236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>vendor</th>\n",
       "      <th>cohere</th>\n",
       "      <th>openai</th>\n",
       "      <th>vectara</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>אילו דגמים משוחררים לשימוש מסחרי?</th>\n",
       "      <td>The context information does not provide any specific information about released models for commercial use.</td>\n",
       "      <td>Noam Shazeer's \"Fast transformer decoding: One write-head is all you need\" from 2019 and \"Glu variants improve transformer\" from 2020, Gabriel Synnaeve's \"Growing up together: Structured exploration for large action spaces\" from 2019, Yarden Tal, Inbal Magar, and Roy Schwartz's \"Fewer errors, but more stereotypes? The effect of model size on gender bias\" from 2020b, Rico Sennrich, Barry Haddow, and Alexandra Birch's \"Neural machine translation of rare words with subword units\" from 2016, Uri Shaham, Elad Segal, Maor Ivgi, Avia Efrat, Ori Yoran, Adi Haviv, Ankit Gupta, Wenhan Xiong, Mor Geva, Jonathan Berant, and Omer Levy's \"SCROLLS: Standardized CompaRison over long language sequences\" from 2022, Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton's \"Program synthesis with large language models\" from 2021, and David Autor and Anna Salomons' \"Is automation labor-displacing? Productivity growth, employment, and the labor share\" are all released for commercial use.</td>\n",
       "      <td>Llama 2 is the model that is released for commercial use.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>באיזה קצב למידה נעשה שימוש בהכשרה מוקדמת?</th>\n",
       "      <td>According to the information in the context, there is no specific information on the rate of use of early training.</td>\n",
       "      <td>The rate at which pretraining is used is not mentioned in the given information.</td>\n",
       "      <td>The rate used in pretraining is a cosine learning rate with an initial learning rate of 2 × 10−5.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>האם נעשה שימוש ב-RLHF?</th>\n",
       "      <td>Yes, there is usage of RLHF mentioned in the context information.</td>\n",
       "      <td>Yes, RLHF (Rejection Sampling fine-tuning) is one of the algorithms explored in the context.</td>\n",
       "      <td>Yes, RLHF (Reinforcement Learning from Human Feedback) is mentioned in the context information. It is described as a powerful strategy for fine-tuning Large Language Models (LLMs) and has been used to align the models' responses more closely with human expectations and preferences. RLHF has been applied in various applications and has shown improvements in the performance of LLMs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>האם נעשה שימוש בצוות אדום?</th>\n",
       "      <td>It is not possible to determine whether a red team was used based on the given information.</td>\n",
       "      <td>According to the information in the context, there is no specific information or answer to the question of whether a red team was used.</td>\n",
       "      <td>Yes, a red team was used during the process. The Red Team includes more than 350 people, including experts in cyber, election riots, social media information bombardment, law, policy, civil rights, ethics, software engineering, machine learning, AI credibility, and creative writing. The team also includes people from a diverse demographic of social class, gender, ethnicity, and race.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "vendor                                                                                                                                                  cohere  \\\n",
       "question                                                                                                                                                         \n",
       "אילו דגמים משוחררים לשימוש מסחרי?                  The context information does not provide any specific information about released models for commercial use.   \n",
       "באיזה קצב למידה נעשה שימוש בהכשרה מוקדמת?  According to the information in the context, there is no specific information on the rate of use of early training.   \n",
       "האם נעשה שימוש ב-RLHF?                                                                       Yes, there is usage of RLHF mentioned in the context information.   \n",
       "האם נעשה שימוש בצוות אדום?                                         It is not possible to determine whether a red team was used based on the given information.   \n",
       "\n",
       "vendor                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           openai  \\\n",
       "question                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "אילו דגמים משוחררים לשימוש מסחרי?          Noam Shazeer's \"Fast transformer decoding: One write-head is all you need\" from 2019 and \"Glu variants improve transformer\" from 2020, Gabriel Synnaeve's \"Growing up together: Structured exploration for large action spaces\" from 2019, Yarden Tal, Inbal Magar, and Roy Schwartz's \"Fewer errors, but more stereotypes? The effect of model size on gender bias\" from 2020b, Rico Sennrich, Barry Haddow, and Alexandra Birch's \"Neural machine translation of rare words with subword units\" from 2016, Uri Shaham, Elad Segal, Maor Ivgi, Avia Efrat, Ori Yoran, Adi Haviv, Ankit Gupta, Wenhan Xiong, Mor Geva, Jonathan Berant, and Omer Levy's \"SCROLLS: Standardized CompaRison over long language sequences\" from 2022, Jacob Austin, Augustus Odena, Maxwell Nye, Maarten Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry, Quoc Le, and Charles Sutton's \"Program synthesis with large language models\" from 2021, and David Autor and Anna Salomons' \"Is automation labor-displacing? Productivity growth, employment, and the labor share\" are all released for commercial use.   \n",
       "באיזה קצב למידה נעשה שימוש בהכשרה מוקדמת?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              The rate at which pretraining is used is not mentioned in the given information.   \n",
       "האם נעשה שימוש ב-RLHF?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     Yes, RLHF (Rejection Sampling fine-tuning) is one of the algorithms explored in the context.   \n",
       "האם נעשה שימוש בצוות אדום?                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      According to the information in the context, there is no specific information or answer to the question of whether a red team was used.   \n",
       "\n",
       "vendor                                                                                                                                                                                                                                                                                                                                                                                                                                vectara  \n",
       "question                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "אילו דגמים משוחררים לשימוש מסחרי?                                                                                                                                                                                                                                                                                                                                                   Llama 2 is the model that is released for commercial use.  \n",
       "באיזה קצב למידה נעשה שימוש בהכשרה מוקדמת?                                                                                                                                                                                                                                                                                                   The rate used in pretraining is a cosine learning rate with an initial learning rate of 2 × 10−5.  \n",
       "האם נעשה שימוש ב-RLHF?                        Yes, RLHF (Reinforcement Learning from Human Feedback) is mentioned in the context information. It is described as a powerful strategy for fine-tuning Large Language Models (LLMs) and has been used to align the models' responses more closely with human expectations and preferences. RLHF has been applied in various applications and has shown improvements in the performance of LLMs.  \n",
       "האם נעשה שימוש בצוות אדום?                 Yes, a red team was used during the process. The Red Team includes more than 350 people, including experts in cyber, election riots, social media information bombardment, law, policy, civil rights, ethics, software engineering, machine learning, AI credibility, and creative writing. The team also includes people from a diverse demographic of social class, gender, ethnicity, and race.  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_per_lang('iw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04151a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>vendor</th>\n",
       "      <th>cohere</th>\n",
       "      <th>openai</th>\n",
       "      <th>vectara</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>question</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Hangi modeller ticari kullanıma sunuluyor?</th>\n",
       "      <td>It is not stated which models are available for commercial use.</td>\n",
       "      <td>Llama 2 model is being released to the general public for research and commercial use.</td>\n",
       "      <td>Llama 2 and Llama 2-Chat models are available for commercial use.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RLHF kullanıldı mı?</th>\n",
       "      <td>Yes, RLHF was used in the study mentioned in the context information.</td>\n",
       "      <td>Yes, RLHF (Reinforcement Learning from Human Feedback) was used in the study mentioned in the context information.</td>\n",
       "      <td>Yes, RLHF (Reinforcement Learning from Human Feedback) was used in the described research. The authors trained successive versions of RLHF models, referred to as RLHF-V1, RLHF-V2, RLHF-V3, RLHF-V4, and RLHF-V5. They explored RLHF fine-tuning using two main algorithms: Proximal Policy Optimization (PPO) and Rejection Sampling fine-tuning.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kırmızı takım kullanıldı mı?</th>\n",
       "      <td>There is no information in the given context about whether the red team was used or not.</td>\n",
       "      <td>Yes, the red team was used.</td>\n",
       "      <td>Yes, the red team was used.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ön eğitim için hangi öğrenme oranı kullanıldı?</th>\n",
       "      <td>No information is given about the learning rate.</td>\n",
       "      <td>The learning rate used for pretraining is not specified.</td>\n",
       "      <td>10−6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "vendor                                                                                                                            cohere  \\\n",
       "question                                                                                                                                   \n",
       "Hangi modeller ticari kullanıma sunuluyor?                               It is not stated which models are available for commercial use.   \n",
       "RLHF kullanıldı mı?                                                Yes, RLHF was used in the study mentioned in the context information.   \n",
       "kırmızı takım kullanıldı mı?                    There is no information in the given context about whether the red team was used or not.   \n",
       "Ön eğitim için hangi öğrenme oranı kullanıldı?                                          No information is given about the learning rate.   \n",
       "\n",
       "vendor                                                                                                                                                      openai  \\\n",
       "question                                                                                                                                                             \n",
       "Hangi modeller ticari kullanıma sunuluyor?                                  Llama 2 model is being released to the general public for research and commercial use.   \n",
       "RLHF kullanıldı mı?                             Yes, RLHF (Reinforcement Learning from Human Feedback) was used in the study mentioned in the context information.   \n",
       "kırmızı takım kullanıldı mı?                                                                                                           Yes, the red team was used.   \n",
       "Ön eğitim için hangi öğrenme oranı kullanıldı?                                                            The learning rate used for pretraining is not specified.   \n",
       "\n",
       "vendor                                                                                                                                                                                                                                                                                                                                                                                      vectara  \n",
       "question                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "Hangi modeller ticari kullanıma sunuluyor?                                                                                                                                                                                                                                                                                        Llama 2 and Llama 2-Chat models are available for commercial use.  \n",
       "RLHF kullanıldı mı?                             Yes, RLHF (Reinforcement Learning from Human Feedback) was used in the described research. The authors trained successive versions of RLHF models, referred to as RLHF-V1, RLHF-V2, RLHF-V3, RLHF-V4, and RLHF-V5. They explored RLHF fine-tuning using two main algorithms: Proximal Policy Optimization (PPO) and Rejection Sampling fine-tuning.  \n",
       "kırmızı takım kullanıldı mı?                                                                                                                                                                                                                                                                                                                                            Yes, the red team was used.  \n",
       "Ön eğitim için hangi öğrenme oranı kullanıldı?                                                                                                                                                                                                                                                                                                                                                 10−6  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_per_lang('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52f781bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- OPENAI ---\n",
      "3\n",
      "\n",
      "We are releasing the following models to the general public for research and commercial use‡:\n",
      "\n",
      "1. \n",
      "**\n",
      "2 models and others open-source models.\n",
      "\n",
      "\n",
      "**\n",
      "Lastly, openly releasing these models consolidates costs and eliminates barriers to entry, allowing small businesses to leverage innovations in LLMs to explore and build text-generation use cases. \n",
      "**\n",
      "Progression of Models. \n",
      "**\n",
      "Collaboration will make these models better and safer. \n",
      "--- COHERE ---\n",
      "2 models and others open-source models.\n",
      "\n",
      "\n",
      "**\n",
      "One of the model generations is a Llama 2-Chat model and the other generation is one of the open source or closed source models. \n",
      "**\n",
      "3\n",
      "\n",
      "We are releasing the following models to the general public for research and commercial use‡:\n",
      "\n",
      "1. \n",
      "**\n",
      "Lastly, openly releasing these models consolidates costs and eliminates barriers to entry, allowing small businesses to leverage innovations in LLMs to explore and build text-generation use cases. \n",
      "**\n",
      "(2023), as well as closed-source models (Chat- GPT (OpenAI, 2023) and PaLM Anil et al. \n",
      "--- VECTARA ---\n",
      "We also share novel observations we made during the development of Llama 2 and Llama 2-Chat, such as the emergence of tool usage and temporal organization of knowledge. 3  We are releasing the following models to the general public for research and commercial use‡:  1. Llama 2, an updated version of Llama 1, trained on a new mix of publicly available data.\n",
      "**\n",
      "We also share novel observations we made during the development of Llama 2 and Llama 2-Chat, such as the emergence of tool usage and temporal organization of knowledge. 3  We are releasing the following models to the general public for research and commercial use‡:  1. Llama 2, an updated version of Llama 1, trained on a new mix of publicly available data.\n",
      "**\n",
      "For MPT models, we use the mpt-7b-chat model. For Falcon models, we use the Falcon-40B-Instruct model which is a chat/instruct model. For Vicuna models, we use vicuna-13b-delta-v1.1 and vicuna-33b-delta-v1.3 models from lmsys.\n",
      "**\n",
      "For MPT models, we use the mpt-7b-chat model. For Falcon models, we use the Falcon-40B-Instruct model which is a chat/instruct model. For Vicuna models, we use vicuna-13b-delta-v1.1 and vicuna-33b-delta-v1.3 models from lmsys.\n",
      "**\n",
      "§§  5.3 Responsible Release Strategy  Release Details. We make Llama 2 available for both research and commercial use at https://ai.meta. com/resources/models-and-libraries/llama/.\n"
     ]
    }
   ],
   "source": [
    "query = queries[2]\n",
    "\n",
    "c = get_context(openai_index, query)\n",
    "print(\"--- OPENAI ---\")\n",
    "print('\\n**\\n'.join([t[0] for t in c]))\n",
    "\n",
    "c = get_context(cohere_index, query)\n",
    "print(\"--- COHERE ---\")\n",
    "print('\\n**\\n'.join([t[0] for t in c]))\n",
    "\n",
    "c = get_vectara_context(vectara_index, query)\n",
    "print(\"--- VECTARA ---\")\n",
    "print('\\n**\\n'.join([t.text.replace('\\n', ' ') for t in c.source_nodes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0f9c903",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- OPENAI ---\n",
      "Noam Shazeer. \n",
      "**\n",
      "Noam Shazeer. \n",
      "**\n",
      "Yarden Tal, Inbal Magar, and Roy Schwartz. \n",
      "**\n",
      "Uri Shaham, Elad Segal, Maor Ivgi, Avia Efrat, Ori Yoran, Adi Haviv, Ankit Gupta, Wenhan Xiong, Mor Geva, Jonathan Berant, and Omer Levy. \n",
      "**\n",
      "David Autor and Anna Salomons. \n",
      "--- COHERE ---\n",
      "Uri Shaham, Elad Segal, Maor Ivgi, Avia Efrat, Ori Yoran, Adi Haviv, Ankit Gupta, Wenhan Xiong, Mor Geva, Jonathan Berant, and Omer Levy. \n",
      "**\n",
      "Kilem L. Gwet. \n",
      "**\n",
      "Yarden Tal, Inbal Magar, and Roy Schwartz. \n",
      "**\n",
      "Noam Shazeer. \n",
      "**\n",
      "Noam Shazeer. \n",
      "--- VECTARA ---\n",
      "We also share novel observations we made during the development of Llama 2 and Llama 2-Chat, such as the emergence of tool usage and temporal organization of knowledge. 3  We are releasing the following models to the general public for research and commercial use‡:  1. Llama 2, an updated version of Llama 1, trained on a new mix of publicly available data.\n",
      "**\n",
      "We also share novel observations we made during the development of Llama 2 and Llama 2-Chat, such as the emergence of tool usage and temporal organization of knowledge. 3  We are releasing the following models to the general public for research and commercial use‡:  1. Llama 2, an updated version of Llama 1, trained on a new mix of publicly available data.\n",
      "**\n",
      "Status  This is a static model trained on an offline dataset. Future versions of the tuned models will be released as we improve model safety with community feedback. License  Where to send com- ments  A custom commercial models-and-libraries/llama-downloads/ Instructions on how to provide feedback or comments on the model can be found in the model README, or by opening an issue in the GitHub repository (https://github.com/facebookresearch/llama/).\n",
      "**\n",
      "Status  This is a static model trained on an offline dataset. Future versions of the tuned models will be released as we improve model safety with community feedback. License  Where to send com- ments  A custom commercial models-and-libraries/llama-downloads/ Instructions on how to provide feedback or comments on the model can be found in the model README, or by opening an issue in the GitHub repository (https://github.com/facebookresearch/llama/).\n",
      "**\n",
      "We believe that the decentralization of AI expertise does more than simply distribute knowledge—it stimulates innovation and accelerates progress in the industry. Lastly, openly releasing these models consolidates costs and eliminates barriers to entry, allowing small businesses to leverage innovations in LLMs to explore and build text-generation use cases. Ultimately, we believe this will create a more level playing field for organizations of all sizes across the globe to benefit from the economic growth promised by the advancement of AI.\n"
     ]
    }
   ],
   "source": [
    "query = translate(queries[2], 'iw')\n",
    "\n",
    "c = get_context(openai_index, query)\n",
    "print(\"--- OPENAI ---\")\n",
    "print('\\n**\\n'.join([t[0] for t in c]))\n",
    "\n",
    "c = get_context(cohere_index, query)\n",
    "print(\"--- COHERE ---\")\n",
    "print('\\n**\\n'.join([t[0] for t in c]))\n",
    "\n",
    "c = get_vectara_context(vectara_index, query)\n",
    "print(\"--- VECTARA ---\")\n",
    "print('\\n**\\n'.join([t.text.replace('\\n', ' ') for t in c.source_nodes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fe3f2e9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- OPENAI ---\n",
      "2 models and others open-source models.\n",
      "\n",
      "\n",
      "**\n",
      "If applicable, the model can advise on legal alternatives. \n",
      "**\n",
      "Model cards for model reporting. \n",
      "**\n",
      "3\n",
      "\n",
      "We are releasing the following models to the general public for research and commercial use‡:\n",
      "\n",
      "1. \n",
      "**\n",
      "Progression of Models. \n",
      "--- COHERE ---\n",
      "2 models and others open-source models.\n",
      "\n",
      "\n",
      "**\n",
      "For Vicuna models, we use vicuna-13b-delta-v1.1 and vicuna-33b-delta-v1.3 models from lmsys. \n",
      "**\n",
      "Mirac Suzgun, Nathan Scales, Nathanael Schärli, Sebastian Gehrmann, Yi Tay, Hyung Won Chung, Aakanksha Chowdhery, Quoc V Le, Ed H Chi, Denny Zhou, et al. \n",
      "**\n",
      "For Falcon models, we use the Falcon-40B-Instruct model which is a chat/instruct model. \n",
      "**\n",
      "All model weights were obtained from HuggingFace.\n",
      "\n",
      "\n",
      "--- VECTARA ---\n",
      "We also share novel observations we made during the development of Llama 2 and Llama 2-Chat, such as the emergence of tool usage and temporal organization of knowledge. 3  We are releasing the following models to the general public for research and commercial use‡:  1. Llama 2, an updated version of Llama 1, trained on a new mix of publicly available data.\n",
      "**\n",
      "We also share novel observations we made during the development of Llama 2 and Llama 2-Chat, such as the emergence of tool usage and temporal organization of knowledge. 3  We are releasing the following models to the general public for research and commercial use‡:  1. Llama 2, an updated version of Llama 1, trained on a new mix of publicly available data.\n",
      "**\n",
      "Status  This is a static model trained on an offline dataset. Future versions of the tuned models will be released as we improve model safety with community feedback. License  Where to send com- ments  A custom commercial models-and-libraries/llama-downloads/ Instructions on how to provide feedback or comments on the model can be found in the model README, or by opening an issue in the GitHub repository (https://github.com/facebookresearch/llama/).\n",
      "**\n",
      "Status  This is a static model trained on an offline dataset. Future versions of the tuned models will be released as we improve model safety with community feedback. License  Where to send com- ments  A custom commercial models-and-libraries/llama-downloads/ Instructions on how to provide feedback or comments on the model can be found in the model README, or by opening an issue in the GitHub repository (https://github.com/facebookresearch/llama/).\n",
      "**\n",
      "Llama 2-Chat, a fine-tuned version of Llama 2 that is optimized for dialogue use cases. We release variants of this model with 7B, 13B, and 70B parameters as well. Llama 2-Chat, a fine-tuned version of Llama 2 that is optimized for dialogue use cases.\n"
     ]
    }
   ],
   "source": [
    "query = translate(queries[2], 'tr')\n",
    "\n",
    "c = get_context(openai_index, query)\n",
    "print(\"--- OPENAI ---\")\n",
    "print('\\n**\\n'.join([t[0] for t in c]))\n",
    "\n",
    "c = get_context(cohere_index, query)\n",
    "print(\"--- COHERE ---\")\n",
    "print('\\n**\\n'.join([t[0] for t in c]))\n",
    "\n",
    "c = get_vectara_context(vectara_index, query)\n",
    "print(\"--- VECTARA ---\")\n",
    "print('\\n**\\n'.join([t.text.replace('\\n', ' ') for t in c.source_nodes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a77651f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
