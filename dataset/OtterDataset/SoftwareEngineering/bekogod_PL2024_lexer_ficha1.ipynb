{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# lexer\n",
        "\n",
        "Funções sobre Tokens :\n",
        ".value -> retorna o valor guardado dentro do token\n",
        "\n",
        ".type -> retorna o tipo do token\n",
        "\n",
        ".lineno -> retorna alinha onde o token foi identificado\n",
        "\n",
        ".lexpos -> posição do token, aponta para o primeiro caractere onde houve match\n"
      ],
      "metadata": {
        "id": "uN8oyUmdgk0D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercícios"
      ],
      "metadata": {
        "id": "Voz3CnKDgrNk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício 1\n",
        "\n",
        "1.1 Utilizando o lex do módulo ply crie um reconhecedor capax de tokenizar a seguinte linguagem de expressões :\n",
        "\n",
        "```\n",
        "x=a+1\n",
        "b=2\n",
        "a = b-1\n",
        "a*=2\n",
        "\n",
        "```\n",
        "1.2 Caso um exista um input inválido o reconhecedor deve imprimir uma mensagem de erro com o input inválido, a sua localização e continuar o processamento.\n",
        "\n",
        "1.3 O reconhecedor deve ser capaz de receber input vindo do stdin até o utilizador introduzir \"STOP\".\n",
        "\n",
        "1.4 Sempre que o reconhecedor encontrar uma variavel(numero ou letra) devera imprimir a mensagem \"variavel nome_da_variavel \\n\".\n",
        "\n",
        "1.5 Sempre que o reconhecedor encontrar um operador devera imprimir a mensagem \"operador encontrado\".\n",
        "\n",
        "1.6 Sempre que o reconhecedor encontrar uma mudancança de linha devera imprimir \"\\n\"."
      ],
      "metadata": {
        "id": "m4L_BEDticA1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício 2\n",
        "\n",
        "2.1 Utilizando o lex do módulo ply crie um reconhecedor capax de tokenizar entradas bibliográficas em latex :\n",
        "``` latex\n",
        "@techreport{Camila,\n",
        "  author ={{projecto Camila}},\n",
        "  editor ={L.S. Barbosa and J.J. Almeida and J.N. Oliveira and Luís Neves},\n",
        "  title = \"\\textsc{Camila} - A Platform for Software Mathematical Development\",\n",
        "  url=\"http://camila.di.uminho.pt\",\n",
        "  type=\"(Páginas do projecto)\",\n",
        "  institution = umdi,\n",
        "  year=1998,\n",
        "  keyword = \"FS\",\n",
        "}\n",
        "```\n",
        "2.2 Caso um exista um input inválido o reconhecedor deve imprimir uma mensagem de erro com o input inválido, a sua localização e interromper o processamento.\n",
        "2.2 Construa um dicionário em que a chave são os anos e o valor a contagem do número de vezes que aparecem no ficheiro.\n",
        "\n"
      ],
      "metadata": {
        "id": "XbLo1ysUgwEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "#  Reconhecedor Léxico para BibTeX\n",
        "#\n",
        "\n",
        "import ply.lex as lex\n"
      ],
      "metadata": {
        "id": "5omG8iUGiSn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício 3 - Utilizar states\n",
        "\n",
        "Define um analisador léxico capaz de ler ficheiros em formato JSON e identificar os seus *tokens*.\n",
        "\n",
        "Exemplo de um documento JSON:\n",
        "\n",
        "---\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"name\": \"John Doe\",\n",
        "  \"age\": 21,\n",
        "  \"gender\": \"male\",\n",
        "  \"height\": 1.68,\n",
        "  \"address\": {\n",
        "    \"street\": \"123 Main Street\",\n",
        "    \"city\": \"New York\",\n",
        "    \"country\": \"USA\",\n",
        "    \"zip\": \"10001\"\n",
        "  },\n",
        "  \"married\": false,\n",
        "  \"hobbies\": [\n",
        "    {\n",
        "      \"name\": \"reading\",\n",
        "      \"books\": [\n",
        "        {\n",
        "          \"title\": \"Heartstopper: Volume 1\",\n",
        "          \"author\": \"Alice Oseman\",\n",
        "          \"genres\": [\"Graphic Novels\", \"Romance\", \"Queer\"]\n",
        "        },\n",
        "        {\n",
        "          \"title\": \"1984\",\n",
        "          \"author\": \"George Orwell\",\n",
        "          \"genres\": [\"Science Fiction\", \"Dystopia\", \"Politics\"]\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"gaming\",\n",
        "      \"games\": [\n",
        "        {\n",
        "          \"title\": \"Portal 2\",\n",
        "          \"platform\": [\"PC\", \"PlayStation 3\", \"Xbox 360\"]\n",
        "        },\n",
        "        {\n",
        "          \"title\": \"Synth Riders\",\n",
        "          \"platform\": [\"PSVR\", \"PSVR2\", \"PCVR\", \"Oculus Quest\"]\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "```\n",
        "---"
      ],
      "metadata": {
        "id": "5b1_NgGh2Ck4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Reconhecedor Léxico de JSON\n",
        "#\n",
        "\n",
        "import ply.lex as lex"
      ],
      "metadata": {
        "id": "J54xRL8-iX7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício 4 - Utilizar states\n",
        "\n",
        "Cria um programa em Python que tenha o seguinte comportamento:\n",
        "\n",
        "* Pretende-se um programa que some todas as sequências de dígitos que encontre num texto;\n",
        "* Prepara o programa para ler o texto do canal de entrada: stdin;\n",
        "* Sempre que encontrar a string “Off” em qualquer combinação de maiúsculas e minúsculas, esse comportamento é desligado;\n",
        "* Sempre que encontrar a string “On” em qualquer combinação de maiúsculas e minúsculas, esse comportamento é novamente ligado;\n",
        "* Sempre que encontrar o caráter “=”, o resultado da soma é colocado na saída.\n",
        "\n",
        "Este exercício já foi proposto como TPC, mas agora deves tentar resolvê-lo usando um analisador léxico com condições de contexto."
      ],
      "metadata": {
        "id": "PPOXQCLDO33i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------------------------------------------------\n",
        "# Somador Flip-flop que só soma entre ON e OFF\n",
        "#\n",
        "# somador de números\n",
        "# tokens: on, off, = e \\d+\n",
        "# ------------------------------------------------------------\n",
        "import ply.lex as lex\n",
        "import sys\n",
        "\n"
      ],
      "metadata": {
        "id": "w2zMsP_ch_pY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercício 5. Removedor de Comentários - Utilizar states\n",
        "\n",
        "Desenvolva um analisador léxico capaz de ler um ficheiro de texto e ignorar todo o texto dentro de comentários inline (desde \"//\" até ao fim de linha) e todo o texto\n",
        "dentro de comentários multiline (desde \"/*\" até \"*/\").\n",
        "\n",
        "Note que deve suportar convenientemente comentários dentro de comentários,   conforme exemplificado abaixo:\n",
        "\n",
        "---\n",
        "```bibtex\n",
        "/* comment */ ola1\n",
        "\n",
        "/* comment****comment */ ola2 /*\n",
        "comment\n",
        "comment\n",
        "****/ ola3\n",
        "\n",
        "/*********/\n",
        "\n",
        "ola4\n",
        " mais um pouco // remover comentário inline\n",
        "FIM\n",
        "```\n",
        "----\n"
      ],
      "metadata": {
        "id": "vRpa8dhbYxFy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# Limpa comentários inline e multiline aninhados, de um texto-fonte\n",
        "#\n",
        "\n",
        "import ply.lex as lex\n",
        "import sys\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ggIdWjy-iNEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T6YWg4_0n7W"
      },
      "source": [
        "### Exercício 6 - Utilizar states\n",
        "\n",
        "Define um analisador léxico capaz de ler ficheiros em formato Markdown e identificar os seus *tokens*. O *tokenizer* deve conseguir identificar pelo menos:\n",
        "\n",
        "- cabeçalhos\n",
        "- parágrafos\n",
        "- listas\n",
        "- texto itálico\n",
        "- texto negrito\n",
        "- blocos de código\n",
        "- citações\n",
        "\n",
        "Exemplo de um documento Markdown:\n",
        "\n",
        "---\n",
        "\n",
        "````markdown\n",
        "# This is a heading\n",
        "\n",
        "## This is a subheading\n",
        "\n",
        "This is some **bold** text.\n",
        "\n",
        "This is some *italic* text.\n",
        "\n",
        "- This is a bullet point\n",
        "- This is another bullet point\n",
        "\n",
        "1. This is a numbered list\n",
        "2. This is another numbered list item\n",
        "\n",
        "> This is a blockquote.\n",
        "\n",
        "`This is some inline code.`\n",
        "\n",
        "```python\n",
        "# This is some code block\n",
        "print(\"Hello, world!\")\n",
        "```\n",
        "````\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input maior ex2\n",
        "\n",
        "```\n",
        "@string{ um=\"Universidade do Minho\" }\n",
        "@string{ umdi=\"Universidade do Minho, Departamento de Informática\" }\n",
        "@article{ velharia1,\n",
        "  author = {J.J. Almeida and A. Filipe},\n",
        "  title = {Descrição de um Núcleo Gráfico e Aplicação em {CAD}},\n",
        "  journal = {Revista de Informática},\n",
        "  note = {(KGUM - kernel gráfico U.Minho)},\n",
        "  number = 1,\n",
        "  volume = 6,\n",
        "  year = 1987,\n",
        "}\n",
        "\n",
        "@article{ velharia2,\n",
        "  author = {C. Ferreira and F. Ferreira and F. Martins and  J.J. Almeida and\n",
        "L. Barbosa},\n",
        "  title = {Sistemas de Programação Modular},\n",
        "  journal = {Revista de Informática},\n",
        "  number = 6,\n",
        "  volume = 9,\n",
        "  year = 1988,\n",
        "}\n",
        "\n",
        "@inproceedings{graminteractivas1990,\n",
        "  author={F. Mário Martins and J.J. Almeida and P.R. Henriques},\n",
        "  title = {Mecanismos para Especificação e Prototipagem de Interfaces\n",
        "    Utilizador-Sistema},\n",
        "  note = {(Gramáticas Interactivas guardadas)},\n",
        "  booktitle={3$º$ Encontro Português de Computação Gráfica},\n",
        "  address=\"Coimbra\",\n",
        "  year = 1990,\n",
        "}\n",
        "\n",
        "@techreport{tlc89,\n",
        " author={J.J. Almeida and J.B. Barros},\n",
        " title = {Teoria das Linguagens },\n",
        " institution = umdi,\n",
        " type = \"Texto didáctico\",\n",
        " year = 1988,\n",
        " keyword = \"compiladores\",\n",
        "}\n",
        "\n",
        "@techreport{estruturasdedados90,\n",
        " author={J.B. Barros and J.J. Almeida},\n",
        " title = {Estruturas de Dados},\n",
        " institution = umdi,\n",
        " type = \"Texto didáctico\",\n",
        " year = 1990,\n",
        " keyword = \"algoritmos\",\n",
        "}\n",
        "\n",
        "@techreport{Camila,\n",
        "  author ={{projecto Camila}},\n",
        "  editor ={L.S. Barbosa and J.J. Almeida and J.N. Oliveira and Luís Neves},\n",
        "  title = \"\\textsc{Camila} - A Platform for Software Mathematical Development\",\n",
        "  url=\"http://camila.di.uminho.pt\",\n",
        "  type=\"(Páginas do projecto)\",\n",
        "  institution = umdi,\n",
        "  year=1998,\n",
        "  keyword = \"FS\",\n",
        "}\n",
        "\n",
        "@techreport{Natura,\n",
        "  author ={J.J. Almeida},\n",
        "  title = \"{Natura} - Natural language processing\",\n",
        "  url=\"http://natura.di.uminho.pt/\",\n",
        "  type=\"(Páginas do projecto)\",\n",
        "  note=\"\\url{http://natura.di.uminho.pt/}\",\n",
        "  institution = umdi,\n",
        "  keyword = \"PLN\",\n",
        "  year = 1997,\n",
        "}\n",
        "\n",
        "@techreport{PDavid,\n",
        "  author = \"{projecto David}\",\n",
        "  editor ={J.C. Ramalho and J.J. Almeida and P.R. Henriques},\n",
        "  title = \"David -- Processamento estruturado de documentos\",\n",
        "  url=\"http://www.di.uminho.pt/~jcr/projectos/david/princ.html\",\n",
        "  note=\"\\url{http://www.di.uminho.pt/~jcr/projectos/david/princ.html}\",\n",
        "  type=\"(Páginas do projecto)\",\n",
        "  institution = umdi,\n",
        "  keyword = \"FS,SGML\",\n",
        "  year = 1998,\n",
        "}\n",
        "\n",
        "@misc{nllex,\n",
        "  type={tool},\n",
        "  author ={J.J. Almeida},\n",
        "  title = \"NLlex -- Natural Language LEX\",\n",
        "  url=\"http://natura.di.uminho.pt/~jj/pln/pln.html#nllex\",\n",
        "  keyword = \"lexical analysis, Natura,lex\",\n",
        "  year = 1996,\n",
        "}\n",
        "\n",
        "@misc{jspell,\n",
        "  type = {tool},\n",
        "  author ={J.J. Almeida and Ulisses Pinto},\n",
        "  title = \"Jspell a module for morphological analyser for natural language\",\n",
        "  url=\"http://natura.di.uminho.pt/~jj/pln/pln.html#jspell\",\n",
        "  keyword = \"lexical analysis, Natura,morphology\",\n",
        "  year = 1997,\n",
        "}\n",
        "\n",
        "@techreport{jspell1,\n",
        "   author = \"J.J. Almeida and Ulisses Pinto\",\n",
        "   title = \"Manual de Utilizador do {JSpell}\",\n",
        "   year = 1994,\n",
        "   type = \"Manual\",\n",
        "   month = \"Jul\",\n",
        "   institution = umdi,\n",
        "   keyword = \"morphology, lexical analysis,jspell\",\n",
        "   abstract = {},\n",
        "   url = \"http://natura.di.uminho.pt/~jj/pln/jspellman.ps.gz\",\n",
        "}\n",
        "\n",
        "@inproceedings{Almeida94b,\n",
        "   author = \"J.J. Almeida\",\n",
        "   title = \"{GPC} -- a Tool for higher-order grammar specification\",\n",
        "   booktitle = \"Actas del X Congreso de Lenguajes Naturales e Leanguajes Formales, Sevilla\",\n",
        "   year = 1994,\n",
        "   url = \"http://natura.di.uminho.pt/~jj/pln/yalg3.ps.gz\",\n",
        "   editor=\"Carlos Martin Vide\",\n",
        " keyword =\"DCG,grammar\",\n",
        "}\n",
        "\n",
        "@inproceedings{Almeida95a,\n",
        "   author = \"J.J. Almeida\",\n",
        "   title = \"{YaLG} -- extending {DCG} for natural language processing\",\n",
        "   booktitle = \"Actas del XI Congreso de Lenguajes Naturales e Leanguajes Formales, Tortosa\",\n",
        "   year = 1995,\n",
        "   pages = \"621--628\",\n",
        "   editor=\"Carlos Martin Vide\",\n",
        "   url = \"http://natura.di.uminho.pt/~jj/pln/yalg.ps.gz\",\n",
        " keyword =\"jspell,morphology,PLN,DCG,nllex\",\n",
        "}\n",
        "\n",
        "@inproceedings{Almeida94c,\n",
        "   author = \"J.J. Almeida and Ulisses Pinto\",\n",
        "   title = \"Jspell -- um módulo para análise léxica genérica de linguagem natural\",\n",
        "   booktitle = \"Actas do X Encontro da Associação Portuguesa de Linguística\",\n",
        " address={Évora 1994},\n",
        "   pages = \"1--15\",\n",
        "   year = 1995,\n",
        "   url = \"http://natura.di.uminho.pt/~jj/pln/jspell1.ps.gz\",\n",
        " keyword =\"jspell,morphology,PLN,perl\",\n",
        "}\n",
        "\n",
        "@inproceedings{Almeida94a,\n",
        "   author = \"J.J. Almeida\",\n",
        "   title = \"Documents in an Informatic Academic environment\",\n",
        "   booktitle = \"Congresso Nacional de Bibliotecários, Arquivistas e\n",
        "Documentalistas\",\n",
        "   address = \"Lisboa\",\n",
        "   year = 1994,\n",
        " keyword =\"librarian studies,WWW,WAIS,IR\",\n",
        "}\n",
        "\n",
        "@techreport{jj95,\n",
        "   author = \"J.J. Almeida\",\n",
        "   title = \"{NLlex} -- a tool to generate lexical analysers for natural language\",\n",
        "   institution = umdi,\n",
        "   year   = 1995,\n",
        "   number = \"UM-DI-95.04\",\n",
        "   url = \"http://natura.di.uminho.pt/~jj/pln/nllex.ps.gz\",\n",
        " keyword =\"jspell,morphology,lex,PLN,nllex\",\n",
        "}\n",
        "\n",
        "@techreport{Barbosa95,\n",
        " author = \"L.S. Barbosa and J.J. Almeida\",\n",
        " title  = \"System Prototyping in \\textsc{Camila}\",\n",
        " year = 1995,\n",
        " number = \"DI-CAM-95:11:1\",\n",
        " institution=\"University of Minho\",\n",
        " note = \"Lecture notes for the System Design Course,\n",
        "         Computer System Engineering, University of Bristol\",\n",
        " url=\"http://www.di.uminho.pt/~lsb/pub_camila/LNcam.ps.gz\",\n",
        " keyword =\"Camila, formal specification\",\n",
        "}\n",
        "\n",
        "@techreport{Barbosa95a,\n",
        " author = \"L.S. Barbosa and J.J. Almeida\",\n",
        " title  = \"\\textsc{Camila}: A reference Manual\",\n",
        " year = 1995,\n",
        " number = \"DI-CAM-95:11:2\",\n",
        " institution=\"University of Minho\",\n",
        " url=\"http://www.di.uminho.pt/~lsb/pub_camila/RMcam.ps.gz\",\n",
        " keyword =\"Camila\",\n",
        "}\n",
        "\n",
        "@techreport{BA97a,\n",
        "  keyword = \"Formal Methods, Prototyping, Camila\",\n",
        "  author = \"L.S. Barbosa and J.J. Almeida\",\n",
        "  title = \"Systems Prototyping in \\textsc{Camila}\",\n",
        "  type = \"{Lecture Notes for the Bristol Course  (1st ed.  1995)}\",\n",
        "  year = 1998,\n",
        "  institution = \"DI (U. Minho)\",\n",
        "  number = \"DI-CAM-95:11:1:v98\"\n",
        "  }\n",
        "\n",
        "@techreport{Barbosa95b,\n",
        "   author = \"L.S. Barbosa and J.J. Almeida\",\n",
        "   title = \"Growing Up With \\textsc{Camila}\",\n",
        "   institution =   umdi,\n",
        "   year   = 1995,\n",
        "   number = \"DI-CAM-95:7:1\",\n",
        "   url = \"http://www.di.uminho.pt/~lsb/pub_camila/romantic.ps.gz\",\n",
        " keyword =\"Camila, formal specification, didatics\",\n",
        "}\n",
        "\n",
        "@inproceedings{Ramalho95,\n",
        "   author = \"J.C. Ramalho and J.J. Almeida and P.R. Henriques\",\n",
        "   title = \"Algebraic Specification of Documents\",\n",
        "   booktitle = \"TWLT10 - Algebraic Methods in Language Processing\",\n",
        "   year = 1995,\n",
        "   month = \"6--8 Dec.\",\n",
        "   editor = \"A. Nijholt and G. Scollo and R. Steetskamp\",\n",
        "   address = \"Twente University, Netherlands\",\n",
        "   note = \"AMiLP'95\",\n",
        "   series = \"Twente Workshop on Language Technology\",\n",
        "   url=\"http://natura.di.uminho.pt/~jj/bib/amilp95.ps.gz\",\n",
        "   docpage=\"http://www.di.uminho.pt/~jcr/projectos/david/ARTIGOS/AMiLP95/amilp95.html\",\n",
        "   pages = \"55--64\",\n",
        "   keyword =\"PDavid, Camila, SGML\",\n",
        "}\n",
        "\n",
        "@inproceedings{Almeida96a,\n",
        "   author = \"J.J. Almeida\",\n",
        "   title = \"Especificação e tratamento de Dicionários\",\n",
        "   booktitle = \"Actas do XI Encontro da Associação Portuguesa de Linguística\",\n",
        "   address={Lisboa 1995},\n",
        "   year = 1996,\n",
        "   volume=2,\n",
        "   url = \"http://natura.di.uminho.pt/~jj/pln/etdic.ps.gz\",\n",
        "   keyword =\"perl,morphology,lexical analysis, dictionary\",\n",
        "}\n",
        "\n",
        "@inproceedings{Ulisses96,\n",
        "   author = \"Ulisses Pinto and J.J. Almeida\",\n",
        "   title = \"Tratamento automático de termos compostos\",\n",
        "   booktitle = \"Actas do XI Encontro da Associação Portuguesa de Linguística\",\n",
        "   address= \"Lisboa 1995\",\n",
        "   volume=2,\n",
        "   year = 1996,\n",
        "   url = \"http://natura.di.uminho.pt/~jj/pln/ptc.ps.gz\",\n",
        "   keyword = \"jspell,morphology,lexical analysis, PLN\",\n",
        "}\n",
        "\n",
        "@inproceedings{Almeida96b,\n",
        "   author = \"J.J. Almeida and J.B. Barros\",\n",
        "   title = \"{YaLG} a tool for higher-order grammar specification\",\n",
        "   booktitle = \" II International Conference on Mathematical Linguistics, Tarragona, Spain\",\n",
        "   year = 1996,\n",
        "   url=\"http://natura.di.uminho.pt/~jj/pln/yalg2.ps.gz\",\n",
        "   keyword =\"yalg,DCG,RS\",\n",
        "}\n",
        "\n",
        "@article{jj96,\n",
        "   author = \"J.J. Almeida\",\n",
        "   title = \"{NLlex} -- a tool to generate lexical analysers for natural language\",\n",
        "   year   = 1996,\n",
        "   month = \"Sep\",\n",
        "   volume = \"19\",\n",
        "   pages = \"81--90\",\n",
        "  journal =    {Procesamiento del Lenguaje Natural},\n",
        "   publisher=\"Sociedade Española para el Procesamiento del Lenguaje Natural\",\n",
        "   keyword =\"jspell,morphology,lex,PLN,nllex\",\n",
        "   url= \"http://natura.di.uminho.pt/~jj/pln/nllex2.ps.gz\",\n",
        "}\n",
        "\n",
        "@techreport{Almeida96c,\n",
        "   author = \"J.J. Almeida and J.C. Ramalho\",\n",
        "   title = \"From {BiBTeX} to {HTML} semantic nets\",\n",
        "   institution =   umdi,\n",
        "   year   = 1996,\n",
        "   number = \"DI-DAV-96:1:1\",\n",
        "   docpage = \"http://natura.di.uminho.pt/~jcr/bib/dbib.html\",\n",
        " keyword =\"PDavid, bibtex, librarian studies,html\",\n",
        "}\n",
        "\n",
        "@inproceedings{Ramalho96,\n",
        "  author = \"J.C. Ramalho and J.J. Almeida and P.R. Henriques\",\n",
        "  title = \"Document Semantics: two approaches\",\n",
        "  booktitle = \"Celebrating a Decade of SGML\",\n",
        "  year = 1996,\n",
        "  month = \"Nov.\",\n",
        "  address = \"Boston, USA\",\n",
        "  note = \"SGML'96 Conference\",\n",
        "  editor = \"Graphic Communications Association\",\n",
        "  publisher = \"ArborText\",\n",
        "  pages = \"473--483\",\n",
        " docpage=\"http://natura.di.uminho.pt/~jcr/projectos/david/COMS/sgml96/sgml96.html\",\n",
        "  keyword =\"PDavid, Camila, SGML,AG,FS\",\n",
        "}\n",
        "\n",
        "@InProceedings{SGML97,\n",
        "  author = \"J.C. Ramalho and J.G. Rocha and J.J. Almeida and P.R. Henriques\",\n",
        "  title = \"SGML Documents: where does quality go?\",\n",
        "  booktitle = \"SGML/XML'97 Conference\",\n",
        "  year =  1997,\n",
        "  address = \"Washington D.C. - USA\",\n",
        "  month =  \"Dec.\",\n",
        "  keyword = \"PDavid, SGML, Semantics\",\n",
        "}\n",
        "\n",
        "@inproceedings{Almeida98,\n",
        "   author = \"J.J. Almeida\",\n",
        "   title = \"Programação de dicionários\",\n",
        "   booktitle= \"Actas do XIII Encontro da Associação Portuguesa de Linguística\",\n",
        "   year=1998,\n",
        "   pages=\"21--28\",\n",
        "   volume= \"1\",\n",
        "   address = \"Lisboa 1997\",\n",
        "   keyword =\"perl,morphology,dictionary,parser\",\n",
        "   url= \"http://natura.di.uminho.pt/~jj/bib/progDic.ps.gz\",\n",
        "}\n",
        "\n",
        "@inproceedings{Reis98,\n",
        "   author = \"Ricardo Reis and J.J. Almeida\",\n",
        "   title = \"Etiquetador morfo-sintáctico para o Português\",\n",
        "   booktitle= \"Actas do XIII Encontro da Associação Portuguesa de Linguística\",\n",
        "   address = \"Lisboa 1997\",\n",
        "   year=1998,\n",
        "   keyword =\"tagger, PLN\",\n",
        "   url= \"http://natura.di.uminho.pt/~jj/bib/etiquetador2.ps.gz\",\n",
        "}\n",
        "\n",
        "@inproceedings{ABNO97a,\n",
        "   title = \"\\textsc{Camila}: Formal Software Engineering Supported by Functional Programming\",\n",
        "   author = \"J.J. Almeida and Barbosa, L.S. and Neves, F.L. and Oliveira, J.N.\",\n",
        "   booktitle = \"Proc. II Conf. Latino Americana de Programaci\\'on Funcional ({CLaPF97})\",\n",
        "   editor = \"De Giusti, A. and Diaz, J. and Pesado, P.\",\n",
        "   year = 1997,\n",
        "   month = \"October\",\n",
        "   address = \"La Plata, Argentina\",\n",
        "   pages = \"1343--1358\",\n",
        "   keyword =\"Camila, formal specification\",\n",
        "   url = \"http://camila.di.uminho.pt/camila-doc/CLaPF97.ps.gz\",\n",
        "}\n",
        "\n",
        "@inproceedings{ABNO97b,\n",
        "   title = \"\\textsc{Camila}: Prototyping and Refinement of Constructive Specifications\",\n",
        "   author = \"J.J. Almeida and Barbosa, L.S. and Neves, F.L. and Oliveira, J.N.\",\n",
        "   booktitle = \"6th International Conference on Algebraic Methods and Software Technology ({AMAST'97})\",\n",
        "   editor = \"Johnson, M.\",\n",
        "   year = 1997,\n",
        "   month = \"December\",\n",
        "   address = \"Sydney, Australia\",\n",
        "   publisher = \"Springer Lect. Notes Comp. Sci. (1349)\",\n",
        "   pages = \"554--559\",\n",
        "   keyword =\"Camila, formal specification\",\n",
        "}\n",
        "\n",
        "\n",
        "@inproceedings{AH97,\n",
        "   title = \"Dynamic Dictionary = cooperative information sources\",\n",
        "   author = \"J.J. Almeida and P.R. Henriques\",\n",
        "   year = 1998,\n",
        "   address = \"Australia\",\n",
        "   url = \"http://natura.di.uminho.pt/~jj/bib/agentes97.ps.gz\",\n",
        "   keyword =\"dictionary, Agentes\",\n",
        "   booktitle = \"Proc. II Conference on Knowledge-based Intelligent Electronic Systems ({Kes98})\",\n",
        "   month = \"April\",\n",
        "}\n",
        "\n",
        "@inproceedings{museums98,\n",
        " author={J.G. Rocha and M.R. Henriques and J.C. Ramalho and J.J. Almeida\n",
        "    and J.L.  Faria and P.R. Henriques},\n",
        " title={Adapting Museum Structures for the Web: No Changes Needed!},\n",
        " booktitle = \"Museums and the Web 1998\",\n",
        " note = \"Toronto - Canadá\",\n",
        " year= 1998,\n",
        "}\n",
        "\n",
        "@inproceedings{ABBN98,\n",
        "   author = \"Almeida, J.J. and Barbosa, L.S. and Barros, J.B. and\n",
        "             Neves, L.F.\",\n",
        "   title = \"On The Development of \\textsc{Camila}\",\n",
        "   booktitle = \"Workshop on Research Themes on Functional Programming\",\n",
        "   year = 1998,\n",
        "   month = \"18 Sep.\",\n",
        "   editor = \"L.S. Barbosa and J.A. Saraiva\",\n",
        "   publisher = \"Proc. 3rd Summer School on Advan. Funct. Prog., Braga\"\n",
        "}\n",
        "\n",
        "@article{Ramalho98,\n",
        "   author = \"J.C. Ramalho and J.J. Almeida and P.R. Henriques\",\n",
        "   title = \"Algebraic specification of documents\",\n",
        "   year = 1998,\n",
        "   volume = \"199\",\n",
        "   pages = \"231--247\",\n",
        "   journal = \"Theoretical Computer Science\",\n",
        "   url=\"http://natura.di.uminho.pt/~jj/bib/amilp95.ps.gz\",\n",
        "   docpage=\"http://www.di.uminho.pt/~jcr/projectos/david/ARTIGOS/AMiLP95/amilp95.html\",\n",
        "   keyword =\"PDavid, Camila, SGML\",\n",
        "}\n",
        "\n",
        "@inproceedings{Gis99,\n",
        "  author = \"Jorge Rocha and Ana Silva and Ricardo Henriques and J.J. Almeida and Pedro Henriques\",\n",
        "  title={Formal Methods for {GI} Systems Development},\n",
        "  booktitle = \"Conferência da Association of Geographic Information\n",
        "Laboratories for Europe (AGILE)\",\n",
        "  address=\"Roma\",\n",
        "  year=1999,\n",
        " keyword=\"GIS\",\n",
        "}\n",
        "\n",
        "@inproceedings{RPA99,\n",
        "  author={Jorge Rocha and Tiago Pedroso and J.J. Almeida},\n",
        "  title ={{MAPit} - A tool set for automatically generation of {HTML} Maps},\n",
        "  booktitle = \"Conferência da Association of Geographic Information\n",
        "Laboratories for Europe (AGILE)\",\n",
        "  address=\"Roma\",\n",
        "  year=1999,\n",
        " keyword=\"GIS, XML, mapit\",\n",
        "}\n",
        "\n",
        "@inproceedings{RSea99,\n",
        "  author = {Jorge Gustavo Rocha and Ana Silva and J.J. Almeida and Mario Ricardo Henriques and Pedro Rangel Henriques},\n",
        "  title= {Sobre a Utilização de Metodologias Formais no Desenvolvimento de\n",
        "{SIG}},\n",
        "  booktitle = {GISBRASIL'99, Salvador},\n",
        "  year=1999,\n",
        " keyword=\"GIS\",\n",
        "}\n",
        "\n",
        "@inproceedings{xmldt99,\n",
        "  author = { J.J. Almeida and José Carlos Ramalho},\n",
        "  title = {{XML::DT} a Perl Down-Translation module},\n",
        "  booktitle = \"XML-Europe'99, Granada - Espanha\",\n",
        "  month = \"May\",\n",
        "  year=  1999,\n",
        " keyword=\"XML, perl\",\n",
        "}\n",
        "\n",
        "@article{RRAH99,\n",
        " author={J.C. Ramalho and J.G. Rocha and J.J. Almeida and P.R. Henriques},\n",
        " title = {SGML documents: Where does quality go?},\n",
        " journal={Markup Languages: theory and practice},\n",
        " Volume =\"1\",\n",
        " pages = \"75--90\",\n",
        " publisher=\"MIT Press\",\n",
        " year= 1999,\n",
        " keyword=\"SGML\",\n",
        "}\n",
        "\n",
        "@inproceedings{Barbosa2000,\n",
        "   author = \"L.S. Barbosa and J.B. Barros and J.J. Almeida\",\n",
        "   title = \"Polytypic Recursion Patterns\",\n",
        "   year = 2000,\n",
        "   month = \"May\",\n",
        "   booktitle = \"{SBLP'2000} (to appear as a ENTCS volume)\",\n",
        "   address = \"{UFP}, Recife, Brasil\",\n",
        "   keyword=\"FS, Camila\",\n",
        "}\n",
        "\n",
        "@inproceedings{jj2001x,\n",
        "   author = \"J.J. Almeida\",\n",
        "   title = \"Smallbook -- comando para produção de livros em pequena escala\",\n",
        "   year = 2000,\n",
        "   pages = \"445--450\",\n",
        "   booktitle = \"Actas da II Conferência Internacional de Tecnologias de\n",
        "Informação e Comunicação na Educação\",\n",
        "   address=\"Braga\",\n",
        "   keyword=\"publishing, latex, smallbook\",\n",
        "}\n",
        "\n",
        "@article{speaker:sepln2001,\n",
        " author={J.J. Almeida and A. M. Simões},\n",
        " title = {Text to speech -- a rewriting system approach},\n",
        "  journal =    {Procesamiento del Lenguaje Natural},\n",
        " address=\"Sevilha\",\n",
        " volume =\"27\",\n",
        " pages = \"247--255\",\n",
        " publisher=\"Sociedade Española para el Procesamiento del Lenguaje Natural\",\n",
        " month=\"Sep.\",\n",
        " year= 2001,\n",
        " keyword=\"TTS,RS,fonética\",\n",
        "}\n",
        "\n",
        "@inproceedings{mp2001,\n",
        " author= {J.J. Almeida and  J. Gustavo Rocha and  P. Rangel Henriques and\n",
        "    Sónia Moreira and Alberto Simões},\n",
        " title = {{Museu da Pessoa} -- Arquitectura} ,\n",
        " booktitle = {Congresso Nacional de Bibliotecários, Arquivistas e\n",
        "    Documentalistas},\n",
        " address = {Porto},\n",
        " url = \"http://natura.di.uminho.pt/~jj/bib/museuDaPessoa2001.ps.gz\",\n",
        " month = \"Maio\",\n",
        " year= 2001,\n",
        "}\n",
        "\n",
        "@inproceedings{alfarrabio2001,\n",
        " author= {J.J. Almeida and P. Rangel Henriques and J. Gustavo Rocha and  \n",
        "    Alberto Simões},\n",
        " title = {Alfarrábio: Adding value to an Heterogeneous Site Collection} ,\n",
        " booktitle = {Congresso Nacional de Bibliotecários, Arquivistas e\n",
        "    Documentalistas},\n",
        " address = {Porto},\n",
        " url = \"http://natura.di.uminho.pt/~jj/bib/alfarrabio2001.ps.gz\",\n",
        " month = \"Maio\",\n",
        " year= 2001,\n",
        "}\n",
        "\n",
        "@inproceedings{freq2002,\n",
        " author= {Paulo A. Rocha and Alberto M. Simões and J.J. Almeida},\n",
        " title={ Cálculo de frequências de\n",
        "palavras para entradas de dicionários através do uso conjunto de analisadores\n",
        "morfológicos, taggers e corpora},\n",
        " booktitle={Actas do XVII Encontro da Associação Portuguesa de Linguística},\n",
        " address={Lisboa 2001},\n",
        " pages=\"407--418\",\n",
        " year= 2002,\n",
        " url =\"http://natura.di.uminho.pt/~jj/bib/apl:freqnormpt.ps.gz\",\n",
        " abstract = {Apresentamos neste documento uma possível abordagem à\n",
        "                extracção de frequências de palavras a partir de\n",
        "                corpora, baseada numa utilização cooperativa de várias\n",
        "                ferramentas de Processamento de Linguagem Natural.},\n",
        "}\n",
        "\n",
        "@inproceedings{jspell2002,\n",
        " author= {Alberto M. Simões and J.J. Almeida},\n",
        " title={ Jspell.pm -- um módulo de análise morfológica\n",
        "para uso em processamento de linguagem natural},\n",
        " booktitle={Actas do XVII Encontro da Associação Portuguesa de Linguística},\n",
        " address={Lisboa 2001},\n",
        " pages=\"485--495\",\n",
        " abstract = {Neste documento é nosso propósito apresentar as\n",
        "                características presentes no analisador morfológico\n",
        "                jspell e quais as suas consequências ao nível de\n",
        "                aplicações de processamento de linguagem natural. Como\n",
        "                ferramenta que é frequentemente integrada em software\n",
        "                mais específico, apresentamos um módulo Perl\n",
        "                desenvolvido com o objectivo de facilitar a interligação\n",
        "                do analisador morfológico com pequenas aplicações\n",
        "                desenvolvidas em linguagens de scripting. Devido à\n",
        "                constante necessidade de melhoramento de dicionários, e\n",
        "                em particular dos analisadores morfológicos, discutimos\n",
        "                as propriedades que estes devem conter para facilitar o\n",
        "                seu processamento e enriquecimento automático.},\n",
        " year= 2002,\n",
        "}\n",
        "\n",
        "@inproceedings{dag2002,\n",
        " author= {Alberto M. Simões and J.J. Almeida and Pedro R. Henriques},\n",
        " title={Directory Attribute Grammars},\n",
        " booktitle={VI Simpósio Brasileiro de Linguagens de Programação},\n",
        " pages = {297--308},\n",
        " address = {Rio de Janeiro, Brasil},\n",
        " year= 2002,\n",
        "}\n",
        "\n",
        "@inproceedings{elpub2002,\n",
        " author= {Alberto M. Simões and J.J. Almeida},\n",
        " title={Library::* -- a toolkit for digital libraries},\n",
        " booktitle={Elpub 2002 -- International Conference on Electronic Publishing},\n",
        " address = {Karlov Vary, República Checa},\n",
        " month=\"Nov.\",\n",
        " pages = {203--211},\n",
        " year= 2002,\n",
        " isbn = \"3-89700-357-0\",\n",
        " abstract = {\n",
        "  In last years the amount of digital documents has increased\n",
        "  dramatically. Unfortunately the same did not occur with the\n",
        "  structure and organization of the information. Traditionally we\n",
        "  built a digital library using a catalog with documents'\n",
        "  meta-information including a conceptual classification and an\n",
        "  ontology of concepts.\n",
        "  \n",
        "  In this document we present a set of modules to help in the task of\n",
        "  building and maintaining a digital library. It includes a module to\n",
        "  work with ontologies, a set of modules to handle specific catalog\n",
        "  formats (like Bib\\TeX), a module to define new catalog formats\n",
        "  and a tool to integrate ontologies and multi-format\n",
        "  catalogs in a web browse-able knowledge-base.\n",
        " }\n",
        "}\n",
        "\n",
        "@article{parguess2002,\n",
        " author= {J.J. Almeida and Alberto M. Simões and J. Alves de Castro},\n",
        " title={Grabbing parallel corpora from the web},\n",
        " publisher=\"Sociedade Española para el Procesamiento del Lenguaje Natural\",\n",
        "  journal =    {Procesamiento del Lenguaje Natural},\n",
        " volume =\"29\",\n",
        " pages = \"13--20\",\n",
        " month=\"Sep.\",\n",
        " year= 2002,\n",
        "  abstract = {\n",
        "  Multilingual resources  are useful for linguistic studies, translation,\n",
        "and many other tasks. Unfortunately, these resources are difficult to obtain\n",
        "and organize.\n",
        "  In this document we describe a set of tools designed to help in the\n",
        "task of mining bilingual resources from the web, from a specific site,\n",
        "from a file system, from a list of URLs, or from a translation memory.\n",
        "  As a design goal we intend to build tools that can be used both\n",
        "cooperatively (in pipeline)  and also in a independent way.  }\n",
        "}\n",
        "\n",
        "@Article{cP,\n",
        "  author = \"Alberto Manuel Simões\",\n",
        "  title = \"Cooking Perl with flex\",\n",
        "  journal = \"The Perl Review\",\n",
        "  year = \"2002\",\n",
        "  volume = \"0\",\n",
        "  number = \"3\",\n",
        "  month = \"May\",\n",
        "  abstract = {\n",
        "\n",
        "     There are a lot of tools for parser generation using Perl. As we\n",
        "     know, Perl has flexible data structures which makes it easy to\n",
        "     generate generic trees. While it is easy to write a grammar and a\n",
        "     lexical analyzer using modules like \\texttt{Parse::Yapp} and\n",
        "     \\texttt{Parse::Lex}, this pair of tools is not as efficient as I\n",
        "     would like. In this document I'll present a way to cook quickly\n",
        "     \\texttt{Parse::Yapp} with the better lexical analyzer I know:\n",
        "     \\texttt{flex}.\n",
        "  }\n",
        "}\n",
        "@InProceedings{APL2k2.Parguess,\n",
        "  author = \"J.J. Almeida and Alberto Manuel Simões and José Alves Castro\",\n",
        "  title     = \"Extracção de corpora paralelo a partir da web: construção e\n",
        "disponibilização\",\n",
        "  booktitle={Actas do XVIII Encontro da Associação Portuguesa de Linguística},\n",
        " address={Porto 2002},\n",
        "  year      = \"2003\",\n",
        "  lang      = \"PT\",\n",
        "  url       = {http://alfarrabio.di.uminho.pt/~albie/publications/APL2k2.Parguess.pdf},\n",
        "  abstract  = {\n",
        "   Ao longo deste documento descrever-se-á um conjunto de ferramentas\n",
        "   construídas para extracção automática de recursos bilingues a partir\n",
        "   da Web, a partir de um \\emph{site} específico, a partir de um\n",
        "   sistema de ficheiros contendo alguns textos que sejam traduções de outros,\n",
        "   ou ainda a partir de memórias de tradução.\n",
        "\n",
        "   Neste trabalho apresenta-se todo o processo de construção de corpora\n",
        "   paralelo desde os algoritmos de minagem dos dados (data mining) até à\n",
        "   construção de vários tipos de recursos bilingues incluindo a construção\n",
        "   automática de corpus paralelos pesquisáveis na Internet.\n",
        "  }\n",
        "}\n",
        "\n",
        "@InProceedings{APL2k2.Synthesis,\n",
        "  author = \"J.J. Almeida and Alberto Manuel Simões\",\n",
        "  title     = \"Geração de voz com sotaque\",\n",
        "  booktitle={Actas do XVIII Encontro da Associação Portuguesa de Linguística},\n",
        "  address={Porto 2002},\n",
        "  year      = \"2003\",\n",
        "  url       = {http://alfarrabio.di.uminho.pt/~albie/publications/APL2k2.Synthesis.pdf},\n",
        "  lang      = \"PT\",\n",
        "  abstract  = {\n",
        "   Como é sabido os sotaques podem estar ligados a uma zona geográfica,\n",
        "   a um grupo social, podem até ser uma característica pessoal.  O seu\n",
        "   estudo e descrição tem interessado muitos investigadores embora\n",
        "   normalmente esse estudo tem sido feito de modo pouco formal.\n",
        "\n",
        "   No trabalho que aqui se relata, tentou-se descrever formalmente\n",
        "   sotaques e disfunções através de criação de regras a integrar como\n",
        "   variantes num gerador de voz.  Deste modo, pretendeu-se criar um\n",
        "   ambiente de experimentação dos modelos construídos para descrever\n",
        "   algumas características de certos sotaques ou certas disfunções, de\n",
        "   modo a permitir a sua validação.\n",
        "\n",
        "   Constatou-se que se consegue obter certas disfunções e certos\n",
        "   sotaques com facilidade por simples acrescento de regras opcionais\n",
        "   em certas fases da geração da voz. Outros, aparentam ser de maior\n",
        "   dificuldade, ou por não conhecermos suficiente bem os fenómenos\n",
        "   neles envolvidos ou envolverem maior complexidade prosódica.\n",
        "  },\n",
        "}\n",
        "\n",
        "@InProceedings{xata:xmldt,\n",
        "  author    = \"J.J. Almeida and Alberto Manuel Simões\",\n",
        "  title     = \"Engenharia reversa de {HTML} usando tecnologia {XML}\",\n",
        "  booktitle = \"{XATA --- XML}, Aplicações e Tecnologias Associadas\",\n",
        "  year      = \"2003\",\n",
        "  url =\n",
        "{http://alfarrabio.di.uminho.pt/~albie/publications/xata2003xml.pdf},\n",
        "  lang      = \"PT\",\n",
        "  abstract  = { O proliferar de ferramentas criadores de HTML e o uso\n",
        "                  de HTML guiado pelo aspecto, tem vindo a arruinar o\n",
        "                  seu lado conceptual. Este problema foi reconhecido e\n",
        "                  deu origem a vários formatos ou tecnologias com o\n",
        "                  objectivo de separar o aspecto do conceito.  No\n",
        "                  entanto a realidade actual mostra uma enorme\n",
        "                  quantidade de páginas HTML com péssima leitura\n",
        "                  conceptual e estrutural, invalidando uma série de\n",
        "                  usos possíveis da informação nelas contida.  Nesta\n",
        "                  comunicação apresenta-se um trabalho (em fase\n",
        "                  inicial) que pretende fazer engenharia reversa de\n",
        "                  HTML para permitir aumentar a sua acessibilidade, a\n",
        "                  fim de ser usada num \\emph{browser} para invisuais.\n",
        "                  },\n",
        "  irreditor =\"José Carlos Ramalho\",\n",
        "}\n",
        "\n",
        "@InProceedings{xata:museudapessoa,\n",
        "  author = \"Alberto Manuel Simões and J.J. Almeida\",\n",
        "  title     = {{H}istórias de {V}ida + {P}rocessamento {E}strutural = {M}useu\n",
        "da {P}essoa},\n",
        "  booktitle = \"{XATA --- XML}, Aplicações e Tecnologias Associadas\",\n",
        "  year      = \"2003\",\n",
        "  lang      = \"PT\",\n",
        "  abstract  = {\n",
        "   Este artigo apresenta a arquitectura actual do Museu da Pessoa,\n",
        "   contemplando a forma como os documentos estão a ser editador,\n",
        "   catalogados, arquivados, e processados para a criação das estruturas\n",
        "   necessárias ao Museu.\n",
        "},\n",
        "url = {http://alfarrabio.di.uminho.pt/~albie/publications/xata2003mp.pdf},\n",
        "  editor =\"José Carlos Ramalho\",\n",
        "}\n",
        "\n",
        "@InProceedings{elpub2003,\n",
        "  author = \"Alberto Manuel Simões and J.J. Almeida\",\n",
        "  year= 2003,\n",
        "  title= \"Music publishing\",\n",
        "  isbn = \"972-98921-2-1\",\n",
        "  note = {Guimarães},\n",
        "  publisher = \"Universidade do Minho\",\n",
        "  url = {http://alfarrabio.di.uminho.pt/~albie/publications/elpub2003.pdf},\n",
        "  editor =\"Sely Costa et al.\",\n",
        "  booktitle= \"ElPub 2003 -- International conference on electronic publishing\",\n",
        "  month = \"June\",\n",
        "  pages = \"288--298\",\n",
        "  lang=\"EN\",\n",
        "  abstract = {\n",
        "     Current music publishing in the Internet is mainly concerned with\n",
        "  sound publishing. We claim that music publishing is not only to make\n",
        "  sound available but also to define relations between a set of music\n",
        "  objects like music scores, guitar chords, lyrics and their\n",
        "  meta-data. We want an easy way to publish music in the Internet, to\n",
        "  make high quality paper booklets and even to create Audio CD's.\n",
        "  In this document we present a workbench for music publishing based\n",
        "  on open formats, using open-source tools and script programming over\n",
        "  them.  The workbench is based on an archive specification written in\n",
        "  a text-based format which includes sound references, music scores,\n",
        "  chords and lyrics and their meta-information.\n",
        "  },\n",
        "\n",
        " keyword =\"música, bibliotecas digitais\",\n",
        "}\n",
        "\n",
        "@InProceedings{cp3a:terminum2003,\n",
        "  author = \"J.J. Almeida and Alberto Simões and José Castro and Bruno\n",
        "     Martins and Paulo Silva\",\n",
        "  year= 2003,\n",
        "  title= \"Projecto {TerminUM}\",\n",
        "  publisher = \"Universidade do Minho\",\n",
        "  booktitle={CP3A 2003 -- Workshop em Corpora Paralelos: aplicações e\n",
        "    algoritmos associados},\n",
        "  note = {Braga},\n",
        "  month=\"Jun.\",\n",
        "  pages = \"7--14\",\n",
        " keyword =\"terminum, parallel corpora\",\n",
        "   url = {http://alfarrabio.di.uminho.pt/~albie/publications/cp3a2003-terminum.pdf},\n",
        "  abstract = { O projecto TerminUM tem como objectivos principais o\n",
        "                  estudo, experimentação e a criação de recursos na\n",
        "                  área dos corpora paralelos, terminologia\n",
        "                  (descritiva) e recursos multilingues ligados a\n",
        "                  corpora: fazer extracção tão automática quanto\n",
        "                  possível de corpora a partir da web; fazer extracção\n",
        "                  de dicionários, de terminologia e de outros recursos\n",
        "                  ligados à tradução; criar e interligar as\n",
        "                  ferramentas desenvolvidas; criar e disponibilizar:\n",
        "                  (1) listas de Bitextos, corpora e corpora paralelos,\n",
        "                  (2) ferramentas de criação e transformação de\n",
        "                  corpora, (3) recursos multilingues derivados/ligados\n",
        "                  a corpora.  Nesta apresentação serão abordadas\n",
        "                  algumas tarefas presentemente a decorrer no âmbito\n",
        "                  do projecto, nomeadamente: ciclo de vida da\n",
        "                  construção e transformação de corpora; resumo das\n",
        "                  ferramentas desenvolvidas (e em desenvolvimento);\n",
        "                  construção de corpora paralelos tomando como base\n",
        "                  legendas de filmes (subtitles), ficheiro de\n",
        "                  internacionalização (mensagens de software .po) e\n",
        "                  ficheiros de memórias de tradução (TMX); animação de\n",
        "                  corpora paralelos via web (criação de motores de\n",
        "                  consulta usando diversas ferramentas).  }\n",
        "}\n",
        "\n",
        "@InProceedings{cp3a:kvec2003,\n",
        "  author = \"Bruno Martins\",\n",
        "  year= 2003,\n",
        "  title= \"{Lingua-Biterm}: um módulo Perl para extracção de terminologia bilingue\",\n",
        "  publisher = \"Universidade do Minho\",\n",
        "  booktitle={CP3A 2003 -- Workshop em Corpora Paralelos: aplicações e\n",
        "    algoritmos associados},\n",
        "  note = {Braga},\n",
        "  month=\"Jun.\",\n",
        "  pages = \"65--70\",\n",
        " keyword =\"kvec, terminum, parallel corpora, word alignment\",\n",
        "}\n",
        "\n",
        "@InProceedings{cp3a:natools2003,\n",
        "  author = \"Alberto Simões\",\n",
        "  year= 2003,\n",
        "  title= \"Alinhamento de corpora paralelos\",\n",
        "  publisher = \"Universidade do Minho\",\n",
        "  booktitle={CP3A 2003 -- Workshop em Corpora Paralelos: aplicações e\n",
        "    algoritmos associados},\n",
        "  note = {Braga},\n",
        "  month=\"Jun.\",\n",
        "  pages = \"71--77\",\n",
        " keyword =\"natools, terminum, parallel corpora, word alignment\",\n",
        "}\n",
        "\n",
        "@article{sepln2003,\n",
        " author= {Alberto M. Simões and J.J. Almeida},\n",
        " title=\"{NATools} -- A Statistical Word Aligner Workbench\",\n",
        " publisher=\"Sociedade Española para el Procesamiento del Lenguaje Natural\",\n",
        "  journal =    {Procesamiento del Lenguaje Natural},\n",
        " volume =\"31\",\n",
        " pages = \"217--224\",\n",
        " month=\"Sep.\",\n",
        " year= 2003,\n",
        " abstract = {This document presents the TerminUM project and the\n",
        "  work done in its statistical word aligner workbench (NATools). It\n",
        "  shows a variety of alignment methods for parallel corpora and\n",
        "  discusses the resulting terminological dictionaries and their use:\n",
        "  evaluation of sentence translations; construction of a multi-level\n",
        "  navigation system for linguistic studies or statistical\n",
        "  translations. },\n",
        " keyword =\"natools, terminum, parallel corpora, word alignment\",\n",
        "}\n",
        "\n",
        "@phdthesis{tesejj,\n",
        "  author =       {José João Dias de Almeida},\n",
        "  title =        {Dicionários dinâmicos multi-fonte},\n",
        "  school =       {Universidade do Minho},\n",
        "  type =         \"Tese de Doutoramento\",\n",
        "  superviser =   \"Pedro Rangel Henriques\",\n",
        "  url=           \"http://natura.di.uminho.pt/~jj/bib/tesejj.pdf\",\n",
        "  year =         2003,\n",
        "  lang      = \"PT\",\n",
        "}\n",
        "\n",
        "@MastersThesis{teseambs,\n",
        "  author =       {Alberto Manuel Brandão Simões},\n",
        "  title =        {Parallel Corpora word alignment and applications},\n",
        "  school =       {Escola de Engenharia - Universidade do Minho},\n",
        "  url=           \"http://alfarrabio.di.uminho.pt/~albie/publications/msc.pdf\",\n",
        "  type =         \"Tese de Mestrado\",\n",
        "  superviser =   \"José João Almeida and Pedro Rangel Henriques\",\n",
        "  year =         {2004},\n",
        "  lang      = \"EN\",\n",
        "}\n",
        "\n",
        "@InProceedings{xata04:tx,\n",
        "  author =       {José João Almeida and Alberto Simões},\n",
        "  title =        {{TX} --- {V}alidação de {XML} baseada em tipos dinâmicos},\n",
        "  booktitle =    {{XATA 2004} - XML, Aplicações e Tecnologias Associadas},\n",
        "  pages =        {217--224},\n",
        "  year =         {2004},\n",
        "  url =\n",
        "{http://alfarrabio.di.uminho.pt/~albie/publications/xata04-tx.pdf},\n",
        "  lang      = \"PT\",\n",
        "  isbn =         {972-99166-0-8},\n",
        "  irreditor =       {José Carlos Ramalho and Alberto Simões},\n",
        "  month =        {February},\n",
        "  abstract = {\n",
        "  Desde o advento do SGML e posteriormente do XML, que a validação de\n",
        "  documentos tem sido focada.\n",
        "  \n",
        "  Esta validação surgiu para analisar a estrutura dos documentos SGML\n",
        "  e XML usando DTDs.  Além dessa, e devido às restrições do XML em\n",
        "  relação ao SGML, a validação de XML bem formado também tem sido\n",
        "  usada.  Mais recentemente, os Schema e Schematron vieram permitir a\n",
        "  validação a um nível superior: não só a estrutura do documento mas\n",
        "  também alguma validação de conteúdo.\n",
        "  \n",
        "  Neste artigo apresentamos a ferramenta TX que visa outro nível de\n",
        "  validação, em que os tipos possam ser mais ricos e/ou calculados\n",
        "  dinamicamente, e onde se possa definir funções de anotação e/ou\n",
        "  correcção das porções do documento que não sigam as especificações.\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "@InProceedings{xata04:mtd,\n",
        "  author =       {Alberto Simões and José João Almeida and Xavier Gomez\n",
        "Guinovart},\n",
        "  title =        {Memórias de Tradução Distribuídas},\n",
        "  booktitle =    {{XATA 2004} --- XML, Aplicações e Tecnologias Associadas},\n",
        "  pages =        {59--68},\n",
        "  year =         {2004},\n",
        "  lang      = \"PT\",\n",
        "  url = {http://alfarrabio.di.uminho.pt/~albie/publications/xata04-mtd.pdf},\n",
        "  isbn =         {972-99166-0-8},\n",
        "  irreditor =       {José Carlos Ramalho and Alberto Simões},\n",
        "  month =        {February},\n",
        "  abstract = {\n",
        "  Neste documento apresenta-se o conceito de memórias de tradução\n",
        "  distribuídas, discutindo-se o seu interesse na área da tradução, bem\n",
        "  como as vantagens que uma ferramenta de tradução pode tirar do seu\n",
        "  uso.\n",
        "  \n",
        "  É apresentada uma possível implementação de memórias de tradução\n",
        "  distribuídas usando WebServices numa arquitectura de cooperativismo.\n",
        "  São definidos as mensagens (API) que um serviço deste género deve\n",
        "  implementar para que uma ferramenta de tradução possa tirar partido\n",
        "  da colaboração entre tradutores.\n",
        "  }\n",
        "}\n",
        "\n",
        "@article{xmldt2,\n",
        "  author = {Alberto Simões},\n",
        "  title = {{XML::DT} - Down-Translating XML},\n",
        "  journal = {The Perl Review},\n",
        "  number = 1,\n",
        "  volume = 1,\n",
        "  year = 2004,\n",
        "}\n",
        "\n",
        "@article{sepln2004,\n",
        " author= {Alberto Simões and Xavier Gómez Guinovart and J.J. Almeida},\n",
        " title={Distributed Translation Memories implementation using WebServices},\n",
        " publisher=\"Sociedade Española para el Procesamiento del Lenguaje Natural\",\n",
        " journal =      {Procesamiento del Lenguaje Natural},\n",
        "  pages =        {89--94},\n",
        "  volume =       {33},\n",
        "  month =        {July},\n",
        "  year =         {2004},\n",
        "  lang =         {EN},\n",
        " url = {http://alfarrabio.di.uminho.pt/~albie/publications/dtm-sepln.pdf},\n",
        " keyword ={TMs, MT, distributed translation memories, WebServices, CAT},\n",
        " abstract= { Translation Memories are very useful for translators\n",
        "  but are difficult to share and reuse in a community of translators.\n",
        "  This article presents the concept of Distributed Translation\n",
        "  Memories, where all users can contribute and sharing translations.\n",
        "  Implementation details using WebServices are shown, as well as an\n",
        "  example of a distributed system between Portugal and Spain.}\n",
        "}\n",
        "\n",
        "@inproceedings{linguateca,\n",
        " author = {Diana Santos and Alberto Simões and Ana Frankenberg-Garcia and\n",
        "   Ana Pinto and Anabela Barreiro and Belinda Maia and Cristina Mota and Débora\n",
        "   Oliveira and Eckhard Bick and Elisabete Ranchhod and J.J. Almeida\n",
        "   and Luís Cabral and Luís Costa and Luís Sarmento and Marcirio Chaves and Nuno\n",
        "   Cardoso and Paulo Rocha and Rachel Aires and Rosário Silva and Rui Vilela and\n",
        "   Susana Afonso},\n",
        " title = {Linguateca: um centro de recursos distribuído para o processamento\n",
        "   computacional da língua portuguesa},\n",
        " year = 2004,\n",
        " booktitle = {Workshop on Linguistic Tools and Resources for Spanish and\n",
        "   Portuguese},\n",
        " editor = {IBERAMIA 2004},\n",
        " lang = \"EN\",\n",
        " pages=\"147--154\",\n",
        " address=\"Puebla, México\",\n",
        " url = {http://alfarrabio.di.uminho.pt/~albie/publications/linguateca.pdf},\n",
        " abstract = {\n",
        "   Neste artigo apresentamos uma panorâmica da actividade da Linguateca na criação\n",
        "   e disponibilização de recursos e ferramentas para a língua portuguesa.  Começamos\n",
        "   por uma descrição dos objectivos e pressupostos da Linguateca e uma breve história\n",
        "   da sua intervenção, e finalizamos com algumas considerações sobre a melhor forma\n",
        "   de prosseguir na organização da área.\n",
        " }\n",
        "}\n",
        "\n",
        "\n",
        "@inproceedings{xata05:fs,\n",
        "    author=\"Rui Vilela and Alberto Simões and Eckhard Bick and J.J. Almeida\",\n",
        "    title=\"Representação em {XML} da {F}loresta {S}intáctica\",\n",
        "    month=\"Fev.\",\n",
        "    year=2005,\n",
        "    irreditor=\"José Carlos Ramalho and Alberto Simões and João Correia Lopes\",\n",
        "    booktitle=\"XATA 2005, Aplicações e Tecnologias Associadas\",\n",
        "    publisher=\"Departamento de Informática, Universidade do Minho\",\n",
        "    location=\"Braga\",\n",
        "    keyword = {XML, Floresta Sintáctica, tigerXML, Lingua::PT::Dirty},\n",
        "}\n",
        "\n",
        "@inproceedings{xata05:tdt,\n",
        "    author=\"J.J. Almeida and Alberto Simões\",\n",
        "    title=\"Inferência de tipos em documentos {XML}\",\n",
        "    month=\"Fev.\",\n",
        "    year=2005,\n",
        "    irreditor=\"José Carlos Ramalho and Alberto Simões and João Correia Lopes\",\n",
        "    booktitle=\"XATA 2005, Aplicações e Tecnologias Associadas\",\n",
        "    publisher=\"Departamento de Informática, Universidade do Minho\",\n",
        "    location=\"Braga\",\n",
        "    keyword = {XML, XML::DT},\n",
        "}\n",
        "\n",
        "@inproceedings{xata06:navegante,\n",
        "    author=\"J.J. Almeida and Alberto Simões\",\n",
        "    title=\"Navegante: um proxy de ordem superior para navegação intusiva\",\n",
        "    month=\"Fev.\",\n",
        "    year=2006,\n",
        "    irreditor=\"José Carlos Ramalho and Alberto Simões and João Correia Lopes\",\n",
        "    booktitle=\"XATA 2006, Aplicações e Tecnologias Associadas\",\n",
        "    publisher=\"ESTGP\",\n",
        "    address =      {Portalegre},\n",
        "    Note=\"poster\",\n",
        "    pages=\"376--377\",\n",
        "    keyword = {XML, XML::DT, HTML},\n",
        "}\n",
        "\n",
        "@inproceedings{xata06:xmlauto,\n",
        "    author=\"J.J. Almeida and Alberto Simões\",\n",
        "    title =        {Geração dinâmica de {API}s {P}erl para criação de {XML}},\n",
        "    month=\"Fev.\",\n",
        "    year=2006,\n",
        "    irreditor=\"José Carlos Ramalho and Alberto Simões and João Correia Lopes\",\n",
        "  booktitle =    {{XATA 2006} --- 4ª Conferência Nacional em XML, Aplicações e Tecnologias Aplicadas},\n",
        "    publisher=\"ESTGP\",\n",
        "  url = {http://alfarrabio.di.uminho.pt/~albie/publications/xata2006-xmlwritersimple.pdf},\n",
        "  address =      {Portalegre},\n",
        "    pages=\"307--314\",\n",
        "    keyword = {XML, XML::DT, HTML},\n",
        "  isbn =         {972-99166-2-4},\n",
        "  lang =         \"PT\",\n",
        "  abstract =     {\n",
        "  É consensual que o XML como linguagem para a estruturação de documentos\n",
        "  tem vindo a tomar um lugar relevante. É também evidente a vantagem\n",
        "  obtida no uso de XML como linguagem de intercâmbio.\n",
        "  No entanto, a sua sintaxe é\n",
        "  demasiado descritiva pelo que a geração de documentos de forma\n",
        "  manual é dolorosa sendo útil dispor de módulos\n",
        "  que simplifiquem essa tarefa.\n",
        "\n",
        "  Neste artigo propomos um módulo Perl (XML::Writer::Simple) configurável via\n",
        "  DTD que simplifica a tarefa de gerar XML.\n",
        "  },\n",
        "}\n",
        "\n",
        "@article{sepln06,\n",
        "  author =       {Alberto Simões and J. João Almeida},\n",
        "  title =        {{NatServer:} A Client-Server Architecture for building Parallel Corpora applications},\n",
        "  year =         {2006},\n",
        "  journal =    {Procesamiento del Lenguaje Natural},\n",
        "  address =      {Zaragoza, Spain},\n",
        "  url = {http://alfarrabio.di.uminho.pt/~albie/publications/sepln06.pdf},\n",
        "  month =        {September},\n",
        "  lang =         {EN},\n",
        "  volume =       {37},\n",
        "  pages =        {91--97},\n",
        "  abstract =     {Parallel corpora are important resources for most\n",
        "                  Natural Language processing tasks. From the common\n",
        "                  applications, like machine translation, to the\n",
        "                  usually mono-lingual tasks as paraphrase detection\n",
        "                  and word sense disambiguation, most researchers are\n",
        "                  using massive parallel corpora.  Thus, the\n",
        "                  availability of an efficient way to manage them is\n",
        "                  very important.  This paper presents a Client-Server\n",
        "                  architecture to query efficiently parallel corpora\n",
        "                  and probabilistic translation dictionaries.},\n",
        "}\n",
        "\n",
        "@inProceedings{eamt06,\n",
        "  author =       {Alberto Simões and J. João Almeida},\n",
        "  title =        {Combinatory Examples Extraction for Machine Translation},\n",
        "  shortin = {{EAMT}},\n",
        "  year =         {2006},\n",
        "  url = {http://alfarrabio.di.uminho.pt/~albie/publications/eamt06.pdf},\n",
        "  booktitle = {11th Annual Conference of the European Association for Machine Translation},\n",
        "  editor =     {Jan Tore L\\o nning and Stephan Oepen},\n",
        "  address =   {Oslo, Norway},\n",
        "  pages =     {27--32},\n",
        "  month =     {19--20, June},\n",
        "  isbn =      {82-7368-294-3},\n",
        "  lang = {EN},\n",
        "  abstract = { One of the bottlenecks of example-based machine\n",
        "                  translation (EBMT) is to be able to amass\n",
        "                  automatically quantities of good examples.  In our\n",
        "                  work in EBMT, we are investigating how far one can\n",
        "                  go by performing example extraction from parallel\n",
        "                  corpora using Probabilistic Translation Dictionaries\n",
        "                  to obtain example segmentation points.  In fact, the\n",
        "                  success of EBMT highly depends on examples quality\n",
        "                  and quantity, but also in their length. Thus, we\n",
        "                  give special importance on methods to extract\n",
        "                  different size examples from the same translation\n",
        "                  unit.  With this article we show that it is possible\n",
        "                  to extract quantities for examples from parallel\n",
        "                  corpora just using probabilistic translation\n",
        "                  dictionaries extracted from the same corpora.},\n",
        "}\n",
        "\n",
        "\n",
        "@InProceedings{lrec06,\n",
        "  author =       {José João Almeida and Alberto Simões},\n",
        "  title =        {{$T_2O$} --- Recycling Thesauri into a Multilingual Ontology},\n",
        "  shortin = {{LREC}},\n",
        "  booktitle =    {Fifth international conference on Language Resources and Evaluation, LREC 2006},\n",
        "  year =         {2006},\n",
        "  url = {http://alfarrabio.di.uminho.pt/~albie/publications/lrec06.pdf},\n",
        "  address =      {Genova, Italy},\n",
        "  month =        {May},\n",
        "  lang =         {EN},\n",
        "  abstract =     {In this article we present $T_2O$ --- a workbench to\n",
        "                  assist the process of translating heterogeneous\n",
        "                  resources into ontologies, to enrich and add\n",
        "                  multilingual information, to help programming with\n",
        "                  them, and to support ontology publishing. $T_2O$ is\n",
        "                  an ontology algebra.},\n",
        "}\n",
        "\n",
        "@inProceedings{elpub06-t2o,\n",
        "  author =       {J. João Almeida and  Alberto Simões },\n",
        "  title =        {Publishing multilingual ontologies: a quick way of obtaining feedback},\n",
        "  year =         {2006},\n",
        "  booktitle =    {{ElPub 2006} --- Digital Spectrum: Integrating Technology and Culture},\n",
        "  address =   {Bansko, Bulgaria},\n",
        "  pages = \"373--374\",\n",
        "  note=\"poster\",\n",
        "  url = {http://alfarrabio.di.uminho.pt/~albie/publications/elpub06-t2o.pdf},\n",
        "  month =     {June},\n",
        "  lang = {EN},\n",
        "  abstract = {Dictionary and Thesaurus are valuable resources for\n",
        "                  Natural Language Processing but do not exist as\n",
        "                  freely available as expected, especially for\n",
        "                  languages other than English and, when they exist,\n",
        "                  they are just available for querying online. Our\n",
        "                  main goal with T2O --- Thesaurus to Ontology\n",
        "                  framework --- is to create a multilingual ontology:\n",
        "                  freely available online and to download; with a\n",
        "                  computer readable format; with a good API; with a\n",
        "                  structure as rich as possible; reusing all the\n",
        "                  structured information we can get; },\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "@InProceedings{elpub06-blind,\n",
        "  author =       {António R. Fernandes and Alexandre Carvalho and J. João Almeida and  Alberto Simões },\n",
        "  title =        {Transcoding for Web Accessibility for the Blind: Semantics\n",
        "from Structure},\n",
        "  shortin = {{ElPub}},\n",
        "  booktitle = {ElPub 2006 --- Digital Spectrum: Integrating Technology and Culture},\n",
        "  year =      {2006},\n",
        "  url  = {http://alfarrabio.di.uminho.pt/~albie/publications/elpub06-blind.pdf},\n",
        "  address =   {Bansko, Bulgaria},\n",
        "  month =     {June},\n",
        "  pages = {123-134},\n",
        "  abstract = {True accessibility requires minimizing the scanning time\n",
        "                  to find a particular piece of\n",
        "                  information. Sequentially reading web pages do not\n",
        "                  provide this type of accessibility, for instance\n",
        "                  before the user gets to the actual text content of\n",
        "                  the page it has to go through a lot of menus and\n",
        "                  headers. However if the user could navigate a web\n",
        "                  page based through semantically classified blocks\n",
        "                  then the user could jump faster to the actual\n",
        "                  content of the page, skipping all the menus and\n",
        "                  other parts of the page. We propose a transcoding\n",
        "                  engine that tackles accessibility at two distinct,\n",
        "                  yet complementary, levels: for specific known sites\n",
        "                  and general unknown sites. We present a tool for\n",
        "                  building customized scripts for known sites that\n",
        "                  turns this process in an extremely simple task,\n",
        "                  which can be performed by anyone, without any\n",
        "                  expertise. For general unknown sites, our approach\n",
        "                  relies on statistical analysis of the structural\n",
        "                  blocks that define a web page to infer a semantic\n",
        "                  for the block.},\n",
        "   lang = \"EN\",\n",
        "}\n",
        "\n",
        "% ^^^^^ 2007 ^^^^^^^^^^\n",
        "\n",
        "%InProceedings{gfkl07:topology,\n",
        "%  author =       {Anália Lourenço and Alberto Simões and Orlando Belo},\n",
        "%  title =        {Evaluating Web Site Structure based on Navigation Profiles and Site Topology},\n",
        "%  booktitle =    {The 31st Annual Conference of the German Classification Society on Data Analysis, Machine Learning, and Applications},\n",
        "%  year =         {2007},\n",
        "%  note =         {\\textbf{forthcoming}},\n",
        "% }\n",
        "\n",
        "\n",
        "%InProceedings{gfkl07:terminology,\n",
        "%  author =       {Alberto Simões and José João Almeida},\n",
        "%  title =        {Using Alignment Patterns for Bilingual Terminology Extraction},\n",
        "%  booktitle =    {The 31st Annual Conference of the German Classification Society on Data Analysis, Machine Learning, and Applications},\n",
        "%  year =         {2007},\n",
        "%  note =         {\\textbf{forthcoming}},\n",
        "% }\n",
        "\n",
        "\n",
        "%InProceedings{gfkl07:music,\n",
        "%  author =       {Alberto Simões and Anália Lourenço and José João Almeida},\n",
        "%  title =        {Mining Classical Music Scores for Epoch Classification},\n",
        "%  booktitle =    {The 31st Annual Conference of the German Classification Society on Data Analysis, Machine Learning, and Applications},\n",
        "%  year =         {2007},\n",
        "%  note =         {\\textbf{forthcoming}},\n",
        "% }\n",
        "\n",
        "\n",
        "@InCollection{avalon:jspell,\n",
        "  author =       {José João Almeida and Alberto Simões},\n",
        "  title =        {Jspellando nas morfolimpíadas: Sobre a participação do {Jspell} nas Morfolimpíadas},\n",
        "  booktitle =    {Avaliação conjunta: um novo paradigma no processamento computacional da língua portuguesa},\n",
        "  shortin =      {Avaliação conjunta, cap. 8},\n",
        "  year =         {2007},\n",
        "  editor =       {Diana Santos},\n",
        "  pages =        {83--90},\n",
        "  publisher =    {{IST Press}},\n",
        "}\n",
        "\n",
        "@InCollection{avalon:avalinha,\n",
        "  author =       {Alberto Simões and José João Almeida},\n",
        "  title =        {Avaliação de alinhadores},\n",
        "  shortin =      {Avaliação conjunta, cap. 18},\n",
        "  booktitle =    {Avaliação conjunta: um novo paradigma no processamento computacional da língua portuguesa},\n",
        "  publisher =    {{IST Press}},\n",
        "  year =         {2007},\n",
        "  pages =        {219--230},\n",
        "  editor =       {Diana Santos},\n",
        "}\n",
        "\n",
        "@InProceedings{xata07:xmltmx,\n",
        "  author =       {José João Almeida and Alberto Simões},\n",
        "  title =        {{XML::TMX} --- Processamento de Memórias de Tradução de Grandes Dimensões},\n",
        "  shortin = {{XATA}},\n",
        "  booktitle =    {{XATA 2007} --- 5ª Conferência Nacional em XML, Aplicações e Tecnologias Aplicadas},\n",
        "  year =         {2007},\n",
        "  month =        {February},\n",
        "  url = {http://alfarrabio.di.uminho.pt/~albie/publications/xmltmx07.pdf},\n",
        "  pages =        {83--93},\n",
        "  isbn =         {978-972-99166-4-9},\n",
        "  irreditor =       {José Carlos Ramalho and João Correia Lopes and Luís Carríço},\n",
        "  abstract =     { As ferramentas de tradução assistida por computador\n",
        "                  tentam reutilizar as traduções realizadas pelo\n",
        "                  tradutor sempre que uma frase semelhante tenha sido\n",
        "                  já traduzida. Para o intercâmbio destes documentos\n",
        "                  foi definido um formato denominado TMX (Translation\n",
        "                  Memory Exchange) baseado em XML.  Este tipo de\n",
        "                  documento ganha facilmente tamanhos incomportáveis\n",
        "                  para o seu processamento com métodos tradicionais.\n",
        "                  Neste artigo propomos uma metodologia de ordem\n",
        "                  superior para o processamento de documentos de\n",
        "                  estrutura repetitiva (em que se inserem as memórias\n",
        "                  de tradução) com uma abordagem baseada na conjunção\n",
        "                  de SAX e DOM.  São apresentados vários exemplos de\n",
        "                  filtros sobre memórias de tradução bem como um\n",
        "                  conjunto de medidas da sua eficiência.  }\n",
        "}\n",
        "\n",
        "% InProceedings{xata07:xmlyamljson,\n",
        "%    author =       {Rúben Fonseca and Alberto Simões},\n",
        "%   title =        {Alternativas ao {XML}: {YAML} e {JSON}},\n",
        "%   booktitle =    {{XATA 2007} --- 5ª Conferência Nacional em XML, Aplicações e Tecnologias Aplicadas},\n",
        "%   year =         {2007},\n",
        "%   month =        {February},\n",
        "%   url = {http://alfarrabio.di.uminho.pt/~albie/publications/xmlyamljson07.pdf},\n",
        "%   pages =        {33--46},\n",
        "%   isbn =         {978-972-99166-4-9},\n",
        "%   editor =       {José Carlos Ramalho and João Correia Lopes and Luís Carríço},\n",
        "%   abstract =     { O XML tem sido eleito como a linguagem de anotação por excelência,\n",
        "% possuindo ao mesmo tempo boas capacidades para serialização de estruturas\n",
        "% computacionais e transporte de dados independente da plataforma.\n",
        "% Recentemente porém, novos formatos de dados têm surgido. Alguns deles\n",
        "% têm tido uma boa aceitação porque resolvem alguns problemas ou limitações\n",
        "% do XML, sendo em algumas situações um bom complemento ou substituto do mesmo.\n",
        "% Neste artigo iremos apresentar dois desses formatos de dados - o YAML e o\n",
        "% JSON - fazendo uma abordagem geral dos mesmos e analisando algumas métricas\n",
        "% que nos poderão ajudar a decidir se e quando usar estas alternativas.\n",
        "%  }\n",
        "% }\n",
        "\n",
        "% techreport{man:rena,\n",
        "%   author = \"Edgar Alves and José João Almeida\",\n",
        "%   title = \"Manual de Utilizador do {RENA}\",\n",
        "%   year = 2006,\n",
        "%   type = \"Manual\",\n",
        "%   month = \"Jul\",\n",
        "%   institution = umdi,\n",
        "%   keyword = \"REM, PLN, IR\",\n",
        "%   abstract = {},\n",
        "%   url = \"http://natura.di.uminho.pt/~jj/pln/rena.pdf\",\n",
        "% }\n",
        "\n",
        "@InProceedings{MP07,\n",
        "  author =       {Alberto Simões and Rúben Fonseca and José João Almeida},\n",
        "  title =        {{Makefile::Parallel} Dependency Specification Language},\n",
        "  booktitle =    {Euro-Par 2007},\n",
        "  year =         {2007},\n",
        "  address =      {Rennes, France},\n",
        "  month =        {August},\n",
        "  pages =\t {33--41},\n",
        "  editor =\t {Anne-Marie Kermarrec and Luc Bougé and Thierry Priol},\n",
        "  volume =\t {4641},\n",
        "  series =\t {LNCS},\n",
        "  publisher =\t {Springer-Verlag},\n",
        "  abstract =     {  Some processes are not easy to be programmed from scratch\n",
        "for\n",
        "  parallel machines (clusters), but can be easily split on simple\n",
        "  steps. Makefile::Parallel is a tool which lets users to specify how processes\n",
        "  depend on each other.\n",
        "\n",
        "  The language syntax resembles the well known Makefile\n",
        "  makefiles format, but instead of specifying files or targets\n",
        "  dependencies, Makefile::Parallel specifies processes (or jobs) dependencies.\n",
        "\n",
        "  The scheduler submits jobs to the cluster scheduler (in our case,\n",
        "  Rocks PBS) waiting them to end. When each process finishes,\n",
        "  dependencies are calculated and direct dependent jobs are submitted.\n",
        "\n",
        "  Makefile::Parallel language includes features to specify parametric rules,\n",
        "used\n",
        "  to split and join processes dependencies.  Some tasks can be split\n",
        "  into n smaller jobs working on different portions of files. At the\n",
        "  end, another process can be used to join the results.\n",
        "},\n",
        "}\n",
        "\n",
        "\n",
        "@InProceedings{epia-bio-2007,\n",
        "  booktitle = {New Trends in Artificial Intelligence},\n",
        "  irreditor = {José Neves and Manuel Filipe Santos and José Manuel Machado},\n",
        "  pages = {541--552},\n",
        "  isbn13 = {978-989-95618-0-9},\n",
        "  author =       { Anália  Lourenço and Alberto  Simões and José João Almeida  and\n",
        "Miguel  Rocha and  Isabel  Rocha and Eugénio  Ferreira},\n",
        "  title =        {An Ontology-Based Approach To Systems Biology Literature\n",
        "Retrieval and Processing},\n",
        "  shortin = {Epia, CMBSB},\n",
        "  year =         {2007},\n",
        "  month =        {December},\n",
        "  abstract =     {This paper details the \\emph{SysBio Explorer}, a\n",
        "                  Systems Biology Literature Retrieval and Processing\n",
        "                  Framework, whose aim relies on the automatic\n",
        "                  inference of regulatory and metabolic networks based\n",
        "                  on biomedical literature. The \\emph{SysBio Explorer}\n",
        "                  does not focus on any organism or problem in\n",
        "                  particular and encompasses a number of processing\n",
        "                  and analysis techniques. It works over full-text\n",
        "                  documents, applying Natural Language Processing\n",
        "                  techniques and using biomedical dictionaries and\n",
        "                  ontologies together with hand-made rules. Besides\n",
        "                  biological entity recognition and relation\n",
        "                  extraction, document classification, relevance\n",
        "                  assessment and authoring networks are also within\n",
        "                  its present scope. The framework is described in\n",
        "                  terms of its design requirements and implementation\n",
        "                  decisions, exposing current achievements, but also\n",
        "                  highlighting present obstacles and future\n",
        "                  work. Experiments over real-world problems\n",
        "                  concerning the organisms \\emph{E. coli},\n",
        "                  \\emph{S. cerevisiae} and \\emph{H. pylori} are used\n",
        "                  in its validation.}\n",
        "}\n",
        "\n",
        "@InProceedings{epia-music-2007,\n",
        "  booktitle = {New Trends in Artificial Intelligence},\n",
        "  irreditor = {José Neves and Manuel Filipe Santos and José Manuel Machado},\n",
        "  shortin = {Epia, TEMA},\n",
        "  pages = {791--799},\n",
        "  author =       {Alberto Simões and Anália Lourenço and José João Almeida},\n",
        "  title =        {Using Text Mining Techniques for Classical Music Scores\n",
        "Analysis},\n",
        "  year =         {2007},\n",
        "  month =        {December},\n",
        "  abstract =     {Music Classification is a particular area\n",
        "                  of Computational Musicology that provides valuable\n",
        "                  insights about the evolving of composition patterns\n",
        "                  and assists in catalogue generation. The proposed work\n",
        "                  detaches from former works by classifying music based\n",
        "                  on music score information. Text Mining techniques\n",
        "                  support music score processing while Classification\n",
        "                  techniques are used in the construction of decision\n",
        "                  models. Although research is still at its earliest\n",
        "                  beginnings, the work already provides valuable\n",
        "                  contributes to symbolic music representation processing\n",
        "                  and subsequent analysis. Score processing involved\n",
        "                  the counting of ascending and descending chromatic\n",
        "                  intervals, note duration and meta-information\n",
        "                  tagging. Analysis involved feature selection and\n",
        "                  the evaluation of several data mining algorithms,\n",
        "                  ensuring extensibility towards larger repositories or\n",
        "                  more complex problems. Experiments report the analysis\n",
        "                  of composition epochs on a subset of the Mutopia project\n",
        "                  open archive of classical LilyPond-annotated\n",
        "                  music scores.  \n",
        "  },\n",
        "}\n",
        "\n",
        "\n",
        "@InCollection{harem:rena,\n",
        "  author =       {J.João Almeida},\n",
        "  title =        {{RENA} - Reconhecedor de Entidades},\n",
        "  booktitle =    {Reconhecimento de entidades mencionadas em português},\n",
        "  year =         {2007},\n",
        "  note = {Documentação e actas do HAREM, a primeira avaliação conjunta na\n",
        "área},\n",
        "  pages =        {157-172},\n",
        "  url = {http://acdc.linguateca.pt/aval_conjunta/LivroHAREM/Cap13-SantosCardoso2007-Almeida.pdf},\n",
        "  ISBN = {978-989-20-0731-1},\n",
        "  irreditor =       {Diana Santos and Nuno Cardoso},\n",
        "  publisher = {Linguateca},\n",
        "  shortin ={{HAREM} cap. XIII},\n",
        "}\n",
        "\n",
        "@Article{sepln07,\n",
        "  author =       {Alberto Simões and José João Almeida},\n",
        "  title =        {Parallel Corpora based Translation Resources Extraction},\n",
        "  journal =      {Procesamiento del Lenguaje Natural},\n",
        "  year =         {2007},\n",
        "  pages =        {265--272},\n",
        "  volume =       {39},\n",
        "  month =        {September},\n",
        "  lang =         {EN},\n",
        "  abstract =     {This paper describes NATools, a toolkit to process,\n",
        "                  analyze and extract translation resources from\n",
        "                  Parallel Corpora. It includes tools like a\n",
        "                  sentence-aligner, a probabilistic translation\n",
        "                  dictionaries extractor, word-aligner, a corpus\n",
        "                  server, a set of tools to query corpora and\n",
        "                  dictionaries, as well as a set of tools to extract\n",
        "                  bilingual resources.}\n",
        "}\n",
        "\n",
        "@InProceedings{cgiauto08,\n",
        "  author =       {Davide Sousa and Alberto Simões and José João Almeida},\n",
        "  title =        {{CGI::Auto} --- Automatic Web-Service Creation},\n",
        "  booktitle =    {{XATA 2008} --- 6ª Conferência Nacional em XML, Aplicações e\n",
        "Tecnologias Aplicadas},\n",
        "  year =         {2008},\n",
        "  month =        {February},\n",
        "  url = {http://alfarrabio.di.uminho.pt/~albie/publications/cgiauto08.pdf},\n",
        "  pages =        {22--27},\n",
        "  isbn =         {978-972-99166-5-6},\n",
        "  irreditor =       {José Carlos Ramalho and João Correia Lopes and Salvador\n",
        "Abreu},\n",
        "  abstract =     {   The creation of a CGI or a WebService as an interface for\n",
        "a command line tool is\n",
        "not as unusual as it may seem. It is extremely usual and useful.\n",
        "\n",
        "There are applications developed as command line tools that can be useful for\n",
        "different purposes,\n",
        "and different kind of users. Some of these users might not be able to run\n",
        "these tools directly.\n",
        "For instance, it\n",
        "is not easy to install a bunch of Perl modules to have a small tool working.\n",
        "For these situations, it is easier to make the tool available in the Web or as\n",
        "a\n",
        "WebService.\n",
        "\n",
        "The problem with making the tool available in these fashions, is that\n",
        "programmers tend to rewrite\n",
        "the tools to incorporate the CGI or XML specific layers.\n",
        "\n",
        "We defend that these CGI or WebService interfaces should use the already\n",
        "available command line\n",
        " tool, without any change. This interface should be able to read a simple\n",
        "textual\n",
        "specification of how the command line tool works, and buid the CGI or XML\n",
        "specific layers\n",
        "automatically.\n",
        "\n",
        "The CGI::Auto module aims this purpose:\n",
        "to encapsulate command line tools in a CGI layer based on a textual\n",
        "specification, transforming\n",
        "the command line tool in a web application.\n",
        "\n",
        " }\n",
        "}\n",
        "\n",
        "\n",
        "@InProceedings{navegante08,\n",
        "  author =       {Nuno Carvalho and José João Almeida and Alberto Simões},\n",
        "  title =        {{NAVEGANTE} --- An Intrusive Browseing Framework},\n",
        "  booktitle =    {{XATA 2008} --- 6ª Conferência Nacional em XML, Aplicações e\n",
        "Tecnologias Aplicadas},\n",
        "  year =         {2008},\n",
        "  month =        {February},\n",
        "  url = {http://alfarrabio.di.uminho.pt/~albie/publications/navegante08.pdf},\n",
        "  pages =        {52--63},\n",
        "  isbn =         {978-972-99166-5-6},\n",
        "  irreditor =       {José Carlos Ramalho and João Correia Lopes and Salvador\n",
        "Abreu},\n",
        "  abstract =     {   NAVEGANTE is a generic framework to build superior order\n",
        "proxies for\n",
        "  intrusive browsing. This framework provides the means for developing\n",
        "  tools that behave as proxies, but perform some processing task on\n",
        "  the content that is being browsed. Parallel to this content processing,\n",
        "  applications can also run other user-defined functions with different\n",
        "  purposes and interfaces, but we'll explain those later. Currently,\n",
        "  NAVEGANTE only builds applications that run as CGIs, but this is intended\n",
        "  to change in a near future. Applications are built writing programs in\n",
        "  NAVEGANTE's Domain Specific Language (DSL).\n",
        "\n",
        "  NAVEGANTE is a work in progress. This article aims to describe the current\n",
        "  state of development. What applications can be built and how. Also, we\n",
        "  identify some implementation problems, and briefly discuss some future\n",
        "  improvements. Finally, we try to illustrate most of the concepts described\n",
        "  using a couple of case studies.\n",
        " }\n",
        "}\n",
        "\n",
        "@Article{sepln08,\n",
        "  author =       {Alberto Simões and José João Almeida},\n",
        "  title =        {Bilingual Terminology Extraction based on Translation\n",
        "Patterns},\n",
        "  journal =      {Procesamiento del Lenguaje Natural},\n",
        "  year =         {2008},\n",
        "  month =        {September},\n",
        "  lang =         {EN},\n",
        "  abstract =     {Parallel corpora are rich sources of translation\n",
        "    resources. This document presents a methodology for the extraction\n",
        "of bilingual\n",
        "    nominals (terminology candidates) from parallel corpora, using\n",
        "translation patterns.\n",
        "    The patterns proposed in this work specify the order changes that\n",
        "occur during translation\n",
        "    and that are intrinsic to the involved languages syntaxes.\n",
        "    These patterns are described in a domain specific language\n",
        "    named PDL (Pattern Description Language), and are extremely\n",
        "    efficient for the detection of nominal phrases.\n",
        "  },\n",
        "  volume = {41},\n",
        "  pages = {281--288},\n",
        "}\n",
        "\n",
        "\n",
        "@inproceedings{propor-apslt08,\n",
        "  author    = { J. J. Almeida and  Alberto Simões},\n",
        "  title     = { A Textual Rewriting system for NLP},\n",
        "  booktitle = {Applications of Portuguese Speech and Language Technologies,\n",
        "               PROPOR 2008 Special session},\n",
        "  year      = {2008},\n",
        "  pages     = {35--42},\n",
        "  irreditor    = {António Teixeira and Daniela Braga},\n",
        "}\n",
        "\n",
        "@inproceedings{epia:DruryA09,\n",
        "  author    = {Brett Drury and J. J. Almeida},\n",
        "  title     = {Construction of a Local Domain Ontology from News Stories},\n",
        "  booktitle = {EPIA},\n",
        "  year      = {2009},\n",
        "  pages     = {400-410},\n",
        "  url       = {http://dx.doi.org/10.1007/978-3-642-04686-5_33},\n",
        "  publisher = {Springer},\n",
        "  series    = {Lecture Notes in Computer Science},\n",
        "  volume    = {5816},\n",
        "  note     = {Progress in Artificial Intelligence, EPIA 2009, Aveiro, Portugal, October 12-15},\n",
        "  editor    = {Luis Seabra Lopes and\n",
        "               Nuno Lau and\n",
        "               Pedro Mariano and\n",
        "               Luis Mateus Rocha},\n",
        "}\n",
        "\n",
        "@InProceedings{markers09,\n",
        "  author =       {Alberto Simões and José João Almeida},\n",
        "  title =        {Bilingual Example Segmentation based on Markers\n",
        "Hypothesis},\n",
        "  booktitle =   {I Iberian SLTech 2009},\n",
        "  editor  = { António Teixeira and Miguel Sales Dias and Daniela Braga},\n",
        "  year =         {2009},\n",
        "  address = {Porto Salvo, Portugal},\n",
        "  month = {September, 3--4},\n",
        "  isbn = {978-989-96278-1-9},\n",
        "  pages = {95--98},\n",
        "  lang = {EN},\n",
        "  abstract = {  The Marker Hypothesis was first defined by Thomas Green\n",
        "in 1979.  It\n",
        "  is a psycho-linguistic hypothesis defining that there is a set of\n",
        "  words in every language that marks boundaries of phrases in a\n",
        "  sentence. While it remains a hypothesis because nobody has proved\n",
        "  it, tests have shows that results are comparable to basic shallow\n",
        "  parsers with higher efficiency.\n",
        "\n",
        "  The chunking algorithm based on the Marker Hypothesis is simple,\n",
        "  fast and almost language independent. It depends on a list of\n",
        "  closed-class words, that are already available for most languages.\n",
        "  This makes it suitable for bilingual chunking (there is not the\n",
        "  requirement for separate language shallow parsers).\n",
        "\n",
        "  This paper discusses the use of the Marker Hypothesis combined\n",
        "  with Probabilistic Translation Dictionaries for example-based machine\n",
        "  translation resources extraction from parallel corpora.},\n",
        "}\n",
        "\n",
        "\n",
        "%%=============================================== 2010\n",
        "\n",
        "@InProceedings{xata2010-rewritexml,\n",
        "  author =       {Alberto Simões and José João Almeida},\n",
        "  title =        {Processing {XML:} a rewriting system approach},\n",
        "  booktitle =    {{XATA 2010} --- 8ª Conferência Nacional em XML, Aplicações e\n",
        "Tecnologias Aplicadas },\n",
        "  pages =        {27--38},\n",
        "  year =         {2010},\n",
        "  editor =       {Alberto Simões and Daniela da Cruz and José Carlos Ramalho},\n",
        "  address =      {Vila do Conde},\n",
        "  month =        {Maio},\n",
        "  lang =         {EN},\n",
        "  abstract =     { Nowadays XML processing is performed using one of\n",
        "                  two approaches: using the SAX (Simple API for XML)\n",
        "                  or using the DOM (Document Ob ject Model). While\n",
        "                  these two approaches are adequate for most cases\n",
        "                  there are situations where other approaches can make\n",
        "                  the solution easier to write, read and, therefore,\n",
        "                  to maintain.  This document presents a rewriting\n",
        "                  approach for XML documents processing, focusing\n",
        "                  the tasks of transforming XML documents (into other\n",
        "                  XML formats or other textual documents) and the task\n",
        "                  of rewriting other textual formats into XML\n",
        "                  dialects.  These approaches were validated with some\n",
        "                  case studies, ranging from an XML authoring tool to\n",
        "                  a dictionary publishing mechanism.  }\n",
        "}\n",
        "\n",
        "@article{ocr2010,\n",
        " author = {Brett Drury and José João Almeida},\n",
        "title = {A Case Study of Rule Based and Probabilistic Word Error Correction of\n",
        "Portuguese OCR Text in a \"Real World\" Environment for Inclusion in a Digital\n",
        "Library},\n",
        "   journal={International Journal of Computational Linguistics},\n",
        "   note={presented in {CICLING2010}},\n",
        "   Volume ={1},\n",
        "   Number ={1-2},\n",
        "   pages = {307--315},\n",
        "   year={2010},\n",
        "   url = \"http://10.255.0.115/pub/2010/DA10\"\n",
        "}\n",
        "\n",
        "@InProceedings{lrec10:bigorna,\n",
        "  author = {José João Almeida and André Santos and Alberto Simões},\n",
        "  title = {Bigorna -- A Toolkit for Orthography Migration Challenges},\n",
        "  booktitle = {Proceedings of the Seventh conference on International Language\n",
        "Resources and Evaluation (LREC'10)},\n",
        "  shortin = {{LREC}},\n",
        "  year = {2010},\n",
        "  month = {may},\n",
        "  date = {19-21},\n",
        "  address = {Valletta, Malta},\n",
        "  editor = {Nicoletta Calzolari and others},\n",
        "  publisher = {European Language Resources Association (ELRA)},\n",
        "  isbn = {2-9517408-6-7},\n",
        "  language = {english}\n",
        "}\n",
        "\n",
        "@InProceedings{lrec10:dicaberto,\n",
        "  author = {Alberto Simões and José João Almeida and Rita Farinha},\n",
        "  title = {Processing and Extracting Data from Dicionário Aberto},\n",
        "  booktitle = {Proceedings of the Seventh conference on International Language\n",
        "Resources and Evaluation (LREC'10)},\n",
        "  year = {2010},\n",
        "  shortin = {{LREC}},\n",
        "  month = {may},\n",
        "  date = {19-21},\n",
        "  address = {Valletta, Malta},\n",
        "  editor = {Nicoletta Calzolari and others},\n",
        "  publisher = {European Language Resources Association (ELRA)},\n",
        "  isbn = {2-9517408-6-7},\n",
        "  language = {english}\n",
        " }\n",
        "\n",
        "@InProceedings{bucc2010,\n",
        "  author =       {José João Almeida and Alberto Simões},\n",
        "  title =        {Automatic Parallel Corpora and Bilingual Terminology extraction from Parallel WebSites },\n",
        "  booktitle =    {BUCC2010 -- 3rd Workshop on Building and Using Comparable Corpora, lrec2010},\n",
        "  pages =        {50--55},\n",
        "  year =         {2010},\n",
        "  editor =       {Reinhard Rapp and Pierre Zweigenbaum and Serge Sharoff},\n",
        "  address =      {Valletta, Malta},\n",
        "  month =        {May},\n",
        "  lang =         {EN},\n",
        "  url = {http://alfarrabio.di.uminho.pt/~albie/publications/bucc2010.pdf},\n",
        "  abstract = { In our days, the notion, the importance and the\n",
        "                  significance of parallel corpora is so big that needs\n",
        "                  no special introduction. Unfortunately, public\n",
        "                  available parallel corpora is somewhat limited in\n",
        "                  range. There are big corpora about politics or\n",
        "                  legislation, about medicine and other specific areas,\n",
        "                  but we miss corpora for other different\n",
        "                  areas. Currently there is a huge investment on using\n",
        "                  the Web as a corpus.  This article uncovers GWB, a\n",
        "                  tool that aims automatic construction of parallel\n",
        "                  corpora from the web. We defend that it is possible\n",
        "                  to build high quality terminological corpora in an\n",
        "                  automatic fashion, just by specifying a sensible\n",
        "                  Internet domain and using an appropriate set of seed\n",
        "                  keywords. GWB is a web-spider that works in\n",
        "                  conjunction with a set of other Open-Source tools,\n",
        "                  de¿ning a pipeline that includes the documents\n",
        "                  retrieval from the web, alignment at sentence level\n",
        "                  and its quality analysis, bilingual dictionaries and\n",
        "                  terminology extraction and construction of off-line\n",
        "                  dictionaries.  }\n",
        "}\n",
        "\n",
        "@InProceedings{brett:lrec,\n",
        "  author =       {José João Almeida and Brett Drury},\n",
        "  title =        { Identification, extraction and population of collective named\n",
        "entities from business news},\n",
        "  booktitle =    {Entity2010 -- Workshop on Resources and Evaluation for Entity Resolution and Entity\n",
        "Management, lrec2010},\n",
        "  pages =        {19--22},\n",
        "  year =         {2010},\n",
        "  address =      {Valletta, Malta},\n",
        "  month =        {May},\n",
        "  lang =         {EN},\n",
        "  abstract = {\n",
        "Sentiment analysis of business news has become an increasingly popular\n",
        "area of research for both the practitioner and academic. The future\n",
        "financial prospects of companies can be estimated through the aggregation\n",
        "of sentiment over a period of time. The aggregation of sentiment\n",
        "for a specific company is only possible if the company is explicitly\n",
        "mentioned in the news text. In certain instances, news text may refer\n",
        "to groups or collections of companies, for example \"The Automotive\n",
        "Sector\" or \"The Russell Group of Universities\".  Widely available named\n",
        "entity dictionaries will not recognize these groups of companies, and\n",
        "consequently, it may not be possible to assign sentiment attributed\n",
        "to these groups of companies to their individual members. This paper\n",
        "describes a method for identifying groups of companies, which for the\n",
        "purposes of this paper will be known as \"Collective Entities\". The\n",
        "described method is corpus based: it uses linguistic patterns to\n",
        "identify Collective Entity Names, their members and their natural\n",
        "relations with other Collective Entities. The described methodology\n",
        "contains the following steps: 1. Identify and validate seed extraction\n",
        "patterns, 2. Expand seed patterns, 3. Extract and validate Collective\n",
        "Named Entities, 4. Extract related Collective Named Entities, 5. Construct\n",
        "and populate an Ontology and 6. Expand the members of Collective Entity\n",
        "sets with Linked Data. }\n",
        "}\n",
        "\n",
        "@InProceedings{fala2010-triPsi,\n",
        " author =       {João Filipe Machado and José João Almeida and Alberto Simões\n",
        "and Ana Soares},\n",
        " title =        {Automating psycholinguistic statistics computation:\n",
        "Procura-Palavras },\n",
        " year =         {2010},\n",
        " booktitle =    {FALA2010 -- II Iberian SLTech Workshop},\n",
        " editor =       {Carmen Mateo and Francisco Díaz and Francisco Pazó},\n",
        " address =      {Vigo},\n",
        " pages =        {217--220},\n",
        " month =        {November},\n",
        " abstract = {\n",
        "This article describes psycholinguistic lexical databases\n",
        "available in various languages, including English, Spanish and\n",
        "Portuguese. These lexical databases are important for researchers\n",
        "in Psycholinguistics and other related areas, providing\n",
        "a pool of experimental materials and allowing for an efficient\n",
        "process of selection of these experimental materials.\n",
        "The process of gathering statistics is slow, resulting in a\n",
        "small pool of materials in the short-term. The need to find an\n",
        "alternative method to gather limited or yet unavailable statistics\n",
        "for a specific language led us to consider gathering statistics\n",
        "from other languages and to compute their triangulation. Our\n",
        "aim was to automatize the computation of statistics such as\n",
        "Familiarity, Imageability, Age of Acquisition and Written Word\n",
        "Frequency for that specific language.\n",
        "We will describe the process of preparing this data and triangulating and\n",
        "comparing statistics for some languages in an attempt of finding a\n",
        "relationship between them. The results were\n",
        "analysed considering correlations between each statistic in each\n",
        "pair of languages and by computing the mean of absolute differences between\n",
        "each language's values.\n",
        " }\n",
        "}\n",
        "\n",
        "@article{opencert2010,\n",
        "  author    = {Alberto Simões and Nuno Carvalho and José João Almeida},\n",
        "  title     = {Testing as a Certification Approach},\n",
        "  journal   = {Electronic Communications of the EASST},\n",
        "  volume    = {33},\n",
        "  year      = {2010},\n",
        "  editor    = {Luis Barbosa and Antonio Cerone and Siraj Shaikh (Guest Eds.)},\n",
        "  note      = {Foundations and Techniques for Open Source Software Certification},\n",
        "  url       = {http://journal.ub.tu-berlin.de/index.php/eceasst/article/view/458/446}\n",
        "}\n",
        "\n",
        "@Article{p-pal-linguamatica,\n",
        "  author = {Ana Paula Soares and Montserrat Comesaña and Álvaro Iriarte\n",
        "Sanroman and José João Almeida and Alberto Manuel Brandão Simões and Ana Costa,\n",
        "Patrícia Cunha França and João Machado },\n",
        "  title =        {{P-PAL:} {U}ma base lexical com índices psicolinguísticos do\n",
        "{P}ortuguês {E}uropeu},\n",
        "  journal =      {Linguamática},\n",
        "  year =         {2010},\n",
        "  volume =       {2},\n",
        "  number =       {3},\n",
        "  pages =        {67--72},\n",
        "  month =        {December},\n",
        "  issn =         {1647--0818},\n",
        "  url = {http://linguamatica.com/index.php/linguamatica/article/download/80/108},\n",
        "  irreditor =       {Alberto Simões and José João Almeida and Xavier Gómez\n",
        "Guinovart},\n",
        "  abstract = {\n",
        "      Neste trabalho apresentamos o projecto Procura-PALavras (P-PAL)\n",
        "      cujo principal objectivo é desenvolver uma ferramenta\n",
        "      electrónica que disponibilize informação sobre índices\n",
        "      psicolinguísticos objectivos e subjectivos de palavras do\n",
        "      Português Europeu (PE). O P-PAL será disponibilizado\n",
        "      gratuitamente à comunidade científica num formato amigável a\n",
        "      partir de um sítio na Internet a construir para o efeito. Ao\n",
        "      utilizar o P-PAL, o investigador poderá fazer uma utilização\n",
        "      personalizada do programa ao seleccionar, da ampla variedade de\n",
        "      análises oferecidas, os índices que se adequam aos propósitos da\n",
        "      sua investigação e numa dupla funcionalidade de utilização:\n",
        "      pedir ao programa para analisar listas de palavras previamente\n",
        "      constituídas nos índices considerados relevantes para a\n",
        "      investigação ou para obter listas de palavras que obedeçam aos\n",
        "      parâmetros definidos. O P-PAL assume-se assim como uma\n",
        "      ferramenta fundamental à promoção e internacionalização da\n",
        "      investigação em Portugal.\n",
        "  }\n",
        "}\n",
        "\n",
        "%%=============================================== 2011\n",
        "\n",
        "\n",
        "@InProceedings{drury-torgo-almeida:2011:ROBUS,\n",
        "  author    = {Drury, Brett  and  Torgo, Luis  and  J.J. Almeida},\n",
        "  title     = {Guided Self Training for Sentiment Classification},\n",
        "  booktitle = {Proceedings of Workshop on Robust Unsupervised and Semisupervised\n",
        "Methods in Natural Language Processing},\n",
        "  month     = {September},\n",
        "  year      = {2011},\n",
        "  address   = {Hissar, Bulgaria},\n",
        "  pages     = {9--16},\n",
        "  url       = {http://www.aclweb.org/anthology/W11-3902},\n",
        "}\n",
        "\n",
        "@inproceedings{drury1,\n",
        "  title={Classifying News Stories to Estimate the Direction of a Stock Market Index},\n",
        "  author={Brett Drury and Luis Torgo and J.J. Almeida },\n",
        "  booktitle={Third Workshop on Intelligent Systems and Applications (WISA)},\n",
        "  year=2011,\n",
        "  location = {Chaves},\n",
        "  pages = {1-4},\n",
        "}\n",
        "\n",
        "\n",
        "@inproceedings{drury2,\n",
        "  title={ Magellan: An Adaptive Ontology Driven \"breaking Financial News\"\n",
        "Recommender},\n",
        "  author={ Brett Drury and  J.J. Almeida and Helena Morais},\n",
        "  year=2011,\n",
        "  booktitle = {CISTI-2011},\n",
        "  location = {Chaves},\n",
        "}\n",
        "\n",
        "@inproceedings{drury3,\n",
        "  title     = {An Error Correction Methodology for Time Dependent Ontologies},\n",
        "  author={ Brett Drury and  J.J. Almeida and Helena Morais},\n",
        "  booktitle = {{CAiSE} Workshops (ONTOSE)},\n",
        "  year      = {2011},\n",
        "  pages     = {501-512},\n",
        "  ee        = {http://dx.doi.org/10.1007/978-3-642-22056-2_52},\n",
        "  editor    = {Camille Salinesi and Oscar Pastor},\n",
        "  publisher = {Springer},\n",
        "  series    = {Lecture Notes in Business Information Processing},\n",
        "  volume    = {83},\n",
        "  part      = {8},\n",
        "  isbn      = {978-3-642-22055-5},\n",
        "}\n",
        "\n",
        "\n",
        "@inproceedings{nuno1,\n",
        "  title={ Oml: A Scripting Approach For Manipulating Ontologies},\n",
        "  author={ Nuno Carvalho and  Alberto Simões and J.J. Almeida},\n",
        "  booktitle = {CISTI-2011},\n",
        "  location = {Chaves},\n",
        "  year=2011,\n",
        "}\n",
        "\n",
        "@InProceedings{corta2011-pftl,\n",
        "  author    = {Nuno Carvalho and Alberto Simões and José João Almeida and\n",
        "Pedro Rangel Henriques and Maria João Varanda Pereira},\n",
        "  title     = {{PFTL}: A Systematic Approach For Describing Filesystem Tree\n",
        "Processors},\n",
        "  booktitle = {INForum'11 --- Simpósio de Informática (CoRTA2011 track)},\n",
        "  editor    = {Raul Barbosa and Luis Caires},\n",
        "  publisher = {Dep. de Eng. Informática da Universidade de Coimbra},\n",
        "  pages     = {222--233},\n",
        "  isbn      = {978-989-96001-5-7},\n",
        "  address   = {Coimbra, Portugal},\n",
        "  year      = {2011},\n",
        "  month     = {Setembro},\n",
        "  language  = {EN},\n",
        "  pdf={http://ambs.perl-hackers.net/publications/corta2011-pftl.pdf},\n",
        "  abstract  = {  Today, most\n",
        " developers prefer to store information in databases. But\n",
        "  plain filesystems were used for years, and are still used, to store\n",
        "  information, commonly in files of heterogeneous formats that are\n",
        "  organized in directory trees. This approach is a very flexible and\n",
        "  natural way to create hierarchical organized structures of\n",
        "  documents.\n",
        "\n",
        "  We can devise a formal notation to describe a filesystem tree structure,\n",
        "  similar to a grammar, assuming that filenames can be considered terminal\n",
        "  symbols, and directory names non-terminal symbols. This specification\n",
        "  would allow to derive correct language sentences (combination of terminal\n",
        "  symbols) and to associate semantic actions, that can produce arbitrary\n",
        "  side effects, to each valid sentence, just as we do in common parser\n",
        "  generation tools. These specifications can be used to systematically\n",
        "  process files in directory trees, and the final result depends on the\n",
        "  semantic actions associated with each production rule.\n",
        "\n",
        "  In this paper we revamped an old idea of using a domain specific\n",
        "  language to implement these specifications similar to context free\n",
        "  grammars. And introduce some examples of applications that can be\n",
        "  built using this approach.\n",
        "  },\n",
        "}\n",
        "\n",
        "@InProceedings{corta2011-oml,\n",
        "  author    = {Nuno Carvalho and José João Almeida and Alberto Simões},\n",
        "  title     = {Weaving {OML} in a General Purpose Programming Language},\n",
        "  booktitle = {INForum'11 --- Simpósio de Informática (CoRTA2011 track)},\n",
        "  editor    = {Raul Barbosa and Luis Caires},\n",
        "  publisher = {Dep. de Eng. Informática da Universidade de Coimbra},\n",
        "  isbn      = {978-989-96001-5-7},\n",
        "  address   = {Coimbra, Portugal},\n",
        "  pdf       = {http://ambs.perl-hackers.net/publications/corta2011-oml.pdf},\n",
        "  year      = {2011},\n",
        "  month     = {Setembro},\n",
        "  language  = {EN},\n",
        "  pages     = {184--197},\n",
        "  abstract  = {\n",
        "  Most existing programming languages can be categorized as general\n",
        "  purpose programming languages, meaning that they can be used to\n",
        "  implement solutions for any given domain. They are not, in any way,\n",
        "  optimized for a specific set of problems. In contrast, Domain\n",
        "  Specific Languages (DSL) are used to solve specific problems in a\n",
        "  well defined domain. DSL are optimized to a particular set of\n",
        "  problems, but they lack support for a wide range of operations that\n",
        "  are required when dealing with real world problems. So, in a\n",
        "  perfect world, we would like to implement applications using a\n",
        "  general purpose programming language, but use a set of different DSL\n",
        "  to handle specific domains' tasks.\n",
        "\n",
        "  In this paper we describe a DSL named Ontology Manipulation Language\n",
        "  (OML), designed to describe operations over\n",
        "  with ontologies. Programs can be written\n",
        "  using only the OML syntax and be executed independently. OML syntax\n",
        "  was designed to deal with ontologies and the language itself is\n",
        "  optimized to perform these tasks, which means that other relatively\n",
        "  simpler tasks can not be easily done. To overcome this challenge a\n",
        "  mechanism was developed so that you can weave small snippets of OML code\n",
        "  inside Perl programs, meaning we have the power of OML to manipulate\n",
        "  ontologies and, at the same time, all the paraphernalia of modules\n",
        "  that Perl offers to handle everything else.\n",
        "  },\n",
        "}\n",
        "\n",
        "\n",
        "@inproceedings{wims2011,\n",
        "  author    = {Brett Drury and J.J. Almeida},\n",
        "  title     = {Identification of fine grained feature based event and sentiment\n",
        "               phrases from business news stories},\n",
        "  booktitle = {WIMS},\n",
        "  year      = {2011},\n",
        "  pages     = {27--34},\n",
        "  ee        = {http://doi.acm.org/10.1145/1988688.1988720},\n",
        "  editor    = {Rajendra Akerkar},\n",
        "  booktitle_full  = {Proceedings of the International Conference on Web\n",
        "Intelligence, Mining and Semantics, WIMS 2011, Sogndal, Norway, May 25\n",
        "               - 27, 2011},\n",
        "  publisher = {ACM},\n",
        "  isbn      = {978-1-4503-0148-0},\n",
        "  bibsource = {DBLP, http://dblp.uni-trier.de},\n",
        "}\n",
        "\n",
        "@inproceedings{sepln:bookcleaner,\n",
        "  author={ Santos, André and José João Almeida} ,\n",
        "  title = {{Text::Perfide::BookCleaner}, a Perl module to\n",
        "clean and normalize plain text books},\n",
        "  booktitle = {Actas del XXVII Congreso de la Sociedad Española\n",
        "para el Procesamiento del Lenguaje Natural},\n",
        "  year= 2011,\n",
        "  pp={433-441},\n",
        "  location = {Huelva, 5 - 7 Set},\n",
        "  url ={http://natura.di.uminho.pt/~jj/pln/sepln2011-boolcleaner.pdf},\n",
        "}\n",
        "\n",
        "@article{drury4,\n",
        "  author={ Brett Drury and  J.J. Almeida and Helena Morais},\n",
        "  title     = {Construction and maintenance of a fuzzy temporal ontology\n",
        "               from news stories},\n",
        "  journal   = {IJMSO},\n",
        "  journalfull={International Journal of Metadata, Semantics and Ontologies},\n",
        "  volume    = {6},\n",
        "  number    = {3/4},\n",
        "  year      = {2011},\n",
        "  pages     = {219-233},\n",
        "  doi       = {http://dx.doi.org/10.1504/IJMSO.2011.048028},\n",
        "}\n",
        "\n",
        "@InProceedings{xml2pm-xata2011,\n",
        "  author = {Nuno Carvalho and Alberto Simões and José João Almeida},\n",
        "  title  = {xml2pm: A Tool for Automatic Creation of Object Definitions Based\n",
        "on {XML} Instances},\n",
        "  booktitle = {{XATA 2011} --- 9ª Conferência Nacional em XML, Aplicações e\n",
        "Tecnologias Aplicadas },\n",
        "  year = {2011},\n",
        "  pages = {103--114},\n",
        "  isbn = {978-989-96863-1-1},\n",
        "  editor = {Alberto Simões},\n",
        "  month = {1--2 June},\n",
        "  address = {Vila do Conde, Portugal},\n",
        "  pdf={http://ambs.perl-hackers.net/publications/xml2pm-xata2011.pdf},\n",
        "  lang = {EN},\n",
        "  abstract = {\n",
        "The eXtensible Mark-up Language (XML) is probably one of the\n",
        "most popular markup languages available today. It is very typical to find all\n",
        "kind\n",
        "of services or programs representing data in this format. This situation is\n",
        "even\n",
        "more common in web development environments or Service Oriented Architectures\n",
        " (SOA), where data flows from one service to another, being consumed and\n",
        "produced by an heterogeneous set of applications, which sole requirement is to\n",
        "understand XML.\n",
        "\n",
        "This workflow of data represented in XML implies some tasks that applications\n",
        "have to perform if they are required to consume or produce information: the\n",
        "task of parsing an XML document, giving specific semantics to the information\n",
        "parsed, and the task of producing an XML document.\n",
        "\n",
        "Our main goal is to create object definitions that can analyze an XML document\n",
        "and automatically create an object definition that can be used abstractly by\n",
        "the\n",
        "application. These objects are able to parse the XML document and gather all\n",
        "the\n",
        "data required to mimic all the information present in the document.\n",
        "This paper introduces xml2pm, a simple tool that can inspect the structure of\n",
        "an XML document and create an object definition (a Perl module) that stores\n",
        "the\n",
        "same information present in the orinial document, but as a runtime object. We\n",
        "also\n",
        "introduce a simple case of how this approach allows the creation of\n",
        "applications\n",
        "based on Web Services in an elegant and simple way.\n",
        "  }\n",
        "}\n",
        "\n",
        "\n",
        "@article{drury5,\n",
        "  author={ Brett Drury and Luis Torgo and  J.J. Almeida},\n",
        "  title     = {Classifying News Stories with a Constrained Learning Strategy\n",
        "               to Estimate the Direction of a Market Index},\n",
        "  journal_full={International Journal of Computer Science and Applications},\n",
        "  journal   = {IJCSA},\n",
        "  volume    = {9},\n",
        "  number    = {1},\n",
        "  year      = {2012},\n",
        "  pages     = {1-22},\n",
        "  url       = {http://www.tmrfindia.org/ijcsa/v9i11.pdf},\n",
        "  bibsource = {DBLP, http://dblp.uni-trier.de}\n",
        "}\n",
        "\n",
        "@article{da2012,\n",
        "  title = {Dicionário-Aberto -- A Source of Resources for the\n",
        "Portuguese Language Processing},\n",
        "  author = {Alberto Simões and Álvaro Iriarte Sanromán and José João Almeida},\n",
        "  year = 2012,\n",
        "  volume = {7243},\n",
        "  editor = {Helena Caseli and Aline Villavicencio and António Teixeira\n",
        "and Fernando Perdigão},\n",
        "  address = {Coimbra, Portugal},\n",
        "  pages = {121--127},\n",
        "  publisher = {Springer},\n",
        "  month = {April},\n",
        "  journal = {Computational Processing of the Portuguese Language,\n",
        "Lecture Notes for Artificial Intelligence},\n",
        "}\n",
        "\n",
        "\n",
        "@InProceedings{LREC12.967,\n",
        "  author = {André Santos and José João Almeida and Nuno Carvalho},\n",
        "  title = {Structural alignment of plain text books},\n",
        "  booktitle = {Proceedings of the Eight International Conference on Language\n",
        "Resources and Evaluation (LREC'12)},\n",
        "  year = {2012},\n",
        "  month = {may},\n",
        "  date = {23-25},\n",
        "  address = {Istanbul, Turkey},\n",
        "  editor = {Nicoletta Calzolari and others},\n",
        "  publisher = {European Language Resources Association (ELRA)},\n",
        "  isbn = {978-2-9517408-7-7},\n",
        "  language = {english}\n",
        " }\n",
        "\n",
        "@InProceedings{LREC12.611,\n",
        "  author = {Brett Drury and José João Almeida},\n",
        "  title = {The Minho Quotation Resource},\n",
        "  booktitle = {Proceedings of the Eight International Conference on Language\n",
        "Resources and Evaluation (LREC'12)},\n",
        "  year = {2012},\n",
        "  month = {may},\n",
        "  date = {23-25},\n",
        "  address = {Istanbul, Turkey},\n",
        "  editor = {Nicoletta Calzolari and others},\n",
        "  publisher = {European Language Resources Association (ELRA)},\n",
        "  isbn = {978-2-9517408-7-7},\n",
        "  language = {english}\n",
        " }\n",
        "\n",
        "@InProceedings{CAPH12a,\n",
        "  author =    {Nuno Ramos Carvalho and Jose Joao Almeida and Maria\n",
        "João Varanda Pereira and Pedro Rangel Henriques},\n",
        "  title =     {Probabilistic SynSet Based Concept Location},\n",
        "  booktitle = {SLATe'12 --- Symposium on Languages, Applications and Technologies},\n",
        "  irreditor = {Alberto Simões and Ricardo Queirós and Daniela da Cruz},\n",
        "  publisher = {OASIC -- Open Access Series in Informatics, Schloss\n",
        "Dagstuhl - Leibniz-Zentrum für Informatik, Dagstuhl Publishing, Germany},\n",
        "  year =     {2012},\n",
        "  month =     {June},\n",
        "  volume = {21},\n",
        "  pages     = {239-253},\n",
        "  ISSN      = {978-3-939879-40-8},\n",
        "  DOI       = {10.4320/OASIcs.SLATE.2012.I},\n",
        "  abstract  = {Concept location is a common task in program comprehension\n",
        "  techniques, essential in many approaches used for software care and\n",
        "  software evolution. An important goal of this process is to discover\n",
        "  a mapping between source code and human oriented concepts.\n",
        "\n",
        "  Although programs are written in a strict and formal language, natural\n",
        "  language terms and sentences like identifiers (variables or functions\n",
        "  names), constant strings or comments, can still be found embedded in\n",
        "  programs. Using terminology concepts and natural language processing\n",
        "  techniques these terms can be exploited to discover clues about which\n",
        "  real world concepts source code is addressing.\n",
        "\n",
        "  This work extends symbol tables build by compilers with ontology\n",
        "  driven constructs, extends synonym sets defined by linguistics, with\n",
        "  automatically created Probabilistic SynSets from software\n",
        "  domain parallel corpora. And using a relational algebra, creates\n",
        "  semantic bridges between program elements and human oriented concepts,\n",
        "  to enhance concept location tasks.}\n",
        "}\n",
        "\n",
        "\n",
        "@article{wikiscore,\n",
        "  title={{Wiki::Score} A collaborative environment for music transcription and\n",
        "  publishing},\n",
        "  author={J.J. Almeida and Nuno Ramos Carvalho and José Nuno Oliveira},\n",
        "  journal_small={ISU},\n",
        "  journal={Information, Services and Use (ISU)},\n",
        "  volume={31},\n",
        "  number={3-4/2011},\n",
        "  year={2012},\n",
        "  pages={177--187},\n",
        "  ee={DOI\t10.3233/ISU-2012-0647},\n",
        "  publisher={IOS Press},\n",
        "  ISSN={0167-5265 (Print) 1875-8789 (Online)},\n",
        "  comment={elpub 2012},\n",
        "}\n",
        "\n",
        "@InProceedings{flapp,\n",
        "  author =  {Alberto Simões and Nuno Ramos Carvalho and José João Almeida},\n",
        "  title =   {{Generating flex Lexical Scanners for Perl Parse::Yapp}},\n",
        "  booktitle =   {1st Symposium on Languages, Applications and Technologies },\n",
        "  pages =   {41--50},\n",
        "  series =  {OpenAccess Series in Informatics (OASIcs)},\n",
        "  ISBN =    {978-3-939897-40-8},\n",
        "  ISSN =    {2190-6807},\n",
        "  idx = {DBLP},\n",
        "  year =    {2012},\n",
        "  volume =  {21},\n",
        "  irreditor =  {Alberto Simões and Ricardo Queirós and Daniela da Cruz},\n",
        "  publisher =   {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},\n",
        "  address = {Dagstuhl, Germany},\n",
        "  url =     {http://drops.dagstuhl.de/opus/volltexte/2012/3513},\n",
        "  doi =     {http://dx.doi.org/10.4230/OASIcs.SLATE.2012.41},\n",
        "abstract = {\n",
        "Perl is known for its versatile regular expressions. Nevertheless, using Perl regular\n",
        "expressions for creating fast lexical analyzer is not easy. As an alternative, the authors\n",
        "defend the automated generation of the lexical analyzer in a well known fast application\n",
        "(flex) based on a simple Perl definition in the syntactic analyzer. In this paper we\n",
        "extend the syntax used by Parse::Yapp, one of the most used parser generators for Perl,\n",
        "making the automatic generation of flex lexical scanners possible. We explain how this is\n",
        "performed and conclude with some benchmarks that show the relevance of the approach.\n",
        "}\n",
        "}\n",
        "\n",
        "\n",
        "@inproceedings{DBLP:conf/slate/DruryA12,\n",
        "  author    = {Brett Drury and José João Almeida},\n",
        "  title     = {Predicting Market Direction from Direct Speech by Business\n",
        "               Leaders},\n",
        "  booktitle = {SLATE},\n",
        "  publisher = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik},\n",
        "  series    = {OASICS},\n",
        "  year      = {2012},\n",
        "  volume    = {21},\n",
        "  pages     = {163-172},\n",
        "  doi       = {http://dx.doi.org/10.4230/OASIcs.SLATE.2012.163},\n",
        "  irreditor    = {Alberto Sim{\\~o}es and\n",
        "               Ricardo Queir{\\'o}s and\n",
        "               Daniela Carneiro da Cruz},\n",
        "  bibsource = {DBLP, http://dblp.uni-trier.de}\n",
        "}\n",
        "\n",
        "\n",
        "%%=================================== 2013\n",
        "\n",
        "@inproceedings{ptd2013,\n",
        " title={Defining a Probabilistic Translation Dictionaries Algebra},\n",
        " Author={ Alberto Simões and José João Almeida and Nuno Ramos Carvalho},\n",
        " Booktitle={ XVI Portuguese Conference on Artificial Inteligence - EPIA},\n",
        " Year= 2013,\n",
        " Month={ September},\n",
        " pages={444--455},\n",
        " irreditor = {Luís Correia and Luís Paulo Reis and José Cascalho and Luís\n",
        "Gomes and Hélia Guerra and Pedro Cardoso},\n",
        " address = {Angra do Heroismo, Azores},\n",
        " url = {http://natura.di.uminho.pt/~jj/bib/ptd-algebra.pdf},\n",
        "}\n",
        "\n",
        "\n",
        "@inproceedings{algarve-cross2013,\n",
        " title={Open Source Software Documentation Mining for Quality Assessment},\n",
        " Year={ 2013},\n",
        " Isbn={ 978-3-642-36980-3},\n",
        " Booktitle={ Advances in Information Systems and Technologies},\n",
        " Volume={ 206},\n",
        " Series={ Advances in Intelligent Systems and Computing},\n",
        " Editor={ Rocha, Álvaro and Correia, Ana Maria and Wilson, Tom and Stroetmann,\n",
        "Karl A.},\n",
        " Publisher={ Springer Berlin Heidelberg},\n",
        " Author={ Nuno Ramos Carvalho and Alberto Simões and José João Almeida},\n",
        " Pages={785--794},\n",
        " Abstract={ Besides source code, the fundamental source of information about Open Source\n",
        "Software lies in documentation, and other non source code files, like README,\n",
        "INSTALL, or HowTo files, commonly available in the software ecosystem. These\n",
        "documents, written in natural language, provide valuable information during the\n",
        "software development stage, but also in future maintenance and evolution tasks.\n",
        "DMOSS is a toolkit designed to systematically assess the quality of non source\n",
        "code text found in software packages. The toolkit handles a package as an\n",
        "attribute tree, and performs several tree traverse algorithms through a set of\n",
        "plugins, specialized in retrieving specific metrics from text, gathering\n",
        "information about the software. These metrics are later used to infer knowledge\n",
        "about the software, and composed together to build reports that assess the\n",
        "quality of specific features of the software. This paper discusses the\n",
        "motivations for this work, continues with a description of the toolkit\n",
        "implementation and design goals. Follows an example of its usage to process a\n",
        "software package, and the produced report. Finally some final remarks and\n",
        "trends for future work are presented.},\n",
        " url={http://alfarrabio.di.uminho.pt/~albie/publications/wcist2012-dmoss.pdf },\n",
        "}\n",
        "\n",
        "\n",
        "@inproceedings{algarve2013,\n",
        "  title={Evaluating Web Site Structure Based on Navigation Profiles and Site Topology},\n",
        "  Author={Alberto Simões and Anália Lourenço and José João Almeida},\n",
        "  Year={ 2013},\n",
        "  Isbn={ 978-3-642-36980-3},\n",
        "  Booktitle={ Advances in Information Systems and Technologies},\n",
        "  Volume={ 206},\n",
        "  Series={ Advances in Intelligent Systems and Computing},\n",
        "  Editor={ Rocha, Álvaro and Correia, Ana Maria and Wilson, Tom and Stroetmann,\n",
        "Karl A.},\n",
        "  Publisher={ Springer Berlin Heidelberg},\n",
        "  Pages={ 305-311},\n",
        "  Abstract={ This work aims at pointing out the benefits of a topology-oriented\n",
        "wide scope, but differentiated, profile analysis. The goal was to conciliate\n",
        "advanced common website usage profiling techniques with the analysis of the\n",
        "website's topology information, outputting valuable knowledge in an intuitive\n",
        "and comprehensible way. Server load balancing, crawler activity evaluation and\n",
        "Web site restructuring are the primary analysis concerns and, in this regard,\n",
        "experiments over six month data of a real-world Web site were considered\n",
        "successful. },\n",
        "  url={http://alfarrabio.di.uminho.pt/~albie/publications/wcist2012-webtopology.pdf},\n",
        "}\n",
        "\n",
        "@inproceedings{Passarola2013,\n",
        "  title={PASSAROLA: High-Order Exercise Generation },\n",
        "  author={J.João Almeida and Isabel Araújo and  Irene Brito and Nuno Carvalho and\n",
        "            Gaspar J. Machado and Rui M.S. Pereira and Georgi Smirnov},\n",
        "  year=2013,\n",
        "  booktitle = {CISTI-2013},\n",
        "  location = {Lisboa},\n",
        "  pages = { 763--768},\n",
        "  url = \"http://natura.di.uminho.pt/~jj/bib/passarola-cisti2013.pdf\",\n",
        "  abstract={In order to be robust and achieve multi-domain\n",
        "coverage, exercise generation systems usually work with answers\n",
        "of simple types (e.g. multiple-choice, Boolean, integer, or file\n",
        "comparison). In this paper we describe an exercise generation\n",
        "system PASSAROLA, a simple, yet powerful, language that anyone\n",
        "with no computer science background, can use to develop\n",
        "exercises, that include a collection of heterogeneous objects, and\n",
        "allows the usage of complex elements. Its main characteristic\n",
        "features are the use of simple reusable templates, simple and rich\n",
        "types, rich notation and syntax (LaTeX based) for questions,\n",
        "solutions, and answers, transformations and calculations,\n",
        "external calculators.},\n",
        "}\n",
        "\n",
        "@inproceedings{ticames2013,\n",
        "  title={Math exercise generation and smart assessment},\n",
        "  author={J.João Almeida and Isabel Araújo and  Irene Brito and Nuno Carvalho and\n",
        "            Gaspar J. Machado and Rui M.S. Pereira and Georgi Smirnov},\n",
        "  year=2013,\n",
        "  booktitle = {Workshop of TICAMES (Information and Communication Technology in\n",
        "     Higher Education: Learning Mathematics), CISTI-2013},\n",
        "  location = {Lisboa},\n",
        "  pages = { 1014--1019},\n",
        "  url = \"http://natura.di.uminho.pt/~jj/bib/passarola-ticames2013.pdf\",\n",
        "  abstract={In this paper we concentrate on the field of\n",
        "mathematics education where the aim is to generate exercises\n",
        "going beyond those with answers of simple types (e.g. multiple-choice,\n",
        "Boolean, integer, or file comparison). We present three\n",
        "examples from introductory college mathematics and emphasize\n",
        "the key points that should be taken into account in order to\n",
        "develop a \"well-posed\" exercise together with its verification. All\n",
        "the presented examples were implemented in the system},\n",
        "}\n",
        "\n",
        "@inproceedings{crossportal,\n",
        "  author    = {Pedro Martins and\n",
        "               Nuno Ramos Carvalho and\n",
        "               João Paulo Fernandes and\n",
        "               José João Almeida and\n",
        "               João Saraiva},\n",
        "  title     = {A Framework for Modular and Customizable Software Analysis},\n",
        "  booktitle = {ICCSA (2)},\n",
        "  year      = {2013},\n",
        "  pages     = {443-458},\n",
        "  doi        = {http://dx.doi.org/10.1007/978-3-642-39643-4_32},\n",
        "  offcrossref  = {DBLP:conf/iccsa/2013-2},\n",
        "  bibsource = {DBLP, http://dblp.uni-trier.de},\n",
        "  editor    = {Beniamino Murgante and others},\n",
        "  irrbooktitle = {Computational Science and Its Applications - ICCSA 2013\n",
        "               - 13th International Conference, Ho Chi Minh City, Vietnam,\n",
        "               June 24-27, 2013, Proceedings, Part II},\n",
        "  booktitle = {ICCSA (2)},\n",
        "  publisher = {Springer},\n",
        "  series    = {Lecture Notes in Computer Science},\n",
        "  volume    = {7972},\n",
        "  isbn      = {978-3-642-39642-7},\n",
        "  ee        = {http://dx.doi.org/10.1007/978-3-642-39643-4},\n",
        "}\n",
        "\n",
        "@inproceedings{icaicte13,\n",
        "  title = {Exercise generation with the system Passarola},\n",
        "  booktitle={ICAICTE-13, Advances in Intelligent Systems Research},\n",
        "  isbn={ 978-90786-77-79-6},\n",
        "  issn={ 1951-6851},\n",
        "  doi={doi:10.2991/icaicte.2013.64},\n",
        "  url={http://natura.di.uminho.pt/~jj/bib/ecaicte2013.pdf},\n",
        "  author={José João Almeida and Isabel Araújo and Irene Brito and Nuno Carvalho and Gaspar J.\n",
        "    Machado and  Rui M. S.  Pereira and  Georgi Smirnov},\n",
        "  year={2013},\n",
        "  keywords={ Passarola, exercise generation system, self-regulating study},\n",
        "  abstract={ A robust multi-domain coverage exercise generation system\n",
        "usually works with an-swers of simple types (e.g. multiple-choice,\n",
        "Boolean, integer, or file compari-son). In this paper we describe\n",
        "Passarola, a simple, yet powerful, exercise genera-tion system and its\n",
        "language that anyone with no computer science background can use to\n",
        "develop exercises. It may include a collection of heterogeneous objects\n",
        "allowing the usage of complex elements. Its main characteristics are the\n",
        "use of simple reusable templates, simple and rich types, and rich notation\n",
        "and syntax (LaTeX based) for questions, solutions, and answers.},\n",
        "}\n",
        "\n",
        "@inproceedings{slate/AzevedoA13,\n",
        "  author    = {Bruno M. Azevedo and\n",
        "               José João Almeida},\n",
        "  title     = {ABC with a UNIX Flavor},\n",
        "  s_booktitle = {SLATE},\n",
        "  year      = {2013},\n",
        "  pages     = {203-218},\n",
        "  doi       = {http://dx.doi.org/10.4230/OASIcs.SLATE.2013.203},\n",
        "  url       = {http://drops.dagstuhl.de/opus/volltexte/2013/4039/pdf/14.pdf},\n",
        "  irreditor  = {José Paulo Leal and\n",
        "               Ricardo Rocha and\n",
        "               Alberto Simões},\n",
        "  booktitle = {2nd Symposium on Languages, Applications and Technologies,\n",
        "               SLATE 2013, June 20-21, 2013 - Porto, Portugal},\n",
        "  publisher = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik},\n",
        "  series    = {OASICS},\n",
        "  volume    = {29},\n",
        "  year      = {2013},\n",
        "  isbn      = {978-3-939897-52-1},\n",
        "  bibsource = {DBLP, http://dblp.uni-trier.de},\n",
        "  abstract  = {\n",
        "ABC is a simple, yet powerful, textual musical notation.\n",
        "This paper presents ABC::DT, a rule-based domain-specific\n",
        "language (Perl embedded), designed to simplify the\n",
        "creation of ABC processing tools. Inspired by the Unix philosophy,\n",
        "those tools intend to be simple and compositional in a Unix filters' way.\n",
        "From ABC::DT's rules we obtain an ABC processing tools whose main\n",
        "algorithm follows a traditional compiler architecture, thus consisting of\n",
        "three stages:\n",
        "1) ABC parser (based on abcmtops parser),\n",
        "2) ABC semantic transformation (associated with ABC attributes),\n",
        "3) output generation (either a user defined or system provided ABC generator).\n",
        "  },\n",
        "}\n",
        "\n",
        "@article{escolex2013,\n",
        "  author = { Soares, Ana Paula and José Carlos Medeiros and Alberto Simões\n",
        "    and João Machado and Ana Costa and Álvaro Iriarte and José João Almeida\n",
        "    and Ana P. Pinheiro and and Montserrat Comesaña},\n",
        "  year = 2013,\n",
        "  title = { Escolex: A grade-level lexical database from european portuguese\n",
        "      elementary to middle school textbooks.},\n",
        "  journal = {Behavior Research Methods},\n",
        "  pages = {1--14},\n",
        "  url = {http://p-pal.di.uminho.pt/static/files/db/Soares_et_al.__in_press_ESCOLEX.pdf},\n",
        "  abstract = {\n",
        "In this article, we introduce ESCOLEX, the first European Portuguese children's\n",
        "lexical database with grade-level-adjusted word frequency statistics. Computed\n",
        "from a 3.2-million-word corpus, ESCOLEX provides 48,381 word forms extracted\n",
        "from 171 elementary and middle school textbooks for 6- to 11-year-old children\n",
        "attendin' the first six grades in the Portuguese educational system. Like other\n",
        "children's grade-level databases, ESCOLEX provides four frequency indices for\n",
        "each grade: overall word frequency (F), index of dispersion across the selected\n",
        "textbooks (D), estimated frequency per million words (U), and standard\n",
        "frequency index (SFI). It also provides a new measure, contextual diversity\n",
        "(CD). In addition, the number of letters in the word and its part(s) of speech,\n",
        "number of syllables, syllable structure, and adult frequencies taken from P-PAL\n",
        "(a European Portuguese corpus-based lexical database) are provided. ESCOLEX\n",
        "will be a useful tool both for researchers interested in language processing\n",
        "and development and for professionals in need of verbal materials adjusted to\n",
        "children's developmental stages. ESCOLEX can be downloaded along with this\n",
        "article or from http://p-pal.di.uminho.pt/about/databases.\n",
        "  },\n",
        "}\n",
        "\n",
        "\n",
        "@inproceedings{coloquiosOutono2013,\n",
        "  author    = {José João Almeida and Sílvia Araújo and Idalete Dias and Ana Correio},\n",
        "  title     = {{Per-fide}: Projecto de compilação de um corpus multilingue},\n",
        "  booktitle = {Humanidades: Novos Paradigmas do Conhecimento e da Investigação,\n",
        "               XIV Colóquio de Outono},\n",
        "  year      = {2013},\n",
        "  pages     = {323--339},\n",
        "  editor  = {Ana Gabriela Macedo and\n",
        "             Carlos Mendes de Sousa and\n",
        "             Vitor Moura},\n",
        "  publisher = {húmus, Universidade do Minho},\n",
        "}\n",
        "\n",
        "%%=================================== 2014\n",
        "\n",
        "@incollection{sardinha2014,\n",
        "    author = { José João Almeida and Sílvia Araújo and Nuno Carvalho and\n",
        "        Idalete Dias and Ana Oliveira and André Santos and Alberto Simões},\n",
        "    title = {The {Per-Fide} Corpus: A New Resource for Corpus-Based Terminology,\n",
        "Contrastive Linguistics and Translation Studies},\n",
        "    booktitle = {Working with Portuguese Corpora},\n",
        "    publisher = {Bloomsbury Publishing},\n",
        "    year = {2014},\n",
        "    editor = {Tony Berber Sardinha and Telma São-Bento Ferreira},\n",
        "    url={http://ambs.perl-hackers.net/publications/perfide_ch9_sardinha.pdf},\n",
        "    month = {April},\n",
        "    chapter = {9},\n",
        "    pages = {177--200},\n",
        "    isbn = {978-1441190505},\n",
        "}\n",
        "\n",
        "@article{SOARES2014,\n",
        "   title = {{Procura-PALavras (P-Pal): uma nova medida de frequência lexical do português europeu contemporâneo}},\n",
        "   journal = {{Psicologia: Reflexão e Crítica}},\n",
        "   author={Soares, Ana Paula and Iriarte, Álvaro and Almeida, José João\n",
        "and Simões, Alberto and Costa, Ana and França, Patricia and Machado, João and\n",
        "Comesaña, Montserrat},\n",
        "   ISSN = {0102-7972},\n",
        "   language = {pt},\n",
        "   url = {http://www.scielo.br/scielo.php?script=sci_arttext&pid=S0102-79722014000100013&nrm=iso},\n",
        "   volume = {27},\n",
        "   year = {2014},\n",
        "   month = {03},\n",
        "   pages = {110 - 123},\n",
        "   publisher = {scielo},\n",
        "   off_crossref = {10.1590/S0102-79722014000100013},\n",
        "}\n",
        "\n",
        "@article{ppal2014,\n",
        "    title = {Procura-PALavras (P-PAL): A new measure\n",
        "of word frequency for contemporary European Portuguese | Procura-PALavras\n",
        "(P-PAL): Uma nova medida de frequência lexical do Português Europeu\n",
        "contemporâneo},\n",
        "    journal = {{Psicologia: Reflexao e Critica}},\n",
        "    year = {2014},\n",
        "    volume = {27},\n",
        "    number = {1},\n",
        "    pages = {110-123},\n",
        "    author = {Soares, A.P. and Iriarte, A. and Almeida, J.J.\n",
        "       and Simões, A. and Costa, A. and França, P.\n",
        "       and Machado, J. and Comesaña, M.},\n",
        "    doi = {10.1590/S0102-79722014000100013},\n",
        "    EID = {2-s2.0-84902185491},\n",
        "}\n",
        "\n",
        "@article{conclave-iccsa2104,\n",
        "  author =\t{Nuno Ramos Carvalho and José João Almeida and Maria\n",
        "João Varanda Pereira and Pedro Rangel Henriques},\n",
        "  title =\t{{Conclave: Ontology-driven measurement of semantic relatedness\n",
        "between source code elements and problem domain concepts}},\n",
        "  journal = {Lecture Notes in Computer Science (including subseries Lecture\n",
        "Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},\n",
        "  offbooktitle = {14th International Conference on Computational Science and its\n",
        "     Applications, ICCSA 2014; Guimaraes; Portugal},\n",
        "  pages =\t{116-131},\n",
        "  year =\t{2014},\n",
        "  volume =\t{8584 LNCS},\n",
        "  number = {PART 6},\n",
        "  publisher =\t{Springer Verlag},\n",
        "  address =\t{},\n",
        "  ISBN =\t{978-331909152-5},\n",
        "  doi =\t{10.1007/978-3-319-09153-2_9},\n",
        "  annote =\t{Document Type: Conference Paper; SCOPUS}\n",
        "}\n",
        "\n",
        "@article{comsys-dmoss,\n",
        "  author = {Carvalho, N. R. and Simões, A. and  Almeida, J. J.},\n",
        "  title = {{DMOSS}: Open Source Software Documentation Assessment},\n",
        "  journal = {Computer Science and Information Systems},\n",
        "  volume = 11,\n",
        "  number = 4,\n",
        "  year = 2014,\n",
        "  pages = {1191-1207},\n",
        "  abstract = {Besides source code, the fundamental source of information\n",
        "   about open source software lies in documentation, and other non source\n",
        "   code files, like README, INSTALL, or How-To files, commonly available in\n",
        "   the software ecosystem. These documents, written in natural language,\n",
        "   provide valuable information during the software development stage,\n",
        "   but also in future maintenance and evolution tasks. DMOSS3 is a toolkit\n",
        "   designed to systematically assess the quality of non source code content\n",
        "   found in software packages. The toolkit handles a package as an attribute\n",
        "   tree, and performs several tree traverse algorithms through a set of\n",
        "   plugins, specialized in retrieving specific metrics from text, gathering\n",
        "   information about the software. These metrics are later used to infer\n",
        "   knowledge about the software, and composed together to build reports\n",
        "   that assess the quality of specific features. This paper discusses the\n",
        "   motivations for this work, continues with a description of the toolkit\n",
        "   implementation and design goals. This is followed by an example of its\n",
        "   usage to process a software package, and the produced report.},\n",
        "  url = {http://www.comsis.org/archive.php?show=pprwc110-1308},\n",
        "}\n",
        "\n",
        "%% ver 2015\n",
        "@article{jss-Carvalho2014,\n",
        "  author = \"Nuno Ramos Carvalho and José João Almeida and Pedro Rangel Henriques\n",
        "      and Maria João Varanda\",\n",
        "  title = {From source code identifiers to natural language terms},\n",
        "  journal = \"Journal of Systems and Software \",\n",
        "  volume = \"\",\n",
        "  number = \"0\",\n",
        "  year = \"2014\",\n",
        "  issn = \"0164-1212\",\n",
        "  doi = \"http://dx.doi.org/10.1016/j.jss.2014.10.013\",\n",
        "  url = \"http://www.sciencedirect.com/science/article/pii/S0164121214002179\",\n",
        "  keywords = \"Program comprehension\",\n",
        "  keywords = \"Natural language processing\",\n",
        "  keywords = \"Identifier splitting \",\n",
        "  abstract = \"Abstract Program comprehension techniques often explore program\n",
        "    identifiers, to infer knowledge about programs. The relevance of source code\n",
        "    identifiers as one relevant source of information about programs is already\n",
        "    established in the literature, as well as their direct impact on future\n",
        "    comprehension tasks. Most programming languages enforce some constrains on\n",
        "    identifiers strings (e.g., white spaces or commas are not allowed). Also,\n",
        "    programmers often use word combinations and abbreviations, to devise strings\n",
        "    that represent single, or multiple, domain concepts in order to increase\n",
        "    programming linguistic efficiency (convey more semantics writing less). These\n",
        "    strings do not always use explicit marks to distinguish the terms used (e.g.,\n",
        "    CamelCase or underscores), so techniques often referred as hard splitting are\n",
        "    not enough. This paper introduces Lingua::IdSplitter a dictionary based\n",
        "    algorithm for splitting and expanding strings that compose multi-term\n",
        "    identifiers. It explores the use of general programming and abbreviations\n",
        "    dictionaries, but also a custom dictionary automatically generated from\n",
        "    software natural language content, prone to include application domain terms\n",
        "    and specific abbreviations. This approach was applied to two software packages,\n",
        "    written in C, achieving a f-measure of around 90% for correctly splitting and\n",
        "    expanding identifiers. A comparison with current state-of-the-art approaches is\n",
        "    also presented. \"\n",
        "}\n",
        "\n",
        "@InProceedings{conclave-slate2014,\n",
        "  author =\t{Nuno Ramos Carvalho and José João Almeida and\n",
        "             Maria João Varanda Pereira and Pedro Rangel Henriques},\n",
        "  title =\t{{Conclave: Writing Programs to Understand Programs}},\n",
        "  booktitle =\t{3rd Symposium on Languages, Applications and Technologies},\n",
        "  pages =\t{19--34},\n",
        "  series =\t{OpenAccess Series in Informatics (OASIcs)},\n",
        "  ISBN =\t{978-3-939897-68-2},\n",
        "  ISSN =\t{2190-6807},\n",
        "  year =\t{2014},\n",
        "  volume =\t{38},\n",
        "  irreditor =\t{Maria João Varanda Pereira and José Paulo Leal and Alberto Simões},\n",
        "  publisher =\t{Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},\n",
        "  address =\t{Dagstuhl, Germany},\n",
        "  URL =\t{http://drops.dagstuhl.de/opus/volltexte/2014/4556},\n",
        "  URN =\t{urn:nbn:de:0030-drops-45561},\n",
        "  doi =\t{http://dx.doi.org/10.4230/OASIcs.SLATE.2014.19},\n",
        "  annote =\t{Keywords: software maintenance, software evolution, program comprehension, feature location, concept location, natural language processing}\n",
        "}\n",
        "\n",
        "@inproceedings{DBLP:conf/slate/BritoA14,\n",
        "  author    = {Rui Brito and\n",
        "               José João Almeida},\n",
        "  title     = {A Workflow Description Language to Orchestrate Multi-Lingual Resources},\n",
        "  booktitle = {3rd Symposium on Languages, Applications and Technologies, {SLATE}\n",
        "               2014, June 19-20, 2014 - Bragança, Portugal},\n",
        "  pages     = {77--83},\n",
        "  year      = {2014},\n",
        "  url       = {http://dx.doi.org/10.4230/OASIcs.SLATE.2014.77},\n",
        "  doi       = {10.4230/OASIcs.SLATE.2014.77},\n",
        "  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/slate/BritoA14},\n",
        "  irreditor    = {Maria João Varanda Pereira and\n",
        "               José Paulo Leal and\n",
        "               Alberto Simões},\n",
        "  series    = {{OASICS}},\n",
        "  volume    = {38},\n",
        "  publisher = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik},\n",
        "  isbn      = {978-3-939897-68-2},\n",
        "}\n",
        "\n",
        "\n",
        "@inproceedings{DBLP:conf/slate/SimoesAB14,\n",
        "  author    = {Alberto Simões and\n",
        "               José João Almeida and\n",
        "               Simon D. Byers},\n",
        "  title     = {Language Identification: a Neural Network Approach},\n",
        "  booktitle = {3rd Symposium on Languages, Applications and Technologies, {SLATE}\n",
        "               2014, June 19-20, 2014 - Bragança, Portugal},\n",
        "  pages     = {251--265},\n",
        "  year      = {2014},\n",
        "  url       = {http://dx.doi.org/10.4230/OASIcs.SLATE.2014.251},\n",
        "  doi       = {10.4230/OASIcs.SLATE.2014.251},\n",
        "  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/slate/SimoesAB14},\n",
        "  irreditor    = {Maria João Varanda Pereira and\n",
        "               José Paulo Leal and\n",
        "               Alberto Simões},\n",
        "  series    = {{OASICS}},\n",
        "  volume    = {38},\n",
        "  publisher = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik},\n",
        "  isbn      = {978-3-939897-68-2},\n",
        "}\n",
        "\n",
        "@inproceedings{DBLP:conf/slate/CarvalhoA14,\n",
        "  author    = {Pedro Carvalho and\n",
        "               José João Almeida},\n",
        "  title     = {MLT-prealigner: a Tool for Multilingual Text Alignment},\n",
        "  booktitle = {3rd Symposium on Languages, Applications and Technologies, {SLATE}\n",
        "               2014, June 19-20, 2014 - Bragança, Portugal},\n",
        "  pages     = {283--290},\n",
        "  year      = {2014},\n",
        "  url       = {http://dx.doi.org/10.4230/OASIcs.SLATE.2014.283},\n",
        "  doi       = {10.4230/OASIcs.SLATE.2014.283},\n",
        "  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/slate/CarvalhoA14},\n",
        "  irreditor    = {Maria João Varanda Pereira and\n",
        "               José Paulo Leal and\n",
        "               Alberto Simões},\n",
        "  series    = {{OASICS}},\n",
        "  volume    = {38},\n",
        "  publisher = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik},\n",
        "  isbn      = {978-3-939897-68-2},\n",
        "}\n",
        "\n",
        "\n",
        "@InProceedings{tmxa,\n",
        "  author =       {Rui Brito and José João Almeida and Alberto Simões},\n",
        "  title =        {Processing Annotated {TMX} Parallel Corpora},\n",
        "  booktitle =    {IberSpeech 2014 --- VIII Jornadas en Tecnologías del Habla and IV Iberian SLTech Workshop},\n",
        "  year =         {2014},\n",
        "  month =        {November},\n",
        "  address =      {Las Palmas de Gran Canaria, Spain},\n",
        "  pages  =       {188--197},\n",
        "  abstract =     {    In the later years the amount of freely available multilingual\n",
        "      corpora has grown in an exponential way. Unfortunately the way these\n",
        "      corpora are made available is very diverse, ranging from simple text\n",
        "      files or specific XML schemas to supposedly standard formats like\n",
        "      the XML Corpus Encoding Initiative, the Text Encoding Initiative, or\n",
        "      even the Translation Memory Exchange formats.\n",
        "      In this document we defend the usage of Translation Memory Exchange\n",
        "      documents, but we enrich its structure in order to support the\n",
        "      annotation of the documents with different information like lemmas,\n",
        "      multi-words or entities.\n",
        "      To support the adoption of the proposed formats, we present a set of\n",
        "      tools to manipulate the different formats in an agile way.},\n",
        "   url= {http://ambs.perl-hackers.net/publications/tmxa.pdf},\n",
        "}\n",
        "\n",
        "%%========================= 2015\n",
        "\n",
        "@article{jss-CarvalhoAHP15,\n",
        "  author    = {Nuno Ramos Carvalho and\n",
        "               Jos{\\'{e}} Jo{\\~{a}}o Almeida and\n",
        "               Pedro Rangel Henriques and\n",
        "               Maria Jo{\\~{a}}o Varanda Pereira},\n",
        "  title     = {From source code identifiers to natural language terms},\n",
        "  journal   = {Journal of Systems and Software},\n",
        "  volume    = {100},\n",
        "  pages     = {117--128},\n",
        "  year      = {2015},\n",
        "  url       = {http://dx.doi.org/10.1016/j.jss.2014.10.013},\n",
        "  doi       = {10.1016/j.jss.2014.10.013},\n",
        "  timestamp = {Mon, 22 Dec 2014 09:51:10 +0100},\n",
        "  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/jss/CarvalhoAHP15},\n",
        "  bibsource = {dblp computer science bibliography, http://dblp.org},\n",
        "  keywords = \"Program comprehension\",\n",
        "  keywords = \"Natural language processing\",\n",
        "  keywords = \"Identifier splitting \",\n",
        "  abstract = \"Abstract Program comprehension techniques often explore program\n",
        "    identifiers, to infer knowledge about programs. The relevance of source code\n",
        "    identifiers as one relevant source of information about programs is already\n",
        "    established in the literature, as well as their direct impact on future\n",
        "    comprehension tasks. Most programming languages enforce some constrains on\n",
        "    identifiers strings (e.g., white spaces or commas are not allowed). Also,\n",
        "    programmers often use word combinations and abbreviations, to devise strings\n",
        "    that represent single, or multiple, domain concepts in order to increase\n",
        "    programming linguistic efficiency (convey more semantics writing less). These\n",
        "    strings do not always use explicit marks to distinguish the terms used (e.g.,\n",
        "    CamelCase or underscores), so techniques often referred as hard splitting are\n",
        "    not enough. This paper introduces Lingua::IdSplitter a dictionary based\n",
        "    algorithm for splitting and expanding strings that compose multi-term\n",
        "    identifiers. It explores the use of general programming and abbreviations\n",
        "    dictionaries, but also a custom dictionary automatically generated from\n",
        "    software natural language content, prone to include application domain terms\n",
        "    and specific abbreviations. This approach was applied to two software packages,\n",
        "    written in C, achieving a f-measure of around 90% for correctly splitting and\n",
        "    expanding identifiers. A comparison with current state-of-the-art approaches is\n",
        "    also presented. \"\n",
        "}\n",
        "\n",
        "@article { acores-wordcist2015,\n",
        "   title = {New algorithms for smart assessment of math exercises},\n",
        "   journal = {Advances in Intelligent Systems and Computing},\n",
        "   year = {2015},\n",
        "   volume = {353},\n",
        "   pages = {1221-1230},\n",
        "   author = {Araújo, I. and Brito, I. and Machado, G.J. and Pereira, R.M.S.\n",
        "        and Almeida, J.J. and Smirnov, G.},\n",
        "\n",
        "}\n",
        "\n",
        "@inproceedings{ cisti-almeida2015,\n",
        "   title = {Gröbner bases and mathematical exercises generation with nondetermined structure},\n",
        "   titlept= { Bases de Gröbner e geração de exercícios matemáticos com estrutura não determinada},\n",
        "   booktitle = {2015 10th Iberian Conference on Information Systems and Technologies,\n",
        "            CISTI 2015},\n",
        "   year = {2015},\n",
        "   author = {Araújo, I. and Smirnov, G. and Almeida, J.J.},\n",
        "   url={http://www.scopus.com/inward/record.url?eid=2-s2.0-84943328958&partnerID=MN8TOARS},\n",
        "}\n",
        "\n",
        "@article { subtitles2015,\n",
        "   title = {On the advantages of word frequency and contextual\n",
        "      diversity measures extracted from subtitles: The case of Portuguese},\n",
        "   journal = {Quarterly Journal of Experimental Psychology},\n",
        "   year = {2015},\n",
        "   volume = {68},\n",
        "   number = {4},\n",
        "   pages = {680-696},\n",
        "   author = {Soares, A.P. and Machado, J. and Costa, A. and Iriarte, Á.\n",
        "      and Simões, A. and Almeida, J.J. and Comesaña, M. and Perea, M.},\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "@incollection{PULO:springer,\n",
        "  year={2015},\n",
        "  isbn={978-3-319-27652-6},\n",
        "  booktitle={Languages, Applications and Technologies},\n",
        "  volume={563},\n",
        "  series={Communications in Computer and Information Science},\n",
        "  irreditor={Sierra-Rodríguez, José-Luis and Leal, José-Paulo and Simões, Alberto},\n",
        "  doi={10.1007/978-3-319-27653-3_5},\n",
        "  title={Experiments on Enlarging a Lexical Ontology},\n",
        "  publisher={Springer International Publishing},\n",
        "  author={Simões, Alberto and Almeida, José João},\n",
        "  pages={49--56},\n",
        "  language={English}\n",
        "}\n",
        "\n",
        "%%============================ 2016\n",
        "\n",
        "@InProceedings{SIMES16.1052,\n",
        "  author = {Alberto Simões and Xavier Gómez Guinovart and J. João Almeida},\n",
        "  title = {Enriching a {P}ortuguese {WordNet} using Synonyms from a\n",
        "Monolingual Dictionary},\n",
        "  booktitle = {Proceedings of the Ninth International Conference on\n",
        "Language Resources and Evaluation (LREC 2016)},\n",
        "  year = {2016},\n",
        "  month = {may},\n",
        "  date = {23-28},\n",
        "  address = {Portoroz, Slovenia},\n",
        "  editor = {Nicoletta Calzolari (Conference Chair) and Khalid Choukri\n",
        "and Thierry Declerck and Marko Grobelnik and Bente Maegaard and Joseph\n",
        "Mariani and Asuncion Moreno and Jan Odijk and Stelios Piperidis},\n",
        "  publisher = {European Language Resources Association (ELRA)},\n",
        "  isbn = {978-2-9517408-9-1},\n",
        "  language = {english}\n",
        " }\n",
        "\n",
        "@InProceedings{almeida_et_al2016,\n",
        "  author =  {José João Almeida and Eliana Grande and Georgi Smirnov},\n",
        "  title =   {{Context-Free Grammars: Exercise Generation and Probabilistic\n",
        "Assessment}},\n",
        "  booktitle =   {5th Symposium on Languages, Applications and Technologies\n",
        "(SLATE'16)},\n",
        "  pages =   {1--8},\n",
        "  series =  {OpenAccess Series in Informatics (OASIcs)},\n",
        "  ISBN =    {978-3-95977-006-4},\n",
        "  ISSN =    {2190-6807},\n",
        "  year =    {2016},\n",
        "  volume =  {51},\n",
        "  offeditor =   {Marjan Mernik and José Paulo Leal and Hugo Gonçalo Oliveira},\n",
        "  publisher =   {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},\n",
        "  offaddress =  {Dagstuhl, Germany},\n",
        "  offURL =      {http://drops.dagstuhl.de/opus/volltexte/2016/6015},\n",
        "  URN =     {urn:nbn:de:0030-drops-60159},\n",
        "  doi =     {http://dx.doi.org/10.4230/OASIcs.SLATE.2016.10},\n",
        "  annote =  {Keywords: Exercise generation, context-free grammars, assessment}\n",
        "}\n",
        "\n",
        "@article{cisti2016,\n",
        "  title = {Architectural approaches to build the museum of the person},\n",
        "  journal = {Iberian Conference on Information Systems and Technologies, CISTI},\n",
        "  year = {2016},\n",
        "  volume = {2016-July},\n",
        "  doi={https://doi.org/10.1109/CISTI.2016.7521367},\n",
        "  author = {Araujo, C. and Henriques, P.R. and Martini, R.G. and Almeida, J.J.}\n",
        "}\n",
        "\n",
        "\n",
        "@article{exercise-composition2016,\n",
        "   title = {Exercise composition: From environment properties to composed problems},\n",
        "   journal = {Advances in Intelligent Systems and Computing},\n",
        "   year = {2016},\n",
        "   volume = {445},\n",
        "   pages = {235-244},\n",
        "   author = {Araújo, I. and Almeida, J.J. and Smirnov, G.},\n",
        "   doi= {https://doi.org/10.1007/978-3-319-31307-8_24},\n",
        "   note={WorldCIST'16},\n",
        "}\n",
        "\n",
        "\n",
        "@article{ontoMP2016,\n",
        "   title = {OntoMP, an ontology to build the museum of the person},\n",
        "   journal = {Advances in Intelligent Systems and Computing},\n",
        "   year = {2016},\n",
        "   volume = {445},\n",
        "   pages = {653-661},\n",
        "   author = {Martini, R.G. and Ara{\\'u}jo, C. and Almeida, J.J. and Henriques, P.R.},\n",
        "   doi={https://doi.org/10.1007/978-3-319-31307-8_67},\n",
        "   note={WorldCIST'16},\n",
        "}\n",
        "\n",
        "%%============================ 2017\n",
        "\n",
        "@inproceedings { portosanto-worldcist2017,\n",
        "   title = {Exercise generation on language specification},\n",
        "   series = {Advances in Intelligent Systems and Computing, vol. 659},\n",
        "   year = {2017},\n",
        "   booktitle={Recent Advances in Information Systems and Technologies},\n",
        "   pages = {277-286},\n",
        "   note={WorldCIST'17},\n",
        "   author = {Almeida, J.J. and Eliana Grande and Smirnov, G.},\n",
        "   abstract ={Exercise generation on language specification is a challenging\n",
        "problem, because of the richness of the objects in the domain.\n",
        "In this paper we discuss Mgbeg (Meta-Grammar-Based Exercise Generator) -- a\n",
        "toolkit for exercise generation on context-free languages.\n",
        "Mgbeg approach is based on a meta-grammar formalism and tool, used to define\n",
        "a set of similar exercises.\n",
        "Mgbeg is a simple attributed grammar used to describe the set of valid\n",
        "exercise (and randomly generate one of them).\n",
        "Each exercise typically contains several attributes calculated during the\n",
        "generation steps: namely, one or more formal specification of the language\n",
        "(context free grammar); the exercise statement; other information such as\n",
        "examples, common mistakes, validation data, to be used in the construction\n",
        "of the exercise statement, solution, and assessment steps.\n",
        "Complementary the toolkit provides a grammar module, with functionality\n",
        "for grammar comparison, sentence generation and recognition; a template\n",
        "engine (to help in textual attributes calculation).\n",
        "   },\n",
        "}\n",
        "\n",
        "%%========================= 2018\n",
        "\n",
        "@incollection{Martins2018a,\n",
        "     author       = {Ricardo Martins and J.João Almeida\n",
        "         and Pedro Rangel Henriques and Paulo Novais},\n",
        "     title        = {Increasing authorship identification through emotional analysis},\n",
        "     booktitle    = {Trends and Advances in Information Systems and Technologies, WorldCist2018},\n",
        "     offeditor       =  {Álvaro Rocha and Hojjat Adeli and Luís Paulo Reis and Sandra Costanzo},\n",
        "     series       = {Advances in Intelligent Systems and Computing},\n",
        "     publisher    = {Springer International Publishing},\n",
        "     year         = 2018,\n",
        "     volume       = 745,\n",
        "     pages        = {763-772},\n",
        "     edition      = 1,\n",
        "     month        = {March},\n",
        "     doi          = {https://doi.org/10.1007/978-3-319-77703-0_76},\n",
        "     isbn         = {978-3-319-77702-3}\n",
        "}\n",
        "\n",
        "\n",
        "@inproceedings{DBLP:conf/ideal/MarcondesAN18,\n",
        "  author    = {Francisco S. Marcondes and\n",
        "               José João Almeida and\n",
        "               Paulo Novais},\n",
        "  title     = {Chatbot Theory - A Naïve and Elementary Theory for Dialogue\n",
        "               Management},\n",
        "  booktitle = {{IDEAL} {(1)}},\n",
        "  series    = {Lecture Notes in Computer Science},\n",
        "  volume    = {11314},\n",
        "  pages     = {374--384},\n",
        "  publisher = {Springer},\n",
        "  year      = {2018}\n",
        "}\n",
        "\n",
        "@inproceedings{DBLP:conf/bracis/Martins0ANH18,\n",
        "  author    = {Ricardo Martins and\n",
        "               Marco Gomes and\n",
        "               José João Almeida and\n",
        "               Paulo Novais and\n",
        "               Pedro Rangel Henriques},\n",
        "  title     = {Hate Speech Classification in Social Media Using Emotional Analysis},\n",
        "  booktitle = {{BRACIS}},\n",
        "  pages     = {61--66},\n",
        "  publisher = {{IEEE} Computer Society},\n",
        "  year      = {2018}\n",
        "}\n",
        "\n",
        "@inproceedings{DBLP:conf/dcai/MartinsAHN18,\n",
        "  author    = {Ricardo Martins and\n",
        "               José João Almeida and\n",
        "               Pedro Rangel Henriques and\n",
        "               Paulo Novais},\n",
        "  title     = {Domain Identification Through Sentiment Analysis},\n",
        "  booktitle = {{DCAI}},\n",
        "  series    = {Advances in Intelligent Systems and Computing},\n",
        "  volume    = {800},\n",
        "  pages     = {276--283},\n",
        "  publisher = {Springer},\n",
        "  year      = {2018}\n",
        "}\n",
        "\n",
        "@inproceedings{DBLP:conf/slate/MendesA18,\n",
        "  author    = {Rui Mendes and\n",
        "               José João Almeida},\n",
        "  title     = {eOS: The Exercise Operating System},\n",
        "  booktitle = {{SLATE}},\n",
        "  series    = {{OASICS}},\n",
        "  volume    = {62},\n",
        "  pages     = {5:1--5:13},\n",
        "  publisher = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik},\n",
        "  year      = {2018}\n",
        "}\n",
        "\n",
        "@inproceedings{DBLP:conf/slate/Almeida18,\n",
        "  author    = {José João Almeida},\n",
        "  title     = {Abcl: Abc music notation with rich chord support (Short Paper)},\n",
        "  booktitle = {{SLATE}},\n",
        "  series    = {{OASICS}},\n",
        "  volume    = {62},\n",
        "  pages     = {8:1--8:8},\n",
        "  publisher = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik},\n",
        "  year      = {2018}\n",
        "}\n",
        "\n",
        "@inproceedings{DBLP:conf/slate/MartinsAHN18,\n",
        "  author    = {Ricardo Martins and\n",
        "               José João Almeida and\n",
        "               Pedro Rangel Henriques and\n",
        "               Paulo Novais},\n",
        "  title     = {Predicting Performance Problems Through Emotional Analysis (Short\n",
        "               Paper)},\n",
        "  booktitle = {{SLATE}},\n",
        "  series    = {{OASICS}},\n",
        "  volume    = {62},\n",
        "  pages     = {19:1--19:9},\n",
        "  publisher = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik},\n",
        "  year      = {2018}\n",
        "}\n",
        "\n",
        "@inproceedings{DBLP:conf/webmedia/MartinsANH18,\n",
        "  author    = {Ricardo Martins and\n",
        "               José João Almeida and\n",
        "               Paulo Novais and\n",
        "               Pedro Rangel Henriques},\n",
        "  title     = {Creating a social media-based personal emotional lexicon},\n",
        "  booktitle = {WebMedia},\n",
        "  pages     = {261--264},\n",
        "  publisher = {{ACM}},\n",
        "  year      = {2018}\n",
        "}\n",
        "\n",
        "@inproceedings{DBLP:conf/worldcist/MartinsAHN18,\n",
        "  author    = {Ricardo Martins and\n",
        "               José João Almeida and\n",
        "               Pedro Rangel Henriques and\n",
        "               Paulo Novais},\n",
        "  title     = {Increasing Authorship Identification Through Emotional Analysis},\n",
        "  booktitle = {WorldCIST {(1)}},\n",
        "  series    = {Advances in Intelligent Systems and Computing},\n",
        "  volume    = {745},\n",
        "  pages     = {763--772},\n",
        "  publisher = {Springer},\n",
        "  year      = {2018}\n",
        "}\n",
        "\n",
        "\n",
        "%%============================ 2019\n",
        "\n",
        "@article{ cola19,\n",
        "  title = {On solving cycle-free context-free grammar equivalence problem using numerical analysis},\n",
        "  author= {José João Almeida   and\n",
        "           Eliana Grande and\n",
        "           Georgi Smirnov},\n",
        "  journal={Journal of Computer Languages},\n",
        "  publisher={Elsevier},\n",
        "  volume= 51,\n",
        "  pages ={48-56},\n",
        "  \n",
        "  Keywords={ Formal languages, Context-free grammars, Automatic assessment},\n",
        "  abstract={\n",
        "In this paper we consider the problem of cycle-free context-free grammars equivalence. To every context-free\n",
        "grammar there corresponds a system of formal equations. Formally applying the iteration method to this system\n",
        "we obtain the grammar axiom in the form of a formal power series composed of the words generated by the\n",
        "grammar \"multiplied\" by the respective ambiguities.\n",
        "We define a transform that attributes a matrix meaning to the system of formal equations and to formal power\n",
        "series: terminal symbols are substituted by matrices and formal sum and product are substituted by the matrix\n",
        "ones. In order to effectively compute the sum of a matrix series we numerically solve the system of matrix\n",
        "equations. We prove distinguishability theorems showing that if two formal power series generated by cycle-free\n",
        "context-free grammars are different, then there exists a matrix substitution such that the sums of the respective\n",
        "matrix series are different. Based on this result, we suggest a procedure that can resolve the problem of\n",
        "equivalence of cycle-free context-free grammars in many practical cases.\n",
        "The results obtained in this paper form a theoretical basis for algorithms oriented to automatic assessment of\n",
        "students' answers in computer science. We present the respective algorithms. Then we compare our approach\n",
        "with a simple heuristic method based on CYK algorithm and discuss the limitations of our method.\n",
        "}\n",
        "}\n",
        "\n",
        "\n",
        "@inproceedings{Almeida2019,\n",
        "author={Almeida, J.J. and Mendes, R.C.},\n",
        "title={Hunting ancestors: A unified approach for discovering genealogical information},\n",
        "journal={OpenAccess Series in Informatics},\n",
        "year={2019},\n",
        "volume={74},\n",
        "doi={10.4230/OASIcs.SLATE.2019.22},\n",
        "art_number={22},\n",
        "url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071097688&doi=10.4230%2fOASIcs.SLATE.2019.22&partnerID=40&md5=8e2f42806d411bdfa553dcfa27be17a9},\n",
        "abstract={This paper presents an unified approach for discovering\n",
        "genealogical information. It presents a frameworks for storing information\n",
        "concerning ancestors, locations, dates and documents. It also intends\n",
        "to provide a framework that is able to perform inference concerning\n",
        "dates by using constraints and for handling relations, locations and\n",
        "sources. The DSL presented also aims to help users store information\n",
        "from heterogeneous sources along with the evidence contained therein. ©\n",
        "José J. Almeida and Rui C. Mendes.},\n",
        "document_type={Conference Paper},\n",
        "source={Scopus},\n",
        "}\n",
        "\n",
        "\n",
        "@inproceedings{Simões2019453,\n",
        "author={Simões, Alberto and Salgado, Ana and Costa, Rute and Almeida, J.J.},\n",
        "title={LexMart: A smart tool for lexicographers},\n",
        "journal={Proceedings of Electronic Lexicography in the 21st Century Conference},\n",
        "year={2019},\n",
        "volume={2019-October},\n",
        "pages={453-466},\n",
        "url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075350281&partnerID=40&md5=c5171c547089e5728c1cec0d5c755df1},\n",
        "abstract={The digital era has brought some challenges to lexicographers,\n",
        "but it has also brought new opportunities as part of the rise of\n",
        "information technology and, more recently, the emergence of digital\n",
        "humanities. This paper provides a description of LeXmart, the framework\n",
        "that supports the digital development of the Portuguese Academy of\n",
        "Sciences Dictionary. LeXmart is a smart tool framework to support\n",
        "lexicographers' work that offers different types of tools, ranging from a\n",
        "structural editor to a set of validation tools. Given that the dictionary\n",
        "is stored in eXist-DB, LeXmart is developed on top of its ecosystem,\n",
        "using W3C standard languages, and offering default functionalities\n",
        "offered by eXist-DB, namely a RESTful API. © 2019 Lexical Computing CZ\n",
        "s.r.o.. All rights reserved.},\n",
        "document_type={Conference Paper},\n",
        "source={Scopus},\n",
        "}\n",
        "\n",
        "@ARTICLE{Martins2019,\n",
        "author={Martins, R. and Almeida, J.J. and Henriques, P. and Novais, P.},\n",
        "title={A sentiment analysis approach to increase authorship identification},\n",
        "journal={Expert Systems},\n",
        "year={2019},\n",
        "doi={10.1111/exsy.12469},\n",
        "art_number={e12469},\n",
        "url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074844787&doi=10.1111%2fexsy.12469&partnerID=40&md5=bb5b7acab849e47b90246393026a4ba4},\n",
        "abstract={Writing style is considered the manner in which an author\n",
        "expresses his thoughts, influenced by language characteristics, period,\n",
        "school, or nation. Often, this writing style can identify the author. One\n",
        "of the most famous examples comes from 1914 in Portuguese literature. With\n",
        "Fernando Pessoa and his heteronyms Alberto Caeiro, Álvaro de Campos,\n",
        "and Ricardo Reis, who had completely different writing styles, led\n",
        "people to believe that they were different individuals. Currently,\n",
        "the discussion of authorship identification is more relevant because\n",
        "of the considerable amount of widespread fake news in social media,\n",
        "in which it is hard to identify who authored a text and even a simple\n",
        "quote can impact the public image of an author, especially if these\n",
        "texts or quotes are from politicians. This paper presents a process to\n",
        "analyse the emotion contained in social media messages such as Facebook to\n",
        "identify the author's emotional profile and use it to improve the ability\n",
        "to predict the author of the message. Using preprocessing techniques,\n",
        "lexicon-based approaches, and machine learning, we achieved an authorship\n",
        "identification improvement of approximately 5% in the whole dataset\n",
        "and more than 50% in specific authors when considering the emotional\n",
        "profile on the writing style, thus increasing the ability to identify\n",
        "the author of a text by considering only the author's emotional profile,\n",
        "previously detected from prior texts. © 2019 John Wiley & Sons, Ltd.},\n",
        "document_type={Article},\n",
        "source={Scopus},\n",
        "}\n",
        "\n",
        "@inproceedings{Martins2019276,\n",
        "author={Martins, R. and Almeida, J.J. and Henriques, P. and Novais, P.},\n",
        "title={Domain identification through sentiment analysis},\n",
        "journal={Advances in Intelligent Systems and Computing},\n",
        "year={2019},\n",
        "volume={800},\n",
        "pages={276-283},\n",
        "doi={10.1007/978-3-319-94649-8_33},\n",
        "url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049987273&doi=10.1007%2f978-3-319-94649-8_33&partnerID=40&md5=3fe3521d746330d391ee8ec0dd7bd4e9},\n",
        "abstract={When dealing with chatbots, domain identification is an\n",
        "important feature to adapt the interactions between user and computer in\n",
        "order to increase the reliability of the communication and, consequently,\n",
        "the audience and decrease its rejection avoiding misunderstandings. In\n",
        "order to adapt to different domains, the writing style will be different\n",
        "for the same author. For example, the same person in the role of a\n",
        "student writes to his professor in a different style than he does for\n",
        "his brother. This article presents a process that uses sentiment analysis\n",
        "to identify the average emotional profile of the communication scenario\n",
        "where the conversation is done. Using Natural Language Processing and\n",
        "Machine Learning techniques, it was possible to obtain an index of\n",
        "96.21% of correct classifications in the identification of where these\n",
        "communications have occurred only analysing the emotional profile of\n",
        "these texts. © Springer International Publishing AG, part of Springer\n",
        "Nature 2019.},\n",
        "document_type={Conference Paper},\n",
        "source={Scopus},\n",
        "}\n",
        "\n",
        "\n",
        "%%===== 2020\n",
        "@inproceedings{Silva2020,\n",
        "author={Silva, Pedro and Almeida, J.J.},\n",
        "title={Musikla: Language for generating musical events},\n",
        "journal={OpenAccess Series in Informatics},\n",
        "year={2020},\n",
        "volume={83},\n",
        "doi={10.4230/OASIcs.SLATE.2020.6},\n",
        "art_number={A6},\n",
        "url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091704838&doi=10.4230%2fOASIcs.SLATE.2020.6&partnerID=40&md5=1c450e4e7bb940f5855eafaedb4ccba3},\n",
        "abstract={In this paper, we'll discuss a simple approach to integrating\n",
        "musical events, such as notes or chords, into a programming language. This\n",
        "means treating music sequences as a first class citizen. It will be\n",
        "possible to save those sequences into variables or play them right away,\n",
        "pass them into functions or apply operators on them (like transposing or\n",
        "repeating the sequence). Furthermore, instead of just allowing static\n",
        "sequences to be generated, we'll integrate a music keyboard system\n",
        "that easily allows the user to bind keys (or other kinds of events) to\n",
        "expressions. Finally, it is important to provide the user with multiple\n",
        "and extensible ways of outputing their music, such as synthesizing it into\n",
        "a file or directly into the speakers, or writing a MIDI or music sheet\n",
        "file. We'll structure this paper first with an analysis of the problem\n",
        "and its particular requirements. Then we will discuss the solution we\n",
        "developed to meet those requirements. Finally we'll analyze the result\n",
        "and discuss possible alternative routes we could've taken. © 2020 Schloss\n",
        "Dagstuhl- Leibniz-Zentrum fur Informatik GmbH, Dagstuhl Publishing. All\n",
        "rights reserved.},\n",
        "document_type={Conference Paper},\n",
        "source={Scopus},\n",
        "}\n",
        "\n",
        "@inproceedings{Oliveira2020,\n",
        "author={Oliveira, M. and Silva, P.M. and Moura, Pedro and Almeida, J.J. and Henriques, P.R.},\n",
        "title={BhTSL, behavior trees specification and processing},\n",
        "journal={OpenAccess Series in Informatics},\n",
        "year={2020},\n",
        "volume={83},\n",
        "doi={10.4230/OASIcs.SLATE.2020.4},\n",
        "art_number={A4},\n",
        "url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091707856&doi=10.4230%2fOASIcs.SLATE.2020.4&partnerID=40&md5=3b2daa7d548eeed77224386d6790adc7},\n",
        "abstract={In the context of game development, there is always the\n",
        "need for describing behaviors for various entities, whether NPCs or\n",
        "even the world itself. That need requires a formalism to describe\n",
        "properly such behaviors. As the gaming industry has been growing,\n",
        "many approaches were proposed. First, finite state machines were used\n",
        "and evolved to hierarchical state machines. As that formalism was not\n",
        "enough, a more powerful concept appeared. Instead of using states for\n",
        "describing behaviors, people started to use tasks. This concept was\n",
        "incorporated in behavior trees. This paper focuses in the specification\n",
        "and processing of Behavior Trees. A DSL designed for that purpose will\n",
        "be introduced. It will also be discussed a generator that produces LATEX\n",
        "diagrams to document the trees, and a Python module to implement the\n",
        "behavior described. Additionally, a simulator will be presented. These\n",
        "achievements will be illustrated using a concrete game as a case study. ©\n",
        "2020 Schloss Dagstuhl- Leibniz-Zentrum fur Informatik GmbH, Dagstuhl\n",
        "Publishing. All rights reserved.},\n",
        "document_type={Conference Paper},\n",
        "source={Scopus},\n",
        "}\n",
        "\n",
        "@inproceedings{Simões2020,\n",
        "author={Simões, Alberto and Sacanene, B. and Iriarte, Alvaro and Almeida, J.J. and Macedo, J.},\n",
        "title={Towards a morphological analyzer for the umbundu language},\n",
        "journal={OpenAccess Series in Informatics},\n",
        "year={2020},\n",
        "volume={83},\n",
        "doi={10.4230/OASIcs.SLATE.2020.10},\n",
        "art_number={A10},\n",
        "url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091700212&doi=10.4230%2fOASIcs.SLATE.2020.10&partnerID=40&md5=26f3c0eacb3fc1ea35f005c08377b083},\n",
        "abstract={In this document we present the first developments on an Umbundu\n",
        "dictionary for a jSpell, a morphological analyzer. Initially some comments\n",
        "are performed regarding the Umbundu language morphology, followed by the\n",
        "discussion on jSpell dictionaries structure and its environment. Last, we\n",
        "describe the Umbundu dictionary bootstrap process and perform some final\n",
        "experiments on its coverage. © 2020 Schloss Dagstuhl- Leibniz-Zentrum\n",
        "fur Informatik GmbH, Dagstuhl Publishing. All rights reserved.},\n",
        "document_type={Conference Paper},\n",
        "source={Scopus},\n",
        "}\n",
        "\n",
        "\n",
        "@inproceedings{Marcondes2020,\n",
        "author={Marcondes, F.S. and Almeida, J.J. and Novais, P.},\n",
        "title={Structural onomatology for username generation: A partial account},\n",
        "journal={CEUR Workshop Proceedings},\n",
        "year={2020},\n",
        "volume={2655},\n",
        "url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090898082&partnerID=40&md5=3bee224fddd1133fbeb306d5c88737fa},\n",
        "abstract={The username hints for most of the on-line social networks are\n",
        "mostly unpleasant for human beings since they are mostly a simple name\n",
        "variation followed by numbers. This paper shows that it is possible to\n",
        "generate human likable usernames through heuristics guided by structural\n",
        "onomastics. The objective then is to conceive heuristics as such and\n",
        "check its availability in Twitter in order to verify if is it possible\n",
        "to generate a sufficiently big and available username data-set that is\n",
        "able to justify the transitions from unpleasant to a pleasant username\n",
        "suggestion. This paper finds that it is possible to generate 8281 handles\n",
        "on average through the proposed heuristics and their permutations,\n",
        "therefore, the number of various possibilities is comfortable. This is\n",
        "a partial account since not all possibilities were explored and some\n",
        "improvements are required, but suits for a proof of concept and to\n",
        "indicate paths. © 2020 CEUR-WS. All rights reserved.},\n",
        "document_type={Conference Paper},\n",
        "source={Scopus},\n",
        "}\n",
        "\n",
        "@inproceedings{Marcondes202028,\n",
        "author={Marcondes, F.S. and Almeida, J.J. and Novais, P.},\n",
        "title={A short survey on chatbot technology: Failure in raising the state of the art},\n",
        "journal={Advances in Intelligent Systems and Computing},\n",
        "year={2020},\n",
        "volume={1003},\n",
        "pages={28-36},\n",
        "doi={10.1007/978-3-030-23887-2_4},\n",
        "url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068602421&doi=10.1007%2f978-3-030-23887-2_4&partnerID=40&md5=cbf6fb00a51eb082aa7e1097f926fece},\n",
        "abstract={This short survey aimed initially to explore the existing\n",
        "state of the art for the application of chatbot on fighting (and not on\n",
        "spreading) of fake-news. It was then realized that there is not common to\n",
        "use chatbots with this \"virtuous\" purpose. Therefore, after two surveys\n",
        "and a meta-analysis, the topic had to be withdrawn since there were no\n",
        "survey results to discuss besides the absence of results. The survey\n",
        "result raised then a need to realize how chatbots are being currently\n",
        "used, designed and their primary sources. The result was once again\n",
        "confusing since, on the sample: (1) no significant concentration of usage\n",
        "could be found; (2) no widely adopted design strategies were identified,\n",
        "and (3) no significant crosscutting references to be considered as primary\n",
        "sources. Certainly, this can be due to a biased sample but may also be a\n",
        "symptom of a methodological issue on the chatbot researches. If the second\n",
        "possibility is proved to be right it means that chatbot research is still\n",
        "on a pre-paradigm stage according to Kuhn¿s conception. For this paper,\n",
        "there were performed 4 surveys with a total sample of 50 papers mostly\n",
        "from the last 3Â years. © Springer Nature Switzerland AG 2020.},\n",
        "document_type={Conference Paper},\n",
        "source={Scopus},\n",
        "}\n",
        "\n",
        "@ARTICLE{Marcondes2020170,\n",
        "author={Marcondes, F.S. and Almeida, J.J. and Durães, D. and Novais, P.},\n",
        "title={Fact-Check spreading behavior in twitter: A qualitative profile for false-claim news},\n",
        "journal={Advances in Intelligent Systems and Computing},\n",
        "year={2020},\n",
        "volume={1160 AISC},\n",
        "pages={170-180},\n",
        "doi={10.1007/978-3-030-45691-7_16},\n",
        "url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086245198&doi=10.1007%2f978-3-030-45691-7_16&partnerID=40&md5=6547f11464462d6bfdb1505e6142b733},\n",
        "abstract={Fact-check spread is usually performed by a plain tweet with\n",
        "just the link. Since it is not proper human behavior, it may cause\n",
        "uncanny, hinder the reader¿s attention and harm the counter-propaganda\n",
        "influence. This paper presents a profile of fact-check link spread in\n",
        "Twitter (suiting for TRL-1) and, as an additional outcome, proposes\n",
        "a preliminary behavior design based on it (suiting for TRL-2). The\n",
        "underlying hypothesis is by simulating human-like behavior, a bot gets\n",
        "more attention and exerts more influence on its followers. © The Editor(s)\n",
        "(if applicable) and The Author(s), under exclusive license to Springer\n",
        "Nature Switzerland AG 2020.},\n",
        "document_type={Conference Paper},\n",
        "source={Scopus},\n",
        "}\n",
        "\n",
        "@ARTICLE{Martins2020134,\n",
        "author={Martins, R. and Almeida, J. and Henriques, P. and Novais, P.},\n",
        "title={Predicting an Election's Outcome Using Sentiment Analysis},\n",
        "journal={Advances in Intelligent Systems and Computing},\n",
        "year={2020},\n",
        "volume={1159 AISC},\n",
        "pages={134-143},\n",
        "doi={10.1007/978-3-030-45688-7_14},\n",
        "url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085513930&doi=10.1007%2f978-3-030-45688-7_14&partnerID=40&md5=d559e334a2140bea6ea02051264b73c4},\n",
        "abstract={Political debate - in its essence - carries a robust\n",
        "emotional charge, and social media have become a vast arena for voters\n",
        "to disseminate and discuss the ideas proposed by candidates. The\n",
        "Brazilian presidential elections of 2018 were marked by a high level\n",
        "of polarization, making the discussion of the candidates¿ ideas an\n",
        "ideological battlefield, full of accusations and verbal aggression,\n",
        "creating an excellent source for sentiment analysis. In this paper,\n",
        "we analyze the emotions of the tweets posted about the presidential\n",
        "candidates of Brazil on Twitter, so that it was possible to identify the\n",
        "emotional profile of the adherents of each of the leading candidates,\n",
        "and thus to discern which emotions had the strongest effects upon the\n",
        "election results. Also, we created a model using sentiment analysis and\n",
        "machine learning, which predicted with a correlation of 0.90 the final\n",
        "result of the election. © 2020, The Editor(s) (if applicable) and The\n",
        "Author(s), under exclusive license to Springer Nature Switzerland AG.},\n",
        "document_type={Conference Paper},\n",
        "source={Scopus},\n",
        "}\n",
        "@inproceedings{Martins201861,\n",
        "author={Martins, R. and Gomes, M. and Almeida, J.J. and Novais, P. and Henriques, P.},\n",
        "title={Hate speech classification in social media using emotional analysis},\n",
        "journal={Proceedings - 2018 Brazilian Conference on Intelligent Systems, BRACIS 2018},\n",
        "year={2018},\n",
        "pages={61-66},\n",
        "doi={10.1109/BRACIS.2018.00019},\n",
        "art_number={8575590},\n",
        "url={https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060849408&doi=10.1109%2fBRACIS.2018.00019&partnerID=40&md5=10284a22b511c161a903debd79e5619a},\n",
        "abstract={In this paper, we examine methods to classify hate speech\n",
        "in social media. We aim to establish lexical baselines for this task\n",
        "by applying classification methods using a dataset annotated for this\n",
        "purpose. As features, our system uses Natural Language Processing (NLP)\n",
        "techniques in order to expand the original dataset with emotional\n",
        "information and provide it for machine learning classification. We\n",
        "obtain results of 80.56% accuracy in hate speech identification, which\n",
        "represents an increase of almost 100% from the original analysis used\n",
        "as a reference. © 2018 IEEE.},\n",
        "document_type={Conference Paper},\n",
        "source={Scopus},\n",
        "}\n",
        "```\n"
      ],
      "metadata": {
        "id": "BARbOqhS1R6d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8BO430IT1zoQ"
      }
    }
  ]
}