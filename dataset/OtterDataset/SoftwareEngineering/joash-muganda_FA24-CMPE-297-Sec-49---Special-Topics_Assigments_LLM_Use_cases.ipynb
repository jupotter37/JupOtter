{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "63b68a50674c46cea6289c06ae1826fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05ad7eea5d974961970a8c48fb905a8f",
              "IPY_MODEL_92f60f0d88144585971a1f8a70106ae5",
              "IPY_MODEL_a050b8de83c04a68a730a4f1aef0425a"
            ],
            "layout": "IPY_MODEL_30c3e95842af4bc1bdc194506afe96e3"
          }
        },
        "05ad7eea5d974961970a8c48fb905a8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80a1265d21da40a0abe38da0209f6c5c",
            "placeholder": "​",
            "style": "IPY_MODEL_f04e8c433b1b46e981342df2ff52bbf1",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "92f60f0d88144585971a1f8a70106ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4241eb231e55440185f2aeef80b11302",
            "max": 287,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0799f94b5d97427b9435462b59b43182",
            "value": 287
          }
        },
        "a050b8de83c04a68a730a4f1aef0425a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc7f4d6676004d4eb18605984ef6d5f3",
            "placeholder": "​",
            "style": "IPY_MODEL_d4513c0f1ada42b7a1031f0377c655c8",
            "value": " 287/287 [00:00&lt;00:00, 14.3kB/s]"
          }
        },
        "30c3e95842af4bc1bdc194506afe96e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80a1265d21da40a0abe38da0209f6c5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f04e8c433b1b46e981342df2ff52bbf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4241eb231e55440185f2aeef80b11302": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0799f94b5d97427b9435462b59b43182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fc7f4d6676004d4eb18605984ef6d5f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4513c0f1ada42b7a1031f0377c655c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ee9138c32b048859f402b9eff92ad9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb8c87ab22ce4c538017934375d47591",
              "IPY_MODEL_22bee754c60b46f5850c6ce5982e167b",
              "IPY_MODEL_a2d7f0e0f8ed44c88312e98b239d0463"
            ],
            "layout": "IPY_MODEL_374feb3ab7a04dfdb8a4d163e8ddbeac"
          }
        },
        "eb8c87ab22ce4c538017934375d47591": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_408c49491b3e47b08a7ebd3d839a1d6e",
            "placeholder": "​",
            "style": "IPY_MODEL_766c9925e5b6408db4f5bdaeed651584",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "22bee754c60b46f5850c6ce5982e167b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba42b220c7814594ac109ebebcd9b099",
            "max": 506,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4ca9c5d60bf4d3eb4573a64a00b85cc",
            "value": 506
          }
        },
        "a2d7f0e0f8ed44c88312e98b239d0463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3b1d8cb96af4062b0a362f22b37230c",
            "placeholder": "​",
            "style": "IPY_MODEL_45544ffb144f48a9ad21e8a889d5dc45",
            "value": " 506/506 [00:00&lt;00:00, 32.4kB/s]"
          }
        },
        "374feb3ab7a04dfdb8a4d163e8ddbeac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "408c49491b3e47b08a7ebd3d839a1d6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "766c9925e5b6408db4f5bdaeed651584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba42b220c7814594ac109ebebcd9b099": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4ca9c5d60bf4d3eb4573a64a00b85cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3b1d8cb96af4062b0a362f22b37230c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45544ffb144f48a9ad21e8a889d5dc45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfd46594500a4bb7b04c69378034290a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fef20fe0513b4634b8ff4cb144e7e38f",
              "IPY_MODEL_f83946cbd74946838dc566fec1671413",
              "IPY_MODEL_c6f32a41a3e948f5a6b46d946b702aab"
            ],
            "layout": "IPY_MODEL_8124ab24d7bb4cf3869a0d5ea43de6fc"
          }
        },
        "fef20fe0513b4634b8ff4cb144e7e38f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1acaae031a2f421db36258bd88856e2d",
            "placeholder": "​",
            "style": "IPY_MODEL_b778e733ecac4d79a94338c0b6d95607",
            "value": "vocab.txt: 100%"
          }
        },
        "f83946cbd74946838dc566fec1671413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2da2f0b73bc24a819afec5342a325a1b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bfe75d1318143c7bcf8c78ab481b10e",
            "value": 231508
          }
        },
        "c6f32a41a3e948f5a6b46d946b702aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4f51be0ba8a4142990215cf4fb0e016",
            "placeholder": "​",
            "style": "IPY_MODEL_d634c6fc2dce4a79a2ce9beb4339b54a",
            "value": " 232k/232k [00:00&lt;00:00, 584kB/s]"
          }
        },
        "8124ab24d7bb4cf3869a0d5ea43de6fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1acaae031a2f421db36258bd88856e2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b778e733ecac4d79a94338c0b6d95607": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2da2f0b73bc24a819afec5342a325a1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bfe75d1318143c7bcf8c78ab481b10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4f51be0ba8a4142990215cf4fb0e016": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d634c6fc2dce4a79a2ce9beb4339b54a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bdaf2c0e5f842bea116c8c127e9cb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d707f4b917048ac8318ab1d3d97d826",
              "IPY_MODEL_4dada3e32eaf4147b5441a906f10479a",
              "IPY_MODEL_d34a54d9a48947d69414ec03aaace40c"
            ],
            "layout": "IPY_MODEL_f5114b03ca0f498d839351d46d6f0966"
          }
        },
        "9d707f4b917048ac8318ab1d3d97d826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f487536663a489ea35303a8f145dc2c",
            "placeholder": "​",
            "style": "IPY_MODEL_956fe5a3ba3c4dd686e13440ccf923b2",
            "value": "tokenizer.json: 100%"
          }
        },
        "4dada3e32eaf4147b5441a906f10479a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b39474eb702f400d8c6627632ed54865",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c32eb5631a754dcfa8916525f08b0a9a",
            "value": 711396
          }
        },
        "d34a54d9a48947d69414ec03aaace40c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1478b61a65314da8b90f19eab8115678",
            "placeholder": "​",
            "style": "IPY_MODEL_97c6d06ec7e747a9b7dc21f702527ee3",
            "value": " 711k/711k [00:00&lt;00:00, 1.19MB/s]"
          }
        },
        "f5114b03ca0f498d839351d46d6f0966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f487536663a489ea35303a8f145dc2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "956fe5a3ba3c4dd686e13440ccf923b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b39474eb702f400d8c6627632ed54865": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c32eb5631a754dcfa8916525f08b0a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1478b61a65314da8b90f19eab8115678": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97c6d06ec7e747a9b7dc21f702527ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "077b9f12082649c890e668e681bae98c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b09f2e5c9ad4828b89f94a8c387b802",
              "IPY_MODEL_a96eb429a2344afab03cd87ed601f7bf",
              "IPY_MODEL_714fb53f2f4c4b89acb991f11236d57a"
            ],
            "layout": "IPY_MODEL_0a4335d2468d40b6a11519929aa9297e"
          }
        },
        "5b09f2e5c9ad4828b89f94a8c387b802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1f28ccae4dc4e24bb0836dc78945c6e",
            "placeholder": "​",
            "style": "IPY_MODEL_09933e91635b40b8bd1aec7771120926",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a96eb429a2344afab03cd87ed601f7bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9a0ac3e8c8a47bfb1afc1271e7365cc",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d730f43a8e3e40b68f45edfe0ad78a4d",
            "value": 125
          }
        },
        "714fb53f2f4c4b89acb991f11236d57a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39554839f7ea478282a9286d22b5469c",
            "placeholder": "​",
            "style": "IPY_MODEL_22ea23198c1c47fea6ccde82ebd8ffe0",
            "value": " 125/125 [00:00&lt;00:00, 4.76kB/s]"
          }
        },
        "0a4335d2468d40b6a11519929aa9297e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1f28ccae4dc4e24bb0836dc78945c6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09933e91635b40b8bd1aec7771120926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9a0ac3e8c8a47bfb1afc1271e7365cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d730f43a8e3e40b68f45edfe0ad78a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39554839f7ea478282a9286d22b5469c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22ea23198c1c47fea6ccde82ebd8ffe0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aa1120b5575c43bd9ef0bfc16b2f93e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_438694985df4454594373b4c06f49041",
              "IPY_MODEL_8e339e1639a445bb8bd304507bea7ce0",
              "IPY_MODEL_13ea939c1758408a821efd4b59f26c1e"
            ],
            "layout": "IPY_MODEL_106a145525d64d8aa68bb615a547f91c"
          }
        },
        "438694985df4454594373b4c06f49041": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21077708eed84c87984ec9fd08a53348",
            "placeholder": "​",
            "style": "IPY_MODEL_1ec817ccf343438194c7afafb0b0130a",
            "value": "config.json: 100%"
          }
        },
        "8e339e1639a445bb8bd304507bea7ce0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae8fae40747c49a98e778572d56cb6f3",
            "max": 4563,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b41f5aa278644c380468636c2064518",
            "value": 4563
          }
        },
        "13ea939c1758408a821efd4b59f26c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30586b86cb0e419dbe4f334781d7bc9d",
            "placeholder": "​",
            "style": "IPY_MODEL_c8e9db5e12a640858b00650fcc1f7b56",
            "value": " 4.56k/4.56k [00:00&lt;00:00, 278kB/s]"
          }
        },
        "106a145525d64d8aa68bb615a547f91c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21077708eed84c87984ec9fd08a53348": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ec817ccf343438194c7afafb0b0130a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae8fae40747c49a98e778572d56cb6f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b41f5aa278644c380468636c2064518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30586b86cb0e419dbe4f334781d7bc9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8e9db5e12a640858b00650fcc1f7b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8db8d4c4815f47a79a2ba3dc1894b8ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe228fe5429f4d20a80ba0518f4da441",
              "IPY_MODEL_2752b84ea80240b89d038521b05d0548",
              "IPY_MODEL_12a57b04b8614a3b9c2643277cab18aa"
            ],
            "layout": "IPY_MODEL_633f152f1f75411097a3f804010ffad6"
          }
        },
        "fe228fe5429f4d20a80ba0518f4da441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7227a3db57554c9d8348dcb414f320f1",
            "placeholder": "​",
            "style": "IPY_MODEL_a1d0c1e1107b44d5a26d2df6cb8ee60a",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "2752b84ea80240b89d038521b05d0548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4f438ee818d482f9ae66e8a8d221bec",
            "max": 989820849,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9092bea3d265455f8cedcd573d8eb682",
            "value": 989820849
          }
        },
        "12a57b04b8614a3b9c2643277cab18aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98e371f65f0a41d18afd072402132310",
            "placeholder": "​",
            "style": "IPY_MODEL_b2f9ee47ce894804ba4b0d4f481f72e2",
            "value": " 990M/990M [00:11&lt;00:00, 88.9MB/s]"
          }
        },
        "633f152f1f75411097a3f804010ffad6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7227a3db57554c9d8348dcb414f320f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1d0c1e1107b44d5a26d2df6cb8ee60a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4f438ee818d482f9ae66e8a8d221bec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9092bea3d265455f8cedcd573d8eb682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "98e371f65f0a41d18afd072402132310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2f9ee47ce894804ba4b0d4f481f72e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Text samarization using chat gpt 4**"
      ],
      "metadata": {
        "id": "NvFhOc-p3Fvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install openai wikipedia-api\n",
        "\n",
        "import openai\n",
        "import wikipediaapi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "whWPhcJF5G6R",
        "outputId": "62e0c240-be0d-474f-c7d1-5e97b426696b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.44.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting wikipedia-api\n",
            "  Downloading wikipedia_api-0.7.1.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from wikipedia-api) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->wikipedia-api) (2.0.7)\n",
            "Downloading openai-1.44.0-py3-none-any.whl (367 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m367.8/367.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: wikipedia-api\n",
            "  Building wheel for wikipedia-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia-api: filename=Wikipedia_API-0.7.1-py3-none-any.whl size=14347 sha256=e2edfb229ee7aea3c0f37f45fa18b8a1be8ea8bd5b93f7e7f2753ec8584db576\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/96/18/b9201cc3e8b47b02b510460210cfd832ccf10c0c4dd0522962\n",
            "Successfully built wikipedia-api\n",
            "Installing collected packages: jiter, h11, wikipedia-api, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 openai-1.44.0 wikipedia-api-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#API Key\n",
        "client = openai.OpenAI(api_key = \"Fake\")"
      ],
      "metadata": {
        "id": "bzUMx2Nk5dme"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wikipedia_content(page_title):\n",
        "    # Initialize the Wikipedia API with a custom user agent\n",
        "    wiki_wiki = wikipediaapi.Wikipedia(\n",
        "        language='en',\n",
        "        user_agent='ColabDemoScript/1.0 (Contact: myemail@example.com)'\n",
        "    )\n",
        "\n",
        "    # Fetch the page\n",
        "    page = wiki_wiki.page(page_title)\n",
        "\n",
        "    # Check if the page exists\n",
        "    if page.exists():\n",
        "        return page.text\n",
        "    else:\n",
        "        print(f\"Page '{page_title}' does not exist.\")\n",
        "        return None\n",
        "\n",
        "def summarize_text(input_text):\n",
        "    # Use the client to create a chat completion\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes text.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Summarize the following text:\\n{input_text}\"}\n",
        "        ],\n",
        "        max_tokens=100  # Adjust max_tokens as needed\n",
        "    )\n",
        "    # Use the model's attributes to access the content\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "\n",
        "\n",
        "# Specify the Wikipedia page title you want to summarize\n",
        "page_title = \"Artificial intelligence\"  # Replace with any Wikipedia page title\n",
        "\n",
        "# Fetch the content from the Wikipedia page\n",
        "wiki_content = get_wikipedia_content(page_title)\n",
        "\n",
        "if wiki_content:\n",
        "    # Summarize the fetched content\n",
        "    summary = summarize_text(wiki_content[:2000])  # Limiting the length for summarization\n",
        "    print(\"Summary:\\n\", summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67MzKaI63DIR",
        "outputId": "d69b2a64-2c65-4098-9f1a-876345da7d8e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            " Artificial intelligence is a field of research in computer science focused on building and studying systems that can perceive their environment and use learning and intelligence to complete tasks. AI is commonly used in tools such as search engines, recommendation systems, speech interaction software, autonomous vehicles, and advanced gaming software. However, many AI applications go unnoticed as they become integrated into general use. The focus of AI research includes reasoning, knowledge representation, planning, learning, language processing, perception and robotics support, with the aim of creating\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **text Translation**"
      ],
      "metadata": {
        "id": "FprCevCY9IOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_text(input_text, target_language):\n",
        "    # Use the client to create a chat completion for translation\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that translates text.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Translate the following text to {target_language}:\\n{input_text}\"}\n",
        "        ],\n",
        "        max_tokens=150  # Adjust max_tokens as needed\n",
        "    )\n",
        "    # Use the model's attributes to access the content\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "# Example input text for translation\n",
        "input_text = \"Homo sapiens are the modern man\"\n",
        "target_language = \"Dholuo\"  # Swpecify the target language\n",
        "\n",
        "# Translate the input text\n",
        "translation = translate_text(input_text, target_language)\n",
        "print(f\"Translation to {target_language}:\\n\", translation)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKE6m_8dANXI",
        "outputId": "2705c836-afbc-484e-eb0b-011207f3c228"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation to Dholuo:\n",
            " Homo sapiens nitie jaduong' marachiel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Audio process with chat-gpt-4**"
      ],
      "metadata": {
        "id": "T9I2eP6xBCXf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai-whisper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EJkKiDXLG_fI",
        "outputId": "b7645d48-ba04-4464-80c9-010c334e6d9e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting triton<3,>=2.0.0 (from openai-whisper)\n",
            "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.4.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.5)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.3.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper) (3.15.4)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n",
            "Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801359 sha256=551feba6b07ad0b69cd1f4b26a1323fc507b7f3dae447b65c720c7e092eee3e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/85/e1/9361b4cbea7dd4b7f6702fa4c3afc94877952eeb2b62f45f56\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: triton, tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20231117 tiktoken-0.7.0 triton-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Audio Processing with GPT-4 (Whisper-transcribe)**"
      ],
      "metadata": {
        "id": "q28HUFGoHPTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!apt-get install -y ffmpeg\n",
        "\n",
        "import whisper\n",
        "from google.colab import files\n",
        "\n",
        "# Upload the audio file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the Whisper model\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "# Transcribe audio file\n",
        "audio_file_path = next(iter(uploaded.keys()))\n",
        "transcription = model.transcribe(audio_file_path)\n",
        "print(\"Transcription:\\n\", transcription['text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "E-r6V69FMvT_",
        "outputId": "31b597ac-811a-481e-bd71-24792a9dbd93"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6f50d727-4027-47d8-9178-d7adfd7eaecc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6f50d727-4027-47d8-9178-d7adfd7eaecc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving A Mysterious Design That Appears Across Millennia  Terry Moore  TED.m4a to A Mysterious Design That Appears Across Millennia  Terry Moore  TED.m4a\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:04<00:00, 33.5MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(fp, map_location=device)\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription:\n",
            "  This is Roger Penrose, certainly one of the great scientists of our time. Winner of the 2020 Nobel Prize in Physics for his work reconciling black holes with Einstein's general theory of relativity. But back in the 1970s, Roger Penrose made a contribution to the world of mathematics and that part of mathematics known as tiling. You know, tiling the process of putting tiles together so that they form a particular pattern. The thing that was remarkable about the pattern that Roger Penrose developed is that by using only two shapes, he constructed a pattern that could be expanded infinitely in any direction without ever repeating. Much like the number pi has a decimal that isn't random, but it will go on forever without repeating. In mathematics, this is a property known as a periodicity. And the notion of an a periodic tile set using only two tiles was such a sensation that was given the name Penrose tiling. Here's Roger Penrose, now Sir Roger Penrose standing on a field of Penrose tiles. Then in 2007, this man, Peter Lew, who was then a graduate student in Physics at Princeton, while on vacation with his cousin in Uzbekistan, discovered this pattern on a 14th century madrasa. And after some analysis concluded that this was in fact Penrose tiling 500 years before Penrose. That information took the scientific world by storm and prompted headlines everywhere, including Discover Magazine, which proclaimed this the 59 most important scientific discovery of the year 2007. So now we've heard about this amazing pattern from the point of view of mathematics and from physics. And now art and archaeology, so that leads us to the question, what was there about this pattern? That this ancient culture found so important that they put it on their most important building. So for that, we look to the world of anthropology and ask the question, what was the world view of the culture that made this? And this is what we learned. This pattern is life. And as you can see, life's complicated. It's complicated. But not only is life complicated, life is also aparyotic in the sense that every event, every happening, every decision will make the future unfold differently, often in ways that are impossible to predict. Yet in spite of the complexity and in spite of a future that's impossible to predict, there remains an underlying unity that holds everything together and gives rise to everything. Let's see how that works in a design much like the one Peter Lew found in the spec of Stan. This is that design. Now it turns out this is actually based on this set of Penrose tiles, which are reducible to these shapes. And in order to draw these shapes, the medieval craftsmen who did this would have done them by using these construction lines. And I add here that the construction lines don't appear in the final work. But if we add them back, we have this. And now if we weave them together, we will have this. And now if we hide the tiles and just look at the construction lines, we see this. Clearly, there's an underlying structure and unity to things that seem to be complex and apiatic. This notion of a hidden underlying unity was common throughout the ancient world. And one sees it in Egypt, in Greece, in Australia, in Mesoamerica, in North America, in Europe, in the Middle East. Now in the modern West, we might call this underlying unity God, but throughout the ages, other terms have been used to describe the same thing. This is what Plato called first cause. In the medieval period, philosopher Spinoza called this the singular substance. In the 20th century, a number of terms were coined to describe this. One of my favorites being from philosopher Alfred North Whitehead, who called this the undifferentiated aesthetic continuum. Doesn't that have a 20th century sound to it? But for me, a lover of science that I am, I will take the term coined by the great 20th century physicist David Bohm, who called this the implicate order. So what's the takeaway here? Very simply this. And we see these wonderful designs created by cultures that are separated from our own, by thousands of miles or thousands of years. We can't know these are decorations. These are statements about the fundamental values that culture had, what they found important how they saw themselves, the world and themselves in the world. It has been said that architecture is a book written in stone. So when we see these amazing designs, we can know they're not decorations. They're a statement. They're a message. Look, listen. You can hear their voices. Thank you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Summarization**"
      ],
      "metadata": {
        "id": "ALixgdvuPRIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the transcribed text using GPT-4\n",
        "def summarize_audio_text(transcribed_text):\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes text.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Summarize the following text:\\n{transcribed_text}\"}\n",
        "        ],\n",
        "        max_tokens=100\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n",
        "\n",
        "summary = summarize_audio_text(transcription['text'])\n",
        "print(\"Summary:\\n\", summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhS8YuR6PbXf",
        "outputId": "faaef435-bbdb-4c46-bc9b-90a17b8f6f6e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            " Roger Penrose, a notable scientist and the 2020 Nobel Prize in Physics laureate, made significant contributions to mathematics, specifically in tiling, forming unique patterns with two shapes that can expand infinitely without repetition. His concept, famously known as \"Penrose tiling,\" was surprisingly found on a 14th-century building in Uzbekistan by Peter Lew, a physics graduate student, in 2007, marking the structure as a phenomenon that predates Penrose's invention. The discovery led to\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n"
      ],
      "metadata": {
        "id": "a-6UpHk9aVSe"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Perform Image Captioning**"
      ],
      "metadata": {
        "id": "OCij_kYVa3bB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text generation using gemini**"
      ],
      "metadata": {
        "id": "8_8UqSr8r4DV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai\n"
      ],
      "metadata": {
        "id": "RyOpBuPKrRJ5"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Set your API key (replace with your actual key)\n",
        "os.environ[\"API_KEY\"] = \"fake4\"\n"
      ],
      "metadata": {
        "id": "a1sK7QJcrYvn"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=os.environ[\"API_KEY\"])\n"
      ],
      "metadata": {
        "id": "MNAl_JkDrmNv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model instance\n",
        "model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Use the generateContent method to generate text\n",
        "response = model.generate_content(\"Write a story about a magic backpack.\")\n",
        "print(\"Generated Text:\", response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "A9iFAWcvru51",
        "outputId": "a5834271-6585-4397-a5e8-42a8c3701937"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Text: The dusty attic smelled of mothballs and forgotten dreams. Ten-year-old Finn, nose wrinkled, sifted through a pile of forgotten treasures, his fingers brushing against a worn leather backpack tucked in a corner. A tingle ran up his arm, the backpack suddenly feeling warm and alive. \n",
            "\n",
            "He pulled it out, its faded leather gleaming in the dusty light. A brass buckle, etched with strange symbols, gleamed on the front. Curiosity gnawing at him, Finn unbuckled the backpack. A gust of warm air rushed out, carrying the scent of pine needles and fresh earth. Inside, nestled among a pile of soft moss, lay a single, perfectly formed, ruby red apple.\n",
            "\n",
            "\"Wow,\" Finn whispered, picking up the apple. It felt heavy, almost impossibly real. He took a bite. The apple exploded in his mouth, a burst of summer sunshine and sweet nectar. He closed his eyes, the flavor lingering, the feeling of magic dancing on his tongue.\n",
            "\n",
            "That night, Finn dreamed of a vast forest, filled with towering trees and sparkling waterfalls. The dream felt so real, the smells and sounds almost tangible. He woke up with the feeling that the forest was waiting for him, just beyond the edge of his imagination.\n",
            "\n",
            "The next day, Finn took the backpack to school. He filled it with books and a lunchbox, but as he slung it over his shoulder, the world around him shifted. The schoolyard, usually a bustling mess of chattering kids, was now a quiet meadow, buzzing with butterflies. \n",
            "\n",
            "The classroom was gone, replaced by a cozy treehouse, its windows overlooking a sprawling green valley. The teacher, a kindly old woman with a mischievous twinkle in her eye, smiled at him, her voice sounding like the rustling leaves. \n",
            "\n",
            "\"Welcome, Finn,\" she said, her voice a comforting whisper. \"Today we learn about the secrets of the forest.\"\n",
            "\n",
            "Finn spent the day exploring the enchanted world within his backpack, learning about the language of the birds, the wisdom of the trees, and the magic hidden in the most ordinary things. He was a different Finn when he returned home that night, his eyes filled with wonder and his heart overflowing with joy.\n",
            "\n",
            "He continued to visit the magical world within his backpack, learning new things every day. He discovered he could bring back treasures from the forest – a handful of glistening pebbles, a feather from a magnificent bird, a single, perfect flower. \n",
            "\n",
            "But the magic wasn't just about the forest. He found he could use the backpack to visit other places, to see things he'd only dreamed of. He traveled to distant lands, met mythical creatures, and even flew on the back of a giant eagle. \n",
            "\n",
            "The backpack became his secret portal to a world of endless possibilities. And Finn, the boy who once felt lost and ordinary, became a boy with a magic backpack and a heart full of wonder, forever changed by the adventures that unfolded within its worn leather folds. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code generation using  gemini**"
      ],
      "metadata": {
        "id": "Urqnd-fMunJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Set up the model for generating code\n",
        "# model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Create a prompt for advanced code generation\n",
        "prompt = \"\"\"\n",
        "Write a Python script that implements a Convolutional Neural Network (CNN) using TensorFlow and Keras for image classification.\n",
        "The model should be able to classify images from the CIFAR-10 dataset. Include code for data preprocessing, model architecture,\n",
        "training, evaluation, and visualization of training results.\n",
        "\"\"\"\n",
        "\n",
        "# Generate the code with Gemini\n",
        "response = model.generate_content(prompt)\n",
        "print(\"Generated Code:\\n\", response.text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-Xenpcetuu6-",
        "outputId": "48483dec-1e63-4ab2-89ae-5c9fd066a17c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Code:\n",
            " ```python\n",
            "import tensorflow as tf\n",
            "from tensorflow.keras.datasets import cifar10\n",
            "from tensorflow.keras.models import Sequential\n",
            "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
            "from tensorflow.keras.optimizers import Adam\n",
            "from tensorflow.keras.utils import to_categorical\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# Load the CIFAR-10 dataset\n",
            "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
            "\n",
            "# Data preprocessing\n",
            "# Normalize pixel values to the range [0, 1]\n",
            "x_train = x_train.astype('float32') / 255.0\n",
            "x_test = x_test.astype('float32') / 255.0\n",
            "\n",
            "# Convert labels to one-hot encoding\n",
            "y_train = to_categorical(y_train, num_classes=10)\n",
            "y_test = to_categorical(y_test, num_classes=10)\n",
            "\n",
            "# Define the CNN model architecture\n",
            "model = Sequential()\n",
            "\n",
            "# Convolutional layers\n",
            "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
            "model.add(MaxPooling2D((2, 2)))\n",
            "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
            "model.add(MaxPooling2D((2, 2)))\n",
            "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
            "model.add(MaxPooling2D((2, 2)))\n",
            "\n",
            "# Flatten the output of the convolutional layers\n",
            "model.add(Flatten())\n",
            "\n",
            "# Fully connected layers\n",
            "model.add(Dense(128, activation='relu'))\n",
            "model.add(Dropout(0.5))\n",
            "model.add(Dense(10, activation='softmax'))\n",
            "\n",
            "# Compile the model\n",
            "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
            "\n",
            "# Train the model\n",
            "history = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))\n",
            "\n",
            "# Evaluate the model\n",
            "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
            "print('Test Loss:', loss)\n",
            "print('Test Accuracy:', accuracy)\n",
            "\n",
            "# Visualize training results\n",
            "plt.figure(figsize=(12, 4))\n",
            "\n",
            "# Plot training and validation loss\n",
            "plt.subplot(1, 2, 1)\n",
            "plt.plot(history.history['loss'], label='Training Loss')\n",
            "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
            "plt.title('Training and Validation Loss')\n",
            "plt.xlabel('Epochs')\n",
            "plt.ylabel('Loss')\n",
            "plt.legend()\n",
            "\n",
            "# Plot training and validation accuracy\n",
            "plt.subplot(1, 2, 2)\n",
            "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
            "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
            "plt.title('Training and Validation Accuracy')\n",
            "plt.xlabel('Epochs')\n",
            "plt.ylabel('Accuracy')\n",
            "plt.legend()\n",
            "\n",
            "plt.tight_layout()\n",
            "plt.show()\n",
            "```\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "1. **Import Libraries:** Import necessary libraries:\n",
            "   - `tensorflow` for building and training the model.\n",
            "   - `keras` for defining and compiling the model.\n",
            "   - `matplotlib.pyplot` for visualizing training results.\n",
            "\n",
            "2. **Load Data:**\n",
            "   - Load the CIFAR-10 dataset using `cifar10.load_data()`. This splits the data into training (x_train, y_train) and testing sets (x_test, y_test).\n",
            "\n",
            "3. **Data Preprocessing:**\n",
            "   - Normalize pixel values to the range [0, 1] by dividing by 255.0.\n",
            "   - Convert labels (y_train, y_test) to one-hot encoding using `to_categorical()`.\n",
            "\n",
            "4. **Model Architecture:**\n",
            "   - Create a `Sequential` model.\n",
            "   - **Convolutional layers:**\n",
            "     - Add convolutional layers (Conv2D) with ReLU activation, padding, and max pooling (MaxPooling2D) to extract features from the images.\n",
            "   - **Flatten:** Flatten the output of the convolutional layers.\n",
            "   - **Dense layers:** Add fully connected layers (Dense) for classification.\n",
            "   - **Dropout:** Add a dropout layer (Dropout) to prevent overfitting.\n",
            "\n",
            "5. **Model Compilation:**\n",
            "   - Compile the model using `model.compile()`:\n",
            "     - **Optimizer:** Use `Adam` with a learning rate of 0.001.\n",
            "     - **Loss function:** Use `categorical_crossentropy` for multi-class classification.\n",
            "     - **Metrics:** Include `accuracy` to monitor performance.\n",
            "\n",
            "6. **Training:**\n",
            "   - Train the model using `model.fit()`:\n",
            "     - **Training data:** `x_train` and `y_train`.\n",
            "     - **Validation data:** `x_test` and `y_test` for monitoring performance during training.\n",
            "     - **Epochs:** 10 training iterations.\n",
            "     - **Batch size:** 64 images per training step.\n",
            "\n",
            "7. **Evaluation:**\n",
            "   - Evaluate the model on the test set using `model.evaluate()`.\n",
            "   - Print the test loss and accuracy.\n",
            "\n",
            "8. **Visualization:**\n",
            "   - Plot the training and validation loss and accuracy over epochs using `matplotlib`. This helps to visualize the model's learning process and identify overfitting or underfitting.\n",
            "\n",
            "**Note:** This is a basic CNN model. You can further improve it by:\n",
            "\n",
            "- Experimenting with different model architectures (deeper networks, more layers).\n",
            "- Tuning hyperparameters (learning rate, batch size, dropout rate).\n",
            "- Using data augmentation techniques to increase the training dataset.\n",
            "- Implementing early stopping to prevent overfitting.\n",
            "- Exploring more sophisticated optimizers.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Data preprocessing\n",
        "# Normalize pixel values to the range [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "y_train = to_categorical(y_train, num_classes=10)\n",
        "y_test = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "# Define the CNN model architecture\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional layers\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten the output of the convolutional layers\n",
        "model.add(Flatten())\n",
        "\n",
        "# Fully connected layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test Loss:', loss)\n",
        "print('Test Accuracy:', accuracy)\n",
        "\n",
        "# Visualize training results\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "collapsed": true,
        "id": "fJg9gcOpvmOr",
        "outputId": "89a88bb9-6478-4295-8ab1-a4c6c6600c3a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "URL fetch failure on https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz: None -- [Errno 110] Connection timed out",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[1;32m   1349\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1282\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1283\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1277\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    941\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http.client.connect\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m         self.sock = self._create_connection(\n\u001b[0m\u001b[1;32m    943\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    844\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    846\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    832\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/file_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir, force_download)\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDLProgbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[0;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    518\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'urllib.Request'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    535\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[1;32m    537\u001b[0m                                   '_open', req)\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1391\u001b[0;31m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[1;32m   1392\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n",
            "\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1350\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1351\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1352\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 110] Connection timed out>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-65880b96a7ca>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load the CIFAR-10 dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Data preprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/datasets/cifar10.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mdirname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cifar-10-batches-py\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0morigin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     path = get_file(\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0morigin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/file_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir, force_download)\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mURLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: URL fetch failure on https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz: None -- [Errno 110] Connection timed out"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Code genaration using open ai**"
      ],
      "metadata": {
        "id": "vON6UwDzwBRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a prompt for advanced code generation\n",
        "prompt = \"\"\"\n",
        "Write a Python script that implements a Convolutional Neural Network (CNN) using TensorFlow and Keras for image classification.\n",
        "The model should be able to classify images from the CIFAR-10 dataset. Include code for data preprocessing, model architecture,\n",
        "training, evaluation, and visualization of training results.\n",
        "\"\"\"\n",
        "\n",
        "# Generate the code with OpenAI\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",  # Use 'gpt-4' or 'gpt-3.5-turbo' depending on your access\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        ")\n",
        "\n",
        "# Print the generated code\n",
        "print(\"Generated Code:\\n\", response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMkV-pwhw_k7",
        "outputId": "ba8d7aea-0647-4362-c475-6992ea5ce3b7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Code:\n",
            " Certainly, here is an example of a Python script that uses a Convolutional Neural Network (CNN) using TensorFlow and Keras to classify images from the CIFAR-10 dataset.\n",
            "\n",
            "This CNN will consist of a stack of Conv2D and MaxPooling2D layers, ending in a Dense layer for the classification. We will also use Dropout to prevent overfitting.\n",
            "\n",
            "```python\n",
            "import tensorflow as tf\n",
            "from tensorflow.keras import datasets, layers, models\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "# Load and split dataset\n",
            "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
            "\n",
            "# Normalize pixel values to be between 0 and 1\n",
            "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
            "\n",
            "# Create the convolutional base \n",
            "model = models.Sequential()\n",
            "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
            "model.add(layers.MaxPooling2D((2, 2)))\n",
            "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
            "model.add(layers.MaxPooling2D((2, 2)))\n",
            "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
            "\n",
            "# Add Dense layers on top\n",
            "model.add(layers.Flatten())\n",
            "model.add(layers.Dense(64, activation='relu'))\n",
            "model.add(layers.Dense(10))\n",
            "\n",
            "# Compile and train the model\n",
            "model.compile(optimizer='adam', \n",
            "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
            "              metrics=['accuracy'])\n",
            "\n",
            "history = model.fit(train_images, train_labels, epochs=10, \n",
            "                    validation_data=(test_images, test_labels))\n",
            "\n",
            "# Evaluate the model\n",
            "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
            "print('\\nTest accuracy:', test_acc)\n",
            "\n",
            "# Plot the training results\n",
            "plt.plot(history.history['accuracy'], label='accuracy')\n",
            "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
            "plt.xlabel('Epoch')\n",
            "plt.ylabel('Accuracy')\n",
            "plt.ylim([0.5, 1])\n",
            "plt.legend(loc='lower right')\n",
            "```\n",
            "This script works by firstly downloading and preparing the CIFAR-10 dataset, then it creates the Convolutional Neural Network model with TensorFlow's Keras API. It then trains the model on the training data for 10 epochs while validating each epoch with the validation data. After training, it evaluates the model on the test data and prints the test accuracy. Finally, it plots a graph of both the training and validation accuracy over the 10 epochs.\n",
            "\n",
            "Please note, as this is just a simple model, the accuracy might not be that high. Hyperparameter tuning or a more complex model might be needed for a higher accuracy.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using OpenAI with the BLIP Model for Image Captioning**"
      ],
      "metadata": {
        "id": "EuSMUqFy4QFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install torch torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DQWz5_Cq4Obq",
        "outputId": "19ceb6c8-b9ee-42da-d897-e42d8be38aa7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.19.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "from PIL import Image\n",
        "\n",
        "# Load the BLIP processor and model\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400,
          "referenced_widgets": [
            "63b68a50674c46cea6289c06ae1826fe",
            "05ad7eea5d974961970a8c48fb905a8f",
            "92f60f0d88144585971a1f8a70106ae5",
            "a050b8de83c04a68a730a4f1aef0425a",
            "30c3e95842af4bc1bdc194506afe96e3",
            "80a1265d21da40a0abe38da0209f6c5c",
            "f04e8c433b1b46e981342df2ff52bbf1",
            "4241eb231e55440185f2aeef80b11302",
            "0799f94b5d97427b9435462b59b43182",
            "fc7f4d6676004d4eb18605984ef6d5f3",
            "d4513c0f1ada42b7a1031f0377c655c8",
            "6ee9138c32b048859f402b9eff92ad9b",
            "eb8c87ab22ce4c538017934375d47591",
            "22bee754c60b46f5850c6ce5982e167b",
            "a2d7f0e0f8ed44c88312e98b239d0463",
            "374feb3ab7a04dfdb8a4d163e8ddbeac",
            "408c49491b3e47b08a7ebd3d839a1d6e",
            "766c9925e5b6408db4f5bdaeed651584",
            "ba42b220c7814594ac109ebebcd9b099",
            "f4ca9c5d60bf4d3eb4573a64a00b85cc",
            "b3b1d8cb96af4062b0a362f22b37230c",
            "45544ffb144f48a9ad21e8a889d5dc45",
            "dfd46594500a4bb7b04c69378034290a",
            "fef20fe0513b4634b8ff4cb144e7e38f",
            "f83946cbd74946838dc566fec1671413",
            "c6f32a41a3e948f5a6b46d946b702aab",
            "8124ab24d7bb4cf3869a0d5ea43de6fc",
            "1acaae031a2f421db36258bd88856e2d",
            "b778e733ecac4d79a94338c0b6d95607",
            "2da2f0b73bc24a819afec5342a325a1b",
            "6bfe75d1318143c7bcf8c78ab481b10e",
            "f4f51be0ba8a4142990215cf4fb0e016",
            "d634c6fc2dce4a79a2ce9beb4339b54a",
            "4bdaf2c0e5f842bea116c8c127e9cb09",
            "9d707f4b917048ac8318ab1d3d97d826",
            "4dada3e32eaf4147b5441a906f10479a",
            "d34a54d9a48947d69414ec03aaace40c",
            "f5114b03ca0f498d839351d46d6f0966",
            "5f487536663a489ea35303a8f145dc2c",
            "956fe5a3ba3c4dd686e13440ccf923b2",
            "b39474eb702f400d8c6627632ed54865",
            "c32eb5631a754dcfa8916525f08b0a9a",
            "1478b61a65314da8b90f19eab8115678",
            "97c6d06ec7e747a9b7dc21f702527ee3",
            "077b9f12082649c890e668e681bae98c",
            "5b09f2e5c9ad4828b89f94a8c387b802",
            "a96eb429a2344afab03cd87ed601f7bf",
            "714fb53f2f4c4b89acb991f11236d57a",
            "0a4335d2468d40b6a11519929aa9297e",
            "a1f28ccae4dc4e24bb0836dc78945c6e",
            "09933e91635b40b8bd1aec7771120926",
            "d9a0ac3e8c8a47bfb1afc1271e7365cc",
            "d730f43a8e3e40b68f45edfe0ad78a4d",
            "39554839f7ea478282a9286d22b5469c",
            "22ea23198c1c47fea6ccde82ebd8ffe0",
            "aa1120b5575c43bd9ef0bfc16b2f93e1",
            "438694985df4454594373b4c06f49041",
            "8e339e1639a445bb8bd304507bea7ce0",
            "13ea939c1758408a821efd4b59f26c1e",
            "106a145525d64d8aa68bb615a547f91c",
            "21077708eed84c87984ec9fd08a53348",
            "1ec817ccf343438194c7afafb0b0130a",
            "ae8fae40747c49a98e778572d56cb6f3",
            "1b41f5aa278644c380468636c2064518",
            "30586b86cb0e419dbe4f334781d7bc9d",
            "c8e9db5e12a640858b00650fcc1f7b56",
            "8db8d4c4815f47a79a2ba3dc1894b8ef",
            "fe228fe5429f4d20a80ba0518f4da441",
            "2752b84ea80240b89d038521b05d0548",
            "12a57b04b8614a3b9c2643277cab18aa",
            "633f152f1f75411097a3f804010ffad6",
            "7227a3db57554c9d8348dcb414f320f1",
            "a1d0c1e1107b44d5a26d2df6cb8ee60a",
            "b4f438ee818d482f9ae66e8a8d221bec",
            "9092bea3d265455f8cedcd573d8eb682",
            "98e371f65f0a41d18afd072402132310",
            "b2f9ee47ce894804ba4b0d4f481f72e2"
          ]
        },
        "collapsed": true,
        "id": "fbYZqI9A4szc",
        "outputId": "2ca5b1d5-1fe9-4057-f620-568631597a39"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/287 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63b68a50674c46cea6289c06ae1826fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/506 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ee9138c32b048859f402b9eff92ad9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfd46594500a4bb7b04c69378034290a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4bdaf2c0e5f842bea116c8c127e9cb09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "077b9f12082649c890e668e681bae98c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/4.56k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa1120b5575c43bd9ef0bfc16b2f93e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/990M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8db8d4c4815f47a79a2ba3dc1894b8ef"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload an image from your local system\n",
        "uploaded = files.upload()\n",
        "image_path = next(iter(uploaded.keys()))  # Get the image file path from the uploaded files\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Prepare the image for the model\n",
        "inputs = processor(image, return_tensors=\"pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "QVdqqrgS5CAe",
        "outputId": "e9b43a2a-2807-41f2-e8c7-b3db45e3c62d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-761a047c-e88c-4755-b52a-3d1c01ffe22e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-761a047c-e88c-4755-b52a-3d1c01ffe22e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving IB at 3 and a half.jpg to IB at 3 and a half.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Generate an Initial Caption**"
      ],
      "metadata": {
        "id": "gindxIHb5Wld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a caption using the BLIP model\n",
        "output = model.generate(**inputs)\n",
        "initial_caption = processor.decode(output[0], skip_special_tokens=True)\n",
        "print(\"Initial Caption:\", initial_caption)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IggOW5nT5VE7",
        "outputId": "04dcea5c-f5c6-4484-d97c-e15d7d392e1f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Caption: a young boy sitting on a pink suitcase\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt = f\"Refine this image caption: '{initial_caption}'. Make it more descriptive and engaging.\"\n",
        "\n",
        "# Generate refined caption with OpenAI\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",  # Use 'gpt-4' or 'gpt-3.5-turbo' depending on your access\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        ")\n",
        "\n",
        "# Print the refined caption\n",
        "print(\"Refined Caption:\", response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQOdiPcr56YE",
        "outputId": "50bf5a19-5d84-41b1-ca03-750769cae0c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Refined Caption: A sprightly young boy perched atop a bubblegum-pink suitcase, brimming with anticipation and exhilaration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Video Summarization using open ai**"
      ],
      "metadata": {
        "id": "hz_T7kQX86Bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg-python pydub openai\n"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2EX4Bjm9eBd",
        "outputId": "2fced1ed-8b2a-4790-e6e5-906a9555088f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.44.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub, ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0 pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import ffmpeg\n",
        "\n",
        "# Upload the video file\n",
        "uploaded = files.upload()\n",
        "input_video = next(iter(uploaded.keys()))  # Get the uploaded video file name\n",
        "output_audio = 'output_audio.wav'  # Define the output audio file name\n",
        "\n",
        "# Extract audio from video\n",
        "ffmpeg.input(input_video).output(output_audio).run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "lMjtlcZt9qsR",
        "outputId": "017e46cb-89e8-499a-9676-501a6bd31804"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c7154293-8dbc-40e6-9c33-8983c00ea4c9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c7154293-8dbc-40e6-9c33-8983c00ea4c9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving elevator_pitch.mp4 to elevator_pitch.mp4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(output_audio, \"rb\") as audio_file:\n",
        "    transcript = client.audio.transcriptions.create(\n",
        "        model=\"whisper-1\",  # Use the Whisper model\n",
        "        file=audio_file\n",
        "    )\n",
        "\n",
        "# Correct way to access transcription text\n",
        "transcription_text = transcript.text\n",
        "print(\"Transcription:\\n\", transcription_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72TevsmY-emb",
        "outputId": "56c71811-7c50-4d47-94b0-317e6d277509"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription:\n",
            " Hi, I'm Jawash Muganda. I'm pursuing a master's in software engineering with concentration in data science at San Jose State University. I also hold a master's in IT and a bachelor's in computer science. My professional journey includes IT, logistics and manufacturing roles, which I believe have significantly developed my analytical and problem-solving skills. I'm interested in creating AI-powered applications and my current university hands-on projects, have prepared me for a future in AI-driven software development.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Summarize the Transcription Using OpenAI**"
      ],
      "metadata": {
        "id": "8Vs_BmaGB6tm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a prompt to summarize the transcription\n",
        "prompt = f\"Summarize the following transcript: {transcription_text}. Formata the ouput nice for readability\"\n",
        "\n",
        "# Generate a summary with OpenAI\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",  # Use 'gpt-4' or 'gpt-3.5-turbo'\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        ")\n",
        "\n",
        "# Print the generated summary\n",
        "print(\"Summary:\\n\", response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlo-8umcB_OK",
        "outputId": "ba7ed16b-bc8a-4c3f-c948-2be39176575f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary:\n",
            " Speaker: Jawash Muganda\n",
            "- Education: Currently pursuing a master's in software engineering with a focus on data science at San Jose State University. Also holds a master's in IT and a bachelor's in computer science.\n",
            "- Professional Experience: Worked in IT, logistics, and manufacturing roles, which have enhanced his analytical and problem-solving skills.\n",
            "- Career Interest: Interested in creating AI-powered applications.\n",
            "- Preparation: His current university projects provide him hands-on experience, preparing him for a future in AI-driven software development.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Code generation using  Claude**"
      ],
      "metadata": {
        "id": "RfOwkNozCnOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anthropic"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2njb1InAC_aj",
        "outputId": "389d871e-74f0-4d99-813a-fc6447a8c0c7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anthropic\n",
            "  Downloading anthropic-0.34.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.24.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n",
            "Downloading anthropic-0.34.2-py3-none-any.whl (891 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.9/891.9 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anthropic\n",
        "\n",
        "import anthropic\n",
        "import os\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Set your API key\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = \"fake\"\n",
        "\n",
        "# Initialize the client\n",
        "client = anthropic.Anthropic()\n",
        "\n",
        "def ask_claude(prompt, max_tokens=1000):\n",
        "    \"\"\"\n",
        "    Function to send a prompt to Claude and get a response\n",
        "    \"\"\"\n",
        "    message = client.messages.create(\n",
        "        model=\"claude-3-opus-20240229\",  # Updated model name\n",
        "        max_tokens=max_tokens,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return message.content[0].text\n",
        "\n",
        "# Example: Generate Python code for a simple web scraper\n",
        "prompt = \"\"\"\n",
        "Write Python code for a web scraper that does the following:\n",
        "1. Uses the requests library to fetch the content of a given URL\n",
        "2. Uses BeautifulSoup to parse the HTML\n",
        "3. Extracts all the paragraph texts from the page\n",
        "4. Saves the extracted text to a file\n",
        "\n",
        "Please include necessary imports and error handling.\n",
        "\"\"\"\n",
        "\n",
        "code_response = ask_claude(prompt)\n",
        "\n",
        "# Display the generated code\n",
        "display(Markdown(f\"```python\\n{code_response}\\n```\"))\n",
        "\n",
        "# Example: Ask Claude to explain the generated code\n",
        "explanation_prompt = f\"Explain the following Python code in detail:\\n\\n{code_response}\"\n",
        "\n",
        "explanation = ask_claude(explanation_prompt)\n",
        "\n",
        "# Display the explanation\n",
        "display(Markdown(f\"## Explanation\\n\\n{explanation}\"))\n",
        "\n",
        "# Interactive prompt\n",
        "while True:\n",
        "    user_prompt = input(\"Enter your prompt (or 'quit' to exit): \")\n",
        "    if user_prompt.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "    response = ask_claude(user_prompt)\n",
        "    display(Markdown(f\"## Claude's Response\\n\\n{response}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "WHZIZgH7EYJ4",
        "outputId": "1864d315-52f0-4c0c-9897-0aa39d971077"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: anthropic in /usr/local/lib/python3.10/dist-packages (0.34.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic) (0.19.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from anthropic) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->anthropic) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.20.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic) (0.24.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic) (2.0.7)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "```python\nHere's a Python script for a web scraper that fulfills the given requirements:\n\n```python\nimport requests\nfrom bs4 import BeautifulSoup\n\ndef scrape_webpage(url, output_file):\n    try:\n        # Send a GET request to the URL\n        response = requests.get(url)\n        response.raise_for_status()  # Raise an exception for 4xx or 5xx status codes\n\n        # Create a BeautifulSoup object to parse the HTML content\n        soup = BeautifulSoup(response.text, 'html.parser')\n\n        # Find all the paragraph elements on the page\n        paragraphs = soup.find_all('p')\n\n        # Extract the text from each paragraph element\n        paragraph_texts = [p.get_text() for p in paragraphs]\n\n        # Join the paragraph texts into a single string\n        extracted_text = '\\n\\n'.join(paragraph_texts)\n\n        # Save the extracted text to a file\n        with open(output_file, 'w', encoding='utf-8') as file:\n            file.write(extracted_text)\n\n        print(f\"Successfully scraped the webpage and saved the content to {output_file}\")\n\n    except requests.exceptions.RequestException as e:\n        print(f\"Error occurred while making the request: {e}\")\n    except Exception as e:\n        print(f\"An error occurred: {e}\")\n\n# Example usage\nurl = 'https://example.com'\noutput_file = 'scraped_content.txt'\nscrape_webpage(url, output_file)\n```\n\nExplanation:\n\n1. The necessary libraries, `requests` and `bs4` (BeautifulSoup), are imported at the beginning of the script.\n\n2. The `scrape_webpage` function takes two parameters: `url` (the URL of the webpage to scrape) and `output_file` (the name of the file to save the extracted text).\n\n3. Inside the function, a `try` block is used to handle exceptions that may occur during the scraping process.\n\n4. The script sends a GET request to the specified URL using `requests.get()`. If the response status code indicates an error (4xx or 5xx), an exception is raised using `response.raise_for_status()`.\n\n5. A BeautifulSoup object is created by passing the response text and the HTML parser to use (`'html.parser'`).\n\n6. The script finds all the paragraph elements (`<p>`) on the page using `soup.find_all('p')`.\n\n7. The text content of each paragraph element is extracted using `p.get_text()` and stored in a list called `paragraph_texts`.\n\n8. The extracted paragraph texts are joined into a single string using `'\\n\\n'.join(paragraph_texts)`, where `'\\n\\n'` is used as a separator between paragraphs.\n\n9. The extracted text is saved to the specified output file using `open()` in write mode ('w'). The encoding is set to 'utf-8' to handle Unicode characters.\n\n10. If any exceptions occur during the scraping process, they are caught in the `except` blocks. The script prints an error message indicating the type of exception that occurred.\n\n11. Finally, an example usage of the `scrape_webpage` function is provided, where the URL and output file name are specified.\n\nNote: Make sure to replace `'https://example.com'` with the actual URL of the webpage you want to scrape.\n\nThis script provides a basic web scraper that fetches the content of a webpage, extracts the paragraph texts, and saves them to a file, with error handling included.\n```"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Explanation\n\nCertainly! Let's go through the Python code you provided and explain it in detail:\n\n1. Importing necessary libraries:\n   - `import requests`: This line imports the `requests` library, which is used to send HTTP requests and retrieve the content of web pages.\n   - `from bs4 import BeautifulSoup`: This line imports the `BeautifulSoup` class from the `bs4` (BeautifulSoup4) library, which is used for parsing HTML and XML documents.\n\n2. Defining the `scrape_webpage` function:\n   - The function takes two parameters: `url` (the URL of the webpage to scrape) and `output_file` (the name of the file to save the extracted text).\n   - The function is responsible for scraping the webpage and saving the extracted content to a file.\n\n3. Sending a GET request to the URL:\n   - The `requests.get(url)` function sends a GET request to the specified URL and returns the response.\n   - The `response.raise_for_status()` method is called to raise an exception if the response status code indicates an error (4xx or 5xx).\n\n4. Creating a BeautifulSoup object:\n   - The `BeautifulSoup` class is instantiated with the response text (`response.text`) and the HTML parser to use (`'html.parser'`).\n   - This creates a BeautifulSoup object, which allows for easy navigation and extraction of data from the HTML content.\n\n5. Finding all paragraph elements:\n   - The `soup.find_all('p')` method finds all the paragraph elements (`<p>`) on the page and returns them as a list.\n   - The resulting list is stored in the `paragraphs` variable.\n\n6. Extracting text from paragraph elements:\n   - A list comprehension is used to extract the text content of each paragraph element using `p.get_text()`.\n   - The extracted text is stored in the `paragraph_texts` list.\n\n7. Joining paragraph texts into a single string:\n   - The `'\\n\\n'.join(paragraph_texts)` expression joins the extracted paragraph texts into a single string.\n   - The `'\\n\\n'` separator is used to add two newline characters between each paragraph.\n   - The resulting string is stored in the `extracted_text` variable.\n\n8. Saving the extracted text to a file:\n   - The `open()` function is used to open the specified `output_file` in write mode ('w') with UTF-8 encoding.\n   - The `file.write()` method is used to write the `extracted_text` to the file.\n   - The file is automatically closed after the `with` block.\n\n9. Handling exceptions:\n   - The code is wrapped in a `try` block to handle exceptions that may occur during the scraping process.\n   - If a `requests.exceptions.RequestException` occurs (e.g., network error, invalid URL), an error message is printed indicating the specific exception.\n   - If any other exception occurs, a generic error message is printed.\n\n10. Example usage:\n    - The `scrape_webpage` function is called with a specific URL (`'https://example.com'`) and output file name (`'scraped_content.txt'`).\n    - Make sure to replace `'https://example.com'` with the actual URL of the webpage you want to scrape.\n\nThis script provides a basic web scraper that fetches the content of a webpage, extracts the text from paragraph elements, and saves the extracted text to a file. It includes error handling to catch and report any exceptions that may occur during the scraping process."
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your prompt (or 'quit' to exit): word's population analysis\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Claude's Response\n\nHere's a brief analysis of the world's population:\n\n1. Current population: As of 2023, the world's population is estimated to be around 8 billion people.\n\n2. Population growth: The global population has been growing rapidly over the past century due to advancements in healthcare, nutrition, and living standards. However, the growth rate has slowed down in recent years.\n\n3. Regions with highest population: Asia is the most populous continent, with over 4.7 billion people. Africa has the second-largest population, followed by Europe, North America, South America, and Australia/Oceania.\n\n4. Countries with the largest populations: China and India have the world's largest populations, each with over 1.4 billion people. Other countries with large populations include the United States, Indonesia, Pakistan, Brazil, Nigeria, and Bangladesh.\n\n5. Urbanization: More than half of the world's population lives in urban areas, and this trend is expected to continue as people migrate from rural to urban areas for better job opportunities and living conditions.\n\n6. Age structure: The global population is aging due to declining fertility rates and increasing life expectancy. This demographic shift has significant implications for healthcare, social security, and the economy.\n\n7. Future projections: The United Nations projects that the world's population will reach 9.7 billion by 2050 and could peak at nearly 11 billion around 2100. However, these projections are subject to change based on factors such as fertility rates, mortality rates, and migration patterns."
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your prompt (or 'quit' to exit): Exit\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Claude's Response\n\nGoodbye! It was a pleasure chatting with you. Feel free to reach out anytime if you have more questions or just want to talk. Take care!"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your prompt (or 'quit' to exit): quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **generate an opinion piece criticizing Kenya's politics using the Anthropic API**"
      ],
      "metadata": {
        "id": "N9f1YbfBHoi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Initialize the client\n",
        "# client = anthropic.Anthropic()\n",
        "\n",
        "def ask_claude(prompt, max_tokens=1000):\n",
        "    \"\"\"\n",
        "    Function to send a prompt to Claude and get a response\n",
        "    \"\"\"\n",
        "    message = client.messages.create(\n",
        "        model=\"claude-3-opus-20240229\",\n",
        "        max_tokens=max_tokens,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return message.content[0].text\n",
        "\n",
        "# Prompt for generating an opinion piece\n",
        "prompt = \"\"\"\n",
        "Write an opinion piece of about 500 words criticizing Kenya's politics.\n",
        "Include the following points:\n",
        "1. Issues with corruption\n",
        "2. Tribal politics and its impact on national unity\n",
        "3. Economic challenges and wealth inequality\n",
        "4. The need for electoral reforms\n",
        "5. Suggestions for improving governance\n",
        "\n",
        "Ensure the tone is critical but constructive, and back up claims with general examples\n",
        "(no need for specific names or dates). The piece should be suitable for a newspaper op-ed.\n",
        "\"\"\"\n",
        "\n",
        "opinion_piece = ask_claude(prompt)\n",
        "\n",
        "# Display the generated opinion piece\n",
        "display(Markdown(f\"## Opinion Piece on Kenya's Politics\\n\\n{opinion_piece}\"))\n",
        "\n",
        "# Optional: Ask for a summary of the main points\n",
        "summary_prompt = \"Summarize the main points of the opinion piece in bullet points.\"\n",
        "\n",
        "summary = ask_claude(summary_prompt)\n",
        "\n",
        "# Display the summary\n",
        "display(Markdown(f\"## Summary of Main Points\\n\\n{summary}\"))\n",
        "\n",
        "# Interactive prompt for follow-up questions or modifications\n",
        "while True:\n",
        "    user_prompt = input(\"Enter a follow-up question or 'quit' to exit: \")\n",
        "    if user_prompt.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "    response = ask_claude(user_prompt)\n",
        "    display(Markdown(f\"## Claude's Response\\n\\n{response}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "gQbTv-0UHnJu",
        "outputId": "8b0bdb45-b597-448c-9cbd-4ecd6ae1b605"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Opinion Piece on Kenya's Politics\n\nKenya's Politics: A Call for Reform\n\nKenya's political landscape has long been marred by endemic corruption, tribal divisions, and economic inequality. These deep-rooted issues have hindered the nation's progress and undermined the very foundations of its democracy. It is high time for Kenyans to demand change and hold their leaders accountable for the betterment of the country.\n\nCorruption has become a cancer that has spread throughout the political system. From local government offices to the highest echelons of power, the misuse of public funds and abuse of authority have become all too common. Scandals involving the embezzlement of millions of dollars meant for public projects have eroded trust in the government. This rampant graft has not only lined the pockets of the elite but has also deprived ordinary citizens of essential services and infrastructure. The lack of transparency and accountability has allowed corrupt officials to operate with impunity, further entrenching the problem.\n\nMoreover, tribal politics continue to divide the nation along ethnic lines. Political parties and campaigns often exploit these divisions for their own gain, fueling tensions and undermining national unity. The focus on tribal loyalties rather than merit and competence has led to a political culture of patronage and nepotism. This not only perpetuates inequality but also stifles the emergence of visionary leaders who can unite the country and drive progress. It is crucial for Kenyans to transcend these tribal identities and embrace a shared national identity based on common values and aspirations.\n\nThe economic challenges facing Kenya are closely intertwined with its political troubles. Despite pockets of growth and development, wealth inequality remains a glaring issue. A small elite continues to amass wealth and influence while a significant portion of the population grapples with poverty and lack of opportunities. The unequal distribution of resources and the concentration of economic power in the hands of a few have led to a sense of marginalization and frustration among the masses. Addressing this inequality requires political will and policies that prioritize inclusive growth, job creation, and social safety nets.\n\nTo tackle these challenges, Kenya must undertake comprehensive electoral reforms. The current system is prone to manipulation and irregularities, undermining the integrity of the democratic process. Strengthening the independence and capacity of the electoral commission, ensuring transparency in campaign financing, and enhancing voter education are crucial steps. By creating a level playing field and empowering citizens to make informed choices, electoral reforms can help restore faith in the political process and promote accountability.\n\nImproving governance in Kenya requires a multi-faceted approach. First and foremost, there must be a genuine commitment to the fight against corruption. This involves strengthening anti-corruption institutions, prosecuting offenders irrespective of their status, and fostering a culture of integrity in public service. Additionally, promoting transparency and public participation in decision-making processes can help enhance accountability and restore trust in the government.\n\nFurthermore, investing in education and civic engagement can empower citizens to hold their leaders accountable and demand better governance. Encouraging the growth of a vibrant civil society and independent media can provide checks and balances on power and amplify the voices of the people.\n\nKenya stands at a critical juncture in its political journey. The challenges it faces are significant, but they are not insurmountable. By confronting corruption, transcending tribal divisions, addressing economic inequality, and undertaking electoral reforms, Kenya can build a more inclusive, prosperous, and democratic society. It is up to the Kenyan people to demand change and hold their leaders accountable. Only through collective effort and a commitment to the greater good can Kenya realize its full potential and create a brighter future for all its citizens."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Summary of Main Points\n\nI apologize, but you haven't provided me with an opinion piece to summarize. If you can share the text of the opinion piece you'd like me to analyze, I'd be happy to read through it and provide a summary of the main points in bullet form for you."
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a follow-up question or 'quit' to exit: Quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Analyze Kenya's market and identify potentially profitable export opportunities from the USA to Kenya. _claude**"
      ],
      "metadata": {
        "id": "PBlqYeFmJy7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def ask_claude(prompt, max_tokens=2000):\n",
        "    \"\"\"\n",
        "    Function to send a prompt to Claude and get a response\n",
        "    \"\"\"\n",
        "    message = client.messages.create(\n",
        "        model=\"claude-3-opus-20240229\",\n",
        "        max_tokens=max_tokens,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return message.content[0].text\n",
        "\n",
        "def generate_analysis(topic):\n",
        "    prompt = f\"\"\"\n",
        "    Provide a detailed analysis on {topic}. Include relevant data and insights.\n",
        "    Structure your response with clear headings and bullet points where appropriate.\n",
        "    \"\"\"\n",
        "    return ask_claude(prompt)\n",
        "\n",
        "def generate_swot(topic):\n",
        "    prompt = f\"\"\"\n",
        "    Conduct a SWOT analysis for {topic}.\n",
        "    Clearly list the Strengths, Weaknesses, Opportunities, and Threats.\n",
        "    Provide brief explanations for each point.\n",
        "    \"\"\"\n",
        "    return ask_claude(prompt)\n",
        "\n",
        "def generate_business_plan(topic):\n",
        "    prompt = f\"\"\"\n",
        "    Create a brief business plan outline for {topic}.\n",
        "    Include sections on:\n",
        "    1. Executive Summary\n",
        "    2. Market Analysis\n",
        "    3. Product/Service Offering\n",
        "    4. Marketing Strategy\n",
        "    5. Financial Projections\n",
        "    6. Conclusion\n",
        "    Provide concise content for each section.\n",
        "    \"\"\"\n",
        "    return ask_claude(prompt)\n",
        "\n",
        "# Generate Market Analysis\n",
        "market_analysis = generate_analysis(\"the current market conditions in Kenya, focusing on import trends and consumer needs. Identify potential products or services that could be profitably exported from the USA to Kenya.\")\n",
        "\n",
        "# Generate SWOT Analysis\n",
        "swot_analysis = generate_swot(\"exporting goods from the USA to Kenya\")\n",
        "\n",
        "# Generate Business Plan Outline\n",
        "business_plan = generate_business_plan(\"a business exporting high-potential products from the USA to Kenya\")\n",
        "\n",
        "# Display the results\n",
        "display(Markdown(f\"## Market Analysis: Kenya's Import Market\\n\\n{market_analysis}\"))\n",
        "display(Markdown(f\"## SWOT Analysis: Exporting from USA to Kenya\\n\\n{swot_analysis}\"))\n",
        "display(Markdown(f\"## Business Plan Outline: USA to Kenya Export Business\\n\\n{business_plan}\"))\n",
        "\n",
        "# Interactive prompt for follow-up questions\n",
        "while True:\n",
        "    user_prompt = input(\"Enter a follow-up question or 'quit' to exit: \")\n",
        "    if user_prompt.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "    response = ask_claude(user_prompt)\n",
        "    display(Markdown(f\"## Additional Information\\n\\n{response}\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k4A8aKl-JpuS",
        "outputId": "c0aef59d-32a1-4eda-aa15-fe3a215728b3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Market Analysis: Kenya's Import Market\n\nMarket Analysis: Kenya's Import Trends and Consumer Needs\n\n1. Economic Overview\n   - Kenya's GDP: $95.5 billion (2020)\n   - GDP growth rate: -0.3% (2020), projected to recover to 7.6% (2021)\n   - Population: 53.8 million (2020)\n\n2. Import Trends\n   - Total imports: $15.4 billion (2020)\n   - Major import categories:\n     - Machinery and transportation equipment (29%)\n     - Petroleum products (18%)\n     - Manufactured goods (17%)\n     - Chemicals (13%)\n   - Top import partners: China (23%), India (10%), UAE (8%), Saudi Arabia (7%), Japan (5%)\n\n3. Consumer Needs and Preferences\n   - Growing middle class with increasing purchasing power\n   - Preference for quality and affordable products\n   - Increasing demand for technology and digital services\n   - Rising health consciousness and demand for healthcare products\n   - Urbanization driving demand for processed foods and convenience products\n\n4. Potential Export Opportunities from the USA to Kenya\n   a. Agricultural Machinery and Equipment\n      - Kenya's agriculture sector contributes 34% to GDP\n      - Demand for modern farming equipment to improve productivity\n      - Potential products: tractors, irrigation systems, precision farming tools\n\n   b. Healthcare Products and Equipment\n      - Growing healthcare sector due to government investments and private sector participation\n      - Demand for medical devices, diagnostic equipment, and pharmaceuticals\n      - Potential products: medical imaging equipment, surgical instruments, generic drugs\n\n   c. Information and Communication Technology (ICT) Solutions\n      - Kenya is a regional hub for ICT innovation and services\n      - Demand for software solutions, e-commerce platforms, and digital financial services\n      - Potential services: cloud computing, cybersecurity solutions, mobile app development\n\n   d. Renewable Energy Technologies\n      - Government initiatives to increase renewable energy adoption\n      - Opportunities in solar, wind, and geothermal energy sectors\n      - Potential products: solar panels, wind turbines, energy storage systems\n\n   e. Educational Services and Products\n      - Growing demand for quality education and vocational training\n      - Opportunities in e-learning, educational software, and training programs\n      - Potential services: online courses, educational technology, teacher training\n\n5. Market Entry Strategies\n   - Collaborate with local distributors and partners for market knowledge and distribution networks\n   - Participate in trade fairs and exhibitions to showcase products and services\n   - Engage with relevant government agencies and industry associations for support and guidance\n   - Consider setting up a local presence or representative office for better market access\n\nIn conclusion, Kenya presents significant opportunities for U.S. exporters in sectors such as agriculture, healthcare, ICT, renewable energy, and education. By understanding the import trends, consumer needs, and market dynamics, U.S. companies can tailor their products and services to meet the growing demand in Kenya. Effective market entry strategies and collaboration with local partners will be key to successfully navigating the Kenyan market and establishing a strong presence in the region."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## SWOT Analysis: Exporting from USA to Kenya\n\nHere is a SWOT analysis for exporting goods from the USA to Kenya:\n\nStrengths:\n1. Quality products: The USA is known for producing high-quality goods that are in demand globally.\n2. Strong trade relations: The USA and Kenya have a strong trade partnership, with the African Growth and Opportunity Act (AGOA) facilitating duty-free exports to Kenya.\n3. Developed infrastructure: The USA has a well-developed transportation and logistics infrastructure, making it easier to export goods efficiently.\n\nWeaknesses:\n1. Distance: The geographical distance between the USA and Kenya can lead to longer shipping times and higher transportation costs.\n2. Cultural differences: Differences in business practices, language, and cultural norms can pose challenges when conducting business in Kenya.\n3. Competition: Other countries, such as China and India, also export goods to Kenya, creating competition for American products.\n\nOpportunities:\n1. Growing middle class: Kenya's growing middle class presents an opportunity for American businesses to tap into a new consumer market.\n2. Diversification: Exporting to Kenya allows American businesses to diversify their customer base and reduce dependence on domestic markets.\n3. Emerging sectors: Kenya's emerging sectors, such as technology and renewable energy, present opportunities for American companies to provide goods and expertise.\n\nThreats:\n1. Political instability: Political instability and security concerns in Kenya can disrupt trade and increase the risk for American businesses.\n2. Economic fluctuations: Economic downturns or currency fluctuations in Kenya can impact the demand for American goods and the profitability of exports.\n3. Regulatory changes: Changes in Kenyan trade regulations, import duties, or bureaucratic processes can create additional barriers and costs for American exporters."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Business Plan Outline: USA to Kenya Export Business\n\nBusiness Plan Outline: Exporting High-Potential Products from the USA to Kenya\n\n1. Executive Summary\n   - Overview of the business concept: Exporting high-potential products from the USA to Kenya\n   - Key objectives and goals\n   - Unique selling proposition and competitive advantage\n   - Brief summary of financial projections\n\n2. Market Analysis\n   - Overview of the Kenyan market, including economic, political, and social factors\n   - Target market segments and customer profiles\n   - Competitive landscape analysis\n   - Market trends, opportunities, and challenges\n\n3. Product/Service Offering\n   - Description of the high-potential products to be exported\n   - Product features, benefits, and unique selling points\n   - Sourcing and supply chain management\n   - Quality control and product standards\n\n4. Marketing Strategy\n   - Pricing strategy, considering market conditions and competition\n   - Distribution channels and partnerships in Kenya\n   - Promotional and advertising strategies\n   - Sales forecasts and growth projections\n\n5. Financial Projections\n   - Startup costs and initial investment requirements\n   - Sales and revenue projections for the first three to five years\n   - Profit and loss statement\n   - Break-even analysis\n   - Cash flow projections\n\n6. Conclusion\n   - Summary of the business plan and key points\n   - Restatement of the unique selling proposition and competitive advantage\n   - Future growth and expansion plans\n   - Call to action for potential investors or partners"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a follow-up question or 'quit' to exit: Quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **summaries of modern philosophies, including their founders and potential criticisms or errors associated with each _Claude**"
      ],
      "metadata": {
        "id": "qdAox0cpOc0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def ask_claude(prompt, max_tokens=2000):\n",
        "    \"\"\"\n",
        "    Function to send a prompt to Claude and get a response\n",
        "    \"\"\"\n",
        "    message = client.messages.create(\n",
        "        model=\"claude-3-opus-20240229\",\n",
        "        max_tokens=max_tokens,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "    return message.content[0].text\n",
        "\n",
        "def summarize_philosophy(philosophy):\n",
        "    prompt = f\"\"\"\n",
        "    Provide a summary of {philosophy} as a modern philosophical movement. Include the following:\n",
        "    1. A brief overview of the philosophy\n",
        "    2. Key founders or prominent figures\n",
        "    3. Main ideas and concepts\n",
        "    4. Potential criticisms or errors associated with this philosophy\n",
        "    5. Its influence on modern thought\n",
        "\n",
        "    Structure your response with clear headings and bullet points where appropriate.\n",
        "    \"\"\"\n",
        "    return ask_claude(prompt)\n",
        "\n",
        "# List of modern philosophies to summarize\n",
        "philosophies = [\n",
        "    \"Existentialism\",\n",
        "    \"Postmodernism\",\n",
        "    \"Phenomenology\",\n",
        "    \"Pragmatism\",\n",
        "    \"Analytical Philosophy\",\n",
        "    \"Critical Theory\",\n",
        "    \"Feminism (as a philosophical movement)\"\n",
        "]\n",
        "\n",
        "# Generate and display summaries for each philosophy\n",
        "for philosophy in philosophies:\n",
        "    summary = summarize_philosophy(philosophy)\n",
        "    display(Markdown(f\"## {philosophy}\\n\\n{summary}\"))\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator between philosophies\n",
        "\n",
        "# Interactive prompt for additional philosophies or questions\n",
        "while True:\n",
        "    user_input = input(\"Enter a philosophy to summarize or a question (or 'quit' to exit): \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "\n",
        "    response = ask_claude(f\"Summarize the philosophy of {user_input} or answer this question: {user_input}\")\n",
        "    display(Markdown(f\"## Response\\n\\n{response}\"))\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")  # Separator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H3fmIAgXPUUh",
        "outputId": "f55c7f1a-42b0-4224-e049-3ed3df42f605"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Existentialism\n\nExistentialism Summary\n\n1. Overview:\n   - Existentialism is a philosophical movement that emerged in the late 19th and early 20th centuries\n   - Focuses on the individual's existence, freedom, and responsibility\n   - Emphasizes the uniqueness of each person's experience and the absence of a predetermined essence or purpose\n\n2. Key Founders and Prominent Figures:\n   - Søren Kierkegaard (1813-1855) - Danish philosopher, often considered the first existentialist thinker\n   - Friedrich Nietzsche (1844-1900) - German philosopher, known for his concepts of the \"will to power\" and the \"death of God\"\n   - Jean-Paul Sartre (1905-1980) - French philosopher and playwright, a central figure in 20th-century existentialism\n   - Martin Heidegger (1889-1976) - German philosopher, influential in the development of existential phenomenology\n   - Simone de Beauvoir (1908-1986) - French writer and philosopher, known for her contributions to feminist existentialism\n\n3. Main Ideas and Concepts:\n   - Existence precedes essence: Individuals create their own essence through their choices and actions\n   - Authenticity: The need for individuals to take responsibility for their lives and live according to their own values\n   - Freedom and responsibility: Humans are fundamentally free, but this freedom comes with the responsibility to create meaning in their lives\n   - Absurdity: The inherent meaninglessness of life and the human struggle to find purpose in an indifferent universe\n   - Anxiety and despair: The emotional consequences of confronting one's freedom and the absence of inherent meaning\n\n4. Potential Criticisms or Errors:\n   - Subjectivism: Existentialism's emphasis on individual experience can lead to a rejection of objective truth or moral standards\n   - Nihilism: The focus on the absurdity of life may lead to a sense of hopelessness or a lack of motivation to engage with the world\n   - Elitism: Existentialism has been criticized for being an intellectual philosophy that may not resonate with the experiences of ordinary people\n   - Lack of clear definition: The diversity of thought within existentialism can make it difficult to define as a cohesive philosophical movement\n\n5. Influence on Modern Thought:\n   - Existentialism has had a significant impact on various fields, including literature, psychology, and the arts\n   - It has influenced the development of humanistic psychology, emphasizing the importance of individual experience and personal growth\n   - Existentialist themes are prevalent in modern literature, theater, and cinema, exploring the human condition and the search for meaning\n   - Existentialism has contributed to the development of postmodernism, with its skepticism towards grand narratives and emphasis on subjective interpretation"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Postmodernism\n\nPostmodernism Summary\n\n1. Overview:\n   - Postmodernism is a philosophical movement that emerged in the late 20th century.\n   - It challenges the fundamental assumptions of Enlightenment rationality, objectivity, and universal truths.\n   - Postmodernism emphasizes the role of language, power relations, and social constructs in shaping reality and knowledge.\n\n2. Key Founders and Prominent Figures:\n   - Jean-François Lyotard\n   - Jacques Derrida\n   - Michel Foucault\n   - Jean Baudrillard\n   - Richard Rorty\n\n3. Main Ideas and Concepts:\n   - Rejection of meta-narratives: Postmodernism rejects grand, overarching theories or explanations of reality, such as religion, science, or Marxism.\n   - Deconstruction: A method of critical analysis that seeks to expose the underlying assumptions and contradictions in texts and discourses.\n   - Power and knowledge: Postmodernists argue that power relations shape knowledge and truth, and that dominant discourses marginalize alternative perspectives.\n   - Linguistic relativism: Language is seen as a social construct that shapes our understanding of reality rather than reflecting an objective truth.\n   - Pluralism and diversity: Postmodernism celebrates diversity, difference, and multiplicity, rejecting the idea of a single, universal truth or cultural norm.\n\n4. Criticisms and Potential Errors:\n   - Relativism: Critics argue that postmodernism's rejection of objective truth and universal values can lead to moral and epistemological relativism.\n   - Self-refutation: Some critics claim that postmodernism's critique of meta-narratives and universal truths is itself a meta-narrative.\n   - Political passivity: The emphasis on deconstruction and the rejection of grand narratives may lead to political disengagement and a lack of positive action.\n   - Obscurantism: Postmodern writing is often criticized for being obscure, jargon-laden, and inaccessible to a broader audience.\n\n5. Influence on Modern Thought:\n   - Postmodernism has significantly influenced various fields, including literature, art, architecture, sociology, and cultural studies.\n   - It has contributed to the rise of identity politics, multiculturalism, and the critique of dominant power structures.\n   - Postmodern ideas have been applied to analyze various social issues, such as gender, race, and sexuality.\n   - The postmodern critique of objective truth has influenced the development of social constructionism and critical theory.\n   - Postmodernism's emphasis on language and discourse has shaped the development of fields like discourse analysis and semiotics.\n\nIn conclusion, postmodernism is a complex and influential philosophical movement that has challenged traditional notions of truth, objectivity, and universal values. While it has faced criticism for potential relativism and obscurantism, its ideas have significantly shaped contemporary thought across various disciplines."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Phenomenology\n\nPhenomenology as a Modern Philosophical Movement\n\n1. Overview\n   - Phenomenology is a philosophical approach that emphasizes the study of consciousness and subjective experience.\n   - It seeks to describe and understand the structures of human experience and the essence of phenomena as they appear to the conscious mind.\n\n2. Key Founders and Prominent Figures\n   - Edmund Husserl (1859-1938): Considered the founder of phenomenology, developed the concept of \"intentionality\" and the phenomenological method.\n   - Martin Heidegger (1889-1976): Expanded phenomenology to include the study of human existence (Dasein) and being-in-the-world.\n   - Maurice Merleau-Ponty (1908-1961): Focused on embodiment and perception, emphasizing the role of the body in human experience.\n   - Jean-Paul Sartre (1905-1980): Developed existential phenomenology, exploring human freedom, responsibility, and authenticity.\n\n3. Main Ideas and Concepts\n   - Intentionality: The idea that consciousness is always directed towards an object or phenomenon.\n   - Bracketing (epoché): Suspending judgments and preconceptions to focus on the pure experience of phenomena.\n   - Lifeworld (Lebenswelt): The pre-reflective, lived experience of the world as encountered in everyday life.\n   - Embodiment: The recognition that the body plays a crucial role in shaping human experience and perception.\n   - Intersubjectivity: The shared nature of human experience and the importance of understanding others' perspectives.\n\n4. Potential Criticisms or Errors\n   - Subjectivism: Some critics argue that phenomenology's emphasis on subjective experience neglects the importance of objective reality.\n   - Solipsism: The focus on individual consciousness may lead to a form of solipsism, where the existence of the external world is questioned.\n   - Lack of empirical grounding: Phenomenological methods are often criticized for lacking scientific rigor and relying too heavily on introspection.\n   - Difficulty in achieving true bracketing: Critics question whether it is possible to completely suspend preconceptions and biases.\n\n5. Influence on Modern Thought\n   - Phenomenology has had a significant impact on various disciplines, including psychology, sociology, and anthropology.\n   - It has influenced the development of existentialism, hermeneutics, and poststructuralism.\n   - Phenomenological methods have been applied to the study of various phenomena, such as perception, emotion, and social interaction.\n   - Phenomenology has contributed to the understanding of the lived experience of individuals in different contexts, such as illness, disability, and marginalization.\n   - It has also inspired the development of qualitative research methods, such as interpretative phenomenological analysis (IPA)."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Pragmatism\n\nPragmatism: A Modern Philosophical Movement\n\n1. Overview:\n   - Pragmatism is a philosophical movement that originated in the United States in the late 19th century.\n   - It emphasizes the practical consequences and real-world effects of ideas and beliefs as the key criterion for determining their value and truth.\n   - Pragmatism rejects the notion of absolute truth and instead focuses on the usefulness and workability of ideas in a given context.\n\n2. Key Founders and Prominent Figures:\n   - Charles Sanders Peirce (1839-1914): Considered the founder of pragmatism, introduced the pragmatic maxim.\n   - William James (1842-1910): Popularized pragmatism, applied it to various philosophical and psychological issues.\n   - John Dewey (1859-1952): Developed pragmatism further, particularly in the context of education and social reform.\n   - Other notable figures include George Herbert Mead, Josiah Royce, and F.C.S. Schiller.\n\n3. Main Ideas and Concepts:\n   - Pragmatic Maxim: The meaning of a concept or idea lies in its practical consequences and effects.\n   - Instrumentalism: Ideas and theories are instruments for solving problems and navigating the world, rather than abstract truths.\n   - Fallibilism: All beliefs and knowledge claims are provisional and subject to revision based on future experiences and evidence.\n   - Pluralism: There can be multiple valid perspectives and approaches to understanding reality.\n   - Emphasis on Experience: Pragmatism stresses the importance of concrete experiences and practical outcomes over abstract theories.\n\n4. Potential Criticisms or Errors:\n   - Relativism: Critics argue that pragmatism can lead to a form of relativism, where truth becomes subjective and dependent on individual or cultural contexts.\n   - Lack of Foundational Principles: Some argue that pragmatism lacks a solid foundation for moral and ethical principles.\n   - Overemphasis on Practicality: Pragmatism's focus on practical consequences may neglect other important aspects of human experience and knowledge.\n   - Potential for Shortsightedness: The emphasis on immediate practical results may overlook long-term consequences or deeper philosophical questions.\n\n5. Influence on Modern Thought:\n   - Pragmatism has had a significant impact on various fields, including education, psychology, sociology, and politics.\n   - It has influenced the development of functionalism in psychology and the philosophy of education, particularly through the work of John Dewey.\n   - Pragmatism has also contributed to the development of certain strands of analytic philosophy and has been influential in shaping American intellectual and cultural life.\n   - The pragmatic approach has been applied to diverse areas such as scientific inquiry, legal reasoning, and public policy decision-making.\n\nIn summary, pragmatism is a philosophical movement that emphasizes the practical consequences and real-world effects of ideas as the primary criterion for determining their value and truth. Its main ideas include the pragmatic maxim, instrumentalism, fallibilism, pluralism, and an emphasis on experience. While pragmatism has faced criticisms such as relativism and a potential for shortsightedness, it has had a significant influence on various fields and continues to shape modern thought."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Analytical Philosophy\n\nAnalytical Philosophy: A Modern Philosophical Movement\n\n1. Overview\n   - Analytical philosophy is a modern philosophical approach that emphasizes the importance of logical analysis, clarity, and precision in philosophical discourse.\n   - It focuses on the study of language, meaning, and the logical structure of arguments.\n   - Analytical philosophers aim to clarify philosophical problems and provide rigorous, systematic solutions using formal logic and linguistic analysis.\n\n2. Key Founders and Prominent Figures\n   - Gottlob Frege (1848-1925): Developed modern symbolic logic and made significant contributions to the philosophy of language.\n   - Bertrand Russell (1872-1970): Co-authored \"Principia Mathematica,\" championed logical atomism, and made contributions to various areas of philosophy.\n   - Ludwig Wittgenstein (1889-1951): Authored \"Tractatus Logico-Philosophicus\" and later developed the concept of language games in his \"Philosophical Investigations.\"\n   - Other notable figures include G.E. Moore, Rudolf Carnap, W.V.O. Quine, and Saul Kripke.\n\n3. Main Ideas and Concepts\n   - Logical Analysis: The use of formal logic to analyze and clarify philosophical arguments and concepts.\n   - Philosophy of Language: The study of the nature of language, meaning, and the relationship between language and reality.\n   - Logical Atomism: The view that the world consists of atomic facts that can be expressed through logically perfect language.\n   - Verificationism: The idea that a statement is meaningful only if it can be empirically verified or is analytically true.\n   - Ordinary Language Philosophy: The analysis of the use and meaning of everyday language to address philosophical problems.\n\n4. Potential Criticisms or Errors\n   - Narrow Focus: Some argue that analytical philosophy's emphasis on logic and language neglects other important aspects of human experience and philosophical inquiry.\n   - Overreliance on Formal Methods: Critics claim that the heavy reliance on formal logic and linguistic analysis may not adequately capture the complexity and nuances of philosophical issues.\n   - Neglect of Metaphysics: The focus on language and logic has led some analytical philosophers to dismiss or overlook fundamental metaphysical questions.\n   - Limited Scope: The narrow focus of analytical philosophy may exclude valuable insights from other philosophical traditions and disciplines.\n\n5. Influence on Modern Thought\n   - Analytical philosophy has had a significant impact on various fields, including linguistics, cognitive science, and computer science.\n   - It has contributed to the development of formal logic, the study of language, and the analysis of concepts such as truth, knowledge, and meaning.\n   - Analytical approaches have been applied to diverse philosophical topics, including ethics, mind, and metaphysics.\n   - The emphasis on clarity, rigor, and logical analysis has influenced the way philosophy is practiced and taught in many academic institutions.\n\nIn conclusion, analytical philosophy has made significant contributions to modern philosophical thought by emphasizing the importance of logical analysis, language, and conceptual clarity. Despite its potential limitations and criticisms, it remains an influential and important approach to philosophical inquiry."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Critical Theory\n\nSummary of Critical Theory as a Modern Philosophical Movement\n\n1. Overview:\n   - Critical Theory is a philosophical approach that originated in the Frankfurt School in the 1930s.\n   - It focuses on critiquing and challenging dominant social, political, and economic structures.\n   - Critical Theory aims to uncover hidden power dynamics and oppressive ideologies in society.\n\n2. Key Founders and Prominent Figures:\n   - Max Horkheimer\n   - Theodor Adorno\n   - Herbert Marcuse\n   - Jürgen Habermas\n   - Walter Benjamin\n   - Erich Fromm\n\n3. Main Ideas and Concepts:\n   - Dialectical Reasoning: Examining social phenomena through the lens of contradictions and conflicts.\n   - Critique of Instrumental Reason: Challenging the dominance of rationality and efficiency in modern society.\n   - Culture Industry: Analyzing mass media and popular culture as tools for maintaining the status quo.\n   - Emancipation: Striving for individual and societal liberation from oppressive structures.\n   - Interdisciplinary Approach: Incorporating insights from various fields, such as sociology, psychology, and economics.\n\n4. Potential Criticisms or Errors:\n   - Accusation of Elitism: Critical Theory has been criticized for being overly intellectual and disconnected from practical concerns.\n   - Lack of Empirical Grounding: Some argue that Critical Theory relies heavily on theoretical speculation without sufficient empirical evidence.\n   - Overemphasis on Negativity: Critics suggest that Critical Theory focuses excessively on criticizing existing structures without offering concrete alternatives.\n   - Neglect of Individual Agency: Some contend that Critical Theory underestimates the role of individual choice and responsibility in shaping society.\n\n5. Influence on Modern Thought:\n   - Critical Theory has had a significant impact on various disciplines, including sociology, political science, cultural studies, and literary theory.\n   - It has inspired social movements and activism, particularly in the areas of feminism, anti-racism, and anti-capitalism.\n   - Critical Theory has contributed to the development of postmodernism and poststructuralism.\n   - Its ideas have been applied to diverse fields, such as education, media studies, and environmental studies.\n   - Contemporary thinkers continue to engage with and build upon the insights of Critical Theory to analyze and critique modern society."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "## Feminism (as a philosophical movement)\n\nFeminism (as a philosophical movement)\n\n1. Overview:\n   - Feminism is a philosophical movement that advocates for gender equality and challenges patriarchal norms and structures.\n   - It examines and critiques the historical, social, political, and cultural inequalities faced by women.\n   - Feminism seeks to empower women and promote their rights, autonomy, and dignity.\n\n2. Key founders and prominent figures:\n   - Mary Wollstonecraft (1759-1797): Considered one of the earliest feminist philosophers; wrote \"A Vindication of the Rights of Woman\" (1792).\n   - Simone de Beauvoir (1908-1986): French philosopher; authored the influential book \"The Second Sex\" (1949).\n   - Betty Friedan (1921-2006): American writer and activist; wrote \"The Feminine Mystique\" (1963), which sparked the second wave of feminism.\n   - bell hooks (1952-2021): American author and social activist; known for her works on the intersection of race, gender, and class.\n\n3. Main ideas and concepts:\n   - Gender equality: Feminism advocates for equal rights, opportunities, and treatment of women in all spheres of life.\n   - Patriarchy: Feminism challenges the systemic domination of men over women in society, politics, and culture.\n   - Intersectionality: Recognizes the interconnected nature of social categorizations such as race, class, and gender, and how they create overlapping systems of discrimination or disadvantage.\n   - Empowerment: Feminism seeks to empower women to take control of their lives, bodies, and choices.\n   - Feminist epistemology: Questions traditional ways of knowing and emphasizes the importance of women's experiences and perspectives in knowledge production.\n\n4. Potential criticisms or errors:\n   - Essentialism: Some critics argue that feminism sometimes relies on essentialist notions of gender, assuming a universal female experience.\n   - Exclusivity: Historically, feminism has been criticized for focusing primarily on the experiences of white, middle-class women, neglecting the diverse experiences of women from different backgrounds.\n   - Radical feminism: Some radical feminist views, such as the rejection of all men or the complete overhaul of societal structures, have been criticized as extreme or divisive.\n   - Backlash: Feminist movements have often faced backlash and resistance from those who perceive feminism as a threat to traditional gender roles and power dynamics.\n\n5. Influence on modern thought:\n   - Feminism has significantly influenced various fields, including philosophy, sociology, literature, art, and politics.\n   - It has contributed to the recognition of women's rights as human rights and the advancement of gender equality in many societies.\n   - Feminist perspectives have challenged traditional philosophical canon and introduced new areas of inquiry, such as feminist ethics and feminist epistemology.\n   - Feminism has inspired social and political movements worldwide, leading to legal and policy changes that promote gender equality and combat discrimination."
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "\n",
            "Enter a philosophy to summarize or a question (or 'quit' to exit): quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dV0pJWPKOamJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}