{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "288cb707",
   "metadata": {},
   "source": [
    "## Machine Learning Avanzado\n",
    "#### Redes Recursivas y Recurrentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "447a8c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 20:47:03.502886: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-18 20:47:03.612165: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-18 20:47:04.005789: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-18 20:47:04.005832: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-18 20:47:04.005836: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Parametros iniciales\n",
    "velocidadDeAprendizaje = 0.001\n",
    "numeroDeIteracionesEntrenamiento = 5000\n",
    "iteracionesMostrarInfo = 1000\n",
    "numeroEntradas = 3\n",
    "\n",
    "# Numero de unidades ocultas en una celda RNN\n",
    "hidden = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c0613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n",
    "# Each input sequence will be of size (28, 28) (height is treated like time).\n",
    "input_dim = 28\n",
    "\n",
    "units = 64\n",
    "output_size = 10  # labels are from 0 to 9\n",
    "\n",
    "# Build the RNN model\n",
    "def build_model(allow_cudnn_kernel=True):\n",
    "    # CuDNN is only available at the layer level, and not at the cell level.\n",
    "    # This means `LSTM(units)` will use the CuDNN kernel,\n",
    "    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n",
    "    if allow_cudnn_kernel:\n",
    "        # The LSTM layer with default options uses CuDNN.\n",
    "        lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\n",
    "    else:\n",
    "        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n",
    "        lstm_layer = keras.layers.RNN(\n",
    "            keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n",
    "        )\n",
    "    model = keras.models.Sequential(\n",
    "        [\n",
    "            lstm_layer,\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dense(output_size),\n",
    "        ]\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e95c6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "sample, sample_label = x_train[0], y_train[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "302c4e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-18 20:47:04.691394: E tensorflow/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2022-11-18 20:47:04.691416: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: pop-os\n",
      "2022-11-18 20:47:04.691420: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: pop-os\n",
      "2022-11-18 20:47:04.691477: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 515.65.1\n",
      "2022-11-18 20:47:04.691490: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 515.65.1\n",
      "2022-11-18 20:47:04.691493: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 515.65.1\n",
      "2022-11-18 20:47:04.691748: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 13s 13ms/step - loss: 0.9600 - accuracy: 0.6967 - val_loss: 0.5352 - val_accuracy: 0.8284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7f0d0520e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(allow_cudnn_kernel=True)\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "\n",
    "model.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de77b35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "938/938 [==============================] - 13s 13ms/step - loss: 0.3910 - accuracy: 0.8822 - val_loss: 0.2861 - val_accuracy: 0.9099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7ed07e8a60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noncudnn_model = build_model(allow_cudnn_kernel=False)\n",
    "noncudnn_model.set_weights(model.get_weights())\n",
    "noncudnn_model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=\"sgd\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "noncudnn_model.fit(\n",
    "    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c0e4d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted result is: [3], target result is: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with tf.device(\"CPU:0\"):\n",
    "    cpu_model = build_model(allow_cudnn_kernel=True)\n",
    "    cpu_model.set_weights(model.get_weights())\n",
    "    result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, 0)), axis=1)\n",
    "    print(\n",
    "        \"Predicted result is: %s, target result is: %s\" % (result.numpy(), sample_label)\n",
    "    )\n",
    "    plt.imshow(sample, cmap=plt.get_cmap(\"gray\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "833aa202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path_to_module = \"/home/tom/miniconda3/envs/MachineLearning/lib/python3.10/site-packages/\"\n",
    "sys.path.append(path_to_module)\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e08683d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7e7072a5c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "file = '/media/tom/Fonte Storage/00 Clases/UDD/MLA/Laboratorios/5.png'\n",
    "test_image = cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "plt.imshow(test_image,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c707187b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7e7078e890>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_resized = cv2.resize(test_image,(28,28),interpolation = cv2.INTER_LINEAR)\n",
    "img_resized = cv2.bitwise_not(img_resized)\n",
    "plt.imshow(img_resized,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a15bebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted result is: [7], target result is: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_label = 3#\n",
    "\n",
    "with tf.device(\"CPU:0\"):\n",
    "    cpu_model = build_model(allow_cudnn_kernel=True)\n",
    "    cpu_model.set_weights(model.get_weights())\n",
    "    result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(img_resized, 0)), axis=1)\n",
    "    print(\n",
    "        \"Predicted result is: %s, target result is: %s\" % (result.numpy(), sample_label)\n",
    "    )\n",
    "    plt.imshow(sample, cmap=plt.get_cmap(\"gray\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da8ddf3",
   "metadata": {},
   "source": [
    "### Redes Recursivas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06fe18bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2215361388.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [13]\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(self, ...):\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Primero hay que representar el arbol de la estructura de datos en un grafico\n",
    "\n",
    "class Node:  # a node in the tree\n",
    "    def __init__(self, ...):\n",
    "        self.isLeaf = True / False\n",
    "        self.hidden_state = None\n",
    "        # for leaves\n",
    "        self.word = word\n",
    "        # for inner nodes\n",
    "        self.left = None  # reference to left child\n",
    "        self.right = None  # reference to right child\n",
    "#..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15bdedec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_Model():\n",
    "    def add_model_vars(self):\n",
    "        with tf.variable_scope('Embeddings'):\n",
    "            embeddings = \\\n",
    "            tf.get_variable('embeddings', [len(self.vocab), self.config.embed_size])\n",
    "            with tf.variable_scope('Composition'):\n",
    "                W1 = tf.get_variable('W1',\n",
    "                                     [2 * self.config.embed_size, self.config.embed_size])\n",
    "                b1 = tf.get_variable('b1', [1, self.config.embed_size])\n",
    "            with tf.variable_scope('Projection'):\n",
    "                U = tf.get_variable('U', [self.config.embed_size, self.config.label_size])\n",
    "                bs = tf.get_variable('bs', [1, self.config.label_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f47fca0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtree\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mConfig\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124;03m\"\"\"Holds model hyperparams and data information.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    Model objects are passed a Config() object at instantiation.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tree'"
     ]
    }
   ],
   "source": [
    "import os, sys,shutil,time,itertools\n",
    "import math, random\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "import utils\n",
    "import tree\n",
    "\n",
    "\n",
    "class Config(object):\n",
    "    \"\"\"Holds model hyperparams and data information.\n",
    "    Model objects are passed a Config() object at instantiation.\n",
    "    \"\"\"\n",
    "    \n",
    "    embed_size = 35\n",
    "    label_size = 2\n",
    "    early_stopping = 2\n",
    "    anneal_threshold = 0.99\n",
    "    anneal_by = 1.5\n",
    "    max_epochs = 30\n",
    "    lr = 0.01\n",
    "    l2 = 0.02\n",
    "    \n",
    "    model_name = MODEL_STR % (embed_size, l2, lr)\n",
    "\n",
    "\n",
    "class RecursiveNetStaticGraph():\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        \n",
    "        # Load train data and build vocabulary\n",
    "        self.train_data, self.dev_data, self.test_data = tree.simplified_data(700,\n",
    "                                                                              100,\n",
    "                                                                              200)\n",
    "        \n",
    "        # print(\"data \",self.train_data)\n",
    "        self.vocab = utils.Vocab()\n",
    "        train_sents = [t.get_words() for t in self.train_data]\n",
    "        self.vocab.construct(list(itertools.chain.from_iterable(train_sents)))\n",
    "        \n",
    "        # add input placeholders\n",
    "        self.is_leaf_placeholder = tf.placeholder(\n",
    "            tf.bool, (None), name='is_leaf_placeholder')\n",
    "        self.left_children_placeholder = tf.placeholder(\n",
    "            tf.int32, (None), name='left_children_placeholder')\n",
    "        self.right_children_placeholder = tf.placeholder(\n",
    "            tf.int32, (None), name='right_children_placeholder')\n",
    "        self.node_word_indices_placeholder = tf.placeholder(\n",
    "            tf.int32, (None), name='node_word_indices_placeholder')\n",
    "        self.labels_placeholder = tf.placeholder(\n",
    "            tf.int32, (None), name='labels_placeholder')\n",
    "        \n",
    "        # add model variables\n",
    "        with tf.variable_scope('Embeddings'):\n",
    "            embeddings = tf.get_variable('embeddings',\n",
    "                                         [len(self.vocab), self.config.embed_size])\n",
    "        with tf.variable_scope('Composition'):\n",
    "            W1 = tf.get_variable('W1',\n",
    "                                 [2 * self.config.embed_size, self.config.embed_size])\n",
    "            b1 = tf.get_variable('b1', [1, self.config.embed_size])\n",
    "        with tf.variable_scope('Projection'):\n",
    "            U = tf.get_variable('U', [self.config.embed_size, self.config.label_size])\n",
    "            bs = tf.get_variable('bs', [1, self.config.label_size])\n",
    "            \n",
    "        # build recursive graph\n",
    "        \n",
    "        tensor_array = tf.TensorArray(\n",
    "            tf.float32,\n",
    "            size=0,\n",
    "            dynamic_size=True,\n",
    "            clear_after_read=False,\n",
    "            infer_shape=False)\n",
    "        \n",
    "        def embed_word(word_index):\n",
    "            with tf.device('/cpu:0'):\n",
    "                return tf.expand_dims(tf.gather(embeddings, word_index), 0)\n",
    "\n",
    "    def combine_children(left_tensor, right_tensor):\n",
    "        return tf.nn.relu(tf.matmul(tf.concat([left_tensor, right_tensor],1), W1) + b1)\n",
    "    \n",
    "    def loop_body(tensor_array, i):\n",
    "        node_is_leaf = tf.gather(self.is_leaf_placeholder, i)\n",
    "        node_word_index = tf.gather(self.node_word_indices_placeholder, i)\n",
    "        left_child = tf.gather(self.left_children_placeholder, i)\n",
    "        right_child = tf.gather(self.right_children_placeholder, i)\n",
    "        print(left_child,\"left_child\")\n",
    "        node_tensor = tf.cond(\n",
    "            node_is_leaf,\n",
    "            lambda: embed_word(node_word_index),\n",
    "            lambda: combine_children(tensor_array.read(left_child),\n",
    "                                     tensor_array.read(right_child)))\n",
    "        tensor_array = tensor_array.write(i, node_tensor)\n",
    "        i = tf.add(i, 1)\n",
    "        return tensor_array, i\n",
    "    \n",
    "    loop_cond = lambda tensor_array, i: \\\n",
    "        tf.less(i, tf.squeeze(tf.shape(self.is_leaf_placeholder)))\n",
    "    self.tensor_array, _ = tf.while_loop(loop_cond, loop_body, [tensor_array, 0], parallel_iterations=1)\n",
    "    \n",
    "    # add projection layer\n",
    "    self.logits = tf.matmul(self.tensor_array.concat(), U) + bs\n",
    "    self.root_logits = tf.matmul(\n",
    "        self.tensor_array.read(self.tensor_array.size() - 1), U) + bs\n",
    "    self.root_prediction = tf.squeeze(tf.argmax(self.root_logits, 1))\n",
    "    \n",
    "    # add loss layer\n",
    "    regularization_loss = self.config.l2 * (\n",
    "        tf.nn.l2_loss(W1) + tf.nn.l2_loss(U))\n",
    "    included_indices = tf.where(tf.less(self.labels_placeholder, 2))\n",
    "    self.full_loss = regularization_loss + tf.reduce_sum(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=tf.gather(self.logits, included_indices),labels=tf.gather(\n",
    "                self.labels_placeholder, included_indices)))\n",
    "    self.root_loss = tf.reduce_sum(\n",
    "        tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "            logits=self.root_logits,labels=self.labels_placeholder[-1:]))\n",
    "    \n",
    "    # add training op\n",
    "    self.train_op = tf.train.GradientDescentOptimizer(self.config.lr).minimize(\n",
    "        self.full_loss)\n",
    "    \n",
    "    def build_feed_dict(self, node):\n",
    "        nodes_list = []\n",
    "        tree.leftTraverse(node, lambda node, args: args.append(node), nodes_list)\n",
    "        node_to_index = OrderedDict()\n",
    "        for i in xrange(len(nodes_list)):\n",
    "            node_to_index[nodes_list[i]] = i\n",
    "        feed_dict = {\n",
    "            self.is_leaf_placeholder: [node.isLeaf for node in nodes_list],\n",
    "            self.left_children_placeholder: [node_to_index[node.left] if\n",
    "                                             not node.isLeaf else -1\n",
    "                                             for node in nodes_list],\n",
    "            self.right_children_placeholder: [node_to_index[node.right] if\n",
    "                                              not node.isLeaf else -1\n",
    "                                              for node in nodes_list],\n",
    "            self.node_word_indices_placeholder: [self.vocab.encode(node.word) if\n",
    "                                                 node.word else -1\n",
    "                                                 for node in nodes_list],\n",
    "            self.labels_placeholder: [node.label for node in nodes_list]\n",
    "        }\n",
    "        return feed_dict\n",
    "    \n",
    "    def predict(self, trees, weights_path, get_loss=False):\n",
    "        \"\"\"Make predictions from the provided model.\"\"\"\n",
    "        results = []\n",
    "        losses = []\n",
    "        with tf.Session() as sess:\n",
    "            saver = tf.train.Saver()\n",
    "            saver.restore(sess, weights_path)\n",
    "            for tree in trees:\n",
    "                feed_dict = self.build_feed_dict(tree.root)\n",
    "                if get_loss:\n",
    "                    root_prediction, loss = sess.run(\n",
    "                        [self.root_prediction, self.root_loss], feed_dict=feed_dict)\n",
    "                    losses.append(loss)\n",
    "                else:\n",
    "                    root_prediction = sess.run(self.root_prediction, feed_dict=feed_dict)\n",
    "                    results.append(root_prediction)\n",
    "            return results, losses\n",
    "\n",
    "    def run_epoch(self, new_model=False, verbose=True):\n",
    "        loss_history = []\n",
    "        # training\n",
    "        random.shuffle(self.train_data)\n",
    "        with tf.Session() as sess:\n",
    "            if new_model:\n",
    "                sess.run(tf.initialize_all_variables())\n",
    "            else:\n",
    "                saver = tf.train.Saver()\n",
    "                saver.restore(sess, SAVE_DIR + '%s.temp' % self.config.model_name)\n",
    "            for step, tree in enumerate(self.train_data):\n",
    "                print(tree,\"tree\")\n",
    "                feed_dict = self.build_feed_dict(tree.root)\n",
    "                loss_value, _ = sess.run([self.full_loss, self.train_op],\n",
    "                                         feed_dict=feed_dict)\n",
    "                loss_history.append(loss_value)\n",
    "                if verbose:\n",
    "                    sys.stdout.write('\\r{} / {} :    loss = {}'.format(step, len(\n",
    "                        self.train_data), np.mean(loss_history)))\n",
    "                    sys.stdout.flush()\n",
    "                    saver = tf.train.Saver()\n",
    "                    if not os.path.exists(SAVE_DIR):\n",
    "                        os.makedirs(SAVE_DIR)\n",
    "                    saver.save(sess, SAVE_DIR + '%s.temp' % self.config.model_name)\n",
    "            # statistics\n",
    "            train_preds, _ = self.predict(self.train_data,\n",
    "                                          SAVE_DIR + '%s.temp' % self.config.model_name)\n",
    "            val_preds, val_losses = self.predict(\n",
    "                self.dev_data,\n",
    "                SAVE_DIR + '%s.temp' % self.config.model_name,\n",
    "                get_loss=True)\n",
    "            train_labels = [t.root.label for t in self.train_data]\n",
    "            val_labels = [t.root.label for t in self.dev_data]\n",
    "            train_acc = np.equal(train_preds, train_labels).mean()\n",
    "            val_acc = np.equal(val_preds, val_labels).mean()\n",
    "            \n",
    "            print()\n",
    "            print( 'Training acc (only root node): {}'.format(train_acc))\n",
    "            print( 'Valiation acc (only root node): {}'.format(val_acc))\n",
    "            print( self.make_conf(train_labels, train_preds))\n",
    "            print( self.make_conf(val_labels, val_preds))\n",
    "            return train_acc, val_acc, loss_history, np.mean(val_losses)\n",
    "\n",
    "    def train(self, verbose=True):\n",
    "        complete_loss_history = []\n",
    "        train_acc_history = []\n",
    "        val_acc_history = []\n",
    "        prev_epoch_loss = float('inf')\n",
    "        best_val_loss = float('inf')\n",
    "        best_val_epoch = 0\n",
    "        stopped = -1\n",
    "        for epoch in xrange(self.config.max_epochs):\n",
    "            print( 'epoch %d' % epoch)\n",
    "            if epoch == 0:\n",
    "                train_acc, val_acc, loss_history, val_loss = self.run_epoch(\n",
    "                    new_model=True)\n",
    "            else:\n",
    "                train_acc, val_acc, loss_history, val_loss = self.run_epoch()\n",
    "            complete_loss_history.extend(loss_history)\n",
    "            train_acc_history.append(train_acc)\n",
    "            val_acc_history.append(val_acc)\n",
    "            #lr annealing\n",
    "            epoch_loss = np.mean(loss_history)\n",
    "            if epoch_loss > prev_epoch_loss * self.config.anneal_threshold:\n",
    "                self.config.lr /= self.config.anneal_by\n",
    "                print( 'annealed lr to %f' % self.config.lr)\n",
    "            prev_epoch_loss = epoch_loss\n",
    "\n",
    "        #save if model has improved on val\n",
    "        if val_loss < best_val_loss:\n",
    "            shutil.copyfile(SAVE_DIR + '%s.temp' % self.config.model_name,\n",
    "                            SAVE_DIR + '%s' % self.config.model_name)\n",
    "            best_val_loss = val_loss\n",
    "            best_val_epoch = epoch\n",
    "\n",
    "        # if model has not imprvoved for a while stop\n",
    "        if epoch - best_val_epoch > self.config.early_stopping:\n",
    "            stopped = epoch\n",
    "            #break\n",
    "        if verbose:\n",
    "            sys.stdout.write('\\r')\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        print( '\\n\\nstopped at %d\\n' % stopped)\n",
    "        return {\n",
    "            'loss_history': complete_loss_history,\n",
    "            'train_acc_history': train_acc_history,\n",
    "            'val_acc_history': val_acc_history,\n",
    "        }\n",
    "\n",
    "    def make_conf(self, labels, predictions):\n",
    "        confmat = np.zeros([2, 2])\n",
    "        for l, p in itertools.izip(labels, predictions):\n",
    "            confmat[l, p] += 1\n",
    "        return confmat\n",
    "\n",
    "def plot_loss_history(stats):\n",
    "    plt.plot(stats['loss_history'])\n",
    "    plt.title('Loss history')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.savefig('loss_history.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_RNN():\n",
    "    \"\"\"Test RNN model implementation.\n",
    "    \"\"\"\n",
    "    config = Config()\n",
    "    model = RecursiveNetStaticGraph(config)\n",
    "    #graph_def = tf.get_default_graph().as_graph_def()\n",
    "    #with open('static_graph.pb', 'wb') as f:\n",
    "    #  f.write(graph_def.SerializeToString())\n",
    "    \n",
    "    start_time = time.time()\n",
    "    stats = model.train(verbose=True)\n",
    "    print( 'Training time: {}'.format(time.time() - start_time))\n",
    "    \n",
    "    plot_loss_history(stats)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    val_preds, val_losses = model.predict(\n",
    "        model.dev_data,\n",
    "        SAVE_DIR + '%s.temp' % model.config.model_name,\n",
    "        get_loss=True)\n",
    "    \n",
    "    val_labels = [t.root.label for t in model.dev_data]\n",
    "    val_acc = np.equal(val_preds, val_labels).mean()\n",
    "    print( val_acc)\n",
    "    \n",
    "    print( '-' * 20)\n",
    "    print( 'Test')\n",
    "    predictions, _ = model.predict(model.test_data,\n",
    "                                   SAVE_DIR + '%s.temp' % model.config.model_name)\n",
    "    labels = [t.root.label for t in model.test_data]\n",
    "    print(model.make_conf(labels, predictions))\n",
    "    test_acc = np.equal(predictions, labels).mean()\n",
    "    print('Test acc: {}'.format(test_acc))\n",
    "    print('Inference time, dev+test: {}'.format(time.time() - start_time))\n",
    "    print('-' * 20)\n",
    "    \n",
    "    if __name__ == '__main__':\n",
    "        test_RNN()\n",
    "  # train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "75aec0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {'the': 0, 'old': 1, 'cat': 2}\n",
    "node_words = ['the', 'old', 'cat', '', '']\n",
    "is_leaf = [True, True, True, False, False]\n",
    "left_children = [-1, -1, -1, 1, 0]   # indices of left children nodes in this list\n",
    "right_children = [-1, -1, -1, 2, 3]  # indices of right children nodes in this list\n",
    "\n",
    "node_word_indices = [vocab[word] if word else -1 for word in node_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6da1ed8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node_tensors, i\n\u001b[1;32m     25\u001b[0m loop_cond \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m node_tensors, i: \\\n\u001b[1;32m     26\u001b[0m         tf\u001b[38;5;241m.\u001b[39mless(i, tf\u001b[38;5;241m.\u001b[39msqueeze(tf\u001b[38;5;241m.\u001b[39mshape(is_leaf)))\n\u001b[0;32m---> 28\u001b[0m node_tensors, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloop_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:629\u001b[0m, in \u001b[0;36mdeprecated_arg_values.<locals>.deprecated_wrapper.<locals>.new_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    622\u001b[0m           _PRINTED_WARNING[(func, arg_name)] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    623\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    624\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrom \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m: calling \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m (from \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) with \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    625\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwill be removed \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mInstructions for updating:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    626\u001b[0m             _call_location(), decorator_utils\u001b[38;5;241m.\u001b[39mget_qualified_name(func),\n\u001b[1;32m    627\u001b[0m             func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m, arg_name, arg_value, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124min a future version\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    628\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m date \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mafter \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m date), instructions)\n\u001b[0;32m--> 629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/control_flow_ops.py:2513\u001b[0m, in \u001b[0;36mwhile_loop_v2\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, maximum_iterations, name)\u001b[0m\n\u001b[1;32m   2337\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile_loop\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m   2338\u001b[0m \u001b[38;5;129m@deprecation\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecated_arg_values(\n\u001b[1;32m   2339\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2354\u001b[0m                   maximum_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2355\u001b[0m                   name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2356\u001b[0m   \u001b[38;5;124;03m\"\"\"Repeat `body` while the condition `cond` is true.\u001b[39;00m\n\u001b[1;32m   2357\u001b[0m \n\u001b[1;32m   2358\u001b[0m \u001b[38;5;124;03m  `cond` is a callable returning a boolean scalar tensor. `body` is a callable\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2511\u001b[0m \n\u001b[1;32m   2512\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2513\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwhile_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2514\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2515\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2516\u001b[0m \u001b[43m      \u001b[49m\u001b[43mloop_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloop_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2517\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshape_invariants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape_invariants\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2518\u001b[0m \u001b[43m      \u001b[49m\u001b[43mparallel_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2519\u001b[0m \u001b[43m      \u001b[49m\u001b[43mback_prop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mback_prop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2520\u001b[0m \u001b[43m      \u001b[49m\u001b[43mswap_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswap_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2521\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2522\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmaximum_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximum_iterations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2523\u001b[0m \u001b[43m      \u001b[49m\u001b[43mreturn_same_structure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/control_flow_ops.py:2762\u001b[0m, in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2759\u001b[0m loop_var_structure \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(type_spec\u001b[38;5;241m.\u001b[39mtype_spec_from_value,\n\u001b[1;32m   2760\u001b[0m                                         \u001b[38;5;28mlist\u001b[39m(loop_vars))\n\u001b[1;32m   2761\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cond(\u001b[38;5;241m*\u001b[39mloop_vars):\n\u001b[0;32m-> 2762\u001b[0m   loop_vars \u001b[38;5;241m=\u001b[39m \u001b[43mbody\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mloop_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2763\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m try_to_pack \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loop_vars, (\u001b[38;5;28mlist\u001b[39m, _basetuple)):\n\u001b[1;32m   2764\u001b[0m     packed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mloop_body\u001b[0;34m(node_tensors, i)\u001b[0m\n\u001b[1;32m     14\u001b[0m left_child \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather(left_children, i)\n\u001b[1;32m     15\u001b[0m right_child \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather(right_children, i)\n\u001b[0;32m---> 16\u001b[0m node_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcond\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnode_is_leaf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43membed_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_word_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcombine_children\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_tensors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft_child\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mnode_tensors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright_child\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m node_tensors \u001b[38;5;241m=\u001b[39m node_tensors\u001b[38;5;241m.\u001b[39mwrite(i, node_tensor)\n\u001b[1;32m     22\u001b[0m i \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39madd(i, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mloop_body.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m left_child \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather(left_children, i)\n\u001b[1;32m     15\u001b[0m right_child \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mgather(right_children, i)\n\u001b[1;32m     16\u001b[0m node_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcond(\n\u001b[1;32m     17\u001b[0m     node_is_leaf,\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43membed_word\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_word_index\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: combine_children(node_tensors\u001b[38;5;241m.\u001b[39mread(left_child),\n\u001b[1;32m     20\u001b[0m                              node_tensors\u001b[38;5;241m.\u001b[39mread(right_child)))\n\u001b[1;32m     21\u001b[0m node_tensors \u001b[38;5;241m=\u001b[39m node_tensors\u001b[38;5;241m.\u001b[39mwrite(i, node_tensor)\n\u001b[1;32m     22\u001b[0m i \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39madd(i, \u001b[38;5;241m1\u001b[39m)\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36membed_word\u001b[0;34m(word_index)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_word\u001b[39m(word_index):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/cpu:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m----> 6\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mexpand_dims(tf\u001b[38;5;241m.\u001b[39mgather(\u001b[43membeddings\u001b[49m, word_index), \u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "node_tensors = tf.TensorArray(tf.float32, size=0, dynamic_size=True,\n",
    "                              clear_after_read=False, infer_shape=False)\n",
    "\n",
    "def embed_word(word_index):\n",
    "    with tf.device('/cpu:0'):\n",
    "        return tf.expand_dims(tf.gather(embeddings, word_index), 0)\n",
    "\n",
    "def combine_children(left_tensor, right_tensor):\n",
    "    return tf.nn.relu(tf.matmul(tf.concat(1, [left_tensor, right_tensor]), W1) + b1)\n",
    "\n",
    "def loop_body(node_tensors, i):\n",
    "    node_is_leaf = tf.gather(is_leaf, i)\n",
    "    node_word_index = tf.gather(node_word_indices, i)\n",
    "    left_child = tf.gather(left_children, i)\n",
    "    right_child = tf.gather(right_children, i)\n",
    "    node_tensor = tf.cond(\n",
    "        node_is_leaf,\n",
    "        lambda: embed_word(node_word_index),\n",
    "        lambda: combine_children(node_tensors.read(left_child),\n",
    "                                 node_tensors.read(right_child)))\n",
    "    node_tensors = node_tensors.write(i, node_tensor)\n",
    "    i = tf.add(i, 1)\n",
    "    return node_tensors, i\n",
    "\n",
    "loop_cond = lambda node_tensors, i: \\\n",
    "        tf.less(i, tf.squeeze(tf.shape(is_leaf)))\n",
    "\n",
    "node_tensors, _ = tf.while_loop(loop_cond, loop_body, [node_tensors, 0],\n",
    "                                     parallel_iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "281add89",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Embedding' from 'keras' (/usr/local/lib/python3.10/dist-packages/keras/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embedding \u001b[38;5;28;01mas\u001b[39;00m embedding\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Embedding' from 'keras' (/usr/local/lib/python3.10/dist-packages/keras/__init__.py)"
     ]
    }
   ],
   "source": [
    "from keras import Embedding as embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5c031",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
