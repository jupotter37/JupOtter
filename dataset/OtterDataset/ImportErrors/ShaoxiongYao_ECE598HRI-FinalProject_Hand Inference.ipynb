{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9a7499d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbaf653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import scipy.optimize as sopt\n",
    "from klampt.math import se3,so3\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "from create_point_cloud import load_whole_point_cloud, load_point_cloud,get_masked_point_cloud\n",
    "import scipy\n",
    "import torch\n",
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "from collections import deque\n",
    "from queue import Queue\n",
    "from threading import Event, Lock, Thread\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "from mmpose.apis import (get_track_id, inference_top_down_pose_model,\n",
    "                         init_pose_model, vis_pose_result)\n",
    "from mmpose.core import apply_bugeye_effect, apply_sunglasses_effect\n",
    "from mmpose.utils import StopWatch\n",
    "\n",
    "try:\n",
    "    from mmdet.apis import inference_detector, init_detector\n",
    "    has_mmdet = True\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    has_mmdet = False\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "    psutil_proc = psutil.Process()\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    psutil_proc = None\n",
    "from torch import nn\n",
    "    \n",
    "from utils import get_proper_image_paths, strip_dataset_parent_folder,get_aligned_dataset,find_hand_center,find_point_position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e6e25",
   "metadata": {},
   "source": [
    "# Preprocessing the datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94aa01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_pickle('./first_ground_truth_shaoxiong_no_sword3.pkl')\n",
    "clean_df = get_proper_image_paths(raw_df,'/home/motion/data/ECE598/our_dataset')\n",
    "data = []\n",
    "mask = np.zeros(133).astype(bool)\n",
    "mask[:] = False\n",
    "mask[5:23] = True\n",
    "mask[91] = True\n",
    "mask[112] = True\n",
    "# mask[:] = True\n",
    "hm = []\n",
    "for i in tqdm(clean_df.index):  \n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        res,outputs = inference_top_down_pose_model(\n",
    "                pose_model,\n",
    "                clean_df.cam_torso_color[i],\n",
    "                format='xyxy',\n",
    "                dataset=dataset_name,return_heatmap = False)\n",
    "        print('Estimating the kp took {}'.format(time.time()-start_time))\n",
    "        start_time = time.time()\n",
    "        kp = res[0]['keypoints'][mask,:]\n",
    "        pcd = load_whole_point_cloud(clean_df.loc[i,'cam_torso_color'],clean_df.loc[i,'cam_torso_depth'],'realsense_torso')\n",
    "        kp_mean_positions = find_point_position(pcd,kp)\n",
    "        print('Point Clouds extraction took: {}'.format(time.time()-start_time))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    hm.append(kp_mean_positions)\n",
    "        \n",
    "clean_df['pre_processed_torso_features'] = hm\n",
    "clean_df.to_pickle('shaoxiong_no_sword_pre_processed3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0c930c",
   "metadata": {},
   "source": [
    "# Motion Forecasting experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117706c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MMPOSE_DIR = '/home/motion/Joao/classes/hri_kdc/final_project/mmpose'\n",
    "det_config = '{}/demo/mmdetection_cfg/ssdlite_mobilenetv2_scratch_600e_coco.py'.format(MMPOSE_DIR)\n",
    "det_checkpoint = 'https://download.openmmlab.com/mmdetection/v2.0/ssd/ssdlite_mobilenetv2_scratch_600e_coco/ssdlite_mobilenetv2_scratch_600e_coco_20210629_110627-974d9307.pth'\n",
    "device = 'cuda:0'\n",
    "enable_human_pose = 1\n",
    "human_pose_config = '{}/configs/wholebody/2d_kpt_sview_rgb_img/topdown_heatmap/coco-wholebody/vipnas_res50_coco_wholebody_256x192_dark.py'.format(MMPOSE_DIR)\n",
    "human_pose_checkpoint = 'https://download.openmmlab.com/mmpose/top_down/vipnas/vipnas_res50_wholebody_256x192_dark-67c0ce35_20211112.pth'\n",
    "human_det_ids = [1]\n",
    "buffer_size = 1\n",
    "display_delay = 0\n",
    "assert has_mmdet, 'Please install mmdet to run the demo.'\n",
    "assert det_config is not None\n",
    "assert det_checkpoint is not None\n",
    "\n",
    "# build detection model\n",
    "det_model = init_detector(\n",
    "    det_config, det_checkpoint, device=device.lower())\n",
    "\n",
    "# build pose models\n",
    "pose_model_list = []\n",
    "if enable_human_pose:\n",
    "    pose_model = init_pose_model(\n",
    "        human_pose_config,\n",
    "        human_pose_checkpoint,\n",
    "        device=device.lower())\n",
    "    model_info = {\n",
    "        'name': 'HumanPose',\n",
    "        'model': pose_model,\n",
    "        'cat_ids': human_det_ids,\n",
    "        'bbox_color': (148, 139, 255),\n",
    "    }\n",
    "    pose_model_list.append(model_info)\n",
    "\n",
    "\n",
    "# store pose history for pose tracking\n",
    "pose_history_list = []\n",
    "\n",
    "# for _ in range(len(pose_model_list)):\n",
    "#     pose_history_list.append({'pose_results_last': [], 'next_id': 0})\n",
    "    \n",
    "# datasets_dir = '/home/motion/data/ECE598/our_dataset'\n",
    "# scenes = sorted(glob(datasets_dir + '/*'))\n",
    "\n",
    "# dataset_folder = scenes[0]\n",
    "\n",
    "# clean_df =  get_aligned_dataset(dataset_folder,master_camera = 'cam_torso_depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3277b149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame = cv2.imread(clean_df.loc[0,'cam_torso_color'], cv2.IMREAD_COLOR)\n",
    "dataset_name = pose_model.cfg.data['test']['type']\n",
    "\n",
    "# res,outputs = inference_top_down_pose_model(\n",
    "#             pose_model,\n",
    "#             frame,\n",
    "#             format='xyxy',\n",
    "#             dataset=dataset_name,return_heatmap = True)\n",
    "# heatmap = outputs[0]['heatmap']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05e0fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# points = get_masked_point_cloud(clean_df.loc[0,'cam_torso_depth'],'realsense_torso')\n",
    "# points.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3464cf8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4054b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hands_Dataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, master_df,pose_model,history_length = 5,pred_horizon = 3):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "        \"\"\"\n",
    "        self.master_df = master_df\n",
    "        self.history_length = history_length\n",
    "        self.pred_horizon = pred_horizon\n",
    "        self.max_idx = self.master_df.shape[0] - 1\n",
    "        mask = np.zeros(133)\n",
    "        mask[:] = False\n",
    "        mask[5:24] = True\n",
    "        mask[91:] = True\n",
    "        self.pose_model = pose_model\n",
    "        self.mask = mask\n",
    "        feature_lenght = 10800 + 63\n",
    "    def __len__(self):\n",
    "        return self.master_df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        imgs_idx = np.arange(idx,idx-self.history_length,-1)\n",
    "        imgs_idx = np.clip(imgs_idx,0,self.max_idx)\n",
    "        gt_idx = np.clip([idx+self.pred_horizon],0,self.max_idx)[0]\n",
    "        features = []\n",
    "        for img_idx in imgs_idx:\n",
    "#             color = cv2.imread(self.master_df.loc[img_idx,'cam_torso_color'], cv2.IMREAD_COLOR)\n",
    "            feature = np.array(self.master_df.loc[img_idx,'pre_processed_torso_features'])\n",
    "            features.append(feature.flatten())\n",
    "#         colors = np.array(colors)\n",
    "        features = np.array(features)\n",
    "        gt_left = self.master_df.loc[gt_idx,'gt_left_hand']\n",
    "        gt_right = self.master_df.loc[gt_idx,'gt_right_hand']\n",
    "        gt = np.concatenate((gt_left,gt_right))\n",
    "#         print(gt)\n",
    "#         img_name = os.path.join(self.root_dir,\n",
    "#                                 self.landmarks_frame.iloc[idx, 0])\n",
    "#         image = io.imread(img_name)\n",
    "#         landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "#         landmarks = np.array([landmarks])\n",
    "#         landmarks = landmarks.astype('float').reshape(-1, 2)\n",
    "        sample = {'data': features, 'gt_pose': gt}\n",
    "\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1d6ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers,history_length = 6):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.history_length = history_length\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True,nonlinearity = 'relu')   \n",
    "        # Fully connected layert\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.device = torch.device('cuda:0')\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        hidden.to(self.device)\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x.to(self.device), hidden)\n",
    "        self.intermediate = out\n",
    "        out = out[:,-1,:]\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "#         out = out.contiguous().view(batch_size, -1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden        \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        return hidden\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_dim, n_layers,history_length = 6):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        # Defining some parameters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.history_length = history_length\n",
    "        #Defining the layers\n",
    "        # RNN Layer\n",
    "        self.rnn = nn.LSTM(input_size, hidden_dim, n_layers, batch_first=True)   \n",
    "        # Fully connected layert\n",
    "        self.fc = nn.Linear(hidden_dim, output_size)\n",
    "        self.device = torch.device('cuda:0')\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        #Initializing hidden state for first input using method defined below\n",
    "        hidden,c = self.init_hidden(batch_size)\n",
    "        hidden.to(self.device)\n",
    "        c.to(self.device)\n",
    "        # Passing in the input and hidden state into the model and obtaining outputs\n",
    "        out, hidden = self.rnn(x.to(self.device), (hidden,c))\n",
    "        self.intermediate = out\n",
    "        out = out[:,-1,:]\n",
    "        # Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "#         out = out.contiguous().view(batch_size, -1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        return out, hidden        \n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        # This method generates the first hidden state of zeros which we'll use in the forward pass\n",
    "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "        c = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
    "         # We'll send the tensor holding the hidden state to the device we specified earlier as well\n",
    "        return hidden,c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b6a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_horizon = 15\n",
    "history_length = 10\n",
    "clean_df = pd.read_pickle('alice_no_sword_pre_processed.pkl')\n",
    "clean_df2 = pd.read_pickle('alice_no_sword_pre_processed2.pkl')\n",
    "clean_df = pd.concat([clean_df,clean_df2])\n",
    "clean_df = clean_df.reset_index(drop = True)\n",
    "dataset = Hands_Dataset(clean_df,pose_model,pred_horizon = pred_horizon,history_length = history_length)\n",
    "test_df = pd.read_pickle('alice_no_sword_pre_processed3.pkl')\n",
    "test_dataset = Hands_Dataset(test_df,pose_model,pred_horizon = pred_horizon,history_length = history_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cac6d48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, batch_size=16, shuffle=False,num_workers = 4,prefetch_factor= 8,persistent_workers=  True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False,num_workers = 4,prefetch_factor= 8,persistent_workers=  True)\n",
    "device = torch.device('cuda:0')\n",
    "# our_model = Model(80,6,250,5,history_length = history_length)\n",
    "our_model = LSTMModel(80,6,250,1,history_length = history_length)\n",
    "\n",
    "our_model.to(device)\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(our_model.parameters(), lr=0.0005)\n",
    "losses = []\n",
    "for epoch in tqdm(range(1000)):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dataloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        x = data['data'].float()\n",
    "        x.to(device)\n",
    "        gt_pose = data['gt_pose'].float().to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs,hidden = our_model(x)\n",
    "        loss = criterion(outputs, gt_pose)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "#         if i % 10 == 9:    # print every 2000 mini-batches\n",
    "#             print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}')\n",
    "#             losses.append(running_loss/10)\n",
    "\n",
    "#             running_loss = 0.0\n",
    "    losses.append(running_loss/dataset.__len__())\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.array(losses)\n",
    "plt.scatter(x = range(l.shape[0]),y= l)\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Training loss for horizon = 0.1s - single episode')\n",
    "plt.savefig('./training_loss_relu.png',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6201df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model.eval()\n",
    "final_loss = 0\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False,num_workers = 1,prefetch_factor= 4,persistent_workers=  True)\n",
    "gts = []\n",
    "preds = []\n",
    "for data in tqdm(test_dataloader):\n",
    "    x = data['data'].float()\n",
    "    x.to(device)\n",
    "    gt_pose = data['gt_pose'].float().to(device)\n",
    "    with torch.no_grad():\n",
    "#         start_time = time.start()\n",
    "        # zero the parameter gradients\n",
    "        # forward + backward + optimize\n",
    "        outputs,hidden = our_model(x)\n",
    "        preds.append(outputs.cpu().numpy())\n",
    "        gts.append(gt_pose.cpu().numpy())\n",
    "        loss = criterion(outputs, gt_pose)\n",
    "        final_loss += loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee4a4ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# help(mean_squared_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d414cbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(np.array(gts).reshape(-1,6),np.array(preds).reshape(-1,6),squared = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6b237c",
   "metadata": {},
   "source": [
    "RNN: (80,6,250,1,horizon_length = 10)\n",
    "MSE for 0.5 seconds horizon: 0.3864m\n",
    "MSE for 5/30 seconds horizon: 0.3181\n",
    "MSE for 0.1 seconds horizon: 0.2897\n",
    "\n",
    "RNN: (80,6,250,5,history_length = 10)\n",
    "MSE for 0.5 seconds horizon: 0.3337\n",
    "MSE for 5/30 seconds horizon: 0.3180\n",
    "MSE for 0.1 seconds horizon: 0.2831\n",
    "\n",
    "LSTM:(80,6,250,5,history_length = 10)\n",
    "MSE for 0.5 seconds horizon: 0.3372\n",
    "MSE for 5/30 seconds horizon: 0.3124\n",
    "MSE for 0.1 seconds horizon: 0.2901\n",
    "\n",
    "LSTM:(80,6,250,1,history_length = 10)\n",
    "MSE for 0.5 seconds horizon: 0.31\n",
    "MSE for 5/30 seconds horizon: 0.2994\n",
    "MSE for 0.1 seconds horizon: 0.2649\n",
    "\n",
    "Baseline:\n",
    "MSE for 0.5 seconds horizon: 0.3812\n",
    "MSE for 5/30 seconds horizon:0.3220\n",
    "MSE for 0.1 seconds horizon: 0.3097"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e6b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "performance_dict = {'network':['Baseline','Baseline','Baseline','RNN_1','RNN_1','RNN_1','RNN_5','RNN_5','RNN_5','LSTM_1','LSTM_1','LSTM_1','LSTM_5','LSTM_5','LSTM_5'],\n",
    "                   'Horizon (s)':[15/30,np.round(5/30,3),3/30,15/30,np.round(5/30,3),3/30,15/30,np.round(5/30,3),3/30,15/30,np.round(5/30,3),3/30,15/30,np.round(5/30,3),3/30],\n",
    "                   'RMSE (m)':[0.3812,0.3220,0.3097,0.3864,0.3181,0.2897,0.3337,0.3180,0.2831,0.3372,0.3124,0.2901,0.31,0.2994,0.2649]}\n",
    "performance_df = pd.DataFrame(performance_dict)\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "\n",
    "\n",
    "sns.catplot(x='Horizon (s)', y='RMSE (m)', hue='network', data=performance_df, kind='bar')\n",
    "\n",
    "plt.savefig('./Test_Error_LSTM_RNN.pdf',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63dd11f",
   "metadata": {},
   "source": [
    "# non-learning baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01944bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_valid_value(array,index):\n",
    "    valid_idxs = np.where(array[:,index,:3] != [0,0,0])\n",
    "#     print(valid_idxs)\n",
    "    if(len(valid_idxs[0]) > 0):\n",
    "        max_valid_idx = valid_idxs[0].max()\n",
    "#         print(array.shape)\n",
    "        return True,array[max_valid_idx,index,:3]\n",
    "    else:\n",
    "        return False,[0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b84d847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our_model.eval()\n",
    "final_loss = 0\n",
    "pred_horizon = 15\n",
    "test_df = pd.read_pickle('alice_no_sword_pre_processed3.pkl')\n",
    "test_dataset = Hands_Dataset(test_df,pose_model,pred_horizon = pred_horizon,history_length = history_length)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False,num_workers = 1,prefetch_factor= 4,persistent_workers=  True)\n",
    "gts = []\n",
    "preds = []\n",
    "last_valid_right = False\n",
    "last_valid_left = False\n",
    "valid_left_pose = [0,0,0]\n",
    "valid_right_pose = [0,0,0]\n",
    "for data in tqdm(test_dataloader):\n",
    "    x = data['data'].float().numpy().reshape(-1,20,4)\n",
    "#     x.to(device)\n",
    "    gt_pose = data['gt_pose'].float().to(device)\n",
    "    valid_l,left_pose = get_last_valid_value(x,18)\n",
    "    valid_r,right_pose = get_last_valid_value(x,19)\n",
    "    if(valid_l):\n",
    "        valid_left_pose = left_pose\n",
    "    if(valid_r):\n",
    "        valid_right_pose = right_pose\n",
    "    \n",
    "    pred = np.concatenate([valid_left_pose,valid_right_pose])\n",
    "    preds.append(pred)\n",
    "    with torch.no_grad():\n",
    "#         start_time = time.start()\n",
    "        # zero the parameter gradients\n",
    "        # forward + backward + optimize\n",
    "#         outputs,hidden = our_model(x)\n",
    "#         preds.append(outputs.cpu().numpy())\n",
    "#         break\n",
    "        gts.append(gt_pose.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5a88da",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(np.array(gts).reshape(-1,6),np.array(preds).reshape(-1,6),squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0050f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_last_valid_value(x,18)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
