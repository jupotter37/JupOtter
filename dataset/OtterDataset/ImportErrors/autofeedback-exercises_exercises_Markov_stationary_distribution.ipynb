{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NVOkK4hCU7RK"
   },
   "source": [
    "# Run this cell first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCMw-lybOsz-"
   },
   "outputs": [],
   "source": [
    "# this code enables the automated feedback. If you remove this, you won't get any feedback\n",
    "# so don't delete this cell!\n",
    "try:\n",
    "  import AutoFeedback\n",
    "except (ModuleNotFoundError, ImportError):\n",
    "  %pip install git+https://github.com/abrown41/AutoFeedback\n",
    "  import AutoFeedback\n",
    "\n",
    "try:\n",
    "  from testsrc import test_main\n",
    "except (ModuleNotFoundError, ImportError):\n",
    "  %pip install \"git+https://github.com/autofeedback-exercises/exercises.git#subdirectory=New-SOR3012/Markov_stationary_distribution\"\n",
    "  from testsrc import test_main\n",
    "\n",
    "def runtest(tlist):\n",
    "  import unittest\n",
    "  from contextlib import redirect_stderr\n",
    "  from os import devnull\n",
    "  with redirect_stderr(open(devnull, 'w')):\n",
    "    suite = unittest.TestSuite()\n",
    "    for tname in tlist:\n",
    "      suite.addTest(eval(f\"test_main.UnitTests.{tname}\"))\n",
    "    runner = unittest.TextTestRunner()\n",
    "    try:\n",
    "      runner.run(suite)\n",
    "    except AssertionError:\n",
    "      pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AvmnPiZHJswa"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this block we are going to continue exploring the properties of Markov chains.  The chains we will look at in this block are not going to have transient states.  Many of these chains have a property known as ergodicity which is described in the following 16-minute video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eU_odTSCJswa"
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/JZnzQ8YzVZg?si=KHq96zsu7XRZek03\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wVc3obbLJswb"
   },
   "source": [
    "Once you have watched the video above run the following cell and continue on with the exercises that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a3ZHhH9iJswb"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zY6mjniU4p6S"
   },
   "source": [
    "# Calculating transition probabilities by sampling\n",
    "\n",
    "The aim of this exercise is to write a function to estimate the elements of the `n`-step transition probability matrix by sampling.  The method that we will use to do this is described in the following video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJ8lffeVJswc"
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/xPw1hwREe4Y?si=k4lNcQOTcxHJvXcY\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41AFws0kJswc"
   },
   "source": [
    "Let's try to implement the algorithm from the video.  Let's consider a chain with the following transition matrix .\n",
    "\n",
    "$$\n",
    "A = \\left(\n",
    "\\begin{matrix}\n",
    "0.3 & 0.5 & 0.2 \\\\\n",
    "0.3 & 0.4 & 0.3 \\\\\n",
    "0.2 & 0.5 & 0.3\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "You can thus set a variable `A` equal to this matrix by using the `np.array` command that was introduced in previous exercises.\n",
    "\n",
    "To sample the chain you should write a function called `markov_move`.  This function is the same as the function you wrote in the previous block for generating the next state in a Markov chain.  Just as in the previous exercises this function takes two arguments.  The first of these arguments, `trans`, should be the 1-step transition matrix for the Markov chain that is being simulated.  The second argument, `start`, is the state that the system is currently within.  Your function should generate the next state in the chain.\n",
    "\n",
    "You can now write a function to generate the Bernoulli random variable described above.  In order to pass the test you will need to call this function `is_transition`.  Furthermore, this function should have four arguments:\n",
    "\n",
    "* `trans` is the one-step transition probablity matrix\n",
    "* `start` is the state that the chain begins within\n",
    "* `nsteps` is the number of steps in the Markov chain that you are going to run\n",
    "* `target` is the target state that you would like to end in\n",
    "\n",
    "Within the function you should call `markov_move` `nsteps` time starting from state `start`.  Your function should then return 1 if the final state is state `target` and 0 otherwise.\n",
    "\n",
    "The final function you should write should be called `sample_mean`.   This function should take five arguments:\n",
    "\n",
    "* `trans`, should be the 1-step transition matrix for the Markov chain that is being simulated.\n",
    "* `start` is then state that the system starts within.\n",
    "* `nsteps` is the number of steps in the Markov chain that you are going to run\n",
    "* `target` is the target state that you would like to end in\n",
    "* `nsamples` should be the number of samples that are going to be generated by calling `is_transition`.\n",
    "\n",
    "Your `sample_mean` function should call `is_transition` `nsamples` times and thus generate `nsamples` samples of the Bernoulli random variable of interest.  You should calculate a sample mean and a sample variance from these `nsamples` copies of the random variable.  The function `sample_mean` should then return 2 arguments:\n",
    "\n",
    "* `mean` - the sample mean that was obtained by calling `endstate` `nsamples` times\n",
    "* `conf` - the 90% confidence limit around this estimate of the mean\n",
    "\n",
    "You can calculate the confidence limit by using the ideas about the central limit theorem that were introduced in previous exercises.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rgf5oCm1zyj0"
   },
   "outputs": [],
   "source": [
    "def markov_move( trans, start ) :\n",
    "\n",
    "\n",
    "def is_transition( trans, start, nsteps, target ) :\n",
    "\n",
    "\n",
    "def sample_mean( trans, start, nsteps, target, nsamples ) :\n",
    "\n",
    "    return mean, conf\n",
    "\n",
    "# Setup the transition matrix here\n",
    "A = \n",
    "\n",
    "\n",
    "# Now estimate some hitting probablities if we start from state 2\n",
    "for i in range(3) :\n",
    "    for j in range(3) :\n",
    "        prob, conf = sample_mean( A, i, 10, j, 100 )\n",
    "        print('There is a 90% probablity that element', i+1, j+1, 'of the 10-step transition probablity matrix is within', conf, 'of', prob )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hUP6mnDQvmJH"
   },
   "outputs": [],
   "source": [
    "runtest(['test_markov_move', 'test_endstate', 'test_mean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7cmi1k2NOZY"
   },
   "source": [
    "# Using the Chapmann-Kolmogorov relation\n",
    "\n",
    "Calculating the n-step transition matrix for a Markov chain by hand is not very sensible because, as the following video explains, there is an easy to derive result called the Chapman Kolmogorov relation which tells us that:\n",
    "\n",
    "$$\n",
    "A^{n+m} = A^n A^m\n",
    "$$\n",
    "\n",
    "This relationship essentially tells us that the n step transition probablity matrix is equal to the nth power of the 1-step transition probablity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wDq_LOMJswd"
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/W5P4kCpdhho?si=i5Un3tS9jOeZ-fya\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-z3IojgSJswd"
   },
   "source": [
    "You can calculate the `n`th power of a matrix, `A`, in python by using the following command:\n",
    "\n",
    "```python\n",
    "matpow = np.linalg.matrix_power( A, n )\n",
    "```\n",
    "\n",
    "Furthermore, you can set the matrix `A` using the `np.array` command that we have learned about elsewhere.\n",
    "\n",
    "Your task in this exericse is to set the variables `A2`, `A10`, `A50` and `A100` equal to the 2, 10, 50 and 100 step transition probablity matrices respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJMJFt1djOeS"
   },
   "outputs": [],
   "source": [
    "\n",
    "A = \n",
    "\n",
    "A2 = \n",
    "A10 = \n",
    "A50 = \n",
    "A100 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QIGHOirB1nIA"
   },
   "outputs": [],
   "source": [
    "runtest(['test_vals'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sP8el5LVumNI"
   },
   "source": [
    "# Sampling the stationary distribution\n",
    "\n",
    "Consider the Markov chain with the transition matrix shown below:\n",
    "\n",
    "$$\n",
    "A = \\left(\n",
    "\\begin{matrix}\n",
    "0.3 & 0.5 & 0.2 \\\\\n",
    "0.3 & 0.4 & 0.3 \\\\\n",
    "0.2 & 0.5 & 0.3\n",
    "\\end{matrix}\n",
    "\\right)\n",
    "$$\n",
    "\n",
    "All the states in this chain are recurrent.  If you leave any one state there is a guarantee that you will return to it again at some point in the future.  We can thus run the Markov chain for a certain amount of time and calculate the fraction of time that is spent in each of the three states.  The fraction of time that the chain spends in each state is an estimate of a quantity known as the stationary distribution of this Markov chain.  In this exercise we are thus going to learn how to estimate this stationary distribution by sampling the chain.\n",
    "\n",
    "The algorithm that you will use to estimate the stationary distribution is described in the following video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iTEOzv6IJswe"
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/knh8iqowfHg?si=6Fql8CLPhmQA4H4h\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cZbYP8-gJswe"
   },
   "source": [
    "To complete the exercise I want you to write some code in the cell below to generate and plot an estimate of the stationary distribution for the Markov chain with the transition matrix that I have provided above.  You should plot a bar chart in which the heights of the bars are the estimates for the elements of the stationary distribution that you get by sampling.   These x-coordinates of the bars should at 1, 2 and 3 and the x-axis label in your graph should be 'state'. The y-axis label should then be 'probability'.  Furthermore, as has already been discussed the bars should have heights that correspond to the fraction of the `nsteps` that you ran the chain for when the chain was in that particular state.\n",
    "\n",
    "Notice that you should have already set a variable `A` equal to the matrix.  You will also already have written a function called `markov_move` for generating the next state in a Markov chain for an earlier exericse. You can call ths `markov_move` function repeatedly and thus generate a Markov chain that samples the above transition matrix.  Much as you have learned to do when calculating histograms you can setup a vector to keep track of the number of visits to each of the states in the chain.  In other words, you can run the chain for `nsteps` steps and count the number of times the chain visits each state in a 3 dimensional vector.  If you then divide this 3 dimensional vector by `nsteps` what you have is an estimate of the stationary distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3byDY0srucI"
   },
   "outputs": [],
   "source": [
    "# This is the number of steps to run with the Markov chain\n",
    "nsteps = 1000\n",
    "# Add code to accumulate and plot your estimate of the transition probablity matrix here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This code is required for the autofeedback- don't delete it!\n",
    "fighand = plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aEvnT-wQr49a"
   },
   "outputs": [],
   "source": [
    "runtest(['test_plot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gUAZiKCz3ca"
   },
   "source": [
    "# Calculating the stationary distribution\n",
    "\n",
    "You can calculate the limiting stationary distribution for a Markov chain by sampling.  You can also extract this vector by calculating the principle left eigenvector of the transition matrix.  If you are interested the following video (which you don't have to watch) explains why this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wmdm3NtSJswe"
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/1v-GEdV8zys?si=4MTMBnrISRsx89tt\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWKoR5b1Jswe"
   },
   "source": [
    "You can then calculate the eigenvalues and eigenvectors of `A` using the `np.linalg.eig` command as shown below:\n",
    "\n",
    "```python\n",
    "w, v = np.linalg.eig( A )\n",
    "```\n",
    "\n",
    "The variable `w` here is a vector that contains the eigenvalues of the matrix, while `v` is a matrix that contains the right eigenvectors.  If you print the eigenvalues (`w`) you should see that there is one eigenvalue that is equal to 1.  All the other eigenvalues will be less than 1.  If you now print the eigenvector that corresponds to the eigenvalue that has eigenvalue 1 you should see that all its elements are the same as is illustrated in the code cell below:\n",
    "\n",
    "```python\n",
    "#Â Print the eigenvalues\n",
    "print(w)    # This outputs [ 1.   0.1 -0.1] notice that element 0 of this vector of eigenvalues is 1.\n",
    "# Now print the eigenvector that corresponds to the eigenvalue that is equal to one\n",
    "print(v[:,0])   # This outputs [-0.57735027 -0.57735027 -0.57735027]  # Notice that all the elements of this eigenvector are the same.\n",
    "```\n",
    "\n",
    "Doing the experiments above allows you to confirm that you have setup your transition matrix correctly.  If the Markov chain has a limiting stationary distribution then the largest eigenvalue of the transition matrix should be equal to one and the eigenvector that corresponds to this eigenvalue should have all its elements equal.  We have not extracted the limiting stationary distribution by doing the above, however, as to extract the limiting stationary distribution you need to extract the left eigenvectors by using the commands shown below:\n",
    "\n",
    "```python\n",
    "w, lv = np.linalg.eig( A.T )\n",
    "```\n",
    "\n",
    "The command above diagonalises the transpose of the transition matrix.  The eigenvalues of the transpose should be the same as the eigenvalues of the original matrix.  There should, therefore, still be an eigenvalue that is equal to one.  The eigenvector that corresponds to this eigenvalue contains the information about the limiting stationary distribution.   Problematically, however, the eigenvector will have been calculated so that its `n` elements satisfy:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n a_i^2 = 1\n",
    "$$\n",
    "\n",
    "we can resolve this problem by renormalising the eigenvector as follows:\n",
    "\n",
    "```python\n",
    "# I am assuming here that w[0]=1\n",
    "stationary_distribution = lv[:,0] / sum(lv[:,0)\n",
    "```\n",
    "\n",
    "The elements of the vector `stationary_distribution` above sum to one.  The elements of this vector thus tell us the probabilities of being in the various states of the Markov chain.\n",
    "\n",
    "Your task in this exercise is use the commands I have shown you to calculate and plot the limiting stationary distribution for the Markov chain with the transition graph that I have given you above.  You should label the states in this chain as 1, 2 and 3 and these labels should appear on the x-axis of your graph.  You should then draw a bar chart in which the heights of the bars are the elements of the stationary distribution for states 1, 2 and 3.  The label for the x-axis of your graph should be 'State' and the label for the y-axis of your graph should be 'Probability'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOHycfZbiTbW"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# This code is required for the autofeedback- don't delete it!\n",
    "fighand = plt.gca()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdFlRgKRyu21"
   },
   "outputs": [],
   "source": [
    "runtest(['test_plot_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfhXoPEScc5n"
   },
   "source": [
    "# Errors on sampled stationary distributions\n",
    "\n",
    "In earlier blocks we have emphasized that when you estimate histograms and averages by sampling you must **always** provide an estimate of the error on you estimate.  Providing the information on the errors is essential as the results you obtain from stocastic simulations are random variables.  For them to be reproducible we must provide some information on the distribution that was sampled.\n",
    "\n",
    "We cannot calculate the error on the histogram we sampled in the previous but one exercise by sampling because the random variables that we generate when we sample a Markov chain are **not independent**.  This is important because if we estimate the sample variance, $S^2$ for a set of identical but non-independent random variables using:\n",
    "\n",
    "$$\n",
    "S^2 = \\frac{n}{n-1} \\left[ \\left( \\frac{1}{n} \\sum_{i=1}^n X_i^2 \\right) - \\overline{X}^2 \\right] \\qquad \\textrm{where} \\qquad \\overline{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n",
    "$$\n",
    "\n",
    "Then the variance for $\\overline{X}$ cannot be estimated $\\frac{S^2}{n}$, which is the result we have used for identical **and indepndent** random variables throughout this course.\n",
    "\n",
    "Consequently, to get an estimate of the variance for a time series of correlated random variables we have to use a method known as block averaging, which is described in the following video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMaVAeCmJswf"
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/0KqCK0yG9T0?si=t1klpc0qdZvLdbP_\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" referrerpolicy=\"strict-origin-when-cross-origin\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yeR3XdQ2Jswf"
   },
   "source": [
    "The rest of the exercises in this notebook provide you with an opportunity to try to use this block averaging technique yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KUnCoygaJswf"
   },
   "source": [
    "## Calculating the average\n",
    "\n",
    "Let's start with something easy.  I have read in a time series of random variables into the NumPy array called data in the following cell.  Your first task is set a variable called `average` equal to the average value that the random variable took during the trajectory.  This quantity should, obviously, be calculated using:\n",
    "\n",
    "$$\n",
    "\\overline{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n",
    "$$\n",
    "\n",
    "In this expression $n$ is the random variable in the trajectory and $X_i$ is the value of the $i$th random variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d5ckpxdhAlV3"
   },
   "outputs": [],
   "source": [
    "# Read in the data from a file\n",
    "data = np.loadtxt(\"https://raw.githubusercontent.com/autofeedback-exercises/exercises/main/New-SOR3012/Markov_stationary_distribution/energies\")[:,1]\n",
    "\n",
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iibpa9qhXvzs"
   },
   "outputs": [],
   "source": [
    "runtest(['test_mean_1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LW3D4-Juii9"
   },
   "source": [
    "# Calculating block averages\n",
    "\n",
    "In this exercise we are going to calculate block averages.\n",
    "\n",
    "The NumPy array `data` contains 1000 random variables.  For this exercise I want you to calculate:\n",
    "\n",
    "* The average over the first 100 variables\n",
    "* The average over the second 100 variables\n",
    "* The average over the third 100 variabels\n",
    "* and so on.\n",
    "\n",
    "The final result should thus be a list containing 10 average values.  I have setup a list with 10 elements that you can use to hold these averages.  The list is called `av_eng`.\n",
    "\n",
    "Once you have calculated the elements of `av_eng` I would like you to draw a graph of the results.  The x-coordinates for the 10 points in your graph should be the integers from 1 to 10.  The y-coordinates\n",
    "should be the values of the 10 block averages that you have obtained.  The point with x-coordinate 1 should be the block average from the first 100 energies, the point with x-coordinate 2 should be the block\n",
    "average from the second 100 energies and so on.\n",
    "\n",
    "The x-axis label for your graph should be 'Index' and the y-axis label should be 'Average energy / natural units'\n",
    "\n",
    "\n",
    "N.B. I wrote this exercise for a physics module.  The quantities in the variable are all energies.  The way the physicists in that module are analysing these energies is the same as the way you are analysing the data. Physicists actually do quite a lot of sampling of Markov chains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C4VlvqIjDcNE"
   },
   "outputs": [],
   "source": [
    "# Read in the data from a file\n",
    "data = np.loadtxt(\"https://raw.githubusercontent.com/autofeedback-exercises/exercises/main/New-SOR3012/Markov_stationary_distribution/energies\")[:,1]\n",
    "\n",
    "# Create a list with 10 elements that you will use to hold the average eneriges\n",
    "av_eng = np.zeros(10)\n",
    "\n",
    "# Your code goes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This code is required for the autofeedback- don't delete it!\n",
    "fighand = plt.gca()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYxesXts80jB"
   },
   "outputs": [],
   "source": [
    "runtest(['test_energies'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjz3fywBPBDw"
   },
   "source": [
    "# Calculating the standard deviation\n",
    "\n",
    "In this exercise we are going to remind ourselves how to compute the variance.  We will also see that computing the error is not simply a matter of computing the variance.\n",
    "\n",
    "Recall that the sample variance is given by:\n",
    "\n",
    "$$\n",
    "S^2 = \\frac{n}{n-1} \\left[ \\left( \\frac{1}{n} \\sum_{i=1}^n X_i^2 \\right) - \\overline{X}^2 \\right] \\qquad \\textrm{where} \\qquad \\overline{X} = \\frac{1}{n} \\sum_{i=1}^n X_i\n",
    "$$\n",
    "\n",
    "For this exercise I want you to calculate this quantity for:\n",
    "\n",
    "* The first 100 energies in this file\n",
    "* The second 100 energies in this file\n",
    "* The third 100 energies in the file\n",
    "* and so on.\n",
    "\n",
    "The values for these 10 variances should be stored in the array called `variances`, which I have already created for you.\n",
    "\n",
    "In addition to computing these 10 values for the block variance I would also like you to compute the variance using all the data in the trajectory.  The value of this variance should be stored in a variable called `total_var`.\n",
    "\n",
    "To complete the exercise you will need to plot a graph with two data series.  You will use the first data series to show the variances from each of the blocks.  The x-coordinates of the 10 points of this line should thus be the integers from 1 to 10.  The y-coordinates will then be the values of the 10 block variances that you have obtained.  The point with x-coordinate 1 should be the block variance from the first 100 energies, the point with x-coordinate 2 should be the block variance from the second 100 energies and so on.\n",
    "\n",
    "The other thing you will plot is a line indicating the total variance for all the data. You can plot this with a command like the following:\n",
    "\n",
    "```python\n",
    "plt.plot( [1,10], [total_var,total_var], 'r-' )\n",
    "```\n",
    "\n",
    "This command ensures that a red horizontal line is drawn to indicate the value of the total variance.  You should find that black dots illustrating the block variances should all be reasonably close to the red line.  This makes sense - both sets of calculations that you are performing here are estimating the same quantity.  The only difference is that when you compute the variances from each block of data you have fewer data points.\n",
    "\n",
    "The x-axis label for your graph should be 'Index' and the y-axis label should be 'Variance / energy^2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Qgfvo-aXMVL"
   },
   "outputs": [],
   "source": [
    "# Read in the energies from a file\n",
    "data = np.loadtxt(\"https://raw.githubusercontent.com/autofeedback-exercises/exercises/main/New-SOR3012/Markov_stationary_distribution/energies\")[:,1]\n",
    "# Create a list with 10 elements that you will use to hold the variances\n",
    "variances = np.zeros(10)\n",
    "data2 = data*data\n",
    "# Your code goes here\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This code is required for the autofeedback- don't delete it!\n",
    "fighand = plt.gca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DHqLcU4aDMqj"
   },
   "outputs": [],
   "source": [
    "runtest(['test_graph'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSK-InwsDR7X"
   },
   "source": [
    "# The variance for the block averages\n",
    "\n",
    "In this exercise we are going to compute the variance for the block averages.\n",
    "\n",
    "The previous exercise showed you how to compute the variance over the whole trajectory.  We also learned that this variance is not going to be useful in terms of us calculating the error bars for our ensemble averages.  The error bars on the ensemble average will be computed by calculating the average of the block averages.  In other words, we are going to calculate $n$ block averages over each of the $m$-frame blocks in our trajectory using:\n",
    "\n",
    "$$\n",
    "\\overline{X}_j = \\frac{1}{m} \\sum_{i=1}^m X_i\n",
    "$$\n",
    "\n",
    "We will assume that these $n$ block averages represent $n$ samples of the same random variable.  We can thus calculate the average for this random variable as:\n",
    "\n",
    "$$\n",
    "\\overline{X} = \\frac{1}{n} \\sum_{j=1}^n \\overline{X}_j\n",
    "$$\n",
    "\n",
    "\n",
    "Furthermore, because we have $n$ samples, we can estimate the standard deviation (the error) for this average using:\n",
    "\n",
    "$$\n",
    "S = \\sqrt{\\frac{1}{n-1}\\left[ \\left( \\frac{1}{n} \\sum_{j=1}^n \\overline{X}_j^2\\right) - \\overline{X}^2\\right] }\n",
    "$$\n",
    "\n",
    "I would like you to insert code in `main.py` that computes the average energy from the blocks using the second equation on this page and the error in this quantity using the third equation on this page.  To do this you are going to first have to compute block averages over the first 100, second 100, third 100 and so on frames in the trajectory as you have done in previous exercises.  You are then going to have to compute the quantities above from these block averages.  The final value that you get for the average energy should be saved in a variable called `average` and the final value for the error should be saved in a variable called `error`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6tl3czxqO-6C"
   },
   "outputs": [],
   "source": [
    "# Read in the energies from a file\n",
    "data = np.loadtxt(\"https://raw.githubusercontent.com/autofeedback-exercises/exercises/main/New-SOR3012/Markov_stationary_distribution/energies\")[:,1]\n",
    "\n",
    "# Create a list to hold the block averages\n",
    "blocks = np.zeros(10)\n",
    "\n",
    "# Your code goes here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e6lANdTn8KOt"
   },
   "outputs": [],
   "source": [
    "runtest(['test_average_correct', 'test_error_correct'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MYhOwQLQ2brE"
   },
   "source": [
    "# The relationship between the error and the size of the blocks\n",
    "\n",
    "In this final exercise we are going to bring together everything we have learned in order to look at how the block averaging technique allows us to resolve the problems that we would otherwise have in estimating errors with correlated variables.\n",
    "\n",
    "The previous four exercises have shown you how to compute the average and the standard deviation by block averaging.   In this exercise we are going to look at how the size of the error depends on the size of the blocks.  To do this we will need to encapsulate\n",
    "the code that we have written to calculate block averages and errors in a function that takes as input the data and the length of the block, M, into which to divide the data.  In `main.py` I have written the first line of this function for you as follows\n",
    "\n",
    "```python\n",
    "def block_average( M, data ) :\n",
    "    # Your code goes here\n",
    "\n",
    "    return error\n",
    "```\n",
    "\n",
    "You should then use the function you have written to plot a graph that shows how the size of the error depends on the length of the blocks.  In drawing this graph you should calculate the error when block averages with the following lengths\n",
    "are used in the calculation of the error:\n",
    "\n",
    "```python\n",
    "xvals = [10,20,30,40,60,100,120,200,300,400]\n",
    "```\n",
    "\n",
    "The x coordinates of the points of in your graph should be equal to the numbers in the list above.  The y-coordinates of these points should then be the corresponding values of the error for that size of block.  The y value for the point at x=10 is thus\n",
    "the error that is calculated from block averages that are calculated from the first 10, second 10 points and so on.  In practise you can calculate these y-values by using the function `block_average` that you will have written.\n",
    "\n",
    "You should see that error is initially small.  It will then grow as the size of the various blocks is increased before plateauing to a constant value.\n",
    "\n",
    "The x axis label of your graph should be 'Size of blocks' and the y axis label should be 'Error'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cv-gvpwd108u"
   },
   "outputs": [],
   "source": [
    "def block_average( M, data ) :\n",
    "  # Your code goes here\n",
    "  \n",
    "\n",
    "  return error\n",
    "\n",
    "# Read in the energies from a file\n",
    "data = np.loadtxt(\"https://raw.githubusercontent.com/autofeedback-exercises/exercises/main/New-SOR3012/Markov_stationary_distribution/energies\")[:,1]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# This code is required for the autofeedback- don't delete it!\n",
    "fighand = plt.gca()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kenI7qxdqSMq"
   },
   "outputs": [],
   "source": [
    "runtest(['test_blockVals', 'test_plot_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bOxcnJ83Jswg"
   },
   "source": [
    "# Taking it further\n",
    "\n",
    "The exercises in this notebook have been concerned with Markov chains that only contain recurrent states.  The obvious thing to do to take these ideas further is to devise a Markov chain with all recurrent states of your own design and then investigate it.  You can do any one of the following analyses on your Markov chain:\n",
    "\n",
    "* You can calculate the $n$ step transition probability matrix by sampling and compare it with the result you obtain using the Chapmann Kolmogorov relation.\n",
    "* You can calculate the limiting stationary distribution by sampling and you can compare it with the top eigenvector of the transition matrix.\n",
    "\n",
    "Remember that any time that you estimate a quantity by sampling it multiple times you **must** also include the error on your estimate to make your result reproducible.  If you are estimating the $n$-step transition probability matrix the error can be obtained in the usual way.  if you are estimating the **limiting stationary distribution** this error **must be obtained using the block averaging technique.**   \n",
    "\n",
    "If you want to challenge yourself and investigate this subject further, you can investigate a Markov chain that has a stationary distribution that is not limiting.  I'll leave it to you to work out what that means.  A good place to start is the video about determining the limiting stationary distribution by finding an eigenvector that I included earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqzU-7v5Jswg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "cell_execution_strategy": "setup",
   "collapsed_sections": [
    "NVOkK4hCU7RK"
   ],
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
