{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imageio'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-57e97af0373f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mimageio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imageio'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import imageio\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    def tqdm(x): return x\n",
    "    print(\"Install tqdm for cool progress bars\")\n",
    "\n",
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "\n",
    "def weight_variable(shape):\n",
    "    '''\n",
    "    Initialize weights\n",
    "    :param shape: shape of weights, e.g. [w, h ,Cin, Cout] where\n",
    "    w: width of the filters\n",
    "    h: height of the filters\n",
    "    Cin: the number of the channels of the filters\n",
    "    Cout: the number of filters\n",
    "    :return: a tensor variable for weights with initial values\n",
    "    '''\n",
    "\n",
    "    # IMPLEMENT YOUR WEIGHT_VARIABLE HERE\n",
    "    W = tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "    return W\n",
    "\n",
    "def bias_variable(shape):\n",
    "    '''\n",
    "    Initialize biases\n",
    "    :param shape: shape of biases, e.g. [Cout] where\n",
    "    Cout: the number of filters\n",
    "    :return: a tensor variable for biases with initial values\n",
    "    '''\n",
    "\n",
    "    # IMPLEMENT YOUR BIAS_VARIABLE HERE\n",
    "    b = tf.Variable(tf.constant(0.0, shape=shape))\n",
    "    return b\n",
    "\n",
    "def conv2d(x, W):\n",
    "    '''\n",
    "    Perform 2-D convolution\n",
    "    :param x: input tensor of size [N, W, H, Cin] where\n",
    "    N: the number of images\n",
    "    W: width of images\n",
    "    H: height of images\n",
    "    Cin: the number of channels of images\n",
    "    :param W: weight tensor [w, h, Cin, Cout]\n",
    "    w: width of the filters\n",
    "    h: height of the filters\n",
    "    Cin: the number of the channels of the filters = the number of channels of images\n",
    "    Cout: the number of filters\n",
    "    :return: a tensor of features extracted by the filters, a.k.a. the results after convolution\n",
    "    '''\n",
    "\n",
    "    # IMPLEMENT YOUR CONV2D HERE\n",
    "    h_conv = tf.nn.conv2d(x, W, strides[1, 1, 1, 1], padding='SAME')\n",
    "    return h_conv\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    '''\n",
    "    Perform non-overlapping 2-D maxpooling on 2x2 regions in the input data\n",
    "    :param x: input data\n",
    "    :return: the results of maxpooling (max-marginalized + downsampling)\n",
    "    '''\n",
    "\n",
    "    # IMPLEMENT YOUR MAX_POOL_2X2 HERE\n",
    "    h_max = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "    return h_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers\n",
    "def var_log(name, vector):\n",
    "    with tf.name_scope(name + \"_SUMMARY\"):\n",
    "        mean, var = tf.nn.moments(vector, axes=list(range(tf.rank(vector).eval())))\n",
    "        tf.summary.scalar(\"mean\", mean)\n",
    "        tf.summary.scalar(\"variance\", var)\n",
    "        tf.summary.scalar(\"std\", tf.sqrt(var))\n",
    "        tf.summary.scalar(\"max\", tf.reduce_max(vector))\n",
    "        tf.summary.scalar(\"min\", tf.reduce_min(vector))\n",
    "        tf.summary.histogram('Hist', vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2fa0ab65f6cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntrain\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnclass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntest\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnclass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnchannels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mLTrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntrain\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnclass\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnclass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "ntrain = 1000 # per class\n",
    "ntest = 100 # per class\n",
    "nclass = 10 # number of classes\n",
    "imsize = 28\n",
    "nchannels = 1\n",
    "batchsize = 128\n",
    "epochs = 50\n",
    "\n",
    "Train = np.zeros((ntrain*nclass,imsize,imsize,nchannels))\n",
    "Test = np.zeros((ntest*nclass,imsize,imsize,nchannels))\n",
    "LTrain = np.zeros((ntrain*nclass,nclass))\n",
    "LTest = np.zeros((ntest*nclass,nclass))\n",
    "\n",
    "itrain = -1\n",
    "itest = -1\n",
    "for iclass in range(0, nclass):\n",
    "    for isample in range(0, ntrain):\n",
    "        path = '~/CIFAR10/Train/%d/Image%05d.png' % (iclass,isample)\n",
    "        im = img.imread(path) # 28 by 28\n",
    "        im = im.astype(float)/255\n",
    "        itrain += 1\n",
    "        Train[itrain,:,:,0] = im\n",
    "        LTrain[itrain,iclass] = 1 # 1-hot label\n",
    "    for isample in range(0, ntest):\n",
    "        path = '~/CIFAR10/Test/%d/Image%05d.png' % (iclass,isample)\n",
    "        im = img.imread(path) # 28 by 28\n",
    "        im = im.astype(float)/255\n",
    "        itest += 1\n",
    "        Test[itest,:,:,0] = im\n",
    "        LTest[itest,iclass] = 1 # 1-hot label\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "tf_data = tf.placeholder(tf.float32, shape=[None, imsize, imsize, nchannels])#tf variable for the data, remember shape is [None, width, height, numberOfChannels]\n",
    "tf_labels = tf.placeholder(tf.float32, shape=[None, nclass])#tf variable for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# model\n",
    "#create your model\n",
    "x = tf_data\n",
    "W1 = weight_variable([5, 5, 1, 32])\n",
    "b1 = bias_variable([32])\n",
    "h1 = tf.nn.relu(conv2d(x, W1) + b1) #Running it with ReLu activation\n",
    "h_pool1 = max_pool_2x2(h1)\n",
    "\n",
    "var_log(\"W1\", W1)\n",
    "var_log(\"b1\", b1)\n",
    "var_log(\"h1\", h1)\n",
    "var_log(\"h_pool1\", h_pool1)\n",
    "\n",
    "h_pool1_dropoff = tf.nn.dropout(h_pool1, tf.placeholder(tf.float32))\n",
    "\n",
    "W2 = weight_variable([5, 5, 64, 128])\n",
    "b2 = bias_variable([128])\n",
    "h2 = tf.nn.relu(conv2d(x, W2) + b2) #Running it with ReLu activation\n",
    "h_pool2 = max_pool_2x2(h2)\n",
    "\n",
    "var_log(\"W2\", W2)\n",
    "var_log(\"b2\", b2)\n",
    "var_log(\"h2\", h2)\n",
    "var_log(\"h_pool2\", h_pool2)\n",
    "\n",
    "h_pool2_dropoff = tf.nn.dropout(h_pool2, tf.placeholder(tf.float32))\n",
    "\n",
    "conv_out = h_pool2_dropoff\n",
    "\n",
    "out_shape = conv_out.get_shape().as_list()\n",
    "flat_shape = out_shape[1] * out_shape[2] * out_shape[3]\n",
    "flat_conv = tf.reshape(conv_out, [-1, flat_shape])\n",
    "\n",
    "prob = tf.placeholder(tf.float32)\n",
    "flat_conv_dropout = tf.nn.dropout(flat_conv, prob)\n",
    "\n",
    "# final layer\n",
    "W_full2 = weight_variable([flat_shape, 10])\n",
    "b_full2 = bias_variable([10])\n",
    "y_conv = tf.matmul(flat_conv_dropout, W_full2) + b_full2\n",
    "\n",
    "var_log(\"W_full2\", W_full2)\n",
    "var_log(\"b_full2\", b_full2)\n",
    "var_log(\"y_conv\", y_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------\n",
    "# loss\n",
    "# set up the loss, optimization, evaluation, and accuracy\n",
    "# setup training\n",
    "# --------------------------------------------------\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels=tf_labels, logits=y_conv))\n",
    "opt = tf.train.AdamOptimizer(1e-3) # MODIFIED this learning rate as a variable for accuracy.\n",
    "optimizer = opt.minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(tf_labels, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "tf.summary.scalar(\"Loss\", cross_entropy)\n",
    "tf.summary.scalar(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
