{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "b4c8889d364f4dfebd025cc0b0e3b7ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8becb5f472f24631b27efc5a44b16ee7",
       "IPY_MODEL_2c2073133a9d4645bdbd42f8d8d5ea4d",
       "IPY_MODEL_cbdb5d6d7b524f5581321b4b4be6ed35"
      ],
      "layout": "IPY_MODEL_30393dc160e4496e990324ae36faad15"
     }
    },
    "8becb5f472f24631b27efc5a44b16ee7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a591a4f5c0f44122b93b0e0fb39fed40",
      "placeholder": "​",
      "style": "IPY_MODEL_d6fd3479d6434fd1a4cd7d320a0926c1",
      "value": "Fetching 9 files: 100%"
     }
    },
    "2c2073133a9d4645bdbd42f8d8d5ea4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bea540f9e14644eab250808f8d0694d2",
      "max": 9,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_168ba64152ef4d43a007420a5c3c4183",
      "value": 9
     }
    },
    "cbdb5d6d7b524f5581321b4b4be6ed35": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf6f3b27c31f4fe49d4d49742e241b27",
      "placeholder": "​",
      "style": "IPY_MODEL_df63ed141f394298a6bef1aef983c98f",
      "value": " 9/9 [00:00&lt;00:00, 286.90it/s]"
     }
    },
    "30393dc160e4496e990324ae36faad15": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a591a4f5c0f44122b93b0e0fb39fed40": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6fd3479d6434fd1a4cd7d320a0926c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bea540f9e14644eab250808f8d0694d2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "168ba64152ef4d43a007420a5c3c4183": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "bf6f3b27c31f4fe49d4d49742e241b27": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df63ed141f394298a6bef1aef983c98f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCP3n0Q_mZT8"
   },
   "outputs": [],
   "source": [
    "!pip install docling\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install torch\n"
   ],
   "metadata": {
    "id": "PblQ7SyQm8ef",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9efc232d-f7ef-4bf2-ee7a-0a1e87262418"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers\n"
   ],
   "metadata": {
    "id": "CVr-M-Kdm_6h",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6c2c3801-43fa-43a9-db2d-5a7f3ecf5e94"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install requests\n"
   ],
   "metadata": {
    "id": "tAoGL0sem_3W",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9fa18196-a92c-4051-c235-79e65d614071"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install huggingface-hub\n"
   ],
   "metadata": {
    "id": "Na1L3_eFm_0U"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install tqdm"
   ],
   "metadata": {
    "id": "nW94ag2em_xd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "pdfs = {\n",
    "    \"MALM\": \"https://www.ikea.com/us/en/assembly_instructions/malm-4-drawer-chest-white__AA-2398381-2-100.pdf\",\n",
    "    \"BILLY\": \"https://www.ikea.com/us/en/assembly_instructions/billy-bookcase-white__AA-1844854-6-2.pdf\",\n",
    "    \"BOAXEL\": \"https://www.ikea.com/us/en/assembly_instructions/boaxel-wall-upright-white__AA-2341341-2-100.pdf\",\n",
    "    \"MICKE\": \"https://www.ikea.com/us/en/assembly_instructions/micke-desk-white__AA-476626-10-100.pdf\"\n",
    "}\n",
    "\n",
    "output_dir = \"data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for name, url in pdfs.items():\n",
    "    response = requests.get(url)\n",
    "    pdf_path = os.path.join(output_dir, f\"{name}.pdf\")\n",
    "\n",
    "    with open(pdf_path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "    print(f\"Downloadeчd {name} to {pdf_path}\")\n",
    "\n",
    "print(\"Downloaded files:\", os.listdir(output_dir))"
   ],
   "metadata": {
    "id": "pxR0toWMm_uj"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, TableFormerMode\n",
    "from docling_core.transforms.chunker import HierarchicalChunker\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import logging\n",
    "pipeline_options = PdfPipelineOptions(do_table_structure=True)\n",
    "pipeline_options.table_structure_options.mode = TableFormerMode.ACCURATE  # use more accurate TableFormer model\n",
    "\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")"
   ],
   "metadata": {
    "id": "U8qLKYavm_rk"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from docling_core.types.doc import DoclingDocument, PictureItem\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "class ImageProcessor:\n",
    "    def __init__(self, doc: DoclingDocument):\n",
    "        self.doc = doc\n",
    "\n",
    "    def add_image(self, image_path: str, page_num: int = 0):\n",
    "        \"\"\"\n",
    "        Добавление изображения в DoclingDocument\n",
    "\n",
    "        Args:\n",
    "            image_path: Путь к изображению\n",
    "            page_num: Номер страницы\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Создаем PictureItem\n",
    "            picture = PictureItem(\n",
    "                source=image_path,\n",
    "                type=\"image\",\n",
    "                parent=\"#/body\",\n",
    "                children=[],\n",
    "                page=page_num,\n",
    "                # Дополнительные метаданные\n",
    "                metadata={\n",
    "                    \"format\": self._get_image_format(image_path),\n",
    "                    \"size\": self._get_image_size(image_path)\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Добавляем в документ\n",
    "            self.doc.pictures.append(picture)\n",
    "\n",
    "            # Обновляем структуру body\n",
    "            self.doc.body.children.append(f\"#/pictures/{len(self.doc.pictures)-1}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error adding image: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def _get_image_format(self, image_path: str) -> str:\n",
    "        \"\"\"Получение формата изображения\"\"\"\n",
    "        with Image.open(image_path) as img:\n",
    "            return img.format"
   ],
   "metadata": {
    "id": "yKdNhi0UbkYX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from docling_core.transforms.chunker import HierarchicalChunker\n",
    "from typing import List, Dict\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "class DocumentProcessor:\n",
    "    def __init__(self, chunk_size: int = 3000, chunk_overlap: int = 300):\n",
    "        self.converter = DocumentConverter()\n",
    "        self.chunker = HierarchicalChunker(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            split_on_headings=True\n",
    "        )\n",
    "\n",
    "    def save_image(self, image, output_dir: Path, prefix: str, page_num: int, img_num: int) -> str:\n",
    "        \"\"\"Сохраняет изображение и возвращает путь\"\"\"\n",
    "        img_dir = output_dir / 'images'\n",
    "        img_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        img_path = img_dir / f\"{prefix}_page{page_num}_img{img_num}.png\"\n",
    "        image.save(img_path)\n",
    "        return str(img_path)\n",
    "\n",
    "    def process_document(self, document_path: str):\n",
    "        try:\n",
    "            doc_path = Path(document_path)\n",
    "            print(f\"\\nОбработка документа: {doc_path.name}\")\n",
    "\n",
    "            doc_result = self.converter.convert(doc_path)\n",
    "\n",
    "            if doc_result and doc_result.document:\n",
    "                chunks = list(self.chunker.chunk(doc_result.document))\n",
    "\n",
    "                processed_chunks = []\n",
    "                images_by_page = {}\n",
    "\n",
    "                # Извлекаем изображения из документа\n",
    "                if hasattr(doc_result.document, 'pages'):\n",
    "                    for page_num, page in enumerate(doc_result.document.pages, 1):\n",
    "                        if hasattr(page, 'images'):\n",
    "                            images_by_page[page_num] = []\n",
    "                            for img_num, img in enumerate(page.images, 1):\n",
    "                                try:\n",
    "                                    # Конвертируем изображение в PIL Image\n",
    "                                    image = Image.open(io.BytesIO(img.content))\n",
    "\n",
    "                                    # Сохраняем изображение\n",
    "                                    img_path = self.save_image(\n",
    "                                        image,\n",
    "                                        Path(\"processed_texts\"),\n",
    "                                        doc_path.stem,\n",
    "                                        page_num,\n",
    "                                        img_num\n",
    "                                    )\n",
    "\n",
    "                                    images_by_page[page_num].append({\n",
    "                                        'path': img_path,\n",
    "                                        'width': image.width,\n",
    "                                        'height': image.height,\n",
    "                                        'format': image.format\n",
    "                                    })\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Ошибка при обработке изображения: {str(e)}\")\n",
    "\n",
    "                for chunk in chunks:\n",
    "                    if hasattr(chunk, 'text'):\n",
    "                        page_num = chunk.meta.doc_items[0].prov[0].page_no if hasattr(chunk.meta, 'doc_items') else None\n",
    "\n",
    "                        chunk_data = {\n",
    "                            'text': chunk.text,\n",
    "                            'metadata': {\n",
    "                                'headings': chunk.meta.headings if hasattr(chunk.meta, 'headings') else [],\n",
    "                                'page_number': page_num,\n",
    "                                'images': images_by_page.get(page_num, [])\n",
    "                            }\n",
    "                        }\n",
    "                        processed_chunks.append(chunk_data)\n",
    "\n",
    "                return processed_chunks\n",
    "            else:\n",
    "                print(f\"Не удалось извлечь текст из {doc_path}\")\n",
    "                return None\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке {document_path}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "def process_all_pdfs():\n",
    "    processor = DocumentProcessor()\n",
    "    data_dir = Path(\"data\")\n",
    "    output_dir = Path(\"processed_texts\")\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    pdf_files = list(data_dir.glob(\"*.pdf\"))\n",
    "    print(f\"Найдено PDF файлов: {len(pdf_files)}\")\n",
    "\n",
    "    for pdf_path in pdf_files:\n",
    "        print(f\"\\nОбработка {pdf_path.name}\")\n",
    "        chunks = processor.process_document(str(pdf_path))\n",
    "\n",
    "\n",
    "        if chunks:\n",
    "            output_path = output_dir / f\"{pdf_path.stem}_chunks.json\"\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump({\n",
    "                    'filename': pdf_path.name,\n",
    "                    'chunks': chunks,\n",
    "                    'total_chunks': len(chunks)\n",
    "                }, f, ensure_ascii=False, indent=2)\n",
    "            print(f\"Сохранено чанков: {len(chunks)}\")\n",
    "\n",
    "            if chunks:\n",
    "                print(\"\\nПример первого чанка:\")\n",
    "                print(\"-\" * 50)\n",
    "                print(f\"Текст: {chunks[0]['text'][:200]}...\")\n",
    "                print(f\"Страница: {chunks[0]['metadata']['page_number']}\")\n",
    "                print(f\"Заголовки: {chunks[0]['metadata']['headings']}\")\n",
    "                if chunks[0]['metadata']['images']:\n",
    "                    print(f\"Изображения на странице: {len(chunks[0]['metadata']['images'])}\")\n",
    "\n",
    "def check_results():\n",
    "    output_dir = Path(\"processed_texts\")\n",
    "    if not output_dir.exists():\n",
    "        print(\"Директория с результатами не найдена\")\n",
    "        return\n",
    "\n",
    "    print(\"\\nРезультаты обработки:\")\n",
    "    for json_file in output_dir.glob(\"*_chunks.json\"):\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            print(f\"\\nФайл: {data['filename']}\")\n",
    "            print(f\"Всего чанков: {data['total_chunks']}\")\n",
    "            if data['chunks']:\n",
    "                print(\"Пример первого чанка:\")\n",
    "                print(\"-\" * 50)\n",
    "                print(f\"Текст: {data['chunks'][0]['text'][:200]}\")\n",
    "                print(f\"Изображения: {len(data['chunks'][0]['metadata']['images'])}\")\n",
    "                for img in data['chunks'][0]['metadata']['images']:\n",
    "                    print(f\"- {img['path']} ({img['width']}x{img['height']})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_all_pdfs()\n",
    "    print(\"\\nПроверка результатов:\")\n",
    "    check_results()"
   ],
   "metadata": {
    "id": "QtUSofly3rwR",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 894,
     "referenced_widgets": [
      "b4c8889d364f4dfebd025cc0b0e3b7ea",
      "8becb5f472f24631b27efc5a44b16ee7",
      "2c2073133a9d4645bdbd42f8d8d5ea4d",
      "cbdb5d6d7b524f5581321b4b4be6ed35",
      "30393dc160e4496e990324ae36faad15",
      "a591a4f5c0f44122b93b0e0fb39fed40",
      "d6fd3479d6434fd1a4cd7d320a0926c1",
      "bea540f9e14644eab250808f8d0694d2",
      "168ba64152ef4d43a007420a5c3c4183",
      "bf6f3b27c31f4fe49d4d49742e241b27",
      "df63ed141f394298a6bef1aef983c98f"
     ]
    },
    "outputId": "7e8c2226-1c82-4898-b576-7c624cf2b3b9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Найдено PDF файлов: 5\n",
      "\n",
      "Обработка ADILS.pdf\n",
      "\n",
      "Обработка документа: ADILS.pdf\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Fetching 9 files:   0%|          | 0/9 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4c8889d364f4dfebd025cc0b0e3b7ea"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Сохранено чанков: 51\n",
      "\n",
      "Пример первого чанка:\n",
      "--------------------------------------------------\n",
      "Текст: For increased stability, re-tighten the screws about two weeks after assembly. Make sure they stay tight by checking them a couple of times per year....\n",
      "Страница: 2\n",
      "Заголовки: ['English']\n",
      "\n",
      "Обработка BILLY.pdf\n",
      "\n",
      "Обработка документа: BILLY.pdf\n",
      "Сохранено чанков: 118\n",
      "\n",
      "Пример первого чанка:\n",
      "--------------------------------------------------\n",
      "Текст: Serious or fatal crushing injuries can occur from furniture tip over. To prevent tip over this furniture must be used with the wall attachment device(s) provided....\n",
      "Страница: 2\n",
      "Заголовки: ['WARNING!']\n",
      "\n",
      "Обработка MALM.pdf\n",
      "\n",
      "Обработка документа: MALM.pdf\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-35-41d62332944e>\u001B[0m in \u001B[0;36m<cell line: 146>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    146\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"__main__\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 147\u001B[0;31m     \u001B[0mprocess_all_pdfs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    148\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"\\nПроверка результатов:\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0mcheck_results\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-35-41d62332944e>\u001B[0m in \u001B[0;36mprocess_all_pdfs\u001B[0;34m()\u001B[0m\n\u001B[1;32m    102\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mpdf_path\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpdf_files\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    103\u001B[0m         \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"\\nОбработка {pdf_path.name}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 104\u001B[0;31m         \u001B[0mchunks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprocessor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_document\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpdf_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    105\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    106\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-35-41d62332944e>\u001B[0m in \u001B[0;36mprocess_document\u001B[0;34m(self, document_path)\u001B[0m\n\u001B[1;32m     32\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf\"\\nОбработка документа: {doc_path.name}\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 34\u001B[0;31m             \u001B[0mdoc_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconvert\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdoc_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     35\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     36\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mdoc_result\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mdoc_result\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdocument\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/validate_call_decorator.py\u001B[0m in \u001B[0;36mwrapper_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     58\u001B[0m         \u001B[0;34m@\u001B[0m\u001B[0mfunctools\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwraps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfunction\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     59\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mwrapper_function\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 60\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mvalidate_call_wrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     61\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m         \u001B[0mwrapper_function\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraw_function\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfunction\u001B[0m  \u001B[0;31m# type: ignore\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_validate_call.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 96\u001B[0;31m         \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__pydantic_validator__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvalidate_python\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpydantic_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mArgsKwargs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     97\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__return_pydantic_validator__\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     98\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__return_pydantic_validator__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mres\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/docling/document_converter.py\u001B[0m in \u001B[0;36mconvert\u001B[0;34m(self, source, raises_on_error, max_num_pages, max_file_size)\u001B[0m\n\u001B[1;32m    170\u001B[0m             \u001B[0mmax_file_size\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmax_file_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    171\u001B[0m         )\n\u001B[0;32m--> 172\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_res\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    173\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    174\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mvalidate_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mConfigDict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstrict\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/docling/document_converter.py\u001B[0m in \u001B[0;36mconvert_all\u001B[0;34m(self, source, raises_on_error, max_num_pages, max_file_size)\u001B[0m\n\u001B[1;32m    191\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    192\u001B[0m         \u001B[0mhad_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 193\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mconv_res\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mconv_res_iter\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    194\u001B[0m             \u001B[0mhad_result\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    195\u001B[0m             if raises_on_error and conv_res.status not in {\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/docling/document_converter.py\u001B[0m in \u001B[0;36m_convert\u001B[0;34m(self, conv_input, raises_on_error)\u001B[0m\n\u001B[1;32m    226\u001B[0m             \u001B[0;31m# Note: PDF backends are not thread-safe, thread pool usage was disabled.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    227\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 228\u001B[0;31m             for item in map(\n\u001B[0m\u001B[1;32m    229\u001B[0m                 \u001B[0mpartial\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_process_document\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mraises_on_error\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mraises_on_error\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    230\u001B[0m                 \u001B[0minput_batch\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/docling/document_converter.py\u001B[0m in \u001B[0;36m_process_document\u001B[0;34m(self, in_doc, raises_on_error)\u001B[0m\n\u001B[1;32m    267\u001B[0m         )\n\u001B[1;32m    268\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mvalid\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 269\u001B[0;31m             \u001B[0mconv_res\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_execute_pipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0min_doc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mraises_on_error\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mraises_on_error\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    270\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    271\u001B[0m             \u001B[0merror_message\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34mf\"File format not allowed: {in_doc.file}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/docling/document_converter.py\u001B[0m in \u001B[0;36m_execute_pipeline\u001B[0;34m(self, in_doc, raises_on_error)\u001B[0m\n\u001B[1;32m    290\u001B[0m             \u001B[0mpipeline\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_pipeline\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0min_doc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    291\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mpipeline\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 292\u001B[0;31m                 \u001B[0mconv_res\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpipeline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecute\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0min_doc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mraises_on_error\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mraises_on_error\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    293\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    294\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mraises_on_error\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/docling/pipeline/base_pipeline.py\u001B[0m in \u001B[0;36mexecute\u001B[0;34m(self, in_doc, raises_on_error)\u001B[0m\n\u001B[1;32m     42\u001B[0m                 \u001B[0;31m# These steps are building and assembling the structure of the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m                 \u001B[0;31m# output DoclingDocument\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m                 \u001B[0mconv_res\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_build_document\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconv_res\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m                 \u001B[0mconv_res\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_assemble_document\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconv_res\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m                 \u001B[0;31m# From this stage, all operations should rely only on conv_res.output\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/docling/pipeline/base_pipeline.py\u001B[0m in \u001B[0;36m_build_document\u001B[0;34m(self, conv_res)\u001B[0m\n\u001B[1;32m    147\u001B[0m                     \u001B[0mpipeline_pages\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_apply_on_pages\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconv_res\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minit_pages\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    148\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 149\u001B[0;31m                     \u001B[0;32mfor\u001B[0m \u001B[0mp\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpipeline_pages\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# Must exhaust!\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    150\u001B[0m                         \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    151\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/docling/pipeline/base_pipeline.py\u001B[0m in \u001B[0;36m_apply_on_pages\u001B[0;34m(self, conv_res, page_batch)\u001B[0m\n\u001B[1;32m    114\u001B[0m             \u001B[0mpage_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mconv_res\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpage_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    115\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 116\u001B[0;31m         \u001B[0;32myield\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpage_batch\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    117\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    118\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_build_document\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconv_res\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mConversionResult\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mConversionResult\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/docling/models/page_assemble_model.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, conv_res, page_batch)\u001B[0m\n\u001B[1;32m     57\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconv_res\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mConversionResult\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpage_batch\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mIterable\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mPage\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     58\u001B[0m     ) -> Iterable[Page]:\n\u001B[0;32m---> 59\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mpage\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpage_batch\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     60\u001B[0m             \u001B[0;32massert\u001B[0m \u001B[0mpage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mpage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_valid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/docling/models/table_structure_model.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, conv_res, page_batch)\u001B[0m\n\u001B[1;32m     91\u001B[0m             \u001B[0;32mreturn\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     92\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 93\u001B[0;31m         \u001B[0;32mfor\u001B[0m \u001B[0mpage\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpage_batch\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     94\u001B[0m             \u001B[0;32massert\u001B[0m \u001B[0mpage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     95\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mpage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_valid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/docling/models/layout_model.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, conv_res, page_batch)\u001B[0m\n\u001B[1;32m    288\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    289\u001B[0m                     \u001B[0mclusters\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 290\u001B[0;31m                     for ix, pred_item in enumerate(\n\u001B[0m\u001B[1;32m    291\u001B[0m                         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayout_predictor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpage\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_image\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mscale\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1.0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    292\u001B[0m                     ):\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/docling_ibm_models/layoutmodel/layout_predictor.py\u001B[0m in \u001B[0;36mpredict\u001B[0;34m(self, orig_img)\u001B[0m\n\u001B[1;32m    141\u001B[0m         \u001B[0;31m# Predict\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 143\u001B[0;31m             \u001B[0mlabels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mboxes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mscores\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0morig_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    144\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    145\u001B[0m         \u001B[0;31m# Yield output\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1734\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_compiled_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[misc]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1735\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1736\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_call_impl\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1737\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1738\u001B[0m     \u001B[0;31m# torchrec tests the code consistency with the following code\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m                 \u001B[0;32mor\u001B[0m \u001B[0m_global_backward_pre_hooks\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0m_global_backward_hooks\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1746\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1747\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1748\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1749\u001B[0m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ],
   "metadata": {
    "id": "YU8Zyeug8Vmu",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 38
    },
    "outputId": "b6f6db12-5c23-4458-f221-17f6ffc526cb"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-5de7892d-16d4-4b32-acfe-bd138b3febc1\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-5de7892d-16d4-4b32-acfe-bd138b3febc1\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ]
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# pdf_processor/config.py\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "class WorkspaceConfig:\n",
    "    \"\"\"Конфигурация рабочего пространства\"\"\"\n",
    "    DIRECTORIES = {\n",
    "        'input': Path('input'),\n",
    "        'processed': Path('processed'),\n",
    "        'images': Path('processed/images')\n",
    "    }"
   ],
   "metadata": {
    "id": "_858LUl_RNBs"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# pdf_processor/workspace.py\n",
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "from .config import WorkspaceConfig  # Обратите внимание на точку перед импортом\n",
    "\n",
    "def setup_workspace() -> Dict[str, Path]:\n",
    "    \"\"\"\n",
    "    Создает структуру рабочих директорий.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Path]: Словарь с путями к рабочим директориям\n",
    "    \"\"\"\n",
    "    for dir_path in WorkspaceConfig.DIRECTORIES.values():\n",
    "        dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    return WorkspaceConfig.DIRECTORIES"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "JlZrO6ZCRO59",
    "outputId": "481da846-4fad-4ec9-ce36-03024cd716c7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-31-227b0e80b86f>\u001B[0m in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpathlib\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mPath\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mtyping\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mDict\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mWorkspaceConfig\u001B[0m  \u001B[0;31m# Обратите внимание на точку перед импортом\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0msetup_workspace\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mDict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mPath\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mImportError\u001B[0m: attempted relative import with no known parent package",
      "",
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n"
     ],
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# main.py\n",
    "from google.colab import files\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "import json\n",
    "\n",
    "from workspace import setup_workspace\n",
    "from file_handler import FileHandler\n",
    "from document_processor import DocumentProcessor\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Основной процесс обработки документов\"\"\"\n",
    "    # Создаем рабочее пространство\n",
    "    workspace = setup_workspace()\n",
    "\n",
    "    # Импортируем файлы\n",
    "    file_handler = FileHandler()\n",
    "    imported_files = file_handler.import_pdfs(workspace)\n",
    "\n",
    "    # Создаем экземпляр процессора\n",
    "    processor = DocumentProcessor()\n",
    "\n",
    "    # Обрабатываем каждый файл\n",
    "    for pdf_path in imported_files:\n",
    "        result = processor.process_document(str(pdf_path), workspace)\n",
    "\n",
    "        if result:\n",
    "            # Сохраняем результаты\n",
    "            output_path = workspace['processed'] / f\"{pdf_path.stem}_processed.json\"\n",
    "            file_handler.save_results(result, output_path)\n",
    "\n",
    "            print(f\"\\nОбработан документ: {pdf_path.name}\")\n",
    "            print(f\"Чанков: {len(result['chunks'])}\")\n",
    "            print(f\"Изображений: {len(result['images'])}\")\n",
    "\n",
    "    # Скачиваем результаты\n",
    "    print(\"\\nСкачивание результатов...\")\n",
    "    for result_file in workspace['processed'].glob('*.json'):\n",
    "        files.download(str(result_file))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "KfUMNTHGWl0B",
    "outputId": "6ed332da-0b9a-4507-fdac-9a09e0372e1d"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name 'setup_workspace' from 'workspace' (unknown location)",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-32-1267d111bbda>\u001B[0m in \u001B[0;36m<cell line: 7>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mworkspace\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0msetup_workspace\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mfile_handler\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mFileHandler\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mdocument_processor\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mDocumentProcessor\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'setup_workspace' from 'workspace' (unknown location)",
      "",
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n"
     ],
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# pdf_processor/file_handler.py\n",
    "from google.colab import files\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "import json\n",
    "\n",
    "class FileHandler:\n",
    "    \"\"\"Обработчик файловых операций\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def import_pdfs(workspace: Dict[str, Path]) -> List[Path]:\n",
    "        \"\"\"\n",
    "        Импортирует PDF файлы через интерфейс Colab.\n",
    "\n",
    "        Args:\n",
    "            workspace: Словарь с путями к рабочим директориям\n",
    "\n",
    "        Returns:\n",
    "            List[Path]: Список путей к импортированным файлам\n",
    "        \"\"\"\n",
    "        print(\"Выберите PDF файлы для загрузки...\")\n",
    "        uploaded = files.upload()\n",
    "\n",
    "        imported_files = []\n",
    "        for filename in uploaded.keys():\n",
    "            if filename.lower().endswith('.pdf'):\n",
    "                dest_path = workspace['input'] / filename\n",
    "                with open(dest_path, 'wb') as f:\n",
    "                    f.write(uploaded[filename])\n",
    "                imported_files.append(dest_path)\n",
    "                print(f'Импортирован файл: {filename}')\n",
    "\n",
    "        return imported_files\n",
    "\n",
    "    @staticmethod\n",
    "    def save_results(result: Dict, output_path: Path) -> None:\n",
    "        \"\"\"\n",
    "        Сохраняет результаты обработки в JSON файл.\n",
    "\n",
    "        Args:\n",
    "            result: Результаты обработки документа\n",
    "            output_path: Путь для сохранения результатов\n",
    "        \"\"\"\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(result, f, ensure_ascii=False, indent=2)"
   ],
   "metadata": {
    "id": "Eq0fL1ZMRRKf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# pdf_processor/document_processor.py\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional\n",
    "\n",
    "class DocumentProcessor:\n",
    "    \"\"\"Процессор документов\"\"\"\n",
    "\n",
    "    def process_document(self, pdf_path: str, workspace: Dict[str, Path]) -> Optional[Dict]:\n",
    "        \"\"\"\n",
    "        Обрабатывает PDF документ.\n",
    "\n",
    "        Args:\n",
    "            pdf_path: Путь к PDF файлу\n",
    "            workspace: Словарь с путями к рабочим директориям\n",
    "\n",
    "        Returns:\n",
    "            Optional[Dict]: Результаты обработки или None в случае ошибки\n",
    "        \"\"\"\n",
    "        # Здесь должна быть ваша логика обработки PDF\n",
    "        # Пример заглушки:\n",
    "        return {\n",
    "            'chunks': ['chunk1', 'chunk2'],\n",
    "            'images': ['image1.png', 'image2.png']\n",
    "        }"
   ],
   "metadata": {
    "id": "HMYpAKJlRTdn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# main.py\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "import json\n",
    "\n",
    "from pdf_processor.workspace import setup_workspace\n",
    "from pdf_processor.file_handler import FileHandler\n",
    "from pdf_processor.document_processor import DocumentProcessor\n",
    "\n",
    "def main():\n",
    "    \"\"\"Основной процесс обработки документов\"\"\"\n",
    "    # Создаем рабочее пространство\n",
    "    workspace = setup_workspace()\n",
    "\n",
    "    # Импортируем файлы\n",
    "    file_handler = FileHandler()\n",
    "    imported_files = file_handler.import_pdfs(workspace)\n",
    "\n",
    "    # Создаем экземпляр процессора\n",
    "    processor = DocumentProcessor()\n",
    "\n",
    "    # Обрабатываем каждый файл\n",
    "    for pdf_path in imported_files:\n",
    "        result = processor.process_document(str(pdf_path), workspace)\n",
    "\n",
    "        if result:\n",
    "            # Сохраняем результаты\n",
    "            output_path = workspace['processed'] / f\"{pdf_path.stem}_processed.json\"\n",
    "            file_handler.save_results(result, output_path)\n",
    "\n",
    "            print(f\"\\nОбработан документ: {pdf_path.name}\")\n",
    "            print(f\"Чанков: {len(result['chunks'])}\")\n",
    "            print(f\"Изображений: {len(result['images'])}\")\n",
    "\n",
    "    # Скачиваем результаты\n",
    "    print(\"\\nСкачивание результатов...\")\n",
    "    for result_file in workspace['processed'].glob('*.json'):\n",
    "        files.download(str(result_file))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "Fu7cUT16RV1t",
    "outputId": "fc3ca8e6-2109-49af-b50c-50d28c683529"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdf_processor'",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-26-929eb97a9636>\u001B[0m in \u001B[0;36m<cell line: 6>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mpdf_processor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mworkspace\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0msetup_workspace\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpdf_processor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfile_handler\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mFileHandler\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpdf_processor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdocument_processor\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mDocumentProcessor\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'pdf_processor'",
      "",
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n"
     ],
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# main.py\n",
    "from google.colab import files\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "import json\n",
    "\n",
    "def main():\n",
    "    \"\"\"Основной процесс обработки документов\"\"\"\n",
    "    # Создаем рабочее пространство\n",
    "    workspace = setup_workspace()\n",
    "\n",
    "    # Импортируем файлы\n",
    "    file_handler = FileHandler()\n",
    "    imported_files = file_handler.import_pdfs(workspace)\n",
    "\n",
    "    # Создаем экземпляр процессора\n",
    "    processor = DocumentProcessor()\n",
    "\n",
    "    # Обрабатываем каждый файл\n",
    "    for pdf_path in imported_files:\n",
    "        result = processor.process_document(str(pdf_path), workspace)\n",
    "\n",
    "        if result:\n",
    "            # Сохраняем результаты\n",
    "            output_path = workspace['processed'] / f\"{pdf_path.stem}_processed.json\"\n",
    "            file_handler.save_results(result, output_path)\n",
    "\n",
    "            print(f\"\\nОбработан документ: {pdf_path.name}\")\n",
    "            print(f\"Чанков: {len(result['chunks'])}\")\n",
    "            print(f\"Изображений: {len(result['images'])}\")\n",
    "\n",
    "    # Скачиваем результаты\n",
    "    print(\"\\nСкачивание результатов...\")\n",
    "    for result_file in workspace['processed'].glob('*.json'):\n",
    "        files.download(str(result_file))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "id": "a-RYLMZEXGBa",
    "outputId": "7359a880-7866-4009-d931-5754a8e8db25"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Выберите PDF файлы для загрузки...\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-7f19cb08-291c-487a-a6d8-2319021cba26\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-7f19cb08-291c-487a-a6d8-2319021cba26\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving Godovoi_-otchet-PAO-GMK-Norilskii_-nikel-za-2023-god.pdf to Godovoi_-otchet-PAO-GMK-Norilskii_-nikel-za-2023-god (4).pdf\n",
      "Импортирован файл: Godovoi_-otchet-PAO-GMK-Norilskii_-nikel-za-2023-god (4).pdf\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "DocumentProcessor.process_document() takes 2 positional arguments but 3 were given",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-34-c92c42095446>\u001B[0m in \u001B[0;36m<cell line: 37>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0m__name__\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"__main__\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 38\u001B[0;31m     \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-34-c92c42095446>\u001B[0m in \u001B[0;36mmain\u001B[0;34m()\u001B[0m\n\u001B[1;32m     19\u001B[0m     \u001B[0;31m# Обрабатываем каждый файл\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mpdf_path\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mimported_files\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 21\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprocessor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mprocess_document\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpdf_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mworkspace\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     22\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     23\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: DocumentProcessor.process_document() takes 2 positional arguments but 3 were given"
     ]
    }
   ]
  }
 ]
}
