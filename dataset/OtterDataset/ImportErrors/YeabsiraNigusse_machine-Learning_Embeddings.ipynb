{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe076e32",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f2b19",
   "metadata": {},
   "source": [
    "Embeddings are numerical representation of text that computers process easlly. to understand how they work think like a grid that contains a lot of words so the location of words can be found using their grid(x,y) location if we say it is 2D. but in real life they represented with large numbers like thousend of numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398584b2",
   "metadata": {},
   "source": [
    "### Setup\n",
    "Load needed API keys and relevant Python libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bed955b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cohere in c:\\users\\nigus\\anaconda3\\lib\\site-packages (4.21)\n",
      "Requirement already satisfied: umap-learn in c:\\users\\nigus\\anaconda3\\lib\\site-packages (0.5.3)\n",
      "Requirement already satisfied: altair in c:\\users\\nigus\\anaconda3\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: datasets in c:\\users\\nigus\\anaconda3\\lib\\site-packages (2.14.4)\n",
      "Requirement already satisfied: backoff<3.0,>=2.0 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from cohere) (2.2.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from cohere) (1.26.9)\n",
      "Requirement already satisfied: aiohttp<4.0,>=3.0 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from cohere) (3.8.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.25.0 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from cohere) (2.31.0)\n",
      "Requirement already satisfied: fastavro==1.8.2 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from cohere) (1.8.2)\n",
      "Requirement already satisfied: importlib_metadata<7.0,>=6.0 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from cohere) (6.8.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from umap-learn) (1.0.2)\n",
      "Requirement already satisfied: numba>=0.49 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from umap-learn) (0.55.1)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from umap-learn) (1.7.3)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from umap-learn) (0.5.10)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from umap-learn) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from umap-learn) (1.21.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from altair) (2.11.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from altair) (0.11.2)\n",
      "Requirement already satisfied: pandas>=0.18 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from altair) (1.4.2)\n",
      "Requirement already satisfied: typing-extensions>=4.0.1 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from altair) (4.1.1)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from altair) (4.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from datasets) (2022.2.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from datasets) (3.3.0)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: packaging in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere) (21.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere) (1.6.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from aiohttp<4.0,>=3.0->cohere) (5.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.7.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from jsonschema>=3.0->altair) (0.18.0)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from numba>=0.49->umap-learn) (0.38.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from numba>=0.49->umap-learn) (61.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from packaging->datasets) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from pandas>=0.18->altair) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from pandas>=0.18->altair) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from pynndescent>=0.5->umap-learn) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=0.18->altair) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.25.0->cohere) (2021.10.8)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->umap-learn) (2.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from tqdm->umap-learn) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\nigus\\anaconda3\\lib\\site-packages (from jinja2->altair) (2.0.1)\n",
      "Requirement already satisfied: utils in c:\\users\\nigus\\anaconda3\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    " !pip install cohere umap-learn altair datasets\n",
    " !pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dcb6496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "co = cohere.Client('N5X7udH3zHT2FY6dsCZT2hypAGMVXrBj4RCi5Grw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26a296f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # used for table data representation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b780b4",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "\n",
    "Consider a very small dataset of three words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a4fd89a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happiness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>potato</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text\n",
       "0        joy\n",
       "1  happiness\n",
       "2     potato"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "three_words = pd.DataFrame({'text':\n",
    "  [\n",
    "      'joy',\n",
    "      'happiness',\n",
    "      'potato'\n",
    "  ]})\n",
    "\n",
    "three_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11dc02d",
   "metadata": {},
   "source": [
    "Let's create the embeddings for the three words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30fbf2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_words_emb = co.embed(texts=list(three_words['text']), # function from cohere used to embade words\n",
    "                           model='embed-english-v2.0').embeddings # it takes the data we want to \n",
    "                                                                  # embadde and the name of model we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b74ea269",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_1 = three_words_emb[0]\n",
    "word_2 = three_words_emb[1]\n",
    "word_3 = three_words_emb[2]\n",
    "#word_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f81fe5b",
   "metadata": {},
   "source": [
    "## Sentence Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e79875",
   "metadata": {},
   "source": [
    "Consider a very small dataset of three sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77245330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Where is the world cup?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The world cup is in Qatar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What color is the sky?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The sky is blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Where does the bear live?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The bear lives in the the woods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is an apple?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>An apple is a fruit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text\n",
       "0          Where is the world cup?\n",
       "1        The world cup is in Qatar\n",
       "2           What color is the sky?\n",
       "3                  The sky is blue\n",
       "4        Where does the bear live?\n",
       "5  The bear lives in the the woods\n",
       "6                What is an apple?\n",
       "7              An apple is a fruit"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = pd.DataFrame({'text':\n",
    "  [\n",
    "   'Where is the world cup?',\n",
    "   'The world cup is in Qatar',\n",
    "   'What color is the sky?',\n",
    "   'The sky is blue',\n",
    "   'Where does the bear live?',\n",
    "   'The bear lives in the the woods',\n",
    "   'What is an apple?',\n",
    "   'An apple is a fruit',\n",
    "  ]})\n",
    "\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa571b",
   "metadata": {},
   "source": [
    "Let's create the embeddings for the three sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "369292c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27319336, -0.37768555, -1.0273438]\n",
      "[0.49804688, 1.2236328, 0.4074707]\n",
      "[-0.23571777, -0.9375, 0.9614258]\n",
      "[0.08300781, -0.32080078, 0.9272461]\n",
      "[0.49780273, -0.35058594, -1.6171875]\n",
      "[1.2294922, -1.3779297, -1.8378906]\n",
      "[0.15686035, -0.92041016, 1.5996094]\n",
      "[1.0761719, -0.7211914, 0.9296875]\n"
     ]
    }
   ],
   "source": [
    "emb = co.embed(texts=list(sentences['text']),\n",
    "               model='embed-english-v2.0').embeddings\n",
    "\n",
    "# Explore the 10 first entries of the embeddings of the 3 sentences:\n",
    "for e in emb:\n",
    "    print(e[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ac20ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(emb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f7125914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "688a594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import umap_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "48d7a466",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chart \u001b[38;5;241m=\u001b[39m \u001b[43mumap_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "#chart = umap_plot(sentences, emb) # getting an error while using umap_plot function fro utils package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1e519be5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chart' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mchart\u001b[49m\u001b[38;5;241m.\u001b[39minteractive()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chart' is not defined"
     ]
    }
   ],
   "source": [
    "#chart.interactive() # this function outputs the sentences that are closelly related and visualize it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f354c62",
   "metadata": {},
   "source": [
    "## Articles Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b90f8d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'wikipedia.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m wiki_articles \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwikipedia.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m wiki_articles\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\pickle.py:187\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m    186\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    194\u001b[0m \n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py:798\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    790\u001b[0m             handle,\n\u001b[0;32m    791\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    794\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    795\u001b[0m         )\n\u001b[0;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    799\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    801\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'wikipedia.pkl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "wiki_articles = pd.read_pickle('wikipedia.pkl')\n",
    "wiki_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efa3696e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'umap_plot_big' from 'utils' (C:\\Users\\nigus\\anaconda3\\lib\\site-packages\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m umap_plot_big\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'umap_plot_big' from 'utils' (C:\\Users\\nigus\\anaconda3\\lib\\site-packages\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from utils import umap_plot_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "893f2209",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wiki_articles' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m articles \u001b[38;5;241m=\u001b[39m \u001b[43mwiki_articles\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[0;32m      2\u001b[0m embeds \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m wiki_articles[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memb\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n\u001b[0;32m      4\u001b[0m chart \u001b[38;5;241m=\u001b[39m umap_plot_big(articles, embeds)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wiki_articles' is not defined"
     ]
    }
   ],
   "source": [
    "articles = wiki_articles[['title', 'text']]\n",
    "embeds = np.array([d for d in wiki_articles['emb']])\n",
    "\n",
    "chart = umap_plot_big(articles, embeds)\n",
    "chart.interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fa9dd1",
   "metadata": {},
   "source": [
    " if they work the above visuilization tells us based on the closness of the sentences and aricles we can query from our data and get the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f63c0574",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
