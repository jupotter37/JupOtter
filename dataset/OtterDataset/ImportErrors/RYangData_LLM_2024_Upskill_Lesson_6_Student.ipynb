{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "911b3b37-3b29-4833-94f2-bfe47af00c83",
   "metadata": {},
   "source": [
    "# Lesson 6: Essay Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5762271-8736-4e94-9444-8c92bd0e8074",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0168aee-bce9-4d60-b827-f86a88187e31",
   "metadata": {
    "height": 157
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated, List\n",
    "import operator\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, AIMessage, ChatMessage\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2589c5b6-6cc2-4594-9a17-dccdcf676054",
   "metadata": {
    "height": 149
   },
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    task: str\n",
    "    plan: str\n",
    "    draft: str\n",
    "    critique: str\n",
    "    content: List[str]\n",
    "    revision_number: int\n",
    "    max_revisions: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2ba84ec-c172-4de7-ac55-e3158a531b23",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "876d5092-b8ef-4e38-b4d7-0e80c609bf7a",
   "metadata": {
    "height": 89
   },
   "outputs": [],
   "source": [
    "PLAN_PROMPT = \"\"\"You are an expert writer tasked with writing a high level outline of an essay. \\\n",
    "Write such an outline for the user provided topic. Give an outline of the essay along with any relevant notes \\\n",
    "or instructions for the sections.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10084a02-2928-4945-9f7c-ad3f5b33caf7",
   "metadata": {
    "height": 174
   },
   "outputs": [],
   "source": [
    "WRITER_PROMPT = \"\"\"You are an essay assistant tasked with writing excellent 5-paragraph essays.\\\n",
    "Generate the best essay possible for the user's request and the initial outline. \\\n",
    "If the user provides critique, respond with a revised version of your previous attempts. \\\n",
    "Utilize all the information below as needed: \n",
    "\n",
    "------\n",
    "\n",
    "{content}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "714d1205-f8fc-4912-b148-2a45da99219c",
   "metadata": {
    "height": 89
   },
   "outputs": [],
   "source": [
    "REFLECTION_PROMPT = \"\"\"You are a teacher grading an essay submission. \\\n",
    "Generate critique and recommendations for the user's submission. \\\n",
    "Provide detailed recommendations, including requests for length, depth, style, etc.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83588e70-254f-4f83-a510-c8ae81e729b0",
   "metadata": {
    "height": 106
   },
   "outputs": [],
   "source": [
    "RESEARCH_PLAN_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when writing the following essay. Generate a list of search queries that will gather \\\n",
    "any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cb3ef4c-58b3-401b-b104-0d51e553d982",
   "metadata": {
    "height": 106
   },
   "outputs": [],
   "source": [
    "RESEARCH_CRITIQUE_PROMPT = \"\"\"You are a researcher charged with providing information that can \\\n",
    "be used when making any requested revisions (as outlined below). \\\n",
    "Generate a list of search queries that will gather any relevant information. Only generate 3 queries max.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc3293b7-a50c-43c8-a022-8975e1e444b8",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel\n",
    "\n",
    "class Queries(BaseModel):\n",
    "    queries: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0722c3d4-4cbf-43bf-81b0-50f634c4ce61",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "import os\n",
    "tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b2f82fe-3ec4-4917-be51-9fb10d1317fa",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "def plan_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=PLAN_PROMPT), \n",
    "        HumanMessage(content=state['task'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"plan\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee0fe1c7-77e2-499c-a2f9-1f739bb6ddf0",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "def research_plan_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_PLAN_PROMPT),\n",
    "        HumanMessage(content=state['task'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98f303b1-a4d0-408c-8cc0-515ff980717f",
   "metadata": {
    "height": 310
   },
   "outputs": [],
   "source": [
    "def generation_node(state: AgentState):\n",
    "    content = \"\\n\\n\".join(state['content'] or [])\n",
    "    user_message = HumanMessage(\n",
    "        content=f\"{state['task']}\\n\\nHere is my plan:\\n\\n{state['plan']}\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=WRITER_PROMPT.format(content=content)\n",
    "        ),\n",
    "        user_message\n",
    "        ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\n",
    "        \"draft\": response.content, \n",
    "        \"revision_number\": state.get(\"revision_number\", 1) + 1\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf4dcb93-6298-4cfd-b3ce-61dfac7fb35f",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "def reflection_node(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(content=REFLECTION_PROMPT), \n",
    "        HumanMessage(content=state['draft'])\n",
    "    ]\n",
    "    response = model.invoke(messages)\n",
    "    return {\"critique\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "932883a4-c722-42bb-aec0-b4f41c5c81a4",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "def research_critique_node(state: AgentState):\n",
    "    queries = model.with_structured_output(Queries).invoke([\n",
    "        SystemMessage(content=RESEARCH_CRITIQUE_PROMPT),\n",
    "        HumanMessage(content=state['critique'])\n",
    "    ])\n",
    "    content = state['content'] or []\n",
    "    for q in queries.queries:\n",
    "        response = tavily.search(query=q, max_results=2)\n",
    "        for r in response['results']:\n",
    "            content.append(r['content'])\n",
    "    return {\"content\": content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff362f49-dcf1-4ea1-a86c-e516e9ab897d",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "def should_continue(state):\n",
    "    if state[\"revision_number\"] > state[\"max_revisions\"]:\n",
    "        return END\n",
    "    return \"reflect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7e15a20-83d7-434c-8551-bce8dcc32be0",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "builder = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "54ab2c74-f32e-490c-a85d-932d11444210",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "builder.add_node(\"planner\", plan_node)\n",
    "builder.add_node(\"generate\", generation_node)\n",
    "builder.add_node(\"reflect\", reflection_node)\n",
    "builder.add_node(\"research_plan\", research_plan_node)\n",
    "builder.add_node(\"research_critique\", research_critique_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a833d3ce-bd31-4319-811d-decff226b970",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "builder.set_entry_point(\"planner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76e93cce-6eab-4c7c-ac64-e9993fdb30d6",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "builder.add_conditional_edges(\n",
    "    \"generate\", \n",
    "    should_continue, \n",
    "    {END: END, \"reflect\": \"reflect\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd2d0990-a932-423f-9ff3-5cada58c5f32",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "builder.add_edge(\"planner\", \"research_plan\")\n",
    "builder.add_edge(\"research_plan\", \"generate\")\n",
    "\n",
    "builder.add_edge(\"reflect\", \"research_critique\")\n",
    "builder.add_edge(\"research_critique\", \"generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27cde654-64e2-48bc-80a9-0ed668ccb7dc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4871f644-b131-4065-b7ce-b82c20a41f11",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Install pygraphviz to draw graphs: `pip install pygraphviz`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain_core/runnables/graph_png.py:136\u001b[0m, in \u001b[0;36mPngDrawer.draw\u001b[0;34m(self, graph, output_path)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygraphviz\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpgv\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pygraphviz'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 3\u001b[0m Image(\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_png\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain_core/runnables/graph.py:401\u001b[0m, in \u001b[0;36mGraph.draw_png\u001b[0;34m(self, output_file_path, fontname, labels)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_png\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PngDrawer\n\u001b[1;32m    388\u001b[0m default_node_labels \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    389\u001b[0m     node\u001b[38;5;241m.\u001b[39mid: node_data_str(node) \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    390\u001b[0m }\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPngDrawer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfontname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mLabelsDict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdefault_node_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnodes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43medges\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43medges\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m--> 401\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_file_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/langchain_core/runnables/graph_png.py:138\u001b[0m, in \u001b[0;36mPngDrawer.draw\u001b[0;34m(self, graph, output_path)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpygraphviz\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpgv\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m--> 138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    139\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstall pygraphviz to draw graphs: `pip install pygraphviz`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    140\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Create a directed graph\u001b[39;00m\n\u001b[1;32m    143\u001b[0m viz \u001b[38;5;241m=\u001b[39m pgv\u001b[38;5;241m.\u001b[39mAGraph(directed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, nodesep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, ranksep\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: Install pygraphviz to draw graphs: `pip install pygraphviz`."
     ]
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "Image(graph.get_graph().draw_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98f3be1d-cc4c-41fa-9863-3e386e88e305",
   "metadata": {
    "height": 157
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'planner': {'plan': 'I. Introduction\\n    A. Brief overview of Langchain and Langsmith\\n    B. Thesis statement: Exploring the differences between Langchain and Langsmith\\n\\nII. Langchain\\n    A. Definition and explanation\\n    B. Key features and characteristics\\n    C. Use cases and applications\\n    D. Advantages and disadvantages\\n\\nIII. Langsmith\\n    A. Definition and explanation\\n    B. Key features and characteristics\\n    C. Use cases and applications\\n    D. Advantages and disadvantages\\n\\nIV. Comparison between Langchain and Langsmith\\n    A. Technology stack\\n    B. Scalability\\n    C. Security\\n    D. Interoperability\\n    E. Performance\\n\\nV. Conclusion\\n    A. Recap of main differences between Langchain and Langsmith\\n    B. Future outlook and potential developments in the field\\n\\nNotes:\\n- Ensure to provide clear definitions and explanations of both Langchain and Langsmith.\\n- Include specific examples of how each technology is used and its benefits.\\n- Use comparative analysis to highlight the distinctions between Langchain and Langsmith.\\n- Conclude with insights on the significance of these technologies and their impact on the industry.'}}\n",
      "{'research_plan': {'content': ['Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses 👑 to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you’re trying to figure out which tool fits your needs or you’re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here’s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou’re not limited to Python, though.', \"LangSmith Cookbook: Real-world Lang Smith Examples\\nThe LangSmith Cookbook is not just a compilation of code snippets; it's a goldmine of hands-on examples designed to inspire and assist you in your projects. On This Page\\nLangSmith: Best Way to Test LLMs and AI Application\\nPublished on 12/17/2023\\nIf you're in the world of Language Learning Models (LLMs), you've probably heard of LangSmith. How to Download Feedback and Examples (opens in a new tab): Export predictions, evaluation results, and other information to add to your reports programmatically.\\n This article is your one-stop guide to understanding LangSmith, a platform that offers a plethora of features for debugging, testing, evaluating, and monitoring LLM applications.\\n How do I get access to LangSmith?\\nTo get access to LangSmith, you'll need to sign up for an account on their website.\", 'Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses 👑 to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you’re trying to figure out which tool fits your needs or you’re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here’s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou’re not limited to Python, though.', \"This was such an important unlock for us as we build in tactical functionality to our AI.\\nAdvice for Product Teams Considering LangSmith\\nWhen you're in the thick of product development, the whirlwind of AI and LLMs can be overwhelming. ou can now clearly see the citations coming through with the responses in the traces, and we’re good to ship the changes to the prompt to prod.\\n We do this primarily to legitimize the LLMs response and give our HelpHub customer’s peace of mind that their end users are in fact getting to the help resource they need (instead of an LLM just hallucinating and giving any response it wants.)\\n Take it from us, as we integrated AI more heavily and widely across our products, we’ve been more conscious than ever that the quality of the outputs matches the quality and trust that our customers have in our product. We updated our prompt to be more firm when asking for the sources:\\nWe then tested everything using LangSmith evals, to make sure that it fixes the issue before pushing to production.\\n\", 'Compare in LangSmith. Navigate to the \"Retrieval QA Questions\" dataset in LangSmith, select the two tests you just completed, then click \"Compare.\" From this view, you can manually review and compare the results. You can even filter by initial scores to select outputs where the grades differ.', 'Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses 👑 to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you’re trying to figure out which tool fits your needs or you’re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here’s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou’re not limited to Python, though.']}}\n",
      "{'generate': {'draft': \"**Title: Langchain vs Langsmith: Contrasting Two AI Language Model Frameworks**\\n\\nI. Introduction\\nIn the realm of AI language model frameworks, Langchain and Langsmith stand out as prominent tools for developers. Langchain is an open-source framework designed to facilitate the creation of applications using large language models like GPT-3. On the other hand, Langsmith offers a platform with a myriad of features for testing, debugging, and evaluating language learning models (LLMs). This essay aims to delve into the disparities between Langchain and Langsmith.\\n\\nII. Langchain\\nLangchain is a versatile framework that empowers developers to harness the capabilities of large language models such as GPT-3. Its key features include seamless integration with Python, support for various programming languages, and a robust community for support and collaboration. Developers utilize Langchain for a wide range of applications, including chatbots, content generation, and automated customer service. While Langchain offers flexibility and ease of use, some drawbacks include potential scalability issues and limited security features.\\n\\nIII. Langsmith\\nIn contrast, Langsmith is a platform tailored for testing, debugging, and monitoring language learning models. It provides users with tools to evaluate model performance, export predictions, and streamline the development process. Langsmith is instrumental in ensuring the quality and reliability of AI applications by offering comprehensive testing capabilities. However, its focus on testing and evaluation may limit its applicability for broader development purposes compared to Langchain.\\n\\nIV. Comparison between Langchain and Langsmith\\nA. Technology Stack: Langchain emphasizes versatility and compatibility with multiple programming languages, while Langsmith prioritizes tools for testing and evaluation.\\nB. Scalability: Langchain may face scalability challenges due to its open-source nature, whereas Langsmith's focus on testing enhances scalability in terms of model performance.\\nC. Security: Langchain may have security vulnerabilities due to its open nature, while Langsmith's testing tools contribute to ensuring the security and reliability of AI applications.\\nD. Interoperability: Langchain offers broader interoperability with various systems and applications, while Langsmith's interoperability may be more limited to testing environments.\\nE. Performance: Langchain excels in application development and flexibility, while Langsmith shines in evaluating and enhancing the performance of language learning models.\\n\\nV. Conclusion\\nIn conclusion, the comparison between Langchain and Langsmith reveals distinct strengths and weaknesses in their respective focuses. While Langchain caters to developers seeking flexibility and ease of application development, Langsmith targets users in need of robust testing and evaluation tools for language learning models. Understanding these differences is crucial for developers to choose the most suitable framework based on their specific requirements. As the AI industry continues to evolve, both Langchain and Langsmith are poised to play integral roles in shaping the future of AI applications.\", 'revision_number': 2}}\n",
      "{'reflect': {'critique': 'Overall, your essay provides a clear and structured comparison between Langchain and Langsmith, highlighting their key features and differences effectively. Here are some suggestions to enhance your submission:\\n\\n1. **Depth and Analysis**: While you have outlined the key features of both frameworks, consider delving deeper into specific examples or case studies where each framework has excelled or faced challenges. Providing real-world scenarios can help illustrate the practical implications of using Langchain and Langsmith.\\n\\n2. **Critical Analysis**: It would be beneficial to include a more critical analysis of the drawbacks and limitations of each framework. For instance, you briefly mentioned scalability issues with Langchain and security vulnerabilities, but expanding on these points with examples or potential solutions would add depth to your comparison.\\n\\n3. **Recommendations**: Consider offering recommendations for developers based on the strengths and weaknesses of Langchain and Langsmith. Providing guidance on when to choose one framework over the other based on specific project requirements can be valuable for readers.\\n\\n4. **Additional Information**: You could include information on the user base or adoption rates of Langchain and Langsmith, as well as any recent updates or developments in each framework. This would demonstrate your awareness of the current trends in AI language model frameworks.\\n\\n5. **Conclusion**: While your conclusion summarizes the key points effectively, consider adding a forward-looking statement on the future prospects of Langchain and Langsmith. How do you see these frameworks evolving in response to emerging technologies or industry demands?\\n\\n6. **Length**: Your essay is concise and to the point, which is good for clarity. However, expanding on certain sections with more detailed explanations or examples could provide a more comprehensive analysis.\\n\\nOverall, your essay is well-structured and informative. By incorporating the above suggestions, you can further enhance the depth and analysis of your comparison between Langchain and Langsmith. Keep up the good work!'}}\n",
      "{'research_critique': {'content': ['Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses 👑 to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you’re trying to figure out which tool fits your needs or you’re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here’s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou’re not limited to Python, though.', \"LangSmith Cookbook: Real-world Lang Smith Examples\\nThe LangSmith Cookbook is not just a compilation of code snippets; it's a goldmine of hands-on examples designed to inspire and assist you in your projects. On This Page\\nLangSmith: Best Way to Test LLMs and AI Application\\nPublished on 12/17/2023\\nIf you're in the world of Language Learning Models (LLMs), you've probably heard of LangSmith. How to Download Feedback and Examples (opens in a new tab): Export predictions, evaluation results, and other information to add to your reports programmatically.\\n This article is your one-stop guide to understanding LangSmith, a platform that offers a plethora of features for debugging, testing, evaluating, and monitoring LLM applications.\\n How do I get access to LangSmith?\\nTo get access to LangSmith, you'll need to sign up for an account on their website.\", 'Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses 👑 to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you’re trying to figure out which tool fits your needs or you’re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here’s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou’re not limited to Python, though.', \"This was such an important unlock for us as we build in tactical functionality to our AI.\\nAdvice for Product Teams Considering LangSmith\\nWhen you're in the thick of product development, the whirlwind of AI and LLMs can be overwhelming. ou can now clearly see the citations coming through with the responses in the traces, and we’re good to ship the changes to the prompt to prod.\\n We do this primarily to legitimize the LLMs response and give our HelpHub customer’s peace of mind that their end users are in fact getting to the help resource they need (instead of an LLM just hallucinating and giving any response it wants.)\\n Take it from us, as we integrated AI more heavily and widely across our products, we’ve been more conscious than ever that the quality of the outputs matches the quality and trust that our customers have in our product. We updated our prompt to be more firm when asking for the sources:\\nWe then tested everything using LangSmith evals, to make sure that it fixes the issue before pushing to production.\\n\", 'Compare in LangSmith. Navigate to the \"Retrieval QA Questions\" dataset in LangSmith, select the two tests you just completed, then click \"Compare.\" From this view, you can manually review and compare the results. You can even filter by initial scores to select outputs where the grades differ.', 'Langchain vs Langsmith: Unpacking the AI Language Model Showdown\\nOverview of Langchain and Langsmith\\nLangchain is a versatile open-source framework that enables you to build applications utilizing large language models (LLM) like GPT-3. Check out our free WhatsApp channel to stay educated on LLM developments:\\nJoin the Finxter Academy and unlock access to premium courses 👑 to certify your skills in exponential technologies and programming.\\n Frequently Asked Questions\\nWhether you’re trying to figure out which tool fits your needs or you’re just getting started with language model automation, these FAQs will help shed light on the common curiosities about Langchain and LangSmith.\\n The best way to find out is to reach out to them through the LangSmith Walkthrough page or to inquire about access directly through their support channels.\\n Here’s how you might start a simple Langchain project in Python:\\nTo integrate LangSmith, you could write something like this:\\nYou’re not limited to Python, though.', \"Rakuten Group builds with LangChain and LangSmith to deliver premium products for its business clients\\nLangChain Partners with CommandBar on their Copilot User Assistant\\nLangChain partners with Elastic to launch the Elastic AI Assistant\\nAlly Financial Collaborates with LangChain to Deliver Coding Module to Mask PII\\nLLMs accelerate Adyen's support team through\\nsmart-ticket routing and support agent copilot\\nMorningstar Intelligence Engine puts personalized investment insights at analysts' fingertips\\nRobocorp’s code generation assistant makes building Python automation easy for developers\\nLangChain Expands Collaboration with Microsoft\\nHear from our happy customers\\nLangSmith helps teams of all sizes, across all industries, from ambitious\\nstartups to established enterprises.\\n We could have built evaluation, testing and monitoring tools in house, but with LangSmith it took us 10x less time to get a 1000x better tool.”\\nReady to start shipping\\nreliable GenAI apps faster?\\nLangChain and LangSmith are critical parts of the reference\\narchitecture to get you from prototype to production. We couldn’t have achieved \\xa0the product experience delivered to our customers without LangChain, and we couldn’t have done it at the same pace without LangSmith.”\\n“As soon as we heard about LangSmith, we moved our entire development stack onto it. We couldn’t have achieved \\xa0the product experience delivered to our customers without LangChain, and we couldn’t have done it at the same pace without LangSmith.”\\n“As soon as we heard about LangSmith, we moved our entire development stack onto it. We could have built evaluation, testing and monitoring tools in house, but with LangSmith it took us 10x less time to get a 1000x better tool.”\\n“LangSmith helped us improve the accuracy and performance of Retool’s fine-tuned models.\", 'In 2023, LangChain seemed ideal. It offered impressive components and tools and was gaining popularity. LangChain promised \"to turn an idea into working code in an afternoon,\" but as our needs grew complex, problems emerged. LangChain became a hindrance rather than a productivity booster.', 'Based on my understanding, you were facing issues with security scans due to vulnerabilities in the Langchain application. Another user named \"dosu-beta\" has provided some suggestions for possible solutions, such as disabling the execution of arbitrary Python code from prompts and implementing a strict whitelist or validation mechanism for ...', \"SQL Injection: CVE-2023-36189. The CVE-2023-36189 vulnerability impacts versions of LangChain up to 0.0.64 and was disclosed on July 6, 2023. It exposes a weakness in the SQLDatabaseChain feature, allowing for SQL injection attacks that can execute arbitrary code via Python's exec method.. Before delving into this vulnerability, it's essential to grasp the functionality of SQLDatabaseChain.\", \"Logging a trace and feedback score from ChatLangChain, viewing the results in LangSmith\\nAnnotating Traces\\nLangSmith also supports sending runs to annotation queues, which allow annotators to closely inspect interesting traces and annotate them with respect to different criteria. Sending a trace to an Annotation Queue\\nAdding Runs to a Dataset\\nAs your application progresses through the beta testing phase, it's essential to continue collecting data to refine and improve its performance. Adding the inputs/outputs of a run as an example to a dataset\\nProduction\\nClosely inspecting key data points, growing benchmarking datasets, annotating traces, and drilling down into important data in trace view are workflows you’ll also want to do once your app hits production. Announcing the General Availability of LangSmith and Our Series A Led By Sequoia Capital\\nToday, we’re thrilled to announce the general availability of LangSmith — our solution for LLM application development, monitoring, and testing. Inspecting test cases and test runs\\nComparison View\\nWhen prototyping different versions of your applications and making changes, it’s important to see whether or not you’ve regressed with respect to your initial test cases.\", 'Once a prototype is ready, LangSmith’s integrated platform facilitates deployment via hosted LangServe, offering detailed insights into production dynamics, from cost and latency to anomalies and errors, thereby ensuring the delivery of high-quality, cost-efficient LLM applications.\\n Required fields are marked *\\nComment\\nName *\\nEmail *\\nWebsite\\nHave an awesome business idea?\\nTell us more about it.\\n LangSmith serves as a comprehensive platform, empowering developers to expedite the lifecycle of LLM projects, encompassing everything from initial development and testing phases to final deployment and ongoing monitoring. Initially launched in a limited beta in July of the previous year, LangSmith has rapidly become a critical tool for numerous enterprises, witnessing widespread adoption on a monthly basis, the company reports.\\n LangChain stands alongside other platforms like TruEra’s TruLens, W&B Prompts, and Arize’s Pheonix, which also contribute to the evaluation and monitoring of LLM applications.\\n']}}\n",
      "{'generate': {'draft': '**Title: Langchain vs Langsmith: Contrasting Two AI Language Model Frameworks**\\n\\nI. Introduction\\nIn the realm of AI language model frameworks, Langchain and Langsmith have emerged as prominent players, each offering unique features and capabilities. This essay delves into a comparative analysis of Langchain and Langsmith to elucidate their differences and applications.\\n\\nII. Langchain\\nLangchain is an open-source framework designed to facilitate the development of applications utilizing large language models like GPT-3. It provides a versatile platform for building AI-driven solutions. Key features include flexibility in programming languages, scalability, and a supportive community. Langchain finds applications in various fields such as natural language processing, chatbots, and automated content generation. While it offers extensive customization options, potential drawbacks may include a steeper learning curve for beginners.\\n\\nIII. Langsmith\\nOn the other hand, Langsmith is a comprehensive platform tailored for debugging, testing, evaluating, and monitoring language learning models (LLMs) applications. It offers a plethora of features to enhance the development lifecycle of AI projects. Langsmith is particularly useful for quality assurance and performance optimization in AI applications. Its advantages lie in its robust testing capabilities and user-friendly interface. However, users may encounter limitations in terms of customization compared to Langchain.\\n\\nIV. Comparison between Langchain and Langsmith\\nA. Technology Stack: Langchain emphasizes flexibility in programming languages, while Langsmith focuses on testing and monitoring tools.\\nB. Scalability: Langchain offers scalability for building diverse applications, whereas Langsmith prioritizes performance optimization and debugging.\\nC. Security: Langchain may face security vulnerabilities like SQL injection, while Langsmith provides tools for secure and reliable AI application development.\\nD. Interoperability: Langchain supports integration with various systems, whereas Langsmith focuses on enhancing the functionality of LLM applications.\\nE. Performance: Langchain enables rapid prototyping and development, while Langsmith ensures the accuracy and efficiency of AI models through rigorous testing.\\n\\nV. Conclusion\\nIn conclusion, Langchain and Langsmith cater to distinct needs in the AI development landscape. While Langchain excels in flexibility and customization, Langsmith shines in testing and monitoring capabilities. Understanding the nuances between these frameworks is crucial for developers and organizations to choose the most suitable platform for their AI projects. As the AI industry continues to evolve, advancements in frameworks like Langchain and Langsmith will play a pivotal role in shaping the future of AI applications.', 'revision_number': 3}}\n"
     ]
    }
   ],
   "source": [
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for s in graph.stream({\n",
    "    'task': \"what is the difference between langchain and langsmith\",\n",
    "    \"max_revisions\": 2,\n",
    "    \"revision_number\": 1,\n",
    "}, thread):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad8a6cc-65d4-4ce7-87aa-4e67d7c23d7b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d1664b5-75e0-46b7-9c2b-4ac9171f4597",
   "metadata": {},
   "source": [
    "## Essay Writer Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e0ae270-3ec3-484a-b729-df7d2b7b0f76",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from helper import ewriter, writer_gui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0ebfa79-c7fc-4aaa-b668-64e5b6cede80",
   "metadata": {
    "height": 64
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MultiAgent = ewriter()\n",
    "app = writer_gui(MultiAgent.graph)\n",
    "app.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592b5e62-a203-433c-92a0-3783f490cde1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fa923c-7e4f-42d1-965f-0f8ccd50fbd7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c6245-2837-4ac5-983b-95f61f3ac10d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b910915-b087-4d35-afff-0ec30a5852f1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4feb6cc-5129-4a99-bb45-851bc07b5709",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a02b4-96cc-4b01-8792-397a774eb499",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8b86a6-5e20-4252-b1d8-009b8318345a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af925917-b746-48c9-ac74-62fefbe5246c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5048f2c-4d82-49a5-9cb1-918d78b39f7b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393f7f1f-68b4-4462-bfa5-b6472ef1304a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac0aa9-baa7-4b58-889d-2118cc00c6b5",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6098b9-e2a9-4767-8cb5-346db835c8d2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d23cf2a-a179-44dc-9ae3-2eddda4b67b4",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6005b-0221-4f5e-9be0-0580c1d03126",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1ec12-f1c8-41ae-bb3e-5f28997b9b99",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8c07d7-be17-4c17-82c5-6fe1db028b8b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04592c8e-1cfe-4b26-93b5-caf1ed1e7d24",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6181c4a9-0e71-4f67-b71f-18a225e37202",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c478a9-7bfe-49e2-8a7d-1536271f45a6",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6d6771-3fad-4f37-9b32-45b36ad85c59",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3629eb3-655d-467a-b413-63f547c2de08",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f772f251-2b61-4d10-97c5-61cef9207a76",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de92979-7ac5-4a7c-91c1-10806b7d529c",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c4325-f625-4bbf-9d74-cc58f10763f2",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4070be7-72da-42f9-a25d-8a6c628788b8",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9289efbe-7033-4f32-8482-2039c5f9db90",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e480bb-22ab-4acb-a42c-71da3d04a5b1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dea35c-7483-4b3d-b5e3-76eb3a0fe536",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ac5730-a9d5-4ea4-8546-ebcb265cf1da",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e1f28b-46d8-4bcd-b2e4-730376ee7ccf",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ac7020-b4f4-4bd2-a875-ccee93f83d83",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f79eb9-d1c9-44b0-9efd-a8f9b380332a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce509206-bde1-43e4-a88f-8a565539d357",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdba1590-9e7b-4c0f-9492-81a07d286c55",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8fe4a8-5372-479d-b248-af7a295c86c1",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7514720a-14bc-4552-ade5-fa03f86f4c73",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
