{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "lab_transfer_learing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a3d0d8b411f4ac9ab2c34a3f8867c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32c585eb9ecd44669cba507079fe9857",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9f03941f6b2c443fb6e7f52e1e7ca58d",
              "IPY_MODEL_56910d5b91e5459c996e35c51590b971"
            ]
          }
        },
        "32c585eb9ecd44669cba507079fe9857": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f03941f6b2c443fb6e7f52e1e7ca58d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_905b0cafd20044ad981f74cc81254aa3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5ff829700e7445e2a4bfe94f4463f263"
          }
        },
        "56910d5b91e5459c996e35c51590b971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_873948dc777b4fa286c9fa3a12ed11d2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:10&lt;00:00, 22.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2318c11fc8df40b68c3ed62777e69bc7"
          }
        },
        "905b0cafd20044ad981f74cc81254aa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5ff829700e7445e2a4bfe94f4463f263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "873948dc777b4fa286c9fa3a12ed11d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2318c11fc8df40b68c3ed62777e69bc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99bcb506c8784c5bba160cbd97fcf6ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cd3bb15ced874261acef91efbf2f9efc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f7e5ccb4e7a5429ea97bbd4253e667ad",
              "IPY_MODEL_caf3ac38c2da4d4a8ce6a46c3f00252b"
            ]
          }
        },
        "cd3bb15ced874261acef91efbf2f9efc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7e5ccb4e7a5429ea97bbd4253e667ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aec344788a224bdda42769ea3061ff08",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ea4d9a45fcd541c78b4fc697dbd46f63"
          }
        },
        "caf3ac38c2da4d4a8ce6a46c3f00252b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1663ece3aa884a63a5664841a2f8d5c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:03&lt;00:00, 137kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e9566d400054e829341b1fe2386c91e"
          }
        },
        "aec344788a224bdda42769ea3061ff08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ea4d9a45fcd541c78b4fc697dbd46f63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1663ece3aa884a63a5664841a2f8d5c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e9566d400054e829341b1fe2386c91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fce9b83fc1334a0caf50c4faba7130d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e66c9b06a3b84a8890abf199adb7b084",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6f110d18202d468b91b83e2749c5791c",
              "IPY_MODEL_0269942456c6453c917ae5fa8c118af4"
            ]
          }
        },
        "e66c9b06a3b84a8890abf199adb7b084": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f110d18202d468b91b83e2749c5791c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5c24272b598b4453b3b88faff8b20cc1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d8d49b5eba7a4e55b8bed46da8e0baf8"
          }
        },
        "0269942456c6453c917ae5fa8c118af4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0fc22c3487984e3dadf58bfdd567203a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:01&lt;00:00, 390B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf9445e08a1149519a3a8b32246818ca"
          }
        },
        "5c24272b598b4453b3b88faff8b20cc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d8d49b5eba7a4e55b8bed46da8e0baf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0fc22c3487984e3dadf58bfdd567203a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf9445e08a1149519a3a8b32246818ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1463c890cb2d41c6965108999e7756dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e93faf91347d431c84d437f1252682e5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_214d0b908cc34c1cbf924c09fcaacb8a",
              "IPY_MODEL_363fbdc2fefc4bbd932c345446b2616d"
            ]
          }
        },
        "e93faf91347d431c84d437f1252682e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "214d0b908cc34c1cbf924c09fcaacb8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5a5fdc0536d748a1aae8b6aa2f8499fe",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9544fc6bc5564512b515960cb039662d"
          }
        },
        "363fbdc2fefc4bbd932c345446b2616d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_938114524bc44b4a968470056cfd7d60",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:14&lt;00:00, 29.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20c20c52bd664bf99780ac824d5b9a19"
          }
        },
        "5a5fdc0536d748a1aae8b6aa2f8499fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9544fc6bc5564512b515960cb039662d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "938114524bc44b4a968470056cfd7d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20c20c52bd664bf99780ac824d5b9a19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2f37c08e407449786d596a36575edf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_26865232562841908360e1bf2b29beb1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_07d6735352824e49a4c7163f4d113b54",
              "IPY_MODEL_861ae22dbea848d0a7bb503ada582d7d"
            ]
          }
        },
        "26865232562841908360e1bf2b29beb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07d6735352824e49a4c7163f4d113b54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a34a00f99af14f9196b81bd37ff79b56",
            "_dom_classes": [],
            "description": "  1%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 18750,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 160,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3eadef3f69874268808610a0ffc2f6b2"
          }
        },
        "861ae22dbea848d0a7bb503ada582d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e5bde96e7f9d4a49ab8aa3a821b3c331",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 160/18750 [55:28&lt;13:51:13,  2.68s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8192abe607924656a707d0a49edb65fe"
          }
        },
        "a34a00f99af14f9196b81bd37ff79b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3eadef3f69874268808610a0ffc2f6b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5bde96e7f9d4a49ab8aa3a821b3c331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8192abe607924656a707d0a49edb65fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm1PCf4RunHb"
      },
      "source": [
        "# Практическое задание 3 \n",
        "\n",
        "# Классификация с использованием BERT\n",
        "\n",
        "## курс \"Математические методы анализа текстов\"\n",
        "\n",
        "\n",
        "### ФИО: Волынцев Дмитрий Александрович"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jUXLypiunHd"
      },
      "source": [
        "## Введение\n",
        "\n",
        "### Постановка задачи\n",
        "\n",
        "В этом задании вы будете классифицировать пары вопросов из stack overflow на предмет дубликатов.\n",
        "Чтобы получить гораздо более высокое качество на гораздо меньшем количестве данных, чем DSSM, предлагается дообучать предобученную модель BERT.\n",
        "\n",
        "### Библиотеки\n",
        "\n",
        "Для этого задания вам понадобятся следующие библиотеки:\n",
        " - [Pytorch](https://pytorch.org/).\n",
        " - [Transformers](https://github.com/huggingface/transformers).\n",
        " \n",
        "### Данные\n",
        "\n",
        "Данные лежат в архиве task3_data.zip, который состоит из:\n",
        "\n",
        "* train.tsv - обучающая выборка. В каждой строке записаны: <вопрос 1>, <вопрос 2>, <таргет>\n",
        "\n",
        "* validation.tsv - dev выборка, которую можно использовать для подбора гиперпарамеров; например, для ранней остановки. В каждой строке через табуляцию записаны: , <похожий вопрос>, <отрицательный пример 1>, <отрицательный пример 2>, ...\n",
        "\n",
        "* test.tsv - тестовая выборка, по которой оценивается итоговое качество. В каждой строке через табуляцию записаны: , <похожий вопрос>, <отрицательный пример 1>, <отрицательный пример 2>, ...\n",
        "\n",
        "Скачать данные можно здесь: [ссылка на google диск](https://drive.google.com/file/d/1Owb5Vpv7mVjksYo7gD9VuHkMETkzhIdr/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMxpd7SEunHe"
      },
      "source": [
        "## Часть 1. Подготовка данных (1 балл)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZbLLz0UunHf"
      },
      "source": [
        "Мы будем работать с теми же данными, которые были в первом задании. А также будем учиться классифицировать пары вопросов аналогично третьей части в первом задании. Теперь выборка для обучения сгенерирована заранее :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEeh64DyunHg"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tqdm\n",
        "import os\n",
        "import tests"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x84Mesx5utRn",
        "outputId": "d9e2b620-6085-4881-be40-af0aca75d60a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ33sRwuunHk"
      },
      "source": [
        "Путь к папке с данными:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgrnZmmJunHl"
      },
      "source": [
        "DATA_PATH = '/content/drive/My Drive/Colab Notebooks/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-VqaeAhunHo"
      },
      "source": [
        "Считывание данных для обучения:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaOSlvkeunHp"
      },
      "source": [
        "train = pd.read_table(os.path.join(DATA_PATH, 'train.tsv'))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WbC2qhYunHs",
        "outputId": "97b0c8bd-8a1f-401e-90a8-7a21b8f00dbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "train"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question_1</th>\n",
              "      <th>question_2</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>How to store an Array[String] to an output file</td>\n",
              "      <td>Rails ActiveJob Background Job Keeps Pinging M...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Pass a function return to another in the same row</td>\n",
              "      <td>jQuery AJAX submit form</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Is there a RegExp.escape function in Javascript?</td>\n",
              "      <td>Using my own method with LINQ to Entities</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How to update Google Play Services for Android...</td>\n",
              "      <td>Visual Studio keeps crashing: Application Error</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Using comet with PHP?</td>\n",
              "      <td>Group by followed by select only rows if its v...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599995</th>\n",
              "      <td>animate the fill color in cylinder from bottom...</td>\n",
              "      <td>Fill color with animation</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599996</th>\n",
              "      <td>Using %f to print an integer variable</td>\n",
              "      <td>using printf to print out floating values</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599997</th>\n",
              "      <td>How to handle session end in global.asax?</td>\n",
              "      <td>LOAD SQL Table from flat file</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599998</th>\n",
              "      <td>Is there a good reason for always enclosing a ...</td>\n",
              "      <td>Access CKEditor iframe's style tags with jQuery</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599999</th>\n",
              "      <td>Cannot set the value of read-only property 'jn...</td>\n",
              "      <td>Google Chrome wrong character - bug?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>600000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               question_1  ... target\n",
              "0         How to store an Array[String] to an output file  ...      0\n",
              "1       Pass a function return to another in the same row  ...      0\n",
              "2        Is there a RegExp.escape function in Javascript?  ...      0\n",
              "3       How to update Google Play Services for Android...  ...      0\n",
              "4                                   Using comet with PHP?  ...      0\n",
              "...                                                   ...  ...    ...\n",
              "599995  animate the fill color in cylinder from bottom...  ...      1\n",
              "599996              Using %f to print an integer variable  ...      1\n",
              "599997          How to handle session end in global.asax?  ...      0\n",
              "599998  Is there a good reason for always enclosing a ...  ...      0\n",
              "599999  Cannot set the value of read-only property 'jn...  ...      0\n",
              "\n",
              "[600000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2noOGtJxunHw"
      },
      "source": [
        "Модель **BERT** использует специальный токенизатор Wordpiece для разбиения предложений на токены. Готовая предобученная версия такого токенизатора существует в библиотеке **transformers**. Есть два класса: **BertTokenizer** и **BertTokenizerFast**. Использовать можно любой, но второй вариант работает существенно быстрее.\n",
        "\n",
        "Токенизаторы можно обучать с нуля на своем корпусе данных, а можно подгружать уже готовые. Готовые токенизаторы, как правило, соответствуют предобученной конфигурации модели, которая использует словарь из этого токенизатора. \n",
        "\n",
        "Мы будем использовать базовую конфигурацию предобученного **BERT** для модели и токенизатора:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScF13f-eunHx"
      },
      "source": [
        "BERT_MODEL = 'bert-base-uncased'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyOfjMxmunH1"
      },
      "source": [
        "Подгружение предобученных моделей и токенизаторов в **huggingface** происходит с помощью конструктора **from_pretrained**.\n",
        "\n",
        "В данном конструкторе можно указать либо путь к предобученному токенизатору, либо название предобученной конфигурации, как в нашем случае: тогда **transformers** сам подгрузит нужные параметры."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7dfLvPUyqPK",
        "outputId": "91690eab-5a16-4aea-ac35-bb12d99b591f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 9.1MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 23.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 48.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 51.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=64727d85821a3c938d04f6d5fcc2babad529b5ab7fa633d5aacbad10cf15f0a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnXRxMaYunH5",
        "outputId": "2c46e77e-b37c-42e1-9922-366b38135cab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "8a3d0d8b411f4ac9ab2c34a3f8867c0b",
            "32c585eb9ecd44669cba507079fe9857",
            "9f03941f6b2c443fb6e7f52e1e7ca58d",
            "56910d5b91e5459c996e35c51590b971",
            "905b0cafd20044ad981f74cc81254aa3",
            "5ff829700e7445e2a4bfe94f4463f263",
            "873948dc777b4fa286c9fa3a12ed11d2",
            "2318c11fc8df40b68c3ed62777e69bc7",
            "99bcb506c8784c5bba160cbd97fcf6ba",
            "cd3bb15ced874261acef91efbf2f9efc",
            "f7e5ccb4e7a5429ea97bbd4253e667ad",
            "caf3ac38c2da4d4a8ce6a46c3f00252b",
            "aec344788a224bdda42769ea3061ff08",
            "ea4d9a45fcd541c78b4fc697dbd46f63",
            "1663ece3aa884a63a5664841a2f8d5c8",
            "9e9566d400054e829341b1fe2386c91e"
          ]
        }
      },
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained(BERT_MODEL)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a3d0d8b411f4ac9ab2c34a3f8867c0b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99bcb506c8784c5bba160cbd97fcf6ba",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVq_Zr78unH9"
      },
      "source": [
        "Для классификации пар предложений необходимо привести примеры к виду: \n",
        "\n",
        "**[CLS] sent 1 [SEP] sent2 [SEP]**, \n",
        "\n",
        "где последний [SEP] можно опустить - в некоторых реализациях его используют, в некоторых нет. Существенного влияния на качество он не оказывает.\n",
        "\n",
        "Предлагается привести все предложения из обучения к данному виду перед созданием Dataset. Для этого удобно использовать метод **tokenizer.encode_plus**, который сам вставляет специальные специальные токены [CLS], [SEP] в числовое представление примера. \n",
        "\n",
        "Кроме того, данный метод сразу формирует для наших примеров сегментные эмбеддинги - т.е. сопоставляет всем токенам первого предложения эмбеддинг **А**, и всем токенам второго предложения эмбеддинг **Б**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZOe7Z7FunH9"
      },
      "source": [
        "def encode(query1, query2):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        query1: query text\n",
        "        query2: second query text\n",
        "        \n",
        "    Returns:\n",
        "        obj: dict {'input_ids': [0, 1, 2, 2, 1], 'token_type_ids': [0, 0, 1, 1, 1]}\n",
        "    \"\"\"\n",
        "    #pass\n",
        "    obj = tokenizer.encode_plus(query1, query2)\n",
        "    return obj"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Na13Y91l-oV6",
        "outputId": "55ddbbde-abed-49b6-c650-4cfd8b829202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "from tests import test_encode"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-751d679920ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtest_encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'test_encode'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNT9oyrH-a9z"
      },
      "source": [
        "Какая-то проблема с коллабом, не получается достать функции из tests, так что продублировал их сюда"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHMAykzJ-_GY"
      },
      "source": [
        "def test_encode(encode):\n",
        "    result = encode('this is some text', 'this is another text')\n",
        "\n",
        "    assert result['input_ids'] == [101, 2023, 2003, 2070, 3793, 102, 2023, 2003, 2178, 3793, 102], \\\n",
        "        'input_ids should be [101, 2023, 2003, 2070, 3793, 102, 2023, 2003, 2178, 3793, 102]'\n",
        "    assert result['token_type_ids'] == [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], \\\n",
        "        'token_type_ids should be [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]'\n",
        "    \n",
        "def test_dataset(dataset):\n",
        "    assert len(dataset[0]) == 3, 'Dataset[idx] should output tuple with 3 elements.'\n",
        "    assert isinstance(dataset[0][-1], np.int64) or isinstance(dataset[0][-1], int), \\\n",
        "        'target should np.int64 or int'\n",
        "    \n",
        "def test_collator(dataset, collate_fn):\n",
        "    ids, token_type_ids, labels = collate_fn([dataset[i] for i in range(10)])\n",
        "    assert ids.shape[0] == labels.shape[0] == token_type_ids.shape[0], \\\n",
        "        'ids, token_type_ids, labels shoud have equal first dimension'\n",
        "    assert ids.shape[1] == token_type_ids.shape[1], 'Incorrect shape of ids or token_type_ids'\n",
        "    \n",
        "def test_model(dataloader, model, device):\n",
        "    input_ids, token_type_ids, _ = map(lambda x: x.to(device), next(iter(dataloader)))\n",
        "    pred_shape = model(input_ids, token_type_ids).shape\n",
        "    assert len(pred_shape) == 1 and pred_shape[0] == input_ids.shape[0], \\\n",
        "        f'Incorrect shape for the output of the model: {pred_shape} instead of {[input_ids.shape[0]]}'"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7_BYljg0v2x"
      },
      "source": [
        "test_encode(encode)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bs2yheL2unIB",
        "outputId": "40434c61-5cc4-4ac3-8c97-3c7ccf044568",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tqdm.tqdm.pandas()\n",
        "\n",
        "train['enc'] = train.progress_apply(lambda x: encode(x['question_1'], x['question_2']), axis=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 600000/600000 [01:44<00:00, 5747.70it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xt11eIRGunIE"
      },
      "source": [
        "Проанализируйте количество токенов в получившихся представлениях объектов, выберите максимальный порог длины, затем обрежьте все представления по этому порогу. Это необходимо для более разумного использования видеопамяти.\n",
        "\n",
        "**hint:** можно использовать квантиль из **np.percentile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYt5tbvZunIF"
      },
      "source": [
        "###########################\n",
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "###########################\n",
        "len_list = []\n",
        "for item in train['enc']:\n",
        "  len_list.append(len(item['input_ids']))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RAigniyTBtzp",
        "outputId": "20f56970-1864-47b0-9345-471e6b51de0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "#Посмотрим на полученное распределение длин визуально\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(len_list)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([3.62810e+04, 2.97709e+05, 2.08384e+05, 4.77850e+04, 7.96000e+03,\n",
              "        1.50900e+03, 3.00000e+02, 5.80000e+01, 1.10000e+01, 3.00000e+00]),\n",
              " array([  8.,  18.,  28.,  38.,  48.,  58.,  68.,  78.,  88.,  98., 108.]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6IZw6doCWa9"
      },
      "source": [
        "Как видим, праздник заканчивается в районе 50 :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8XWYOZJB5rD"
      },
      "source": [
        "MAXLEN = 48"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inlMuAEOunII"
      },
      "source": [
        "## Часть 2. Задание пайплайна обучения (2 балла)\n",
        "\n",
        "**Внимание**. За эту часть можно получить ненулевой балл, только при демонстрации того, что ваша модель хоть как-то обучается и  работает."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBTaXof0unIJ"
      },
      "source": [
        "### Датасет и загрузчик\n",
        "\n",
        "Создайте датасет, из которого **DataLoader** будет брать объекты для формирования батчей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6qSSb2gunIK"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, corpus, targets):\n",
        "        ###########################\n",
        "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "        ###########################\n",
        "        #pass\n",
        "        self.input_ids_list = []\n",
        "        self.token_type_ids_list = []\n",
        "        self.targets = targets\n",
        "\n",
        "        for item in corpus:\n",
        "          #чтобы далее в паддингах использовать .size()\n",
        "          input_item_array = np.array(item['input_ids'])\n",
        "          token_type_item_array = np.array(item['token_type_ids'])\n",
        "          #список таких массивов\n",
        "          self.input_ids_list.append(input_item_array)\n",
        "          self.token_type_ids_list.append(token_type_item_array)\n",
        "\n",
        "    def __len__(self):\n",
        "        ###########################\n",
        "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "        ###########################\n",
        "        #pass\n",
        "        return len(self.targets)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            obj: (input_ids, token_type_ids, target)\n",
        "        \"\"\"\n",
        "        ###########################\n",
        "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "        ###########################\n",
        "        #pass\n",
        "        obj = (self.input_ids_list[idx], self.token_type_ids_list[idx], self.targets[idx])\n",
        "        return obj"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3c7WLrmunIN"
      },
      "source": [
        "ds = MyDataset(train['enc'], train['target'])\n",
        "\n",
        "test_dataset(ds)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36_FaKAmunIR"
      },
      "source": [
        "Реализуйте технику динамического паддинга батчей, используя функцию **collate_fn**, которую можно передать как одноименный параметр в класс **DataLoader**.\n",
        "\n",
        "**hint**: удобно использовать метод **torch.nn.utils.rnn**. Обратите особое внимание на параметр *batch_first*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0QYNznEunIS"
      },
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def collate_fn(batch, pad_idx=0):\n",
        "    \"\"\"\n",
        "        Args:\n",
        "            batch: list of objects\n",
        "            pad_idx: padding idx\n",
        "        Returns:\n",
        "            padded ids, token_type_ids, labels\n",
        "    \"\"\"\n",
        "    ###########################\n",
        "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "    ###########################\n",
        "    #pass\n",
        "    padded_ids = pad_sequence([torch.tensor(i[0]) for i in batch], batch_first = True, padding_value = pad_idx) #input\n",
        "    token_type_ids = pad_sequence([torch.tensor(j[1]) for j in batch], batch_first = True, padding_value = pad_idx) #token_type\n",
        "    labels = torch.tensor([k[2] for k in batch]) #target\n",
        "\n",
        "    return padded_ids, token_type_ids, labels\n",
        "\n",
        "test_collator(ds, collate_fn)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BMOtkDNunIV"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "dataloader = DataLoader(ds, collate_fn=collate_fn, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g0LZFMSunIY"
      },
      "source": [
        "### Модель\n",
        "\n",
        "\n",
        "В библиотеке **transformers** есть классы для модели BERT, уже настроенные под решение конкретных задач, с соответствующими головами классификации. Но гораздо более гибкий подход --- использовать энкодер BERT и, по необходимости, входной слой BERT.\n",
        "\n",
        "Существует два способа задания модели:\n",
        "* с помощью конфига **transformers.BertConfig**, в котором указываются все гиперпараметры модели\n",
        "* с помощью подгрузки предобученной модели. Можно загружать как свои предобученные модели, указав путь, так и готовые предобученные модели, указав название конфигурации. В данном задании мы уже выбрали как модель базовую конфигурацию *BERT base*:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D9qYidOunIZ",
        "outputId": "713651eb-0129-4632-971a-843212ed58c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114,
          "referenced_widgets": [
            "fce9b83fc1334a0caf50c4faba7130d4",
            "e66c9b06a3b84a8890abf199adb7b084",
            "6f110d18202d468b91b83e2749c5791c",
            "0269942456c6453c917ae5fa8c118af4",
            "5c24272b598b4453b3b88faff8b20cc1",
            "d8d49b5eba7a4e55b8bed46da8e0baf8",
            "0fc22c3487984e3dadf58bfdd567203a",
            "bf9445e08a1149519a3a8b32246818ca",
            "1463c890cb2d41c6965108999e7756dd",
            "e93faf91347d431c84d437f1252682e5",
            "214d0b908cc34c1cbf924c09fcaacb8a",
            "363fbdc2fefc4bbd932c345446b2616d",
            "5a5fdc0536d748a1aae8b6aa2f8499fe",
            "9544fc6bc5564512b515960cb039662d",
            "938114524bc44b4a968470056cfd7d60",
            "20c20c52bd664bf99780ac824d5b9a19"
          ]
        }
      },
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "bert = BertModel.from_pretrained(BERT_MODEL)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fce9b83fc1334a0caf50c4faba7130d4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1463c890cb2d41c6965108999e7756dd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWIVMuKDunIc"
      },
      "source": [
        "Напишите модель-обертку, которая:\n",
        "* принимает на вход название конфигурации (или путь к предобученной модели) и загружает как свой внутренний слой, обычно называемый *backbone* слоем\n",
        "* создает голову для классификации\n",
        "* при вызове метода **forward** использует векторное представление токена [CLS] с последнего слоя для классификации\n",
        "\n",
        "На вход BERT принимает:\n",
        "* input_ids --- непосредственно индексы ваших токенов в словаре\n",
        "* attention_mask --- булеву маску со значениями FALSE для всех PAD_IDX токенов\n",
        "* token_type_ids --- индексы принадлежности токена к 1 или 2 вопросу\n",
        "\n",
        "**hint:** в статье про BERT авторы опустили следующий архитектурный момент - представление CLS токена используется для NSP задачи, но перед классификацией оно проходит через так называемый **pooler** слой - линейный слой с *tanh* в качестве функции активации, который сохраняет размерность (т.е. на выходе оставляет hidden size значений). Если вы хотите использовать выход именно *pooler* слоя, нужно использовать вектор, получаемый из энкодера как второй элемент кортежа."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXABql19unId"
      },
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "class BERTClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, bert, n_classes=1):\n",
        "        ###########################\n",
        "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "        ###########################\n",
        "        #pass\n",
        "        super().__init__()\n",
        "        self.bert = bert\n",
        "        self.hidden_size = 768\n",
        "        self.n_classes = n_classes\n",
        "        self.linear = nn.Linear(self.hidden_size, self.n_classes)\n",
        "        \n",
        "    @classmethod\n",
        "    def from_pretrained(cls, path, n_classes=1):\n",
        "        bert = BertModel.from_pretrained(path)\n",
        "        return cls(bert, n_classes)\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "        \"\"\"\n",
        "            Args:\n",
        "                input_ids: token ids, shape = [batch_size, sequence_length]\n",
        "                attention_mask: masks out padding tokens, shape = [batch_size, sequence_length]\n",
        "                token_type_ids: segmend ids, shape = [batch_size, sequence_length]\n",
        "            Returns:\n",
        "                predictions, shape [batch_size]\n",
        "        \"\"\"\n",
        "        ###########################\n",
        "        ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "        ###########################\n",
        "        #pass\n",
        "        full_output = self.bert(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask)\n",
        "        #второй элемент\n",
        "        output = self.linear(full_output[1])\n",
        "        #shape = ([32, 1])\n",
        "        return torch.sigmoid(output[:, 0])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHfKzjZ4unIg"
      },
      "source": [
        "device = torch.device('cuda')\n",
        "\n",
        "model = BERTClassifier.from_pretrained(BERT_MODEL, n_classes=1).to(device)\n",
        "\n",
        "test_model(dataloader, model, device)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5307n0VunIj"
      },
      "source": [
        "### Оптимизатор\n",
        "\n",
        "Для оптимизации **BERT** будем использовать **AdamW** c увеличенным learning rate'ом для параметров головы-классификатора. \n",
        "\n",
        "Отличие **AdamW** от **Adam** заключается в более корректной реализации $l_2$ регуляризации, которая задается параметром **weight_decay** при инициализации.\n",
        "\n",
        "Параметры необходимо объединить на три группы:\n",
        "\n",
        "* параметры, которым нужен weight decay --- все параметры из backbone, кроме сдвигов (bias) и LayerNorm слоев.\n",
        "* остальные парамеры из backbone\n",
        "* параметры головы классификации, для которых мы будем задавать гораздо больший learning rate\n",
        "\n",
        "Будем использовать **model.named_parameters()**, чтобы разделить параметры на три группы, исходя из названий слоев."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsqwHl37unIk"
      },
      "source": [
        "NO_DECAY = ['bias', 'LayerNorm.weight']\n",
        "\n",
        "def is_backbone(name):\n",
        "    ###########################\n",
        "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "    ###########################\n",
        "    #pass\n",
        "    #bert или linear\n",
        "    if 'bert' in name:\n",
        "      return 'True'\n",
        "    else:\n",
        "      return 'False'\n",
        "\n",
        "def needs_decay(name):\n",
        "    ###########################\n",
        "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "    ###########################\n",
        "    #pass\n",
        "    if any(nd in name for nd in NO_DECAY):\n",
        "      return 'False'\n",
        "    else:\n",
        "      return 'True'\n",
        "\n",
        "def get_optimizer(model, lr, weight_decay, head_lr):\n",
        "    grouped_parameters = [\n",
        "        {\n",
        "            'params': [param for name, param in model.named_parameters() if is_backbone(name) and needs_decay(name)],\n",
        "            'lr': lr,\n",
        "            'weight_decay': weight_decay,\n",
        "        },\n",
        "        {\n",
        "            'params': [param for name, param in model.named_parameters() if is_backbone(name) and not needs_decay(name)],\n",
        "            'lr': lr,\n",
        "            'weight_decay': 0.,\n",
        "        },\n",
        "        {\n",
        "            'params': [param for name, param in model.named_parameters() if not is_backbone(name)],\n",
        "            'lr': head_lr,\n",
        "            'weight_decay': weight_decay,\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    optimizer = torch.optim.AdamW(grouped_parameters, lr, weight_decay=weight_decay)\n",
        "\n",
        "    return optimizer\n",
        "\n",
        "LEARNING_RATE = 0.0001\n",
        "WEIGHT_DECAY = 0.0001\n",
        "HEAD_LEARNING_RATE = 0.0001\n",
        "\n",
        "optimizer = get_optimizer(model, lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, head_lr=HEAD_LEARNING_RATE)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7urNmWMunIm"
      },
      "source": [
        "### Scheduler\n",
        "\n",
        "\n",
        "Также необходимо задать расписание для learning rate. Для **BERT** используется **linear warmup**. \n",
        "\n",
        "В **transformers** есть реализация **linear warmup** с помощью метода **transformers.get_linear_schedule_with_warmup**, в которой learning rate стартует с 0, и в течение **num_warmup_steps** линейно возрастает до значения, указанного в качестве стартового в оптимизаторе. Затем в течение **num_training_steps - num_warmup_steps** learning rate линейно падает до 0.\n",
        "\n",
        "Используйте *dataloader.dataset* и *dataloader.batch_size*, чтобы рассчитать *num_training_steps* исходя из количества эпох. В случае нашей задачи одной эпохи должно быть достаточно для обучения модели.\n",
        "\n",
        "В случае ограниченного количества видеопамяти может возникнуть ситуация, при которой батч нужного размера не влезает в видеокарту. Для таких ситуаций предлагается использовать аккумуляцию градиента - накапливание градиента в течение *accumulation_steps* с последующим шагом спуска. Т.е. делать *(loss / accumulation_steps).backward()* для каждого батча, и при этом каждые *accumulation_steps* шагов делать *optimizer.step()*.\n",
        "\n",
        "При обучении количество шагов warmup выбирают либо как 10000 шагов, либо как 0.01% или 0.06% от всех шагов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S37yDUMfunIn"
      },
      "source": [
        "import transformers\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "def get_scheduler(optimizer, dataloader, n_epochs, accumulation_steps, warmup_percentage):\n",
        "    ###########################\n",
        "    ### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "    ###########################\n",
        "    #pass\n",
        "    steps_per_epoch = len(dataloader)\n",
        "    steps = n_epochs * steps_per_epoch\n",
        "    warmup_steps = steps * warmup_percentage\n",
        "    sheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, steps)\n",
        "    return sheduler\n",
        "\n",
        "N_EPOCHS = 1\n",
        "ACCUMULATION_STEPS = 1\n",
        "WARMUP_PERCENTAGE = 0.01\n",
        "\n",
        "scheduler = get_scheduler(\n",
        "    optimizer, dataloader, n_epochs=N_EPOCHS, accumulation_steps=ACCUMULATION_STEPS, warmup_percentage=WARMUP_PERCENTAGE\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfQue5wbunIq"
      },
      "source": [
        "Для проверки качества модели необходимо использовать подготовленный для задания **Evaluator**. Важный момент: при использовании, evaluator переводит модель в режим валидации: model.eval(). Во время обучения необходимо самостоятельно переключать ее на model.train() после каждого использования.\n",
        "\n",
        "На вход evaluator принимает вашу модель и device (CUDA или CPU), на котором необходимо считать результаты моделирования. \n",
        "\n",
        "При использовании evaluator можно использовать BATCH_SIZE значительно большего размера, потому что отпадает необходимость считать градиенты для параметров."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zjy6i38OunIq",
        "outputId": "39ba723f-4098-4f47-e8a9-ded2d527b2ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "from utils import Evaluator"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-02f2af813416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tu6ynz6CAyMe"
      },
      "source": [
        "Опять продблирую utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIdCAiBoAPYc"
      },
      "source": [
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class InferenceDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        ids = torch.tensor(self.data[idx]['input_ids'], dtype=torch.long)\n",
        "        type_ids = torch.tensor(self.data[idx]['token_type_ids'], dtype=torch.long)\n",
        "        return ids, type_ids\n",
        "\n",
        "    \n",
        "def collate_fn(batch, pad_idx=0):\n",
        "    ids, type_ids = map(lambda x: pad_sequence(x, batch_first=True, padding_value=pad_idx), zip(*batch))\n",
        "    return ids, type_ids\n",
        "\n",
        "\n",
        "def hits_count(dup_ranks, k):\n",
        "    ranks = [rank <= k for rank in dup_ranks]\n",
        "    return 0. if not ranks else np.mean(ranks)\n",
        "\n",
        "\n",
        "def dcg_score(dup_ranks, k):\n",
        "    vals = [1. / np.log2(1. + rank) for rank in dup_ranks if rank <= k]\n",
        "    return 0. if not vals else np.sum(vals) / len(dup_ranks)\n",
        "\n",
        "\n",
        "class Evaluator:\n",
        "\n",
        "    def __init__(self, path, tokenizer, maxlen, batch_size, pad_idx=0, verbose=False):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.maxlen = maxlen\n",
        "        self.pad_idx = pad_idx\n",
        "        \n",
        "        data = []\n",
        "        for line in open(path, encoding='utf-8'):\n",
        "            data.append(line.strip().split('\\t'))\n",
        "\n",
        "        lengths = []\n",
        "        prep_data = []\n",
        "        for query, *docs in tqdm.tqdm(data, disable=not verbose, desc='Encoding text...'):\n",
        "            for doc in docs:\n",
        "                prep_data.append(self.encode(query, doc))\n",
        "            lengths.append(len(docs))\n",
        "        self.bounds = np.cumsum([0] + lengths)\n",
        "        self.ids, prep_data = zip(*sorted(enumerate(prep_data), key=lambda x: len(x[1]['input_ids'])))\n",
        "\n",
        "        ds = InferenceDataset(prep_data)\n",
        "        self.dataloader = DataLoader(ds, batch_size, collate_fn=collate_fn)\n",
        "        \n",
        "    def __call__(self, model, device, verbose=False):\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        \n",
        "        preds = []\n",
        "        for batch in tqdm.tqdm(self.dataloader, disable=not verbose, desc='Computing predictions...'):\n",
        "            input_ids, token_type_ids = map(lambda x: x.to(device), batch)\n",
        "            attention_mask = input_ids != self.pad_idx\n",
        "            with torch.no_grad():\n",
        "                pred = model(input_ids, attention_mask, token_type_ids).cpu()\n",
        "            preds.append(pred)\n",
        "        preds = torch.cat(preds).numpy()\n",
        "        \n",
        "        _, preds = zip(*sorted(zip(self.ids, preds), key=lambda x: x[0]))\n",
        "        \n",
        "        rankings = []\n",
        "        for i in range(len(self.bounds) - 1):\n",
        "            rankings.append(\n",
        "                list(np.argsort(-np.array(preds[self.bounds[i]:self.bounds[i + 1]]))).index(0) + 1\n",
        "            )\n",
        "            \n",
        "        metrics = {\n",
        "            'DCG': {f'DCG@{k}': dcg_score(rankings, k) for k in [1, 5, 10, 100, 500, 1000]},\n",
        "            'Hits': {f'Hits@{k}': hits_count(rankings, k) for k in [1, 5, 10, 100, 500, 1000]}\n",
        "        }\n",
        "        \n",
        "        return metrics\n",
        "            \n",
        "    def encode(self, query, doc):\n",
        "        enc = self.tokenizer.encode_plus(query, doc, add_special_tokens=True)\n",
        "        return {'input_ids': enc.input_ids[:self.maxlen], 'token_type_ids': enc.token_type_ids[:self.maxlen]}"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsYEt1FVANqd",
        "outputId": "77e5262d-7bf2-4c3b-984e-fda503129d0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "evaluator = Evaluator(os.path.join(DATA_PATH, 'validation.tsv'), tokenizer, maxlen=MAXLEN, batch_size=1024)\n",
        "metrics = evaluator(model, device, verbose=True)\n",
        "metrics"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Computing predictions...: 100%|██████████| 98/98 [03:01<00:00,  1.85s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DCG': {'DCG@1': 0.52,\n",
              "  'DCG@10': 0.6044309951592103,\n",
              "  'DCG@100': 0.6310030269090201,\n",
              "  'DCG@1000': 0.6540623227798987,\n",
              "  'DCG@5': 0.594703974563633,\n",
              "  'DCG@500': 0.6499113729145151},\n",
              " 'Hits': {'Hits@1': 0.52,\n",
              "  'Hits@10': 0.68,\n",
              "  'Hits@100': 0.81,\n",
              "  'Hits@1000': 1.0,\n",
              "  'Hits@5': 0.65,\n",
              "  'Hits@500': 0.96}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq-TTxIlunIu"
      },
      "source": [
        "Данный **evaluator** предлагается использовать не только для оценки итогового качества, но также для вывода промежуточных результатов на dev сете в логи с помощью **torch.utils.tensorboard.SummaryWriter**.\n",
        "\n",
        "Перед обучением необходимо создать объект данного класса, указав папку для записи логов.\n",
        "\n",
        "Во время обучения через каждые $10000$ объектов необходимо записывать значения метрик в логи с помощью методов **writer.add_scalars**. Кроме того, необходимо записывать значение функционала ошибки на каждом батче во время обучения с помощью метода **writer.add_scalar**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kn3kzfxLunIv"
      },
      "source": [
        "## Часть 3. Обучение модели (7 баллов)\n",
        "\n",
        "Ниже предлагаются примерные значения гиперпараметров, приводящие к необходимым метрикам качества. Для подбора точных значений гиперпараметров предлагается использовать *dev set*.\n",
        "\n",
        "**Гиперпараметры для обучения:**\n",
        "\n",
        "* размер батча в $\\{32, 64\\}$\n",
        "* клиппинг нормы градиента (используйте **torch.nn.utils.clip_grad_norm_**)\n",
        "* шаг обучения в $\\{$1e-5, 2e-5, 3e-5, 4e-5$\\}$\n",
        "* weight decay в $\\{$1e-2, 1e-3, 1e-4$\\}$\n",
        "* warmup percentage в $\\{0.01, 0.06\\}$\n",
        "* шаг обучения для головы-классификатора в $\\{10, 50, 100\\}$ раз больше, чем для остальных параметров"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoCuOI3munIv"
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "###########################\n",
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "###########################\n",
        "logs = SummaryWriter('logs/')\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.00001\n",
        "WEIGHT_DECAY = 0.01\n",
        "WARMUP_PERCENTAGE = 0.01\n",
        "HEAD_LEARNING_RATE = 0.001\n",
        "N_EPOCHS = 3"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WQ0DUIBX0Tm"
      },
      "source": [
        "from torch.nn import BCELoss\n",
        "evaluator = Evaluator(os.path.join(DATA_PATH, 'validation.tsv'), tokenizer, maxlen=MAXLEN, batch_size=1024)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-NGBhmcYeD_",
        "outputId": "68c286eb-97fc-4036-f4a9-296ac2f60de5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378,
          "referenced_widgets": [
            "a2f37c08e407449786d596a36575edf7",
            "26865232562841908360e1bf2b29beb1",
            "07d6735352824e49a4c7163f4d113b54",
            "861ae22dbea848d0a7bb503ada582d7d",
            "a34a00f99af14f9196b81bd37ff79b56",
            "3eadef3f69874268808610a0ffc2f6b2",
            "e5bde96e7f9d4a49ab8aa3a821b3c331",
            "8192abe607924656a707d0a49edb65fe"
          ]
        }
      },
      "source": [
        "from tqdm.notebook import tqdm as tqdm_n\n",
        "model.to(device)\n",
        "model.train()\n",
        "loss_func = BCELoss()\n",
        "train_loss = []\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "  for step, batch in enumerate(tqdm_n(dataloader)):\n",
        "    padded_ids, token_type_ids, labels = batch\n",
        "    output = model(input_ids = padded_ids.to(device), token_type_ids = token_type_ids.to(device), attention_mask = None)\n",
        "    loss = loss_func(output.float().to(device), labels.float().to(device))\n",
        "    loss = loss / ACCUMULATION_STEPS\n",
        "    train_loss.append(loss)\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "    logs.add_scalar('Loss/train', loss.float(), step)\n",
        "\n",
        "    if (step + 1) % ACCUMULATION_STEPS == 0:\n",
        "      optimizer.step() \n",
        "      scheduler.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    if step % (10 * ACCUMULATION_STEPS) == 0:\n",
        "      metrics = evaluator(model, device, verbose=False)\n",
        "      logs.add_scalars('Eval/Hits', metrics[\"Hits\"], step)\n",
        "      logs.add_scalars('Eval/DCG', metrics[\"DCG\"], step)\n",
        "\n",
        "      model.train()\n",
        "logs.close()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2f37c08e407449786d596a36575edf7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=18750.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-96890cab568c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mACCUMULATION_STEPS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Eval/Hits'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Hits\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_scalars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Eval/DCG'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"DCG\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-40-754f0b26ac65>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, model, device, verbose)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Dzi3CeYTunIy"
      },
      "source": [
        "dev_metrics = evaluator(model, device)\n",
        "dev_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBjNE-VmunI1"
      },
      "source": [
        "test_evaluator = Evaluator(os.path.join(DATA_PATH, 'test.tsv'), tokenizer, maxlen=MAXLEN, batch_size=1024)\n",
        "test_metrics = test_evaluator(model, device, verbose=True)\n",
        "test_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET17tp4junI4"
      },
      "source": [
        "Задание будет засчитано на полный балл при *Hits@1* на *test set* больше $0.6$. Необходимо приложить логи из тензорборда, а также скриншот этих самых логов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTJzVkL5unI5"
      },
      "source": [
        "## Бонусная часть (до 6 баллов)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bo4oMgKCunI5"
      },
      "source": [
        "### ELMO-подобная архитектура для головы-классификатора (до 2 баллов)\n",
        "\n",
        "Реализуйте и обучите ELMO-подобную архитектуру для головы-классификатора: берутся все 13 векторных представлений CLS токена, и затем с обучаемыми софтмакс-нормализуемыми весами складываются перед линейным классификатором. Дообучаются ВСЕ веса, включая сам берт. Можно попробовать зафризить исходный берт, но с большой вероятностью наибольшее качество достигается при дообучении всего.\n",
        "\n",
        "Рекомендуется инициализировать обучаемые веса равными значениями, а также наряду с головой-классификатором присвоить им learning rate, значительно больший по значению, чем у энкодера.\n",
        "\n",
        "Требуется получить качество хотя бы примерно такое же (а желательно и выше), чем при основной архитектуре. Может понадобиться больше эпох для обучения!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r12WmozkunI6"
      },
      "source": [
        "###########################\n",
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "###########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rque63YgunI9"
      },
      "source": [
        "### Улучшение качества на том же наборе данных (до 2 баллов)\n",
        "\n",
        "Можно использовать любые способа для улучшения качества, КРОМЕ изменения датасетов. Например:\n",
        "\n",
        "* Multi-sample Dropout --- при обучении, перед головой классификации итоговый вектор прогоняется через Dropout *n*-ное количество раз, каждый из полученных векторов проводится через голову классификации, и результаты усредняются.\n",
        "* Изменения в архитектуре энкодера --- попробовать large конфигурацию, поменять функцию активации и прочие гиперпараметры, взять предобученный альберт из huggingface c пошаренными весами в энкодере\n",
        "* попробовать дотюнить bert на MLM задачу (как в ULMFiT) перед дообучением на задачу классификации\n",
        "* попробовать другие головы классификации - elmo-like голову, макс/авг пулинг по всем токенам или по всем векторам CLS токена, конкатенацию векторов CLS токена; сверточную сеть для классификации\n",
        "\n",
        "Требуется получить Hits@1 $ \\geqslant 0.65$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNeDKGVGunI9"
      },
      "source": [
        "###########################\n",
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "###########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKAsgqAPunJA"
      },
      "source": [
        "### Улучшение качества с генерацией нового тренировочного набора (до 2 баллов)\n",
        "\n",
        "Для формирования тренировочной выборки в данном задании использовался *train_data* из первой домашней работы. Были взяты $100000$ пар дубликатов, и для первого дубликата из каждой пары также было сгенерировано 5 отрицательных примеров с помощью негативного сэмплирования. Предлагается самостоятельно сгенерировать тренировочную выборку, подобрать наилучший размер, а также количество негативных сэмплов.\n",
        "\n",
        "Валидироваться надо на тех же самых датасетах.\n",
        "\n",
        "Требуется получить Hits@1 $\\geqslant0.7$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f61Cwt1yunJA"
      },
      "source": [
        "###########################\n",
        "### ╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ\n",
        "###########################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oan6ke3LunJD"
      },
      "source": [
        "P.S.: возможна корректировка дополнительных баллов по результатам выполнения бонусов. Рекомендуется в любом случае попробовать их сделать, даже если не получится получить нужное значение метрики :)"
      ]
    }
  ]
}