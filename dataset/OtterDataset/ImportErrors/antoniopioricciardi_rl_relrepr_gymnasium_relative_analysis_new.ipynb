{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tueplots\n",
    "# !pip install backports.strenum\n",
    "# !pip install nncore\n",
    "# !pip install StrEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/antonioricciardi/projects/rl_relrepr_gymnasium/notebooks\n",
      "/Users/antonioricciardi/projects/rl_relrepr_gymnasium\n",
      "0.0.7\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'latentis.transform.base'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 34\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlatentis\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(latentis\u001b[38;5;241m.\u001b[39m__version__)\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlatentis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaling, Centering\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlatentis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdim_matcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ZeroPadding\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlatentis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtranslate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maligner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MatrixAligner, Translator\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'latentis.transform.base'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "import random\n",
    "from typing import Sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from pytorch_lightning import seed_everything\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    # be ready for 3.10 when it drops\n",
    "    from enum import StrEnum\n",
    "except ImportError:\n",
    "    from backports.strenum import StrEnum\n",
    "from enum import auto\n",
    "\n",
    "# from nn_core.common import PROJECT_ROOT\n",
    "import pickle\n",
    "\n",
    "print(os.path.abspath(os.curdir))\n",
    "os.chdir(\"..\")\n",
    "print(os.path.abspath(os.curdir))\n",
    "from zeroshotrl.rl_agents.ppo.ppo_end_to_end_relu_stack_align import FeatureExtractor\n",
    "from zeroshotrl.utils.relative import *\n",
    "from zeroshotrl.utils.notebooks import *\n",
    "\n",
    "import latentis\n",
    "\n",
    "print(latentis.__version__)\n",
    "\n",
    "from latentis.transform.base import StandardScaling, Centering\n",
    "from latentis.transform.dim_matcher import ZeroPadding\n",
    "from latentis.transform.translate.aligner import MatrixAligner, Translator\n",
    "from latentis.transform.translate.functional import (\n",
    "    svd_align_state,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR: Path = PROJECT_ROOT / \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tueplots import bundles\n",
    "\n",
    "# plt.rcParams.update(bundles.icml2022())\n",
    "bundles.icml2022()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CMAP = \"jet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR: Path = PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color1 = \"green\"\n",
    "color2 = \"blue\"\n",
    "enc1_seed = 1\n",
    "enc2_seed = 1\n",
    "\n",
    "obs_path1 = f\"data/anchors/CarRacing-v2/rgb_ppo_transitions_{color1}_obs.pkl\"\n",
    "obs_path2 = f\"data/anchors/CarRacing-v2/rgb_ppo_transitions_{color2}_obs.pkl\"\n",
    "\n",
    "algo1 = \"ppo\"\n",
    "algo2 = \"ppo\"\n",
    "env_id1 = \"CarRacing-v2\"\n",
    "env_id2 = \"CarRacing-v2\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "encoder1_path = torch.load(\n",
    "    f\"models/{env_id1}/rgb/{color1}/{algo1}/absolute/relu/seed_{enc1_seed}/encoder.pt\",\n",
    "    map_location=device,\n",
    ")\n",
    "encoder2_path = torch.load(\n",
    "    f\"models/{env_id2}/rgb/{color2}/{algo2}/absolute/relu/seed_{enc2_seed}/encoder.pt\",\n",
    "    map_location=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder1 = FeatureExtractor()\n",
    "encoder2 = FeatureExtractor()\n",
    "encoder1.load_state_dict(encoder1_path)\n",
    "encoder2.load_state_dict(encoder2_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_set_1 = pickle.load(Path(obs_path1).open(\"rb\"))  # [30:2000]\n",
    "obs_set_2 = pickle.load(Path(obs_path2).open(\"rb\"))  # [30:2000]\n",
    "print(\"\\n#####\\nObs loaded\\n#####\\n\")\n",
    "# subset_indices = np.random.randint(0, len(obs_set_1), 5000)\n",
    "obs_set_1 = obs_set_1\n",
    "obs_set_2 = obs_set_2\n",
    "\n",
    "print(\"Converting obs to torch tensor\")\n",
    "# convert the (4000, 3, 84, 84) numpy array to a torch tensor\n",
    "obs_set_1 = torch.tensor(np.array(obs_set_1), dtype=torch.float32)\n",
    "obs_set_2 = torch.tensor(np.array(obs_set_2), dtype=torch.float32)\n",
    "print(\"Done converting obs to torch tensor\\n#####\\n\")\n",
    "\n",
    "# obs_set_1 = torch.cat([obs_set_1, obs_set_2], dim=0)  # [anch_indices\n",
    "# obs_set_2 = obs_set_1\n",
    "\n",
    "subset_indices = np.arange(len(obs_set_1))  # [:4000]\n",
    "\n",
    "# obs_set_1 = torch.cat(obs_set_1, dim=0).cpu()  # [anch_indices]\n",
    "# obs_set_2 = torch.cat(obs_set_2, dim=0).cpu()  # [anch_indices]\n",
    "space1 = encoder1.forward_single(obs_set_1.to(device)).detach().cpu()[:900]\n",
    "space2 = encoder2.forward_single(obs_set_2.to(device)).detach().cpu()[:900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot obs_set_1 and obs_set_2 images in a subplot\n",
    "i = 500\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(obs_set_1[i].permute(1, 2, 0))\n",
    "ax[1].imshow(obs_set_2[i].permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert space1.shape == space2.shape\n",
    "# assert space1.size(0) == labels.size(0)\n",
    "space1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative stuff\n",
    "# from latentis.project import relative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_space1: torch.Tensor = F.normalize(space1, p=2, dim=-1)\n",
    "norm_space2: torch.Tensor = F.normalize(space2, p=2, dim=-1)\n",
    "\n",
    "assert norm_space1.shape == norm_space2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pairwise_dist(space1=space1, space2=space2, prefix=\"Absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_sim_comparison(space1=space1, space2=space2, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 6), sharey=False)\n",
    "dist_method = DistMethod.COSINE\n",
    "prefix = \"Absolute\"\n",
    "dists = all_dist(space1=space1, space2=space2, method=dist_method)\n",
    "# ax.set_title(f\"{prefix} self-similarities ({dist_method})\")\n",
    "img = ax.imshow(dists, cmap=CMAP, vmin=-1, vmax=1)  # Set vmin and vmax to -1 and 1\n",
    "plt.colorbar(img, ax=ax)\n",
    "plt.savefig(\n",
    "    f\"experiments/plots/{env_id1}_{color1}_{env_id2}_{color2}_abs_selfsim.pdf\",\n",
    "    bbox_inches=\"tight\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors_space1 = encoder1.forward_single(obs_set_1.to(device)).detach().cpu()\n",
    "anchors_space2 = encoder2.forward_single(obs_set_2.to(device)).detach().cpu()\n",
    "# # center anchors\n",
    "# anchors_space1_mean = anchors_space1.mean(dim=0)\n",
    "# anchors_space2_mean = anchors_space2.mean(dim=0)\n",
    "\n",
    "# center_anchor_translations = torch.cdist(anchors_space1_mean.unsqueeze(0), anchors_space2_mean.unsqueeze(0), p=2)\n",
    "\n",
    "# anchors_space1 = (anchors_space1 - anchors_space1.mean(dim=0)) # / anchors_space1.std(dim=0)\n",
    "# anchors_space2 = (anchors_space2 - anchors_space2.mean(dim=0)) # / anchors_space2.std(dim=0)\n",
    "# center_anchor_translations = torch.cdist(anchors_space1.mean(dim=0, keepdim=True), anchors_space2.mean(dim=0, keepdim=True).unsqueeze(0), p=2)\n",
    "\n",
    "# norm_anchors_space1: torch.Tensor = F.normalize(anchors_space1, p=2, dim=-1)\n",
    "# norm_anchors_space2: torch.Tensor = F.normalize(anchors_space2, p=2, dim=-1)\n",
    "\n",
    "# assert norm_anchors_space1.shape == norm_anchors_space2.shape\n",
    "\n",
    "\n",
    "# norm_space1 = (space1 - anchors_space1_mean)#  / self.anchors_std\n",
    "# norm_space1: torch.Tensor = F.normalize(norm_space1, p=2, dim=-1)\n",
    "\n",
    "# norm_space2 = (space2 - anchors_space2_mean)#  / self.anchors_std\n",
    "# norm_space2: torch.Tensor = F.normalize(norm_space2, p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rel_space1 = norm_space1 @ anchors_space1.T # space1_anchors.T\n",
    "# rel_space2 = norm_space2 @ anchors_space2.T # space2_anchors.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from latentis.transform.projection import cosine_proj, relative_projection\n",
    "from latentis.transform import XTransformSequence\n",
    "\n",
    "x_transform = XTransformSequence(transforms=[StandardScaling()])\n",
    "y_transform = XTransformSequence(transforms=[StandardScaling()])\n",
    "\n",
    "x_transform.fit(anchors_space1)\n",
    "y_transform.fit(anchors_space2)\n",
    "\n",
    "rel_space1 = relative_projection(\n",
    "    x=x_transform.transform(space1),\n",
    "    anchors=x_transform.transform(anchors_space1),\n",
    "    projection_fn=cosine_proj,\n",
    ")\n",
    "rel_space2 = relative_projection(\n",
    "    x=y_transform.transform(space2),\n",
    "    anchors=y_transform.transform(anchors_space2),\n",
    "    projection_fn=cosine_proj,\n",
    ")\n",
    "rel_space1.shape, rel_space2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_pairwise_dist(space1=rel_space1, space2=rel_space2, prefix=\"Relative\")\n",
    "# save fig\n",
    "# fig.savefig(f\"experiments/plots/{env_id1}_{color1}_{env_id2}_{color2}_pairwise_dist_rel.pdf\", bbox_inches='tight')\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_sim_comparison(space1=rel_space1, space2=rel_space2, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_self_dist(space1=rel_space1, space2=rel_space2, prefix=\"Relative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 6), sharey=False)\n",
    "dist_method = DistMethod.COSINE\n",
    "prefix = \"Relative\"\n",
    "dists = all_dist(space1=rel_space1, space2=rel_space2, method=dist_method)\n",
    "# ax.set_title(f\"{prefix} self-similarities ({dist_method})\")\n",
    "img = ax.imshow(dists, cmap=CMAP, vmin=-1, vmax=1)  # Set vmin and vmax to -1 and 1\n",
    "plt.colorbar(img, ax=ax)\n",
    "# plt.savefig(f\"experiments/plots/{env_id1}_{color1}_{env_id2}_{color2}_rel_selfsim.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    nrows=1, ncols=2, figsize=(11, 5), sharey=True, gridspec_kw={\"wspace\": 0.1}\n",
    ")\n",
    "\n",
    "dist_method = DistMethod.COSINE\n",
    "prefix = \"Absolute\"\n",
    "dists = pairwise_dist(space1=space1, space2=space2, method=dist_method)\n",
    "axs[0].hist(dists, bins=42)\n",
    "axs[0].set_title(f\"{prefix} pairwise similarities ({dist_method})\")\n",
    "axs[0].axvline(dists.mean(), color=\"k\", linestyle=\"dashed\", linewidth=1)\n",
    "\n",
    "min_ylim, max_ylim = axs[0].get_ylim()\n",
    "min_xlim, max_xlim = axs[0].get_xlim()\n",
    "axs[0].text(\n",
    "    dists.mean() + (max_xlim - min_xlim) / 20,\n",
    "    max_ylim * 0.95,\n",
    "    \"Mean: {:.2f}\".format(dists.mean()),\n",
    ")\n",
    "\n",
    "prefix = \"Relative\"\n",
    "dists = pairwise_dist(space1=rel_space1, space2=rel_space2, method=dist_method)\n",
    "axs[1].hist(dists, bins=42)\n",
    "axs[1].set_title(f\"{prefix} pairwise similarities ({dist_method})\")\n",
    "axs[1].axvline(dists.mean(), color=\"k\", linestyle=\"dashed\", linewidth=1)\n",
    "\n",
    "min_ylim, max_ylim = axs[1].get_ylim()\n",
    "min_xlim, max_xlim = axs[1].get_xlim()\n",
    "axs[1].text(\n",
    "    dists.mean() + (max_xlim - min_xlim) / 20,\n",
    "    max_ylim * 0.95,\n",
    "    \"Mean: {:.2f}\".format(dists.mean()),\n",
    ")\n",
    "\n",
    "plt.close()\n",
    "\n",
    "# fig.savefig(f\"experiments/plots/{env_id1}_{color1}_{env_id2}_{color2}_pairwise_dists_abs_rel.pdf\", bbox_inches='tight')\n",
    "\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(\n",
    "    nrows=1, ncols=2, figsize=(11, 5), sharey=True, gridspec_kw={\"wspace\": 0.1}\n",
    ")\n",
    "\n",
    "# Plot Absolute Self-Similarities\n",
    "dist_method = DistMethod.COSINE\n",
    "prefix = \"Absolute\"\n",
    "dists = all_dist(space1=space1, space2=space2, method=dist_method)\n",
    "# axs[0].set_title(f\"{prefix} self-similarities ({dist_method})\")\n",
    "img1 = axs[0].imshow(dists, cmap=\"jet\", vmin=-1, vmax=1)  # cmap='Spectral_r'\n",
    "\n",
    "# Plot Relative Self-Similarities\n",
    "dist_method = DistMethod.COSINE\n",
    "prefix = \"Relative\"\n",
    "dists = all_dist(space1=rel_space1, space2=rel_space2, method=dist_method)\n",
    "# axs[1].set_title(f\"{prefix} self-similarities ({dist_method})\")\n",
    "img2 = axs[1].imshow(dists, cmap=\"jet\", vmin=-1, vmax=1)\n",
    "\n",
    "# Add a smaller colorbar\n",
    "fig.colorbar(img2, ax=axs, orientation=\"vertical\", shrink=0.82)\n",
    "\n",
    "# Save the figure\n",
    "# plt.savefig(f\"experiments/plots/{env_id1}_{color1}_{env_id2}_{color2}_selfsim.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot frame i and frame j in a subplot\n",
    "i = 200\n",
    "j = 650\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5), sharey=True, gridspec_kw={\"wspace\": 0})\n",
    "ax[0].imshow(obs_set_1[i].permute(1, 2, 0))\n",
    "ax[1].imshow(obs_set_2[j].permute(1, 2, 0))\n",
    "\n",
    "# Hide ticks\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# save image to file\n",
    "# plt.savefig(f\"experiments/plots/{env_id1}_{color1}_{env_id2}_{color2}_frames.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Analysis of the Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reduction(StrEnum):\n",
    "    INDEPENDENT_PCA = auto()\n",
    "    SHARED_PCA = auto()\n",
    "    TSNE = auto()\n",
    "    # UMAP = auto()\n",
    "    FIRST_DIMS = auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "def reduce(\n",
    "    space1: torch.Tensor, space2: torch.Tensor, reduction: Reduction, seed: int = 42\n",
    "):\n",
    "    if reduction == Reduction.INDEPENDENT_PCA:\n",
    "        space1 = PCA(2, random_state=seed).fit_transform(space1)\n",
    "        space2 = PCA(2, random_state=seed).fit_transform(space2)\n",
    "    elif reduction == Reduction.SHARED_PCA:\n",
    "        pca = PCA(2, random_state=seed)\n",
    "        space1 = pca.fit_transform(space1)\n",
    "        space2 = pca.transform(space2)\n",
    "    elif reduction == Reduction.TSNE:\n",
    "        space1 = TSNE(\n",
    "            2, random_state=seed, learning_rate=\"auto\", init=\"pca\"\n",
    "        ).fit_transform(space1)\n",
    "        space2 = TSNE(\n",
    "            2, random_state=seed, learning_rate=\"auto\", init=\"pca\"\n",
    "        ).fit_transform(space2)\n",
    "    elif reduction == Reduction.FIRST_DIMS:\n",
    "        space1 = space1[:, [0, 1]]\n",
    "        space2 = space2[:, [0, 1]]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return space1, space2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_space_grid(\n",
    "    x_header: Sequence[str],\n",
    "    y_header: Sequence[str],\n",
    "    spaces: Sequence[Sequence[np.ndarray]],\n",
    "    c=None,\n",
    "    cmap=CMAP,\n",
    "):\n",
    "    \"\"\"Plots a grid of scatter plots using matplotlib.\n",
    "\n",
    "    Args:\n",
    "        x_header: A sequence of strings for the x-axis labels.\n",
    "        y_header: A sequence of strings for the y-axis labels.\n",
    "        spaces: A sequence of sequences of tensors containing the data to be plotted.\n",
    "        c: Optional. The colors of the plotted points.\n",
    "        cmap: The colormap to use for the plotted points.\n",
    "    Returns:\n",
    "        The figure object representing the complete plot.\n",
    "    \"\"\"\n",
    "    n_rows = len(spaces)\n",
    "    n_cols = len(spaces[0])\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=n_rows, ncols=n_cols, figsize=(n_cols * 5, n_rows * 5)\n",
    "    )\n",
    "\n",
    "    for x, row in zip(x_header, axs):\n",
    "        row[0].set_ylabel(x, rotation=90, size=\"xx-large\")\n",
    "\n",
    "    for y, col in zip(y_header, axs[0]):\n",
    "        col.set_title(y, size=\"xx-large\")\n",
    "\n",
    "    for i, j in itertools.product(range(n_rows), range(n_cols)):\n",
    "        space = spaces[i][j]\n",
    "        assert space.shape[1] == 2\n",
    "        axs[i, j].scatter(x=space[:, 0], y=space[:, 1], c=c, cmap=cmap)\n",
    "\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_header = [reduction.upper() for reduction in Reduction]\n",
    "y_header = [\n",
    "    \"Absolute Space 1\",\n",
    "    \"Absolute Space 2\",\n",
    "    \"Relative Space 1\",\n",
    "    \"Relative Space 2\",\n",
    "]\n",
    "\n",
    "spaces = [\n",
    "    [\n",
    "        *reduce(space1=space1, space2=space2, reduction=reduction),\n",
    "        *reduce(space1=rel_space1, space2=rel_space2, reduction=reduction),\n",
    "    ]\n",
    "    for reduction in Reduction\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = torch.arange(space1.shape[0])\n",
    "# load actions list as labels\n",
    "labels_pth = \"data/actions_lists/CarRacing-v2_actions_4000.pkl\"\n",
    "labels = pickle.load(Path(labels_pth).open(\"rb\"))[:900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_space_grid(x_header=x_header, y_header=y_header, spaces=spaces[:200], c=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projector = RelativeProjector(\n",
    "#     projection_fn=relative.cosine_proj,\n",
    "#     abs_transforms=[Centering(), StandardScaling()],\n",
    "# )\n",
    "# rel_space1 = projector(x=space1, anchors=anchors_space1)\n",
    "\n",
    "# rel_space2 = projector(x=space2, anchors=anchors_space2)\n",
    "\n",
    "\n",
    "translator_ortho = Translator(\n",
    "    aligner=MatrixAligner(name=\"ortho\", align_fn_state=svd_align_state),\n",
    "    x_transform=Centering(),  # StandardScaling(),\n",
    "    y_transform=Centering(),  # StandardScaling(),\n",
    "    dim_matcher=ZeroPadding(),\n",
    ")\n",
    "translator_ortho.fit(x=anchors_space1, y=anchors_space2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space1_transformed1 = translator_ortho.transform(space1)[\"x\"]\n",
    "# transl_space2 = translator_ortho(x=space2, anchors=anchors_space2)\n",
    "space1_transformed1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = (space2 - space1_transformed1).abs().mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = (space2 - space1).abs().mean()\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = F.cosine_similarity(space1_transformed1, space2).mean()\n",
    "print(f\"Cosine similarity: {cos_sim}\")\n",
    "print()\n",
    "\n",
    "cos_sim_original = F.cosine_similarity(space1, space2).mean()\n",
    "print(f\"Cosine similarity: {cos_sim_original}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_limit: int = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the items by class\n",
    "sort_indices: torch.Tensor = labels[:sample_limit].sort().indices\n",
    "abs_space1: torch.Tensor = abs_space1[sort_indices, :]\n",
    "abs_space2: torch.Tensor = abs_space2[sort_indices, :]\n",
    "labels: torch.Tensor = labels[sort_indices]\n",
    "\n",
    "assert abs_space1.shape == abs_space2.shape\n",
    "assert abs_space1.size(0) == labels.size(0)\n",
    "abs_space1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_abs_space1: torch.Tensor = F.normalize(abs_space1, p=2, dim=-1)\n",
    "norm_abs_space2: torch.Tensor = F.normalize(abs_space2, p=2, dim=-1)\n",
    "\n",
    "assert norm_abs_space1.shape == norm_abs_space2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistMethod(StrEnum):\n",
    "    COSINE = auto()\n",
    "    INNER = auto()\n",
    "    MSE = auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import mse_loss, pairwise_distance\n",
    "from torchmetrics.functional import pearson_corrcoef, spearman_corrcoef\n",
    "from torch import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_sim_comparison(\n",
    "    space1: torch.Tensor,\n",
    "    space2: torch.Tensor,\n",
    "    normalize: bool = False,\n",
    "):\n",
    "    if normalize:\n",
    "        space1 = F.normalize(space1, p=2, dim=-1)\n",
    "        space2 = F.normalize(space2, p=2, dim=-1)\n",
    "\n",
    "    self_sim1 = space1 @ space1.T\n",
    "    self_sim2 = space2 @ space2.T\n",
    "\n",
    "    spearman = spearman_corrcoef(self_sim1.T, self_sim2.T)\n",
    "    pearson = pearson_corrcoef(self_sim1.T, self_sim2.T)\n",
    "    cosine = cosine_similarity(self_sim1, self_sim2)\n",
    "\n",
    "    return dict(\n",
    "        spearman_mean=spearman.mean().item(),\n",
    "        spearman_std=spearman.std().item(),\n",
    "        pearson_mean=pearson.mean().item(),\n",
    "        pearson_std=pearson.std().item(),\n",
    "        cosine_mean=cosine.mean().item(),\n",
    "        cosine_std=cosine.std().item(),\n",
    "    )\n",
    "\n",
    "\n",
    "def pairwise_dist(space1: torch.Tensor, space2: torch.Tensor, method: DistMethod):\n",
    "    if method == DistMethod.COSINE:\n",
    "        dists = cosine_similarity(space1, space2)\n",
    "    elif method == DistMethod.INNER:\n",
    "        dists = pairwise_distance(space1, space2, p=2)\n",
    "    elif method == DistMethod.MSE:\n",
    "        dists = mse_loss(space1, space2, reduction=\"none\").mean(dim=1)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return dists\n",
    "\n",
    "\n",
    "def all_dist(space1: torch.Tensor, space2: torch.Tensor, method: DistMethod):\n",
    "    if method == DistMethod.COSINE:\n",
    "        space1 = F.normalize(space1, p=2, dim=-1)\n",
    "        space2 = F.normalize(space2, p=2, dim=-1)\n",
    "        dists = space1 @ space2.T\n",
    "    elif method == DistMethod.INNER:\n",
    "        dists = space1 @ space2.T\n",
    "    elif method == DistMethod.MSE:\n",
    "        dists = ((space1[:, None, :] - space2[None, :, :]) ** 2).mean(dim=-1)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pairwise_dist(space1: torch.Tensor, space2: torch.Tensor, prefix: str):\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=1, ncols=len(DistMethod), figsize=(20, 6), sharey=False\n",
    "    )\n",
    "    for dist_method, ax in zip(DistMethod, axs):\n",
    "        dists = pairwise_dist(space1=space1, space2=space2, method=dist_method)\n",
    "        ax.hist(dists, bins=42)\n",
    "        ax.set_title(f\"{prefix} pairwise similarities ({dist_method})\")\n",
    "        ax.axvline(dists.mean(), color=\"k\", linestyle=\"dashed\", linewidth=1)\n",
    "\n",
    "        min_ylim, max_ylim = ax.get_ylim()\n",
    "        min_xlim, max_xlim = ax.get_xlim()\n",
    "        ax.text(\n",
    "            dists.mean() + (max_xlim - min_xlim) / 20,\n",
    "            max_ylim * 0.95,\n",
    "            \"Mean: {:.2f}\".format(dists.mean()),\n",
    "        )\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_self_dist(space1: torch.Tensor, space2: torch.Tensor, prefix: str):\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=2, ncols=len(DistMethod), figsize=(20, 11), sharey=False\n",
    "    )\n",
    "    for dist_method, ax in zip(DistMethod, axs[0]):\n",
    "        dists = all_dist(space1=space1, space2=space2, method=dist_method)\n",
    "        ax.set_title(f\"{prefix} self-similarities ({dist_method})\")\n",
    "        img = ax.imshow(dists, cmap=CMAP)\n",
    "        plt.colorbar(img, ax=ax)\n",
    "\n",
    "    for dist_method, ax in zip(DistMethod, axs[1]):\n",
    "        dists = all_dist(\n",
    "            space1=F.normalize(space1, p=2, dim=-1),\n",
    "            space2=F.normalize(space2, p=2, dim=-1),\n",
    "            method=dist_method,\n",
    "        )\n",
    "        ax.set_title(f\"L2({prefix}) self-similarities ({dist_method})\")\n",
    "        img = ax.imshow(dists, cmap=CMAP)\n",
    "        plt.colorbar(img, ax=ax)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pairwise_dist(space1=abs_space1, space2=abs_space2, prefix=\"Absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_sim_comparison(space1=abs_space1, space2=abs_space2, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_self_dist(space1=abs_space1, space2=abs_space2, prefix=\"Absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_anchors: int = abs_space1.size(1)\n",
    "\n",
    "seed_everything(42)\n",
    "anchor_idxs = list(range(abs_space1.size(0)))\n",
    "random.shuffle(anchor_idxs)\n",
    "anchor_idxs = anchor_idxs[:num_anchors]\n",
    "\n",
    "space1_anchors = norm_abs_space1[anchor_idxs, :]\n",
    "space2_anchors = norm_abs_space2[anchor_idxs, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_space1 = norm_abs_space1 @ space1_anchors.T\n",
    "rel_space2 = norm_abs_space2 @ space2_anchors.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pairwise_dist(space1=rel_space1, space2=rel_space2, prefix=\"Relative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self_sim_comparison(space1=rel_space1, space2=rel_space2, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_self_dist(space1=rel_space1, space2=rel_space2, prefix=\"Absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reduction(StrEnum):\n",
    "    INDEPENDENT_PCA = auto()\n",
    "    SHARED_PCA = auto()\n",
    "    TSNE = auto()\n",
    "    # UMAP = auto()\n",
    "    FIRST_DIMS = auto()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce(\n",
    "    space1: torch.Tensor, space2: torch.Tensor, reduction: Reduction, seed: int = 42\n",
    "):\n",
    "    if reduction == Reduction.INDEPENDENT_PCA:\n",
    "        space1 = PCA(2, random_state=seed).fit_transform(space1)\n",
    "        space2 = PCA(2, random_state=seed).fit_transform(space2)\n",
    "    elif reduction == Reduction.SHARED_PCA:\n",
    "        pca = PCA(2, random_state=seed)\n",
    "        space1 = pca.fit_transform(space1)\n",
    "        space2 = pca.transform(space2)\n",
    "    elif reduction == Reduction.TSNE:\n",
    "        space1 = TSNE(\n",
    "            2, random_state=seed, learning_rate=\"auto\", init=\"pca\"\n",
    "        ).fit_transform(space1)\n",
    "        space2 = TSNE(\n",
    "            2, random_state=seed, learning_rate=\"auto\", init=\"pca\"\n",
    "        ).fit_transform(space2)\n",
    "    elif reduction == Reduction.FIRST_DIMS:\n",
    "        space1 = space1[:, [0, 1]]\n",
    "        space2 = space2[:, [0, 1]]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return space1, space2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_space_grid(\n",
    "    x_header: Sequence[str],\n",
    "    y_header: Sequence[str],\n",
    "    spaces: Sequence[Sequence[np.ndarray]],\n",
    "    c=None,\n",
    "    cmap=CMAP,\n",
    "):\n",
    "    \"\"\"Plots a grid of scatter plots using matplotlib.\n",
    "\n",
    "    Args:\n",
    "        x_header: A sequence of strings for the x-axis labels.\n",
    "        y_header: A sequence of strings for the y-axis labels.\n",
    "        spaces: A sequence of sequences of tensors containing the data to be plotted.\n",
    "        c: Optional. The colors of the plotted points.\n",
    "        cmap: The colormap to use for the plotted points.\n",
    "    Returns:\n",
    "        The figure object representing the complete plot.\n",
    "    \"\"\"\n",
    "    n_rows = len(spaces)\n",
    "    n_cols = len(spaces[0])\n",
    "\n",
    "    fig, axs = plt.subplots(\n",
    "        nrows=n_rows, ncols=n_cols, figsize=(n_cols * 5, n_rows * 5)\n",
    "    )\n",
    "\n",
    "    for x, row in zip(x_header, axs):\n",
    "        row[0].set_ylabel(x, rotation=90, size=\"xx-large\")\n",
    "\n",
    "    for y, col in zip(y_header, axs[0]):\n",
    "        col.set_title(y, size=\"xx-large\")\n",
    "\n",
    "    for i, j in itertools.product(range(n_rows), range(n_cols)):\n",
    "        space = spaces[i][j]\n",
    "        assert space.shape[1] == 2\n",
    "        axs[i, j].scatter(x=space[:, 0], y=space[:, 1], c=c, cmap=cmap)\n",
    "\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_header = [reduction.upper() for reduction in Reduction]\n",
    "y_header = [\n",
    "    \"Absolute Space 1\",\n",
    "    \"Absolute Space 2\",\n",
    "    \"Relative Space 1\",\n",
    "    \"Relative Space 2\",\n",
    "]\n",
    "\n",
    "spaces = [\n",
    "    [\n",
    "        *reduce(space1=abs_space1, space2=abs_space2, reduction=reduction),\n",
    "        *reduce(space1=rel_space1, space2=rel_space2, reduction=reduction),\n",
    "    ]\n",
    "    for reduction in Reduction\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_space_grid(x_header=x_header, y_header=y_header, spaces=spaces, c=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
