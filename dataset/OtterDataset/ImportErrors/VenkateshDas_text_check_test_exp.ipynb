{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuspell import BertChecker, BertsclstmChecker, SclstmbertChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/text_check/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data folder is set to `/Users/venkateshmurugadas/text_check/neuspell/neuspell/../data` script\n"
     ]
    }
   ],
   "source": [
    "from neuspell import SclstmChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elmoscrnn-probwordnoise created\n",
      "Pretrained model downloading start (may take few seconds to couple of minutes based on download speed) ...\n",
      "Pretrained model download success\n"
     ]
    }
   ],
   "source": [
    "import neuspell\n",
    "\n",
    "neuspell.seq_modeling.downloads.download_pretrained_model('elmoscrnn-probwordnoise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocab from path:/Users/venkateshmurugadas/text_check/neuspell/neuspell/../data/checkpoints/elmoscrnn-probwordnoise/vocab.pkl\n",
      "initializing model\n",
      "Number of parameters in the model: 209906438\n",
      "Loading model params from checkpoint dir: /Users/venkateshmurugadas/text_check/neuspell/neuspell/../data/checkpoints/elmoscrnn-probwordnoise\n"
     ]
    },
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, '<'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m checker \u001b[39m=\u001b[39m SclstmChecker()\n\u001b[0;32m----> 2\u001b[0m checker \u001b[39m=\u001b[39m checker\u001b[39m.\u001b[39;49madd_(\u001b[39m\"\u001b[39;49m\u001b[39melmo\u001b[39;49m\u001b[39m\"\u001b[39;49m, at\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minput\u001b[39;49m\u001b[39m\"\u001b[39;49m)  \u001b[39m# \"elmo\" or \"bert\", \"input\" or \"output\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m checker\u001b[39m.\u001b[39mfrom_pretrained()\n",
      "File \u001b[0;32m~/text_check/neuspell/neuspell/corrector_sclstm.py:70\u001b[0m, in \u001b[0;36mSclstmChecker.add_\u001b[0;34m(self, contextual_model, at)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39melif\u001b[39;00m contextual_model \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbert\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     68\u001b[0m     new_checker_name \u001b[39m=\u001b[39m BertsclstmChecker \u001b[39mif\u001b[39;00m at \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m SclstmbertChecker\n\u001b[0;32m---> 70\u001b[0m new_checker \u001b[39m=\u001b[39m new_checker_name(tokenize\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtokenize,\n\u001b[1;32m     71\u001b[0m                                pretrained\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     72\u001b[0m                                device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     73\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnew model loaded: \u001b[39m\u001b[39m{\u001b[39;00mnew_checker_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     74\u001b[0m \u001b[39mreturn\u001b[39;00m new_checker\n",
      "File \u001b[0;32m~/text_check/neuspell/neuspell/corrector_elmosclstm.py:29\u001b[0m, in \u001b[0;36mElmosclstmChecker.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_module_available(\u001b[39m\"\u001b[39m\u001b[39mallennlp\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m     25\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\n\u001b[1;32m     26\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minstall `allennlp` by running `pip install -r extras-requirements.txt`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee `README.md` for more info.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/text_check/neuspell/neuspell/corrector.py:70\u001b[0m, in \u001b[0;36mCorrector.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mpretrained\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_pretrained(ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n",
      "File \u001b[0;32m~/text_check/neuspell/neuspell/corrector.py:140\u001b[0m, in \u001b[0;36mCorrector.from_pretrained\u001b[0;34m(self, ckpt_path, vocab_path, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_pretrained\u001b[39m(\u001b[39mself\u001b[39m, ckpt_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, vocab_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_from_pretrained(ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, vocab_path\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/text_check/neuspell/neuspell/corrector.py:135\u001b[0m, in \u001b[0;36mCorrector._from_pretrained\u001b[0;34m(self, ckpt_path, vocab_path)\u001b[0m\n\u001b[1;32m    132\u001b[0m     download_pretrained_model(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mckpt_path)\n\u001b[1;32m    134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_output_vocab(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab_path)\n\u001b[0;32m--> 135\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_model(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    137\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/text_check/neuspell/neuspell/corrector_elmosclstm.py:34\u001b[0m, in \u001b[0;36mElmosclstmChecker.load_model\u001b[0;34m(self, ckpt_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minitializing model\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m initialized_model \u001b[39m=\u001b[39m load_model(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvocab)\n\u001b[0;32m---> 34\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m load_pretrained(initialized_model, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path, device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n",
      "File \u001b[0;32m~/text_check/neuspell/neuspell/seq_modeling/elmosclstm.py:99\u001b[0m, in \u001b[0;36mload_pretrained\u001b[0;34m(model, checkpoint_path, optimizer, device)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoading model params from checkpoint dir: \u001b[39m\u001b[39m{\u001b[39;00mcheckpoint_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     98\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     checkpoint_data \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(checkpoint_path, \u001b[39m\"\u001b[39;49m\u001b[39mpytorch_model.bin\u001b[39;49m\u001b[39m\"\u001b[39;49m), map_location\u001b[39m=\u001b[39;49mmap_location)\n\u001b[1;32m    100\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m    101\u001b[0m     download_pretrained_model(checkpoint_path)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/text_check/lib/python3.8/site-packages/torch/serialization.py:713\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    711\u001b[0m             \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39mload(opened_file)\n\u001b[1;32m    712\u001b[0m         \u001b[39mreturn\u001b[39;00m _load(opened_zipfile, map_location, pickle_module, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_load_args)\n\u001b[0;32m--> 713\u001b[0m \u001b[39mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/text_check/lib/python3.8/site-packages/torch/serialization.py:920\u001b[0m, in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(f, \u001b[39m'\u001b[39m\u001b[39mreadinto\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m (\u001b[39m3\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mversion_info \u001b[39m<\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m8\u001b[39m, \u001b[39m2\u001b[39m):\n\u001b[1;32m    915\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtorch.load does not work with file-like objects that do not implement readinto on Python 3.8.0 and 3.8.1. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived object of type \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(f)\u001b[39m}\u001b[39;00m\u001b[39m\\\"\u001b[39;00m\u001b[39m. Please update to Python 3.8.2 or newer to restore this \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    918\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mfunctionality.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 920\u001b[0m magic_number \u001b[39m=\u001b[39m pickle_module\u001b[39m.\u001b[39;49mload(f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_load_args)\n\u001b[1;32m    921\u001b[0m \u001b[39mif\u001b[39;00m magic_number \u001b[39m!=\u001b[39m MAGIC_NUMBER:\n\u001b[1;32m    922\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInvalid magic number; corrupt file?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mUnpicklingError\u001b[0m: invalid load key, '<'."
     ]
    }
   ],
   "source": [
    "checker = SclstmChecker()\n",
    "checker = checker.add_(\"elmo\", at=\"input\")  # \"elmo\" or \"bert\", \"input\" or \"output\"\n",
    "checker.from_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocab from path:/Users/venkateshmurugadas/text_check/neuspell/neuspell/../data/checkpoints/scrnnbert-probwordnoise/vocab.pkl\n",
      "initializing model\n",
      "Number of parameters in the model: 297224867\n",
      "Loading model params from checkpoint dir: /Users/venkateshmurugadas/text_check/neuspell/neuspell/../data/checkpoints/scrnnbert-probwordnoise\n"
     ]
    }
   ],
   "source": [
    "# spell_checker = BertChecker()\n",
    "spell_checker = SclstmbertChecker()\n",
    "# spell_checker = BertsclstmChecker()\n",
    "spell_checker.from_pretrained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spelling errors found\n",
      "Original text: You will receive the following: the Enron negotiated rate structure and profiles for consultants that could start immediately.\n",
      "Suggested text: You will receive the following : the Enron negotiated rate structure and profiles for consultants that could start immediately .\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"You will receive the following: the Enron negotiated rate structure and profiles for consultants that could start immediately.\"\"\"\n",
    "spell_checker.correct(text)\n",
    "\n",
    "sugg = spell_checker.correct(text)\n",
    "\n",
    "if text == sugg:\n",
    "    print('No spelling errors found')\n",
    "else:\n",
    "    print('Spelling errors found')\n",
    "    print(f'Original text: {text}')\n",
    "    print(f'Suggested text: {sugg}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "import contextualSpellCheck\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "contextualSpellCheck.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spelling errors found\n",
      "Spelling check done by contextualSpellCheck True\n",
      "Original text: Futhermore , a tour guide will also provide safety and security for travel , since they already know the dos and don'ts of the tour .\n",
      "Suggested text: Furthermore, a tour guide will also provide safety and security for travel, since they already know the dos and dos of the tour.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Futhermore , a tour guide will also provide safety and security for travel , since they already know the dos and don'ts of the tour .\"\"\"\n",
    "\n",
    "doc = nlp(text)\n",
    "sugg = doc._.outcome_spellCheck\n",
    "\n",
    "if text == sugg:\n",
    "    print('No spelling errors found')\n",
    "else:\n",
    "    print('Spelling errors found')\n",
    "    print('Spelling check done by contextualSpellCheck', doc._.performed_spellCheck)\n",
    "    print(f'Original text: {text}')\n",
    "    print(f'Suggested text: {sugg}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original text: Virtual Quill provides you with \"words to sell by...\" Find out more at http:[www.vquill.com/](http://www.vquill.com/) or by e-mail at **mailto**: Register your company on Buy IT, NW Fusion's Vendor Directory and RFP Center and generate new business quick and easy!\n",
      "corrected text: Virtual Quill provides you with \"words to sell by...\" Mind out more at http:[www.quill.com/](http://www.quill.com/) or by e-mail at **mail**: Register your company on Buy of, of Fusion's Vendor Directory and RFP Enter and generate new business quick and easy!\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "a = \"\"\"Virtual Quill provides you with \"words to sell by...\" Find out more at http:[www.vquill.com/](http://www.vquill.com/) or by e-mail at **mailto**: Register your company on Buy IT, NW Fusion's Vendor Directory and RFP Center and generate new business quick and easy!\"\"\"\t\t # incorrect spelling\n",
    "print(\"original text: \"+str(a))\n",
    "\n",
    "b = TextBlob(a)\n",
    "\n",
    "# prints the corrected spelling\n",
    "print(\"corrected text: \"+str(b.correct()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/venkateshmurugadas/text_check\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/text_check/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from gramformer.gramformer import Gramformer\n",
    "import torch\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gramformer] Grammar error correct/highlight model loaded..\n",
      "[Input]  Virtual Quill provides you with \"words to sell by...\" Find out more at http:[www.vquill.com/](http://www.vquill.com/) or by e-mail at **mailto**: Register your company on Buy IT, NW Fusion's Vendor Directory and RFP Center and generate new business quick and easy!\n",
      "[Output]  Virtual Quill provides you with \"words to sell by...\" Find out more at http://www.vquill.com/(http://www.vquill.com/) or by e-mail at **mailto**. Register your company on Buy IT, NW Fusion's Ven\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  Futhermore , a tour guide will also provide safety and security for travel , since they already know the dos and don'ts of the tour .\n",
      "[Output]  Futhermore, a tour guide will also provide safety and security for travel, since they already know the dos and don'ts of the tour.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  You will receive the following: the Enron negotiated rate structure and profiles for consultants that could starrt immedeiately.\n",
      "[Output]  You will receive the following: the Enron negotiated rate structure and profiles for consultants that could start immediately.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  There's a preference for a move towards \"TLS everywhere\" but of a CP a solution is needed that tells a client in advance to visit the login page first.\n",
      "[Output]  There's a preference for a move towards \"TLS everywhere\" but for a CP a solution is needed that tells a client in advance to visit the login page first.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  With that done, everything is ready to move onto the discussions on the data and platforming some portion of the Enron technology on CreditDimensions.\n",
      "[Output]  With that done, everything is ready to move onto the discussions on the data and platforming portion of the Enron technology on CreditDimensions.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  The technical benefits brought by BIERv6; After all the updates , it seems the document is ready for WG adoption.\n",
      "[Output]  The technical benefits brought by BIERv6. After all the updates, it seems the document is ready for WG adoption.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  APX's \"flowgate\" model is included, which has some intriquing characteristics and with some slight supporting modifications (it's very close to the proposal, and may be easier to use in a world with more parallel flows than there are today) If you want more, more, MORE go to the ISO web site (caiso.com) then to Client Services, then to congestion reform, to see all the gory detail.\n",
      "[Output]  APX's \"flowgate\" model is included, which has some interesting characteristics and with some slight supporting modifications (it's very close to the proposal, and may be easier to use in a world with more parallel flows than there are today). If you want more, more, MORE go to\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  The new RAC website and PortRAC system will valuable tools to help manage the business. You can get a personal demo before the introduction of these applications to a broader population.\n",
      "[Output]  The new RAC website and PortRAC system will provide valuable tools to help manage the business. You can get a personal demo before the introduction of these applications to the broader population.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Input]  Ok, it will be necessary to re-read to solidify the context of these documents ;-) occurances of EST Server have been changed to \"BRSKI Registrar\" to be more accurate.\n",
      "[Output]  Ok, it will be necessary to re-read to solidify the context of these documents ;-) occurrences of EST Server have been changed to \"BRSKI Registrar\" to be more accurate.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def set_seed(seed):\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(1214)\n",
    "\n",
    "\n",
    "gf = Gramformer(models = 1, use_gpu=False) # 1=corrector, 2=detector\n",
    "\n",
    "influent_sentences = [\n",
    "    '''Virtual Quill provides you with \"words to sell by...\" Find out more at http:[www.vquill.com/](http://www.vquill.com/) or by e-mail at **mailto**: Register your company on Buy IT, NW Fusion's Vendor Directory and RFP Center and generate new business quick and easy!''',\n",
    "    '''Futhermore , a tour guide will also provide safety and security for travel , since they already know the dos and don'ts of the tour .''',\n",
    "    '''You will receive the following: the Enron negotiated rate structure and profiles for consultants that could starrt immedeiately.''',\n",
    "    '''There's a preference for a move towards \"TLS everywhere\" but of a CP a solution is needed that tells a client in advance to visit the login page first.''',\n",
    "    '''With that done, everything is ready to move onto the discussions on the data and platforming some portion of the Enron technology on CreditDimensions.''',\n",
    "    '''The technical benefits brought by BIERv6; After all the updates , it seems the document is ready for WG adoption.''',\n",
    "    '''APX's \"flowgate\" model is included, which has some intriquing characteristics and with some slight supporting modifications (it's very close to the proposal, and may be easier to use in a world with more parallel flows than there are today) If you want more, more, MORE go to the ISO web site (caiso.com) then to Client Services, then to congestion reform, to see all the gory detail.''',\n",
    "    '''The new RAC website and PortRAC system will valuable tools to help manage the business. You can get a personal demo before the introduction of these applications to a broader population.''',\n",
    "    '''Ok, it will be necessary to re-read to solidify the context of these documents ;-) occurances of EST Server have been changed to \"BRSKI Registrar\" to be more accurate.''',\n",
    "]   \n",
    "\n",
    "for influent_sentence in influent_sentences:\n",
    "    corrected_sentences = gf.correct(influent_sentence, max_candidates=1)\n",
    "    if list(corrected_sentences)[0] != influent_sentence:\n",
    "        print(\"[Input] \", influent_sentence)\n",
    "        print(\"[Output] \", list(corrected_sentences)[0])\n",
    "        # b = TextBlob(list(corrected_sentences)[0])\n",
    "\n",
    "        # # prints the corrected spelling\n",
    "        # print(\"spell corrected text: \"+str(b.correct()))\n",
    "    # for corrected_sentence in corrected_sentences:\n",
    "    #   print(\"[Correction] \",corrected_sentence)\n",
    "        print(\"-\" *100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('text_check')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d396a286edb21c6134599b1a5bcec52c845f570a83527a3ac51c00864d53603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
