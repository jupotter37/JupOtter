{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'cascade_mask_rcnn_tiny.py'\n",
    "foler_name = 'htc_swin_tiny_patch4_adamw_1x_coco'\n",
    "epoch = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/code/mmdetection_trash\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-19 07:42:01,298 - mmdet - INFO - Environment info:\n",
      "------------------------------------------------------------\n",
      "sys.platform: linux\n",
      "Python: 3.7.7 (default, May  7 2020, 21:25:33) [GCC 7.3.0]\n",
      "CUDA available: True\n",
      "GPU 0: Tesla P40\n",
      "CUDA_HOME: None\n",
      "GCC: gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
      "PyTorch: 1.6.0\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v1.5.0 (Git Hash e2ac1fac44c5078ca927cb9b90e1b3066a0b2ed0)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 10.1\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 7.6.3\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_VULKAN_WRAPPER -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, \n",
      "\n",
      "TorchVision: 0.7.0\n",
      "OpenCV: 4.5.2\n",
      "MMCV: 1.3.3\n",
      "MMCV Compiler: GCC 7.3\n",
      "MMCV CUDA Compiler: 10.1\n",
      "MMDetection: 2.11.0+b42c9ce\n",
      "------------------------------------------------------------\n",
      "\n",
      "2021-05-19 07:42:05,288 - mmdet - INFO - Distributed training: False\n",
      "2021-05-19 07:42:09,631 - mmdet - INFO - Config:\n",
      "model = dict(\n",
      "    type='CascadeRCNN',\n",
      "    pretrained=None,\n",
      "    backbone=dict(\n",
      "        type='SwinTransformer',\n",
      "        embed_dim=128,\n",
      "        depths=[2, 2, 18, 2],\n",
      "        num_heads=[4, 8, 16, 32],\n",
      "        window_size=7,\n",
      "        mlp_ratio=4.0,\n",
      "        qkv_bias=True,\n",
      "        qk_scale=None,\n",
      "        drop_rate=0.0,\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.3,\n",
      "        ape=False,\n",
      "        patch_norm=True,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        use_checkpoint=False),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[128, 256, 512, 1024],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(\n",
      "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='CascadeRoIHead',\n",
      "        num_stages=3,\n",
      "        stage_loss_weights=[1, 0.5, 0.25],\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                type='ConvFCBBoxHead',\n",
      "                num_shared_convs=4,\n",
      "                num_shared_fcs=1,\n",
      "                in_channels=256,\n",
      "                conv_out_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=11,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "                reg_class_agnostic=False,\n",
      "                reg_decoded_bbox=True,\n",
      "                norm_cfg=dict(type='BN', requires_grad=True),\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='GIoULoss', loss_weight=10.0)),\n",
      "            dict(\n",
      "                type='ConvFCBBoxHead',\n",
      "                num_shared_convs=4,\n",
      "                num_shared_fcs=1,\n",
      "                in_channels=256,\n",
      "                conv_out_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=11,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n",
      "                reg_class_agnostic=False,\n",
      "                reg_decoded_bbox=True,\n",
      "                norm_cfg=dict(type='BN', requires_grad=True),\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='GIoULoss', loss_weight=10.0)),\n",
      "            dict(\n",
      "                type='ConvFCBBoxHead',\n",
      "                num_shared_convs=4,\n",
      "                num_shared_fcs=1,\n",
      "                in_channels=256,\n",
      "                conv_out_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                roi_feat_size=7,\n",
      "                num_classes=11,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n",
      "                reg_class_agnostic=False,\n",
      "                reg_decoded_bbox=True,\n",
      "                norm_cfg=dict(type='BN', requires_grad=True),\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='GIoULoss', loss_weight=10.0))\n",
      "        ],\n",
      "        mask_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        mask_head=dict(\n",
      "            type='FCNMaskHead',\n",
      "            num_convs=4,\n",
      "            in_channels=256,\n",
      "            conv_out_channels=256,\n",
      "            num_classes=11,\n",
      "            loss_mask=dict(\n",
      "                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=0,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_across_levels=False,\n",
      "            nms_pre=2000,\n",
      "            nms_post=2000,\n",
      "            max_per_img=2000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    min_pos_iou=0.6,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    min_pos_iou=0.7,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                mask_size=28,\n",
      "                pos_weight=-1,\n",
      "                debug=False)\n",
      "        ]),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_across_levels=False,\n",
      "            nms_pre=1000,\n",
      "            nms_post=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='soft_nms', iou_threshold=0.4),\n",
      "            min_bbox_size=20),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='soft_nms', iou_threshold=0.5),\n",
      "            max_per_img=100,\n",
      "            mask_thr_binary=0.5)))\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = '../../input/data/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='AutoAugment',\n",
      "        policies=[[{\n",
      "            'type':\n",
      "            'Resize',\n",
      "            'img_scale': [(480, 1333), (512, 1333), (544, 1333), (576, 1333),\n",
      "                          (608, 1333), (640, 1333), (672, 1333), (704, 1333),\n",
      "                          (736, 1333), (768, 1333), (800, 1333)],\n",
      "            'multiscale_mode':\n",
      "            'value',\n",
      "            'keep_ratio':\n",
      "            True\n",
      "        }],\n",
      "                  [{\n",
      "                      'type': 'Resize',\n",
      "                      'img_scale': [(400, 1333), (500, 1333), (600, 1333)],\n",
      "                      'multiscale_mode': 'value',\n",
      "                      'keep_ratio': True\n",
      "                  }, {\n",
      "                      'type': 'RandomCrop',\n",
      "                      'crop_type': 'absolute_range',\n",
      "                      'crop_size': (400, 400),\n",
      "                      'allow_negative_crop': True\n",
      "                  }, {\n",
      "                      'type':\n",
      "                      'Resize',\n",
      "                      'img_scale': [(480, 1333), (512, 1333), (544, 1333),\n",
      "                                    (576, 1333), (608, 1333), (640, 1333),\n",
      "                                    (672, 1333), (704, 1333), (736, 1333),\n",
      "                                    (768, 1333), (800, 1333)],\n",
      "                      'multiscale_mode':\n",
      "                      'value',\n",
      "                      'override':\n",
      "                      True,\n",
      "                      'keep_ratio':\n",
      "                      True\n",
      "                  }]]),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(512, 512),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "classes = ('UNKNOWN', 'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass',\n",
      "           'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing')\n",
      "data = dict(\n",
      "    samples_per_gpu=4,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        classes=('UNKNOWN', 'General trash', 'Paper', 'Paper pack', 'Metal',\n",
      "                 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery',\n",
      "                 'Clothing'),\n",
      "        ann_file='../../input/data/train_data0.json',\n",
      "        img_prefix='../../input/data/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='AutoAugment',\n",
      "                policies=[[{\n",
      "                    'type':\n",
      "                    'Resize',\n",
      "                    'img_scale': [(480, 1333), (512, 1333), (544, 1333),\n",
      "                                  (576, 1333), (608, 1333), (640, 1333),\n",
      "                                  (672, 1333), (704, 1333), (736, 1333),\n",
      "                                  (768, 1333), (800, 1333)],\n",
      "                    'multiscale_mode':\n",
      "                    'value',\n",
      "                    'keep_ratio':\n",
      "                    True\n",
      "                }],\n",
      "                          [{\n",
      "                              'type': 'Resize',\n",
      "                              'img_scale': [(400, 1333), (500, 1333),\n",
      "                                            (600, 1333)],\n",
      "                              'multiscale_mode': 'value',\n",
      "                              'keep_ratio': True\n",
      "                          }, {\n",
      "                              'type': 'RandomCrop',\n",
      "                              'crop_type': 'absolute_range',\n",
      "                              'crop_size': (400, 400),\n",
      "                              'allow_negative_crop': True\n",
      "                          }, {\n",
      "                              'type':\n",
      "                              'Resize',\n",
      "                              'img_scale': [(480, 1333), (512, 1333),\n",
      "                                            (544, 1333), (576, 1333),\n",
      "                                            (608, 1333), (640, 1333),\n",
      "                                            (672, 1333), (704, 1333),\n",
      "                                            (736, 1333), (768, 1333),\n",
      "                                            (800, 1333)],\n",
      "                              'multiscale_mode':\n",
      "                              'value',\n",
      "                              'override':\n",
      "                              True,\n",
      "                              'keep_ratio':\n",
      "                              True\n",
      "                          }]]),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(\n",
      "                type='Collect',\n",
      "                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        classes=('UNKNOWN', 'General trash', 'Paper', 'Paper pack', 'Metal',\n",
      "                 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery',\n",
      "                 'Clothing'),\n",
      "        ann_file='../../input/data/valid_data0.json',\n",
      "        img_prefix='../../input/data/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(512, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        classes=('UNKNOWN', 'General trash', 'Paper', 'Paper pack', 'Metal',\n",
      "                 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery',\n",
      "                 'Clothing'),\n",
      "        ann_file='../../input/data/test.json',\n",
      "        img_prefix='../../input/data/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(512, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=0.0001,\n",
      "    betas=(0.9, 0.999),\n",
      "    weight_decay=0.05,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            absolute_pos_embed=dict(decay_mult=0.0),\n",
      "            relative_position_bias_table=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0))))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=5,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[10, 15, 20, 25])\n",
      "runner = dict(type='EpochBasedRunnerAmp', max_epochs=36)\n",
      "fp16 = None\n",
      "optimizer_config = dict(\n",
      "    type='DistOptimizerHook',\n",
      "    update_interval=1,\n",
      "    grad_clip=None,\n",
      "    coalesce=True,\n",
      "    bucket_size_mb=-1,\n",
      "    use_fp16=True)\n",
      "checkpoint_config = dict(max_keep_ckpts=1, interval=1)\n",
      "evaluation = dict(interval=1, metric='bbox', save_best='bbox_mAP_50')\n",
      "log_config = dict(\n",
      "    interval=50,\n",
      "    hooks=[\n",
      "        dict(type='TextLoggerHook'),\n",
      "        dict(\n",
      "            type='WandbLoggerHook',\n",
      "            init_kwargs=dict(\n",
      "                project='Project3_object_detection',\n",
      "                name='htc_swin_base_patch4_adamw_3x_v3'))\n",
      "    ])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = '/opt/ml/code/mmdetection_trash/swin_ckpt/cascade_mask_rcnn_swin_base_patch4.pth'\n",
      "resume_from = '/opt/ml/code/mmdetection_trash/work_dirs/htc_swin_base_patch4_adamw_3x_v3/epoch_28.pth'\n",
      "workflow = [('train', 1)]\n",
      "work_dir = './work_dirs/htc_swin_base_patch4_adamw_3x_v3'\n",
      "gpu_ids = range(0, 1)\n",
      "\n",
      "2021-05-19 07:42:09,631 - mmdet - INFO - Set random seed to 42, deterministic: False\n",
      "loading annotations into memory...\n",
      "Done (t=3.16s)\n",
      "creating index...\n",
      "index created!\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n",
      "loading annotations into memory...\n",
      "Done (t=0.75s)\n",
      "creating index...\n",
      "index created!\n",
      "2021-05-19 07:42:22,392 - mmdet - INFO - load checkpoint from /opt/ml/code/mmdetection_trash/work_dirs/htc_swin_base_patch4_adamw_3x_v3/epoch_28.pth\n",
      "2021-05-19 07:42:22,392 - mmdet - INFO - Use load_from_local loader\n",
      "Traceback (most recent call last):\n",
      "  File \"tools/train.py\", line 187, in <module>\n",
      "    main()\n",
      "  File \"tools/train.py\", line 183, in main\n",
      "    meta=meta)\n",
      "  File \"/opt/ml/code/Swin-Transformer-Object-Detection/mmdet/apis/train.py\", line 182, in train_detector\n",
      "    runner.resume(cfg.resume_from)\n",
      "  File \"/opt/ml/code/Swin-Transformer-Object-Detection/mmcv_custom/runner/epoch_based_runner.py\", line 79, in resume\n",
      "    map_location=lambda storage, loc: storage.cuda(device_id))\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/base_runner.py\", line 322, in load_checkpoint\n",
      "    revise_keys=revise_keys)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/checkpoint.py\", line 529, in load_checkpoint\n",
      "    checkpoint = _load_checkpoint(filename, map_location, logger)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/checkpoint.py\", line 467, in _load_checkpoint\n",
      "    return CheckpointLoader.load_checkpoint(filename, map_location, logger)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/checkpoint.py\", line 244, in load_checkpoint\n",
      "    return checkpoint_loader(filename, map_location)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/runner/checkpoint.py\", line 260, in load_from_local\n",
      "    raise IOError(f'{filename} is not a checkpoint file')\n",
      "OSError: /opt/ml/code/mmdetection_trash/work_dirs/htc_swin_base_patch4_adamw_3x_v3/epoch_28.pth is not a checkpoint file\n"
     ]
    }
   ],
   "source": [
    "!python tools/train.py configs/trash/swin/cascade_fold.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"tools/test.py\", line 220, in <module>\n",
      "    main()\n",
      "  File \"tools/test.py\", line 116, in main\n",
      "    cfg = Config.fromfile(args.config)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/utils/config.py\", line 252, in fromfile\n",
      "    use_predefined_variables)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/utils/config.py\", line 124, in _file2dict\n",
      "    check_file_exist(filename)\n",
      "  File \"/opt/conda/lib/python3.7/site-packages/mmcv/utils/path.py\", line 23, in check_file_exist\n",
      "    raise FileNotFoundError(msg_tmpl.format(filename))\n",
      "FileNotFoundError: file \"/opt/ml/code/mmdetection_trash/fconfigs/trash/swin/{file_name}\" does not exist\n"
     ]
    }
   ],
   "source": [
    "!python tools/test.py configs/trash/swin/'{file_name}' work_dirs/'{folder_name}'/best_bbox_mAP_50.pth --out work_dirs/'{folder_name}'/best_bbox_mAP_50.pkl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python pkl_to_submission_htc.py --pkl work_dirs/f'{folder_name}'/epoch15.pkl --csv submission.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
