{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization.textcleaner import split_sentences\n",
    "import re\n",
    "\n",
    "#reg_ex = r'[^a-zA-Z]'\n",
    "#replace = ' '\n",
    "piece = input(\"Enter text to be summarized: \").replace('\\n', ' ').replace('\\r', ' ')\n",
    "#piece = input(\"Enter text to be summarized: \").replace('\\n\\r', ' ').strip()\n",
    "#piece = piece.replace(reg_ex, replace)\n",
    "piece = re.sub(' +', ' ', piece)\n",
    "#print(split_sentences(piece))\n",
    "#comp_df.apply(lambda t: ' '.join([wordnet_lemmatizer.lemmatize(w) for w in t.split()])).str.lower()\n",
    "print('++++++++++++++++++++++++++++++++++++++')\n",
    "print(summarize(piece, ratio=0.4)) # high enough for abstracts with longer sentences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another summarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "def _create_frequency_table(text_string) -> dict:\n",
    "\n",
    "    stopWords = set(stopwords.words(\"english\"))\n",
    "    words = word_tokenize(text_string)\n",
    "    ps = PorterStemmer()\n",
    "\n",
    "    freqTable = dict()\n",
    "    for word in words:\n",
    "        word = ps.stem(word)\n",
    "        if word in stopWords:\n",
    "            continue\n",
    "        if word in freqTable:\n",
    "            freqTable[word] += 1\n",
    "        else:\n",
    "            freqTable[word] = 1\n",
    "\n",
    "    return freqTable\n",
    "\n",
    "def _score_sentences(sentences, freqTable) -> dict:\n",
    "    sentenceValue = dict()\n",
    "\n",
    "    for sentence in sentences:\n",
    "        word_count_in_sentence = (len(word_tokenize(sentence)))\n",
    "        for wordValue in freqTable:\n",
    "            if wordValue in sentence.lower():\n",
    "                if sentence[:10] in sentenceValue:\n",
    "                    sentenceValue[sentence[:10]] += freqTable[wordValue]\n",
    "                else:\n",
    "                    sentenceValue[sentence[:10]] = freqTable[wordValue]\n",
    "\n",
    "        sentenceValue[sentence[:10]] = sentenceValue[sentence[:10]] // word_count_in_sentence\n",
    "\n",
    "    return sentenceValue\n",
    "\n",
    "def _find_average_score(sentenceValue) -> int:\n",
    "    sumValues = 0\n",
    "    for entry in sentenceValue:\n",
    "        sumValues += sentenceValue[entry]\n",
    "\n",
    "    # Average value of a sentence from original text\n",
    "    average = int(sumValues / len(sentenceValue))\n",
    "\n",
    "    return average\n",
    "\n",
    "def _generate_summary(sentences, sentenceValue, threshold):\n",
    "    sentence_count = 0\n",
    "    summary = ''\n",
    "\n",
    "    for sentence in sentences:\n",
    "        if sentence[:10] in sentenceValue and sentenceValue[sentence[:10]] > (threshold):\n",
    "            summary += \" \" + sentence\n",
    "            sentence_count += 1\n",
    "\n",
    "    return summary\n",
    "\n",
    "text = '''Purpose To evaluate moderate (grade 2, hemoglobin <10 g/dl) and severe\n",
    "    (grade 3+, hemoglobin <8 g/dl) anemia as potential risk factors for DDR in the\n",
    "    first line course of chemotherapy. While chemotherapy-induced neutropenia has been\n",
    "    shown to be associated with dose delay/reduction (DDR) in several studies, the effect\n",
    "    of anemia is less well studied. Methods We identified 3955 Kaiser Permanente patients\n",
    "    diagnosed with incident non-Hodgkin’s lymphoma (n = 574), breast (n = 2043), lung (n = 463),\n",
    "    gastric (n = 113), ovarian (n = 204), or colorectal cancers (n = 558) between 2010 and 2012.\n",
    "    Generalized linear mixed effects models were used to study the effect of anemia in subsequent\n",
    "    cycles, adjusting for demographics, comorbidities, chemotherapy cycle, neutropenia, thrombocytopenia,\n",
    "    and liver and renal function. Results We found that moderate (grade 2) to severe (grade 3–4)\n",
    "    anemia increased the risk of DDR in subsequent chemotherapy cycles [odds ratio (OR) = 1.46,\n",
    "    95 % CI (1.32, 1.62) and OR = 2.02 (1.41, 2.89)], respectively, compared to grade 1 or no anemia.\n",
    "    Both stage I–III and IV patients with grade 2 or greater anemia were at higher risk for DDR than\n",
    "    patients with grade 1 or no anemia [ORstage IV, grade 2 = 1.94 (1.58, 2.38); ORstage IV,\n",
    "    grade 3/4 = 2.83 (1.42, 5.62) and ORstage I–III, grade 2 = 1.33 (1.18, 1.49); ORstage I–III,\n",
    "    grade 3–4 = 1.81 (1.18, 2.76)]. Conclusions These results provide insight into novel risk factors\n",
    "    for chemotherapy dose modification that may inform clinicians on management strategies\n",
    "    to optimize treatment outcomes.'''\n",
    "\n",
    "# 1 Create the word frequency table\n",
    "freq_table = _create_frequency_table(text)\n",
    "\n",
    "'''\n",
    "We already have a sentence tokenizer, so we just need \n",
    "to run the sent_tokenize() method to create the array of sentences.\n",
    "'''\n",
    "\n",
    "# 2 Tokenize the sentences\n",
    "sentences = sent_tokenize(text)\n",
    "\n",
    "# 3 Important Algorithm: score the sentences\n",
    "sentence_scores = _score_sentences(sentences, freq_table)\n",
    "\n",
    "# 4 Find the threshold\n",
    "threshold = _find_average_score(sentence_scores)\n",
    "\n",
    "# 5 Important Algorithm: Generate the summary\n",
    "summary = _generate_summary(sentences, sentence_scores, 2.8 * threshold) # the higher the multiplier the shorter\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 3: read study protocol and summarize\n",
    "from gensim.summarization.summarizer import summarize\n",
    "import os\n",
    "import PyPDF2\n",
    "import re\n",
    "#import subprocess\n",
    "\n",
    "def read1k():\n",
    "    return f.read(1024)\n",
    "\n",
    "def read_in_chunks(infile, chunk_size=1024*64):\n",
    "    '''read file in chunks via iterator'''\n",
    "    chunk = infile.read(chunk_size)\n",
    "    while chunk:\n",
    "        yield chunk\n",
    "        chunk = infile.read(chunk_size)\n",
    "\n",
    "def process_data(chunk, text):\n",
    "    text.append(str(chunk)) # 'utf8' codec can't decode byte 0xc3\n",
    "\n",
    "def loadids():\n",
    "    '''load id-title list'''\n",
    "    with open('bsc_idlst0.txt', encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def chunks(l, n):\n",
    "    '''Yield successive n-sized chunks from list l'''\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n] # returns a generator\n",
    "\n",
    "def chunksep(l, s):\n",
    "    '''Yield successive chunks from list l separated by s'''\n",
    "    g = []\n",
    "    for el in l:\n",
    "        if el == s:\n",
    "            yield g\n",
    "            g = []\n",
    "        g.append(el)\n",
    "    yield g\n",
    "\n",
    "def __unicode__(self):\n",
    "    return unicode(self.some_field) or u''\n",
    "\n",
    "def save_corpus(txt): # save corpus\n",
    "    # save corpus as separate file\n",
    "    os.chdir(r'C:\\Users\\Bernie\\Documents\\ML4D\\lrgtxt0') # change this directory to save to a different location\n",
    "    fout = open('bsc_pdf_corpus0.txt', 'w')\n",
    "    fout.write(txt) # requires a string\n",
    "    fout.close()\n",
    "\n",
    "def main():\n",
    "    #os.chdir(r'C:\\Users\\bscho\\Desktop\\NVS StudPro Summ') # all pdf-files in this directory will be processed\n",
    "    # get all pdf filenames\n",
    "    #pdfFiles = []\n",
    "    #for filename in os.listdir('.'):\n",
    "        #if filename.endswith('.pdf'):\n",
    "            #pdfFiles.append(filename)\n",
    "    #pdfFiles.sort(key = str.lower)\n",
    "    \n",
    "    #subprocess.call(['pdftotext', 'forms.pdf', 'output'])\n",
    "    \n",
    "    #outtext = ''\n",
    "    #print(pdfFiles)\n",
    "    #for pdfFileObj in pdfFiles:\n",
    "        #pdfReader = PyPDF2.PdfFileReader(pdfFileObj)\n",
    "        #npgs = pdfReader.numPages\n",
    "        ##print('pages read:', npgs)\n",
    "        #for i in range(npgs):\n",
    "            #pageObj = pdfReader.getPage(i) # get a page object (pages are 0-based)\n",
    "            #print(pageObj.extractText()[:20]) # get the text\n",
    "            #outtext += str(pageObj.extractText().encode('utf-8'))\n",
    "            #outtext += pageObj.extractText()\n",
    "    #print(outtext[:500])\n",
    "    #save_corpus(outtext)\n",
    "    #print('%s' % (summarize(corpus[atxidx:nxtid]))) # auto-summarize results\n",
    "    \n",
    "    summratio = 0.25 # summary ratio for auto-summarizer\n",
    "    \n",
    "    os.chdir(r'C:\\Users\\bscho\\Desktop\\NVS StudPro Summ') # change this directory to save to a different location\n",
    "    fin = open('studsumm0 raw.txt', encoding=\"utf-8\")\n",
    "    \n",
    "    # chapter headings: match newline - number - whitespaces - title\n",
    "    chptr_plst = ['\\s\\d+\\s+Introduction\\s', '\\s\\d+\\s+Objectives and endpoints', '\\s\\d+\\s+Study design', '\\s\\d+\\s+Rationale'\\\n",
    "                  , '\\s\\d+\\s+Population', '\\s\\d+\\s+Treatment', '\\s\\d+\\s+Informed consent procedures'\\\n",
    "                  , '\\s\\d+\\s+Visit schedule and assessments', '\\s\\d+\\s+Study discontinuation and completion'\\\n",
    "                  , '\\s\\d+\\s+Safety monitoring and reporting', '\\s\\d+\\s+Data Collection and Database management'\\\n",
    "                  , '\\s\\d+\\s+Data analysis and statistical methods'\\\n",
    "                  , '\\s\\d+\\s+Ethical considerations and administrative procedures', '\\s\\d+\\s+Protocol adherence'\\\n",
    "                  , '\\s\\d+\\s+References', '\\s\\d+\\s+Appendices']\n",
    "    \n",
    "    text = ''\n",
    "    pattern0 = r\"\\d+\\.\\d+\\.\\d+\\.\\d+\\.\\d+ [A-Z]|\\d+\\.\\d+\\.\\d+\\.\\d+ [A-Z]|\\d+\\.\\d+\\.\\d+ [A-Z]|[1-9]\\.\\d+ [A-Z]\" # |=or pattern match\n",
    "    for piece in read_in_chunks(fin): # compile text from file\n",
    "        #text += piece.replace('\\n', ' ').replace('\\r', ' ')\n",
    "        text += piece\n",
    "        \n",
    "    # remove page numbers and footer\n",
    "    patternpg = r'Novartis Confidential Page \\d+'\n",
    "    text = re.sub(patternpg, '', text)\n",
    "    \n",
    "    #maincptdict = {}\n",
    "    seplst = [] # chapter separation list\n",
    "    \n",
    "    # for each chapter\n",
    "    for cpat in chptr_plst:\n",
    "        #print(re.findall(cpat, text))\n",
    "        for ctr, chdr in enumerate(re.finditer(re.compile(cpat), text)):\n",
    "            #print(ctr, ': ', chdr)\n",
    "            #maincptdict[cpat] = chdr.span()\n",
    "            seplst.append(chdr.span()) # from start position to start position\n",
    "            #print(text[chdr.span()[0]:chdr.span()[1]])\n",
    "    #seplst.append((seplst[len(seplst)-1][0], len(text))) # add the final separator (for the last chapter)\n",
    "    seplst = sorted(seplst, key=lambda tup: tup[0])\n",
    "            \n",
    "    #print(maincptdict)\n",
    "    #print(seplst)\n",
    "    #for ctup in seplst:\n",
    "        #print(text[ctup[0]:ctup[1]])\n",
    "    \n",
    "    subclst = [] # subchapter separation list\n",
    "    for cidx in range(len(seplst) - 1): # main chapters split\n",
    "        thisclst = []\n",
    "        #print('find subchapter in: ', seplst[cidx][0], seplst[cidx+1][1])\n",
    "        for ctr, chptr in enumerate(re.finditer(pattern0, text[seplst[cidx][0]:seplst[cidx+1][1]])):\n",
    "            #print('section: ', ctr, 'for main index ', seplst[cidx], ' : ', chptr_plst[cidx // 2][8:])\n",
    "            #thisclst.append(chptr.span()[0]) # tuple of start and end positions\n",
    "            # need to consider match offset !\n",
    "            thisclst.append((chptr.span()[0]+seplst[cidx][0], chptr.span()[1]+seplst[cidx][1])) # tuple of start and end positions\n",
    "        if len(thisclst) > 0: # need to append a final entry to cover text from last match to end of chapter\n",
    "            thisclst.append((thisclst[len(thisclst) - 1][1], seplst[cidx+1][0]))\n",
    "        else:\n",
    "            thisclst.append((seplst[cidx][0], seplst[cidx+1][0])) # the subchapter is the same as the chapter\n",
    "        subclst.append(thisclst) # subclst is a list of chapters, for each chapter a list of tuples for the subtitle matches\n",
    "            \n",
    "    \n",
    "    #print(subclst)\n",
    "    #for sc in subclst:\n",
    "        #print('chptr')\n",
    "        #for ctup in sc:\n",
    "            #print(text[ctup[0]:ctup[1]])\n",
    "    \n",
    "    ctr = 0\n",
    "    for cidx in range(len(seplst) - 1):\n",
    "        #print('section: ', ctr, 'for main index ', cidx)\n",
    "        ctr += 1\n",
    "        if len(subclst[cidx]) > 1:\n",
    "            for scidx in range(len(subclst[cidx]) - 1): # number of separations of chapter by subchapters\n",
    "                if subclst is not []:\n",
    "                    ctitle = text[subclst[cidx][scidx][0]:subclst[cidx][scidx][1]+10] # the tuple holds the span of the title\n",
    "                    chptr = text[subclst[cidx][scidx][1]:subclst[cidx][scidx+1][1]]\n",
    "                    chptr = chptr.replace('\\n', ' ').replace('\\r', ' ')\n",
    "                    #print('chptr: ', ctitle, subclst[cidx][scidx], subclst[cidx][scidx+1])\n",
    "                    if len(chptr) > 10 and chptr.find('.') > 0:\n",
    "                        #print('section: ', ctr, 'for main index ', seplst[cidx], ' : ', chptr_plst[cidx // 2][8:])\n",
    "                        print('chptr: ', ctitle)\n",
    "                        try:\n",
    "                            print(summarize(chptr, ratio=summratio))\n",
    "                            print()\n",
    "                        except ValueError:\n",
    "                            pass\n",
    "        else: # there is just one subchapter (the chapter itself)\n",
    "            #print('sub', subclst[cidx])\n",
    "            #print('***********', text[subclst[cidx][0][0]:subclst[cidx][0][1]])\n",
    "            ctitle = text[subclst[cidx][0][0]:subclst[cidx][0][1]+10] # the tuple holds the span of the title\n",
    "            if cidx >= len(subclst) - 1:\n",
    "                return 0\n",
    "            chptr = text[subclst[cidx][0][1]:subclst[cidx+1][0][0]]\n",
    "            chptr = chptr.replace('\\n', ' ').replace('\\r', ' ')\n",
    "            if len(chptr) > 50 and chptr.find('.') > 0:\n",
    "                #print('section: ', ctr, 'for main index ', seplst[cidx], ' : ', chptr_plst[cidx // 2][8:])\n",
    "                print('chptr: ', ctitle)\n",
    "                try:\n",
    "                    print(summarize(chptr, ratio=summratio))\n",
    "                    print()\n",
    "                except ValueError:\n",
    "                    pass          \n",
    "            \n",
    "    # fetch chapters\n",
    "    #for ctr, subchdr in enumerate(re.finditer(pattern0, text[chdr.span[0]:chdr.span[0]])):\n",
    "        #print(ctr, ': ', subchdr) \n",
    "        \n",
    "    #text += ' ' + summarize(piece, ratio=0.1)\n",
    "    #print(text)\n",
    "    \n",
    "    '''for cidx in range(len(seplst) - 1): # main chapters split\n",
    "        chpt_txt = re.split(pattern0, text[seplst[cidx]:seplst[cidx+1]])\n",
    "        #print(chpt_txt)\n",
    "        for ctr, chptr in enumerate(chpt_txt):\n",
    "        #for ctr, chptr in enumerate(re.finditer(pattern0, text[seplst[cidx]:seplst[cidx+1]])):\n",
    "            print('section: ', ctr, 'for main index ', seplst[cidx], ' : ', chptr_plst[cidx // 2][8:])\n",
    "            if len(chptr) > 100 and chptr.find('.') > 0:\n",
    "                print('section: ', ctr, 'for main index ', seplst[cidx], ' : ', chptr_plst[cidx // 2][8:])\n",
    "                #print(chptr.match())\n",
    "                try:\n",
    "                    print(summarize(chptr, ratio=0.2))\n",
    "                except ValueError:\n",
    "                    #print(chptr)\n",
    "                    pass'''\n",
    "    \n",
    "if __name__==\"__main__\": \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helling: 0.4397484841235158\n",
      "euclid: 0.6\n",
      "cosine: 1.0215078369104982\n",
      "jacc: 0.6\n",
      "\n",
      "regular:  [6.5 6.4] [6.3 5.8]\n",
      "helling: 0.09034828719135093\n",
      "euclid: 0.6324555320336764\n",
      "cosine: 0.11311325139321936\n",
      "minkov p=4: 0.6018433396869133\n",
      "fract p=0.2: 11.42401086259046\n",
      "\n",
      "L1-norm:  [0.50387597 0.49612403] [0.52066116 0.47933884]\n",
      "helling: 0.011872914294613929\n",
      "euclid: 0.02373784056260818\n",
      "cosine: 1.413191532186627\n",
      "minkov p=4: 0.019961065034961437\n",
      "fract p=0.2: nan\n",
      "\n",
      "L2-norm:  [0.71256682 0.70160425] [0.73569822 0.67730947]\n",
      "helling: 0.014120475850765184\n",
      "euclid: 0.0335454625980808\n",
      "cosine: 0.9997186359018924\n",
      "minkov p=4: 0.028225197377708088\n",
      "fract p=0.2: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\venv\\lib\\site-packages\\ipykernel_launcher.py:39: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# Hellinger metric and Jaccard index\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def l1_norm(v):\n",
    "    '''L1 distance'''\n",
    "    norm = np.sum(v)\n",
    "    return v / norm\n",
    "\n",
    "def l2_norm(v):\n",
    "    '''L2 distance'''\n",
    "    norm = np.sqrt(np.sum(np.square(v)))\n",
    "    return v / norm\n",
    "\n",
    "def hellingm(p, q):\n",
    "    '''returns Hellinger metric for distributions p and q'''\n",
    "    if len(p) != len(q):\n",
    "        return -1\n",
    "    hm = 0.\n",
    "    for idx, elp in enumerate(p):\n",
    "        hm += (math.sqrt(elp) - math.sqrt(q[idx]))**2\n",
    "    return math.sqrt(hm) / math.sqrt(2.)\n",
    "\n",
    "def euclid(p, q):\n",
    "    '''Euclidean metric for distributions p and q'''\n",
    "    if len(p) != len(q):\n",
    "        return -1\n",
    "    ec = 0.\n",
    "    for idx, elp in enumerate(p):\n",
    "        ec += (elp - q[idx]) ** 2\n",
    "    return math.sqrt(ec) \n",
    "\n",
    "def minkovfr(p, q, pp):\n",
    "    '''Minkowski and fractional metric for distributions p and q'''\n",
    "    if len(p) != len(q):\n",
    "        return -1\n",
    "    ec = 0.\n",
    "    for idx, elp in enumerate(p):\n",
    "        ec += (elp - q[idx]) ** pp\n",
    "    return ec ** (1. / pp)\n",
    "\n",
    "def cosine(p, q):\n",
    "    '''cosine similarity for distributions p and q'''\n",
    "    if len(p) != len(q):\n",
    "        return -1\n",
    "    cs = 0.\n",
    "    pn = 0.\n",
    "    qn = 0.\n",
    "    for idx, elp in enumerate(p):\n",
    "        cs += elp * q[idx]\n",
    "        pn += elp * elp\n",
    "        qn += q[idx] * q[idx]\n",
    "    return math.sqrt(cs) / math.sqrt(pn) / math.sqrt(qn)\n",
    "\n",
    "def jaccind(a, b):\n",
    "    '''returns the Jaccard index for two sets a, b'''\n",
    "    return len(a.intersection(b)) / len(a.union(b))\n",
    "\n",
    "def main():\n",
    "    X = np.array([[1., 2., 1],\n",
    "              [2., 4., 2],\n",
    "              [8.0, 8.3, 2],\n",
    "              [6.3, 5.4, 1],\n",
    "              [1.3, 2.7, 0],\n",
    "              [2.3, 3.1, 0],\n",
    "              [6.6, 6.0, 1],\n",
    "              [6.5, 6.4, 1],\n",
    "              [6.3, 5.8, 1],\n",
    "              [9.5, 9.9, 2],\n",
    "              [8.9, 8.9, 2],\n",
    "              [8.7, 9.5, 2],\n",
    "              [2.5, 3.8, 0],\n",
    "              [2.0, 3.1, 0],\n",
    "              [1.3, 1.3, 0]])\n",
    "    \n",
    "    print('helling:', hellingm([0.1, 0.8, 0.2, 0.], [0.0, 0.5, 0.7, 0.1]))\n",
    "    print('euclid:', euclid([0.1, 0.8, 0.2, 0.], [0.0, 0.5, 0.7, 0.1]))\n",
    "    print('cosine:', cosine([0.1, 0.8, 0.2, 0.], [0.0, 0.5, 0.7, 0.1]))\n",
    "    print('jacc:', jaccind({1,2,3,4}, {2,3,4,5}))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    x0 = X[7][:-1]\n",
    "    x1 = X[8][:-1]\n",
    "    print(\"regular: \", x0, x1)\n",
    "    print('helling:', hellingm(x0, x1))\n",
    "    print('euclid:', euclid(x0, x1))\n",
    "    print('cosine:', cosine(x0, x1))\n",
    "    print('minkov p=4:', minkovfr(x0, x1, 4))\n",
    "    print('fract p=0.2:', minkovfr(x0, x1, 0.2))\n",
    "    \n",
    "    print()\n",
    "    x0_n = l1_norm(x0)\n",
    "    x1_n = l1_norm(x1)\n",
    "    print(\"L1-norm: \", x0_n, x1_n)\n",
    "    print('helling:', hellingm(x0_n, x1_n))\n",
    "    print('euclid:', euclid(x0_n, x1_n))\n",
    "    print('cosine:', cosine(x0_n, x1_n))\n",
    "    print('minkov p=4:', minkovfr(x0_n, x1_n, 4))\n",
    "    print('fract p=0.2:', minkovfr(x0_n, x1_n, 0.2))       \n",
    "\n",
    "    print()\n",
    "    x0_n = l2_norm(x0)\n",
    "    x1_n = l2_norm(x1)\n",
    "    print(\"L2-norm: \", x0_n, x1_n)\n",
    "    print('helling:', hellingm(x0_n, x1_n))\n",
    "    print('euclid:', euclid(x0_n, x1_n))\n",
    "    print('cosine:', cosine(x0_n, x1_n))\n",
    "    print('minkov p=4:', minkovfr(x0_n, x1_n, 4))\n",
    "    print('fract p=0.2:', minkovfr(x0_n, x1_n, 0.2))\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text: The extent and importance of autoimmune mechanisms in myelodysplastic syndrome (MDS) and the  role of immunosuppression in the treatment of this disease are not well defined. We report overrepresentation  of HLA-DR2 and its serologic split HLA-DR15 in both MDS and aplastic anemia (AA). Four clinically and ethnically  defined patient groups were analyzed. The HLA-DR15 antigen frequencies among North American white MDS patients  (n = 72) and AA patients (n = 59), who received immunosuppressive treatment at the National Institutes of Health  (NIH), were 36% and 42%, respectively. These antigen frequencies were significantly higher than that of the  control population of 240 North American white NIH blood donors typed for HLA antigens by the same molecular  technique (HLA-DR15, 21.3%, P =.01 for MDS, P <.001 for AA). Among North American white patients reported in the  International Bone Marrow Transplant Registry (IBMTR), 30% of 341 MDS patients and 33% of 364 AA patients were  positive for HLA-DR2. These antigen frequencies were higher than those reported for the general North American  white population (HLA-DR2, 25.3%, P =.089 for MDS, P =.01 for AA). The DR15 and DR2 frequencies were significantly  increased in MDS refractory anemia (RA) (P =.036 and P =.01, respectively) but not MDS refractory anemia with  excess blasts. In the NIH MDS patients, HLA-DR15 was significantly associated with a clinically relevant  response to antithymocyte globulin (ATG) or cyclosporine immunosuppression (multivariate analysis, P =.008).  In MDS with RA, DR15 may be useful as a guide to pathophysiology, prognosis, and treatment.\n",
      "++++++++++++++++++++++++++++++++++++++\n",
      "4.782968367485783\n"
     ]
    }
   ],
   "source": [
    "# text entropy\n",
    "import math\n",
    "import re\n",
    "\n",
    "def uniqc(txt):\n",
    "    '''return unique characters of given text'''\n",
    "    return set(txt)\n",
    "\n",
    "def entropy(txt):\n",
    "    '''calclate information entropy of given text'''\n",
    "    clst = uniqc(txt)\n",
    "    ctlst = []\n",
    "    for c in clst:\n",
    "        ctlst.append(txt.count(c))\n",
    "    res = 0.\n",
    "    sct = sum(ctlst)\n",
    "    for nc in ctlst:\n",
    "        res -= nc * math.log(nc / sct)\n",
    "    return res / math.log(2) / sct\n",
    "        \n",
    "def main():\n",
    "    piece = input(\"Enter text: \").replace('\\n', ' ').replace('\\r', ' ')\n",
    "    print('++++++++++++++++++++++++++++++++++++++')\n",
    "    #print(uniqc(piece))\n",
    "    print(entropy(piece))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# robot on grid\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def robmv(n):\n",
    "    '''n random moves along x,y, not diag'''\n",
    "    mdir = ((1,0), (0,1), (-1,0), (0,-1))\n",
    "    res = [0,0]\n",
    "    for i in range(n):\n",
    "        thismv = random.choice(mdir)\n",
    "        res[0] += thismv[0]\n",
    "        res[1] += thismv[1]\n",
    "    return res\n",
    "\n",
    "def main():\n",
    "    nsteps = 16\n",
    "    data = np.zeros((2*nsteps+1, 2*nsteps+1))\n",
    "    for i in range(20000):\n",
    "        thismv = robmv(nsteps)\n",
    "        #print(thismv)\n",
    "        data[thismv[0]+nsteps, thismv[1]+nsteps] += 1\n",
    "    data /= np.sum(data)\n",
    "    plt.imshow(data)\n",
    "    plt.show()\n",
    "    #print(data)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# byte pair encoding (BPE) test\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "def vocab_cts(corpus: str) -> dict: # -> function annotation e.g. annotate parameters with their expected types\n",
    "    \"\"\"vocab with counts from corpus\"\"\"\n",
    "    # Separate each char in word by space and add mark end of token\n",
    "    tokens = [\" \".join(word) + \" </w>\" for word in corpus.split()]\n",
    "    vocab = Counter(tokens) # count frequency of tokens in corpus, counter is provided to support convenient, rapid tallies\n",
    "    return vocab\n",
    "\n",
    "def ct_prs(vocab: dict) -> dict:\n",
    "    \"\"\"count pairs of consecutive symbols\"\"\"\n",
    "    pairs = defaultdict(int) # dict subclass that calls a factory function to supply missing values\n",
    "    for word, frequency in vocab.items():\n",
    "        symbols = word.split() # split word into its symbols\n",
    "        for i in range(len(symbols) - 1):\n",
    "            pairs[symbols[i], symbols[i + 1]] += frequency # counting up occurrences of pairs\n",
    "    return pairs\n",
    "\n",
    "def merge_vocab(pair: tuple, v_in: dict) -> dict:\n",
    "    \"\"\"merge all occurrences of the most frequent pairs\"\"\"\n",
    "    v_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in v_in:\n",
    "        w_out = p.sub(''.join(pair), word) # replace most frequent pair in all vocabulary\n",
    "        v_out[w_out] = v_in[word]\n",
    "    return v_out\n",
    "\n",
    "corpus = '''The extent and importance of autoimmune mechanisms in myelodysplastic syndrome (MDS) and the \n",
    "role of immunosuppression in the treatment of this disease are not well defined. We report overrepresentation \n",
    "of HLA-DR2 and its serologic split HLA-DR15 in both MDS and aplastic anemia (AA). Four clinically and ethnically \n",
    "defined patient groups were analyzed. The HLA-DR15 antigen frequencies among North American white MDS patients \n",
    "(n = 72) and AA patients (n = 59), who received immunosuppressive treatment at the National Institutes of Health \n",
    "(NIH), were 36% and 42%, respectively. These antigen frequencies were significantly higher than that of the \n",
    "control population of 240 North American white NIH blood donors typed for HLA antigens by the same molecular \n",
    "technique (HLA-DR15, 21.3%, P =.01 for MDS, P <.001 for AA). Among North American white patients reported in the \n",
    "International Bone Marrow Transplant Registry (IBMTR), 30% of 341 MDS patients and 33% of 364 AA patients were \n",
    "positive for HLA-DR2. These antigen frequencies were higher than those reported for the general North American \n",
    "white population (HLA-DR2, 25.3%, P =.089 for MDS, P =.01 for AA). The DR15 and DR2 frequencies were significantly \n",
    "increased in MDS refractory anemia (RA) (P =.036 and P =.01, respectively) but not MDS refractory anemia with \n",
    "excess blasts. In the NIH MDS patients, HLA-DR15 was significantly associated with a clinically relevant \n",
    "response to antithymocyte globulin (ATG) or cyclosporine immunosuppression (multivariate analysis, P =.008). \n",
    "In MDS with RA, DR15 may be useful as a guide to pathophysiology, prognosis, and treatment.'''\n",
    "\n",
    "vocab = vocab_cts(corpus)  # Step 1\n",
    "\n",
    "num_merges = 100  # Hyperparameter\n",
    "for i in range(num_merges):\n",
    "    pairs = ct_prs(vocab)  # Step 2\n",
    "    if not pairs:\n",
    "        break\n",
    "    # step 3\n",
    "    best = max(pairs, key=pairs.get) # gets the key with the maximum value\n",
    "    vocab = merge_vocab(best, vocab)\n",
    "    \n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple regression\n",
    "import numpy as np\n",
    " \n",
    "height = [1.47, 1.50, 1.52, 1.55, 1.57, 1.60, 1.63,\n",
    "    1.65, 1.68, 1.70, 1.73, 1.75, 1.78, 1.80, 1.83]\n",
    "weight = [52.21, 53.12, 54.48, 55.84, 57.20, 58.57, 59.93,\n",
    "    61.29, 63.11, 64.47, 66.28, 68.10, 69.92, 72.19, 74.46]\n",
    " \n",
    "X = np.mat(height**np.arange(3)[:, None])\n",
    "y = np.mat(weight)\n",
    " \n",
    "print(y * X.T * (X*X.T).I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text: The extent and importance of autoimmune mechanisms in myelodysplastic syndrome (MDS) and the  role of immunosuppression in the treatment of this disease are not well defined. We report overrepresentation  of HLA-DR2 and its serologic split HLA-DR15 in both MDS and aplastic anemia (AA). Four clinically and ethnically  defined patient groups were analyzed. The HLA-DR15 antigen frequencies among North American white MDS patients  (n = 72) and AA patients (n = 59), who received immunosuppressive treatment at the National Institutes of Health  (NIH), were 36% and 42%, respectively. These antigen frequencies were significantly higher than that of the  control population of 240 North American white NIH blood donors typed for HLA antigens by the same molecular  technique (HLA-DR15, 21.3%, P =.01 for MDS, P <.001 for AA). Among North American white patients reported in the  International Bone Marrow Transplant Registry (IBMTR), 30% of 341 MDS patients and 33% of 364 AA patients were  positive for HLA-DR2. These antigen frequencies were higher than those reported for the general North American  white population (HLA-DR2, 25.3%, P =.089 for MDS, P =.01 for AA). The DR15 and DR2 frequencies were significantly  increased in MDS refractory anemia (RA) (P =.036 and P =.01, respectively) but not MDS refractory anemia with  excess blasts. In the NIH MDS patients, HLA-DR15 was significantly associated with a clinically relevant  response to antithymocyte globulin (ATG) or cyclosporine immunosuppression (multivariate analysis, P =.008).  In MDS with RA, DR15 may be useful as a guide to pathophysiology, prognosis, and treatment.\n",
      "++++++++++++++++++++++++++++++++++++++\n",
      "extent import autoimmun mechan myelodysplast syndrom md role immunosuppress treatment diseas defin report overrepresent hla serolog split hla md aplast anemia clinic ethnic defin patient group analyz hla antigen frequenc north american white md patient patient receiv immunosuppress treatment nation institut health nih respect antigen frequenc significantli higher control popul north american white nih blood donor type hla antigen molecular techniqu hla md north american white patient report intern bone marrow transplant registri ibmtr md patient patient posit hla antigen frequenc higher report gener north american white popul hla md frequenc significantli increas md refractori anemia respect md refractori anemia excess blast nih md patient hla significantli associ clinic relev respons antithymocyt globulin atg cyclosporin immunosuppress multivari analysi md us guid pathophysiolog prognosi treatment\n",
      "[(('r', 'e'), 24), (('n', 't'), 23), (('e', 'n'), 21), (('a', 'n'), 20), (('t', 'i'), 15), (('l', 'a'), 13), (('a', 't'), 13), (('o', 'r'), 12), (('m', 'd'), 10), (('e', 'r'), 10)]\n",
      "most common pairs: ['re', 'nt', 'en', 'an', 'ti', 'la', 'at', 'or', 'md', 'er']\n",
      "separate out common pairs: exte  imp t autoimmun mech  myelodysp st syndrom   role immunosupp ss t  me  diseas defin  p t ov  p se  h  s olog split h    ap st  emia clinic ethnic defin pa e  group  alyz h  a ig  f qu c n th am ic  white   pa e  pa e   ceiv immunosupp ss t  me  na on ins tut health nih  spect a ig  f qu c significa li high  co rol popul n th am ic  white nih blood don  type h  a ig  molecu r techniqu h    n th am ic  white pa e   p t i  n bone marrow tr sp    gistri ibmtr   pa e  pa e  posit h  a ig  f qu c high   p t g   n th am ic  white popul h    f qu c significa li inc as    fract i  emia  spect    fract i  emia excess b st nih   pa e  h  significa li associ clinic  lev  spons a ithymocyt globulin  g cyclosp in immunosupp ss mul vari  alysi   us guid p hophysiolog prognosi t  me \n",
      "[(('n', 'i'), 10), (('i', 'c'), 10), (('i', 'g'), 9), (('i', 'n'), 8), (('s', 'p'), 7), (('l', 'i'), 7), (('i', 't'), 7), (('t', 'h'), 7), (('p', 'a'), 7), (('s', 'i'), 7)]\n",
      "most common pairs: ['ni', 'ic', 'ig', 'in', 'sp', 'li', 'it', 'th', 'pa', 'si']\n",
      "separate out common pairs: exte  imp t autoimmun mech  myelody  st syndrom   role immunosupp ss t  me  diseas def   p t ov  p se  h  s olog   t h    ap st  emia c  c e  c def    e  group  alyz h  a    f qu c n   am    wh e     e    e   ceiv immunosupp ss t  me  na on  s tut heal   h   ect a    f qu c s  f a   h h  co rol popul n   am    wh e  h blood don  type h  a    molecu r tech qu h    n   am    wh e   e   p t i  n bone marrow tr      gistri ibmtr     e    e  pos  h  a    f qu c h h   p t g   n   am    wh e popul h    f qu c s  f a    c as    fract i  emia   ect    fract i  emia excess b st  h     e  h  s  f a   associ c  c  lev   ons a  hymocyt globul   g cyclo    immunosupp ss mul vari  aly    us guid p hophy olog progno  t  me \n",
      "[(('l', 'o'), 6), (('r', 'o'), 6), (('i', 'm'), 5), (('m', 'u'), 5), (('e', 'c'), 5), (('o', 'l'), 5), (('s', 's'), 5), (('q', 'u'), 5), (('m', 'm'), 4), (('u', 'n'), 4)]\n",
      "most common pairs: ['lo', 'ro', 'im', 'mu', 'ec', 'ol', 'ss', 'qu', 'mm', 'un']\n",
      "separate out common pairs: exte   p t auto  n m h  mye dy  st synd m    le   nosupp   t  me  diseas def   p t ov  p se  h  s o g   t h    ap st  emia c  c e  c def    e  g up  alyz h  a    f   c n   am    wh e     e    e   ceiv   nosupp   t  me  na on  s tut heal   h    t a    f   c s  f a   h h  co  l popul n   am    wh e  h b od don  type h  a    m  u r t h   h    n   am    wh e   e   p t i  n bone mar w tr      gistri ibmtr     e    e  pos  h  a    f   c h h   p t g   n   am    wh e popul h    f   c s  f a    c as    fract i  emia    t    fract i  emia exce  b st  h     e  h  s  f a   a oci c  c  lev   ons a  hymocyt g bul   g cyc       nosupp    l vari  aly    us guid p hophy o g p gno  t  me \n",
      "translated back: exte   p t auto  n m h  mye dy  st synd m    le   nosupp   t  me  diseas def   p t ov  p se  h  s o g   t h    ap st  emia c  c e  c def    e  g up  alyz h  a    f   c n   am    wh e     e    e   ceiv   nosupp   t  me  na on  s tut heal   h    t a    f   c s  f a   h h  co  l popul n   am    wh e  h b od don  type h  a    m  u r t h   h    n   am    wh e   e   p t i  n bone mar w tr      gistri ibmtr     e    e  pos  h  a    f   c h h   p t g   n   am    wh e popul h    f   c s  f a    c as    fract i  emia    t    fract i  emia exce  b st  h     e  h  s  f a   a oci c  c  lev   ons a  hymocyt g bul   g cyc       nosupp    l vari  aly    us guid p hophy o g p gno  t  me \n"
     ]
    }
   ],
   "source": [
    "# BPE test 2\n",
    "from collections import Counter, defaultdict\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "\n",
    "def ctprs(txt, ex_sp=False) -> dict:\n",
    "    '''count symbol pair frequencies'''\n",
    "    pairs = defaultdict(int)\n",
    "    for i in range(len(txt) - 1):\n",
    "        if ex_sp:\n",
    "            if txt[i] == ' ' or txt[i+1] == ' ':\n",
    "                continue\n",
    "        pairs[txt[i], txt[i+1]] += 1\n",
    "    return pairs\n",
    "\n",
    "def main():\n",
    "    piece = input(\"Enter text: \").replace('\\n', ' ').replace('\\r', ' ')\n",
    "    print('++++++++++++++++++++++++++++++++++++++')\n",
    "    corpus = ' '.join(preprocess_string(piece))\n",
    "    print(corpus)\n",
    "    mcp = Counter(ctprs(corpus, True)).most_common(10)\n",
    "    print(mcp)\n",
    "    cmm_prs = [''.join(x) for x, ctr in mcp]\n",
    "    print('most common pairs:', cmm_prs)\n",
    "    for cp in cmm_prs:\n",
    "        #corpus = corpus.replace(cp, ' ' + cp + ' ')\n",
    "        corpus = corpus.replace(cp, ' ')\n",
    "    print('separate out common pairs:', corpus)\n",
    " \n",
    "    mcp = Counter(ctprs(corpus, True)).most_common(10)\n",
    "    print(mcp)\n",
    "    cmm_prs = [''.join(x) for x, ctr in mcp]\n",
    "    print('most common pairs:', cmm_prs)\n",
    "    for cp in cmm_prs:\n",
    "        #corpus = corpus.replace(cp, ' ' + cp + ' ')\n",
    "        corpus = corpus.replace(cp, ' ')\n",
    "    print('separate out common pairs:', corpus)\n",
    "    \n",
    "    mcp = Counter(ctprs(corpus, True)).most_common(10)\n",
    "    print(mcp)\n",
    "    cmm_prs = [''.join(x) for x, ctr in mcp]\n",
    "    print('most common pairs:', cmm_prs)\n",
    "    for cp in cmm_prs:\n",
    "        #corpus = corpus.replace(cp, ' ' + cp + ' ')\n",
    "        corpus = corpus.replace(cp, ' ')\n",
    "    print('separate out common pairs:', corpus)\n",
    "    \n",
    "    for cp in cmm_prs:\n",
    "        corpus = corpus.replace(' ' + cp + ' ', cp)\n",
    "    print('translated back:', corpus)\n",
    "        \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [1], [0], [0, 1]]\n"
     ]
    }
   ],
   "source": [
    "# power sets\n",
    "def pwsts(s):\n",
    "    '''power sets of s'''\n",
    "    if not s:\n",
    "        return [[]]\n",
    "    return pwsts(s[1:]) + [[s[0]] + x for x in pwsts(s[1:])]\n",
    "\n",
    "def main():\n",
    "    print(pwsts([0,1]))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# combination and permutation\n",
    "def nperm(n, k):\n",
    "    '''n permutation'''\n",
    "    res = 1\n",
    "    for i in range(n-k+1, n+1):\n",
    "        res *= i\n",
    "    return res\n",
    "\n",
    "def ncomb(n, k):\n",
    "    '''n combinations'''\n",
    "    res = nperm(n, k)\n",
    "    for i in range(1, k+1):\n",
    "        res /= i\n",
    "    return res\n",
    "\n",
    "def main():\n",
    "    print(nperm(3,2))\n",
    "    print(ncomb(3,3))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "# exp g tst\n",
    "def egrth(n0, n1, t2):\n",
    "    '''how long from n0 to n1 w/o ln'''\n",
    "    tres = 0\n",
    "    while n0 < n1:\n",
    "        n0 *= 2\n",
    "        tres += t2\n",
    "    return tres\n",
    "\n",
    "def main():\n",
    "    print(egrth(1634, 8500000, 2))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text: The extent and importance of autoimmune mechanisms in myelodysplastic syndrome (MDS) and the  role of immunosuppression in the treatment of this disease are not well defined. We report overrepresentation  of HLA-DR2 and its serologic split HLA-DR15 in both MDS and aplastic anemia (AA). Four clinically and ethnically  defined patient groups were analyzed. The HLA-DR15 antigen frequencies among North American white MDS patients  (n = 72) and AA patients (n = 59), who received immunosuppressive treatment at the National Institutes of Health  (NIH), were 36% and 42%, respectively. These antigen frequencies were significantly higher than that of the  control population of 240 North American white NIH blood donors typed for HLA antigens by the same molecular  technique (HLA-DR15, 21.3%, P =.01 for MDS, P <.001 for AA). Among North American white patients reported in the  International Bone Marrow Transplant Registry (IBMTR), 30% of 341 MDS patients and 33% of 364 AA patients were  positive for HLA-DR2. These antigen frequencies were higher than those reported for the general North American  white population (HLA-DR2, 25.3%, P =.089 for MDS, P =.01 for AA). The DR15 and DR2 frequencies were significantly  increased in MDS refractory anemia (RA) (P =.036 and P =.01, respectively) but not MDS refractory anemia with  excess blasts. In the NIH MDS patients, HLA-DR15 was significantly associated with a clinically relevant  response to antithymocyte globulin (ATG) or cyclosporine immunosuppression (multivariate analysis, P =.008).  In MDS with RA, DR15 may be useful as a guide to pathophysiology, prognosis, and treatment.\n",
      "++++++++++++++++++++++++++++++++++++++\n",
      "extent import autoimmun mechan myelodysplast syndrom md role immunosuppress treatment diseas defin report overrepresent hla serolog split hla md aplast anemia clinic ethnic defin patient group analyz hla antigen frequenc north american white md patient patient receiv immunosuppress treatment nation institut health nih respect antigen frequenc significantli higher control popul north american white nih blood donor type hla antigen molecular techniqu hla md north american white patient report intern bone marrow transplant registri ibmtr md patient patient posit hla antigen frequenc higher report gener north american white popul hla md frequenc significantli increas md refractori anemia respect md refractori anemia excess blast nih md patient hla significantli associ clinic relev respons antithymocyt globulin atg cyclosporin immunosuppress multivari analysi md us guid pathophysiolog prognosi treatment\n",
      "[(('r', 'e'), 24), (('n', 't'), 23), (('e', 'n'), 21), (('a', 'n'), 20), (('t', 'i'), 15), (('l', 'a'), 13), (('a', 't'), 13), (('o', 'r'), 12), (('m', 'd'), 10), (('e', 'r'), 10), (('n', 'i'), 10), (('i', 'c'), 10), (('p', 'o'), 9), (('n', 'o'), 9), (('i', 'n'), 9), (('i', 'g'), 9), (('r', 'i'), 9), (('r', 't'), 8), (('m', 'e'), 8), (('e', 's'), 8)]\n",
      "most common pairs: ['re', 'nt', 'en', 'an', 'ti', 'la', 'at', 'or', 'md', 'er', 'ni', 'ic', 'po', 'no', 'in', 'ig', 'ri', 'rt', 'me', 'es']\n",
      "separate out common pairs: extent  po  autoimmun mechan  la  syndrom md role  re   at  diseas defin  po   re  hla serolog split hla md  la  anemia  in  ethnic defin  ti  group analyz hla  ti  frequenc north  er  white md  ti   ti  receiv  re   at   ti   ti  health nih respect  ti  frequenc  nt  higher  nt  popul north  er  white nih blood donor type hla  ti  molecular  ni  hla md north  er  white  ti   po  intern bone marrow  an  registri ibmtr md  ti   ti  posit hla  ti  frequenc higher  po  gener north  er  white popul hla md frequenc  nt   re  md refractori anemia respect md refractori anemia excess blast nih md  ti  hla  nt  associ  in  relev  po   ti  globulin atg  or   re   ti  analysi md us guid pathophysiolog  no   at \n"
     ]
    }
   ],
   "source": [
    "# BPE test 3\n",
    "from collections import Counter, defaultdict\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "import re\n",
    "\n",
    "def ctprs(txt, ex_sp=False) -> dict:\n",
    "    '''count symbol pair frequencies'''\n",
    "    pairs = defaultdict(int)\n",
    "    for i in range(len(txt) - 1):\n",
    "        if ex_sp:\n",
    "            if txt[i] == ' ' or txt[i+1] == ' ':\n",
    "                continue\n",
    "        pairs[txt[i], txt[i+1]] += 1\n",
    "    return pairs\n",
    "\n",
    "def main():\n",
    "    piece = input(\"Enter text: \").replace('\\n', ' ').replace('\\r', ' ')\n",
    "    print('++++++++++++++++++++++++++++++++++++++')\n",
    "    corpus = ' '.join(preprocess_string(piece))\n",
    "    print(corpus)\n",
    "    mcp = Counter(ctprs(corpus, True)).most_common(20)\n",
    "    print(mcp)\n",
    "    cmm_prs = [''.join(x) for x, ctr in mcp]\n",
    "    print('most common pairs:', cmm_prs)\n",
    "    for cp in cmm_prs:\n",
    "        #corpus = corpus.replace(cp, ' ' + cp + ' ')\n",
    "        corpus = re.sub(r'\\w+\\w+' + cp + r'\\w+\\w+', ' ' + cp + ' ', corpus) # only replace if no single characters left\n",
    "    print('separate out common pairs:', corpus)\n",
    "    \n",
    "    #for cp in cmm_prs:\n",
    "        #corpus = corpus.replace(' ' + cp + ' ', cp)\n",
    "    #print('translated back:', corpus)\n",
    "        \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# two players picking numbers\n",
    "def calln(n, nlst):\n",
    "    return nlst[n]\n",
    "\n",
    "def playgm(n, lim):\n",
    "    picks = range(1, n)\n",
    "    tot = 0\n",
    "    n0 = 0\n",
    "    n1 = 1\n",
    "    while tot < lim:\n",
    "        tot += calln(n0, picks)\n",
    "        if tot >= lim:\n",
    "            return 1\n",
    "        tot += calln(n1, picks)\n",
    "    return 0\n",
    "    \n",
    "def main():\n",
    "    print(playgm(3, 21))\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For these numbers:\n",
      "112272537195293\n",
      "  112582718962171\n",
      "  112272537095293\n",
      "  115280098190773\n",
      "  115797840077099\n",
      "  1099726829285419\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3563dbaf7dc6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-3563dbaf7dc6>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'For these numbers:'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n  '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mNUMBERS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mnumber\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_factors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprime_factors_of_number_with_lowest_prime_factor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUMBERS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'    The one with the largest minimum prime factor is {}:'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'      All its prime factors in order are: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_factors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-3563dbaf7dc6>\u001b[0m in \u001b[0;36mprime_factors_of_number_with_lowest_prime_factor\u001b[1;34m(NUMBERS)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprime_factors_of_number_with_lowest_prime_factor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUMBERS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfutures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcessPoolExecutor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mlow_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlowest_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUMBERS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUMBERS\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mall_factors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprime_factors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_factors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-3563dbaf7dc6>\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprime_factors_of_number_with_lowest_prime_factor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUMBERS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mfutures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProcessPoolExecutor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mlow_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlowest_factor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUMBERS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNUMBERS\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         \u001b[0mall_factors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprime_factors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_factor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_factors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\venv\\lib\\concurrent\\futures\\process.py\u001b[0m in \u001b[0;36m_chain_from_iterable_of_lists\u001b[1;34m(iterable)\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[0mcareful\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mto\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0mto\u001b[0m \u001b[0myielded\u001b[0m \u001b[0mobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \"\"\"\n\u001b[1;32m--> 366\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m         \u001b[0melement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0melement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\venv\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    584\u001b[0m                     \u001b[1;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m                         \u001b[1;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\venv\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\venv\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "from concurrent import futures\n",
    "from math import floor, sqrt\n",
    " \n",
    "NUMBERS = [\n",
    "    112272537195293,\n",
    "    112582718962171,\n",
    "    112272537095293,\n",
    "    115280098190773,\n",
    "    115797840077099,\n",
    "    1099726829285419]\n",
    "# NUMBERS = [33, 44, 55, 275]\n",
    " \n",
    "def lowest_factor(n, _start=3):\n",
    "    if n % 2 == 0:\n",
    "        return 2\n",
    "    search_max = int(floor(sqrt(n))) + 1\n",
    "    for i in range(_start, search_max, 2):\n",
    "        if n % i == 0:\n",
    "            return i\n",
    "    return n\n",
    " \n",
    "def prime_factors(n, lowest):\n",
    "    pf = []\n",
    "    while n > 1:\n",
    "        pf.append(lowest)\n",
    "        n //= lowest\n",
    "        lowest = lowest_factor(n, max(lowest, 3))\n",
    "    return pf\n",
    " \n",
    "def prime_factors_of_number_with_lowest_prime_factor(NUMBERS):\n",
    "    with futures.ProcessPoolExecutor() as executor:\n",
    "        low_factor, number = max( (l, f) for l, f in zip(executor.map(lowest_factor, NUMBERS), NUMBERS) )\n",
    "        all_factors = prime_factors(number, low_factor)\n",
    "        return number, all_factors\n",
    " \n",
    " \n",
    "def main():\n",
    "    print('For these numbers:')\n",
    "    print('\\n  '.join(str(p) for p in NUMBERS))\n",
    "    number, all_factors = prime_factors_of_number_with_lowest_prime_factor(NUMBERS)\n",
    "    print('    The one with the largest minimum prime factor is {}:'.format(number))\n",
    "    print('      All its prime factors in order are: {}'.format(all_factors))\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regular:  [2. 4.] [1.3 2.7]\n",
      "L1:  [0.35 0.65]\n",
      "L2:  [0.47409982 0.8804711 ]\n",
      "dot: 13.40\n",
      "helling: 0.32\n",
      "euclid: 1.48\n",
      "cosine: 0.27\n",
      "minkov p=4: 1.33\n",
      "fract p=0.4: 5.50\n",
      "jaccind: 0.00\n",
      "KL: 2.43\n"
     ]
    }
   ],
   "source": [
    "# various norms and distances\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def l1_norm(v):\n",
    "    '''L1 distance'''\n",
    "    norm = np.sum(v)\n",
    "    return v / norm\n",
    "\n",
    "def l2_norm(v):\n",
    "    '''L2 distance'''\n",
    "    norm = np.sqrt(np.sum(np.square(v)))\n",
    "    return v / norm\n",
    "\n",
    "def froto(p, q):\n",
    "    '''vector from p to q'''\n",
    "    return np.array(p) - np.array(q)\n",
    "\n",
    "def hellingm(p, q):\n",
    "    '''returns Hellinger metric for distributions p and q'''\n",
    "    if len(p) != len(q):\n",
    "        return -1\n",
    "    hm = 0.\n",
    "    for idx, elp in enumerate(p):\n",
    "        hm += (math.sqrt(elp) - math.sqrt(q[idx]))**2\n",
    "    return math.sqrt(hm) / math.sqrt(2.)\n",
    "\n",
    "def euclid(p, q):\n",
    "    '''Euclidean metric for distributions p and q'''\n",
    "    if len(p) != len(q):\n",
    "        return -1\n",
    "    ec = 0.\n",
    "    for idx, elp in enumerate(p):\n",
    "        ec += (elp - q[idx]) ** 2\n",
    "    return math.sqrt(ec) \n",
    "\n",
    "def minkovfr(p, q, pp):\n",
    "    '''Minkowski and fractional metric for distributions p and q'''\n",
    "    if len(p) != len(q):\n",
    "        return -1\n",
    "    ec = 0.\n",
    "    for idx, elp in enumerate(p):\n",
    "        ec += (elp - q[idx]) ** pp\n",
    "    return ec ** (1. / pp)\n",
    "\n",
    "def cosine(p, q):\n",
    "    '''cosine similarity for distributions p and q'''\n",
    "    if len(p) != len(q):\n",
    "        return -1\n",
    "    cs = 0.\n",
    "    pn = 0.\n",
    "    qn = 0.\n",
    "    for idx, elp in enumerate(p):\n",
    "        cs += elp * q[idx]\n",
    "        pn += elp * elp\n",
    "        qn += q[idx] * q[idx]\n",
    "    return math.sqrt(cs) / math.sqrt(pn) / math.sqrt(qn)\n",
    "\n",
    "def jaccind(a, b):\n",
    "    '''returns the Jaccard index for two sets a, b'''\n",
    "    return len(a.intersection(b)) / len(a.union(b))\n",
    "\n",
    "def kullei(p, q):\n",
    "    '''Kullback-Leibler divergence'''\n",
    "    return np.sum(np.dot(p, np.log(p / q)))\n",
    "\n",
    "def main():\n",
    "    X = np.array([[1., 2., 1],\n",
    "              [2., 4., 2],\n",
    "              [8.0, 8.3, 2],\n",
    "              [6.3, 5.4, 1],\n",
    "              [1.3, 2.7, 0],\n",
    "              [2.3, 3.1, 0],\n",
    "              [6.6, 6.0, 1],\n",
    "              [6.5, 6.4, 1],\n",
    "              [6.3, 5.8, 1],\n",
    "              [9.5, 9.9, 2],\n",
    "              [8.9, 8.9, 2],\n",
    "              [8.7, 9.5, 2],\n",
    "              [2.5, 3.8, 0],\n",
    "              [2.0, 3.1, 0],\n",
    "              [1.3, 1.3, 0]])\n",
    "    \n",
    "    x0 = X[1][:-1]\n",
    "    x1 = X[4][:-1]\n",
    "    print(\"regular: \", x0, x1)\n",
    "    print('L1: ', l1_norm(froto(x0, x1)))\n",
    "    print('L2: ', l2_norm(froto(x0, x1)))\n",
    "    print('dot: %2.2f' %(np.dot(x0, x1)))\n",
    "    print('helling: %2.2f' %(hellingm(x0, x1)))\n",
    "    print('euclid: %2.2f' %(euclid(x0, x1)))\n",
    "    print('cosine: %2.2f' %(cosine(x0, x1)))\n",
    "    print('minkov p=4: %2.2f' %(minkovfr(x0, x1, 4)))\n",
    "    print('fract p=0.4: %2.2f' %(minkovfr(x0, x1, 0.4)))\n",
    "    print('jaccind: %2.2f' %(jaccind(set(x0), set(x1))))\n",
    "    print('KL: %2.2f' %(kullei(x0, x1)))\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.67, 'km', 4.67, 'km')\n",
      "(9.5, '10m', 950.0, 'dm')\n",
      "(6.07, 'dm', 60.7, 'cm')\n",
      "(4.67, 'mm', 0.0, 'km')\n",
      "(17.33, 'cm', 0.0173, '10m')\n",
      "(1.58, 'cm', 0.158, 'dm')\n",
      "(1.72, 'km', 17.2, '100m')\n",
      "(0.85, 'km', 8.5, '100m')\n",
      "(0.64, 'km', 0.64, 'km')\n",
      "(7.07, 'm', 0.0707, '100m')\n",
      "\n",
      "(46.5, 'mm2', 0.0, 'km2')\n",
      "(9.38, 'km2', 938000000.0, 'dm2')\n",
      "(3.67, 'cm2', 3.67, 'cm2')\n",
      "(3.53, 'dm2', 4e-06, 'ha')\n",
      "(2.55, 'm2', 255.0, 'dm2')\n",
      "(6.27, 'km2', 627.0, 'ha')\n",
      "(20.0, 'dm2', 2e-05, 'ha')\n",
      "(4.2, 'dm2', 420.0, 'cm2')\n",
      "(11.88, 'a', 11.88, 'a')\n",
      "(9.0, 'cm2', 9e-06, 'a')\n",
      "\n",
      "(8.22, 'mm3', 0.00822, 'cm3')\n",
      "(35.0, '1000000m3', 35000000.0, 'm3')\n",
      "(50.0, 'mm3', 0.05, 'cm3')\n",
      "(12.0, 'mm3', 0.0, '1000m3')\n",
      "(1.75, 'km3', 1750000000.0, 'm3')\n",
      "(24.0, '1000000m3', 24000000000000.0, 'cm3')\n",
      "(13.5, 'cm3', 1.35e-05, 'm3')\n",
      "(25.0, 'cm3', 0.0, 'km3')\n",
      "(6.2, 'mm3', 0.0, '1000m3')\n",
      "(4.71, 'mm3', 0.0, 'm3')\n"
     ]
    }
   ],
   "source": [
    "# Auri examples\n",
    "import random\n",
    "\n",
    "def dist():\n",
    "    dfact = [1000, 100, 10, 1, 0.1, 0.01, 0.001]\n",
    "    dnms = ['km', '100m', '10m', 'm', 'dm', 'cm', 'mm']\n",
    "    i0 = random.randint(0, len(dfact)-1)\n",
    "    i1 = random.randint(0, len(dfact)-1)\n",
    "    n0 = round(random.randint(5, 100) / random.randint(1, 20), 2)\n",
    "    return (n0, dnms[i0], round(n0 * dfact[i0] / dfact[i1], 4), dnms[i1])\n",
    "\n",
    "def area():\n",
    "    dfact = [1000000, 10000, 100, 1, 0.01, 0.0001, 0.000001]\n",
    "    dnms = ['km2', 'ha', 'a', 'm2', 'dm2', 'cm2', 'mm2']\n",
    "    i0 = random.randint(0, len(dfact)-1)\n",
    "    i1 = random.randint(0, len(dfact)-1)\n",
    "    n0 = round(random.randint(5, 100) / random.randint(1, 20), 2)\n",
    "    return (n0, dnms[i0], round(n0 * dfact[i0] / dfact[i1], 6), dnms[i1])\n",
    "\n",
    "def vol():\n",
    "    dfact = [1000000000, 1000000, 1000, 1, 0.001, 0.000001, 0.000000001]\n",
    "    dnms = ['km3', '1000000m3', '1000m3', 'm3', 'dm3', 'cm3', 'mm3']\n",
    "    i0 = random.randint(0, len(dfact)-1)\n",
    "    i1 = random.randint(0, len(dfact)-1)\n",
    "    n0 = round(random.randint(5, 100) / random.randint(1, 20), 2)\n",
    "    return (n0, dnms[i0], round(n0 * dfact[i0] / dfact[i1], 8), dnms[i1])\n",
    "\n",
    "def main():\n",
    "    for i in range(10):\n",
    "        print(dist())\n",
    "    print()\n",
    "    for i in range(10):\n",
    "        print(area())\n",
    "    print()\n",
    "    for i in range(10):\n",
    "        print(vol())\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ieee std synopsys\n",
      "dware gtech ramlib std_cell_lib\n",
      "dw01 dw02 dw05 dw06 dw07\n",
      "des_system_lib dw03 dw04\n"
     ]
    }
   ],
   "source": [
    "# topological sort\n",
    "try:\n",
    "    from functools import reduce\n",
    "except:\n",
    "    pass\n",
    " \n",
    "data = {\n",
    "    'des_system_lib':   set('std synopsys std_cell_lib des_system_lib dw02 dw01 ramlib ieee'.split()),\n",
    "    'dw01':             set('ieee dw01 dware gtech'.split()),\n",
    "    'dw02':             set('ieee dw02 dware'.split()),\n",
    "    'dw03':             set('std synopsys dware dw03 dw02 dw01 ieee gtech'.split()),\n",
    "    'dw04':             set('dw04 ieee dw01 dware gtech'.split()),\n",
    "    'dw05':             set('dw05 ieee dware'.split()),\n",
    "    'dw06':             set('dw06 ieee dware'.split()),\n",
    "    'dw07':             set('ieee dware'.split()),\n",
    "    'dware':            set('ieee dware'.split()),\n",
    "    'gtech':            set('ieee gtech'.split()),\n",
    "    'ramlib':           set('std ieee'.split()),\n",
    "    'std_cell_lib':     set('ieee std_cell_lib'.split()),\n",
    "    'synopsys':         set(),\n",
    "    }\n",
    " \n",
    "def toposort2(data):\n",
    "    for k, v in data.items():\n",
    "        v.discard(k) # Ignore self dependencies\n",
    "    extra_items_in_deps = reduce(set.union, data.values()) - set(data.keys())\n",
    "    data.update({item:set() for item in extra_items_in_deps})\n",
    "    while True:\n",
    "        ordered = set(item for item, dep in data.items() if not dep)\n",
    "        if not ordered:\n",
    "            break\n",
    "        yield ' '.join(sorted(ordered))\n",
    "        data = {item: (dep - ordered) for item, dep in data.items() if item not in ordered}\n",
    "    assert not data, \"A cyclic dependency exists amongst %r\" % data\n",
    " \n",
    "print ('\\n'.join( toposort2(data) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#print(math.log(math.factorial(5)))\n",
    "xr = range(1,10)\n",
    "y = [math.log(math.factorial(x)) for x in xr]\n",
    "y1 = [sum([math.log(xx) for xx in range(1,x+1)]) for x in xr]\n",
    "plt.scatter(xr, y)\n",
    "plt.scatter(xr, y1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# various norms and distances graph\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def l1_norm(v):\n",
    "    '''L1 distance'''\n",
    "    norm = np.sum(v)\n",
    "    return v / norm\n",
    "\n",
    "def l2_norm(v):\n",
    "    '''L2 distance'''\n",
    "    norm = np.sqrt(np.sum(np.square(v)))\n",
    "    return v / norm\n",
    "\n",
    "def froto(p, q):\n",
    "    '''vector from p to q'''\n",
    "    return np.array(p) - np.array(q)\n",
    "\n",
    "def hellingm(p, q):\n",
    "    '''returns Hellinger metric for distributions p and q'''\n",
    "    if len(p) != len(q):\n",
    "        return -1\n",
    "    hm = 0.\n",
    "    for idx, elp in enumerate(p):\n",
    "        hm += (math.sqrt(elp) - math.sqrt(max(q[idx], 0.)))**2\n",
    "    return math.sqrt(hm) / math.sqrt(2.)\n",
    "\n",
    "def euclid(p, q):\n",
    "    '''Euclidean metric for distributions p and q'''\n",
    "    if len(p) != len(q):\n",
    "        return -1\n",
    "    ec = 0.\n",
    "    for idx, elp in enumerate(p):\n",
    "        ec += (elp - q[idx]) ** 2\n",
    "    return math.sqrt(ec) \n",
    "\n",
    "def minkovfr(p, q, pp):\n",
    "    '''Minkowski and fractional metric for distributions p and q'''\n",
    "    if len(p) != len(q):\n",
    "        return -1\n",
    "    ec = 0.\n",
    "    for idx, elp in enumerate(p):\n",
    "        ec += (elp - q[idx]) ** pp\n",
    "    return ec ** (1. / pp)\n",
    "\n",
    "def cosine(p, q):\n",
    "    '''cosine similarity for distributions p and q'''\n",
    "    if len(p) != len(q):\n",
    "        return -1\n",
    "    cs = 0.\n",
    "    pn = 0.\n",
    "    qn = 0.\n",
    "    for idx, elp in enumerate(p):\n",
    "        cs += elp * q[idx]\n",
    "        pn += elp * elp\n",
    "        qn += q[idx] * q[idx]\n",
    "    if cs > 0. and pn > 0. and qn > 0.:\n",
    "        return math.sqrt(cs) / math.sqrt(pn) / math.sqrt(qn)\n",
    "    return 0\n",
    "\n",
    "def jaccind(a, b):\n",
    "    '''returns the Jaccard index for two sets a, b'''\n",
    "    return len(a.intersection(b)) / len(a.union(b))\n",
    "\n",
    "def kullei(p, q):\n",
    "    '''Kullback-Leibler divergence (modified)'''\n",
    "    return np.sum(np.dot(p, np.array([np.log(p / (q0 + 1) + 1) for q0 in q])))\n",
    "\n",
    "def main():\n",
    "    vx = np.array([1., 0.])\n",
    "    xc = range(12)\n",
    "    yc = []\n",
    "    yh = []\n",
    "    ye = []\n",
    "    yd = []\n",
    "    ykl = []\n",
    "    for phi in range(0,12):\n",
    "        vy = np.array([math.cos(phi), math.sin(phi)])\n",
    "        yc.append(cosine(vx, vy))\n",
    "        yh.append(hellingm(vx, vy))\n",
    "        ye.append(euclid(vx, vy))\n",
    "        yd.append(np.dot(vx, vy))\n",
    "        ykl.append(kullei(vx, vy))\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set(xlabel='angle pi/12', ylabel='measure')\n",
    "    plt.plot(xc, yc, marker='o') # Cosine\n",
    "    plt.plot(xc, yh, marker='x') # Helling\n",
    "    plt.plot(xc, ye, marker='+') # Euclid\n",
    "    plt.plot(xc, yd, marker='*') # dot\n",
    "    plt.plot(xc, ykl, marker='.') # KL\n",
    "    ax.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1 0.  0.3]\n",
      " [0.1 0.2 0. ]\n",
      " [0.  0.2 0.3]]\n",
      "[[0.07 0.05 0.1 ]]\n",
      "[[1. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# test q,k,v-attention\n",
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"compute softmax values for each sets of scores in x\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "def main():\n",
    "    q = np.array([[0.1, 0.2, 0.2]])\n",
    "    k = np.array([[0.1, 0, 0.3], [0.1, 0.2, 0], [0, 0.2, 0.3]])\n",
    "    v = np.array([[1., 0., 1.]])\n",
    "    print(k)\n",
    "    print(np.dot(q, k.T))\n",
    "    print(softmax(np.dot(q, k.T)) * v)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1, 2, 3, 4, 6, 7, 9, 8)\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def analloc(d1, d2, a0, a1, a2, l0, l1):\n",
    "    if (a0 + l0) % 2 == 0 and a2 + d2 < 10:\n",
    "        res = ( int((a0 + l0) / 2), d1, d2, a0, a1, a2, l0, l1, d2 + a2)\n",
    "        #if res[2] < res[1] or res[5] < res[4] or res[8] < res[7]:\n",
    "            #return ()\n",
    "        for i in range(1,10):\n",
    "            if res.count(i) > 1:\n",
    "                return ()\n",
    "        return res\n",
    "    return ()\n",
    "\n",
    "def main():\n",
    "    #print(analloc(1, 2, 3, 4, 5, 6, 7))\n",
    "    #print(list(itertools.permutations(range(1,4))))\n",
    "    for tpl in list(itertools.combinations(range(1,10), 7)):\n",
    "        res = analloc(tpl[0], tpl[1], tpl[2], tpl[3], tpl[4], tpl[5], tpl[6])\n",
    "        if len(res) > 0:\n",
    "            print(res)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\venv\\lib\\site-packages\\ipykernel_launcher.py:84: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "d:\\anaconda\\envs\\venv\\lib\\site-packages\\ipykernel_launcher.py:86: DeprecationWarning: `imshow` is deprecated!\n",
      "`imshow` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``matplotlib.pyplot.imshow`` instead.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "numpy boolean subtract, the `-` operator, is deprecated, use the bitwise_xor, the `^` operator, or the logical_xor function instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-73233302b9d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test.jpg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"L\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Open image, convert to greyscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mfinalEdges\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCannyEdgeDetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m         \u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfinalEdges\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\anaconda\\envs\\venv\\lib\\site-packages\\numpy\\lib\\utils.py\u001b[0m in \u001b[0;36mnewfunc\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;34m\"\"\"`arrayrange` is deprecated, use `arange` instead!\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mnewfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_set_function_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\venv\\lib\\site-packages\\scipy\\misc\\pilutil.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(arr)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoimage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m     \u001b[0mfnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkstemp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\venv\\lib\\site-packages\\numpy\\lib\\utils.py\u001b[0m in \u001b[0;36mnewfunc\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;34m\"\"\"`arrayrange` is deprecated, use `arange` instead!\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mnewfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_set_function_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\venv\\lib\\site-packages\\scipy\\misc\\pilutil.py\u001b[0m in \u001b[0;36mtoimage\u001b[1;34m(arr, high, low, cmin, cmax, pal, mode, channel_axis)\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'L'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'P'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m             bytedata = bytescale(data, high=high, low=low,\n\u001b[1;32m--> 337\u001b[1;33m                                  cmin=cmin, cmax=cmax)\n\u001b[0m\u001b[0;32m    338\u001b[0m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrombytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'L'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytedata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtostring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpal\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\venv\\lib\\site-packages\\numpy\\lib\\utils.py\u001b[0m in \u001b[0;36mnewfunc\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m     99\u001b[0m             \u001b[1;34m\"\"\"`arrayrange` is deprecated, use `arange` instead!\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdepdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDeprecationWarning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[0mnewfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_set_function_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\venv\\lib\\site-packages\\scipy\\misc\\pilutil.py\u001b[0m in \u001b[0;36mbytescale\u001b[1;34m(data, cmin, cmax, high, low)\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mcmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m     \u001b[0mcscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcmax\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcscale\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"`cmax` should be larger than `cmin`.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: numpy boolean subtract, the `-` operator, is deprecated, use the bitwise_xor, the `^` operator, or the logical_xor function instead."
     ]
    }
   ],
   "source": [
    "#!/bin/python\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import convolve, gaussian_filter\n",
    "from scipy.misc import imread, imshow\n",
    " \n",
    "def CannyEdgeDetector(im, blur = 1, highThreshold = 91, lowThreshold = 31):\n",
    "\tim = np.array(im, dtype=float) #Convert to float to prevent clipping values\n",
    " \n",
    "\t#Gaussian blur to reduce noise\n",
    "\tim2 = gaussian_filter(im, blur)\n",
    " \n",
    "\t#Use sobel filters to get horizontal and vertical gradients\n",
    "\tim3h = convolve(im2,[[-1,0,1],[-2,0,2],[-1,0,1]]) \n",
    "\tim3v = convolve(im2,[[1,2,1],[0,0,0],[-1,-2,-1]])\n",
    " \n",
    "\t#Get gradient and direction\n",
    "\tgrad = np.power(np.power(im3h, 2.0) + np.power(im3v, 2.0), 0.5)\n",
    "\ttheta = np.arctan2(im3v, im3h)\n",
    "\tthetaQ = (np.round(theta * (5.0 / np.pi)) + 5) % 5 #Quantize direction\n",
    " \n",
    "\t#Non-maximum suppression\n",
    "\tgradSup = grad.copy()\n",
    "\tfor r in range(im.shape[0]):\n",
    "\t\tfor c in range(im.shape[1]):\n",
    "\t\t\t#Suppress pixels at the image edge\n",
    "\t\t\tif r == 0 or r == im.shape[0]-1 or c == 0 or c == im.shape[1] - 1:\n",
    "\t\t\t\tgradSup[r, c] = 0\n",
    "\t\t\t\tcontinue\n",
    "\t\t\ttq = thetaQ[r, c] % 4\n",
    " \n",
    "\t\t\tif tq == 0: #0 is E-W (horizontal)\n",
    "\t\t\t\tif grad[r, c] <= grad[r, c-1] or grad[r, c] <= grad[r, c+1]:\n",
    "\t\t\t\t\tgradSup[r, c] = 0\n",
    "\t\t\tif tq == 1: #1 is NE-SW\n",
    "\t\t\t\tif grad[r, c] <= grad[r-1, c+1] or grad[r, c] <= grad[r+1, c-1]:\n",
    "\t\t\t\t\tgradSup[r, c] = 0\n",
    "\t\t\tif tq == 2: #2 is N-S (vertical)\n",
    "\t\t\t\tif grad[r, c] <= grad[r-1, c] or grad[r, c] <= grad[r+1, c]:\n",
    "\t\t\t\t\tgradSup[r, c] = 0\n",
    "\t\t\tif tq == 3: #3 is NW-SE\n",
    "\t\t\t\tif grad[r, c] <= grad[r-1, c-1] or grad[r, c] <= grad[r+1, c+1]:\n",
    "\t\t\t\t\tgradSup[r, c] = 0\n",
    " \n",
    "\t#Double threshold\n",
    "\tstrongEdges = (gradSup > highThreshold)\n",
    " \n",
    "\t#Strong has value 2, weak has value 1\n",
    "\tthresholdedEdges = np.array(strongEdges, dtype=np.uint8) + (gradSup > lowThreshold)\n",
    " \n",
    "\t#Tracing edges with hysteresis\t\n",
    "\t#Find weak edge pixels near strong edge pixels\n",
    "\tfinalEdges = strongEdges.copy()\n",
    "\tcurrentPixels = []\n",
    "\tfor r in range(1, im.shape[0]-1):\n",
    "\t\tfor c in range(1, im.shape[1]-1):\t\n",
    "\t\t\tif thresholdedEdges[r, c] != 1:\n",
    "\t\t\t\tcontinue #Not a weak pixel\n",
    " \n",
    "\t\t\t#Get 3x3 patch\t\n",
    "\t\t\tlocalPatch = thresholdedEdges[r-1:r+2,c-1:c+2]\n",
    "\t\t\tpatchMax = localPatch.max()\n",
    "\t\t\tif patchMax == 2:\n",
    "\t\t\t\tcurrentPixels.append((r, c))\n",
    "\t\t\t\tfinalEdges[r, c] = 1\n",
    " \n",
    "\t#Extend strong edges based on current pixels\n",
    "\twhile len(currentPixels) > 0:\n",
    "\t\tnewPix = []\n",
    "\t\tfor r, c in currentPixels:\n",
    "\t\t\tfor dr in range(-1, 2):\n",
    "\t\t\t\tfor dc in range(-1, 2):\n",
    "\t\t\t\t\tif dr == 0 and dc == 0: continue\n",
    "\t\t\t\t\tr2 = r+dr\n",
    "\t\t\t\t\tc2 = c+dc\n",
    "\t\t\t\t\tif thresholdedEdges[r2, c2] == 1 and finalEdges[r2, c2] == 0:\n",
    "\t\t\t\t\t\t#Copy this weak pixel to final result\n",
    "\t\t\t\t\t\tnewPix.append((r2, c2))\n",
    "\t\t\t\t\t\tfinalEdges[r2, c2] = 1\n",
    "\t\tcurrentPixels = newPix\n",
    " \n",
    "\treturn finalEdges\n",
    " \n",
    "if __name__==\"__main__\":\n",
    "\tim = imread(\"test.jpg\", mode=\"L\") #Open image, convert to greyscale\n",
    "\tfinalEdges = CannyEdgeDetector(im)\n",
    "\timshow(finalEdges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', (1, 1), (0, 3), 'b', (2, 6), (1, 7), 'c']\n",
      "['a', (0, 1), (1, 3), 'b', (2, 6), (0, 7), 'c']\n"
     ]
    }
   ],
   "source": [
    "def multisplit(text, sep):\n",
    "    lastmatch = i = 0\n",
    "    matches = []\n",
    "    while i < len(text):\n",
    "        for j, s in enumerate(sep):\n",
    "            if text[i:].startswith(s):\n",
    "                if i > lastmatch:\n",
    "                    matches.append(text[lastmatch:i])\n",
    "                matches.append((j, i))  # Replace the string containing the matched separator with a tuple of which separator and where in the string the match occured\n",
    "                lastmatch = i + len(s)\n",
    "                i += len(s)\n",
    "                break\n",
    "        else:\n",
    "            i += 1\n",
    "    if i > lastmatch:\n",
    "        matches.append(text[lastmatch:i])\n",
    "    return matches\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    print(multisplit('a!===b=!=c', ['==', '!=', '=']))\n",
    "    print(multisplit('a!===b=!=c', ['!=', '==', '=']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8464393446710154\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    " \n",
    "def entropy(s):\n",
    "    p, lns = Counter(s), float(len(s)) # Counter({'4': 4, '3': 3, '2': 2, '1': 1})\n",
    "    return -sum( count/lns * math.log(count/lns, 2) for count in p.values())\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    print(entropy(\"1223334444\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter text: The extent and importance of autoimmune mechanisms in myelodysplastic syndrome (MDS) and the  role of immunosuppression in the treatment of this disease are not well defined. We report overrepresentation  of HLA-DR2 and its serologic split HLA-DR15 in both MDS and aplastic anemia (AA). Four clinically and ethnically  defined patient groups were analyzed. The HLA-DR15 antigen frequencies among North American white MDS patients  (n = 72) and AA patients (n = 59), who received immunosuppressive treatment at the National Institutes of Health  (NIH), were 36% and 42%, respectively. These antigen frequencies were significantly higher than that of the  control population of 240 North American white NIH blood donors typed for HLA antigens by the same molecular  technique (HLA-DR15, 21.3%, P =.01 for MDS, P <.001 for AA). Among North American white patients reported in the  International Bone Marrow Transplant Registry (IBMTR), 30% of 341 MDS patients and 33% of 364 AA patients were  positive for HLA-DR2. These antigen frequencies were higher than those reported for the general North American  white population (HLA-DR2, 25.3%, P =.089 for MDS, P =.01 for AA). The DR15 and DR2 frequencies were significantly  increased in MDS refractory anemia (RA) (P =.036 and P =.01, respectively) but not MDS refractory anemia with  excess blasts. In the NIH MDS patients, HLA-DR15 was significantly associated with a clinically relevant  response to antithymocyte globulin (ATG) or cyclosporine immunosuppression (multivariate analysis, P =.008).  In MDS with RA, DR15 may be useful as a guide to pathophysiology, prognosis, and treatment.\n",
      "++++++++++++++++++++++++++++++++++++++\n",
      "4.7829683674857835\n"
     ]
    }
   ],
   "source": [
    "# text entropy 2\n",
    "import math\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def entropy(s):\n",
    "    '''calclate information entropy of given text'''\n",
    "    p, lns = Counter(s), float(len(s)) # Counter({'4': 4, '3': 3, '2': 2, '1': 1})\n",
    "    return -sum( count/lns * math.log(count/lns, 2) for count in p.values())\n",
    "        \n",
    "def main():\n",
    "    piece = input(\"Enter text: \").replace('\\n', ' ').replace('\\r', ' ')\n",
    "    print('++++++++++++++++++++++++++++++++++++++')\n",
    "    #print(uniqc(piece))\n",
    "    print(entropy(piece))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.54400374531753\n"
     ]
    }
   ],
   "source": [
    "# average root mean square\n",
    "import math\n",
    "\n",
    "def arms(xl):\n",
    "    '''average root mean square (quadratic mean)'''\n",
    "    return math.sqrt(sum([x*x for x in xl]))\n",
    "\n",
    "def main():\n",
    "    print(arms([-2, 0, 1, 2, 8]))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "♘♘♘♘♘♘♘♘♘♘♘♘♘♞♘♘♘♞♘♞♘♘♘♞♘♘♘♘♘♘\n",
      "♘♘♘♘♘♘♘♘♘♘♘♘♞♘♘♘♞♘♘♘♘♘♘♘♞♘♘♘♞♘\n",
      "♘♞♘♘♘♞♘♘♘♘♘♘♘♘♘♘♘♞♘♞♘♘♘♘♘♞♘♘♘♘\n",
      "♞♘♞♘♘♘♘♘♞♘♞♘♘♘♘♘♞♘♘♘♘♘♞♘♘♘♘♘♘♘\n",
      "♘♘♘♘♘♘♘♘♘♞♘♘♘♘♘♘♘♘♘♘♘♞♘♘♘♞♘♘♘♘\n",
      "♘♘♘♘♞♘♘♘♞♘♘♘♘♘♘♘♞♘♘♘♘♘♞♘♘♘♘♘♘♘\n",
      "♘♘♘♞♘♘♘♘♘♘♘♘♘♞♘♘♘♞♘♞♘♘♘♞♘♞♘♞♘♘\n",
      "♘♘♘♘♘♘♞♘♘♘♘♘♞♘♘♘♘♘♘♘♘♘♞♘♞♘♘♘♞♘\n",
      "♘♞♘♘♘♘♘♞♘♘♘♞♘♞♘♘♘♘♘♘♘♘♘♘♘♘♘♘♘♞\n",
      "♘♘♘♘♘♘♘♘♘♘♘♘♘♘♞♘♞♘♘♘♘♘♞♘♘♘♞♘♘♘\n",
      "♘♘♘♞♘♘♘♞♘♞♘♘♘♞♘♘♘♘♘♘♘♞♘♘♘♞♘♞♘♘\n",
      "♘♘♘♘♘♘♘♘♘♘♘♘♘♘♞♘♞♘♘♘♞♘♘♘♘♘♘♘♘♘\n",
      "♘♘♘♘♘♞♘♘♘♞♘♞♘♘♘♘♘♞♘♞♘♞♘♘♘♘♘♞♘♞\n",
      "♞♘♞♘♞♘♞♘♞♘♞♘♞♘♘♘♞♘♘♘♘♘♘♘♞♘♘♘♘♘\n",
      "♘♘♘♘♘♘♘♘♘♘♘♘♘♞♘♞♘♞♘♘♘♘♘♘♘♘♘♘♘♞\n",
      "♘♘♘♘♘♘♘♘♞♘♘♘♞♘♘♞♞♘♞♘♞♘♞♘♘♘♞♘♞♘\n",
      "♘♞♘♘♘♘♘♘♘♞♘♞♘♞♘♘♘♘♘♘♘♘♘♘♘♘♘♘♘♘\n",
      "♘♘♘♘♘♘♘♘♘♘♞♘♘♘♞♘♘♘♘♘♘♘♘♘♘♘♘♘♘♘\n",
      "♘♘♘♞♘♞♘♘♘♞♘♞♘♘♘♞♘♘♘♞♘♞♘♘♘♞♘♘♘♞\n",
      "♘♘♞♘♘♘♞♘♘♘♞♘♘♘♘♘♞♘♘♘♘♘♞♘♞♘♘♘♞♘\n",
      "♘♘♘♘♘♘♘♘♘♘♘♞♘♘♘♘♘♘♘♘♘♘♘♞♘♘♘♘♘♘\n",
      "♘♘♘♘♘♘♞♘♞♘♘♘♘♘♞♘♘♘♞♘♘♘♞♘♘♘♘♘♘♘\n",
      "♘♘♘♞♘♘♘♞♘♘♘♘♘♘♘♘♘♘♘♞♘♘♘♘♘♘♘♞♘♘\n",
      "♘♘♘♘♞♘♘♘♘♘♞♘♘♘♞♘♞♘♘♘♘♘♘♘♘♘♘♘♘♘\n",
      "♘♘♘♘♘♘♘♘♘♞♘♞♘♘♘♞♘♘♘♘♘♞♘♘♘♞♘♘♘♘\n",
      "♞♘♞♘♞♘♘♘♘♘♘♘♘♘♞♘♞♘♘♘♘♘♞♘♘♘♘♘♞♘\n",
      "♘♞♘♘♘♞♘♘♘♘♘♘♘♘♘♘♘♞♘♞♘♘♘♘♘♘♘♘♘♘\n",
      "♞♘♞♘♘♘♘♘♞♘♘♘♘♘♞♘♘♘♞♘♞♘♘♘♘♘♘♘♘♘\n",
      "♘♘♘♘♘♘♘♞♘♘♘♘♘♘♘♘♘♞♘♘♘♘♘♘♘♞♘♘♘♘\n",
      "♘♘♘♘♘♘♘♘♞♘♞♘♘♘♞♘♞♘♘♘♘♘♘♘♘♘♞♘♘♘\n",
      "\n",
      " -  -  - 397  -  -  -  -  -  -  - 389  -  -  -  -  - 383  -  - \n",
      " -  -  -  -  -  -  -  - 317  -  -  - 313  - 311  -  -  - 307  - \n",
      " - 257  -  -  -  -  - 251  -  -  -  -  -  -  -  -  - 241  - 379 \n",
      " -  - 197  -  -  - 193  - 191  -  -  -  -  -  -  -  -  -  -  - \n",
      " -  -  -  -  -  -  -  -  - 139  - 137  -  -  -  -  - 239  -  - \n",
      " -  - 199  - 101  -  -  -  97  -  -  -  -  -  -  - 181  -  -  - \n",
      " -  -  -  -  -  -  -  -  -  61  -  59  -  -  - 131  -  -  -  - \n",
      "331  -  -  - 103  -  37  -  -  -  -  -  31  -  89  - 179  -  -  - \n",
      " - 263  - 149  -  67  -  17  -  -  -  13  -  -  -  -  -  -  - 373 \n",
      " -  -  -  -  -  -  -  -   5  -   3  -  29  -  -  -  -  -  -  - \n",
      " -  -  - 151  -  -  -  19  -  -   2  11  -  53  - 127  - 233  -  - \n",
      " -  -  -  - 107  -  41  -   7  -  -  -  -  -  -  -  -  -  -  - \n",
      " -  -  -  -  -  71  -  -  -  23  -  -  -  -  -  -  -  -  -  - \n",
      "337  -  -  - 109  -  43  -  -  -  47  -  -  -  83  - 173  -  -  - \n",
      " - 269  -  -  -  73  -  -  -  -  -  79  -  -  -  -  - 229  - 367 \n",
      " -  -  -  -  -  - 113  -  -  -  -  -  -  -  -  -  -  - 293  - \n",
      " - 271  - 157  -  -  -  -  - 163  -  -  - 167  -  -  - 227  -  - \n",
      " -  - 211  -  -  -  -  -  -  -  -  -  -  - 223  -  -  -  -  - \n",
      " -  -  -  -  - 277  -  -  - 281  - 283  -  -  -  -  -  -  -  - \n",
      " -  -  -  - 347  - 349  -  -  - 353  -  -  -  -  - 359  -  -  - \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# coding=UTF-8\n",
    "from __future__ import print_function, division\n",
    "from math import sqrt\n",
    " \n",
    "def cell(n, x, y, start=1):\n",
    "    d, y, x = 0, y - n//2, x - (n - 1)//2\n",
    "    l = 2*max(abs(x), abs(y))\n",
    "    d = (l*3 + x + y) if y >= x else (l - x - y)\n",
    "    return (l - 1)**2 + d + start - 1\n",
    " \n",
    "def show_spiral(n, symbol='# ', start=1, space=None):\n",
    "    top = start + n*n + 1\n",
    "    is_prime = [False,False,True] + [True,False]*(top//2)\n",
    "    for x in range(3, 1 + int(sqrt(top))):\n",
    "        if not is_prime[x]: continue\n",
    "        for i in range(x*x, top, x*2):\n",
    "            is_prime[i] = False\n",
    " \n",
    "    cell_str = lambda x: f(x) if is_prime[x] else space\n",
    "    f = lambda _: symbol # how to show prime cells\n",
    " \n",
    "    if space == None: space = ' '*len(symbol)\n",
    " \n",
    "    if not len(symbol): # print numbers instead\n",
    "        max_str = len(str(n*n + start - 1))\n",
    "        if space == None: space = '.'*max_str + ' '\n",
    "        f = lambda x: ('%' + str(max_str) + 'd ')%x\n",
    " \n",
    "    for y in range(n):\n",
    "        print(''.join(cell_str(v) for v in [cell(n, x, y, start) for x in range(n)]))\n",
    "    print()\n",
    " \n",
    "show_spiral(30, symbol=u'♞', space=u'♘') # black are the primes\n",
    "show_spiral(20, symbol='', space=' - ')\n",
    "# for filling giant terminals\n",
    "#show_spiral(1001, symbol='*', start=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    " \n",
    " \n",
    "class BarnsleyFern(object):\n",
    "    def __init__(self, img_width, img_height, paint_color=(0, 150, 0),\n",
    "                 bg_color=(255, 255, 255)):\n",
    "        self.img_width, self.img_height = img_width, img_height\n",
    "        self.paint_color = paint_color\n",
    "        self.x, self.y = 0, 0\n",
    "        self.age = 0\n",
    " \n",
    "        self.fern = Image.new('RGB', (img_width, img_height), bg_color)\n",
    "        self.pix = self.fern.load()\n",
    "        self.pix[self.scale(0, 0)] = paint_color\n",
    " \n",
    "    def scale(self, x, y):\n",
    "        h = (x + 2.182)*(self.img_width - 1)/4.8378\n",
    "        k = (9.9983 - y)*(self.img_height - 1)/9.9983\n",
    "        return h, k\n",
    " \n",
    "    def transform(self, x, y):\n",
    "        rand = random.uniform(0, 100)\n",
    "        if rand < 1:\n",
    "            return 0, 0.16*y\n",
    "        elif 1 <= rand < 86:\n",
    "            return 0.85*x + 0.04*y, -0.04*x + 0.85*y + 1.6\n",
    "        elif 86 <= rand < 93:\n",
    "            return 0.2*x - 0.26*y, 0.23*x + 0.22*y + 1.6\n",
    "        else:\n",
    "            return -0.15*x + 0.28*y, 0.26*x + 0.24*y + 0.44\n",
    " \n",
    "    def iterate(self, iterations):\n",
    "        for _ in range(iterations):\n",
    "            self.x, self.y = self.transform(self.x, self.y)\n",
    "            self.pix[self.scale(self.x, self.y)] = self.paint_color\n",
    "        self.age += iterations\n",
    " \n",
    "fern = BarnsleyFern(500, 500)\n",
    "fern.iterate(1000000)\n",
    "fern.fern.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'credentials.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-b3c1ed112cd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;31m# Extracts credentials for the login and all of the profiles URL to scrape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m     \u001b[0mcredentials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_to_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'credentials.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m     \u001b[0mprofiles_urls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson_to_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'profiles_urls.json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-b3c1ed112cd0>\u001b[0m in \u001b[0;36mjson_to_obj\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \"\"\"\n\u001b[0;32m    188\u001b[0m     \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m         \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'credentials.json'"
     ]
    }
   ],
   "source": [
    "# https://python.gotrained.com/scraping-facebook-posts-comments/\n",
    "import requests\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import logging\n",
    "import pandas\n",
    "from collections import OrderedDict\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "\n",
    "def get_bs(session, url):\n",
    "    \"\"\"Makes a GET requests using the given Session object\n",
    "    and returns a BeautifulSoup object.\n",
    "    \"\"\"\n",
    "    r = None\n",
    "    while True:\n",
    "        r = session.get(url)\n",
    "        if r.ok:\n",
    "            break\n",
    "    return BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "\n",
    "def make_login(session, base_url, credentials):\n",
    "    \"\"\"Returns a Session object logged in with credentials.\n",
    "    \"\"\"\n",
    "    login_form_url = '/login/device-based/regular/login/?refsrc=https%3A'\\\n",
    "        '%2F%2Fmobile.facebook.com%2Flogin%2Fdevice-based%2Fedit-user%2F&lwv=100'\n",
    "\n",
    "    params = {'email':credentials['email'], 'pass':credentials['pass']}\n",
    "\n",
    "    while True:\n",
    "        time.sleep(3)\n",
    "        logged_request = session.post(base_url+login_form_url, data=params)\n",
    "        \n",
    "        if logged_request.ok:\n",
    "            logging.info('[*] Logged in.')\n",
    "            break\n",
    "\n",
    "\n",
    "def crawl_profile(session, base_url, profile_url, post_limit):\n",
    "    \"\"\"Goes to profile URL, crawls it and extracts posts URLs.\n",
    "    \"\"\"\n",
    "    profile_bs = get_bs(session, profile_url)\n",
    "    n_scraped_posts = 0\n",
    "    scraped_posts = list()\n",
    "    posts_id = None\n",
    "\n",
    "    while n_scraped_posts < post_limit:\n",
    "        try:\n",
    "            posts_id = 'recent'\n",
    "            posts = profile_bs.find('div', id=posts_id).div.div.contents\n",
    "        except Exception:\n",
    "            posts_id = 'structured_composer_async_container'\n",
    "            posts = profile_bs.find('div', id=posts_id).div.div.contents\n",
    "\n",
    "        posts_urls = [a['href'] for a in profile_bs.find_all('a', text='Full Story')] \n",
    "\n",
    "        for post_url in posts_urls:\n",
    "            # print(post_url)\n",
    "            try:\n",
    "                post_data = scrape_post(session, base_url, post_url)\n",
    "                scraped_posts.append(post_data)\n",
    "            except Exception as e:\n",
    "                logging.info('Error: {}'.format(e))\n",
    "            n_scraped_posts += 1\n",
    "            if posts_completed(scraped_posts, post_limit):\n",
    "                break\n",
    "        \n",
    "        show_more_posts_url = None\n",
    "        if not posts_completed(scraped_posts, post_limit):\n",
    "            show_more_posts_url = profile_bs.find('div', id=posts_id).next_sibling.a['href']\n",
    "            profile_bs = get_bs(session, base_url+show_more_posts_url)\n",
    "            time.sleep(3)\n",
    "        else:\n",
    "            break\n",
    "    return scraped_posts\n",
    "\n",
    "def posts_completed(scraped_posts, limit):\n",
    "    \"\"\"Returns true if the amount of posts scraped from\n",
    "    profile has reached its limit.\n",
    "    \"\"\"\n",
    "    if len(scraped_posts) == limit:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def scrape_post(session, base_url, post_url):\n",
    "    \"\"\"Goes to post URL and extracts post data.\n",
    "    \"\"\"\n",
    "    post_data = OrderedDict()\n",
    "\n",
    "    post_bs = get_bs(session, base_url+post_url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Here we populate the OrderedDict object\n",
    "    post_data['url'] = post_url\n",
    "\n",
    "    try:\n",
    "        post_text_element = post_bs.find('div', id='u_0_0').div\n",
    "        string_groups = [p.strings for p in post_text_element.find_all('p')]\n",
    "        strings = [repr(string) for group in string_groups for string in group]\n",
    "        post_data['text'] = strings\n",
    "    except Exception:\n",
    "        post_data['text'] = []\n",
    "    \n",
    "    try:\n",
    "        post_data['media_url'] = post_bs.find('div', id='u_0_0').find('a')['href']\n",
    "    except Exception:\n",
    "        post_data['media_url'] = ''\n",
    "    \n",
    "\n",
    "    try:\n",
    "        post_data['comments'] = extract_comments(session, base_url, post_bs, post_url)\n",
    "    except Exception:\n",
    "        post_data['comments'] = []\n",
    "    \n",
    "    return dict(post_data)\n",
    "\n",
    "\n",
    "def extract_comments(session, base_url, post_bs, post_url):\n",
    "    \"\"\"Extracts all coments from post\n",
    "    \"\"\"\n",
    "    comments = list()\n",
    "    show_more_url = post_bs.find('a', href=re.compile('/story\\.php\\?story'))['href']\n",
    "    first_comment_page = True\n",
    "\n",
    "    logging.info('Scraping comments from {}'.format(post_url))\n",
    "    while True:\n",
    "\n",
    "        logging.info('[!] Scraping comments.')\n",
    "        time.sleep(3)\n",
    "        if first_comment_page:\n",
    "            first_comment_page = False\n",
    "        else:\n",
    "            post_bs = get_bs(session, base_url+show_more_url)\n",
    "            time.sleep(3)\n",
    "        \n",
    "        try:\n",
    "            comments_elements = post_bs.find('div', id=re.compile('composer')).next_sibling\\\n",
    "                .find_all('div', id=re.compile('^\\d+'))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "        if len(comments_elements) != 0:\n",
    "            logging.info('[!] There are comments.')\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        for comment in comments_elements:\n",
    "            comment_data = OrderedDict()\n",
    "            comment_data['text'] = list()\n",
    "            try:\n",
    "                comment_strings = comment.find('h3').next_sibling.strings\n",
    "                for string in comment_strings:\n",
    "                    comment_data['text'].append(string)\n",
    "            except Exception:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                media = comment.find('h3').next_sibling.next_sibling.children\n",
    "                if media is not None:\n",
    "                    for element in media:\n",
    "                        comment_data['media_url'] = element['src']\n",
    "                else:\n",
    "                    comment_data['media_url'] = ''\n",
    "            except Exception:\n",
    "                pass\n",
    "            \n",
    "            comment_data['profile_name'] = comment.find('h3').a.string\n",
    "            comment_data['profile_url'] = comment.find('h3').a['href'].split('?')[0]\n",
    "            comments.append(dict(comment_data))\n",
    "        \n",
    "        show_more_url = post_bs.find('a', href=re.compile('/story\\.php\\?story'))\n",
    "        if 'View more' in show_more_url.text:\n",
    "            logging.info('[!] More comments.')\n",
    "            show_more_url = show_more_url['href']\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return comments\n",
    "\n",
    "\n",
    "def json_to_obj(filename):\n",
    "    \"\"\"Extracts dta from JSON file and saves it on Python object\n",
    "    \"\"\"\n",
    "    obj = None\n",
    "    with open(filename) as json_file:\n",
    "        obj = json.loads(json_file.read())\n",
    "    return obj\n",
    "\n",
    "\n",
    "def save_data(data):\n",
    "    \"\"\"Converts data to JSON.\n",
    "    \"\"\"\n",
    "    with open('profile_posts_data.json', 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    base_url = 'https://mobile.facebook.com'\n",
    "    session = requests.session()\n",
    "\n",
    "    # Extracts credentials for the login and all of the profiles URL to scrape\n",
    "    credentials = json_to_obj('credentials.json')\n",
    "    profiles_urls = json_to_obj('profiles_urls.json')\n",
    "\n",
    "    make_login(session, base_url, credentials)\n",
    "\n",
    "    posts_data = None\n",
    "    for profile_url in profiles_urls:\n",
    "        posts_data = crawl_profile(session, base_url, profile_url, 25)\n",
    "    logging.info('[!] Scraping finished. Total: {}'.format(len(posts_data)))\n",
    "    logging.info('[!] Saving.')\n",
    "    save_data(posts_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "8\n",
      "13\n",
      "21\n",
      "34\n",
      "55\n",
      "89\n",
      "144\n",
      "233\n",
      "377\n",
      "610\n",
      "987\n",
      "1597\n",
      "2584\n",
      "4181\n",
      "6765\n"
     ]
    }
   ],
   "source": [
    "from math import *\n",
    " \n",
    "def analytic_fibonacci(n):\n",
    "    '''Fibonacci analytically'''\n",
    "    sqrt_5 = sqrt(5)\n",
    "    p = (1 + sqrt_5) / 2\n",
    "    q = 1/p\n",
    "    return int( (p**n + q**n) / sqrt_5 + 0.5 )\n",
    " \n",
    "for i in range(1,21):\n",
    "    print(analytic_fibonacci(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "445\n",
      "445\n",
      "1527229998585248450016808958343740453059\n",
      "1527229998585248450016808958343740453059\n"
     ]
    }
   ],
   "source": [
    "# modular exponentiation\n",
    "\n",
    "def modexp(b, e, m):\n",
    "    '''modular exponentiation'''\n",
    "    c = 1\n",
    "    ed = 0\n",
    "    while ed < e:\n",
    "        ed += 1\n",
    "        c = (b * c) % m\n",
    "    return c\n",
    "\n",
    "def modPow(b, e, m):\n",
    "    '''modular exponentiation faster right-to-left binary'''\n",
    "    if m == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        r = 1\n",
    "        b = b % m\n",
    "        while e > 0:\n",
    "            if e % 2 == 1:\n",
    "                r = (r*b) % m\n",
    "            e = e >> 1\n",
    "            b = (b*b) % m\n",
    "        return r\n",
    "\n",
    "def main():\n",
    "    print(modexp(5, 3, 13))\n",
    "    print(pow(5, 3, 13))\n",
    "    print(modPow(5, 3, 13))\n",
    "    print(modexp(4, 13, 497))\n",
    "    print(pow(4, 13, 497))\n",
    "    a = 2988348162058574136915891421498819466320163312926952423791023078876139\n",
    "    b = 2351399303373464486466122544523690094744975233415544072992656881240319\n",
    "    m = 10 ** 40\n",
    "    #print(modexp(a, b, m))\n",
    "    print(pow(a, b, m))\n",
    "    print(modPow(a, b, m))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pygame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-db3ad1c856cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpygame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpygame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwindow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpygame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m600\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m600\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpygame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_caption\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Fractal Tree\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pygame'"
     ]
    }
   ],
   "source": [
    "import pygame, math\n",
    " \n",
    "pygame.init()\n",
    "window = pygame.display.set_mode((600, 600))\n",
    "pygame.display.set_caption(\"Fractal Tree\")\n",
    "screen = pygame.display.get_surface()\n",
    " \n",
    "def drawTree(x1, y1, angle, depth):\n",
    "    fork_angle = 20\n",
    "    base_len = 10.0\n",
    "    if depth > 0:\n",
    "        x2 = x1 + int(math.cos(math.radians(angle)) * depth * base_len)\n",
    "        y2 = y1 + int(math.sin(math.radians(angle)) * depth * base_len)\n",
    "        pygame.draw.line(screen, (255,255,255), (x1, y1), (x2, y2), 2)\n",
    "        drawTree(x2, y2, angle - fork_angle, depth - 1)\n",
    "        drawTree(x2, y2, angle + fork_angle, depth - 1)\n",
    " \n",
    "def input(event):\n",
    "    if event.type == pygame.QUIT:\n",
    "        exit(0)\n",
    " \n",
    "drawTree(300, 550, -90, 9)\n",
    "pygame.display.flip()\n",
    "while True:\n",
    "    input(pygame.event.wait())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lucky the Scarecrow and the Tin\n",
      "Woodman, for we certainly must climb over the wall. When they were on, Dorothy could not take them\n",
      "off had she wished, but of course she did not wish to leave her little dog behind. Toto had run into\n",
      "the crowd to bark at the birds sitting there. Dorothy went to the Witch's castle, where he was\n",
      "placed \n"
     ]
    }
   ],
   "source": [
    "# Markov chain text generator\n",
    "import sys\n",
    "import random\n",
    " \n",
    "def readdata(file):\n",
    "    '''Read file and return contents.'''\n",
    "    with open(file) as f:\n",
    "        contents = f.read()\n",
    "    return contents\n",
    " \n",
    "def makerule(data, context):\n",
    "    '''Make a rule dict for given data.'''\n",
    "    rule = {}\n",
    "    words = data.split(' ')\n",
    "    index = context\n",
    " \n",
    "    for word in words[index:]:\n",
    "        key = ' '.join(words[index-context:index])\n",
    "        if key in rule:\n",
    "            rule[key].append(word)\n",
    "        else:\n",
    "            rule[key] = [word]\n",
    "        index += 1\n",
    " \n",
    "    return rule\n",
    " \n",
    "def makestring(rule, length):    \n",
    "    '''Use a given rule to make a string.'''\n",
    "    oldwords = random.choice(list(rule.keys())).split(' ') #random starting words\n",
    "    string = ' '.join(oldwords) + ' '\n",
    " \n",
    "    for i in range(length):\n",
    "        try:\n",
    "            key = ' '.join(oldwords)\n",
    "            newword = random.choice(rule[key])\n",
    "            string += newword + ' '\n",
    " \n",
    "            for word in range(len(oldwords)):\n",
    "                oldwords[word] = oldwords[(word + 1) % len(oldwords)]\n",
    "            oldwords[-1] = newword\n",
    " \n",
    "        except KeyError:\n",
    "            return string\n",
    "    return string\n",
    " \n",
    "if __name__ == '__main__':\n",
    "    # Usage: markov.py source.txt context length\n",
    "    #data = readdata(sys.argv[1])\n",
    "    data = '''As soon as they heard her orders they ran away in every direction as fast as they could, Dorothy\n",
    "only stopping once to pick a beautiful flower; and after a time the ladder was ready. The Scarecrow\n",
    "climbed up the ladder first, but he was so anxious to get the new house and my wife as soon as\n",
    "possible. The Lion hesitated no longer, but drank till the dish was empty. How do you do? I'm pretty\n",
    "well, thank you, replied Dorothy politely. How do you do? I'm not feeling well, said the wolf, and\n",
    "he dashed away at full speed, followed by the others. It was lucky the Scarecrow and the Tin\n",
    "Woodman, for we certainly must climb over the wall. When they were on, Dorothy could not take them\n",
    "off had she wished, but of course she did not wish to leave her little dog behind. Toto had run into\n",
    "the crowd to bark at the birds sitting there. Dorothy went to the Witch's castle, where he was\n",
    "placed in a small yard with a high arched room, the walls of which glistened with countless\n",
    "emeralds. Before them stood a little man about the same height as herself; and when she had made out\n",
    "the proper way of nursing it, (which was to twist it up into a sort of lullaby to it as she did not\n",
    "notice when the Scarecrow stumbled into a hole and rolled over to the other side of the Tin Woodman,\n",
    "sadly; for he is much too heavy to carry I shall have to think about that, replied the little old\n",
    "woman as her only friend. No, I cannot do that, she replied, but I will give you some supper and a\n",
    "place to pass the night with you, if you will only hold fast to the tip of my tail.'''\n",
    "    #rule = makerule(data, int(sys.argv[2]))\n",
    "    #string = makestring(rule, int(sys.argv[3]))\n",
    "    rule = makerule(data, 10)\n",
    "    string = makestring(rule, 50)\n",
    "    print(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2501132\n"
     ]
    }
   ],
   "source": [
    "# breaking sticks\n",
    "import random\n",
    "\n",
    "def brkstk(n):\n",
    "    '''break stick of length 1 at n places, returns lengths'''\n",
    "    res = [random.random() for i in range(n)]\n",
    "    res.append(0)\n",
    "    res.append(1)\n",
    "    res.sort()\n",
    "    return [res[i] - res[i-1] for i in range(1,len(res))]\n",
    "\n",
    "def chktri(lbrks):\n",
    "    '''check if triangle ineq holds'''\n",
    "    if lbrks[0]<=lbrks[1]+lbrks[2] and \\\n",
    "        lbrks[1]<=lbrks[2]+lbrks[0] and \\\n",
    "        lbrks[2]<=lbrks[0]+lbrks[1]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def main():\n",
    "    #print(brkstk(2))\n",
    "    #print(chktri(brkstk(2)))\n",
    "    ntrials = 10000000\n",
    "    ctr = 0\n",
    "    for i in range(ntrials):\n",
    "        if chktri(brkstk(2)):\n",
    "            ctr += 1\n",
    "    print(ctr/ntrials)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[1, 1, 2, 3, 5, 8, 13, 21, 34]\n",
      "1870\n"
     ]
    }
   ],
   "source": [
    "def fib(n):\n",
    "    if n < 3:\n",
    "        return 1\n",
    "    f0 = 1\n",
    "    f1 = 1\n",
    "    for i in range(3, n+1):\n",
    "        fn = f0 + f1\n",
    "        f0 = f1\n",
    "        f1 = fn\n",
    "    return fn\n",
    "\n",
    "def main():\n",
    "    print(fib(5))\n",
    "    print([fib(x) for x in range(1,10)])\n",
    "    print(sum([fib(x)**2 for x in range(1,10)]))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.sozialministerium.at/\n",
      "https://www.ages.at/themen/krankheitserreger/coronavirus/\n",
      "https://www.who.int/emergencies/diseases/novel-coronavirus-2019/advice-for-public\n",
      "https://en.wikipedia.org/wiki/2019%E2%80%9320_coronavirus_pandemic\n",
      "https://www.ris.bka.gv.at/GeltendeFassung.wxe?Abfrage=Bundesnormen&Gesetzesnummer=20011073\n"
     ]
    }
   ],
   "source": [
    "# search test time constraints on google\n",
    "# googlesearch.search(query, tld='com', lang='en', tbs='0',\n",
    "# safe='off', num=10, start=0, stop=None, domains=None, pause=2.0,\n",
    "# tpe='', country='', extra_params=None, user_agent=None)[source]\n",
    "# tbs (str) – Time limits (i.e “qdr:h” => last hour, “qdr:d” => last 24 hours, “qdr:m” => last month)\n",
    "# A specific time range, for example from March 2 1984 to June 5 1987: tbs=cdr:1,cd_min:3/2/1984,cd_max:6/5/1987\n",
    "# extra_params (dict) – A dictionary of extra HTTP GET parameters,\n",
    "# which must be URL encoded. For example if you don’t want Google to filter similar\n",
    "# results you can set the extra_params to {‘filter’: ‘0’} which will append ‘&filter=0’ to every query.\n",
    "try: \n",
    "    from googlesearch import search \n",
    "except ImportError:  \n",
    "    print(\"No module named 'google' found\") \n",
    "  \n",
    "# to search \n",
    "query = \"covid-19\"\n",
    "  \n",
    "#for j in search(query, tld=\"co.in\", num=5, stop=5, pause=1):\n",
    "#for j in search(query, tld=\"co.in\", tbs='cdr:2Ccd_min:2F30%2F2020:Ccd_max:2F11%2F2020', num=5, stop=5, pause=2):\n",
    "for j in search(query, tld=\"co.in\", tbs='cdr:1,cd_min:3/1/2020,cd_max:3/20/2020', num=5, stop=5, pause=2): \n",
    "    print(j) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your guess (q for quit): 1\n",
      "Enter your guess (q for quit): 2\n",
      "Enter your guess (q for quit): 3\n",
      "correct!\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# guess the number\n",
    "import random\n",
    "\n",
    "def guess(n):\n",
    "    tn = random.randint(1,n)\n",
    "    while True:\n",
    "        pn = input('Enter your guess (q for quit): ')\n",
    "        if pn == \"q\":\n",
    "            return False\n",
    "        if tn == int(pn):\n",
    "            print('correct!')\n",
    "            return True\n",
    "\n",
    "def main():\n",
    "    print(guess(5))\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(2693.8535, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.reduce_sum(tf.random.normal([1000, 1000])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pugnlp\\constants.py:129: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  FLOAT_TYPES = tuple([t for t in set(np.typeDict.values()) if t.__name__.startswith('float')] + [float])\n",
      "D:\\Anaconda\\lib\\site-packages\\pugnlp\\constants.py:130: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  FLOAT_DTYPES = tuple(set(np.dtype(typ) for typ in FLOAT_TYPES))\n",
      "D:\\Anaconda\\lib\\site-packages\\pugnlp\\constants.py:131: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  INT_TYPES = tuple([t for t in set(np.typeDict.values()) if t.__name__.startswith('int')] + [int])\n",
      "D:\\Anaconda\\lib\\site-packages\\pugnlp\\constants.py:132: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  INT_DTYPES = tuple(set(np.dtype(typ) for typ in INT_TYPES))\n",
      "D:\\Anaconda\\lib\\site-packages\\pugnlp\\constants.py:134: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  NUMERIC_DTYPES = tuple(set(np.dtype(typ) for typ in NUMERIC_TYPES))\n",
      "D:\\Anaconda\\lib\\site-packages\\pugnlp\\constants.py:136: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  DATETIME_TYPES = tuple([t for t in set(np.typeDict.values()) if t.__name__.startswith('datetime')] +\n",
      "D:\\Anaconda\\lib\\site-packages\\pugnlp\\constants.py:141: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  VECTOR_TYPES = (list, tuple, np.matrix, np.ndarray)\n",
      "D:\\Anaconda\\lib\\site-packages\\pugnlp\\constants.py:159: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime instead.\n",
      "  MIN_TIMESTAMP = pd.Timestamp(pd.datetime(1677, 9, 22, 0, 12, 44), tz='utc')\n",
      "D:\\Anaconda\\lib\\site-packages\\pugnlp\\constants.py:167: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  INF = pd.np.inf\n",
      "D:\\Anaconda\\lib\\site-packages\\pugnlp\\constants.py:168: FutureWarning: The pandas.np module is deprecated and will be removed from pandas in a future version. Import numpy directly instead\n",
      "  NAN = pd.np.nan\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import tarfile\n",
    "import tqdm\n",
    "\n",
    "import requests\n",
    "\n",
    "from pugnlp.futil import path_status, find_files\n",
    "import numpy as np  # Keras takes care of most of this but it likes to see Numpy arrays\n",
    "from keras.preprocessing import sequence    # A helper module to handle padding input\n",
    "from keras.models import Sequential         # The base keras Neural Network model\n",
    "from keras.layers import Dense, Dropout, Activation   # The layer objects we will pile into the model\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the nlpia package for downloading data too big for the repo\n",
    "\n",
    "BIG_URLS = {\n",
    "    'w2v': (\n",
    "        'https://www.dropbox.com/s/965dir4dje0hfi4/GoogleNews-vectors-negative300.bin.gz?dl=1',\n",
    "        1647046227,\n",
    "    ),\n",
    "    'slang': (\n",
    "        'https://www.dropbox.com/s/43c22018fbfzypd/slang.csv.gz?dl=1',\n",
    "        117633024,\n",
    "    ),\n",
    "    'tweets': (\n",
    "        'https://www.dropbox.com/s/5gpb43c494mc8p0/tweets.csv.gz?dl=1',\n",
    "        311725313,\n",
    "    ),\n",
    "    'lsa_tweets': (\n",
    "        'https://www.dropbox.com/s/rpjt0d060t4n1mr/lsa_tweets_5589798_2003588x200.tar.gz?dl=1',\n",
    "        3112841563,  # 3112841312,\n",
    "    ),\n",
    "    'imdb': (\n",
    "        'https://www.dropbox.com/s/yviic64qv84x73j/aclImdb_v1.tar.gz?dl=1',\n",
    "        3112841563,  # 3112841312,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions are part of the nlpia package which can be pip installed and run from there.\n",
    "# https://github.com/totalgood/nlpia/blob/master/src/nlpia/book/examples/ch07.ipynb\n",
    "def dropbox_basename(url):\n",
    "    filename = os.path.basename(url)\n",
    "    match = re.findall(r'\\?dl=[0-9]$', filename)\n",
    "    if match:\n",
    "        return filename[:-len(match[0])]\n",
    "    return filename\n",
    "\n",
    "def download_file(url, data_path='.', filename=None, size=None, chunk_size=4096, verbose=True):\n",
    "    \"\"\"Uses stream=True and a reasonable chunk size to be able to download large (GB) files over https\"\"\"\n",
    "    if filename is None:\n",
    "        filename = dropbox_basename(url)\n",
    "    file_path = os.path.join(data_path, filename)\n",
    "    if url.endswith('?dl=0'):\n",
    "        url = url[:-1] + '1'  # noninteractive download\n",
    "    if verbose:\n",
    "        tqdm_prog = tqdm\n",
    "        print('requesting URL: {}'.format(url))\n",
    "    else:\n",
    "        tqdm_prog = no_tqdm\n",
    "    r = requests.get(url, stream=True, allow_redirects=True)\n",
    "    size = r.headers.get('Content-Length', None) if size is None else size\n",
    "    print('remote size: {}'.format(size))\n",
    "\n",
    "    stat = path_status(file_path)\n",
    "    print('local size: {}'.format(stat.get('size', None)))\n",
    "    if stat['type'] == 'file' and stat['size'] == size:  # TODO: check md5 or get the right size of remote file\n",
    "        r.close()\n",
    "        return file_path\n",
    "\n",
    "    print('Downloading to {}'.format(file_path))\n",
    "\n",
    "    with open(file_path, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "            if chunk:  # filter out keep-alive chunks\n",
    "                f.write(chunk)\n",
    "\n",
    "    r.close()\n",
    "    return file_path\n",
    "\n",
    "def untar(fname):\n",
    "    if fname.endswith(\"tar.gz\"):\n",
    "        with tarfile.open(fname) as tf:\n",
    "            tf.extractall()\n",
    "    else:\n",
    "        print(\"Not a tar.gz file: {}\".format(fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting URL: https://www.dropbox.com/s/965dir4dje0hfi4/GoogleNews-vectors-negative300.bin.gz?dl=1\n",
      "remote size: 1647046227\n",
      "local size: None\n",
      "Downloading to .\\GoogleNews-vectors-negative300.bin.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'.\\\\GoogleNews-vectors-negative300.bin.gz'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_file(BIG_URLS['w2v'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requesting URL: https://www.dropbox.com/s/yviic64qv84x73j/aclImdb_v1.tar.gz?dl=1\n",
      "remote size: 84125825\n",
      "local size: None\n",
      "Downloading to .\\aclImdb_v1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "untar(download_file(BIG_URLS['imdb'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, \"Well i am going to go against the grain on this film so it seems. Being a self confessed horror fan I sat down to this not quite knowing what to expect. After 2 or 3 mins i actually found myself scared (quite rare). The film obviously has a small budget and is set around charing cross station but the films lack of money does not distract from the story. Yes the story is a bit far fetched and doesn't explain itself very well but THE CREEP is a class act and proceeds to slash and dismember anything that comes its way. MESSAGE FOR LADIES !!! THERE ARE CERTAIN PARTS OF THE FILM YOU SHOULD CLOSE YOUR EYES AT OR AT LEAST CROSS YOUR LEGS !! you will understand when you see it.<br /><br />All in all a good film and it makes a change to see a good slasher movie that actually scares\")\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "def pre_process_data(filepath):\n",
    "    \"\"\"\n",
    "    This is dependent on your training data source but we will try to generalize it as best as possible.\n",
    "    \"\"\"\n",
    "    positive_path = os.path.join(filepath, 'pos')\n",
    "    negative_path = os.path.join(filepath, 'neg')\n",
    "    \n",
    "    pos_label = 1\n",
    "    neg_label = 0\n",
    "    \n",
    "    dataset = []\n",
    "    \n",
    "    for filename in glob.glob(os.path.join(positive_path, '*.txt')):\n",
    "        with open(filename, 'r', encoding=\"utf-8\") as f:\n",
    "            dataset.append((pos_label, f.read()))\n",
    "            \n",
    "    for filename in glob.glob(os.path.join(negative_path, '*.txt')):\n",
    "        with open(filename, 'r', encoding=\"utf-8\") as f:\n",
    "            dataset.append((neg_label, f.read()))\n",
    "    \n",
    "    shuffle(dataset)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "dataset = pre_process_data('./aclImdb/train')\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from gensim.models import KeyedVectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True, limit=200000)\n",
    "\n",
    "def tokenize_and_vectorize(dataset):\n",
    "    tokenizer = TreebankWordTokenizer()\n",
    "    vectorized_data = []\n",
    "    expected = []\n",
    "    for sample in dataset:\n",
    "        tokens = tokenizer.tokenize(sample[1])\n",
    "        sample_vecs = []\n",
    "        for token in tokens:\n",
    "            try:\n",
    "                sample_vecs.append(word_vectors[token])\n",
    "\n",
    "            except KeyError:\n",
    "                pass  # No matching token in the Google w2v vocab\n",
    "            \n",
    "        vectorized_data.append(sample_vecs)\n",
    "\n",
    "    return vectorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_expected(dataset):\n",
    "    \"\"\" Peel of the target values from the dataset \"\"\"\n",
    "    expected = []\n",
    "    for sample in dataset:\n",
    "        expected.append(sample[0])\n",
    "    return expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_data = tokenize_and_vectorize(dataset)\n",
    "expected = collect_expected(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_point = int(len(vectorized_data)*.8)\n",
    "\n",
    "x_train = vectorized_data[:split_point]\n",
    "y_train = expected[:split_point]\n",
    "x_test = vectorized_data[split_point:]\n",
    "y_test = expected[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100 # 400\n",
    "batch_size = 32         # How many samples to show the net before backpropogating the error and updating the weights\n",
    "embedding_dims = 300    # Length of the token vectors we will create for passing into the Convnet\n",
    "filters = 250           # Number of filters we will train\n",
    "kernel_size = 3         # The width of the filters, actual filters will each be a matrix of weights of size: embedding_dims x kernel_size or 50 x 3 in our case\n",
    "hidden_dims = 250       # Number of neurons in the plain feed forward net at the end of the chain\n",
    "epochs = 2              # Number of times we will pass the entire training dataset through the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must manually pad/truncate\n",
    "\n",
    "def pad_trunc(data, maxlen):\n",
    "    \"\"\" For a given dataset pad with zero vectors or truncate to maxlen \"\"\"\n",
    "    new_data = []\n",
    "\n",
    "    # Create a vector of 0's the length of our word vectors\n",
    "    zero_vector = []\n",
    "    for _ in range(len(data[0][0])):\n",
    "        zero_vector.append(0.0)\n",
    "\n",
    "    for sample in data:\n",
    " \n",
    "        if len(sample) > maxlen:\n",
    "            temp = sample[:maxlen]\n",
    "        elif len(sample) < maxlen:\n",
    "            temp = sample\n",
    "            additional_elems = maxlen - len(sample)\n",
    "            for _ in range(additional_elems):\n",
    "                temp.append(zero_vector)\n",
    "        else:\n",
    "            temp = sample\n",
    "        new_data.append(temp)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_trunc(x_train, maxlen)\n",
    "x_test = pad_trunc(x_test, maxlen)\n",
    "\n",
    "x_train = np.reshape(x_train, (len(x_train), maxlen, embedding_dims))\n",
    "y_train = np.array(y_train)\n",
    "x_test = np.reshape(x_test, (len(x_test), maxlen, embedding_dims))\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "20000/20000 [==============================] - 68s 3ms/step - loss: 0.4641 - accuracy: 0.7721 - val_loss: 0.3943 - val_accuracy: 0.8222\n",
      "Epoch 2/2\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.3098 - accuracy: 0.8675 - val_loss: 0.4440 - val_accuracy: 0.8102\n",
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1,\n",
    "                 input_shape=(maxlen, embedding_dims)))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(x_test, y_test))\n",
    "model_structure = model.to_json()\n",
    "with open(\"cnn_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_structure)\n",
    "\n",
    "model.save_weights(\"cnn_weights.h5\")\n",
    "print('Model saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "with open(\"cnn_model.json\", \"r\") as json_file:\n",
    "    json_string = json_file.read()\n",
    "model = model_from_json(json_string)\n",
    "\n",
    "model.load_weights('cnn_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_1 = \"I'm hate that the dismal weather that had me down for so long, when will it break! Ugh, when does happiness return?  The sun is blinding and the puffy clouds are too thin.  I can't wait for the weekend.\"\n",
    "sample_2 = \"I love the sunshine, its warmth, its brightness and the smell of growth in the warm light.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.996151]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We pass a dummy value in the first element of the tuple just because our helper expects it from the way processed the initial data.  That value won't ever see the network, so it can be whatever.\n",
    "vec_list = tokenize_and_vectorize([(1, sample_2)])\n",
    "\n",
    "# Tokenize returns a list of the data (length 1 here)\n",
    "test_vec_list = pad_trunc(vec_list, maxlen)\n",
    "\n",
    "test_vec = np.reshape(test_vec_list, (len(test_vec_list), maxlen, embedding_dims))\n",
    "model.predict(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(test_vec) # 0 = negative, 1 = positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
