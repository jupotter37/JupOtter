{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.trainer because of the following error (look up to see its traceback):\nFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/activations_tf.py:22\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tf_keras/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tf_keras/__internal__/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tf_keras/__internal__/backend/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _initialize_variables \u001b[38;5;28;01mas\u001b[39;00m initialize_variables\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m track_variable\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tf_keras/src/__init__.py:21\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the TF-Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tf_keras/src/applications/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras Applications are premade architectures with pre-trained weights.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtBase\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconvnext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ConvNeXtLarge\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tf_keras/src/applications/convnext.py:26\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtf_keras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/_api/v2/compat/v2/__init__.py:85\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen_data_flow_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dynamic_stitch \u001b[38;5;66;03m# line: 736\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen_experimental_dataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_pinned \u001b[38;5;66;03m# line: 701\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgen_linalg_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m matrix_square_root \u001b[38;5;66;03m# line: 1913\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'check_pinned' from 'tensorflow.python.ops.gen_experimental_dataset_ops' (/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/tensorflow/python/ops/gen_experimental_dataset_ops.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/utils/import_utils.py:1778\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/modeling_tf_utils.py:38\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataCollatorWithPadding, DefaultDataCollator\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mactivations_tf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_tf_activation\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/activations_tf.py:27\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parse(keras\u001b[38;5;241m.\u001b[39m__version__)\u001b[38;5;241m.\u001b[39mmajor \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     28\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour currently installed version of Keras is Keras 3, but this is not yet supported in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     29\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformers. Please install the backwards-compatible tf-keras package with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`pip install tf-keras`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     31\u001b[0m         )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gelu\u001b[39m(x):\n",
      "\u001b[0;31mValueError\u001b[0m: Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/utils/import_utils.py:1778\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/integrations/integration_utils.py:36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpackaging\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel, TFPreTrainedModel\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m version\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/utils/import_utils.py:1766\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1766\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1767\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/utils/import_utils.py:1780\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1781\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1783\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/utils/import_utils.py:1778\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/trainer.py:42\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Integrations must be imported before ML frameworks:\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# isort: off\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     43\u001b[0m     get_reporting_integration_callbacks,\n\u001b[1;32m     44\u001b[0m     hp_params,\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# isort: on\u001b[39;00m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/utils/import_utils.py:1766\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1766\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1767\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/utils/import_utils.py:1780\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1781\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1783\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Hugging Face Transformers and Datasets for NLP tasks and data handling\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     AutoModelForSequenceClassification,\n\u001b[1;32m     22\u001b[0m     AutoTokenizer,\n\u001b[1;32m     23\u001b[0m     TFAutoModelForSequenceClassification,\n\u001b[1;32m     24\u001b[0m     TrainingArguments,\n\u001b[1;32m     25\u001b[0m     Trainer,\n\u001b[1;32m     26\u001b[0m     pipeline,\n\u001b[1;32m     27\u001b[0m     AutoConfig,\n\u001b[1;32m     28\u001b[0m     DataCollatorWithPadding,\n\u001b[1;32m     29\u001b[0m     logging \u001b[38;5;28;01mas\u001b[39;00m hf_logging\n\u001b[1;32m     30\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset, Dataset\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_metric\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/utils/import_utils.py:1766\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1764\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1766\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1767\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/utils/import_utils.py:1780\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1781\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1782\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1783\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.trainer because of the following error (look up to see its traceback):\nFailed to import transformers.integrations.integration_utils because of the following error (look up to see its traceback):\nFailed to import transformers.modeling_tf_utils because of the following error (look up to see its traceback):\nYour currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
     ]
    }
   ],
   "source": [
    "# Basic data handling and array manipulations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import ast\n",
    "\n",
    "# Machine learning, data splitting, and metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# TensorFlow and PyTorch for neural networks\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "# Hugging Face Transformers and Datasets for NLP tasks and data handling\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    TFAutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    "    AutoConfig,\n",
    "    DataCollatorWithPadding,\n",
    "    logging as hf_logging\n",
    ")\n",
    "from datasets import load_dataset, Dataset\n",
    "from datasets import load_metric\n",
    "\n",
    "# Logging and warnings management\n",
    "import logging\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(level=logging.ERROR)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mIMPORT_BABEv3\u001b[39m():\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "def IMPORT_BABEv3():\n",
    "    train_path = \"./clean_datasets/TRAINING_DATAFRAME.csv\"\n",
    "    test_path = \"./clean_datasets/TESTING_DATAFRAME.csv\"\n",
    "    \n",
    "    # Check if the files already exist\n",
    "    if os.path.exists(train_path) and os.path.exists(test_path):\n",
    "        print(\"Training and testing files already exist. Skipping processing.\")\n",
    "        return \n",
    "    \n",
    "    dataset = load_dataset(\"mediabiasgroup/BABE-v3\")\n",
    "    df = pd.DataFrame(dataset[\"train\"])\n",
    "    \n",
    "    # Replace specific values in the 'topic' column\n",
    "    df['topic'] = df['topic'].replace({\"black lives matter\": \"blm\", \"gun-control\": \"gun control\",\"vaccine\": \"vaccines\"})\n",
    "    \n",
    "    df['Predicted'] = 'XXX'\n",
    "    df.drop(['news_link','outlet','label_opinion','biased_words'], axis=1, inplace=True)\n",
    "    df['label'] = 0\n",
    "    df['label'] = df['type'].isin(['left', 'right', 'center']).astype(int)\n",
    "    DF_TRAIN, DF_TEST = train_test_split(df, test_size=0.20, random_state=42)\n",
    "    DF_TRAIN.to_csv(\"./clean_datasets/BABE/TRAINING_DATAFRAME.csv\", index=False)\n",
    "    DF_TEST.to_csv(\"./clean_datasets/BABE/TESTING_DATAFRAME.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IMPORT_pranjali97(split='train'):\n",
    "    # Load the dataset from Hugging Face's dataset repository\n",
    "    dataset = load_dataset(\"pranjali97/Bias-detection-combined\", split=split)\n",
    "    # Convert the dataset to a pandas DataFrame\n",
    "    df = pd.DataFrame(dataset)\n",
    "    DF_TRAIN, DF_TEST = train_test_split(df, test_size=0.20, random_state=42)\n",
    "    DF_TRAIN.to_csv(\"./clean_datasets/pranjali97/TRAINING_DATAFRAME.csv\", index=False)\n",
    "    DF_TEST.to_csv(\"./clean_datasets/pranjali97/TESTING_DATAFRAME.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from collections import Counter\n",
    "import nltk\n",
    "\n",
    "# Download the punkt tokenizer if not already present\n",
    "def IMPORT_ALL_THE_NEWS_1():\n",
    "    # Define the output file path\n",
    "    output_path = \"./clean_datasets/BIG_TESTING_DATAFRAME.csv\"\n",
    "    \n",
    "    # Check if the file already exists\n",
    "    if os.path.exists(output_path):\n",
    "        print(\"Processed file already exists. Skipping processing.\")\n",
    "        return\n",
    "    # Load the data\n",
    "    df = pd.read_csv('./unclean_datasets/ALL_THE_NEWS_1.csv')\n",
    "    print(\"Data loaded.\")\n",
    "    df = df.iloc[:1000]  # Limiting the dataset for demonstration\n",
    "    df.drop(['id', 'title', 'publication', 'author', 'date', 'year', 'month', 'url', 'Unnamed: 0'], axis=1, inplace=True)\n",
    "    df = df.rename(columns={'content': 'text'})\n",
    "    df[\"label\"] = \"unclassified\"  # Initial label before classification\n",
    "\n",
    "    # Setup model pipelines outside the loop for efficiency\n",
    "    max_length = 300  # Based on typical model max token lengths\n",
    "    #model_names = [\"d4data/bias-detection-model\", \"D1V1DE/bias-detection\", \"valurank/distilroberta-bias\"]\n",
    "    model_names = [\"./models/D4DATA-on-BABE-on-PRANJALI/\", \"./models/D4DATA-on-BABE/\",\"./models/VALURANK-on-BABE-on-PRANJALI/\"]\n",
    "    pipelines = {name: pipeline(\"text-classification\", model=name) for name in model_names}\n",
    "    # Process each row\n",
    "    for index, row in df.iterrows():\n",
    "        text_data = row['text']\n",
    "        words = text_data.split()\n",
    "        chunk_size = int(max_length / 2)\n",
    "        chunks = [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "        bias_results = []\n",
    "        \n",
    "        for name, pipe in pipelines.items():\n",
    "            chunk_predictions = [pipe(chunk)[0].get(\"label\", \"No Label\").lower() for chunk in chunks]\n",
    "            counter = Counter(chunk_predictions)\n",
    "            bias_results.append(counter.most_common(1)[0][0])\n",
    "        print(f\"Intermediate results for index {index}: {bias_results}\")\n",
    "        final_counter = Counter(bias_results)\n",
    "        final_bias, _ = final_counter.most_common(1)[0]\n",
    "        df.at[index, 'label'] = 1 if final_bias == \"biased\" else 0\n",
    "    \n",
    "    # Set placeholders for additional analysis\n",
    "    df[\"topic\"] = \"XXX\"\n",
    "    df[\"type\"] = \"YYY\"\n",
    "    df[\"predicted\"] = \"ZZZ\"\n",
    "    \n",
    "    # Save the cleaned dataset\n",
    "    df.to_csv(\"./clean_datasets/BIG_TESTING_DATAFRAME.csv\", index=False)\n",
    "    print(\"Data processing complete and saved.\")\n",
    "\n",
    "IMPORT_ALL_THE_NEWS_1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing datasets\n",
    "IMPORT_BABEv3()\n",
    "IMPORT_pranjali97()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_import(model_name, from_tf=False):\n",
    "    from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "    # Check if the model needs to be loaded from TensorFlow weights\n",
    "    model_kwargs = {'from_tf': from_tf} if from_tf else {}\n",
    "\n",
    "    # Load the model and tokenizer with the necessary parameters\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_name, **model_kwargs)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "    # Replace slashes in the model name for file system compatibility\n",
    "    safe_model_name = model_name.replace('/', '_')\n",
    "    \n",
    "    # Define the save directory\n",
    "    save_directory = \"./models/\" + safe_model_name\n",
    "    \n",
    "    # Save the model and tokenizer to the specified local directory\n",
    "    model.save_pretrained(save_directory)\n",
    "    tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "#importing models\n",
    "\n",
    "model_import(\"D1V1DE/bias-detection\")\n",
    "model_import(\"d4data/bias-detection-model\",from_tf=True)\n",
    "model_import(\"valurank/distilroberta-bias\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FINE TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRAIN_ON_DATA(model, data, save):\n",
    "    # Load the dataset\n",
    "\n",
    "    file_path = data\n",
    "    data = pd.read_csv(file_path)\n",
    "    data = data.iloc[:4000]\n",
    "\n",
    "    # Initialize tokenizer and model from the D1V1DE/bias-detection pretrained model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)  # Move model to the device\n",
    "\n",
    "    # Function to tokenize the text\n",
    "    def tokenize_function(text):\n",
    "        return tokenizer(text, padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "    # Apply tokenization to each text entry\n",
    "    tokenized_data = data['text'].apply(tokenize_function).tolist()\n",
    "    tokenized_df = pd.DataFrame(tokenized_data)\n",
    "    tokenized_df['labels'] = data['label']\n",
    "\n",
    "    # Convert pandas DataFrame to Hugging Face dataset\n",
    "    dataset = Dataset.from_pandas(tokenized_df)\n",
    "\n",
    "    # Setup training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',          # output directory\n",
    "        num_train_epochs=3,              # number of training epochs\n",
    "        per_device_train_batch_size=8,   # batch size for training\n",
    "        per_device_eval_batch_size=16,   # batch size for evaluation\n",
    "        warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.01,               # strength of weight decay\n",
    "        logging_dir='./logs',            # directory for storing logs\n",
    "        logging_steps=10,\n",
    "    )\n",
    "\n",
    "    # Define the trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset,\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the model\n",
    "    model.save_pretrained(save)\n",
    "    tokenizer.save_pretrained(save)\n",
    "\n",
    "# Call the function\n",
    "TRAIN_ON_DATA(\"./models/D1V1DE_bias-detection/\",\"./clean_datasets/BABE/TRAINING_DATAFRAME.csv\",\"./models/D1V1DE-on-BABE\")\n",
    "TRAIN_ON_DATA(\"./models/d4data_bias-detection-model/\",\"./clean_datasets/BABE/TRAINING_DATAFRAME.csv\",\"./models/D4DATA-on-BABE\")\n",
    "TRAIN_ON_DATA(\"./models/valurank_distilroberta-bias/\",\"./clean_datasets/BABE/TRAINING_DATAFRAME.csv\",\"./models/VALURANK-on-BABE\")\n",
    "TRAIN_ON_DATA(\"./models/D1V1DE_bias-detection/\",\"./clean_datasets/pranjali97/TRAINING_DATAFRAME.csv\",\"./models/D1V1DE-on-PRANJALI\")\n",
    "TRAIN_ON_DATA(\"./models/d4data_bias-detection-model/\",\"./clean_datasets/pranjali97/TRAINING_DATAFRAME.csv\",\"./models/D4DATA-on-PRANJALI\")\n",
    "TRAIN_ON_DATA(\"./models/valurank_distilroberta-bias/\",\"./clean_datasets/pranjali97/TRAINING_DATAFRAME.csv\",\"./models/VALURANK-on-PRANJALI\")\n",
    "TRAIN_ON_DATA(\"./models/D1V1DE-on-BABE\",\"./clean_datasets/pranjali97/TRAINING_DATAFRAME.csv\",\"./models/D1V1DE-on-BABE-on-PRANJALI\")\n",
    "TRAIN_ON_DATA(\"./models/D4DATA-on-BABE\",\"./clean_datasets/pranjali97/TRAINING_DATAFRAME.csv\",\"./models/D4DATA-on-BABE-on-PRANJALI\")\n",
    "TRAIN_ON_DATA(\"./models/VALURANK-on-BABE\",\"./clean_datasets/pranjali97/TRAINING_DATAFRAME.csv\",\"./models/VALURANK-on-BABE-on-PRANJALI\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_test_bias(model, tokenizer, csv):\n",
    "    pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "    data = pd.read_csv(csv)\n",
    "    for index, row in data.iterrows():\n",
    "        predicted = pipe(row[\"text\"])\n",
    "        predicted = predicted[0][\"label\"]\n",
    "        if predicted.lower() == \"biased\":\n",
    "            guess = 1\n",
    "        else:\n",
    "            guess = 0\n",
    "        data.at[index, 'Predicted'] = guess\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the analysis code on each of the finalised models\n",
    "# Initialize DataFrame to store results\n",
    "results_df = pd.DataFrame(columns=['model', 'Category', 'Category Value', 'Precision', 'Recall', 'F1', 'Accuracy'])\n",
    "overall_scores_df = pd.DataFrame(columns=['model', 'Overall Precision', 'Overall Recall', 'Overall F1', 'Overall Accuracy'])\n",
    "\n",
    "# List all entries in the models directory\n",
    "entries = os.listdir('./models/')\n",
    "models = [entry for entry in entries if os.path.isdir(os.path.join('./models/', entry))]\n",
    "\n",
    "models = ['D1V1DE_bias-detection',\n",
    "    'd4data_bias-detection-model',\n",
    "    'valurank_distilroberta-bias',\n",
    "    'D1V1DE-on-BABE',\n",
    "    'D4DATA-on-BABE',\n",
    "    'VALURANK-on-BABE',\n",
    "    'D1V1DE-on-PRANJALI',\n",
    "    'D4DATA-on-PRANJALI',\n",
    "    'VALURANK-on-PRANJALI',\n",
    "    'D1V1DE-on-BABE-on-PRANJALI',\n",
    "    'D4DATA-on-BABE-on-PRANJALI',\n",
    "    'VALURANK-on-BABE-on-PRANJALI']\n",
    "\n",
    "count = 0\n",
    "for model_directory in models:\n",
    "    model_path = os.path.join('./models/', model_directory)\n",
    "    try:\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        data_file = \"./clean_datasets/BABE/TESTING_DATAFRAME.csv\"\n",
    "        data = new_test_bias(model, tokenizer, data_file)\n",
    "        \n",
    "        # Calculate overall scores for the model\n",
    "        overall_scores = SUPER_EVAL(data)\n",
    "        overall_scores_row = pd.DataFrame({\n",
    "            'model': [model_directory],\n",
    "            'Overall Precision': [overall_scores[0]],\n",
    "            'Overall Recall': [overall_scores[1]],\n",
    "            'Overall F1': [overall_scores[2]],\n",
    "            'Overall Accuracy': [overall_scores[3]]\n",
    "        })\n",
    "        overall_scores_df = pd.concat([overall_scores_df, overall_scores_row], ignore_index=True)\n",
    "        \n",
    "        # Calculate and append scores by type\n",
    "        grouped_data_type = data.groupby('type')\n",
    "        for typ, group in grouped_data_type:\n",
    "            if group.empty:\n",
    "                continue\n",
    "            scores = SUPER_EVAL(group)\n",
    "            new_row = pd.DataFrame({\n",
    "                'model': [model_directory],\n",
    "                'Category': ['Type'],\n",
    "                'Category Value': [typ],\n",
    "                'Precision': [scores[0]],\n",
    "                'Recall': [scores[1]],\n",
    "                'F1': [scores[2]],\n",
    "                'Accuracy': [scores[3]]\n",
    "            })\n",
    "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "\n",
    "        # Calculate and append scores by topic\n",
    "        grouped_data_topic = data.groupby('topic')\n",
    "        for topic, group in grouped_data_topic:\n",
    "            if group.empty:\n",
    "                continue\n",
    "            scores = SUPER_EVAL(group)\n",
    "            new_row = pd.DataFrame({\n",
    "                'model': [model_directory],\n",
    "                'Category': ['Topic'],\n",
    "                'Category Value': [topic],\n",
    "                'Precision': [scores[0]],\n",
    "                'Recall': [scores[1]],\n",
    "                'F1': [scores[2]],\n",
    "                'Accuracy': [scores[3]]\n",
    "            })\n",
    "            results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or processing model from {model_path}: {e}\")\n",
    "    count += 1\n",
    "    print('completed: ', count , \"of\" , str(len(models)))\n",
    "\n",
    "\n",
    "# Save the results to two CSV files\n",
    "\n",
    "results_df.to_csv(\"grouped_analysis_results.csv\", index=False)\n",
    "overall_scores_df.to_csv(\"overall_model_scores.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EVALUATIONS OF MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy_Metric(data):\n",
    "    # Load the accuracy metric\n",
    "    accuracy_metric = load_metric('accuracy',trust_remote_code=True)\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_metric.compute(predictions=data['Predicted'], references=data['label'])\n",
    "    #print(\"Accuracy:\", accuracy)\n",
    "    return(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision_Recall_F1score(data):\n",
    "    # Load precision, recall, and f1 metrics\n",
    "    precision_metric = load_metric('precision', trust_remote_code=True)\n",
    "    recall_metric = load_metric('recall', trust_remote_code=True)\n",
    "    f1_metric = load_metric('f1', trust_remote_code=True)\n",
    "    # Calculate precision, recall, and f1\n",
    "    precision = precision_metric.compute(predictions=data['Predicted'], references=data['label'], average='binary')\n",
    "    recall = recall_metric.compute(predictions=data['Predicted'], references=data['label'], average='binary')\n",
    "    f1 = f1_metric.compute(predictions=data['Predicted'], references=data['label'], average='binary')\n",
    "    #print(\"Precision:\", precision)\n",
    "    #print(\"Recall:\", recall)\n",
    "    #print(\"F1 Score:\", f1)\n",
    "    return(precision, recall, f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SUPER_EVAL(dataset):\n",
    "    temp1 = Precision_Recall_F1score(dataset)\n",
    "    temp2 = Accuracy_Metric(dataset)\n",
    "    temp3 = temp1[0],temp1[1],temp1[2], temp2\n",
    "    return temp3\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "results analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def count_types_and_topics(file_path1, file_path2, output_file_path):\n",
    "    # Check if files exist\n",
    "    if not os.path.isfile(file_path1):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path1}\")\n",
    "    if not os.path.isfile(file_path2):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path2}\")\n",
    "    \n",
    "    # Load the CSV files\n",
    "    df1 = pd.read_csv(file_path1)\n",
    "    df2 = pd.read_csv(file_path2)\n",
    "    \n",
    "    def count_occurrences(df, column_name, file_label):\n",
    "        if column_name in df.columns:\n",
    "            return df[column_name].value_counts(dropna=False).reset_index(name=f'count_{file_label}')\n",
    "        else:\n",
    "            print(f\"Warning: Column '{column_name}' not found in {file_label}\")\n",
    "            return pd.DataFrame({column_name: [], f'count_{file_label}': []})\n",
    "\n",
    "    # Count the occurrences of each type and topic for each file\n",
    "    type_counts1 = count_occurrences(df1, 'type', 'file1').rename(columns={'index': 'type'})\n",
    "    topic_counts1 = count_occurrences(df1, 'topic', 'file1').rename(columns={'index': 'topic'})\n",
    "    \n",
    "    type_counts2 = count_occurrences(df2, 'type', 'file2').rename(columns={'index': 'type'})\n",
    "    topic_counts2 = count_occurrences(df2, 'topic', 'file2').rename(columns={'index': 'topic'})\n",
    "\n",
    "    # Merge the counts into a single dataframe\n",
    "    type_counts = pd.merge(type_counts1, type_counts2, on='type', how='outer').fillna(0)\n",
    "    topic_counts = pd.merge(topic_counts1, topic_counts2, on='topic', how='outer').fillna(0)\n",
    "\n",
    "    # Concatenate type and topic counts into a single dataframe with separators\n",
    "    type_counts['section'] = 'Type Counts'\n",
    "    topic_counts['section'] = 'Topic Counts'\n",
    "    \n",
    "    combined_counts = pd.concat([type_counts, pd.DataFrame({'type': [''], 'count_file1': [''], 'count_file2': [''], 'section': ['']}) , topic_counts.rename(columns={'topic': 'type'})], ignore_index=True)\n",
    "    combined_counts = combined_counts[['section', 'type', 'count_file1', 'count_file2']]\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    combined_counts.to_csv(output_file_path, index=False)\n",
    "\n",
    "    print(f\"Results saved to {output_file_path}\")\n",
    "    return output_file_path\n",
    "\n",
    "# Example usage with the uploaded file and a duplicated file path\n",
    "file_path1 = './clean_datasets/BABE/TESTING_DATAFRAME.csv'\n",
    "file_path2 = './clean_datasets/BABE/TRAINING_DATAFRAME.csv'  # Duplicating the same file for demonstration\n",
    "output_file_path = 'type_and_topic_counts_combined.csv'\n",
    "\n",
    "count_types_and_topics(file_path1, file_path2, output_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load CSV files\n",
    "overall_scores_path = \"overall_model_scores.csv\"\n",
    "grouped_results_path = \"grouped_analysis_results.csv\"\n",
    "overall_scores_df = pd.read_csv(overall_scores_path)\n",
    "grouped_results_df = pd.read_csv(grouped_results_path)\n",
    "\n",
    "# Function to extract dictionary values and convert to float\n",
    "def extract_metric_values(df, columns, overall=False):\n",
    "    for column in columns:\n",
    "        try:\n",
    "            # Different handling for 'overall' metrics\n",
    "            if overall:\n",
    "                key = column.split()[1].lower()  # Splits on the space and takes the second word, lowercased\n",
    "            else:\n",
    "                key = column.lower()\n",
    "            df[column] = df[column].apply(lambda x: float(ast.literal_eval(x)[key]))\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing column {column}: {e}\")\n",
    "    return df\n",
    "\n",
    "# Specifying columns that contain dictionary values\n",
    "dict_columns_overall = ['Overall Precision', 'Overall Recall', 'Overall F1', 'Overall Accuracy']\n",
    "dict_columns_grouped = ['Precision', 'Recall', 'F1', 'Accuracy']\n",
    "\n",
    "# Extract metrics for both dataframes\n",
    "overall_scores_df = extract_metric_values(overall_scores_df, dict_columns_overall, overall=True)\n",
    "grouped_results_df = extract_metric_values(grouped_results_df, dict_columns_grouped)\n",
    "\n",
    "# Print the first few rows of the DataFrame to verify extraction\n",
    "#print(\"Overall Scores DataFrame:\")\n",
    "#print(overall_scores_df.head())\n",
    "#print(\"\\nGrouped Results DataFrame:\")\n",
    "#print(grouped_results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast  # Import the ast module to safely evaluate strings containing Python expressions\n",
    "\n",
    "# Load the data\n",
    "file_path = \"overall_model_scores.csv\"\n",
    "model_scores = pd.read_csv(file_path)\n",
    "\n",
    "# Function to convert string dictionary to float\n",
    "def extract_value(dict_string):\n",
    "    # Evaluate the string as a dictionary and extract the value\n",
    "    return float(ast.literal_eval(dict_string).get('precision' if 'precision' in dict_string else\n",
    "                                                'recall' if 'recall' in dict_string else\n",
    "                                                'f1' if 'f1' in dict_string else\n",
    "                                                'accuracy'))\n",
    "\n",
    "# Apply the function to each column that contains dictionary strings\n",
    "model_scores['Overall Precision'] = model_scores['Overall Precision'].apply(extract_value)\n",
    "model_scores['Overall Recall'] = model_scores['Overall Recall'].apply(extract_value)\n",
    "model_scores['Overall F1'] = model_scores['Overall F1'].apply(extract_value)\n",
    "model_scores['Overall Accuracy'] = model_scores['Overall Accuracy'].apply(extract_value)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "model_scores.to_csv(\"clean_overall_scores.csv\")\n",
    "print(model_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast  # Import the ast module to safely evaluate strings containing Python expressions\n",
    "\n",
    "# Load the data\n",
    "file_path = 'grouped_analysis_results.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Function to convert string dictionary to float\n",
    "def extract_value(dict_string):\n",
    "    # Evaluate the string as a dictionary and extract the value\n",
    "    return float(ast.literal_eval(dict_string).get('precision' if 'precision' in dict_string else\n",
    "                                                'recall' if 'recall' in dict_string else\n",
    "                                                'f1' if 'f1' in dict_string else\n",
    "                                                'accuracy'))\n",
    "\n",
    "# Apply the function to each column that contains dictionary strings\n",
    "data['Precision'] = data['Precision'].apply(extract_value)\n",
    "data['Recall'] = data['Recall'].apply(extract_value)\n",
    "data['F1'] = data['F1'].apply(extract_value)\n",
    "data['Accuracy'] = data['Accuracy'].apply(extract_value)\n",
    "\n",
    "# Save the cleaned DataFrame\n",
    "cleaned_file_path = 'clean_grouped_analysis_results.csv'\n",
    "data.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "# Display the cleaned DataFrame\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['D1V1DE_bias-detection',\n",
    "    'd4data_bias-detection-model',\n",
    "    'valurank_distilroberta-bias',\n",
    "    'D1V1DE-on-BABE',\n",
    "    'D4DATA-on-BABE',\n",
    "    'VALURANK-on-BABE',\n",
    "    'D1V1DE-on-PRANJALI',\n",
    "    'D4DATA-on-PRANJALI',\n",
    "    'VALURANK-on-PRANJALI',\n",
    "    'D1V1DE-on-BABE-on-PRANJALI',\n",
    "    'D4DATA-on-BABE-on-PRANJALI',\n",
    "    'VALURANK-on-BABE-on-PRANJALI']\n",
    "\n",
    "results = pd.DataFrame()\n",
    "for modelname in models:\n",
    "    model_path = \"./models/\"+ modelname\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    data_file = \"./clean_datasets/BABE/TESTING_DATAFRAME.csv\"\n",
    "    data = new_test_bias(model, tokenizer, data_file)\n",
    "    data['model'] = modelname\n",
    "    results = pd.concat([results, data]) \n",
    "    print(\"success\")\n",
    "\n",
    "results.to_csv(\"full_model_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plots for the overall scores\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_individual_metric(df, metric):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df_sorted = df.sort_values(by=metric, ascending=True)\n",
    "    plt.barh(df_sorted['model'], df_sorted[metric], color='skyblue')\n",
    "    plt.title(f'{metric} of Models')\n",
    "    plt.xlabel('Value')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Metrics to be plotted\n",
    "metrics = ['Overall Precision', 'Overall Recall', 'Overall F1', 'Overall Accuracy']\n",
    "for metric in metrics:\n",
    "    plot_individual_metric(overall_scores_df, metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the grouped results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_individual_metrics_by_category(df, category_type):\n",
    "    # Filter the DataFrame based on the Category type\n",
    "    filtered_df = df[df['Category'] == category_type]\n",
    "    # Get unique category values within the selected type\n",
    "    category_values = sorted(filtered_df['Category Value'].unique())\n",
    "    \n",
    "    metrics = ['Precision', 'Recall', 'F1', 'Accuracy']\n",
    "    \n",
    "    for metric in metrics:\n",
    "        plt.figure(figsize=(10, 6))  # Set the figure size for each plot\n",
    "        for category in category_values:\n",
    "            subset = filtered_df[filtered_df['Category Value'] == category]\n",
    "            plt.plot(subset['model'], subset[metric], marker='o', linestyle='-', label=category)\n",
    "        plt.title(f'{metric} by {category_type}')\n",
    "        plt.xlabel('Models')\n",
    "        plt.ylabel(metric)\n",
    "        plt.xticks(rotation=45)  # Rotate model names for better legibility\n",
    "        plt.legend(title='Category Value', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage to plot performance by 'Type'\n",
    "plot_individual_metrics_by_category(grouped_results_df, 'Type')\n",
    "\n",
    "# Example usage to plot performance by 'Topic'\n",
    "plot_individual_metrics_by_category(grouped_results_df, 'Topic')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visuals/Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graph of overall resultsa\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load your data\n",
    "data = pd.read_csv(\"clean_overall_scores.csv\")\n",
    "\n",
    "# Bar graphs for each overall metric\n",
    "for metric in [\"Overall Precision\", \"Overall Recall\", \"Overall F1\", \"Overall Accuracy\"]:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=\"model\", y=metric, data=data)\n",
    "    plt.title(f'{metric} by Model')\n",
    "    plt.ylabel(metric)\n",
    "    plt.xlabel('Model')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#graphs for each type and topic\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"clean_grouped_analysis_results.csv\")  # Modify the path as needed\n",
    "\n",
    "# Set the model to filter data\n",
    "models = [\n",
    "    'D4DATA-on-BABE',\n",
    "    'D4DATA-on-BABE-on-PRANJALI',\n",
    "    'VALURANK-on-BABE-on-PRANJALI']\n",
    "\n",
    "for model in models:\n",
    "    # Filter the data to only include rows where 'Model' column matches the specified model\n",
    "    filtered_data = data[data['model'] == model]\n",
    "\n",
    "    # Generate bar graphs for each metric\n",
    "    metrics = [\"Precision\", \"Recall\", \"F1\", \"Accuracy\"]\n",
    "    metrics = [\"Recall\"]\n",
    "    for metric in metrics:\n",
    "        if metric in filtered_data.columns:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            sns.barplot(x=\"Category Value\", y=metric, hue=\"Category\", data=filtered_data)\n",
    "            plt.title(f'{metric} by Category and Category Value ({model})')\n",
    "            plt.ylabel(metric)\n",
    "            plt.xlabel('Category Value')\n",
    "            plt.xticks(rotation=45)\n",
    "            plt.legend(title='Category')\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Load your dataset\n",
    "data = pd.read_csv('full_model_predictions.csv')\n",
    "\n",
    "models = [\n",
    "    'D4DATA-on-BABE',\n",
    "    'D4DATA-on-BABE-on-PRANJALI',\n",
    "    'VALURANK-on-BABE-on-PRANJALI']\n",
    "\n",
    "# Generate and plot confusion matrix for each model\n",
    "for model in models:\n",
    "    model_data = data[data['model'] == model]\n",
    "    cm = confusion_matrix(model_data['label'], model_data['Predicted'])\n",
    "\n",
    "    # Plot the confusion matrix using seaborn\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "    plt.title(f'Confusion Matrix for {model}')\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"clean_overall_scores.csv\")\n",
    "\n",
    "# Define your preferred order of the models\n",
    "model_order = [\n",
    "    'D1V1DE_bias-detection',\n",
    "    'D1V1DE-on-BABE',\n",
    "    'D1V1DE-on-PRANJALI',\n",
    "    'D1V1DE-on-BABE-on-PRANJALI',\n",
    "    'd4data_bias-detection-model',\n",
    "    'D4DATA-on-BABE',\n",
    "    'D4DATA-on-PRANJALI',\n",
    "    'D4DATA-on-BABE-on-PRANJALI',\n",
    "    'valurank_distilroberta-bias',\n",
    "    'VALURANK-on-BABE',\n",
    "    'VALURANK-on-PRANJALI',\n",
    "    'VALURANK-on-BABE-on-PRANJALI'\n",
    "]\n",
    "\n",
    "# Melting the DataFrame for easier plotting with seaborn\n",
    "overall_scores_melted = data.melt(id_vars=[\"model\"], \n",
    "                                value_vars=[\"Overall Precision\", \"Overall Recall\", \"Overall F1\", \"Overall Accuracy\"],\n",
    "                                var_name=\"Metric\", value_name=\"Value\")\n",
    "\n",
    "# Calculating average scores for each metric\n",
    "avg_precision = overall_scores_melted[overall_scores_melted['Metric'] == 'Overall Precision']['Value'].mean()\n",
    "avg_recall = overall_scores_melted[overall_scores_melted['Metric'] == 'Overall Recall']['Value'].mean()\n",
    "avg_f1 = overall_scores_melted[overall_scores_melted['Metric'] == 'Overall F1']['Value'].mean()\n",
    "avg_accuracy = overall_scores_melted[overall_scores_melted['Metric'] == 'Overall Accuracy']['Value'].mean()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 10))\n",
    "ax = sns.barplot(x=\"Value\", y=\"model\", hue=\"Metric\", data=overall_scores_melted, palette=\"viridis\", order=model_order)\n",
    "plt.title('Overall Performance Comparison of Models')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Model')\n",
    "\n",
    "# Adding vertical lines for average scores\n",
    "plt.axvline(x=avg_precision, color='blue', linestyle='--', label='Avg Precision')\n",
    "plt.axvline(x=avg_recall, color='red', linestyle='--', label='Avg Recall')\n",
    "plt.axvline(x=avg_f1, color='green', linestyle='--', label='Avg F1')\n",
    "plt.axvline(x=avg_accuracy, color='purple', linestyle='--', label='Avg Accuracy')\n",
    "\n",
    "# Customizing the legend to include only one entry per item\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "new_labels, new_handles = [], []\n",
    "for handle, label in zip(handles, labels):\n",
    "    if label not in new_labels:\n",
    "        new_labels.append(label)\n",
    "        new_handles.append(handle)\n",
    "ax.legend(new_handles, new_labels, title='Metric', loc='lower right')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Large Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from collections import Counter\n",
    "\n",
    "# Load the test dataset\n",
    "test = pd.read_csv(\"./clean_datasets/BIG_TESTING_DATAFRAME.csv\")\n",
    "\n",
    "# Setup model pipelines outside the loop for efficiency\n",
    "max_length = 300  # Based on typical model max token lengths\n",
    "model_names = [\"./models/D4DATA-on-BABE-on-PRANJALI/\", \"./models/D4DATA-on-BABE/\", \"./models/VALURANK-on-BABE-on-PRANJALI/\"]\n",
    "pipelines = {name: pipeline(\"text-classification\", model=name) for name in model_names}\n",
    "\n",
    "# Function to process text and get model predictions\n",
    "def get_model_predictions(text, model_pipeline, max_length=300):\n",
    "    words = text.split()\n",
    "    chunk_size = int(max_length / 2)\n",
    "    chunks = [' '.join(words[i:i + chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "    chunk_predictions = [model_pipeline(chunk)[0].get(\"label\", \"No Label\").lower() for chunk in chunks]\n",
    "    counter = Counter(chunk_predictions)\n",
    "    most_common_label = counter.most_common(1)[0][0]\n",
    "    return 1 if most_common_label == 'biased' else 0\n",
    "\n",
    "# Initialize columns for each model's binary predictions\n",
    "for model_name in model_names:\n",
    "    test[model_name] = 0\n",
    "\n",
    "# Process each model for the entire dataset\n",
    "for model_name, model_pipeline in pipelines.items():\n",
    "    print(f\"Starting processing with model: {model_name}\")\n",
    "    for index, row in test.iterrows():\n",
    "        text_data = row['text']\n",
    "        prediction = get_model_predictions(text_data, model_pipeline, max_length)\n",
    "        test.at[index, model_name] = prediction\n",
    "        if index % 100 == 0:\n",
    "            print(f\"Processed {index} rows for model {model_name}\")\n",
    "    print(f\"Completed processing with model: {model_name}\")\n",
    "\n",
    "# Save the updated DataFrame to CSV\n",
    "output_file_path = 'Large_Text_Results.csv'\n",
    "test.to_csv(output_file_path, index=False)\n",
    "print(f\"Results saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score\n",
    "\n",
    "# Load the results dataset\n",
    "results = pd.read_csv(\"Large_Text_Results.csv\")\n",
    "\n",
    "# Define the true labels column and the model prediction columns\n",
    "true_labels_col = 'label'\n",
    "model_cols = [\"./models/D4DATA-on-BABE-on-PRANJALI/\", \"./models/D4DATA-on-BABE/\", \"./models/VALURANK-on-BABE-on-PRANJALI/\"]\n",
    "\n",
    "# Initialize an empty list to store the metrics\n",
    "metrics_list = []\n",
    "\n",
    "# Calculate metrics for each model\n",
    "for model_col in model_cols:\n",
    "    # Extract true labels and predictions\n",
    "    true_labels = results[true_labels_col]\n",
    "    predictions = results[model_col]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    recall = recall_score(true_labels, predictions, average='weighted')\n",
    "    precision = precision_score(true_labels, predictions, average='weighted')\n",
    "    \n",
    "    # Store metrics in a dictionary\n",
    "    metrics = {\n",
    "        'model': model_col,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'recall': recall,\n",
    "        'precision': precision\n",
    "    }\n",
    "    \n",
    "    # Append dictionary to the list\n",
    "    metrics_list.append(metrics)\n",
    "\n",
    "# Convert the list of metrics to a DataFrame\n",
    "metrics_df = pd.DataFrame(metrics_list)\n",
    "\n",
    "# Save the metrics DataFrame to CSV\n",
    "output_metrics_path = 'model_performance_metrics.csv'\n",
    "metrics_df.to_csv(output_metrics_path, index=False)\n",
    "print(f\"Performance metrics saved to {output_metrics_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Load the new data\n",
    "data = pd.read_csv(\"model_performance_metrics.csv\")\n",
    "\n",
    "# Define the preferred order of the models\n",
    "model_order = [\n",
    "    './models/D4DATA-on-BABE-on-PRANJALI/',\n",
    "    './models/D4DATA-on-BABE/',\n",
    "    './models/VALURANK-on-BABE-on-PRANJALI/'\n",
    "]\n",
    "\n",
    "# Melting the DataFrame for easier plotting with seaborn\n",
    "overall_scores_melted = data.melt(id_vars=[\"model\"], \n",
    "                                value_vars=[\"accuracy\", \"recall\", \"f1_score\", \"precision\"],\n",
    "                                var_name=\"Metric\", value_name=\"Value\")\n",
    "\n",
    "# Calculating average scores for each metric\n",
    "avg_precision = overall_scores_melted[overall_scores_melted['Metric'] == 'precision']['Value'].mean()\n",
    "avg_recall = overall_scores_melted[overall_scores_melted['Metric'] == 'recall']['Value'].mean()\n",
    "avg_f1 = overall_scores_melted[overall_scores_melted['Metric'] == 'f1_score']['Value'].mean()\n",
    "avg_accuracy = overall_scores_melted[overall_scores_melted['Metric'] == 'accuracy']['Value'].mean()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 10))\n",
    "ax = sns.barplot(x=\"Value\", y=\"model\", hue=\"Metric\", data=overall_scores_melted, palette=\"viridis\", order=model_order)\n",
    "plt.title('Overall Performance Comparison of Models')\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Model')\n",
    "\n",
    "# Adding vertical lines for average scores\n",
    "plt.axvline(x=avg_precision, color='blue', linestyle='--', label='Avg Precision')\n",
    "plt.axvline(x=avg_recall, color='red', linestyle='--', label='Avg Recall')\n",
    "plt.axvline(x=avg_f1, color='green', linestyle='--', label='Avg F1')\n",
    "plt.axvline(x=avg_accuracy, color='purple', linestyle='--', label='Avg Accuracy')\n",
    "\n",
    "# Customizing the legend to include only one entry per item\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "new_labels, new_handles = [], []\n",
    "for handle, label in zip(handles, labels):\n",
    "    if label not in new_labels:\n",
    "        new_labels.append(label)\n",
    "        new_handles.append(handle)\n",
    "ax.legend(new_handles, new_labels, title='Metric', loc='lower right')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the DataFrame directly since it wasn't provided in a file\n",
    "data = pd.DataFrame({\n",
    "    'model': [\n",
    "        './models/D4DATA-on-BABE-on-PRANJALI/',\n",
    "        './models/D4DATA-on-BABE/',\n",
    "        './models/VALURANK-on-BABE-on-PRANJALI/'\n",
    "    ],\n",
    "    'accuracy': [0.899, 0.986, 0.538],\n",
    "    'f1_score': [0.9319211978113433, 0.9843814254084137, 0.6816049412329096],\n",
    "    'recall': [0.899, 0.986, 0.538],\n",
    "    'precision': [0.9826147540983606, 0.9842430052217286, 0.9612680076096706]\n",
    "})\n",
    "\n",
    "# Calculate average scores for each metric\n",
    "avg_accuracy = data['accuracy'].mean()\n",
    "avg_f1 = data['f1_score'].mean()\n",
    "avg_recall = data['recall'].mean()\n",
    "avg_precision = data['precision'].mean()\n",
    "\n",
    "# Calculate deviations\n",
    "data['accuracy_deviation'] = data['accuracy'] - avg_accuracy\n",
    "data['f1_deviation'] = data['f1_score'] - avg_f1\n",
    "data['recall_deviation'] = data['recall'] - avg_recall\n",
    "data['precision_deviation'] = data['precision'] - avg_precision\n",
    "\n",
    "# Plotting deviations\n",
    "metrics = ['accuracy_deviation', 'f1_deviation', 'recall_deviation', 'precision_deviation']\n",
    "titles = ['Accuracy Deviation', 'F1 Score Deviation', 'Recall Deviation', 'Precision Deviation']\n",
    "files = ['accuracy_deviation.png', 'f1_deviation.png', 'recall_deviation.png', 'precision_deviation.png']\n",
    "\n",
    "for metric, title, file in zip(metrics, titles, files):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.barh(data['model'], data[metric], color='skyblue')\n",
    "    plt.axvline(x=0, color='black', linestyle='--')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Deviation')\n",
    "    plt.ylabel('Model')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Models To Hugging Face"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "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"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository Onunes/VALURANK-on-PRANJALI already exists.\n",
      "Uploaded VALURANK-on-PRANJALI to Hugging Face Hub\n",
      "Repository Onunes/D1V1DE-on-BABE-on-PRANJALI already exists.\n",
      "Uploaded D1V1DE-on-BABE-on-PRANJALI to Hugging Face Hub\n",
      "Repository Onunes/D4DATA-on-BABE-on-PRANJALI already exists.\n",
      "Uploaded D4DATA-on-BABE-on-PRANJALI to Hugging Face Hub\n",
      "Repository Onunes/VALURANK-on-BABE-on-PRANJALI already exists.\n",
      "Uploaded VALURANK-on-BABE-on-PRANJALI to Hugging Face Hub\n",
      "All models have been processed.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi, create_repo, upload_folder\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from urllib3.util.retry import Retry\n",
    "\n",
    "# Use your token for authentication\n",
    "token = \"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\"\n",
    "\n",
    "# Path to the directory containing the models\n",
    "base_model_dir = 'models'\n",
    "\n",
    "# List of model directories\n",
    "models = [\n",
    "    'VALURANK-on-PRANJALI',\n",
    "    'D1V1DE-on-BABE-on-PRANJALI',\n",
    "    'D4DATA-on-BABE-on-PRANJALI',\n",
    "    'VALURANK-on-BABE-on-PRANJALI'\n",
    "]\n",
    "\n",
    "# Initialize the API\n",
    "api = HfApi()\n",
    "\n",
    "# Configure retry mechanism for HTTP requests\n",
    "session = requests.Session()\n",
    "retry = Retry(\n",
    "    total=5,\n",
    "    backoff_factor=1,\n",
    "    status_forcelist=[500, 502, 503, 504],\n",
    "    allowed_methods=[\"HEAD\", \"GET\", \"OPTIONS\", \"POST\", \"PUT\"]\n",
    ")\n",
    "adapter = HTTPAdapter(max_retries=retry)\n",
    "session.mount(\"https://\", adapter)\n",
    "session.mount(\"http://\", adapter)\n",
    "\n",
    "for model_name in models:\n",
    "    model_dir = os.path.join(base_model_dir, model_name)\n",
    "\n",
    "    # Ensure the directory exists\n",
    "    if not os.path.isdir(model_dir):\n",
    "        print(f\"Directory {model_dir} does not exist. Skipping...\")\n",
    "        continue\n",
    "\n",
    "    # Define the repository name\n",
    "    repo_name = f\"Onunes/{model_name}\"\n",
    "\n",
    "    try:\n",
    "        # Check if the repository exists, create it if it doesn't\n",
    "        try:\n",
    "            api.repo_info(repo_id=repo_name, token=token)\n",
    "            print(f\"Repository {repo_name} already exists.\")\n",
    "        except Exception as e:\n",
    "            if '404' in str(e):\n",
    "                create_repo(repo_id=repo_name, token=token, private=False)\n",
    "                print(f\"Created repository {repo_name}.\")\n",
    "            else:\n",
    "                raise e\n",
    "\n",
    "        # Upload the model folder with retries\n",
    "        for attempt in range(5):\n",
    "            try:\n",
    "                upload_folder(\n",
    "                    repo_id=repo_name,\n",
    "                    folder_path=model_dir,\n",
    "                    commit_message=f\"Initial commit of {model_name}\",\n",
    "                    token=token\n",
    "                )\n",
    "                print(f\"Uploaded {model_name} to Hugging Face Hub\")\n",
    "                break  # Exit the retry loop if upload is successful\n",
    "            except Exception as e:\n",
    "                if attempt < 4:  # Retry up to 5 times\n",
    "                    wait_time = 2 ** attempt  # Exponential backoff\n",
    "                    print(f\"Upload failed, retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    print(f\"An error occurred while processing {model_name}: {e}\")\n",
    "                    raise\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {model_name}: {e}\")\n",
    "\n",
    "print(\"All models have been processed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
