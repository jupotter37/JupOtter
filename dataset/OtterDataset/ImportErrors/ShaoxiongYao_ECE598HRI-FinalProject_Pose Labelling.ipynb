{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17734c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import glob\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import scipy.optimize as sopt\n",
    "from klampt.math import se3,so3\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "from create_point_cloud import load_whole_point_cloud\n",
    "import scipy\n",
    "import torch\n",
    "from mmpose.datasets.dataset_info import DatasetInfo\n",
    "\n",
    "from mmpose.datasets.pipelines import Compose\n",
    "\n",
    "from utils import get_proper_image_paths, strip_dataset_parent_folder,get_aligned_dataset,find_hand_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) OpenMMLab. All rights reserved.\n",
    "from collections import deque\n",
    "from queue import Queue\n",
    "from threading import Event, Lock, Thread\n",
    "\n",
    "import cv2\n",
    "\n",
    "from mmpose.apis import (get_track_id, inference_top_down_pose_model,\n",
    "                         init_pose_model, vis_pose_result)\n",
    "from mmpose.core import apply_bugeye_effect, apply_sunglasses_effect\n",
    "from mmpose.utils import StopWatch\n",
    "\n",
    "try:\n",
    "    from mmdet.apis import inference_detector, init_detector\n",
    "    has_mmdet = True\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    has_mmdet = False\n",
    "\n",
    "try:\n",
    "    import psutil\n",
    "    psutil_proc = psutil.Process()\n",
    "except (ImportError, ModuleNotFoundError):\n",
    "    psutil_proc = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103cec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_pose(frame, mmdet_results,det_score_thr = 0.3):\n",
    "\n",
    "    pose_results_list = []\n",
    "    for model_info, pose_history in zip(pose_model_list,\n",
    "                                        pose_history_list):\n",
    "        model_name = model_info['name']\n",
    "        pose_model = model_info['model']\n",
    "        cat_ids = model_info['cat_ids']\n",
    "        pose_results_last = pose_history['pose_results_last']\n",
    "        next_id = pose_history['next_id']\n",
    "\n",
    "        # process mmdet results\n",
    "        det_results = process_mmdet_results(\n",
    "            mmdet_results,\n",
    "            class_names=det_model.CLASSES,\n",
    "            cat_ids=cat_ids)\n",
    "\n",
    "        # inference pose model\n",
    "        dataset_name = pose_model.cfg.data['test']['type']\n",
    "        pose_results, _ = inference_top_down_pose_model(\n",
    "            pose_model,\n",
    "            frame,\n",
    "            det_results,\n",
    "            bbox_thr=det_score_thr,\n",
    "            format='xyxy',\n",
    "            dataset=dataset_name)\n",
    "\n",
    "        pose_results, next_id = get_track_id(\n",
    "            pose_results,\n",
    "            pose_results_last,\n",
    "            next_id,\n",
    "            use_oks=False,\n",
    "            tracking_thr=0.3,\n",
    "            use_one_euro=True,\n",
    "            fps=None)\n",
    "\n",
    "        pose_results_list.append(pose_results)\n",
    "\n",
    "        # update pose history\n",
    "        pose_history['pose_results_last'] = pose_results\n",
    "        pose_history['next_id'] = next_id\n",
    "    return pose_results_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a28205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_detection(frame):\n",
    "    # inference detection\n",
    "    mmdet_results = inference_detector(det_model, frame)\n",
    "    return mmdet_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87da4fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mmdet_results(mmdet_results, class_names=None, cat_ids=1):\n",
    "    \"\"\"Process mmdet results to mmpose input format.\n",
    "\n",
    "    Args:\n",
    "        mmdet_results: raw output of mmdet model\n",
    "        class_names: class names of mmdet model\n",
    "        cat_ids (int or List[int]): category id list that will be preserved\n",
    "    Returns:\n",
    "        List[Dict]: detection results for mmpose input\n",
    "    \"\"\"\n",
    "    if isinstance(mmdet_results, tuple):\n",
    "        mmdet_results = mmdet_results[0]\n",
    "\n",
    "    if isinstance(class_names, str):\n",
    "        class_names = (class_names, )\n",
    "\n",
    "    if not isinstance(cat_ids, (list, tuple)):\n",
    "        cat_ids = [cat_ids]\n",
    "\n",
    "    # only keep bboxes of interested classes\n",
    "    bbox_results = [mmdet_results[i - 1] for i in cat_ids]\n",
    "    bboxes = np.vstack(bbox_results)\n",
    "\n",
    "    # get textual labels of classes\n",
    "    labels = np.concatenate([\n",
    "        np.full(bbox.shape[0], i - 1, dtype=np.int32)\n",
    "        for i, bbox in zip(cat_ids, bbox_results)\n",
    "    ])\n",
    "    if class_names is None: \n",
    "        labels = [f'class: {i}' for i in labels]\n",
    "    else:\n",
    "        labels = [class_names[i] for i in labels]\n",
    "\n",
    "    det_results = []\n",
    "    for bbox, label in zip(bboxes, labels):\n",
    "        det_result = dict(bbox=bbox, label=label)\n",
    "        det_results.append(det_result)\n",
    "    return det_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe75a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "MMPOSE_DIR = '/home/motion/Joao/classes/hri_kdc/final_project/mmpose'\n",
    "det_config = '{}/demo/mmdetection_cfg/ssdlite_mobilenetv2_scratch_600e_coco.py'.format(MMPOSE_DIR)\n",
    "det_checkpoint = 'https://download.openmmlab.com/mmdetection/v2.0/ssd/ssdlite_mobilenetv2_scratch_600e_coco/ssdlite_mobilenetv2_scratch_600e_coco_20210629_110627-974d9307.pth'\n",
    "device = 'cuda:0'\n",
    "enable_human_pose = 1\n",
    "human_pose_config = '{}/configs/wholebody/2d_kpt_sview_rgb_img/topdown_heatmap/coco-wholebody/vipnas_res50_coco_wholebody_256x192_dark.py'.format(MMPOSE_DIR)\n",
    "human_pose_checkpoint = 'https://download.openmmlab.com/mmpose/top_down/vipnas/vipnas_res50_wholebody_256x192_dark-67c0ce35_20211112.pth'\n",
    "human_det_ids = [1]\n",
    "buffer_size = 1\n",
    "display_delay = 0\n",
    "assert has_mmdet, 'Please install mmdet to run the demo.'\n",
    "assert det_config is not None\n",
    "assert det_checkpoint is not None\n",
    "\n",
    "# build detection model\n",
    "det_model = init_detector(\n",
    "    det_config, det_checkpoint, device=device.lower())\n",
    "\n",
    "# build pose models\n",
    "pose_model_list = []\n",
    "if enable_human_pose:\n",
    "    pose_model = init_pose_model(\n",
    "        human_pose_config,\n",
    "        human_pose_checkpoint,\n",
    "        device=device.lower())\n",
    "    model_info = {\n",
    "        'name': 'HumanPose',\n",
    "        'model': pose_model,\n",
    "        'cat_ids': human_det_ids,\n",
    "        'bbox_color': (148, 139, 255),\n",
    "    }\n",
    "    pose_model_list.append(model_info)\n",
    "\n",
    "\n",
    "# store pose history for pose tracking\n",
    "pose_history_list = []\n",
    "\n",
    "for _ in range(len(pose_model_list)):\n",
    "    pose_history_list.append({'pose_results_last': [], 'next_id': 0})\n",
    "    \n",
    "datasets_dir = '/home/motion/data/ECE598/our_dataset'\n",
    "scenes = sorted(glob(datasets_dir + '/*'))\n",
    "\n",
    "dataset_folder = scenes[5]\n",
    "\n",
    "clean_df =  get_aligned_dataset(dataset_folder,master_camera = 'cam_torso_depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35da7bc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "right_hand_positions = []\n",
    "left_hand_positions = []\n",
    "\n",
    "for index in tqdm(list(clean_df.index)):\n",
    "    frame = cv2.imread(clean_df.loc[index,'cam_right_color'], cv2.IMREAD_COLOR)\n",
    "#     frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if(frame is not None):\n",
    "        res = inference_detection(frame)\n",
    "        pose_results = infer_pose(frame,res,det_score_thr = 0.1)\n",
    "        pose_model = pose_model_list[0]['model']\n",
    "        bbox_color = pose_model_list[0]['bbox_color']\n",
    "        dataset_name = pose_model.cfg.data['test']['type']\n",
    "    #     img = vis_pose_result(pose_model,\n",
    "    #                                 frame,\n",
    "    #                                 pose_results[0],\n",
    "    #                                 radius=4,\n",
    "    #                                 thickness=2,\n",
    "    #                                 dataset=dataset_name,\n",
    "    #                                 kpt_score_thr=0.1,\n",
    "    #                                 bbox_color=bbox_color,show = False)\n",
    "        if(len(pose_results[0])>0):\n",
    "            left_hand = pose_results[0][0]['keypoints'][91:112,:]\n",
    "            right_hand = pose_results[0][0]['keypoints'][112:,:]\n",
    "            lhp = find_hand_center(left_hand,clean_df,index,frame,cam_side = 'right')\n",
    "            rhp = find_hand_center(right_hand,clean_df,index,frame,cam_side = 'right')\n",
    "            left_hand_positions.append(lhp)\n",
    "            right_hand_positions.append(rhp)\n",
    "    #         plt.scatter(fingers[:,0],fingers[:,1])\n",
    "    #         plt.imshow(frame)\n",
    "    #         plt.show()\n",
    "        \n",
    "        else:\n",
    "            left_hand_positions.append(None)\n",
    "            right_hand_positions.append(None)\n",
    "    else:\n",
    "        left_hand_positions.append(None)\n",
    "        right_hand_positions.append(None)\n",
    "#     time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6abf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "kp = pose_results[0][0]['keypoints']\n",
    "frame2 = frame.copy()\n",
    "frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "for point in kp:\n",
    "        cv2.circle(frame2,(int(point[0]),int(point[1])),10,255,-1)\n",
    "\n",
    "plt.imshow(frame2)\n",
    "plt.savefig('./alice_demo.png',bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49c2038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-processing the dataset:\n",
    "# reusable_df = clean_df.copy()\n",
    "# for col in reusable_df.columns:\n",
    "#     if(col.startswith('cam')):\n",
    "#         tmp1 = reusable_df[col].str.split('our_dataset/',expand = True).loc[:,1]\n",
    "#         tmp1 = '{}/' + tmp1\n",
    "#         reusable_df.loc[:,col] = tmp1\n",
    "reusable_df = strip_dataset_parent_folder(clean_df,'our_dataset/')\n",
    "reusable_df['gt_left_hand'] = left_hand_positions\n",
    "reusable_df['gt_right_hand'] = right_hand_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a7e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reusable_df = reusable_df.fillna(method= 'ffill',limit = 11)\n",
    "# reusable_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec78b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "reusable_df.to_pickle('./first_ground_truth_shaoxiong_no_sword3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cad7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = pd.read_pickle('./first_ground_truth_alice_no_sword2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4613b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can use the function \"get_proper_image_paths\" to fill the placeholder {} in the image paths with the \n",
    "# correct path where you are saving the dataset ima\n",
    "test2 = get_proper_image_paths(test1,'/home/motion/data/ECE598/our_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0318fe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = load_whole_point_cloud(test2.loc[0,'cam_torso_color'],test2.loc[0,'cam_torso_depth'],'realsense_torso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdfbd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
