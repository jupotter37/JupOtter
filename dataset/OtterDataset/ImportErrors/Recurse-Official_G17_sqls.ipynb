{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from urllib.parse import quote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostname='localhost'\n",
    "database='inventoryManagement'\n",
    "username='postgres'\n",
    "pwd='kri@123'\n",
    "port_id=5432\n",
    "encoded_pwd = quote(pwd)\n",
    "connection_uri = f\"postgresql+psycopg2://{username}:{encoded_pwd}@{hostname}:{port_id}/{database}\"\n",
    "db = SQLDatabase.from_uri(connection_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(\"productId\") AS total_products\n",
      "FROM \"Products\";\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "generate_query = create_sql_query_chain(llm, db)\n",
    "query = generate_query.invoke({\"question\": \"how many products are there\"})\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(36,)]\n",
      "You are a PostgreSQL expert. Given an input question, first create a syntactically correct PostgreSQL query to run, then look at the results of the query and return the answer to the input question.\n",
      "Unless the user specifies in the question a specific number of examples to obtain, query for at most 5 results using the LIMIT clause as per PostgreSQL. You can order the results to return the most informative data in the database.\n",
      "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in double quotes (\") to denote them as delimited identifiers.\n",
      "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "Pay attention to use CURRENT_DATE function to get the current date, if the question involves \"today\".\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: Question here\n",
      "SQLQuery: SQL Query to run\n",
      "SQLResult: Result of the SQLQuery\n",
      "Answer: Final answer here\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "print(execute_query.invoke(query))\n",
    "\n",
    "chain=generate_query | execute_query\n",
    "chain.get_prompts()[0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 1 customer whose name starts with the letter 'H'.\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"Given the following user question, corresponding SQL query, and SQL result, answer the user question.\n",
    "\n",
    "Question: {question}\n",
    "SQL Query: {query}\n",
    "SQL Result: {result}\n",
    "Answer: \"\"\"\n",
    ")\n",
    "\n",
    "rephrase_answer = answer_prompt | llm | StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(query=generate_query).assign(\n",
    "        result=lambda inputs: execute_query.invoke(inputs[\"query\"])\n",
    "    )\n",
    "    | rephrase_answer\n",
    ")\n",
    "user_question = \"how many customers are their whose name starts with letter h? Show at most 5.\"\n",
    "response = chain.invoke({\"question\": user_question})\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"input\": \"List all customers in France with a credit limit over 20,000.\",\n",
    "        \"query\": \"SELECT * FROM customers WHERE country = 'France' AND creditLimit > 20000;\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Get the highest payment amount made by any customer.\",\n",
    "        \"query\": \"SELECT MAX(amount) FROM payments;\"\n",
    "    },\n",
    "  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: List all customers in France with a credit limit over 20,000.\n",
      "SQLQuery:\n",
      "AI: SELECT * FROM customers WHERE country = 'France' AND creditLimit > 20000;\n",
      "Human: Get the highest payment amount made by any customer.\n",
      "SQLQuery:\n",
      "AI: SELECT MAX(amount) FROM payments;\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder,FewShotChatMessagePromptTemplate,PromptTemplate\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\\nSQLQuery:\"),\n",
    "        (\"ai\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    "    # input_variables=[\"input\",\"top_k\"],\n",
    "    input_variables=[\"input\"],\n",
    ")\n",
    "print(few_shot_prompt.format(input1=\"How many products are there?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nagak\\AppData\\Local\\Temp\\ipykernel_20724\\3587022188.py:5: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma()\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Could not import chromadb python package. Please install it with `pip install chromadb`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\nagak\\anaconda3\\envs\\inventory-management\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:83\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[1;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'chromadb'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexample_selectors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SemanticSimilarityExampleSelector\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_openai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[1;32m----> 5\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m vectorstore\u001b[38;5;241m.\u001b[39mdelete_collection()\n\u001b[0;32m      7\u001b[0m example_selector \u001b[38;5;241m=\u001b[39m SemanticSimilarityExampleSelector\u001b[38;5;241m.\u001b[39mfrom_examples(\n\u001b[0;32m      8\u001b[0m     examples,\n\u001b[0;32m      9\u001b[0m     OpenAIEmbeddings(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     input_keys\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     13\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\nagak\\anaconda3\\envs\\inventory-management\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:216\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     emit_warning()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nagak\\anaconda3\\envs\\inventory-management\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:86\u001b[0m, in \u001b[0;36mChroma.__init__\u001b[1;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import chromadb python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install chromadb`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m     )\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m client \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client_settings \u001b[38;5;241m=\u001b[39m client_settings\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import chromadb python package. Please install it with `pip install chromadb`."
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma()\n",
    "vectorstore.delete_collection()\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,\n",
    "    OpenAIEmbeddings(),\n",
    "    vectorstore,\n",
    "    k=2,\n",
    "    input_keys=[\"input\"],\n",
    ")\n",
    "example_selector.select_examples({\"input\": \"how many users we have?\"})\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    example_selector=example_selector,\n",
    "    input_variables=[\"input\",\"top_k\"],\n",
    ")\n",
    "print(few_shot_prompt.format(input=\"How many products are there?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\n\\nHere is the relevant table info: {table_info}\\n\\nBelow are a number of examples of questions and their corresponding SQL queries.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "print(final_prompt.format(input=\"How many products are there?\",table_info=\"some table info\"))\n",
    "generate_query = create_sql_query_chain(llm, db,final_prompt)\n",
    "chain = (\n",
    "RunnablePassthrough.assign(query=generate_query).assign(\n",
    "    result=itemgetter(\"query\") | execute_query\n",
    ")\n",
    "| rephrase_answer\n",
    ")\n",
    "chain.invoke({\"question\": \"How many cutomers who have purchased more than one item\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain.chains.openai_tools import create_extraction_chain_pydantic\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "def get_table_details():\n",
    "    table_description = pd.read_csv(\"table_descriptions.csv\")\n",
    "    table_docs = []\n",
    "\n",
    "    table_details = \"\"\n",
    "    for index, row in table_description.iterrows():\n",
    "        table_details = table_details + \"Table Name:\" + row['Table'] + \"\\n\" + \"Table Description:\" + row['Description'] + \"\\n\\n\"\n",
    "\n",
    "    return table_details\n",
    "\n",
    "\n",
    "class Table(BaseModel):\n",
    "    \"\"\"Table in SQL database.\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"Name of table in SQL database.\")\n",
    "\n",
    "# table_names = \"\\n\".join(db.get_usable_table_names())\n",
    "table_details = get_table_details()\n",
    "print(table_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_details_prompt = f\"\"\"Return the names of ALL the SQL tables that MIGHT be relevant to the user question. \\\n",
    "The tables are:\n",
    "\n",
    "{table_details}\n",
    "\n",
    "Remember to include ALL POTENTIALLY RELEVANT tables, even if you're not sure that they're needed.\"\"\"\n",
    "\n",
    "table_chain = create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt)\n",
    "tables = table_chain.invoke({\"input\": \"give me details of customer and their order count\"})\n",
    "tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tables(tables: List[Table]) -> List[str]:\n",
    "    tables  = [table.name for table in tables]\n",
    "    return tables\n",
    "\n",
    "select_table = {\"input\": itemgetter(\"question\")} | create_extraction_chain_pydantic(Table, llm, system_message=table_details_prompt) | get_tables\n",
    "select_table.invoke({\"question\": \"give me details of customer and their order count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "RunnablePassthrough.assign(table_names_to_use=select_table) |\n",
    "RunnablePassthrough.assign(query=generate_query).assign(\n",
    "    result=itemgetter(\"query\") | execute_query\n",
    ")\n",
    "| rephrase_answer\n",
    ")\n",
    "chain.invoke({\"question\": \"How many cutomers with order count more than 5\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "history = ChatMessageHistory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\n\\nHere is the relevant table info: {table_info}\\n\\nBelow are a number of examples of questions and their corresponding SQL queries. Those examples are just for referecne and hsould be considered while answering follow up questions\"),\n",
    "        few_shot_prompt,\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "print(final_prompt.format(input=\"How many products are there?\",table_info=\"some table info\",messages=[]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_query = create_sql_query_chain(llm, db,final_prompt)\n",
    "\n",
    "chain = (\n",
    "RunnablePassthrough.assign(table_names_to_use=select_table) |\n",
    "RunnablePassthrough.assign(query=generate_query).assign(\n",
    "    result=itemgetter(\"query\") | execute_query\n",
    ")\n",
    "| rephrase_answer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many cutomers with order count more than 5\"\n",
    "response = chain.invoke({\"question\": question,\"messages\":history.messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_user_message(question)\n",
    "history.add_ai_message(response)\n",
    "history.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"question\": \"Can you list there names?\",\"messages\":history.messages})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Query:SELECT COUNT(\"productId\") AS total_products\n",
      "FROM \"Products\";\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize language model\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "# Create SQL query chain\n",
    "generate_query = create_sql_query_chain(llm, db)\n",
    "\n",
    "# Example query\n",
    "question = \"How many products are there?\"\n",
    "response = generate_query.invoke({\"question\": question})\n",
    "print(f\"Generated Query:{response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Result:No results found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Execute the query\n",
    "execute_query = QuerySQLDataBaseTool(db=db)\n",
    "result = execute_query.invoke(response)\n",
    "\n",
    "# Format results for readability\n",
    "def format_results(result):\n",
    "    if isinstance(result, list) and len(result) > 0:\n",
    "        return \"\".join([str(row) for row in result])\n",
    "    return \"No results found.\"\n",
    "\n",
    "formatted_result = format_results(result)\n",
    "print(f\"Query Result:{formatted_result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Store context using ChatMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "history.add_user_message(question)\n",
    "history.add_ai_message(formatted_result)\n",
    "\n",
    "# View stored context\n",
    "for msg in history.messages:\n",
    "    print(f\"{msg.type.capitalize()}: {msg.content}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inventory-management",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
