{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# First, install necessary libraries\n",
        "import time\n",
        "import boto3\n",
        "from botocore import UNSIGNED\n",
        "from botocore.config import Config\n",
        "import numpy as np\n",
        "import botocore\n",
        "import logging\n",
        "from multiprocessing import Pool, Manager\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "import functools\n",
        "from urllib import request"
      ],
      "metadata": {
        "id": "wyXRponBdtj-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xEIa_ZaEUdUi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d1bab75-0a1a-4319-efeb-e9298086857c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Read annotation file ./open_images_data/train-annotations-bbox.csv\n",
            "WARNING:root:train bounding boxes size: 1722\n",
            "WARNING:root:Approximate Image Stats: \n",
            "WARNING:root:Aircraft: 1030/1030 = 1.00.\n",
            "WARNING:root:Label distribution: \n",
            "WARNING:root:Aircraft: 1722/1722 = 1.00.\n",
            "WARNING:root:Save train data to ./open_images_data/sub-train-annotations-bbox.csv.\n",
            "WARNING:root:Read annotation file ./open_images_data/validation-annotations-bbox.csv\n",
            "WARNING:root:validation bounding boxes size: 182\n",
            "WARNING:root:Approximate Image Stats: \n",
            "WARNING:root:Aircraft: 148/148 = 1.00.\n",
            "WARNING:root:Label distribution: \n",
            "WARNING:root:Aircraft: 182/182 = 1.00.\n",
            "WARNING:root:Save validation data to ./open_images_data/sub-validation-annotations-bbox.csv.\n",
            "WARNING:root:Read annotation file ./open_images_data/test-annotations-bbox.csv\n",
            "WARNING:root:test bounding boxes size: 542\n",
            "WARNING:root:Approximate Image Stats: \n",
            "WARNING:root:Aircraft: 430/430 = 1.00.\n",
            "WARNING:root:Label distribution: \n",
            "WARNING:root:Aircraft: 542/542 = 1.00.\n",
            "WARNING:root:Save test data to ./open_images_data/sub-test-annotations-bbox.csv.\n",
            "WARNING:root:Start downloading 1608 images.\n",
            "WARNING:root:Downloaded 100 images.\n",
            "WARNING:root:Downloaded 200 images.\n",
            "WARNING:root:Downloaded 300 images.\n",
            "WARNING:root:Downloaded 400 images.\n",
            "WARNING:root:Downloaded 500 images.\n",
            "WARNING:root:Downloaded 600 images.\n",
            "WARNING:root:Downloaded 700 images.\n",
            "WARNING:root:Downloaded 800 images.\n",
            "WARNING:root:Downloaded 900 images.\n",
            "WARNING:root:Downloaded 1000 images.\n",
            "WARNING:root:Downloaded 1100 images.\n",
            "WARNING:root:Downloaded 1200 images.\n",
            "WARNING:root:Downloaded 1300 images.\n",
            "WARNING:root:Downloaded 1400 images.\n",
            "WARNING:root:Downloaded 1500 images.\n",
            "WARNING:root:Downloaded 1600 images.\n",
            "WARNING:root:Task Done.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
        "\n",
        "def download(bucket, root, retry, counter, lock, path):\n",
        "    i = 0\n",
        "    src = path\n",
        "    dest = f\"{root}/{path}\"\n",
        "    while i < retry:\n",
        "        try:\n",
        "            if not os.path.exists(dest):\n",
        "                s3.download_file(bucket, src, dest)\n",
        "            else:\n",
        "                logging.info(f\"{dest} already exists.\")\n",
        "            with lock:\n",
        "                counter.value += 1\n",
        "                if counter.value % 100 == 0:\n",
        "                    logging.warning(f\"Downloaded {counter.value} images.\")\n",
        "            return\n",
        "        except botocore.exceptions.ClientError as e:\n",
        "            if e.response['Error']['Code'] == \"404\":\n",
        "                logging.warning(f\"The file s3://{bucket}/{src} does not exist.\")\n",
        "                return\n",
        "            i += 1\n",
        "            logging.warning(f\"Sleep {i} and try again.\")\n",
        "            time.sleep(i)\n",
        "    logging.warning(f\"Failed to download the file s3://{bucket}/{src}. Exception: {e}\")\n",
        "\n",
        "def batch_download(bucket, file_paths, root, num_workers=10, retry=10):\n",
        "    with Pool(num_workers) as p:\n",
        "        m = Manager()\n",
        "        counter = m.Value('i', 0)\n",
        "        lock = m.Lock()\n",
        "        download_ = functools.partial(download, bucket, root, retry, counter, lock)\n",
        "        p.map(download_, file_paths)\n",
        "\n",
        "def http_download(url, path):\n",
        "    with request.urlopen(url) as f:\n",
        "        with open(path, \"wb\") as fout:\n",
        "            buf = f.read(1024)\n",
        "            while buf:\n",
        "                fout.write(buf)\n",
        "                buf = f.read(1024)\n",
        "\n",
        "def log_counts(values):\n",
        "    for k, count in values.value_counts().items():  # Changed iteritems() to items()\n",
        "        logging.warning(f\"{k}: {count}/{len(values)} = {count/len(values):.2f}.\")\n",
        "\n",
        "\n",
        "# Argument Simulation for Colab\n",
        "class Args:\n",
        "    root = './open_images_data'\n",
        "    include_depiction = False\n",
        "    class_names = \"Aircraft,Aeroplane\"\n",
        "    num_workers = 2\n",
        "    retry = 10\n",
        "    filter_file = \"\"\n",
        "    remove_overlapped = False\n",
        "\n",
        "args = Args()\n",
        "\n",
        "# Create root directory if it doesn't exist\n",
        "os.makedirs(args.root, exist_ok=True)\n",
        "\n",
        "# Start processing based on arguments\n",
        "bucket = \"open-images-dataset\"\n",
        "names = [e.strip() for e in args.class_names.split(\",\")]\n",
        "class_names = []\n",
        "group_filters = []\n",
        "percentages = []\n",
        "for name in names:\n",
        "    t = name.split(\":\")\n",
        "    class_names.append(t[0].strip())\n",
        "    if len(t) >= 2 and t[1].strip():\n",
        "        group_filters.append(t[1].strip())\n",
        "    else:\n",
        "        group_filters.append(\"\")\n",
        "    if len(t) >= 3 and t[2].strip():\n",
        "        percentages.append(float(t[2].strip()))\n",
        "    else:\n",
        "        percentages.append(1.0)\n",
        "\n",
        "# Exclude images if a filter file is provided\n",
        "excluded_images = set()\n",
        "if args.filter_file:\n",
        "    for line in open(args.filter_file):\n",
        "        img_id = line.strip()\n",
        "        if not img_id:\n",
        "            continue\n",
        "        excluded_images.add(img_id)\n",
        "\n",
        "# Download class description file\n",
        "class_description_file = os.path.join(args.root, \"class-descriptions-boxable.csv\")\n",
        "if not os.path.exists(class_description_file):\n",
        "    url = \"https://storage.googleapis.com/openimages/2018_04/class-descriptions-boxable.csv\"\n",
        "    logging.warning(f\"Download {url}.\")\n",
        "    http_download(url, class_description_file)\n",
        "\n",
        "# Load the class descriptions to filter by selected classes\n",
        "class_descriptions = pd.read_csv(class_description_file, names=[\"id\", \"ClassName\"])\n",
        "class_descriptions = class_descriptions[class_descriptions['ClassName'].isin(class_names)]\n",
        "\n",
        "# Download images by dataset type (train, validation, test)\n",
        "image_files = []\n",
        "for dataset_type in [\"train\", \"validation\", \"test\"]:\n",
        "    image_dir = os.path.join(args.root, dataset_type)\n",
        "    os.makedirs(image_dir, exist_ok=True)\n",
        "\n",
        "    annotation_file = f\"{args.root}/{dataset_type}-annotations-bbox.csv\"\n",
        "    if not os.path.exists(annotation_file):\n",
        "        url = f\"https://storage.googleapis.com/openimages/2018_04/{dataset_type}/{dataset_type}-annotations-bbox.csv\"\n",
        "        logging.warning(f\"Download {url}.\")\n",
        "        http_download(url, annotation_file)\n",
        "    logging.warning(f\"Read annotation file {annotation_file}\")\n",
        "    annotations = pd.read_csv(annotation_file)\n",
        "    annotations = pd.merge(annotations, class_descriptions, left_on=\"LabelName\", right_on=\"id\", how=\"inner\")\n",
        "    if not args.include_depiction:\n",
        "        annotations = annotations.loc[annotations['IsDepiction'] != 1, :]\n",
        "\n",
        "    # Apply filtering and exclusions\n",
        "    filtered = []\n",
        "    for class_name, group_filter, percentage in zip(class_names, group_filters, percentages):\n",
        "        sub = annotations.loc[annotations['ClassName'] == class_name, :]\n",
        "        excluded_images |= set(sub['ImageID'].sample(frac=1 - percentage))\n",
        "\n",
        "        if group_filter == '~group':\n",
        "            excluded_images |= set(sub.loc[sub['IsGroupOf'] == 1, 'ImageID'])\n",
        "        elif group_filter == 'group':\n",
        "            excluded_images |= set(sub.loc[sub['IsGroupOf'] == 0, 'ImageID'])\n",
        "        filtered.append(sub)\n",
        "\n",
        "    annotations = pd.concat(filtered)\n",
        "    annotations = annotations.loc[~annotations['ImageID'].isin(excluded_images), :]\n",
        "\n",
        "    if args.remove_overlapped:\n",
        "        images_with_group = annotations.loc[annotations['IsGroupOf'] == 1, 'ImageID']\n",
        "        annotations = annotations.loc[~(annotations['ImageID'].isin(set(images_with_group)) & (annotations['IsGroupOf'] == 0)), :]\n",
        "    annotations = annotations.sample(frac=1.0)\n",
        "\n",
        "    logging.warning(f\"{dataset_type} bounding boxes size: {annotations.shape[0]}\")\n",
        "    logging.warning(\"Approximate Image Stats: \")\n",
        "    log_counts(annotations.drop_duplicates([\"ImageID\", \"ClassName\"])[\"ClassName\"])\n",
        "    logging.warning(\"Label distribution: \")\n",
        "    log_counts(annotations['ClassName'])\n",
        "\n",
        "    sub_annotation_file = f\"{args.root}/sub-{dataset_type}-annotations-bbox.csv\"\n",
        "    logging.warning(f\"Save {dataset_type} data to {sub_annotation_file}.\")\n",
        "    annotations.to_csv(sub_annotation_file, index=False)\n",
        "    image_files.extend(f\"{dataset_type}/{id}.jpg\" for id in set(annotations['ImageID']))\n",
        "\n",
        "logging.warning(f\"Start downloading {len(image_files)} images.\")\n",
        "batch_download(bucket, image_files, args.root, args.num_workers, args.retry)\n",
        "logging.warning(\"Task Done.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "KiKXo4YJxQSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/qfgaohao/pytorch-ssd.git\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EYTdgk3olHQ",
        "outputId": "1fe65496-d9ab-49d2-f57a-f57908006d68"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'pytorch-ssd' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXiCz9Aa6h9o",
        "outputId": "6a1af012-998b-4269-aa09-fa6957a02993"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(\"/content/pytorch-ssd\")"
      ],
      "metadata": {
        "id": "9r-P7r-ao4WZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/pytorch-ssd/train_ssd.py \\\n",
        "    --dataset_type open_images \\\n",
        "    --datasets /content/open_images_data \\\n",
        "    --net mb1-ssd \\\n",
        "    --pretrained_ssd /content/pytorch-ssd/models/mobilenet-v1-ssd-mp-0_675.pth \\\n",
        "    --scheduler cosine \\\n",
        "    --lr 0.01 \\\n",
        "    --t_max 100 \\\n",
        "    --validation_epochs 5 \\\n",
        "    --num_epochs 20 \\\n",
        "    --base_net_lr 0.001 \\\n",
        "    --batch_size 5 \\\n",
        "    --checkpoint_folder /content/pytorch-ssd/models/ \\\n",
        "    --freeze_base_net\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5bR65-v6lZF",
        "outputId": "ad25eeab-17d1-49a8-f1f9-efd800a42a6e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RuntimeError: module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem.\n",
            "2024-11-11 09:06:57,929 - root - INFO - Use Cuda.\n",
            "2024-11-11 09:06:57,929 - root - INFO - Namespace(dataset_type='open_images', datasets=['/content/open_images_data'], validation_dataset=None, balance_data=False, net='mb1-ssd', freeze_base_net=True, freeze_net=False, mb2_width_mult=1.0, lr=0.01, momentum=0.9, weight_decay=0.0005, gamma=0.1, base_net_lr=0.001, extra_layers_lr=None, base_net=None, pretrained_ssd='/content/pytorch-ssd/models/mobilenet-v1-ssd-mp-0_675.pth', resume=None, scheduler='cosine', milestones='80,100', t_max=100.0, batch_size=5, num_epochs=20, num_workers=4, validation_epochs=5, debug_steps=100, use_cuda=True, checkpoint_folder='/content/pytorch-ssd/models/')\n",
            "2024-11-11 09:06:57,930 - root - INFO - Prepare training datasets.\n",
            "2024-11-11 09:06:58,436 - root - INFO - Dataset Summary:Number of Images: 1030\n",
            "Minimum Number of Images for a Class: -1\n",
            "Label Distribution:\n",
            "\tAircraft: 1722\n",
            "2024-11-11 09:06:58,438 - root - INFO - Stored labels into file /content/pytorch-ssd/models/open-images-model-labels.txt.\n",
            "2024-11-11 09:06:58,438 - root - INFO - Train dataset size: 1030\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "2024-11-11 09:06:58,439 - root - INFO - Prepare Validation datasets.\n",
            "2024-11-11 09:06:58,642 - root - INFO - Dataset Summary:Number of Images: 430\n",
            "Minimum Number of Images for a Class: -1\n",
            "Label Distribution:\n",
            "\tAircraft: 542\n",
            "2024-11-11 09:06:58,643 - root - INFO - validation dataset size: 430\n",
            "2024-11-11 09:06:58,643 - root - INFO - Build network.\n",
            "2024-11-11 09:06:58,711 - root - INFO - Freeze base net.\n",
            "2024-11-11 09:06:58,711 - root - INFO - Init from pretrained ssd /content/pytorch-ssd/models/mobilenet-v1-ssd-mp-0_675.pth\n",
            "/content/pytorch-ssd/vision/ssd/ssd.py:119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model, map_location=lambda storage, loc: storage)\n",
            "2024-11-11 09:06:58,756 - root - INFO - Took 0.04 seconds to load the model.\n",
            "2024-11-11 09:06:58,882 - root - INFO - Learning rate: 0.01, Base net learning rate: 0.001, Extra Layers learning rate: 0.01.\n",
            "2024-11-11 09:06:58,883 - root - INFO - Uses CosineAnnealingLR scheduler.\n",
            "2024-11-11 09:06:58,883 - root - INFO - Start training from epoch 0.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  warnings.warn(\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "2024-11-11 09:07:39,767 - root - INFO - Epoch: 0, Step: 100, Average Loss: 5.8437, Average Regression Loss 2.6186, Average Classification Loss: 3.2251\n",
            "2024-11-11 09:08:18,357 - root - INFO - Epoch: 0, Step: 200, Average Loss: 5.3841, Average Regression Loss 2.3723, Average Classification Loss: 3.0117\n",
            "2024-11-11 09:08:23,270 - root - INFO - Epoch: 0, Validation Loss: 6.5131, Validation Regression Loss 2.7069, Validation Classification Loss: 3.8062\n",
            "2024-11-11 09:08:23,328 - root - INFO - Saved model /content/pytorch-ssd/models/mb1-ssd-Epoch-0-Loss-6.513086962145429.pth\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:09:03,360 - root - INFO - Epoch: 1, Step: 100, Average Loss: 5.2745, Average Regression Loss 2.4232, Average Classification Loss: 2.8513\n",
            "2024-11-11 09:09:40,708 - root - INFO - Epoch: 1, Step: 200, Average Loss: 5.2876, Average Regression Loss 2.3486, Average Classification Loss: 2.9390\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:10:20,393 - root - INFO - Epoch: 2, Step: 100, Average Loss: 5.0177, Average Regression Loss 2.1425, Average Classification Loss: 2.8752\n",
            "2024-11-11 09:10:55,928 - root - INFO - Epoch: 2, Step: 200, Average Loss: 4.9512, Average Regression Loss 2.1707, Average Classification Loss: 2.7805\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:11:33,663 - root - INFO - Epoch: 3, Step: 100, Average Loss: 5.1219, Average Regression Loss 2.2063, Average Classification Loss: 2.9155\n",
            "2024-11-11 09:12:09,236 - root - INFO - Epoch: 3, Step: 200, Average Loss: 4.7279, Average Regression Loss 2.0493, Average Classification Loss: 2.6786\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:12:51,058 - root - INFO - Epoch: 4, Step: 100, Average Loss: 5.1561, Average Regression Loss 2.2529, Average Classification Loss: 2.9032\n",
            "2024-11-11 09:13:27,673 - root - INFO - Epoch: 4, Step: 200, Average Loss: 4.7608, Average Regression Loss 2.0775, Average Classification Loss: 2.6833\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:14:09,279 - root - INFO - Epoch: 5, Step: 100, Average Loss: 4.8280, Average Regression Loss 2.0293, Average Classification Loss: 2.7987\n",
            "2024-11-11 09:14:43,439 - root - INFO - Epoch: 5, Step: 200, Average Loss: 4.8327, Average Regression Loss 2.1153, Average Classification Loss: 2.7174\n",
            "2024-11-11 09:14:49,558 - root - INFO - Epoch: 5, Validation Loss: 6.8809, Validation Regression Loss 2.5162, Validation Classification Loss: 4.3647\n",
            "2024-11-11 09:14:49,636 - root - INFO - Saved model /content/pytorch-ssd/models/mb1-ssd-Epoch-5-Loss-6.8808776861013365.pth\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:15:27,687 - root - INFO - Epoch: 6, Step: 100, Average Loss: 4.8316, Average Regression Loss 2.0594, Average Classification Loss: 2.7721\n",
            "2024-11-11 09:16:03,436 - root - INFO - Epoch: 6, Step: 200, Average Loss: 4.8684, Average Regression Loss 2.1301, Average Classification Loss: 2.7383\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:16:37,953 - root - INFO - Epoch: 7, Step: 100, Average Loss: 4.7690, Average Regression Loss 2.1551, Average Classification Loss: 2.6139\n",
            "2024-11-11 09:17:15,261 - root - INFO - Epoch: 7, Step: 200, Average Loss: 4.9468, Average Regression Loss 2.1393, Average Classification Loss: 2.8075\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:17:56,248 - root - INFO - Epoch: 8, Step: 100, Average Loss: 4.9014, Average Regression Loss 2.0475, Average Classification Loss: 2.8539\n",
            "2024-11-11 09:18:31,893 - root - INFO - Epoch: 8, Step: 200, Average Loss: 5.0432, Average Regression Loss 2.2982, Average Classification Loss: 2.7450\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:19:12,414 - root - INFO - Epoch: 9, Step: 100, Average Loss: 5.0711, Average Regression Loss 2.2451, Average Classification Loss: 2.8260\n",
            "2024-11-11 09:19:49,891 - root - INFO - Epoch: 9, Step: 200, Average Loss: 4.9551, Average Regression Loss 2.1268, Average Classification Loss: 2.8283\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:20:30,014 - root - INFO - Epoch: 10, Step: 100, Average Loss: 5.0705, Average Regression Loss 2.1887, Average Classification Loss: 2.8817\n",
            "2024-11-11 09:21:02,371 - root - INFO - Epoch: 10, Step: 200, Average Loss: 4.7204, Average Regression Loss 2.0706, Average Classification Loss: 2.6498\n",
            "2024-11-11 09:21:11,019 - root - INFO - Epoch: 10, Validation Loss: 6.4888, Validation Regression Loss 2.2992, Validation Classification Loss: 4.1896\n",
            "2024-11-11 09:21:11,072 - root - INFO - Saved model /content/pytorch-ssd/models/mb1-ssd-Epoch-10-Loss-6.488830133926037.pth\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:21:49,764 - root - INFO - Epoch: 11, Step: 100, Average Loss: 4.9394, Average Regression Loss 2.1788, Average Classification Loss: 2.7607\n",
            "2024-11-11 09:22:28,149 - root - INFO - Epoch: 11, Step: 200, Average Loss: 4.6575, Average Regression Loss 2.0452, Average Classification Loss: 2.6124\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:23:06,777 - root - INFO - Epoch: 12, Step: 100, Average Loss: 4.6262, Average Regression Loss 2.0425, Average Classification Loss: 2.5837\n",
            "2024-11-11 09:23:40,359 - root - INFO - Epoch: 12, Step: 200, Average Loss: 4.6397, Average Regression Loss 2.0908, Average Classification Loss: 2.5489\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:24:18,402 - root - INFO - Epoch: 13, Step: 100, Average Loss: 4.4132, Average Regression Loss 1.9542, Average Classification Loss: 2.4590\n",
            "2024-11-11 09:24:54,297 - root - INFO - Epoch: 13, Step: 200, Average Loss: 4.6322, Average Regression Loss 2.0010, Average Classification Loss: 2.6312\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:25:33,646 - root - INFO - Epoch: 14, Step: 100, Average Loss: 4.9310, Average Regression Loss 2.0538, Average Classification Loss: 2.8772\n",
            "2024-11-11 09:26:11,708 - root - INFO - Epoch: 14, Step: 200, Average Loss: 4.6520, Average Regression Loss 1.9715, Average Classification Loss: 2.6804\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:26:49,186 - root - INFO - Epoch: 15, Step: 100, Average Loss: 4.7401, Average Regression Loss 2.0518, Average Classification Loss: 2.6883\n",
            "2024-11-11 09:27:22,249 - root - INFO - Epoch: 15, Step: 200, Average Loss: 4.6553, Average Regression Loss 2.0378, Average Classification Loss: 2.6175\n",
            "2024-11-11 09:27:31,192 - root - INFO - Epoch: 15, Validation Loss: 6.2867, Validation Regression Loss 2.3003, Validation Classification Loss: 3.9864\n",
            "2024-11-11 09:27:31,274 - root - INFO - Saved model /content/pytorch-ssd/models/mb1-ssd-Epoch-15-Loss-6.286716782769491.pth\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:28:07,377 - root - INFO - Epoch: 16, Step: 100, Average Loss: 4.9693, Average Regression Loss 2.0573, Average Classification Loss: 2.9121\n",
            "2024-11-11 09:28:43,875 - root - INFO - Epoch: 16, Step: 200, Average Loss: 4.6797, Average Regression Loss 2.1022, Average Classification Loss: 2.5775\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:29:23,928 - root - INFO - Epoch: 17, Step: 100, Average Loss: 4.8111, Average Regression Loss 2.1033, Average Classification Loss: 2.7078\n",
            "2024-11-11 09:30:00,042 - root - INFO - Epoch: 17, Step: 200, Average Loss: 4.6194, Average Regression Loss 1.9990, Average Classification Loss: 2.6204\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:30:39,763 - root - INFO - Epoch: 18, Step: 100, Average Loss: 4.6122, Average Regression Loss 1.9634, Average Classification Loss: 2.6489\n",
            "2024-11-11 09:31:16,991 - root - INFO - Epoch: 18, Step: 200, Average Loss: 4.4793, Average Regression Loss 1.9149, Average Classification Loss: 2.5644\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "/content/pytorch-ssd/vision/transforms/transforms.py:247: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  mode = random.choice(self.sample_options)\n",
            "2024-11-11 09:31:55,987 - root - INFO - Epoch: 19, Step: 100, Average Loss: 4.4048, Average Regression Loss 1.9591, Average Classification Loss: 2.4457\n",
            "2024-11-11 09:32:33,814 - root - INFO - Epoch: 19, Step: 200, Average Loss: 4.4256, Average Regression Loss 1.9658, Average Classification Loss: 2.4598\n",
            "2024-11-11 09:32:39,665 - root - INFO - Epoch: 19, Validation Loss: 7.5115, Validation Regression Loss 2.4906, Validation Classification Loss: 5.0209\n",
            "2024-11-11 09:32:39,718 - root - INFO - Saved model /content/pytorch-ssd/models/mb1-ssd-Epoch-19-Loss-7.511481892230899.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python pytorch-ssd/eval_ssd.py \\\n",
        "    --net mb1-ssd \\\n",
        "    --trained_model /content/pytorch-ssd/models/mb1-ssd-Epoch-19-Loss-4.53431602134261.pth \\\n",
        "    --dataset_type open_images \\\n",
        "    --dataset /content/open_images_data/test \\\n",
        "    --label_file /content/open_images_data/open-images-model-labels.txt \\\n",
        "    --use_cuda True \\\n",
        "    --iou_threshold 0.5 \\\n",
        "    --eval_dir /content/pytorch-ssd/eval_results\n",
        "# !python /content/pytorch-ssd/eval_ssd.py \\\n",
        "#     --net mb1-ssd \\\n",
        "#     --dataset_type open_images \\\n",
        "#     --dataset /content/open_images_data/test \\\n",
        "#     --trained_model /content/pytorch-ssd/models/mobilenet-v1-ssd-mp-0_675.pth \\\n",
        "#     --label_file /content/open_images_data/open-images-model-labels.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk6zheyVHoNb",
        "outputId": "bb926c78-77f5-4793-f31e-818f06a827fc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RuntimeError: module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem.\n",
            "/content/pytorch-ssd/eval_ssd.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  all_gt_boxes[class_index][image_id] = torch.tensor(all_gt_boxes[class_index][image_id])\n",
            "/content/pytorch-ssd/vision/ssd/ssd.py:135: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(model, map_location=lambda storage, loc: storage))\n",
            "It took 0.05184817314147949 seconds to load the model.\n",
            "process image 0\n",
            "Load Image: 0.008053 seconds.\n",
            "Inference time:  0.323960542678833\n",
            "Prediction: 0.334886 seconds.\n",
            "process image 1\n",
            "Load Image: 0.005303 seconds.\n",
            "Inference time:  0.0052258968353271484\n",
            "Prediction: 0.014447 seconds.\n",
            "process image 2\n",
            "Load Image: 0.004135 seconds.\n",
            "Inference time:  0.00502324104309082\n",
            "Prediction: 0.017534 seconds.\n",
            "process image 3\n",
            "Load Image: 0.006987 seconds.\n",
            "Inference time:  0.005012035369873047\n",
            "Prediction: 0.015906 seconds.\n",
            "process image 4\n",
            "Load Image: 0.007410 seconds.\n",
            "Inference time:  0.0050008296966552734\n",
            "Prediction: 0.014976 seconds.\n",
            "process image 5\n",
            "Load Image: 0.004384 seconds.\n",
            "Inference time:  0.005259513854980469\n",
            "Prediction: 0.020471 seconds.\n",
            "process image 6\n",
            "Load Image: 0.009280 seconds.\n",
            "Inference time:  0.007977724075317383\n",
            "Prediction: 0.023734 seconds.\n",
            "process image 7\n",
            "Load Image: 0.004375 seconds.\n",
            "Inference time:  0.004890918731689453\n",
            "Prediction: 0.021576 seconds.\n",
            "process image 8\n",
            "Load Image: 0.012084 seconds.\n",
            "Inference time:  0.004871368408203125\n",
            "Prediction: 0.015107 seconds.\n",
            "process image 9\n",
            "Load Image: 0.011534 seconds.\n",
            "Inference time:  0.004824161529541016\n",
            "Prediction: 0.027770 seconds.\n",
            "process image 10\n",
            "Load Image: 0.009778 seconds.\n",
            "Inference time:  0.004893064498901367\n",
            "Prediction: 0.017212 seconds.\n",
            "process image 11\n",
            "Load Image: 0.003362 seconds.\n",
            "Inference time:  0.008065223693847656\n",
            "Prediction: 0.025001 seconds.\n",
            "process image 12\n",
            "Load Image: 0.007702 seconds.\n",
            "Inference time:  0.005172252655029297\n",
            "Prediction: 0.020976 seconds.\n",
            "process image 13\n",
            "Load Image: 0.009259 seconds.\n",
            "Inference time:  0.005585908889770508\n",
            "Prediction: 0.017078 seconds.\n",
            "process image 14\n",
            "Load Image: 0.003625 seconds.\n",
            "Inference time:  0.0050868988037109375\n",
            "Prediction: 0.020329 seconds.\n",
            "process image 15\n",
            "Load Image: 0.009524 seconds.\n",
            "Inference time:  0.0052793025970458984\n",
            "Prediction: 0.023224 seconds.\n",
            "process image 16\n",
            "Load Image: 0.003689 seconds.\n",
            "Inference time:  0.005077362060546875\n",
            "Prediction: 0.016196 seconds.\n",
            "process image 17\n",
            "Load Image: 0.004844 seconds.\n",
            "Inference time:  0.005401134490966797\n",
            "Prediction: 0.016447 seconds.\n",
            "process image 18\n",
            "Load Image: 0.005487 seconds.\n",
            "Inference time:  0.0082855224609375\n",
            "Prediction: 0.018457 seconds.\n",
            "process image 19\n",
            "Load Image: 0.005957 seconds.\n",
            "Inference time:  0.005083560943603516\n",
            "Prediction: 0.013464 seconds.\n",
            "process image 20\n",
            "Load Image: 0.004471 seconds.\n",
            "Inference time:  0.00523829460144043\n",
            "Prediction: 0.017149 seconds.\n",
            "process image 21\n",
            "Load Image: 0.004978 seconds.\n",
            "Inference time:  0.005083322525024414\n",
            "Prediction: 0.015837 seconds.\n",
            "process image 22\n",
            "Load Image: 0.012084 seconds.\n",
            "Inference time:  0.005132913589477539\n",
            "Prediction: 0.016594 seconds.\n",
            "process image 23\n",
            "Load Image: 0.003218 seconds.\n",
            "Inference time:  0.0059528350830078125\n",
            "Prediction: 0.020797 seconds.\n",
            "process image 24\n",
            "Load Image: 0.005702 seconds.\n",
            "Inference time:  0.0052967071533203125\n",
            "Prediction: 0.015792 seconds.\n",
            "process image 25\n",
            "Load Image: 0.004471 seconds.\n",
            "Inference time:  0.005437374114990234\n",
            "Prediction: 0.013425 seconds.\n",
            "process image 26\n",
            "Load Image: 0.014454 seconds.\n",
            "Inference time:  0.0051424503326416016\n",
            "Prediction: 0.012480 seconds.\n",
            "process image 27\n",
            "Load Image: 0.007787 seconds.\n",
            "Inference time:  0.0056416988372802734\n",
            "Prediction: 0.018278 seconds.\n",
            "process image 28\n",
            "Load Image: 0.003898 seconds.\n",
            "Inference time:  0.004942893981933594\n",
            "Prediction: 0.016002 seconds.\n",
            "process image 29\n",
            "Load Image: 0.009708 seconds.\n",
            "Inference time:  0.005044221878051758\n",
            "Prediction: 0.015126 seconds.\n",
            "process image 30\n",
            "Load Image: 0.005221 seconds.\n",
            "Inference time:  0.005214691162109375\n",
            "Prediction: 0.015432 seconds.\n",
            "process image 31\n",
            "Load Image: 0.005340 seconds.\n",
            "Inference time:  0.004904031753540039\n",
            "Prediction: 0.019539 seconds.\n",
            "process image 32\n",
            "Load Image: 0.006481 seconds.\n",
            "Inference time:  0.0049054622650146484\n",
            "Prediction: 0.015722 seconds.\n",
            "process image 33\n",
            "Load Image: 0.003904 seconds.\n",
            "Inference time:  0.004927873611450195\n",
            "Prediction: 0.016177 seconds.\n",
            "process image 34\n",
            "Load Image: 0.008911 seconds.\n",
            "Inference time:  0.004797697067260742\n",
            "Prediction: 0.016707 seconds.\n",
            "process image 35\n",
            "Load Image: 0.006581 seconds.\n",
            "Inference time:  0.004734039306640625\n",
            "Prediction: 0.016745 seconds.\n",
            "process image 36\n",
            "Load Image: 0.010098 seconds.\n",
            "Inference time:  0.008467435836791992\n",
            "Prediction: 0.023579 seconds.\n",
            "process image 37\n",
            "Load Image: 0.007086 seconds.\n",
            "Inference time:  0.0047643184661865234\n",
            "Prediction: 0.014307 seconds.\n",
            "process image 38\n",
            "Load Image: 0.004274 seconds.\n",
            "Inference time:  0.0048749446868896484\n",
            "Prediction: 0.015988 seconds.\n",
            "process image 39\n",
            "Load Image: 0.004440 seconds.\n",
            "Inference time:  0.004855155944824219\n",
            "Prediction: 0.015805 seconds.\n",
            "process image 40\n",
            "Load Image: 0.005826 seconds.\n",
            "Inference time:  0.0049173831939697266\n",
            "Prediction: 0.015531 seconds.\n",
            "process image 41\n",
            "Load Image: 0.007334 seconds.\n",
            "Inference time:  0.004777669906616211\n",
            "Prediction: 0.013386 seconds.\n",
            "process image 42\n",
            "Load Image: 0.009915 seconds.\n",
            "Inference time:  0.004756450653076172\n",
            "Prediction: 0.014515 seconds.\n",
            "process image 43\n",
            "Load Image: 0.005597 seconds.\n",
            "Inference time:  0.00550079345703125\n",
            "Prediction: 0.012891 seconds.\n",
            "process image 44\n",
            "Load Image: 0.009026 seconds.\n",
            "Inference time:  0.00715327262878418\n",
            "Prediction: 0.020532 seconds.\n",
            "process image 45\n",
            "Load Image: 0.004448 seconds.\n",
            "Inference time:  0.005388021469116211\n",
            "Prediction: 0.019248 seconds.\n",
            "process image 46\n",
            "Load Image: 0.006600 seconds.\n",
            "Inference time:  0.005288124084472656\n",
            "Prediction: 0.013391 seconds.\n",
            "process image 47\n",
            "Load Image: 0.004627 seconds.\n",
            "Inference time:  0.006076812744140625\n",
            "Prediction: 0.019845 seconds.\n",
            "process image 48\n",
            "Load Image: 0.008254 seconds.\n",
            "Inference time:  0.005850315093994141\n",
            "Prediction: 0.018328 seconds.\n",
            "process image 49\n",
            "Load Image: 0.003133 seconds.\n",
            "Inference time:  0.008839845657348633\n",
            "Prediction: 0.019047 seconds.\n",
            "process image 50\n",
            "Load Image: 0.005115 seconds.\n",
            "Inference time:  0.005109548568725586\n",
            "Prediction: 0.014386 seconds.\n",
            "process image 51\n",
            "Load Image: 0.007491 seconds.\n",
            "Inference time:  0.005170583724975586\n",
            "Prediction: 0.016959 seconds.\n",
            "process image 52\n",
            "Load Image: 0.006620 seconds.\n",
            "Inference time:  0.0050737857818603516\n",
            "Prediction: 0.017785 seconds.\n",
            "process image 53\n",
            "Load Image: 0.003750 seconds.\n",
            "Inference time:  0.005815744400024414\n",
            "Prediction: 0.022945 seconds.\n",
            "process image 54\n",
            "Load Image: 0.005060 seconds.\n",
            "Inference time:  0.005235910415649414\n",
            "Prediction: 0.019327 seconds.\n",
            "process image 55\n",
            "Load Image: 0.009352 seconds.\n",
            "Inference time:  0.00501561164855957\n",
            "Prediction: 0.019382 seconds.\n",
            "process image 56\n",
            "Load Image: 0.006757 seconds.\n",
            "Inference time:  0.0072422027587890625\n",
            "Prediction: 0.017897 seconds.\n",
            "process image 57\n",
            "Load Image: 0.003408 seconds.\n",
            "Inference time:  0.005461215972900391\n",
            "Prediction: 0.018527 seconds.\n",
            "process image 58\n",
            "Load Image: 0.006162 seconds.\n",
            "Inference time:  0.005032539367675781\n",
            "Prediction: 0.015374 seconds.\n",
            "process image 59\n",
            "Load Image: 0.003431 seconds.\n",
            "Inference time:  0.004980325698852539\n",
            "Prediction: 0.015952 seconds.\n",
            "process image 60\n",
            "Load Image: 0.004544 seconds.\n",
            "Inference time:  0.004979133605957031\n",
            "Prediction: 0.016313 seconds.\n",
            "process image 61\n",
            "Load Image: 0.003212 seconds.\n",
            "Inference time:  0.005120992660522461\n",
            "Prediction: 0.017014 seconds.\n",
            "process image 62\n",
            "Load Image: 0.005929 seconds.\n",
            "Inference time:  0.006697654724121094\n",
            "Prediction: 0.024074 seconds.\n",
            "process image 63\n",
            "Load Image: 0.005201 seconds.\n",
            "Inference time:  0.004825592041015625\n",
            "Prediction: 0.013345 seconds.\n",
            "process image 64\n",
            "Load Image: 0.009457 seconds.\n",
            "Inference time:  0.005920886993408203\n",
            "Prediction: 0.019536 seconds.\n",
            "process image 65\n",
            "Load Image: 0.005565 seconds.\n",
            "Inference time:  0.004810810089111328\n",
            "Prediction: 0.013662 seconds.\n",
            "process image 66\n",
            "Load Image: 0.004490 seconds.\n",
            "Inference time:  0.00544428825378418\n",
            "Prediction: 0.017920 seconds.\n",
            "process image 67\n",
            "Load Image: 0.008514 seconds.\n",
            "Inference time:  0.004832267761230469\n",
            "Prediction: 0.017539 seconds.\n",
            "process image 68\n",
            "Load Image: 0.007526 seconds.\n",
            "Inference time:  0.004858255386352539\n",
            "Prediction: 0.017705 seconds.\n",
            "process image 69\n",
            "Load Image: 0.004564 seconds.\n",
            "Inference time:  0.004731178283691406\n",
            "Prediction: 0.016610 seconds.\n",
            "process image 70\n",
            "Load Image: 0.004807 seconds.\n",
            "Inference time:  0.004783153533935547\n",
            "Prediction: 0.016725 seconds.\n",
            "process image 71\n",
            "Load Image: 0.013365 seconds.\n",
            "Inference time:  0.005895853042602539\n",
            "Prediction: 0.030186 seconds.\n",
            "process image 72\n",
            "Load Image: 0.008205 seconds.\n",
            "Inference time:  0.004773616790771484\n",
            "Prediction: 0.015811 seconds.\n",
            "process image 73\n",
            "Load Image: 0.004901 seconds.\n",
            "Inference time:  0.004723787307739258\n",
            "Prediction: 0.019137 seconds.\n",
            "process image 74\n",
            "Load Image: 0.014792 seconds.\n",
            "Inference time:  0.005257368087768555\n",
            "Prediction: 0.016178 seconds.\n",
            "process image 75\n",
            "Load Image: 0.005223 seconds.\n",
            "Inference time:  0.005522489547729492\n",
            "Prediction: 0.018001 seconds.\n",
            "process image 76\n",
            "Load Image: 0.010953 seconds.\n",
            "Inference time:  0.004942178726196289\n",
            "Prediction: 0.014798 seconds.\n",
            "process image 77\n",
            "Load Image: 0.003989 seconds.\n",
            "Inference time:  0.004812955856323242\n",
            "Prediction: 0.017971 seconds.\n",
            "process image 78\n",
            "Load Image: 0.005257 seconds.\n",
            "Inference time:  0.006392240524291992\n",
            "Prediction: 0.017839 seconds.\n",
            "process image 79\n",
            "Load Image: 0.004271 seconds.\n",
            "Inference time:  0.0047647953033447266\n",
            "Prediction: 0.021052 seconds.\n",
            "process image 80\n",
            "Load Image: 0.005923 seconds.\n",
            "Inference time:  0.004705667495727539\n",
            "Prediction: 0.016094 seconds.\n",
            "process image 81\n",
            "Load Image: 0.006780 seconds.\n",
            "Inference time:  0.006720304489135742\n",
            "Prediction: 0.016774 seconds.\n",
            "process image 82\n",
            "Load Image: 0.005381 seconds.\n",
            "Inference time:  0.0071337223052978516\n",
            "Prediction: 0.021080 seconds.\n",
            "process image 83\n",
            "Load Image: 0.007310 seconds.\n",
            "Inference time:  0.005065441131591797\n",
            "Prediction: 0.013452 seconds.\n",
            "process image 84\n",
            "Load Image: 0.006483 seconds.\n",
            "Inference time:  0.005319356918334961\n",
            "Prediction: 0.012763 seconds.\n",
            "process image 85\n",
            "Load Image: 0.002917 seconds.\n",
            "Inference time:  0.004926443099975586\n",
            "Prediction: 0.018716 seconds.\n",
            "process image 86\n",
            "Load Image: 0.007344 seconds.\n",
            "Inference time:  0.005179643630981445\n",
            "Prediction: 0.015906 seconds.\n",
            "process image 87\n",
            "Load Image: 0.004822 seconds.\n",
            "Inference time:  0.005009651184082031\n",
            "Prediction: 0.015298 seconds.\n",
            "process image 88\n",
            "Load Image: 0.010279 seconds.\n",
            "Inference time:  0.004701852798461914\n",
            "Prediction: 0.015420 seconds.\n",
            "process image 89\n",
            "Load Image: 0.005213 seconds.\n",
            "Inference time:  0.004720211029052734\n",
            "Prediction: 0.014519 seconds.\n",
            "process image 90\n",
            "Load Image: 0.004710 seconds.\n",
            "Inference time:  0.008879899978637695\n",
            "Prediction: 0.023852 seconds.\n",
            "process image 91\n",
            "Load Image: 0.006914 seconds.\n",
            "Inference time:  0.0072174072265625\n",
            "Prediction: 0.021444 seconds.\n",
            "process image 92\n",
            "Load Image: 0.007801 seconds.\n",
            "Inference time:  0.0048313140869140625\n",
            "Prediction: 0.015546 seconds.\n",
            "process image 93\n",
            "Load Image: 0.009681 seconds.\n",
            "Inference time:  0.0047283172607421875\n",
            "Prediction: 0.016183 seconds.\n",
            "process image 94\n",
            "Load Image: 0.006491 seconds.\n",
            "Inference time:  0.0047245025634765625\n",
            "Prediction: 0.019141 seconds.\n",
            "process image 95\n",
            "Load Image: 0.009244 seconds.\n",
            "Inference time:  0.0066988468170166016\n",
            "Prediction: 0.020653 seconds.\n",
            "process image 96\n",
            "Load Image: 0.009762 seconds.\n",
            "Inference time:  0.0048711299896240234\n",
            "Prediction: 0.019782 seconds.\n",
            "process image 97\n",
            "Load Image: 0.004458 seconds.\n",
            "Inference time:  0.005113363265991211\n",
            "Prediction: 0.018865 seconds.\n",
            "process image 98\n",
            "Load Image: 0.005296 seconds.\n",
            "Inference time:  0.0048449039459228516\n",
            "Prediction: 0.027520 seconds.\n",
            "process image 99\n",
            "Load Image: 0.009427 seconds.\n",
            "Inference time:  0.009453773498535156\n",
            "Prediction: 0.032300 seconds.\n",
            "process image 100\n",
            "Load Image: 0.005323 seconds.\n",
            "Inference time:  0.006401777267456055\n",
            "Prediction: 0.021863 seconds.\n",
            "process image 101\n",
            "Load Image: 0.006323 seconds.\n",
            "Inference time:  0.007961511611938477\n",
            "Prediction: 0.023606 seconds.\n",
            "process image 102\n",
            "Load Image: 0.009967 seconds.\n",
            "Inference time:  0.006128787994384766\n",
            "Prediction: 0.018586 seconds.\n",
            "process image 103\n",
            "Load Image: 0.010593 seconds.\n",
            "Inference time:  0.005530595779418945\n",
            "Prediction: 0.020478 seconds.\n",
            "process image 104\n",
            "Load Image: 0.004085 seconds.\n",
            "Inference time:  0.005190134048461914\n",
            "Prediction: 0.016097 seconds.\n",
            "process image 105\n",
            "Load Image: 0.006967 seconds.\n",
            "Inference time:  0.005462646484375\n",
            "Prediction: 0.015197 seconds.\n",
            "process image 106\n",
            "Load Image: 0.010560 seconds.\n",
            "Inference time:  0.004985332489013672\n",
            "Prediction: 0.015052 seconds.\n",
            "process image 107\n",
            "Load Image: 0.004205 seconds.\n",
            "Inference time:  0.005088090896606445\n",
            "Prediction: 0.013781 seconds.\n",
            "process image 108\n",
            "Load Image: 0.010651 seconds.\n",
            "Inference time:  0.0055694580078125\n",
            "Prediction: 0.022231 seconds.\n",
            "process image 109\n",
            "Load Image: 0.003628 seconds.\n",
            "Inference time:  0.005433559417724609\n",
            "Prediction: 0.020340 seconds.\n",
            "process image 110\n",
            "Load Image: 0.004945 seconds.\n",
            "Inference time:  0.005300760269165039\n",
            "Prediction: 0.014380 seconds.\n",
            "process image 111\n",
            "Load Image: 0.006176 seconds.\n",
            "Inference time:  0.00603795051574707\n",
            "Prediction: 0.015347 seconds.\n",
            "process image 112\n",
            "Load Image: 0.003789 seconds.\n",
            "Inference time:  0.005036354064941406\n",
            "Prediction: 0.013859 seconds.\n",
            "process image 113\n",
            "Load Image: 0.004153 seconds.\n",
            "Inference time:  0.005028247833251953\n",
            "Prediction: 0.017558 seconds.\n",
            "process image 114\n",
            "Load Image: 0.011413 seconds.\n",
            "Inference time:  0.005244255065917969\n",
            "Prediction: 0.018997 seconds.\n",
            "process image 115\n",
            "Load Image: 0.004962 seconds.\n",
            "Inference time:  0.004943132400512695\n",
            "Prediction: 0.017951 seconds.\n",
            "process image 116\n",
            "Load Image: 0.006104 seconds.\n",
            "Inference time:  0.0051958560943603516\n",
            "Prediction: 0.016783 seconds.\n",
            "process image 117\n",
            "Load Image: 0.011182 seconds.\n",
            "Inference time:  0.005881309509277344\n",
            "Prediction: 0.018969 seconds.\n",
            "process image 118\n",
            "Load Image: 0.003398 seconds.\n",
            "Inference time:  0.006750345230102539\n",
            "Prediction: 0.024825 seconds.\n",
            "process image 119\n",
            "Load Image: 0.003849 seconds.\n",
            "Inference time:  0.005002737045288086\n",
            "Prediction: 0.013794 seconds.\n",
            "process image 120\n",
            "Load Image: 0.004056 seconds.\n",
            "Inference time:  0.004856109619140625\n",
            "Prediction: 0.015226 seconds.\n",
            "process image 121\n",
            "Load Image: 0.009356 seconds.\n",
            "Inference time:  0.004733085632324219\n",
            "Prediction: 0.022456 seconds.\n",
            "process image 122\n",
            "Load Image: 0.007544 seconds.\n",
            "Inference time:  0.0048100948333740234\n",
            "Prediction: 0.015987 seconds.\n",
            "process image 123\n",
            "Load Image: 0.006419 seconds.\n",
            "Inference time:  0.004739284515380859\n",
            "Prediction: 0.016196 seconds.\n",
            "process image 124\n",
            "Load Image: 0.004500 seconds.\n",
            "Inference time:  0.004780769348144531\n",
            "Prediction: 0.019988 seconds.\n",
            "process image 125\n",
            "Load Image: 0.004129 seconds.\n",
            "Inference time:  0.004703998565673828\n",
            "Prediction: 0.017271 seconds.\n",
            "process image 126\n",
            "Load Image: 0.002782 seconds.\n",
            "Inference time:  0.0064544677734375\n",
            "Prediction: 0.021228 seconds.\n",
            "process image 127\n",
            "Load Image: 0.003574 seconds.\n",
            "Inference time:  0.004746913909912109\n",
            "Prediction: 0.019006 seconds.\n",
            "process image 128\n",
            "Load Image: 0.007747 seconds.\n",
            "Inference time:  0.006246089935302734\n",
            "Prediction: 0.019735 seconds.\n",
            "process image 129\n",
            "Load Image: 0.007164 seconds.\n",
            "Inference time:  0.004811286926269531\n",
            "Prediction: 0.017184 seconds.\n",
            "process image 130\n",
            "Load Image: 0.007082 seconds.\n",
            "Inference time:  0.007521390914916992\n",
            "Prediction: 0.021261 seconds.\n",
            "process image 131\n",
            "Load Image: 0.006023 seconds.\n",
            "Inference time:  0.0055084228515625\n",
            "Prediction: 0.019017 seconds.\n",
            "process image 132\n",
            "Load Image: 0.002949 seconds.\n",
            "Inference time:  0.005341053009033203\n",
            "Prediction: 0.014288 seconds.\n",
            "process image 133\n",
            "Load Image: 0.005046 seconds.\n",
            "Inference time:  0.006428241729736328\n",
            "Prediction: 0.019117 seconds.\n",
            "process image 134\n",
            "Load Image: 0.017207 seconds.\n",
            "Inference time:  0.006145000457763672\n",
            "Prediction: 0.020128 seconds.\n",
            "process image 135\n",
            "Load Image: 0.003556 seconds.\n",
            "Inference time:  0.005686283111572266\n",
            "Prediction: 0.016190 seconds.\n",
            "process image 136\n",
            "Load Image: 0.007411 seconds.\n",
            "Inference time:  0.004979133605957031\n",
            "Prediction: 0.014293 seconds.\n",
            "process image 137\n",
            "Load Image: 0.005368 seconds.\n",
            "Inference time:  0.004863739013671875\n",
            "Prediction: 0.018455 seconds.\n",
            "process image 138\n",
            "Load Image: 0.005381 seconds.\n",
            "Inference time:  0.0056726932525634766\n",
            "Prediction: 0.018515 seconds.\n",
            "process image 139\n",
            "Load Image: 0.006488 seconds.\n",
            "Inference time:  0.005002737045288086\n",
            "Prediction: 0.020682 seconds.\n",
            "process image 140\n",
            "Load Image: 0.005369 seconds.\n",
            "Inference time:  0.005556821823120117\n",
            "Prediction: 0.016895 seconds.\n",
            "process image 141\n",
            "Load Image: 0.006492 seconds.\n",
            "Inference time:  0.005033969879150391\n",
            "Prediction: 0.016895 seconds.\n",
            "process image 142\n",
            "Load Image: 0.003918 seconds.\n",
            "Inference time:  0.005229473114013672\n",
            "Prediction: 0.015888 seconds.\n",
            "process image 143\n",
            "Load Image: 0.009145 seconds.\n",
            "Inference time:  0.004964113235473633\n",
            "Prediction: 0.013797 seconds.\n",
            "process image 144\n",
            "Load Image: 0.003290 seconds.\n",
            "Inference time:  0.004844188690185547\n",
            "Prediction: 0.020341 seconds.\n",
            "process image 145\n",
            "Load Image: 0.002344 seconds.\n",
            "Inference time:  0.004841327667236328\n",
            "Prediction: 0.034155 seconds.\n",
            "process image 146\n",
            "Load Image: 0.002277 seconds.\n",
            "Inference time:  0.005201816558837891\n",
            "Prediction: 0.020763 seconds.\n",
            "process image 147\n",
            "Load Image: 0.009841 seconds.\n",
            "Inference time:  0.00515437126159668\n",
            "Prediction: 0.017897 seconds.\n",
            "process image 148\n",
            "Load Image: 0.004954 seconds.\n",
            "Inference time:  0.004915952682495117\n",
            "Prediction: 0.017544 seconds.\n",
            "process image 149\n",
            "Load Image: 0.004411 seconds.\n",
            "Inference time:  0.005662202835083008\n",
            "Prediction: 0.016671 seconds.\n",
            "process image 150\n",
            "Load Image: 0.010986 seconds.\n",
            "Inference time:  0.009155750274658203\n",
            "Prediction: 0.020653 seconds.\n",
            "process image 151\n",
            "Load Image: 0.007442 seconds.\n",
            "Inference time:  0.004957437515258789\n",
            "Prediction: 0.014332 seconds.\n",
            "process image 152\n",
            "Load Image: 0.009984 seconds.\n",
            "Inference time:  0.0051364898681640625\n",
            "Prediction: 0.017994 seconds.\n",
            "process image 153\n",
            "Load Image: 0.003605 seconds.\n",
            "Inference time:  0.00491786003112793\n",
            "Prediction: 0.018651 seconds.\n",
            "process image 154\n",
            "Load Image: 0.006070 seconds.\n",
            "Inference time:  0.004803895950317383\n",
            "Prediction: 0.015776 seconds.\n",
            "process image 155\n",
            "Load Image: 0.009090 seconds.\n",
            "Inference time:  0.004847526550292969\n",
            "Prediction: 0.015129 seconds.\n",
            "process image 156\n",
            "Load Image: 0.004823 seconds.\n",
            "Inference time:  0.005044460296630859\n",
            "Prediction: 0.016539 seconds.\n",
            "process image 157\n",
            "Load Image: 0.002462 seconds.\n",
            "Inference time:  0.0047419071197509766\n",
            "Prediction: 0.017291 seconds.\n",
            "process image 158\n",
            "Load Image: 0.004119 seconds.\n",
            "Inference time:  0.0053899288177490234\n",
            "Prediction: 0.020323 seconds.\n",
            "process image 159\n",
            "Load Image: 0.004722 seconds.\n",
            "Inference time:  0.006375312805175781\n",
            "Prediction: 0.018659 seconds.\n",
            "process image 160\n",
            "Load Image: 0.007194 seconds.\n",
            "Inference time:  0.004714012145996094\n",
            "Prediction: 0.016342 seconds.\n",
            "process image 161\n",
            "Load Image: 0.005228 seconds.\n",
            "Inference time:  0.004906892776489258\n",
            "Prediction: 0.013161 seconds.\n",
            "process image 162\n",
            "Load Image: 0.005835 seconds.\n",
            "Inference time:  0.005218505859375\n",
            "Prediction: 0.020158 seconds.\n",
            "process image 163\n",
            "Load Image: 0.004103 seconds.\n",
            "Inference time:  0.0049915313720703125\n",
            "Prediction: 0.018203 seconds.\n",
            "process image 164\n",
            "Load Image: 0.004073 seconds.\n",
            "Inference time:  0.00546717643737793\n",
            "Prediction: 0.013262 seconds.\n",
            "process image 165\n",
            "Load Image: 0.004286 seconds.\n",
            "Inference time:  0.005563259124755859\n",
            "Prediction: 0.017487 seconds.\n",
            "process image 166\n",
            "Load Image: 0.005736 seconds.\n",
            "Inference time:  0.005287647247314453\n",
            "Prediction: 0.016025 seconds.\n",
            "process image 167\n",
            "Load Image: 0.008112 seconds.\n",
            "Inference time:  0.0069773197174072266\n",
            "Prediction: 0.015965 seconds.\n",
            "process image 168\n",
            "Load Image: 0.006666 seconds.\n",
            "Inference time:  0.005713224411010742\n",
            "Prediction: 0.022424 seconds.\n",
            "process image 169\n",
            "Load Image: 0.005925 seconds.\n",
            "Inference time:  0.005112886428833008\n",
            "Prediction: 0.012629 seconds.\n",
            "process image 170\n",
            "Load Image: 0.004399 seconds.\n",
            "Inference time:  0.005003213882446289\n",
            "Prediction: 0.016771 seconds.\n",
            "process image 171\n",
            "Load Image: 0.010871 seconds.\n",
            "Inference time:  0.005482673645019531\n",
            "Prediction: 0.019013 seconds.\n",
            "process image 172\n",
            "Load Image: 0.003560 seconds.\n",
            "Inference time:  0.005288124084472656\n",
            "Prediction: 0.016999 seconds.\n",
            "process image 173\n",
            "Load Image: 0.003455 seconds.\n",
            "Inference time:  0.008272647857666016\n",
            "Prediction: 0.029997 seconds.\n",
            "process image 174\n",
            "Load Image: 0.008941 seconds.\n",
            "Inference time:  0.005342960357666016\n",
            "Prediction: 0.017713 seconds.\n",
            "process image 175\n",
            "Load Image: 0.003892 seconds.\n",
            "Inference time:  0.00496983528137207\n",
            "Prediction: 0.017376 seconds.\n",
            "process image 176\n",
            "Load Image: 0.005255 seconds.\n",
            "Inference time:  0.00522303581237793\n",
            "Prediction: 0.016711 seconds.\n",
            "process image 177\n",
            "Load Image: 0.005727 seconds.\n",
            "Inference time:  0.0049953460693359375\n",
            "Prediction: 0.019502 seconds.\n",
            "process image 178\n",
            "Load Image: 0.003263 seconds.\n",
            "Inference time:  0.0048828125\n",
            "Prediction: 0.018497 seconds.\n",
            "process image 179\n",
            "Load Image: 0.007036 seconds.\n",
            "Inference time:  0.0049304962158203125\n",
            "Prediction: 0.013209 seconds.\n",
            "process image 180\n",
            "Load Image: 0.004017 seconds.\n",
            "Inference time:  0.0048694610595703125\n",
            "Prediction: 0.019981 seconds.\n",
            "process image 181\n",
            "Load Image: 0.006775 seconds.\n",
            "Inference time:  0.0049285888671875\n",
            "Prediction: 0.015804 seconds.\n",
            "process image 182\n",
            "Load Image: 0.008248 seconds.\n",
            "Inference time:  0.0048258304595947266\n",
            "Prediction: 0.014797 seconds.\n",
            "process image 183\n",
            "Load Image: 0.004527 seconds.\n",
            "Inference time:  0.004816532135009766\n",
            "Prediction: 0.016419 seconds.\n",
            "process image 184\n",
            "Load Image: 0.008691 seconds.\n",
            "Inference time:  0.004856586456298828\n",
            "Prediction: 0.015615 seconds.\n",
            "process image 185\n",
            "Load Image: 0.006700 seconds.\n",
            "Inference time:  0.004915952682495117\n",
            "Prediction: 0.014666 seconds.\n",
            "process image 186\n",
            "Load Image: 0.004709 seconds.\n",
            "Inference time:  0.006377696990966797\n",
            "Prediction: 0.015802 seconds.\n",
            "process image 187\n",
            "Load Image: 0.009598 seconds.\n",
            "Inference time:  0.004754304885864258\n",
            "Prediction: 0.015610 seconds.\n",
            "process image 188\n",
            "Load Image: 0.008263 seconds.\n",
            "Inference time:  0.004802703857421875\n",
            "Prediction: 0.019711 seconds.\n",
            "process image 189\n",
            "Load Image: 0.003965 seconds.\n",
            "Inference time:  0.004971504211425781\n",
            "Prediction: 0.020350 seconds.\n",
            "process image 190\n",
            "Load Image: 0.009810 seconds.\n",
            "Inference time:  0.0049495697021484375\n",
            "Prediction: 0.016424 seconds.\n",
            "process image 191\n",
            "Load Image: 0.007621 seconds.\n",
            "Inference time:  0.00524449348449707\n",
            "Prediction: 0.017286 seconds.\n",
            "process image 192\n",
            "Load Image: 0.008204 seconds.\n",
            "Inference time:  0.0048296451568603516\n",
            "Prediction: 0.017009 seconds.\n",
            "process image 193\n",
            "Load Image: 0.003048 seconds.\n",
            "Inference time:  0.007666349411010742\n",
            "Prediction: 0.022576 seconds.\n",
            "process image 194\n",
            "Load Image: 0.005933 seconds.\n",
            "Inference time:  0.004946470260620117\n",
            "Prediction: 0.017635 seconds.\n",
            "process image 195\n",
            "Load Image: 0.005620 seconds.\n",
            "Inference time:  0.0047795772552490234\n",
            "Prediction: 0.017826 seconds.\n",
            "process image 196\n",
            "Load Image: 0.002868 seconds.\n",
            "Inference time:  0.004774332046508789\n",
            "Prediction: 0.015581 seconds.\n",
            "process image 197\n",
            "Load Image: 0.006424 seconds.\n",
            "Inference time:  0.005829572677612305\n",
            "Prediction: 0.017249 seconds.\n",
            "process image 198\n",
            "Load Image: 0.005346 seconds.\n",
            "Inference time:  0.0052280426025390625\n",
            "Prediction: 0.017608 seconds.\n",
            "process image 199\n",
            "Load Image: 0.003889 seconds.\n",
            "Inference time:  0.005245208740234375\n",
            "Prediction: 0.017352 seconds.\n",
            "process image 200\n",
            "Load Image: 0.003478 seconds.\n",
            "Inference time:  0.004990577697753906\n",
            "Prediction: 0.012603 seconds.\n",
            "process image 201\n",
            "Load Image: 0.006642 seconds.\n",
            "Inference time:  0.008652210235595703\n",
            "Prediction: 0.019806 seconds.\n",
            "process image 202\n",
            "Load Image: 0.006326 seconds.\n",
            "Inference time:  0.005620241165161133\n",
            "Prediction: 0.017879 seconds.\n",
            "process image 203\n",
            "Load Image: 0.010695 seconds.\n",
            "Inference time:  0.005488872528076172\n",
            "Prediction: 0.023899 seconds.\n",
            "process image 204\n",
            "Load Image: 0.004761 seconds.\n",
            "Inference time:  0.005150318145751953\n",
            "Prediction: 0.013448 seconds.\n",
            "process image 205\n",
            "Load Image: 0.003728 seconds.\n",
            "Inference time:  0.005013704299926758\n",
            "Prediction: 0.015875 seconds.\n",
            "process image 206\n",
            "Load Image: 0.012747 seconds.\n",
            "Inference time:  0.00518798828125\n",
            "Prediction: 0.012674 seconds.\n",
            "process image 207\n",
            "Load Image: 0.003801 seconds.\n",
            "Inference time:  0.005093574523925781\n",
            "Prediction: 0.016817 seconds.\n",
            "process image 208\n",
            "Load Image: 0.003220 seconds.\n",
            "Inference time:  0.005449771881103516\n",
            "Prediction: 0.017531 seconds.\n",
            "process image 209\n",
            "Load Image: 0.005967 seconds.\n",
            "Inference time:  0.0054247379302978516\n",
            "Prediction: 0.019044 seconds.\n",
            "process image 210\n",
            "Load Image: 0.009682 seconds.\n",
            "Inference time:  0.005380153656005859\n",
            "Prediction: 0.016851 seconds.\n",
            "process image 211\n",
            "Load Image: 0.003675 seconds.\n",
            "Inference time:  0.0049724578857421875\n",
            "Prediction: 0.019873 seconds.\n",
            "process image 212\n",
            "Load Image: 0.003525 seconds.\n",
            "Inference time:  0.0050029754638671875\n",
            "Prediction: 0.018747 seconds.\n",
            "process image 213\n",
            "Load Image: 0.006802 seconds.\n",
            "Inference time:  0.006494283676147461\n",
            "Prediction: 0.017372 seconds.\n",
            "process image 214\n",
            "Load Image: 0.016350 seconds.\n",
            "Inference time:  0.00529932975769043\n",
            "Prediction: 0.022476 seconds.\n",
            "process image 215\n",
            "Load Image: 0.006535 seconds.\n",
            "Inference time:  0.005835533142089844\n",
            "Prediction: 0.026138 seconds.\n",
            "process image 216\n",
            "Load Image: 0.006171 seconds.\n",
            "Inference time:  0.005437612533569336\n",
            "Prediction: 0.015713 seconds.\n",
            "process image 217\n",
            "Load Image: 0.003826 seconds.\n",
            "Inference time:  0.0050106048583984375\n",
            "Prediction: 0.013118 seconds.\n",
            "process image 218\n",
            "Load Image: 0.008597 seconds.\n",
            "Inference time:  0.0055806636810302734\n",
            "Prediction: 0.019356 seconds.\n",
            "process image 219\n",
            "Load Image: 0.010750 seconds.\n",
            "Inference time:  0.010526180267333984\n",
            "Prediction: 0.029669 seconds.\n",
            "process image 220\n",
            "Load Image: 0.005191 seconds.\n",
            "Inference time:  0.005225181579589844\n",
            "Prediction: 0.019183 seconds.\n",
            "process image 221\n",
            "Load Image: 0.009708 seconds.\n",
            "Inference time:  0.004973888397216797\n",
            "Prediction: 0.015808 seconds.\n",
            "process image 222\n",
            "Load Image: 0.004978 seconds.\n",
            "Inference time:  0.004882335662841797\n",
            "Prediction: 0.019723 seconds.\n",
            "process image 223\n",
            "Load Image: 0.006741 seconds.\n",
            "Inference time:  0.004901409149169922\n",
            "Prediction: 0.016585 seconds.\n",
            "process image 224\n",
            "Load Image: 0.009427 seconds.\n",
            "Inference time:  0.004780292510986328\n",
            "Prediction: 0.018470 seconds.\n",
            "process image 225\n",
            "Load Image: 0.007243 seconds.\n",
            "Inference time:  0.005093574523925781\n",
            "Prediction: 0.015266 seconds.\n",
            "process image 226\n",
            "Load Image: 0.003746 seconds.\n",
            "Inference time:  0.0046825408935546875\n",
            "Prediction: 0.015976 seconds.\n",
            "process image 227\n",
            "Load Image: 0.013496 seconds.\n",
            "Inference time:  0.0048449039459228516\n",
            "Prediction: 0.020504 seconds.\n",
            "process image 228\n",
            "Load Image: 0.005219 seconds.\n",
            "Inference time:  0.005269765853881836\n",
            "Prediction: 0.017112 seconds.\n",
            "process image 229\n",
            "Load Image: 0.003296 seconds.\n",
            "Inference time:  0.006273031234741211\n",
            "Prediction: 0.019202 seconds.\n",
            "process image 230\n",
            "Load Image: 0.006207 seconds.\n",
            "Inference time:  0.005254983901977539\n",
            "Prediction: 0.017840 seconds.\n",
            "process image 231\n",
            "Load Image: 0.002962 seconds.\n",
            "Inference time:  0.005644798278808594\n",
            "Prediction: 0.016496 seconds.\n",
            "process image 232\n",
            "Load Image: 0.008671 seconds.\n",
            "Inference time:  0.005108833312988281\n",
            "Prediction: 0.016869 seconds.\n",
            "process image 233\n",
            "Load Image: 0.004043 seconds.\n",
            "Inference time:  0.004982948303222656\n",
            "Prediction: 0.021155 seconds.\n",
            "process image 234\n",
            "Load Image: 0.005196 seconds.\n",
            "Inference time:  0.004881143569946289\n",
            "Prediction: 0.015924 seconds.\n",
            "process image 235\n",
            "Load Image: 0.007396 seconds.\n",
            "Inference time:  0.005499362945556641\n",
            "Prediction: 0.017771 seconds.\n",
            "process image 236\n",
            "Load Image: 0.002327 seconds.\n",
            "Inference time:  0.004758596420288086\n",
            "Prediction: 0.019347 seconds.\n",
            "process image 237\n",
            "Load Image: 0.005646 seconds.\n",
            "Inference time:  0.005171298980712891\n",
            "Prediction: 0.017531 seconds.\n",
            "process image 238\n",
            "Load Image: 0.005774 seconds.\n",
            "Inference time:  0.00507807731628418\n",
            "Prediction: 0.016160 seconds.\n",
            "process image 239\n",
            "Load Image: 0.009943 seconds.\n",
            "Inference time:  0.005087375640869141\n",
            "Prediction: 0.014618 seconds.\n",
            "process image 240\n",
            "Load Image: 0.004368 seconds.\n",
            "Inference time:  0.004705905914306641\n",
            "Prediction: 0.013684 seconds.\n",
            "process image 241\n",
            "Load Image: 0.003388 seconds.\n",
            "Inference time:  0.0059244632720947266\n",
            "Prediction: 0.018242 seconds.\n",
            "process image 242\n",
            "Load Image: 0.008267 seconds.\n",
            "Inference time:  0.007367610931396484\n",
            "Prediction: 0.021314 seconds.\n",
            "process image 243\n",
            "Load Image: 0.005105 seconds.\n",
            "Inference time:  0.00695347785949707\n",
            "Prediction: 0.021799 seconds.\n",
            "process image 244\n",
            "Load Image: 0.002449 seconds.\n",
            "Inference time:  0.005185842514038086\n",
            "Prediction: 0.016640 seconds.\n",
            "process image 245\n",
            "Load Image: 0.005944 seconds.\n",
            "Inference time:  0.0050754547119140625\n",
            "Prediction: 0.016253 seconds.\n",
            "process image 246\n",
            "Load Image: 0.007427 seconds.\n",
            "Inference time:  0.005041360855102539\n",
            "Prediction: 0.015131 seconds.\n",
            "process image 247\n",
            "Load Image: 0.004925 seconds.\n",
            "Inference time:  0.0049550533294677734\n",
            "Prediction: 0.018506 seconds.\n",
            "process image 248\n",
            "Load Image: 0.009886 seconds.\n",
            "Inference time:  0.0049321651458740234\n",
            "Prediction: 0.018376 seconds.\n",
            "process image 249\n",
            "Load Image: 0.007434 seconds.\n",
            "Inference time:  0.005099296569824219\n",
            "Prediction: 0.015314 seconds.\n",
            "process image 250\n",
            "Load Image: 0.004025 seconds.\n",
            "Inference time:  0.0058138370513916016\n",
            "Prediction: 0.017110 seconds.\n",
            "process image 251\n",
            "Load Image: 0.005072 seconds.\n",
            "Inference time:  0.005037784576416016\n",
            "Prediction: 0.015949 seconds.\n",
            "process image 252\n",
            "Load Image: 0.005337 seconds.\n",
            "Inference time:  0.005263566970825195\n",
            "Prediction: 0.019424 seconds.\n",
            "process image 253\n",
            "Load Image: 0.005652 seconds.\n",
            "Inference time:  0.004945278167724609\n",
            "Prediction: 0.015398 seconds.\n",
            "process image 254\n",
            "Load Image: 0.007686 seconds.\n",
            "Inference time:  0.004962444305419922\n",
            "Prediction: 0.024415 seconds.\n",
            "process image 255\n",
            "Load Image: 0.008868 seconds.\n",
            "Inference time:  0.0051631927490234375\n",
            "Prediction: 0.016396 seconds.\n",
            "process image 256\n",
            "Load Image: 0.003728 seconds.\n",
            "Inference time:  0.005055427551269531\n",
            "Prediction: 0.016083 seconds.\n",
            "process image 257\n",
            "Load Image: 0.003260 seconds.\n",
            "Inference time:  0.0048635005950927734\n",
            "Prediction: 0.018840 seconds.\n",
            "process image 258\n",
            "Load Image: 0.008259 seconds.\n",
            "Inference time:  0.009508132934570312\n",
            "Prediction: 0.022465 seconds.\n",
            "process image 259\n",
            "Load Image: 0.003980 seconds.\n",
            "Inference time:  0.004989147186279297\n",
            "Prediction: 0.013196 seconds.\n",
            "process image 260\n",
            "Load Image: 0.007083 seconds.\n",
            "Inference time:  0.004792451858520508\n",
            "Prediction: 0.014516 seconds.\n",
            "process image 261\n",
            "Load Image: 0.005249 seconds.\n",
            "Inference time:  0.004872322082519531\n",
            "Prediction: 0.016151 seconds.\n",
            "process image 262\n",
            "Load Image: 0.006457 seconds.\n",
            "Inference time:  0.005684614181518555\n",
            "Prediction: 0.019034 seconds.\n",
            "process image 263\n",
            "Load Image: 0.004057 seconds.\n",
            "Inference time:  0.0053255558013916016\n",
            "Prediction: 0.014163 seconds.\n",
            "process image 264\n",
            "Load Image: 0.009341 seconds.\n",
            "Inference time:  0.005153656005859375\n",
            "Prediction: 0.016987 seconds.\n",
            "process image 265\n",
            "Load Image: 0.004685 seconds.\n",
            "Inference time:  0.0050678253173828125\n",
            "Prediction: 0.013278 seconds.\n",
            "process image 266\n",
            "Load Image: 0.008425 seconds.\n",
            "Inference time:  0.005057573318481445\n",
            "Prediction: 0.015473 seconds.\n",
            "process image 267\n",
            "Load Image: 0.004873 seconds.\n",
            "Inference time:  0.005558967590332031\n",
            "Prediction: 0.018620 seconds.\n",
            "process image 268\n",
            "Load Image: 0.008225 seconds.\n",
            "Inference time:  0.006355762481689453\n",
            "Prediction: 0.018038 seconds.\n",
            "process image 269\n",
            "Load Image: 0.009625 seconds.\n",
            "Inference time:  0.0050907135009765625\n",
            "Prediction: 0.015463 seconds.\n",
            "process image 270\n",
            "Load Image: 0.011490 seconds.\n",
            "Inference time:  0.005168437957763672\n",
            "Prediction: 0.015980 seconds.\n",
            "process image 271\n",
            "Load Image: 0.010725 seconds.\n",
            "Inference time:  0.0051190853118896484\n",
            "Prediction: 0.016548 seconds.\n",
            "process image 272\n",
            "Load Image: 0.004139 seconds.\n",
            "Inference time:  0.0053555965423583984\n",
            "Prediction: 0.013952 seconds.\n",
            "process image 273\n",
            "Load Image: 0.005056 seconds.\n",
            "Inference time:  0.00490880012512207\n",
            "Prediction: 0.014770 seconds.\n",
            "process image 274\n",
            "Load Image: 0.007814 seconds.\n",
            "Inference time:  0.0055637359619140625\n",
            "Prediction: 0.016841 seconds.\n",
            "process image 275\n",
            "Load Image: 0.013884 seconds.\n",
            "Inference time:  0.009263753890991211\n",
            "Prediction: 0.038342 seconds.\n",
            "process image 276\n",
            "Load Image: 0.003918 seconds.\n",
            "Inference time:  0.008775711059570312\n",
            "Prediction: 0.028421 seconds.\n",
            "process image 277\n",
            "Load Image: 0.012055 seconds.\n",
            "Inference time:  0.00904989242553711\n",
            "Prediction: 0.023261 seconds.\n",
            "process image 278\n",
            "Load Image: 0.006801 seconds.\n",
            "Inference time:  0.008777856826782227\n",
            "Prediction: 0.029059 seconds.\n",
            "process image 279\n",
            "Load Image: 0.005370 seconds.\n",
            "Inference time:  0.00661015510559082\n",
            "Prediction: 0.019812 seconds.\n",
            "process image 280\n",
            "Load Image: 0.014045 seconds.\n",
            "Inference time:  0.008873701095581055\n",
            "Prediction: 0.024455 seconds.\n",
            "process image 281\n",
            "Load Image: 0.008731 seconds.\n",
            "Inference time:  0.00726008415222168\n",
            "Prediction: 0.022575 seconds.\n",
            "process image 282\n",
            "Load Image: 0.008136 seconds.\n",
            "Inference time:  0.008844614028930664\n",
            "Prediction: 0.028709 seconds.\n",
            "process image 283\n",
            "Load Image: 0.012121 seconds.\n",
            "Inference time:  0.007566213607788086\n",
            "Prediction: 0.019205 seconds.\n",
            "process image 284\n",
            "Load Image: 0.016608 seconds.\n",
            "Inference time:  0.0065517425537109375\n",
            "Prediction: 0.027630 seconds.\n",
            "process image 285\n",
            "Load Image: 0.010023 seconds.\n",
            "Inference time:  0.006159067153930664\n",
            "Prediction: 0.020084 seconds.\n",
            "process image 286\n",
            "Load Image: 0.006195 seconds.\n",
            "Inference time:  0.00604248046875\n",
            "Prediction: 0.028011 seconds.\n",
            "process image 287\n",
            "Load Image: 0.012475 seconds.\n",
            "Inference time:  0.009981393814086914\n",
            "Prediction: 0.027522 seconds.\n",
            "process image 288\n",
            "Load Image: 0.007255 seconds.\n",
            "Inference time:  0.007572650909423828\n",
            "Prediction: 0.024436 seconds.\n",
            "process image 289\n",
            "Load Image: 0.008526 seconds.\n",
            "Inference time:  0.007718801498413086\n",
            "Prediction: 0.028918 seconds.\n",
            "process image 290\n",
            "Load Image: 0.010062 seconds.\n",
            "Inference time:  0.006762981414794922\n",
            "Prediction: 0.020366 seconds.\n",
            "process image 291\n",
            "Load Image: 0.016340 seconds.\n",
            "Inference time:  0.006590843200683594\n",
            "Prediction: 0.021909 seconds.\n",
            "process image 292\n",
            "Load Image: 0.006400 seconds.\n",
            "Inference time:  0.014220952987670898\n",
            "Prediction: 0.031317 seconds.\n",
            "process image 293\n",
            "Load Image: 0.014581 seconds.\n",
            "Inference time:  0.007109165191650391\n",
            "Prediction: 0.021458 seconds.\n",
            "process image 294\n",
            "Load Image: 0.013616 seconds.\n",
            "Inference time:  0.006548404693603516\n",
            "Prediction: 0.021624 seconds.\n",
            "process image 295\n",
            "Load Image: 0.003779 seconds.\n",
            "Inference time:  0.0065119266510009766\n",
            "Prediction: 0.023134 seconds.\n",
            "process image 296\n",
            "Load Image: 0.008359 seconds.\n",
            "Inference time:  0.0066852569580078125\n",
            "Prediction: 0.019666 seconds.\n",
            "process image 297\n",
            "Load Image: 0.006536 seconds.\n",
            "Inference time:  0.0068547725677490234\n",
            "Prediction: 0.024623 seconds.\n",
            "process image 298\n",
            "Load Image: 0.008875 seconds.\n",
            "Inference time:  0.007039546966552734\n",
            "Prediction: 0.020648 seconds.\n",
            "process image 299\n",
            "Load Image: 0.013257 seconds.\n",
            "Inference time:  0.008514881134033203\n",
            "Prediction: 0.025013 seconds.\n",
            "process image 300\n",
            "Load Image: 0.012064 seconds.\n",
            "Inference time:  0.0061953067779541016\n",
            "Prediction: 0.017745 seconds.\n",
            "process image 301\n",
            "Load Image: 0.010141 seconds.\n",
            "Inference time:  0.006161212921142578\n",
            "Prediction: 0.020403 seconds.\n",
            "process image 302\n",
            "Load Image: 0.010871 seconds.\n",
            "Inference time:  0.0063397884368896484\n",
            "Prediction: 0.020640 seconds.\n",
            "process image 303\n",
            "Load Image: 0.007802 seconds.\n",
            "Inference time:  0.006392240524291992\n",
            "Prediction: 0.017491 seconds.\n",
            "process image 304\n",
            "Load Image: 0.008961 seconds.\n",
            "Inference time:  0.00598597526550293\n",
            "Prediction: 0.019435 seconds.\n",
            "process image 305\n",
            "Load Image: 0.007192 seconds.\n",
            "Inference time:  0.00670933723449707\n",
            "Prediction: 0.026077 seconds.\n",
            "process image 306\n",
            "Load Image: 0.007881 seconds.\n",
            "Inference time:  0.0063703060150146484\n",
            "Prediction: 0.024403 seconds.\n",
            "process image 307\n",
            "Load Image: 0.005577 seconds.\n",
            "Inference time:  0.006148815155029297\n",
            "Prediction: 0.024687 seconds.\n",
            "process image 308\n",
            "Load Image: 0.009732 seconds.\n",
            "Inference time:  0.006186246871948242\n",
            "Prediction: 0.017482 seconds.\n",
            "process image 309\n",
            "Load Image: 0.007326 seconds.\n",
            "Inference time:  0.006485939025878906\n",
            "Prediction: 0.020666 seconds.\n",
            "process image 310\n",
            "Load Image: 0.005655 seconds.\n",
            "Inference time:  0.0059854984283447266\n",
            "Prediction: 0.022438 seconds.\n",
            "process image 311\n",
            "Load Image: 0.007445 seconds.\n",
            "Inference time:  0.008763313293457031\n",
            "Prediction: 0.019670 seconds.\n",
            "process image 312\n",
            "Load Image: 0.014589 seconds.\n",
            "Inference time:  0.006533384323120117\n",
            "Prediction: 0.018875 seconds.\n",
            "process image 313\n",
            "Load Image: 0.007359 seconds.\n",
            "Inference time:  0.006362438201904297\n",
            "Prediction: 0.024736 seconds.\n",
            "process image 314\n",
            "Load Image: 0.010067 seconds.\n",
            "Inference time:  0.009057283401489258\n",
            "Prediction: 0.025565 seconds.\n",
            "process image 315\n",
            "Load Image: 0.011327 seconds.\n",
            "Inference time:  0.0092010498046875\n",
            "Prediction: 0.027158 seconds.\n",
            "process image 316\n",
            "Load Image: 0.010516 seconds.\n",
            "Inference time:  0.007866859436035156\n",
            "Prediction: 0.027663 seconds.\n",
            "process image 317\n",
            "Load Image: 0.004636 seconds.\n",
            "Inference time:  0.009145975112915039\n",
            "Prediction: 0.025757 seconds.\n",
            "process image 318\n",
            "Load Image: 0.015699 seconds.\n",
            "Inference time:  0.007680416107177734\n",
            "Prediction: 0.024474 seconds.\n",
            "process image 319\n",
            "Load Image: 0.008556 seconds.\n",
            "Inference time:  0.008828163146972656\n",
            "Prediction: 0.022924 seconds.\n",
            "process image 320\n",
            "Load Image: 0.011195 seconds.\n",
            "Inference time:  0.0071184635162353516\n",
            "Prediction: 0.023009 seconds.\n",
            "process image 321\n",
            "Load Image: 0.006874 seconds.\n",
            "Inference time:  0.007440090179443359\n",
            "Prediction: 0.025589 seconds.\n",
            "process image 322\n",
            "Load Image: 0.003824 seconds.\n",
            "Inference time:  0.0074689388275146484\n",
            "Prediction: 0.025561 seconds.\n",
            "process image 323\n",
            "Load Image: 0.005532 seconds.\n",
            "Inference time:  0.006383657455444336\n",
            "Prediction: 0.020522 seconds.\n",
            "process image 324\n",
            "Load Image: 0.022445 seconds.\n",
            "Inference time:  0.009462118148803711\n",
            "Prediction: 0.039576 seconds.\n",
            "process image 325\n",
            "Load Image: 0.005763 seconds.\n",
            "Inference time:  0.0073528289794921875\n",
            "Prediction: 0.028150 seconds.\n",
            "process image 326\n",
            "Load Image: 0.006567 seconds.\n",
            "Inference time:  0.009953498840332031\n",
            "Prediction: 0.021680 seconds.\n",
            "process image 327\n",
            "Load Image: 0.004887 seconds.\n",
            "Inference time:  0.00991678237915039\n",
            "Prediction: 0.030055 seconds.\n",
            "process image 328\n",
            "Load Image: 0.005086 seconds.\n",
            "Inference time:  0.00652313232421875\n",
            "Prediction: 0.023538 seconds.\n",
            "process image 329\n",
            "Load Image: 0.008093 seconds.\n",
            "Inference time:  0.006865501403808594\n",
            "Prediction: 0.025970 seconds.\n",
            "process image 330\n",
            "Load Image: 0.010386 seconds.\n",
            "Inference time:  0.008539915084838867\n",
            "Prediction: 0.024628 seconds.\n",
            "process image 331\n",
            "Load Image: 0.012035 seconds.\n",
            "Inference time:  0.007661104202270508\n",
            "Prediction: 0.025605 seconds.\n",
            "process image 332\n",
            "Load Image: 0.008580 seconds.\n",
            "Inference time:  0.014783143997192383\n",
            "Prediction: 0.031178 seconds.\n",
            "process image 333\n",
            "Load Image: 0.007336 seconds.\n",
            "Inference time:  0.009188175201416016\n",
            "Prediction: 0.025131 seconds.\n",
            "process image 334\n",
            "Load Image: 0.010340 seconds.\n",
            "Inference time:  0.012977123260498047\n",
            "Prediction: 0.032171 seconds.\n",
            "process image 335\n",
            "Load Image: 0.008997 seconds.\n",
            "Inference time:  0.007383823394775391\n",
            "Prediction: 0.019726 seconds.\n",
            "process image 336\n",
            "Load Image: 0.006284 seconds.\n",
            "Inference time:  0.010311603546142578\n",
            "Prediction: 0.020475 seconds.\n",
            "process image 337\n",
            "Load Image: 0.004267 seconds.\n",
            "Inference time:  0.007884740829467773\n",
            "Prediction: 0.024933 seconds.\n",
            "process image 338\n",
            "Load Image: 0.005064 seconds.\n",
            "Inference time:  0.008501768112182617\n",
            "Prediction: 0.026888 seconds.\n",
            "process image 339\n",
            "Load Image: 0.007950 seconds.\n",
            "Inference time:  0.007786989212036133\n",
            "Prediction: 0.017960 seconds.\n",
            "process image 340\n",
            "Load Image: 0.006364 seconds.\n",
            "Inference time:  0.013869047164916992\n",
            "Prediction: 0.030748 seconds.\n",
            "process image 341\n",
            "Load Image: 0.005131 seconds.\n",
            "Inference time:  0.007850170135498047\n",
            "Prediction: 0.028405 seconds.\n",
            "process image 342\n",
            "Load Image: 0.005438 seconds.\n",
            "Inference time:  0.008570194244384766\n",
            "Prediction: 0.023812 seconds.\n",
            "process image 343\n",
            "Load Image: 0.009125 seconds.\n",
            "Inference time:  0.007494449615478516\n",
            "Prediction: 0.023007 seconds.\n",
            "process image 344\n",
            "Load Image: 0.013966 seconds.\n",
            "Inference time:  0.008366107940673828\n",
            "Prediction: 0.020459 seconds.\n",
            "process image 345\n",
            "Load Image: 0.015903 seconds.\n",
            "Inference time:  0.007071495056152344\n",
            "Prediction: 0.024064 seconds.\n",
            "process image 346\n",
            "Load Image: 0.010514 seconds.\n",
            "Inference time:  0.007176637649536133\n",
            "Prediction: 0.025100 seconds.\n",
            "process image 347\n",
            "Load Image: 0.004476 seconds.\n",
            "Inference time:  0.008011579513549805\n",
            "Prediction: 0.021443 seconds.\n",
            "process image 348\n",
            "Load Image: 0.003911 seconds.\n",
            "Inference time:  0.008824825286865234\n",
            "Prediction: 0.028184 seconds.\n",
            "process image 349\n",
            "Load Image: 0.013035 seconds.\n",
            "Inference time:  0.009464502334594727\n",
            "Prediction: 0.034678 seconds.\n",
            "process image 350\n",
            "Load Image: 0.006649 seconds.\n",
            "Inference time:  0.010549306869506836\n",
            "Prediction: 0.025033 seconds.\n",
            "process image 351\n",
            "Load Image: 0.005062 seconds.\n",
            "Inference time:  0.00861358642578125\n",
            "Prediction: 0.027063 seconds.\n",
            "process image 352\n",
            "Load Image: 0.009905 seconds.\n",
            "Inference time:  0.008782386779785156\n",
            "Prediction: 0.027251 seconds.\n",
            "process image 353\n",
            "Load Image: 0.009960 seconds.\n",
            "Inference time:  0.008203744888305664\n",
            "Prediction: 0.026024 seconds.\n",
            "process image 354\n",
            "Load Image: 0.011230 seconds.\n",
            "Inference time:  0.011559724807739258\n",
            "Prediction: 0.029848 seconds.\n",
            "process image 355\n",
            "Load Image: 0.018805 seconds.\n",
            "Inference time:  0.00858306884765625\n",
            "Prediction: 0.027113 seconds.\n",
            "process image 356\n",
            "Load Image: 0.009892 seconds.\n",
            "Inference time:  0.008172035217285156\n",
            "Prediction: 0.027884 seconds.\n",
            "process image 357\n",
            "Load Image: 0.007729 seconds.\n",
            "Inference time:  0.008037090301513672\n",
            "Prediction: 0.022121 seconds.\n",
            "process image 358\n",
            "Load Image: 0.005878 seconds.\n",
            "Inference time:  0.00944375991821289\n",
            "Prediction: 0.023141 seconds.\n",
            "process image 359\n",
            "Load Image: 0.011530 seconds.\n",
            "Inference time:  0.0078084468841552734\n",
            "Prediction: 0.020439 seconds.\n",
            "process image 360\n",
            "Load Image: 0.008882 seconds.\n",
            "Inference time:  0.007889747619628906\n",
            "Prediction: 0.018936 seconds.\n",
            "process image 361\n",
            "Load Image: 0.008065 seconds.\n",
            "Inference time:  0.007740497589111328\n",
            "Prediction: 0.022563 seconds.\n",
            "process image 362\n",
            "Load Image: 0.017628 seconds.\n",
            "Inference time:  0.007991552352905273\n",
            "Prediction: 0.019805 seconds.\n",
            "process image 363\n",
            "Load Image: 0.016926 seconds.\n",
            "Inference time:  0.008046865463256836\n",
            "Prediction: 0.020718 seconds.\n",
            "process image 364\n",
            "Load Image: 0.005775 seconds.\n",
            "Inference time:  0.008916378021240234\n",
            "Prediction: 0.030122 seconds.\n",
            "process image 365\n",
            "Load Image: 0.004953 seconds.\n",
            "Inference time:  0.008499622344970703\n",
            "Prediction: 0.037281 seconds.\n",
            "process image 366\n",
            "Load Image: 0.011736 seconds.\n",
            "Inference time:  0.008675575256347656\n",
            "Prediction: 0.037251 seconds.\n",
            "process image 367\n",
            "Load Image: 0.009358 seconds.\n",
            "Inference time:  0.007950544357299805\n",
            "Prediction: 0.022625 seconds.\n",
            "process image 368\n",
            "Load Image: 0.009580 seconds.\n",
            "Inference time:  0.010152101516723633\n",
            "Prediction: 0.027044 seconds.\n",
            "process image 369\n",
            "Load Image: 0.006004 seconds.\n",
            "Inference time:  0.007421970367431641\n",
            "Prediction: 0.020189 seconds.\n",
            "process image 370\n",
            "Load Image: 0.004424 seconds.\n",
            "Inference time:  0.007418394088745117\n",
            "Prediction: 0.030744 seconds.\n",
            "process image 371\n",
            "Load Image: 0.004935 seconds.\n",
            "Inference time:  0.007588386535644531\n",
            "Prediction: 0.022039 seconds.\n",
            "process image 372\n",
            "Load Image: 0.004965 seconds.\n",
            "Inference time:  0.01629352569580078\n",
            "Prediction: 0.031639 seconds.\n",
            "process image 373\n",
            "Load Image: 0.009650 seconds.\n",
            "Inference time:  0.0077245235443115234\n",
            "Prediction: 0.022611 seconds.\n",
            "process image 374\n",
            "Load Image: 0.006434 seconds.\n",
            "Inference time:  0.007817745208740234\n",
            "Prediction: 0.023328 seconds.\n",
            "process image 375\n",
            "Load Image: 0.010407 seconds.\n",
            "Inference time:  0.008652448654174805\n",
            "Prediction: 0.027741 seconds.\n",
            "process image 376\n",
            "Load Image: 0.019181 seconds.\n",
            "Inference time:  0.008143186569213867\n",
            "Prediction: 0.028714 seconds.\n",
            "process image 377\n",
            "Load Image: 0.005563 seconds.\n",
            "Inference time:  0.007640838623046875\n",
            "Prediction: 0.062747 seconds.\n",
            "process image 378\n",
            "Load Image: 0.025557 seconds.\n",
            "Inference time:  0.012344837188720703\n",
            "Prediction: 0.059684 seconds.\n",
            "process image 379\n",
            "Load Image: 0.046523 seconds.\n",
            "Inference time:  0.023899078369140625\n",
            "Prediction: 0.067946 seconds.\n",
            "process image 380\n",
            "Load Image: 0.017832 seconds.\n",
            "Inference time:  0.047139883041381836\n",
            "Prediction: 0.073808 seconds.\n",
            "process image 381\n",
            "Load Image: 0.051950 seconds.\n",
            "Inference time:  0.027926921844482422\n",
            "Prediction: 0.080724 seconds.\n",
            "process image 382\n",
            "Load Image: 0.015156 seconds.\n",
            "Inference time:  0.012167692184448242\n",
            "Prediction: 0.053064 seconds.\n",
            "process image 383\n",
            "Load Image: 0.015570 seconds.\n",
            "Inference time:  0.013334035873413086\n",
            "Prediction: 0.073573 seconds.\n",
            "process image 384\n",
            "Load Image: 0.025949 seconds.\n",
            "Inference time:  0.01895308494567871\n",
            "Prediction: 0.066681 seconds.\n",
            "process image 385\n",
            "Load Image: 0.022450 seconds.\n",
            "Inference time:  0.014148473739624023\n",
            "Prediction: 0.061405 seconds.\n",
            "process image 386\n",
            "Load Image: 0.032589 seconds.\n",
            "Inference time:  0.009265661239624023\n",
            "Prediction: 0.031004 seconds.\n",
            "process image 387\n",
            "Load Image: 0.008156 seconds.\n",
            "Inference time:  0.011025428771972656\n",
            "Prediction: 0.026556 seconds.\n",
            "process image 388\n",
            "Load Image: 0.005536 seconds.\n",
            "Inference time:  0.008697748184204102\n",
            "Prediction: 0.026212 seconds.\n",
            "process image 389\n",
            "Load Image: 0.010464 seconds.\n",
            "Inference time:  0.008893013000488281\n",
            "Prediction: 0.022511 seconds.\n",
            "process image 390\n",
            "Load Image: 0.006306 seconds.\n",
            "Inference time:  0.009032011032104492\n",
            "Prediction: 0.023592 seconds.\n",
            "process image 391\n",
            "Load Image: 0.008424 seconds.\n",
            "Inference time:  0.008590221405029297\n",
            "Prediction: 0.026916 seconds.\n",
            "process image 392\n",
            "Load Image: 0.014249 seconds.\n",
            "Inference time:  0.009228944778442383\n",
            "Prediction: 0.036078 seconds.\n",
            "process image 393\n",
            "Load Image: 0.016876 seconds.\n",
            "Inference time:  0.013251543045043945\n",
            "Prediction: 0.041106 seconds.\n",
            "process image 394\n",
            "Load Image: 0.008465 seconds.\n",
            "Inference time:  0.009601354598999023\n",
            "Prediction: 0.028152 seconds.\n",
            "process image 395\n",
            "Load Image: 0.006762 seconds.\n",
            "Inference time:  0.03494977951049805\n",
            "Prediction: 0.081332 seconds.\n",
            "process image 396\n",
            "Load Image: 0.010047 seconds.\n",
            "Inference time:  0.025326967239379883\n",
            "Prediction: 0.078855 seconds.\n",
            "process image 397\n",
            "Load Image: 0.024199 seconds.\n",
            "Inference time:  0.023316144943237305\n",
            "Prediction: 0.064926 seconds.\n",
            "process image 398\n",
            "Load Image: 0.013772 seconds.\n",
            "Inference time:  0.029042720794677734\n",
            "Prediction: 0.064643 seconds.\n",
            "process image 399\n",
            "Load Image: 0.035130 seconds.\n",
            "Inference time:  0.02039504051208496\n",
            "Prediction: 0.082096 seconds.\n",
            "process image 400\n",
            "Load Image: 0.018798 seconds.\n",
            "Inference time:  0.02002859115600586\n",
            "Prediction: 0.079747 seconds.\n",
            "process image 401\n",
            "Load Image: 0.020639 seconds.\n",
            "Inference time:  0.015010833740234375\n",
            "Prediction: 0.047309 seconds.\n",
            "process image 402\n",
            "Load Image: 0.025285 seconds.\n",
            "Inference time:  0.011738061904907227\n",
            "Prediction: 0.041173 seconds.\n",
            "process image 403\n",
            "Load Image: 0.012129 seconds.\n",
            "Inference time:  0.00882577896118164\n",
            "Prediction: 0.027997 seconds.\n",
            "process image 404\n",
            "Load Image: 0.007676 seconds.\n",
            "Inference time:  0.034745216369628906\n",
            "Prediction: 0.067405 seconds.\n",
            "process image 405\n",
            "Load Image: 0.014981 seconds.\n",
            "Inference time:  0.015625715255737305\n",
            "Prediction: 0.047799 seconds.\n",
            "process image 406\n",
            "Load Image: 0.054975 seconds.\n",
            "Inference time:  0.08352065086364746\n",
            "Prediction: 0.171659 seconds.\n",
            "process image 407\n",
            "Load Image: 0.012434 seconds.\n",
            "Inference time:  0.011934518814086914\n",
            "Prediction: 0.035428 seconds.\n",
            "process image 408\n",
            "Load Image: 0.008790 seconds.\n",
            "Inference time:  0.009759664535522461\n",
            "Prediction: 0.027799 seconds.\n",
            "process image 409\n",
            "Load Image: 0.007872 seconds.\n",
            "Inference time:  0.008721351623535156\n",
            "Prediction: 0.020629 seconds.\n",
            "process image 410\n",
            "Load Image: 0.007962 seconds.\n",
            "Inference time:  0.00818943977355957\n",
            "Prediction: 0.025815 seconds.\n",
            "process image 411\n",
            "Load Image: 0.016691 seconds.\n",
            "Inference time:  0.009192228317260742\n",
            "Prediction: 0.026959 seconds.\n",
            "process image 412\n",
            "Load Image: 0.009034 seconds.\n",
            "Inference time:  0.008442401885986328\n",
            "Prediction: 0.024876 seconds.\n",
            "process image 413\n",
            "Load Image: 0.005771 seconds.\n",
            "Inference time:  0.008332967758178711\n",
            "Prediction: 0.029578 seconds.\n",
            "process image 414\n",
            "Load Image: 0.007649 seconds.\n",
            "Inference time:  0.008341312408447266\n",
            "Prediction: 0.025556 seconds.\n",
            "process image 415\n",
            "Load Image: 0.011688 seconds.\n",
            "Inference time:  0.008292675018310547\n",
            "Prediction: 0.026242 seconds.\n",
            "process image 416\n",
            "Load Image: 0.008152 seconds.\n",
            "Inference time:  0.009011507034301758\n",
            "Prediction: 0.028077 seconds.\n",
            "process image 417\n",
            "Load Image: 0.021608 seconds.\n",
            "Inference time:  0.018057584762573242\n",
            "Prediction: 0.057309 seconds.\n",
            "process image 418\n",
            "Load Image: 0.017818 seconds.\n",
            "Inference time:  0.012708425521850586\n",
            "Prediction: 0.045740 seconds.\n",
            "process image 419\n",
            "Load Image: 0.020561 seconds.\n",
            "Inference time:  0.014165401458740234\n",
            "Prediction: 0.034618 seconds.\n",
            "process image 420\n",
            "Load Image: 0.012233 seconds.\n",
            "Inference time:  0.009025812149047852\n",
            "Prediction: 0.025787 seconds.\n",
            "process image 421\n",
            "Load Image: 0.004490 seconds.\n",
            "Inference time:  0.008715391159057617\n",
            "Prediction: 0.027351 seconds.\n",
            "process image 422\n",
            "Load Image: 0.015175 seconds.\n",
            "Inference time:  0.01001739501953125\n",
            "Prediction: 0.027545 seconds.\n",
            "process image 423\n",
            "Load Image: 0.006459 seconds.\n",
            "Inference time:  0.00841832160949707\n",
            "Prediction: 0.032301 seconds.\n",
            "process image 424\n",
            "Load Image: 0.026086 seconds.\n",
            "Inference time:  0.008852720260620117\n",
            "Prediction: 0.040813 seconds.\n",
            "process image 425\n",
            "Load Image: 0.008955 seconds.\n",
            "Inference time:  0.009454488754272461\n",
            "Prediction: 0.031151 seconds.\n",
            "process image 426\n",
            "Load Image: 0.009100 seconds.\n",
            "Inference time:  0.008929252624511719\n",
            "Prediction: 0.035388 seconds.\n",
            "process image 427\n",
            "Load Image: 0.015287 seconds.\n",
            "Inference time:  0.00850820541381836\n",
            "Prediction: 0.025509 seconds.\n",
            "process image 428\n",
            "Load Image: 0.010071 seconds.\n",
            "Inference time:  0.008764505386352539\n",
            "Prediction: 0.022185 seconds.\n",
            "process image 429\n",
            "Load Image: 0.006225 seconds.\n",
            "Inference time:  0.009817361831665039\n",
            "Prediction: 0.024452 seconds.\n",
            "\n",
            "\n",
            "Average Precision Per-class:\n",
            "Aircraft: 0.2761467181108383\n",
            "\n",
            "Average Precision Across All Classes:0.2761467181108383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### results for original model ###\n",
        "!python pytorch-ssd/eval_ssd.py \\\n",
        "    --net mb1-ssd \\\n",
        "    --trained_model /content/pytorch-ssd/models/mobilenet-v1-ssd-mp-0_675_pretrain.pth \\\n",
        "    --dataset_type open_images \\\n",
        "    --dataset /content/open_images_data/test \\\n",
        "    --label_file /content/open_images_data/open-images-model-labels.txt \\\n",
        "    --use_cuda True \\\n",
        "    --iou_threshold 0.5 \\\n",
        "    --eval_dir /content/pytorch-ssd/eval_results\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yDRMqN8rIpR",
        "outputId": "12850b00-1530-45d4-b3d2-653109e72738"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RuntimeError: module was compiled against NumPy C-API version 0x10 (NumPy 1.23) but the running NumPy has C-API version 0xf. Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem.\n",
            "/content/pytorch-ssd/eval_ssd.py:69: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  all_gt_boxes[class_index][image_id] = torch.tensor(all_gt_boxes[class_index][image_id])\n",
            "/content/pytorch-ssd/vision/ssd/ssd.py:135: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(model, map_location=lambda storage, loc: storage))\n",
            "It took 0.05184030532836914 seconds to load the model.\n",
            "process image 0\n",
            "Load Image: 0.007632 seconds.\n",
            "Inference time:  0.3221585750579834\n",
            "Prediction: 0.338133 seconds.\n",
            "process image 1\n",
            "Load Image: 0.005401 seconds.\n",
            "Inference time:  0.005572319030761719\n",
            "Prediction: 0.019900 seconds.\n",
            "process image 2\n",
            "Load Image: 0.004165 seconds.\n",
            "Inference time:  0.0050373077392578125\n",
            "Prediction: 0.020958 seconds.\n",
            "process image 3\n",
            "Load Image: 0.007062 seconds.\n",
            "Inference time:  0.005200862884521484\n",
            "Prediction: 0.017950 seconds.\n",
            "process image 4\n",
            "Load Image: 0.007275 seconds.\n",
            "Inference time:  0.006371498107910156\n",
            "Prediction: 0.016728 seconds.\n",
            "process image 5\n",
            "Load Image: 0.004481 seconds.\n",
            "Inference time:  0.0051593780517578125\n",
            "Prediction: 0.015993 seconds.\n",
            "process image 6\n",
            "Load Image: 0.006518 seconds.\n",
            "Inference time:  0.005158662796020508\n",
            "Prediction: 0.018254 seconds.\n",
            "process image 7\n",
            "Load Image: 0.004721 seconds.\n",
            "Inference time:  0.005036115646362305\n",
            "Prediction: 0.021569 seconds.\n",
            "process image 8\n",
            "Load Image: 0.011075 seconds.\n",
            "Inference time:  0.005266904830932617\n",
            "Prediction: 0.016467 seconds.\n",
            "process image 9\n",
            "Load Image: 0.013994 seconds.\n",
            "Inference time:  0.005216121673583984\n",
            "Prediction: 0.018957 seconds.\n",
            "process image 10\n",
            "Load Image: 0.009894 seconds.\n",
            "Inference time:  0.004843711853027344\n",
            "Prediction: 0.023628 seconds.\n",
            "process image 11\n",
            "Load Image: 0.003476 seconds.\n",
            "Inference time:  0.004806041717529297\n",
            "Prediction: 0.023861 seconds.\n",
            "process image 12\n",
            "Load Image: 0.007736 seconds.\n",
            "Inference time:  0.00496363639831543\n",
            "Prediction: 0.017100 seconds.\n",
            "process image 13\n",
            "Load Image: 0.008578 seconds.\n",
            "Inference time:  0.0047283172607421875\n",
            "Prediction: 0.016291 seconds.\n",
            "process image 14\n",
            "Load Image: 0.003318 seconds.\n",
            "Inference time:  0.004848480224609375\n",
            "Prediction: 0.021426 seconds.\n",
            "process image 15\n",
            "Load Image: 0.009255 seconds.\n",
            "Inference time:  0.004832744598388672\n",
            "Prediction: 0.025018 seconds.\n",
            "process image 16\n",
            "Load Image: 0.003485 seconds.\n",
            "Inference time:  0.004721641540527344\n",
            "Prediction: 0.016943 seconds.\n",
            "process image 17\n",
            "Load Image: 0.004599 seconds.\n",
            "Inference time:  0.006890058517456055\n",
            "Prediction: 0.021758 seconds.\n",
            "process image 18\n",
            "Load Image: 0.005329 seconds.\n",
            "Inference time:  0.004678249359130859\n",
            "Prediction: 0.019797 seconds.\n",
            "process image 19\n",
            "Load Image: 0.005790 seconds.\n",
            "Inference time:  0.004916667938232422\n",
            "Prediction: 0.018111 seconds.\n",
            "process image 20\n",
            "Load Image: 0.004236 seconds.\n",
            "Inference time:  0.004694700241088867\n",
            "Prediction: 0.019668 seconds.\n",
            "process image 21\n",
            "Load Image: 0.004838 seconds.\n",
            "Inference time:  0.004688739776611328\n",
            "Prediction: 0.016469 seconds.\n",
            "process image 22\n",
            "Load Image: 0.010977 seconds.\n",
            "Inference time:  0.005211830139160156\n",
            "Prediction: 0.020209 seconds.\n",
            "process image 23\n",
            "Load Image: 0.003525 seconds.\n",
            "Inference time:  0.008798837661743164\n",
            "Prediction: 0.026613 seconds.\n",
            "process image 24\n",
            "Load Image: 0.005902 seconds.\n",
            "Inference time:  0.005297422409057617\n",
            "Prediction: 0.020353 seconds.\n",
            "process image 25\n",
            "Load Image: 0.004552 seconds.\n",
            "Inference time:  0.005329608917236328\n",
            "Prediction: 0.017723 seconds.\n",
            "process image 26\n",
            "Load Image: 0.014410 seconds.\n",
            "Inference time:  0.004987478256225586\n",
            "Prediction: 0.015986 seconds.\n",
            "process image 27\n",
            "Load Image: 0.007907 seconds.\n",
            "Inference time:  0.005097150802612305\n",
            "Prediction: 0.018878 seconds.\n",
            "process image 28\n",
            "Load Image: 0.004050 seconds.\n",
            "Inference time:  0.005011320114135742\n",
            "Prediction: 0.016655 seconds.\n",
            "process image 29\n",
            "Load Image: 0.009484 seconds.\n",
            "Inference time:  0.005395174026489258\n",
            "Prediction: 0.018847 seconds.\n",
            "process image 30\n",
            "Load Image: 0.004260 seconds.\n",
            "Inference time:  0.00515437126159668\n",
            "Prediction: 0.025464 seconds.\n",
            "process image 31\n",
            "Load Image: 0.005978 seconds.\n",
            "Inference time:  0.005364179611206055\n",
            "Prediction: 0.022568 seconds.\n",
            "process image 32\n",
            "Load Image: 0.006763 seconds.\n",
            "Inference time:  0.005078792572021484\n",
            "Prediction: 0.019661 seconds.\n",
            "process image 33\n",
            "Load Image: 0.004089 seconds.\n",
            "Inference time:  0.005053520202636719\n",
            "Prediction: 0.019639 seconds.\n",
            "process image 34\n",
            "Load Image: 0.009177 seconds.\n",
            "Inference time:  0.008752107620239258\n",
            "Prediction: 0.021437 seconds.\n",
            "process image 35\n",
            "Load Image: 0.007119 seconds.\n",
            "Inference time:  0.0052642822265625\n",
            "Prediction: 0.021201 seconds.\n",
            "process image 36\n",
            "Load Image: 0.010480 seconds.\n",
            "Inference time:  0.004850864410400391\n",
            "Prediction: 0.018778 seconds.\n",
            "process image 37\n",
            "Load Image: 0.008605 seconds.\n",
            "Inference time:  0.008713960647583008\n",
            "Prediction: 0.026081 seconds.\n",
            "process image 38\n",
            "Load Image: 0.004295 seconds.\n",
            "Inference time:  0.005129575729370117\n",
            "Prediction: 0.019375 seconds.\n",
            "process image 39\n",
            "Load Image: 0.004453 seconds.\n",
            "Inference time:  0.005134105682373047\n",
            "Prediction: 0.017702 seconds.\n",
            "process image 40\n",
            "Load Image: 0.005648 seconds.\n",
            "Inference time:  0.0047893524169921875\n",
            "Prediction: 0.020123 seconds.\n",
            "process image 41\n",
            "Load Image: 0.007247 seconds.\n",
            "Inference time:  0.004800558090209961\n",
            "Prediction: 0.020768 seconds.\n",
            "process image 42\n",
            "Load Image: 0.010085 seconds.\n",
            "Inference time:  0.004861593246459961\n",
            "Prediction: 0.020160 seconds.\n",
            "process image 43\n",
            "Load Image: 0.005567 seconds.\n",
            "Inference time:  0.005227565765380859\n",
            "Prediction: 0.021377 seconds.\n",
            "process image 44\n",
            "Load Image: 0.007715 seconds.\n",
            "Inference time:  0.004829883575439453\n",
            "Prediction: 0.018568 seconds.\n",
            "process image 45\n",
            "Load Image: 0.004111 seconds.\n",
            "Inference time:  0.00539708137512207\n",
            "Prediction: 0.024656 seconds.\n",
            "process image 46\n",
            "Load Image: 0.006581 seconds.\n",
            "Inference time:  0.005524873733520508\n",
            "Prediction: 0.015960 seconds.\n",
            "process image 47\n",
            "Load Image: 0.004311 seconds.\n",
            "Inference time:  0.004737377166748047\n",
            "Prediction: 0.022083 seconds.\n",
            "process image 48\n",
            "Load Image: 0.006808 seconds.\n",
            "Inference time:  0.0048601627349853516\n",
            "Prediction: 0.019848 seconds.\n",
            "process image 49\n",
            "Load Image: 0.002968 seconds.\n",
            "Inference time:  0.004784107208251953\n",
            "Prediction: 0.020009 seconds.\n",
            "process image 50\n",
            "Load Image: 0.005271 seconds.\n",
            "Inference time:  0.005449771881103516\n",
            "Prediction: 0.019103 seconds.\n",
            "process image 51\n",
            "Load Image: 0.007612 seconds.\n",
            "Inference time:  0.005282878875732422\n",
            "Prediction: 0.019526 seconds.\n",
            "process image 52\n",
            "Load Image: 0.006671 seconds.\n",
            "Inference time:  0.00516057014465332\n",
            "Prediction: 0.020567 seconds.\n",
            "process image 53\n",
            "Load Image: 0.004825 seconds.\n",
            "Inference time:  0.005524158477783203\n",
            "Prediction: 0.018654 seconds.\n",
            "process image 54\n",
            "Load Image: 0.005080 seconds.\n",
            "Inference time:  0.004984378814697266\n",
            "Prediction: 0.021421 seconds.\n",
            "process image 55\n",
            "Load Image: 0.010466 seconds.\n",
            "Inference time:  0.005248069763183594\n",
            "Prediction: 0.017045 seconds.\n",
            "process image 56\n",
            "Load Image: 0.006797 seconds.\n",
            "Inference time:  0.0049228668212890625\n",
            "Prediction: 0.018133 seconds.\n",
            "process image 57\n",
            "Load Image: 0.003408 seconds.\n",
            "Inference time:  0.004925727844238281\n",
            "Prediction: 0.019992 seconds.\n",
            "process image 58\n",
            "Load Image: 0.006140 seconds.\n",
            "Inference time:  0.0051784515380859375\n",
            "Prediction: 0.021803 seconds.\n",
            "process image 59\n",
            "Load Image: 0.003449 seconds.\n",
            "Inference time:  0.00505828857421875\n",
            "Prediction: 0.018215 seconds.\n",
            "process image 60\n",
            "Load Image: 0.004693 seconds.\n",
            "Inference time:  0.0049593448638916016\n",
            "Prediction: 0.021231 seconds.\n",
            "process image 61\n",
            "Load Image: 0.003967 seconds.\n",
            "Inference time:  0.005184650421142578\n",
            "Prediction: 0.021666 seconds.\n",
            "process image 62\n",
            "Load Image: 0.005889 seconds.\n",
            "Inference time:  0.005360126495361328\n",
            "Prediction: 0.021472 seconds.\n",
            "process image 63\n",
            "Load Image: 0.006021 seconds.\n",
            "Inference time:  0.005308628082275391\n",
            "Prediction: 0.017508 seconds.\n",
            "process image 64\n",
            "Load Image: 0.009725 seconds.\n",
            "Inference time:  0.004930019378662109\n",
            "Prediction: 0.026410 seconds.\n",
            "process image 65\n",
            "Load Image: 0.005878 seconds.\n",
            "Inference time:  0.005222797393798828\n",
            "Prediction: 0.020617 seconds.\n",
            "process image 66\n",
            "Load Image: 0.004638 seconds.\n",
            "Inference time:  0.0052280426025390625\n",
            "Prediction: 0.018385 seconds.\n",
            "process image 67\n",
            "Load Image: 0.008325 seconds.\n",
            "Inference time:  0.004800319671630859\n",
            "Prediction: 0.020111 seconds.\n",
            "process image 68\n",
            "Load Image: 0.007576 seconds.\n",
            "Inference time:  0.0051727294921875\n",
            "Prediction: 0.019962 seconds.\n",
            "process image 69\n",
            "Load Image: 0.004543 seconds.\n",
            "Inference time:  0.004710674285888672\n",
            "Prediction: 0.017581 seconds.\n",
            "process image 70\n",
            "Load Image: 0.003563 seconds.\n",
            "Inference time:  0.0047740936279296875\n",
            "Prediction: 0.020104 seconds.\n",
            "process image 71\n",
            "Load Image: 0.012069 seconds.\n",
            "Inference time:  0.004749298095703125\n",
            "Prediction: 0.020481 seconds.\n",
            "process image 72\n",
            "Load Image: 0.007406 seconds.\n",
            "Inference time:  0.006310462951660156\n",
            "Prediction: 0.020705 seconds.\n",
            "process image 73\n",
            "Load Image: 0.004942 seconds.\n",
            "Inference time:  0.004850625991821289\n",
            "Prediction: 0.022048 seconds.\n",
            "process image 74\n",
            "Load Image: 0.014307 seconds.\n",
            "Inference time:  0.005428314208984375\n",
            "Prediction: 0.020341 seconds.\n",
            "process image 75\n",
            "Load Image: 0.004953 seconds.\n",
            "Inference time:  0.0054280757904052734\n",
            "Prediction: 0.027317 seconds.\n",
            "process image 76\n",
            "Load Image: 0.012534 seconds.\n",
            "Inference time:  0.005213260650634766\n",
            "Prediction: 0.023687 seconds.\n",
            "process image 77\n",
            "Load Image: 0.004361 seconds.\n",
            "Inference time:  0.005384922027587891\n",
            "Prediction: 0.023760 seconds.\n",
            "process image 78\n",
            "Load Image: 0.005007 seconds.\n",
            "Inference time:  0.006438016891479492\n",
            "Prediction: 0.021778 seconds.\n",
            "process image 79\n",
            "Load Image: 0.004542 seconds.\n",
            "Inference time:  0.005086183547973633\n",
            "Prediction: 0.022111 seconds.\n",
            "process image 80\n",
            "Load Image: 0.008273 seconds.\n",
            "Inference time:  0.0054187774658203125\n",
            "Prediction: 0.019961 seconds.\n",
            "process image 81\n",
            "Load Image: 0.007162 seconds.\n",
            "Inference time:  0.0053141117095947266\n",
            "Prediction: 0.018082 seconds.\n",
            "process image 82\n",
            "Load Image: 0.004221 seconds.\n",
            "Inference time:  0.005072355270385742\n",
            "Prediction: 0.024743 seconds.\n",
            "process image 83\n",
            "Load Image: 0.006996 seconds.\n",
            "Inference time:  0.005293846130371094\n",
            "Prediction: 0.016975 seconds.\n",
            "process image 84\n",
            "Load Image: 0.006290 seconds.\n",
            "Inference time:  0.0051610469818115234\n",
            "Prediction: 0.017242 seconds.\n",
            "process image 85\n",
            "Load Image: 0.002905 seconds.\n",
            "Inference time:  0.005146026611328125\n",
            "Prediction: 0.017639 seconds.\n",
            "process image 86\n",
            "Load Image: 0.007455 seconds.\n",
            "Inference time:  0.0051457881927490234\n",
            "Prediction: 0.018571 seconds.\n",
            "process image 87\n",
            "Load Image: 0.005039 seconds.\n",
            "Inference time:  0.004954814910888672\n",
            "Prediction: 0.021888 seconds.\n",
            "process image 88\n",
            "Load Image: 0.010495 seconds.\n",
            "Inference time:  0.005057334899902344\n",
            "Prediction: 0.022036 seconds.\n",
            "process image 89\n",
            "Load Image: 0.005891 seconds.\n",
            "Inference time:  0.004954099655151367\n",
            "Prediction: 0.019440 seconds.\n",
            "process image 90\n",
            "Load Image: 0.003962 seconds.\n",
            "Inference time:  0.005520820617675781\n",
            "Prediction: 0.020586 seconds.\n",
            "process image 91\n",
            "Load Image: 0.004251 seconds.\n",
            "Inference time:  0.0058727264404296875\n",
            "Prediction: 0.020074 seconds.\n",
            "process image 92\n",
            "Load Image: 0.007839 seconds.\n",
            "Inference time:  0.005082368850708008\n",
            "Prediction: 0.017339 seconds.\n",
            "process image 93\n",
            "Load Image: 0.009269 seconds.\n",
            "Inference time:  0.0048675537109375\n",
            "Prediction: 0.019917 seconds.\n",
            "process image 94\n",
            "Load Image: 0.009834 seconds.\n",
            "Inference time:  0.008566141128540039\n",
            "Prediction: 0.032101 seconds.\n",
            "process image 95\n",
            "Load Image: 0.008974 seconds.\n",
            "Inference time:  0.00878596305847168\n",
            "Prediction: 0.025108 seconds.\n",
            "process image 96\n",
            "Load Image: 0.013390 seconds.\n",
            "Inference time:  0.008832216262817383\n",
            "Prediction: 0.027551 seconds.\n",
            "process image 97\n",
            "Load Image: 0.006548 seconds.\n",
            "Inference time:  0.006472349166870117\n",
            "Prediction: 0.030168 seconds.\n",
            "process image 98\n",
            "Load Image: 0.007963 seconds.\n",
            "Inference time:  0.0068819522857666016\n",
            "Prediction: 0.024306 seconds.\n",
            "process image 99\n",
            "Load Image: 0.013643 seconds.\n",
            "Inference time:  0.008760690689086914\n",
            "Prediction: 0.032920 seconds.\n",
            "process image 100\n",
            "Load Image: 0.005840 seconds.\n",
            "Inference time:  0.006299257278442383\n",
            "Prediction: 0.022074 seconds.\n",
            "process image 101\n",
            "Load Image: 0.006993 seconds.\n",
            "Inference time:  0.006537437438964844\n",
            "Prediction: 0.033277 seconds.\n",
            "process image 102\n",
            "Load Image: 0.010146 seconds.\n",
            "Inference time:  0.008074760437011719\n",
            "Prediction: 0.026116 seconds.\n",
            "process image 103\n",
            "Load Image: 0.014530 seconds.\n",
            "Inference time:  0.006348133087158203\n",
            "Prediction: 0.031567 seconds.\n",
            "process image 104\n",
            "Load Image: 0.005967 seconds.\n",
            "Inference time:  0.008954763412475586\n",
            "Prediction: 0.033627 seconds.\n",
            "process image 105\n",
            "Load Image: 0.010290 seconds.\n",
            "Inference time:  0.006448268890380859\n",
            "Prediction: 0.023787 seconds.\n",
            "process image 106\n",
            "Load Image: 0.015933 seconds.\n",
            "Inference time:  0.006577968597412109\n",
            "Prediction: 0.019489 seconds.\n",
            "process image 107\n",
            "Load Image: 0.006335 seconds.\n",
            "Inference time:  0.0073490142822265625\n",
            "Prediction: 0.032047 seconds.\n",
            "process image 108\n",
            "Load Image: 0.016877 seconds.\n",
            "Inference time:  0.008410215377807617\n",
            "Prediction: 0.029577 seconds.\n",
            "process image 109\n",
            "Load Image: 0.005567 seconds.\n",
            "Inference time:  0.006853342056274414\n",
            "Prediction: 0.032113 seconds.\n",
            "process image 110\n",
            "Load Image: 0.006801 seconds.\n",
            "Inference time:  0.006648540496826172\n",
            "Prediction: 0.021290 seconds.\n",
            "process image 111\n",
            "Load Image: 0.009601 seconds.\n",
            "Inference time:  0.006406068801879883\n",
            "Prediction: 0.023175 seconds.\n",
            "process image 112\n",
            "Load Image: 0.005574 seconds.\n",
            "Inference time:  0.006693601608276367\n",
            "Prediction: 0.028482 seconds.\n",
            "process image 113\n",
            "Load Image: 0.008641 seconds.\n",
            "Inference time:  0.006450176239013672\n",
            "Prediction: 0.023528 seconds.\n",
            "process image 114\n",
            "Load Image: 0.015104 seconds.\n",
            "Inference time:  0.006404399871826172\n",
            "Prediction: 0.022867 seconds.\n",
            "process image 115\n",
            "Load Image: 0.007460 seconds.\n",
            "Inference time:  0.010384798049926758\n",
            "Prediction: 0.032437 seconds.\n",
            "process image 116\n",
            "Load Image: 0.009249 seconds.\n",
            "Inference time:  0.006260395050048828\n",
            "Prediction: 0.027272 seconds.\n",
            "process image 117\n",
            "Load Image: 0.017881 seconds.\n",
            "Inference time:  0.0060198307037353516\n",
            "Prediction: 0.022421 seconds.\n",
            "process image 118\n",
            "Load Image: 0.004609 seconds.\n",
            "Inference time:  0.010916471481323242\n",
            "Prediction: 0.037185 seconds.\n",
            "process image 119\n",
            "Load Image: 0.006044 seconds.\n",
            "Inference time:  0.006737232208251953\n",
            "Prediction: 0.023902 seconds.\n",
            "process image 120\n",
            "Load Image: 0.006467 seconds.\n",
            "Inference time:  0.00646209716796875\n",
            "Prediction: 0.023939 seconds.\n",
            "process image 121\n",
            "Load Image: 0.014956 seconds.\n",
            "Inference time:  0.006421804428100586\n",
            "Prediction: 0.029364 seconds.\n",
            "process image 122\n",
            "Load Image: 0.012031 seconds.\n",
            "Inference time:  0.0066335201263427734\n",
            "Prediction: 0.025656 seconds.\n",
            "process image 123\n",
            "Load Image: 0.010571 seconds.\n",
            "Inference time:  0.006584882736206055\n",
            "Prediction: 0.025847 seconds.\n",
            "process image 124\n",
            "Load Image: 0.007428 seconds.\n",
            "Inference time:  0.00662541389465332\n",
            "Prediction: 0.026989 seconds.\n",
            "process image 125\n",
            "Load Image: 0.006953 seconds.\n",
            "Inference time:  0.0066280364990234375\n",
            "Prediction: 0.021798 seconds.\n",
            "process image 126\n",
            "Load Image: 0.004763 seconds.\n",
            "Inference time:  0.006368875503540039\n",
            "Prediction: 0.035637 seconds.\n",
            "process image 127\n",
            "Load Image: 0.005848 seconds.\n",
            "Inference time:  0.006376743316650391\n",
            "Prediction: 0.028548 seconds.\n",
            "process image 128\n",
            "Load Image: 0.012213 seconds.\n",
            "Inference time:  0.009361982345581055\n",
            "Prediction: 0.033889 seconds.\n",
            "process image 129\n",
            "Load Image: 0.011362 seconds.\n",
            "Inference time:  0.008025407791137695\n",
            "Prediction: 0.034784 seconds.\n",
            "process image 130\n",
            "Load Image: 0.010284 seconds.\n",
            "Inference time:  0.007820367813110352\n",
            "Prediction: 0.032691 seconds.\n",
            "process image 131\n",
            "Load Image: 0.005646 seconds.\n",
            "Inference time:  0.008227825164794922\n",
            "Prediction: 0.031190 seconds.\n",
            "process image 132\n",
            "Load Image: 0.004263 seconds.\n",
            "Inference time:  0.009330272674560547\n",
            "Prediction: 0.026624 seconds.\n",
            "process image 133\n",
            "Load Image: 0.006195 seconds.\n",
            "Inference time:  0.0067861080169677734\n",
            "Prediction: 0.026205 seconds.\n",
            "process image 134\n",
            "Load Image: 0.021507 seconds.\n",
            "Inference time:  0.0069122314453125\n",
            "Prediction: 0.021848 seconds.\n",
            "process image 135\n",
            "Load Image: 0.003909 seconds.\n",
            "Inference time:  0.006270885467529297\n",
            "Prediction: 0.023003 seconds.\n",
            "process image 136\n",
            "Load Image: 0.012280 seconds.\n",
            "Inference time:  0.009671926498413086\n",
            "Prediction: 0.034593 seconds.\n",
            "process image 137\n",
            "Load Image: 0.007441 seconds.\n",
            "Inference time:  0.00852346420288086\n",
            "Prediction: 0.027902 seconds.\n",
            "process image 138\n",
            "Load Image: 0.007454 seconds.\n",
            "Inference time:  0.008999347686767578\n",
            "Prediction: 0.035154 seconds.\n",
            "process image 139\n",
            "Load Image: 0.010797 seconds.\n",
            "Inference time:  0.009382486343383789\n",
            "Prediction: 0.033761 seconds.\n",
            "process image 140\n",
            "Load Image: 0.007412 seconds.\n",
            "Inference time:  0.007316112518310547\n",
            "Prediction: 0.031285 seconds.\n",
            "process image 141\n",
            "Load Image: 0.007769 seconds.\n",
            "Inference time:  0.007799386978149414\n",
            "Prediction: 0.025305 seconds.\n",
            "process image 142\n",
            "Load Image: 0.005245 seconds.\n",
            "Inference time:  0.009267330169677734\n",
            "Prediction: 0.028625 seconds.\n",
            "process image 143\n",
            "Load Image: 0.013320 seconds.\n",
            "Inference time:  0.009226083755493164\n",
            "Prediction: 0.027456 seconds.\n",
            "process image 144\n",
            "Load Image: 0.004568 seconds.\n",
            "Inference time:  0.009008169174194336\n",
            "Prediction: 0.033958 seconds.\n",
            "process image 145\n",
            "Load Image: 0.005828 seconds.\n",
            "Inference time:  0.009396791458129883\n",
            "Prediction: 0.039522 seconds.\n",
            "process image 146\n",
            "Load Image: 0.002871 seconds.\n",
            "Inference time:  0.007326602935791016\n",
            "Prediction: 0.029826 seconds.\n",
            "process image 147\n",
            "Load Image: 0.015192 seconds.\n",
            "Inference time:  0.0075185298919677734\n",
            "Prediction: 0.030710 seconds.\n",
            "process image 148\n",
            "Load Image: 0.006710 seconds.\n",
            "Inference time:  0.008059978485107422\n",
            "Prediction: 0.028125 seconds.\n",
            "process image 149\n",
            "Load Image: 0.006866 seconds.\n",
            "Inference time:  0.007863759994506836\n",
            "Prediction: 0.036299 seconds.\n",
            "process image 150\n",
            "Load Image: 0.016649 seconds.\n",
            "Inference time:  0.008136510848999023\n",
            "Prediction: 0.023762 seconds.\n",
            "process image 151\n",
            "Load Image: 0.010874 seconds.\n",
            "Inference time:  0.007831335067749023\n",
            "Prediction: 0.027488 seconds.\n",
            "process image 152\n",
            "Load Image: 0.013368 seconds.\n",
            "Inference time:  0.007825374603271484\n",
            "Prediction: 0.025141 seconds.\n",
            "process image 153\n",
            "Load Image: 0.004861 seconds.\n",
            "Inference time:  0.007333993911743164\n",
            "Prediction: 0.027446 seconds.\n",
            "process image 154\n",
            "Load Image: 0.008401 seconds.\n",
            "Inference time:  0.007369041442871094\n",
            "Prediction: 0.022406 seconds.\n",
            "process image 155\n",
            "Load Image: 0.014956 seconds.\n",
            "Inference time:  0.007291555404663086\n",
            "Prediction: 0.028237 seconds.\n",
            "process image 156\n",
            "Load Image: 0.007024 seconds.\n",
            "Inference time:  0.007699251174926758\n",
            "Prediction: 0.024271 seconds.\n",
            "process image 157\n",
            "Load Image: 0.003536 seconds.\n",
            "Inference time:  0.007542848587036133\n",
            "Prediction: 0.028721 seconds.\n",
            "process image 158\n",
            "Load Image: 0.005938 seconds.\n",
            "Inference time:  0.008242368698120117\n",
            "Prediction: 0.024277 seconds.\n",
            "process image 159\n",
            "Load Image: 0.005978 seconds.\n",
            "Inference time:  0.009234428405761719\n",
            "Prediction: 0.032259 seconds.\n",
            "process image 160\n",
            "Load Image: 0.010304 seconds.\n",
            "Inference time:  0.009370803833007812\n",
            "Prediction: 0.026895 seconds.\n",
            "process image 161\n",
            "Load Image: 0.007256 seconds.\n",
            "Inference time:  0.008913755416870117\n",
            "Prediction: 0.025768 seconds.\n",
            "process image 162\n",
            "Load Image: 0.008142 seconds.\n",
            "Inference time:  0.008753538131713867\n",
            "Prediction: 0.027078 seconds.\n",
            "process image 163\n",
            "Load Image: 0.005179 seconds.\n",
            "Inference time:  0.009080171585083008\n",
            "Prediction: 0.033386 seconds.\n",
            "process image 164\n",
            "Load Image: 0.007315 seconds.\n",
            "Inference time:  0.010694503784179688\n",
            "Prediction: 0.030853 seconds.\n",
            "process image 165\n",
            "Load Image: 0.006923 seconds.\n",
            "Inference time:  0.009227275848388672\n",
            "Prediction: 0.027422 seconds.\n",
            "process image 166\n",
            "Load Image: 0.012531 seconds.\n",
            "Inference time:  0.011860132217407227\n",
            "Prediction: 0.043844 seconds.\n",
            "process image 167\n",
            "Load Image: 0.010872 seconds.\n",
            "Inference time:  0.008102893829345703\n",
            "Prediction: 0.024247 seconds.\n",
            "process image 168\n",
            "Load Image: 0.009462 seconds.\n",
            "Inference time:  0.00873112678527832\n",
            "Prediction: 0.030967 seconds.\n",
            "process image 169\n",
            "Load Image: 0.009206 seconds.\n",
            "Inference time:  0.00775146484375\n",
            "Prediction: 0.027464 seconds.\n",
            "process image 170\n",
            "Load Image: 0.007022 seconds.\n",
            "Inference time:  0.007883787155151367\n",
            "Prediction: 0.029686 seconds.\n",
            "process image 171\n",
            "Load Image: 0.019065 seconds.\n",
            "Inference time:  0.009230852127075195\n",
            "Prediction: 0.031705 seconds.\n",
            "process image 172\n",
            "Load Image: 0.005775 seconds.\n",
            "Inference time:  0.007997512817382812\n",
            "Prediction: 0.027941 seconds.\n",
            "process image 173\n",
            "Load Image: 0.005936 seconds.\n",
            "Inference time:  0.007941722869873047\n",
            "Prediction: 0.035537 seconds.\n",
            "process image 174\n",
            "Load Image: 0.013643 seconds.\n",
            "Inference time:  0.007784366607666016\n",
            "Prediction: 0.031260 seconds.\n",
            "process image 175\n",
            "Load Image: 0.006169 seconds.\n",
            "Inference time:  0.010335206985473633\n",
            "Prediction: 0.034546 seconds.\n",
            "process image 176\n",
            "Load Image: 0.006602 seconds.\n",
            "Inference time:  0.008045196533203125\n",
            "Prediction: 0.030950 seconds.\n",
            "process image 177\n",
            "Load Image: 0.008901 seconds.\n",
            "Inference time:  0.007699251174926758\n",
            "Prediction: 0.029119 seconds.\n",
            "process image 178\n",
            "Load Image: 0.005345 seconds.\n",
            "Inference time:  0.008154630661010742\n",
            "Prediction: 0.036648 seconds.\n",
            "process image 179\n",
            "Load Image: 0.011015 seconds.\n",
            "Inference time:  0.008290290832519531\n",
            "Prediction: 0.029598 seconds.\n",
            "process image 180\n",
            "Load Image: 0.006453 seconds.\n",
            "Inference time:  0.007953643798828125\n",
            "Prediction: 0.025387 seconds.\n",
            "process image 181\n",
            "Load Image: 0.013144 seconds.\n",
            "Inference time:  0.007387638092041016\n",
            "Prediction: 0.024602 seconds.\n",
            "process image 182\n",
            "Load Image: 0.014750 seconds.\n",
            "Inference time:  0.007576704025268555\n",
            "Prediction: 0.021992 seconds.\n",
            "process image 183\n",
            "Load Image: 0.007551 seconds.\n",
            "Inference time:  0.008501529693603516\n",
            "Prediction: 0.028942 seconds.\n",
            "process image 184\n",
            "Load Image: 0.013875 seconds.\n",
            "Inference time:  0.007973432540893555\n",
            "Prediction: 0.024715 seconds.\n",
            "process image 185\n",
            "Load Image: 0.010338 seconds.\n",
            "Inference time:  0.008260250091552734\n",
            "Prediction: 0.023541 seconds.\n",
            "process image 186\n",
            "Load Image: 0.007598 seconds.\n",
            "Inference time:  0.011762619018554688\n",
            "Prediction: 0.031384 seconds.\n",
            "process image 187\n",
            "Load Image: 0.015178 seconds.\n",
            "Inference time:  0.008136749267578125\n",
            "Prediction: 0.032197 seconds.\n",
            "process image 188\n",
            "Load Image: 0.011131 seconds.\n",
            "Inference time:  0.007886171340942383\n",
            "Prediction: 0.030261 seconds.\n",
            "process image 189\n",
            "Load Image: 0.006155 seconds.\n",
            "Inference time:  0.008090019226074219\n",
            "Prediction: 0.028053 seconds.\n",
            "process image 190\n",
            "Load Image: 0.016917 seconds.\n",
            "Inference time:  0.008814573287963867\n",
            "Prediction: 0.025676 seconds.\n",
            "process image 191\n",
            "Load Image: 0.012160 seconds.\n",
            "Inference time:  0.008683204650878906\n",
            "Prediction: 0.036224 seconds.\n",
            "process image 192\n",
            "Load Image: 0.013065 seconds.\n",
            "Inference time:  0.007660865783691406\n",
            "Prediction: 0.026818 seconds.\n",
            "process image 193\n",
            "Load Image: 0.004081 seconds.\n",
            "Inference time:  0.008056402206420898\n",
            "Prediction: 0.033190 seconds.\n",
            "process image 194\n",
            "Load Image: 0.009527 seconds.\n",
            "Inference time:  0.007767677307128906\n",
            "Prediction: 0.026871 seconds.\n",
            "process image 195\n",
            "Load Image: 0.009018 seconds.\n",
            "Inference time:  0.007650136947631836\n",
            "Prediction: 0.025328 seconds.\n",
            "process image 196\n",
            "Load Image: 0.005091 seconds.\n",
            "Inference time:  0.008163213729858398\n",
            "Prediction: 0.029724 seconds.\n",
            "process image 197\n",
            "Load Image: 0.010046 seconds.\n",
            "Inference time:  0.007932901382446289\n",
            "Prediction: 0.025298 seconds.\n",
            "process image 198\n",
            "Load Image: 0.007966 seconds.\n",
            "Inference time:  0.007517337799072266\n",
            "Prediction: 0.026521 seconds.\n",
            "process image 199\n",
            "Load Image: 0.005882 seconds.\n",
            "Inference time:  0.008559465408325195\n",
            "Prediction: 0.029481 seconds.\n",
            "process image 200\n",
            "Load Image: 0.005531 seconds.\n",
            "Inference time:  0.007552146911621094\n",
            "Prediction: 0.022795 seconds.\n",
            "process image 201\n",
            "Load Image: 0.008434 seconds.\n",
            "Inference time:  0.007394552230834961\n",
            "Prediction: 0.028804 seconds.\n",
            "process image 202\n",
            "Load Image: 0.009605 seconds.\n",
            "Inference time:  0.0109405517578125\n",
            "Prediction: 0.034061 seconds.\n",
            "process image 203\n",
            "Load Image: 0.016628 seconds.\n",
            "Inference time:  0.008809089660644531\n",
            "Prediction: 0.025790 seconds.\n",
            "process image 204\n",
            "Load Image: 0.007550 seconds.\n",
            "Inference time:  0.008040428161621094\n",
            "Prediction: 0.025456 seconds.\n",
            "process image 205\n",
            "Load Image: 0.005840 seconds.\n",
            "Inference time:  0.007752418518066406\n",
            "Prediction: 0.030878 seconds.\n",
            "process image 206\n",
            "Load Image: 0.015815 seconds.\n",
            "Inference time:  0.009885072708129883\n",
            "Prediction: 0.027560 seconds.\n",
            "process image 207\n",
            "Load Image: 0.006101 seconds.\n",
            "Inference time:  0.009275436401367188\n",
            "Prediction: 0.037282 seconds.\n",
            "process image 208\n",
            "Load Image: 0.005290 seconds.\n",
            "Inference time:  0.00857400894165039\n",
            "Prediction: 0.026397 seconds.\n",
            "process image 209\n",
            "Load Image: 0.009163 seconds.\n",
            "Inference time:  0.008588552474975586\n",
            "Prediction: 0.038721 seconds.\n",
            "process image 210\n",
            "Load Image: 0.014094 seconds.\n",
            "Inference time:  0.009007453918457031\n",
            "Prediction: 0.027953 seconds.\n",
            "process image 211\n",
            "Load Image: 0.005979 seconds.\n",
            "Inference time:  0.008533716201782227\n",
            "Prediction: 0.030733 seconds.\n",
            "process image 212\n",
            "Load Image: 0.006012 seconds.\n",
            "Inference time:  0.008649587631225586\n",
            "Prediction: 0.033514 seconds.\n",
            "process image 213\n",
            "Load Image: 0.009971 seconds.\n",
            "Inference time:  0.008592844009399414\n",
            "Prediction: 0.027512 seconds.\n",
            "process image 214\n",
            "Load Image: 0.017478 seconds.\n",
            "Inference time:  0.009083986282348633\n",
            "Prediction: 0.039007 seconds.\n",
            "process image 215\n",
            "Load Image: 0.009697 seconds.\n",
            "Inference time:  0.00896143913269043\n",
            "Prediction: 0.024524 seconds.\n",
            "process image 216\n",
            "Load Image: 0.006865 seconds.\n",
            "Inference time:  0.008200883865356445\n",
            "Prediction: 0.024951 seconds.\n",
            "process image 217\n",
            "Load Image: 0.005408 seconds.\n",
            "Inference time:  0.014535903930664062\n",
            "Prediction: 0.034014 seconds.\n",
            "process image 218\n",
            "Load Image: 0.010811 seconds.\n",
            "Inference time:  0.009018659591674805\n",
            "Prediction: 0.034359 seconds.\n",
            "process image 219\n",
            "Load Image: 0.013559 seconds.\n",
            "Inference time:  0.009409666061401367\n",
            "Prediction: 0.030554 seconds.\n",
            "process image 220\n",
            "Load Image: 0.007819 seconds.\n",
            "Inference time:  0.00793313980102539\n",
            "Prediction: 0.029221 seconds.\n",
            "process image 221\n",
            "Load Image: 0.014114 seconds.\n",
            "Inference time:  0.007698535919189453\n",
            "Prediction: 0.022934 seconds.\n",
            "process image 222\n",
            "Load Image: 0.008646 seconds.\n",
            "Inference time:  0.009853839874267578\n",
            "Prediction: 0.040470 seconds.\n",
            "process image 223\n",
            "Load Image: 0.010127 seconds.\n",
            "Inference time:  0.008689641952514648\n",
            "Prediction: 0.027477 seconds.\n",
            "process image 224\n",
            "Load Image: 0.010582 seconds.\n",
            "Inference time:  0.012942314147949219\n",
            "Prediction: 0.034642 seconds.\n",
            "process image 225\n",
            "Load Image: 0.009217 seconds.\n",
            "Inference time:  0.008146047592163086\n",
            "Prediction: 0.027251 seconds.\n",
            "process image 226\n",
            "Load Image: 0.006030 seconds.\n",
            "Inference time:  0.01054072380065918\n",
            "Prediction: 0.027655 seconds.\n",
            "process image 227\n",
            "Load Image: 0.020463 seconds.\n",
            "Inference time:  0.008388519287109375\n",
            "Prediction: 0.030881 seconds.\n",
            "process image 228\n",
            "Load Image: 0.007849 seconds.\n",
            "Inference time:  0.008369684219360352\n",
            "Prediction: 0.028104 seconds.\n",
            "process image 229\n",
            "Load Image: 0.005034 seconds.\n",
            "Inference time:  0.009456634521484375\n",
            "Prediction: 0.032412 seconds.\n",
            "process image 230\n",
            "Load Image: 0.008837 seconds.\n",
            "Inference time:  0.008488655090332031\n",
            "Prediction: 0.030710 seconds.\n",
            "process image 231\n",
            "Load Image: 0.004853 seconds.\n",
            "Inference time:  0.008536577224731445\n",
            "Prediction: 0.025357 seconds.\n",
            "process image 232\n",
            "Load Image: 0.017048 seconds.\n",
            "Inference time:  0.008561372756958008\n",
            "Prediction: 0.031473 seconds.\n",
            "process image 233\n",
            "Load Image: 0.006532 seconds.\n",
            "Inference time:  0.009262800216674805\n",
            "Prediction: 0.035773 seconds.\n",
            "process image 234\n",
            "Load Image: 0.009025 seconds.\n",
            "Inference time:  0.01046895980834961\n",
            "Prediction: 0.039086 seconds.\n",
            "process image 235\n",
            "Load Image: 0.012864 seconds.\n",
            "Inference time:  0.009407520294189453\n",
            "Prediction: 0.040388 seconds.\n",
            "process image 236\n",
            "Load Image: 0.004511 seconds.\n",
            "Inference time:  0.010399103164672852\n",
            "Prediction: 0.034625 seconds.\n",
            "process image 237\n",
            "Load Image: 0.007361 seconds.\n",
            "Inference time:  0.009143829345703125\n",
            "Prediction: 0.035116 seconds.\n",
            "process image 238\n",
            "Load Image: 0.008410 seconds.\n",
            "Inference time:  0.007813215255737305\n",
            "Prediction: 0.026312 seconds.\n",
            "process image 239\n",
            "Load Image: 0.018874 seconds.\n",
            "Inference time:  0.009092569351196289\n",
            "Prediction: 0.031720 seconds.\n",
            "process image 240\n",
            "Load Image: 0.007313 seconds.\n",
            "Inference time:  0.009017705917358398\n",
            "Prediction: 0.027823 seconds.\n",
            "process image 241\n",
            "Load Image: 0.005604 seconds.\n",
            "Inference time:  0.01041412353515625\n",
            "Prediction: 0.035841 seconds.\n",
            "process image 242\n",
            "Load Image: 0.011083 seconds.\n",
            "Inference time:  0.009888172149658203\n",
            "Prediction: 0.029324 seconds.\n",
            "process image 243\n",
            "Load Image: 0.009037 seconds.\n",
            "Inference time:  0.009446382522583008\n",
            "Prediction: 0.044134 seconds.\n",
            "process image 244\n",
            "Load Image: 0.004273 seconds.\n",
            "Inference time:  0.009433746337890625\n",
            "Prediction: 0.030474 seconds.\n",
            "process image 245\n",
            "Load Image: 0.009281 seconds.\n",
            "Inference time:  0.009567737579345703\n",
            "Prediction: 0.038512 seconds.\n",
            "process image 246\n",
            "Load Image: 0.011274 seconds.\n",
            "Inference time:  0.009030342102050781\n",
            "Prediction: 0.027011 seconds.\n",
            "process image 247\n",
            "Load Image: 0.007578 seconds.\n",
            "Inference time:  0.008477449417114258\n",
            "Prediction: 0.029577 seconds.\n",
            "process image 248\n",
            "Load Image: 0.015023 seconds.\n",
            "Inference time:  0.009631156921386719\n",
            "Prediction: 0.031856 seconds.\n",
            "process image 249\n",
            "Load Image: 0.011441 seconds.\n",
            "Inference time:  0.009623527526855469\n",
            "Prediction: 0.035897 seconds.\n",
            "process image 250\n",
            "Load Image: 0.005968 seconds.\n",
            "Inference time:  0.00855112075805664\n",
            "Prediction: 0.028841 seconds.\n",
            "process image 251\n",
            "Load Image: 0.006995 seconds.\n",
            "Inference time:  0.008375406265258789\n",
            "Prediction: 0.027577 seconds.\n",
            "process image 252\n",
            "Load Image: 0.008317 seconds.\n",
            "Inference time:  0.008446693420410156\n",
            "Prediction: 0.032183 seconds.\n",
            "process image 253\n",
            "Load Image: 0.008732 seconds.\n",
            "Inference time:  0.014089345932006836\n",
            "Prediction: 0.031800 seconds.\n",
            "process image 254\n",
            "Load Image: 0.011883 seconds.\n",
            "Inference time:  0.008919715881347656\n",
            "Prediction: 0.030099 seconds.\n",
            "process image 255\n",
            "Load Image: 0.010791 seconds.\n",
            "Inference time:  0.010979413986206055\n",
            "Prediction: 0.034350 seconds.\n",
            "process image 256\n",
            "Load Image: 0.006051 seconds.\n",
            "Inference time:  0.011118888854980469\n",
            "Prediction: 0.034108 seconds.\n",
            "process image 257\n",
            "Load Image: 0.005333 seconds.\n",
            "Inference time:  0.008543252944946289\n",
            "Prediction: 0.034744 seconds.\n",
            "process image 258\n",
            "Load Image: 0.009917 seconds.\n",
            "Inference time:  0.008698463439941406\n",
            "Prediction: 0.030169 seconds.\n",
            "process image 259\n",
            "Load Image: 0.006122 seconds.\n",
            "Inference time:  0.008671998977661133\n",
            "Prediction: 0.027611 seconds.\n",
            "process image 260\n",
            "Load Image: 0.010749 seconds.\n",
            "Inference time:  0.008448123931884766\n",
            "Prediction: 0.034180 seconds.\n",
            "process image 261\n",
            "Load Image: 0.008067 seconds.\n",
            "Inference time:  0.00930023193359375\n",
            "Prediction: 0.035199 seconds.\n",
            "process image 262\n",
            "Load Image: 0.009474 seconds.\n",
            "Inference time:  0.008287906646728516\n",
            "Prediction: 0.031269 seconds.\n",
            "process image 263\n",
            "Load Image: 0.007067 seconds.\n",
            "Inference time:  0.008283615112304688\n",
            "Prediction: 0.031746 seconds.\n",
            "process image 264\n",
            "Load Image: 0.013782 seconds.\n",
            "Inference time:  0.008149862289428711\n",
            "Prediction: 0.022744 seconds.\n",
            "process image 265\n",
            "Load Image: 0.007455 seconds.\n",
            "Inference time:  0.008391141891479492\n",
            "Prediction: 0.025977 seconds.\n",
            "process image 266\n",
            "Load Image: 0.012539 seconds.\n",
            "Inference time:  0.009067296981811523\n",
            "Prediction: 0.027246 seconds.\n",
            "process image 267\n",
            "Load Image: 0.007674 seconds.\n",
            "Inference time:  0.008450508117675781\n",
            "Prediction: 0.030800 seconds.\n",
            "process image 268\n",
            "Load Image: 0.011173 seconds.\n",
            "Inference time:  0.009784936904907227\n",
            "Prediction: 0.035083 seconds.\n",
            "process image 269\n",
            "Load Image: 0.012932 seconds.\n",
            "Inference time:  0.00945138931274414\n",
            "Prediction: 0.025800 seconds.\n",
            "process image 270\n",
            "Load Image: 0.016531 seconds.\n",
            "Inference time:  0.008634328842163086\n",
            "Prediction: 0.029974 seconds.\n",
            "process image 271\n",
            "Load Image: 0.015535 seconds.\n",
            "Inference time:  0.008001327514648438\n",
            "Prediction: 0.026217 seconds.\n",
            "process image 272\n",
            "Load Image: 0.006198 seconds.\n",
            "Inference time:  0.007634639739990234\n",
            "Prediction: 0.025558 seconds.\n",
            "process image 273\n",
            "Load Image: 0.007478 seconds.\n",
            "Inference time:  0.00781869888305664\n",
            "Prediction: 0.030320 seconds.\n",
            "process image 274\n",
            "Load Image: 0.011425 seconds.\n",
            "Inference time:  0.008016109466552734\n",
            "Prediction: 0.031607 seconds.\n",
            "process image 275\n",
            "Load Image: 0.019648 seconds.\n",
            "Inference time:  0.011869192123413086\n",
            "Prediction: 0.043262 seconds.\n",
            "process image 276\n",
            "Load Image: 0.004536 seconds.\n",
            "Inference time:  0.009587287902832031\n",
            "Prediction: 0.043557 seconds.\n",
            "process image 277\n",
            "Load Image: 0.014144 seconds.\n",
            "Inference time:  0.00946044921875\n",
            "Prediction: 0.028380 seconds.\n",
            "process image 278\n",
            "Load Image: 0.010894 seconds.\n",
            "Inference time:  0.008929014205932617\n",
            "Prediction: 0.030287 seconds.\n",
            "process image 279\n",
            "Load Image: 0.006129 seconds.\n",
            "Inference time:  0.00853276252746582\n",
            "Prediction: 0.035578 seconds.\n",
            "process image 280\n",
            "Load Image: 0.013111 seconds.\n",
            "Inference time:  0.008527517318725586\n",
            "Prediction: 0.026164 seconds.\n",
            "process image 281\n",
            "Load Image: 0.008430 seconds.\n",
            "Inference time:  0.008513927459716797\n",
            "Prediction: 0.027218 seconds.\n",
            "process image 282\n",
            "Load Image: 0.008413 seconds.\n",
            "Inference time:  0.014319658279418945\n",
            "Prediction: 0.042717 seconds.\n",
            "process image 283\n",
            "Load Image: 0.011966 seconds.\n",
            "Inference time:  0.009282350540161133\n",
            "Prediction: 0.031084 seconds.\n",
            "process image 284\n",
            "Load Image: 0.015212 seconds.\n",
            "Inference time:  0.010945558547973633\n",
            "Prediction: 0.034530 seconds.\n",
            "process image 285\n",
            "Load Image: 0.009510 seconds.\n",
            "Inference time:  0.012311697006225586\n",
            "Prediction: 0.031110 seconds.\n",
            "process image 286\n",
            "Load Image: 0.006410 seconds.\n",
            "Inference time:  0.008774518966674805\n",
            "Prediction: 0.033119 seconds.\n",
            "process image 287\n",
            "Load Image: 0.007165 seconds.\n",
            "Inference time:  0.008171319961547852\n",
            "Prediction: 0.029412 seconds.\n",
            "process image 288\n",
            "Load Image: 0.007717 seconds.\n",
            "Inference time:  0.00815439224243164\n",
            "Prediction: 0.031820 seconds.\n",
            "process image 289\n",
            "Load Image: 0.008629 seconds.\n",
            "Inference time:  0.012820243835449219\n",
            "Prediction: 0.039289 seconds.\n",
            "process image 290\n",
            "Load Image: 0.010760 seconds.\n",
            "Inference time:  0.008434057235717773\n",
            "Prediction: 0.028908 seconds.\n",
            "process image 291\n",
            "Load Image: 0.014846 seconds.\n",
            "Inference time:  0.00874018669128418\n",
            "Prediction: 0.032274 seconds.\n",
            "process image 292\n",
            "Load Image: 0.006217 seconds.\n",
            "Inference time:  0.008875131607055664\n",
            "Prediction: 0.025853 seconds.\n",
            "process image 293\n",
            "Load Image: 0.016883 seconds.\n",
            "Inference time:  0.007855892181396484\n",
            "Prediction: 0.031826 seconds.\n",
            "process image 294\n",
            "Load Image: 0.018278 seconds.\n",
            "Inference time:  0.0067899227142333984\n",
            "Prediction: 0.025106 seconds.\n",
            "process image 295\n",
            "Load Image: 0.002680 seconds.\n",
            "Inference time:  0.0052602291107177734\n",
            "Prediction: 0.017195 seconds.\n",
            "process image 296\n",
            "Load Image: 0.004666 seconds.\n",
            "Inference time:  0.00504755973815918\n",
            "Prediction: 0.016848 seconds.\n",
            "process image 297\n",
            "Load Image: 0.004289 seconds.\n",
            "Inference time:  0.005306720733642578\n",
            "Prediction: 0.024297 seconds.\n",
            "process image 298\n",
            "Load Image: 0.005846 seconds.\n",
            "Inference time:  0.005437135696411133\n",
            "Prediction: 0.019847 seconds.\n",
            "process image 299\n",
            "Load Image: 0.010330 seconds.\n",
            "Inference time:  0.0052678585052490234\n",
            "Prediction: 0.019709 seconds.\n",
            "process image 300\n",
            "Load Image: 0.008189 seconds.\n",
            "Inference time:  0.005377769470214844\n",
            "Prediction: 0.018319 seconds.\n",
            "process image 301\n",
            "Load Image: 0.007148 seconds.\n",
            "Inference time:  0.004987239837646484\n",
            "Prediction: 0.021342 seconds.\n",
            "process image 302\n",
            "Load Image: 0.008438 seconds.\n",
            "Inference time:  0.00514674186706543\n",
            "Prediction: 0.017124 seconds.\n",
            "process image 303\n",
            "Load Image: 0.005651 seconds.\n",
            "Inference time:  0.005361318588256836\n",
            "Prediction: 0.021350 seconds.\n",
            "process image 304\n",
            "Load Image: 0.006384 seconds.\n",
            "Inference time:  0.005307197570800781\n",
            "Prediction: 0.019086 seconds.\n",
            "process image 305\n",
            "Load Image: 0.005792 seconds.\n",
            "Inference time:  0.005147218704223633\n",
            "Prediction: 0.019985 seconds.\n",
            "process image 306\n",
            "Load Image: 0.005548 seconds.\n",
            "Inference time:  0.005310535430908203\n",
            "Prediction: 0.020943 seconds.\n",
            "process image 307\n",
            "Load Image: 0.004133 seconds.\n",
            "Inference time:  0.005228996276855469\n",
            "Prediction: 0.019990 seconds.\n",
            "process image 308\n",
            "Load Image: 0.006905 seconds.\n",
            "Inference time:  0.0051021575927734375\n",
            "Prediction: 0.023465 seconds.\n",
            "process image 309\n",
            "Load Image: 0.005568 seconds.\n",
            "Inference time:  0.005332469940185547\n",
            "Prediction: 0.019131 seconds.\n",
            "process image 310\n",
            "Load Image: 0.004073 seconds.\n",
            "Inference time:  0.0049707889556884766\n",
            "Prediction: 0.019655 seconds.\n",
            "process image 311\n",
            "Load Image: 0.003451 seconds.\n",
            "Inference time:  0.005005836486816406\n",
            "Prediction: 0.018903 seconds.\n",
            "process image 312\n",
            "Load Image: 0.009629 seconds.\n",
            "Inference time:  0.004762411117553711\n",
            "Prediction: 0.019590 seconds.\n",
            "process image 313\n",
            "Load Image: 0.004954 seconds.\n",
            "Inference time:  0.004857301712036133\n",
            "Prediction: 0.018173 seconds.\n",
            "process image 314\n",
            "Load Image: 0.006850 seconds.\n",
            "Inference time:  0.004917621612548828\n",
            "Prediction: 0.019470 seconds.\n",
            "process image 315\n",
            "Load Image: 0.008354 seconds.\n",
            "Inference time:  0.004826545715332031\n",
            "Prediction: 0.020255 seconds.\n",
            "process image 316\n",
            "Load Image: 0.009750 seconds.\n",
            "Inference time:  0.00926351547241211\n",
            "Prediction: 0.021878 seconds.\n",
            "process image 317\n",
            "Load Image: 0.003000 seconds.\n",
            "Inference time:  0.004849433898925781\n",
            "Prediction: 0.021588 seconds.\n",
            "process image 318\n",
            "Load Image: 0.010140 seconds.\n",
            "Inference time:  0.004904031753540039\n",
            "Prediction: 0.021569 seconds.\n",
            "process image 319\n",
            "Load Image: 0.004679 seconds.\n",
            "Inference time:  0.0048944950103759766\n",
            "Prediction: 0.019585 seconds.\n",
            "process image 320\n",
            "Load Image: 0.007408 seconds.\n",
            "Inference time:  0.004750728607177734\n",
            "Prediction: 0.017079 seconds.\n",
            "process image 321\n",
            "Load Image: 0.004410 seconds.\n",
            "Inference time:  0.004900455474853516\n",
            "Prediction: 0.024375 seconds.\n",
            "process image 322\n",
            "Load Image: 0.003329 seconds.\n",
            "Inference time:  0.005879640579223633\n",
            "Prediction: 0.024265 seconds.\n",
            "process image 323\n",
            "Load Image: 0.004474 seconds.\n",
            "Inference time:  0.005500316619873047\n",
            "Prediction: 0.024792 seconds.\n",
            "process image 324\n",
            "Load Image: 0.013547 seconds.\n",
            "Inference time:  0.00536656379699707\n",
            "Prediction: 0.021230 seconds.\n",
            "process image 325\n",
            "Load Image: 0.005109 seconds.\n",
            "Inference time:  0.0051953792572021484\n",
            "Prediction: 0.018732 seconds.\n",
            "process image 326\n",
            "Load Image: 0.003930 seconds.\n",
            "Inference time:  0.005248069763183594\n",
            "Prediction: 0.019791 seconds.\n",
            "process image 327\n",
            "Load Image: 0.003275 seconds.\n",
            "Inference time:  0.0056154727935791016\n",
            "Prediction: 0.021197 seconds.\n",
            "process image 328\n",
            "Load Image: 0.003639 seconds.\n",
            "Inference time:  0.005137205123901367\n",
            "Prediction: 0.017405 seconds.\n",
            "process image 329\n",
            "Load Image: 0.006913 seconds.\n",
            "Inference time:  0.005017280578613281\n",
            "Prediction: 0.020420 seconds.\n",
            "process image 330\n",
            "Load Image: 0.007573 seconds.\n",
            "Inference time:  0.008643865585327148\n",
            "Prediction: 0.022745 seconds.\n",
            "process image 331\n",
            "Load Image: 0.009204 seconds.\n",
            "Inference time:  0.005335330963134766\n",
            "Prediction: 0.026073 seconds.\n",
            "process image 332\n",
            "Load Image: 0.008361 seconds.\n",
            "Inference time:  0.00532078742980957\n",
            "Prediction: 0.017716 seconds.\n",
            "process image 333\n",
            "Load Image: 0.005079 seconds.\n",
            "Inference time:  0.005118608474731445\n",
            "Prediction: 0.020199 seconds.\n",
            "process image 334\n",
            "Load Image: 0.007333 seconds.\n",
            "Inference time:  0.005127668380737305\n",
            "Prediction: 0.022308 seconds.\n",
            "process image 335\n",
            "Load Image: 0.006191 seconds.\n",
            "Inference time:  0.004999876022338867\n",
            "Prediction: 0.024596 seconds.\n",
            "process image 336\n",
            "Load Image: 0.004309 seconds.\n",
            "Inference time:  0.0049207210540771484\n",
            "Prediction: 0.015560 seconds.\n",
            "process image 337\n",
            "Load Image: 0.003917 seconds.\n",
            "Inference time:  0.005449056625366211\n",
            "Prediction: 0.021723 seconds.\n",
            "process image 338\n",
            "Load Image: 0.003887 seconds.\n",
            "Inference time:  0.0050127506256103516\n",
            "Prediction: 0.026030 seconds.\n",
            "process image 339\n",
            "Load Image: 0.005493 seconds.\n",
            "Inference time:  0.00487518310546875\n",
            "Prediction: 0.016385 seconds.\n",
            "process image 340\n",
            "Load Image: 0.004421 seconds.\n",
            "Inference time:  0.004903078079223633\n",
            "Prediction: 0.019456 seconds.\n",
            "process image 341\n",
            "Load Image: 0.003581 seconds.\n",
            "Inference time:  0.004814624786376953\n",
            "Prediction: 0.018098 seconds.\n",
            "process image 342\n",
            "Load Image: 0.003788 seconds.\n",
            "Inference time:  0.0048370361328125\n",
            "Prediction: 0.019202 seconds.\n",
            "process image 343\n",
            "Load Image: 0.006156 seconds.\n",
            "Inference time:  0.004826068878173828\n",
            "Prediction: 0.017313 seconds.\n",
            "process image 344\n",
            "Load Image: 0.008919 seconds.\n",
            "Inference time:  0.004806041717529297\n",
            "Prediction: 0.017311 seconds.\n",
            "process image 345\n",
            "Load Image: 0.010656 seconds.\n",
            "Inference time:  0.004876852035522461\n",
            "Prediction: 0.021356 seconds.\n",
            "process image 346\n",
            "Load Image: 0.007290 seconds.\n",
            "Inference time:  0.005339622497558594\n",
            "Prediction: 0.019872 seconds.\n",
            "process image 347\n",
            "Load Image: 0.003042 seconds.\n",
            "Inference time:  0.005862712860107422\n",
            "Prediction: 0.017595 seconds.\n",
            "process image 348\n",
            "Load Image: 0.002965 seconds.\n",
            "Inference time:  0.004836320877075195\n",
            "Prediction: 0.018377 seconds.\n",
            "process image 349\n",
            "Load Image: 0.008806 seconds.\n",
            "Inference time:  0.004946231842041016\n",
            "Prediction: 0.026225 seconds.\n",
            "process image 350\n",
            "Load Image: 0.004215 seconds.\n",
            "Inference time:  0.00875401496887207\n",
            "Prediction: 0.023371 seconds.\n",
            "process image 351\n",
            "Load Image: 0.003176 seconds.\n",
            "Inference time:  0.0054819583892822266\n",
            "Prediction: 0.019051 seconds.\n",
            "process image 352\n",
            "Load Image: 0.006908 seconds.\n",
            "Inference time:  0.00525975227355957\n",
            "Prediction: 0.022440 seconds.\n",
            "process image 353\n",
            "Load Image: 0.006848 seconds.\n",
            "Inference time:  0.005517244338989258\n",
            "Prediction: 0.018554 seconds.\n",
            "process image 354\n",
            "Load Image: 0.008494 seconds.\n",
            "Inference time:  0.005185842514038086\n",
            "Prediction: 0.018832 seconds.\n",
            "process image 355\n",
            "Load Image: 0.012137 seconds.\n",
            "Inference time:  0.005284309387207031\n",
            "Prediction: 0.023236 seconds.\n",
            "process image 356\n",
            "Load Image: 0.006426 seconds.\n",
            "Inference time:  0.005192756652832031\n",
            "Prediction: 0.023257 seconds.\n",
            "process image 357\n",
            "Load Image: 0.006305 seconds.\n",
            "Inference time:  0.005738735198974609\n",
            "Prediction: 0.019114 seconds.\n",
            "process image 358\n",
            "Load Image: 0.003854 seconds.\n",
            "Inference time:  0.0053670406341552734\n",
            "Prediction: 0.019060 seconds.\n",
            "process image 359\n",
            "Load Image: 0.007502 seconds.\n",
            "Inference time:  0.00540471076965332\n",
            "Prediction: 0.020262 seconds.\n",
            "process image 360\n",
            "Load Image: 0.005737 seconds.\n",
            "Inference time:  0.005086421966552734\n",
            "Prediction: 0.017788 seconds.\n",
            "process image 361\n",
            "Load Image: 0.005155 seconds.\n",
            "Inference time:  0.008751153945922852\n",
            "Prediction: 0.022184 seconds.\n",
            "process image 362\n",
            "Load Image: 0.011692 seconds.\n",
            "Inference time:  0.006958961486816406\n",
            "Prediction: 0.018634 seconds.\n",
            "process image 363\n",
            "Load Image: 0.011339 seconds.\n",
            "Inference time:  0.0050966739654541016\n",
            "Prediction: 0.017658 seconds.\n",
            "process image 364\n",
            "Load Image: 0.003661 seconds.\n",
            "Inference time:  0.004923343658447266\n",
            "Prediction: 0.021031 seconds.\n",
            "process image 365\n",
            "Load Image: 0.002602 seconds.\n",
            "Inference time:  0.0051958560943603516\n",
            "Prediction: 0.019059 seconds.\n",
            "process image 366\n",
            "Load Image: 0.006906 seconds.\n",
            "Inference time:  0.0047512054443359375\n",
            "Prediction: 0.017447 seconds.\n",
            "process image 367\n",
            "Load Image: 0.003577 seconds.\n",
            "Inference time:  0.004803895950317383\n",
            "Prediction: 0.024820 seconds.\n",
            "process image 368\n",
            "Load Image: 0.006634 seconds.\n",
            "Inference time:  0.005158901214599609\n",
            "Prediction: 0.018514 seconds.\n",
            "process image 369\n",
            "Load Image: 0.003806 seconds.\n",
            "Inference time:  0.004997730255126953\n",
            "Prediction: 0.018022 seconds.\n",
            "process image 370\n",
            "Load Image: 0.002592 seconds.\n",
            "Inference time:  0.007028341293334961\n",
            "Prediction: 0.025888 seconds.\n",
            "process image 371\n",
            "Load Image: 0.003757 seconds.\n",
            "Inference time:  0.005048274993896484\n",
            "Prediction: 0.020622 seconds.\n",
            "process image 372\n",
            "Load Image: 0.003026 seconds.\n",
            "Inference time:  0.004915714263916016\n",
            "Prediction: 0.016912 seconds.\n",
            "process image 373\n",
            "Load Image: 0.005316 seconds.\n",
            "Inference time:  0.006964206695556641\n",
            "Prediction: 0.019802 seconds.\n",
            "process image 374\n",
            "Load Image: 0.003962 seconds.\n",
            "Inference time:  0.004900455474853516\n",
            "Prediction: 0.017070 seconds.\n",
            "process image 375\n",
            "Load Image: 0.005636 seconds.\n",
            "Inference time:  0.004999876022338867\n",
            "Prediction: 0.026808 seconds.\n",
            "process image 376\n",
            "Load Image: 0.012358 seconds.\n",
            "Inference time:  0.0047664642333984375\n",
            "Prediction: 0.020379 seconds.\n",
            "process image 377\n",
            "Load Image: 0.003292 seconds.\n",
            "Inference time:  0.004814624786376953\n",
            "Prediction: 0.019303 seconds.\n",
            "process image 378\n",
            "Load Image: 0.004318 seconds.\n",
            "Inference time:  0.005071401596069336\n",
            "Prediction: 0.020262 seconds.\n",
            "process image 379\n",
            "Load Image: 0.009521 seconds.\n",
            "Inference time:  0.007139921188354492\n",
            "Prediction: 0.019896 seconds.\n",
            "process image 380\n",
            "Load Image: 0.003562 seconds.\n",
            "Inference time:  0.005011320114135742\n",
            "Prediction: 0.015969 seconds.\n",
            "process image 381\n",
            "Load Image: 0.008142 seconds.\n",
            "Inference time:  0.006189107894897461\n",
            "Prediction: 0.020146 seconds.\n",
            "process image 382\n",
            "Load Image: 0.005098 seconds.\n",
            "Inference time:  0.0050640106201171875\n",
            "Prediction: 0.022142 seconds.\n",
            "process image 383\n",
            "Load Image: 0.003373 seconds.\n",
            "Inference time:  0.005082368850708008\n",
            "Prediction: 0.020023 seconds.\n",
            "process image 384\n",
            "Load Image: 0.008192 seconds.\n",
            "Inference time:  0.005060434341430664\n",
            "Prediction: 0.020199 seconds.\n",
            "process image 385\n",
            "Load Image: 0.007047 seconds.\n",
            "Inference time:  0.005261659622192383\n",
            "Prediction: 0.019414 seconds.\n",
            "process image 386\n",
            "Load Image: 0.011523 seconds.\n",
            "Inference time:  0.005007028579711914\n",
            "Prediction: 0.020331 seconds.\n",
            "process image 387\n",
            "Load Image: 0.005309 seconds.\n",
            "Inference time:  0.0051424503326416016\n",
            "Prediction: 0.020558 seconds.\n",
            "process image 388\n",
            "Load Image: 0.003350 seconds.\n",
            "Inference time:  0.0049877166748046875\n",
            "Prediction: 0.019728 seconds.\n",
            "process image 389\n",
            "Load Image: 0.006765 seconds.\n",
            "Inference time:  0.005158662796020508\n",
            "Prediction: 0.017466 seconds.\n",
            "process image 390\n",
            "Load Image: 0.004078 seconds.\n",
            "Inference time:  0.004871368408203125\n",
            "Prediction: 0.021037 seconds.\n",
            "process image 391\n",
            "Load Image: 0.005352 seconds.\n",
            "Inference time:  0.006326913833618164\n",
            "Prediction: 0.024872 seconds.\n",
            "process image 392\n",
            "Load Image: 0.008467 seconds.\n",
            "Inference time:  0.005170345306396484\n",
            "Prediction: 0.018634 seconds.\n",
            "process image 393\n",
            "Load Image: 0.005417 seconds.\n",
            "Inference time:  0.0048601627349853516\n",
            "Prediction: 0.021892 seconds.\n",
            "process image 394\n",
            "Load Image: 0.005481 seconds.\n",
            "Inference time:  0.0051076412200927734\n",
            "Prediction: 0.019027 seconds.\n",
            "process image 395\n",
            "Load Image: 0.004520 seconds.\n",
            "Inference time:  0.004777193069458008\n",
            "Prediction: 0.022537 seconds.\n",
            "process image 396\n",
            "Load Image: 0.003803 seconds.\n",
            "Inference time:  0.004805803298950195\n",
            "Prediction: 0.023179 seconds.\n",
            "process image 397\n",
            "Load Image: 0.006868 seconds.\n",
            "Inference time:  0.005212545394897461\n",
            "Prediction: 0.018941 seconds.\n",
            "process image 398\n",
            "Load Image: 0.003838 seconds.\n",
            "Inference time:  0.00477147102355957\n",
            "Prediction: 0.018183 seconds.\n",
            "process image 399\n",
            "Load Image: 0.007185 seconds.\n",
            "Inference time:  0.005631208419799805\n",
            "Prediction: 0.020402 seconds.\n",
            "process image 400\n",
            "Load Image: 0.004998 seconds.\n",
            "Inference time:  0.004654884338378906\n",
            "Prediction: 0.016649 seconds.\n",
            "process image 401\n",
            "Load Image: 0.004087 seconds.\n",
            "Inference time:  0.0049245357513427734\n",
            "Prediction: 0.020506 seconds.\n",
            "process image 402\n",
            "Load Image: 0.003687 seconds.\n",
            "Inference time:  0.004725456237792969\n",
            "Prediction: 0.018888 seconds.\n",
            "process image 403\n",
            "Load Image: 0.004297 seconds.\n",
            "Inference time:  0.0047376155853271484\n",
            "Prediction: 0.021658 seconds.\n",
            "process image 404\n",
            "Load Image: 0.004924 seconds.\n",
            "Inference time:  0.004727363586425781\n",
            "Prediction: 0.022715 seconds.\n",
            "process image 405\n",
            "Load Image: 0.003499 seconds.\n",
            "Inference time:  0.004951000213623047\n",
            "Prediction: 0.017814 seconds.\n",
            "process image 406\n",
            "Load Image: 0.006074 seconds.\n",
            "Inference time:  0.0048182010650634766\n",
            "Prediction: 0.020239 seconds.\n",
            "process image 407\n",
            "Load Image: 0.006772 seconds.\n",
            "Inference time:  0.007111072540283203\n",
            "Prediction: 0.024632 seconds.\n",
            "process image 408\n",
            "Load Image: 0.003374 seconds.\n",
            "Inference time:  0.005384206771850586\n",
            "Prediction: 0.020926 seconds.\n",
            "process image 409\n",
            "Load Image: 0.005515 seconds.\n",
            "Inference time:  0.005204677581787109\n",
            "Prediction: 0.027923 seconds.\n",
            "process image 410\n",
            "Load Image: 0.007727 seconds.\n",
            "Inference time:  0.005562543869018555\n",
            "Prediction: 0.016757 seconds.\n",
            "process image 411\n",
            "Load Image: 0.008364 seconds.\n",
            "Inference time:  0.0049457550048828125\n",
            "Prediction: 0.020029 seconds.\n",
            "process image 412\n",
            "Load Image: 0.009400 seconds.\n",
            "Inference time:  0.005082845687866211\n",
            "Prediction: 0.018374 seconds.\n",
            "process image 413\n",
            "Load Image: 0.004043 seconds.\n",
            "Inference time:  0.006624937057495117\n",
            "Prediction: 0.019966 seconds.\n",
            "process image 414\n",
            "Load Image: 0.005937 seconds.\n",
            "Inference time:  0.006308555603027344\n",
            "Prediction: 0.022208 seconds.\n",
            "process image 415\n",
            "Load Image: 0.008176 seconds.\n",
            "Inference time:  0.0054569244384765625\n",
            "Prediction: 0.019951 seconds.\n",
            "process image 416\n",
            "Load Image: 0.005575 seconds.\n",
            "Inference time:  0.005278825759887695\n",
            "Prediction: 0.019797 seconds.\n",
            "process image 417\n",
            "Load Image: 0.009064 seconds.\n",
            "Inference time:  0.004958629608154297\n",
            "Prediction: 0.022877 seconds.\n",
            "process image 418\n",
            "Load Image: 0.005853 seconds.\n",
            "Inference time:  0.005518913269042969\n",
            "Prediction: 0.022425 seconds.\n",
            "process image 419\n",
            "Load Image: 0.008769 seconds.\n",
            "Inference time:  0.005347728729248047\n",
            "Prediction: 0.019913 seconds.\n",
            "process image 420\n",
            "Load Image: 0.009129 seconds.\n",
            "Inference time:  0.005290508270263672\n",
            "Prediction: 0.016429 seconds.\n",
            "process image 421\n",
            "Load Image: 0.002997 seconds.\n",
            "Inference time:  0.005322456359863281\n",
            "Prediction: 0.020110 seconds.\n",
            "process image 422\n",
            "Load Image: 0.010688 seconds.\n",
            "Inference time:  0.0049822330474853516\n",
            "Prediction: 0.019521 seconds.\n",
            "process image 423\n",
            "Load Image: 0.004372 seconds.\n",
            "Inference time:  0.005241870880126953\n",
            "Prediction: 0.020296 seconds.\n",
            "process image 424\n",
            "Load Image: 0.018110 seconds.\n",
            "Inference time:  0.00492405891418457\n",
            "Prediction: 0.022768 seconds.\n",
            "process image 425\n",
            "Load Image: 0.005823 seconds.\n",
            "Inference time:  0.005351066589355469\n",
            "Prediction: 0.021889 seconds.\n",
            "process image 426\n",
            "Load Image: 0.006161 seconds.\n",
            "Inference time:  0.0048389434814453125\n",
            "Prediction: 0.018375 seconds.\n",
            "process image 427\n",
            "Load Image: 0.010590 seconds.\n",
            "Inference time:  0.004818916320800781\n",
            "Prediction: 0.020329 seconds.\n",
            "process image 428\n",
            "Load Image: 0.006949 seconds.\n",
            "Inference time:  0.004815578460693359\n",
            "Prediction: 0.019782 seconds.\n",
            "process image 429\n",
            "Load Image: 0.005605 seconds.\n",
            "Inference time:  0.005781888961791992\n",
            "Prediction: 0.020302 seconds.\n",
            "\n",
            "\n",
            "Average Precision Per-class:\n",
            "Aircraft: 0.20173707211643327\n",
            "\n",
            "Average Precision Across All Classes:0.20173707211643327\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After fine-tuning the model for 20 epochs, the avg precision for the aircraft class improved from 0.2017 to 0.2761, which is a decent gain. This suggests the model has begun adapting to features of the new dataset but still needs  additional fine-tuning or hyperparameter adjustments. To further enhance AP, consider a lower learning rate, increasing the number of epochs.\n"
      ],
      "metadata": {
        "id": "A_mj6k-5laE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/pytorch-ssd/convert_to_caffe2_models.py mb1-ssd \\\n",
        "    /content/pytorch-ssd/models/mb1-ssd-Epoch-19-Loss-4.53431602134261.pth \\\n",
        "    /content/open_images_data/open-images-model-labels.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl6dvayNrFbw",
        "outputId": "89233130-d060-4403-bb51-319accffb0cc"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/pytorch-ssd/convert_to_caffe2_models.py\", line 9, in <module>\n",
            "    from caffe2.python.onnx.backend import Caffe2Backend as c2\n",
            "ModuleNotFoundError: No module named 'caffe2'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/pytorch-ssd/convert_to_onnx_models.py mb1-ssd \\\n",
        "    /content/pytorch-ssd/models/mb1-ssd-Epoch-19-Loss-4.53431602134261.pth \\\n",
        "    /content/open_images_data/open-images-model-labels.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo58hbiPr-4A",
        "outputId": "a5e8ebe8-ae29-4b8b-ff69-c5b1798df37a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pytorch-ssd/vision/ssd/ssd.py:135: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.load_state_dict(torch.load(model, map_location=lambda storage, loc: storage))\n",
            "ONNX model has been saved to /content/pytorch-ssd/models/mb1-ssd.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLBSDly9sDTw",
        "outputId": "53d2ea0d-3e13-4f76-8d6a-5490c498cea2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.22.0)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m105.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "# Load the saved ONNX model\n",
        "onnx_model_path = \"/content/pytorch-ssd/models/mb1-ssd.onnx\"\n",
        "model = onnx.load(onnx_model_path)\n",
        "\n",
        "# Verify the model’s structure\n",
        "try:\n",
        "    onnx.checker.check_model(model)\n",
        "    print(\"The ONNX model structure is valid.\")\n",
        "except onnx.checker.ValidationError as e:\n",
        "    print(\"The ONNX model structure is invalid:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5-l7GXHssnW",
        "outputId": "1dc8ebc3-f91c-4984-8fca-e8b68aba77c4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ONNX model structure is valid.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVCsWmcSttrF",
        "outputId": "fd0ae69f-9092-4ddf-88a2-7b5b8c3e54cb"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.22.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "# Define the model path and create an ONNX Runtime inference session\n",
        "onnx_model_path = \"/content/pytorch-ssd/models/mb1-ssd.onnx\"\n",
        "session = ort.InferenceSession(onnx_model_path)\n",
        "\n",
        "# Display the model's input and output names for reference\n",
        "input_name = session.get_inputs()[0].name\n",
        "output_names = [output.name for output in session.get_outputs()]\n",
        "print(\"Input Name:\", input_name)\n",
        "print(\"Output Names:\", output_names)\n",
        "\n",
        "# Create a dummy input tensor with the shape expected by the model (e.g., batch size 1, 3 channels, 300x300 image)\n",
        "dummy_input = np.random.randn(1, 3, 300, 300).astype(np.float32)\n",
        "\n",
        "# Run the model and get the output\n",
        "outputs = session.run(output_names, {input_name: dummy_input})\n",
        "\n",
        "# Show the output for inspection\n",
        "print(\"Model output scores:\", outputs[0])  # Output scores\n",
        "print(\"Model output boxes:\", outputs[1])    # Output bounding boxes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUxGLHbwuAE0",
        "outputId": "6bbe02b1-b9a7-423f-b11c-4b8e5ca0885f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Name: input.1\n",
            "Output Names: ['scores', 'boxes']\n",
            "Model output scores: [[[0.9812401  0.01875984]\n",
            "  [0.9896458  0.01035417]\n",
            "  [0.95239407 0.04760591]\n",
            "  ...\n",
            "  [0.8913681  0.10863195]\n",
            "  [0.92840225 0.07159783]\n",
            "  [0.90786034 0.09213968]]]\n",
            "Model output boxes: [[[ 2.0111270e-02  2.3486909e-02  9.2707910e-02  9.7269580e-02]\n",
            "  [-7.3224351e-02 -9.2235573e-02  1.3922818e-01  1.4815557e-01]\n",
            "  [ 1.2119297e-02  3.6112197e-02  7.8048974e-02  7.4776717e-02]\n",
            "  ...\n",
            "  [ 2.3496449e-03  5.3672940e-02  9.5140386e-01  9.9243689e-01]\n",
            "  [ 1.5386701e-02  3.9926052e-02  9.5258874e-01  9.8600960e-01]\n",
            "  [ 3.3587217e-04  3.8519919e-02  9.4960421e-01  9.9136883e-01]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ZXq7D5CuIvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 5"
      ],
      "metadata": {
        "id": "EbhHFQ2NvYiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import onnxruntime as ort\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pytorch_model_path = \"/content/pytorch-ssd/models/mb1-ssd-Epoch-19-Loss-4.53431602134261.pth\"\n",
        "onnx_model_path = \"/content/pytorch-ssd/models/mb1-ssd.onnx\"\n",
        "\n",
        "image_paths = [\"/content/open_images_data/test/test/00835f0fbe950715.jpg\", \"/content/open_images_data/test/test/01d4c269fd96589d.jpg\"]  # Paths to test images\n"
      ],
      "metadata": {
        "id": "YkMV1F2evZnW"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess images\n",
        "def preprocess_image(image_path):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((300, 300)),\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "    image = transform(image)\n",
        "    return image.unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "\n",
        "images = [preprocess_image(path) for path in image_paths]\n"
      ],
      "metadata": {
        "id": "mr4Ynyzuvlf5"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from vision.ssd.mobilenetv1_ssd import create_mobilenetv1_ssd\n",
        "\n",
        "\n",
        "num_classes = 2  # Adjust this based on your dataset\n",
        "model = create_mobilenetv1_ssd(num_classes=num_classes, is_test=True)\n",
        "model.load_state_dict(torch.load(pytorch_model_path))\n",
        "model = model.to(\"cuda\")\n",
        "\n",
        "\n",
        "def run_pytorch_inference(model, image_tensor):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        scores, boxes = model(image_tensor.to(\"cuda\"))\n",
        "    return scores.cpu().numpy(), boxes.cpu().numpy()\n",
        "\n",
        "pytorch_scores, pytorch_boxes = run_pytorch_inference(model, images[0].to(\"cuda\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nofiylKLvsZe",
        "outputId": "9769c905-3939-4cea-9d2e-d9065a14a2d2"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-332911b6a0e1>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(pytorch_model_path))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ONNX runtime\n",
        "ort_session = ort.InferenceSession(onnx_model_path)\n",
        "\n",
        "def run_onnx_inference(session, image_tensor):\n",
        "    ort_inputs = {session.get_inputs()[0].name: image_tensor.numpy()}\n",
        "    ort_outs = session.run(None, ort_inputs)\n",
        "    return ort_outs[0], ort_outs[1]\n",
        "\n",
        "onnx_scores, onnx_boxes = run_onnx_inference(ort_session, images[0])\n"
      ],
      "metadata": {
        "id": "Ljmg9UuzvtB6"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compar\n",
        "def compare_outputs(pytorch_output, onnx_output, tolerance=1e-5):\n",
        "    return np.allclose(pytorch_output, onnx_output, atol=tolerance)\n",
        "\n",
        "scores_match = compare_outputs(pytorch_scores, onnx_scores)\n",
        "boxes_match = compare_outputs(pytorch_boxes, onnx_boxes)\n",
        "print(f\"Do PyTorch and ONNX outputs match? Scores: {scores_match}, Boxes: {boxes_match}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyzfcQj6wXs6",
        "outputId": "bd7a4960-9654-4078-e59a-db2164679fe8"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Do PyTorch and ONNX outputs match? Scores: True, Boxes: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run inference with ONNX\n",
        "ort_outputs = [run_onnx_inference(ort_session, img) for img in images]\n",
        "\n",
        "for i, (scores, boxes) in enumerate(ort_outputs):\n",
        "    print(f\"Image {i+1} Output Scores:\\n{scores}\")\n",
        "    print(f\"Image {i+1} Output Boxes:\\n{boxes}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI-Jnp1vwZ2y",
        "outputId": "86573835-e331-4f4e-ece4-0a8f2bb743eb"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image 1 Output Scores:\n",
            "[[[0.98609936 0.01390067]\n",
            "  [0.9922368  0.00776316]\n",
            "  [0.9765129  0.02348709]\n",
            "  ...\n",
            "  [0.9138311  0.08616882]\n",
            "  [0.88797045 0.11202951]\n",
            "  [0.9385606  0.06143935]]]\n",
            "Image 1 Output Boxes:\n",
            "[[[ 8.45224783e-03  2.31708027e-02  9.94724482e-02  1.12552494e-01]\n",
            "  [-8.86582881e-02 -7.63940066e-02  1.41702831e-01  1.68326065e-01]\n",
            "  [-1.40358098e-02  3.18231136e-02  7.93265849e-02  8.37286040e-02]\n",
            "  ...\n",
            "  [ 1.00037754e-02  1.18435740e-01  9.29769278e-01  9.42582250e-01]\n",
            "  [-5.73217869e-04  2.08032310e-01  9.53017712e-01  8.61026227e-01]\n",
            "  [ 3.70020866e-02  8.51177275e-02  9.04490709e-01  9.65587258e-01]]]\n",
            "Image 2 Output Scores:\n",
            "[[[0.99659616 0.00340383]\n",
            "  [0.99416274 0.00583728]\n",
            "  [0.9891417  0.01085833]\n",
            "  ...\n",
            "  [0.87978977 0.12021025]\n",
            "  [0.75105    0.24894999]\n",
            "  [0.907893   0.09210702]]]\n",
            "Image 2 Output Boxes:\n",
            "[[[ 0.01511099  0.01073169  0.09782965  0.09936808]\n",
            "  [-0.09298997 -0.12491205  0.14805041  0.19104698]\n",
            "  [-0.01706864  0.02830485  0.04191089  0.07009736]\n",
            "  ...\n",
            "  [ 0.09663793  0.16920671  0.9310106   0.9239807 ]\n",
            "  [ 0.09857202  0.24746355  0.9572005   0.83869374]\n",
            "  [ 0.12153351  0.13733792  0.9105358   0.9365696 ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def annotate_image(image_path, boxes, scores, threshold=0.5):\n",
        "    image = cv2.imread(image_path)\n",
        "    h, w, _ = image.shape\n",
        "    for i in range(len(scores)):\n",
        "        if scores[i][0] > threshold:  # Adjust threshold as needed\n",
        "            box = boxes[i]\n",
        "            box = [int(b) for b in [box[0] * w, box[1] * h, box[2] * w, box[3] * h]]\n",
        "            cv2.rectangle(image, (box[0], box[1]), (box[2], box[3]), (255, 0, 0), 2)\n",
        "            cv2.putText(image, f\"{scores[i][0]:.2f}\", (box[0], box[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "9J9AoAXuwfS2"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Annotate\n",
        "for i, img_path in enumerate(image_paths):\n",
        "    annotated_image = annotate_image(img_path, ort_outputs[i][1][0], ort_outputs[i][0][0])  # using ONNX output\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f\"Inference Result for Image {i+1}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "sYGt2sXvwjPU",
        "outputId": "ad4ef0c5-f8a7-4fd8-935b-37439ea88304"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pdord1GPwlo_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}