{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.Documentation\n",
    "\n",
    "* Чтобы более подробно ознакомиться с функцией [***read_excel***()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html), предлагаем вам обратиться к [документации]\n",
    "\n",
    "* Чтобы более подробно ознакомиться с функцией [***to_excel()***](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html), предлагаем вам обратиться к документации.\n",
    "\n",
    "* [openpyxl](https://openpyxl.readthedocs.io/en/stable/) — рекомендуемый пакет для чтения и записи файлов Excel 2010+ (например, xlsx); \n",
    "\n",
    "* [xlsxwriter](https://xlsxwriter.readthedocs.io/) — альтернативный пакет для записи данных, информации о форматировании и, в частности, диаграмм в формате Excel 2010+ (например, xlsx);\n",
    "\n",
    "* [pyxlsb](https://pypi.org/project/pyxlsb/) — пакет позволяет читать файлы Excel в xlsb-формате;\n",
    "\n",
    "* [pylightxl](https://pylightxl.readthedocs.io/en/latest/) — пакет позволяет читать xlsx- и xlsm-файлы и записывать xlsx-файлы;\n",
    "\n",
    "* [xlrd](https://xlrd.readthedocs.io/en/latest/) — пакет предназначен для чтения данных и информации о форматировании из старых файлов Excel (например, xls);\n",
    "\n",
    "* [xlwt](https://xlwt.readthedocs.io/en/latest/) — пакет предназначен для записи данных и информации о форматировании в старые файлы Excel (например, xls)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Дополнительные материалы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *ZIP*\n",
    "\n",
    "    * [Working with zip files in Python (англ.)](https://www.geeksforgeeks.org/working-zip-files-python/)\n",
    "\n",
    "* *EXCEL*\n",
    "\n",
    "    * [Автоматизация Excel с помощью Python (рус.)](https://medium.com/nastia-shu/больше-не-нужно-открывать-сотни-файлов-в-excel-e0a1f5a9e9a7)\n",
    "    * [Использование Python и Excel для обработки и анализа данных (рус.)](https://habr.com/ru/company/otus/blog/331998/)\n",
    "    * [How to Work with Excel files in Pandas (англ.)](https://towardsdatascience.com/how-to-work-with-excel-files-in-pandas-c584abb67bfb)\n",
    "    * [Pandas read_excel() – Reading Excel File in Python (англ.)](https://www.journaldev.com/33306/pandas-read_excel-reading-excel-file-in-python)\n",
    "    * [Python Excel Tutorial: The Definitive Guide (англ.)](https://www.datacamp.com/community/tutorials/python-excel-tutorial)\n",
    "    * [Tutorial Using Excel with Python and Pandas (англ.)](https://www.dataquest.io/blog/excel-and-pandas/)\n",
    "\n",
    "* *JSON*\n",
    "\n",
    "    * [Парсинг JSON (рус.)](https://all-python.ru/osnovy/json.html)\n",
    "    * [Working With JSON Data in Python (англ.)](https://realpython.com/python-json/)\n",
    "    * [Python JSON (англ.)](https://www.programiz.com/python-programming/json)\n",
    "\n",
    "* *XML*\n",
    "\n",
    "    * [Работа с XML из Python (рус.)](https://codecamp.ru/blog/python-manipulating-xml/)\n",
    "    * [Processing XML in Python — ElementTree (англ.)](https://towardsdatascience.com/processing-xml-in-python-elementtree-c8992941efd2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Работа с текстовыми файлами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ИСПОЛЬЗУЕМ ФУНКЦИЮ READ_TABLE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ Вы уже работали с текстовыми файлами, данные в которых представлены в табличной форме. Это файлы CSV. \n",
    "\n",
    "Также вам известно, что, указав определенные значения параметров функции **read_csv()**, можно считать данные из файла, в котором используется разделитель данных, отличный от запятой (sep), вместо десятичной точки используется другой символ (decimal), а также при считывании должно быть пропущено некоторое количество строк (*skiprows*). \n",
    "\n",
    "Такие данные обычно хранятся в текстовых файлах с расширением *TXT*.   \n",
    "Этот тип файлов — источник данных, который легко расшифровывать и интерпретировать. Для чтения данных из файлов такого типа Pandas, помимо функции **read_csv()**, предлагает и функцию **read_table()**.\n",
    "\n",
    "* Функция ***read_csv()***, как вы уже знаете, загружает данные с разделителями из файла, URL-адреса, и в качестве разделителя по умолчанию используется запятая (символ).    \n",
    "В документации эта функция описана как «Чтение данных из файла значений, разделённых запятыми (CSV), в DataFrame».\n",
    "* Функция ***read_table()*** также загружает данные с разделителями из файла, URL-адреса, но в качестве разделителя по умолчанию используется символ табуляции ('\\t').    \n",
    "В документации эта функция описана как «Чтение данных из файла значений с разделителями в DataFrame».\n",
    "\n",
    "Данные функции используются похожим образом, и то, что в настоящий момент поддерживаются они обе, обусловлено тем, что многие пользователи продолжают использовать функцию **read_table()**.    \n",
    "Так, например, поиск на GitHub даёт более пятидесяти тысяч результатов по запросу *\"pd.read_table\"*.\n",
    "\n",
    "Для демонстрации использования функции **read_table()** выполним следующее: \n",
    "\n",
    "* используя  функцию **read_csv()**, считаем данные из файла *countries.csv* в переменную countries_data, создав объект *DataFrame*;\n",
    "* используя уже знакомую функцию **to_csv()**, выгрузим этот *DataFrame* в файл *countries.txt* (с расширением TXT), который сохраним в папке data. В качестве разделителя используется символ пробела (\" \").\n",
    "\n",
    "\n",
    "> Файл countries.csv ранее был вами сохранен в папке data. Папка создавалась при изучении материалов модуля PYTHON-10.    \n",
    "Работа с различными источниками данных в Pandas. Если вы потеряли эти данные, скачайте файл [по ссылке](https://lms.skillfactory.ru/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block@DST_3.0._16_2_countries.csv) и сохраните в папке data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотеки pandas — при выполнении последовательно всех примеров ниже\n",
    "# импорт выполняется один раз\n",
    "import pandas as pd \n",
    "# Загружаем данные из файла в переменную, создавая объект DataFrame\n",
    "countries_data = pd.read_csv('D:\\Course_SF_DS_v3\\PYTHON-10. Введение в Pandas\\data/countries.csv', sep=';') \n",
    "# Выгружаем данные из DataFrame в CSV-файл и сохраняем файл в папке data\n",
    "countries_data.to_csv('data/countries.txt', index=False, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем данные из файла countries.txt в переменную **txt_df**  (объект *DataFrame*), применив функцию ***read_table()*** с параметрами *sep=' '*  и  *index_col=['country']* (так мы избавимся от столбца с индексом и присвоим названия строкам, используя данные одного из столбцов). Выводим на экран полученный результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>population</th>\n",
       "      <th>area</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Англия</th>\n",
       "      <td>56.29</td>\n",
       "      <td>133396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Канада</th>\n",
       "      <td>38.05</td>\n",
       "      <td>9984670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>США</th>\n",
       "      <td>322.28</td>\n",
       "      <td>9826630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Россия</th>\n",
       "      <td>146.24</td>\n",
       "      <td>17125191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Украина</th>\n",
       "      <td>45.50</td>\n",
       "      <td>603628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Беларусь</th>\n",
       "      <td>9.50</td>\n",
       "      <td>207600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Казахстан</th>\n",
       "      <td>17.04</td>\n",
       "      <td>2724902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           population      area\n",
       "country                        \n",
       "Англия          56.29    133396\n",
       "Канада          38.05   9984670\n",
       "США            322.28   9826630\n",
       "Россия         146.24  17125191\n",
       "Украина         45.50    603628\n",
       "Беларусь         9.50    207600\n",
       "Казахстан       17.04   2724902"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загружаем данные из файла в переменную, создавая объект DataFrame\n",
    "txt_df = pd.read_table('data/countries.txt', sep=' ', index_col=['country'])\n",
    "# Выводим содержимое DataFrame на экран\n",
    "display(txt_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ПРИМЕНЕНИЕ ПАРАМЕТРА HEADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя параметр ***header***, при создании DataFrame мы учитываем наличие/отсутствие строки заголовков в исходном файле данных.\n",
    "\n",
    "Например, если при считывании данных из ранее сохранённого в папке data файла **melb_data_ps.csv** указать значение параметра **header*=None*, то первая строка исходного файла не будет восприниматься как строка заголовка и будет отнесена к области данных DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>index</td>\n",
       "      <td>Suburb</td>\n",
       "      <td>Address</td>\n",
       "      <td>Rooms</td>\n",
       "      <td>Type</td>\n",
       "      <td>Price</td>\n",
       "      <td>Method</td>\n",
       "      <td>SellerG</td>\n",
       "      <td>Date</td>\n",
       "      <td>Distance</td>\n",
       "      <td>...</td>\n",
       "      <td>Car</td>\n",
       "      <td>Landsize</td>\n",
       "      <td>BuildingArea</td>\n",
       "      <td>YearBuilt</td>\n",
       "      <td>CouncilArea</td>\n",
       "      <td>Lattitude</td>\n",
       "      <td>Longtitude</td>\n",
       "      <td>Regionname</td>\n",
       "      <td>Propertycount</td>\n",
       "      <td>Coordinates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>85 Turner St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>3/12/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.7996</td>\n",
       "      <td>144.9984</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>-37.7996, 144.9984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>25 Bloomburg St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/02/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8079</td>\n",
       "      <td>144.9934</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>-37.8079, 144.9934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>5 Charles St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1465000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/03/2017</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.8093</td>\n",
       "      <td>144.9944</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>-37.8093, 144.9944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>40 Federation La</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>850000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/03/2017</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.7969</td>\n",
       "      <td>144.9969</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "      <td>-37.7969, 144.9969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13576</th>\n",
       "      <td>13575</td>\n",
       "      <td>Wheelers Hill</td>\n",
       "      <td>12 Strada Cr</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>1245000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Barry</td>\n",
       "      <td>26/08/2017</td>\n",
       "      <td>16.7</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.90562</td>\n",
       "      <td>145.16761</td>\n",
       "      <td>South-Eastern Metropolitan</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>-37.90562, 145.16761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13577</th>\n",
       "      <td>13576</td>\n",
       "      <td>Williamstown</td>\n",
       "      <td>77 Merrett Dr</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1031000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Williams</td>\n",
       "      <td>26/08/2017</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>333.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.85927</td>\n",
       "      <td>144.87904</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>6380.0</td>\n",
       "      <td>-37.85927, 144.87904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13578</th>\n",
       "      <td>13577</td>\n",
       "      <td>Williamstown</td>\n",
       "      <td>83 Power St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1170000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Raine</td>\n",
       "      <td>26/08/2017</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.852740000000004</td>\n",
       "      <td>144.88738</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>6380.0</td>\n",
       "      <td>-37.85274, 144.88738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13579</th>\n",
       "      <td>13578</td>\n",
       "      <td>Williamstown</td>\n",
       "      <td>96 Verdon St</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>Sweeney</td>\n",
       "      <td>26/08/2017</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.85908</td>\n",
       "      <td>144.89299</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>6380.0</td>\n",
       "      <td>-37.85908, 144.89299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13580</th>\n",
       "      <td>13579</td>\n",
       "      <td>Yarraville</td>\n",
       "      <td>6 Agnes St</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>1285000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Village</td>\n",
       "      <td>26/08/2017</td>\n",
       "      <td>6.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.81188</td>\n",
       "      <td>144.88449</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>6543.0</td>\n",
       "      <td>-37.81188, 144.88449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13581 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0              1                 2      3     4          5       6   \\\n",
       "0      index         Suburb           Address  Rooms  Type      Price  Method   \n",
       "1          0     Abbotsford      85 Turner St      2     h  1480000.0       S   \n",
       "2          1     Abbotsford   25 Bloomburg St      2     h  1035000.0       S   \n",
       "3          2     Abbotsford      5 Charles St      3     h  1465000.0      SP   \n",
       "4          3     Abbotsford  40 Federation La      3     h   850000.0      PI   \n",
       "...      ...            ...               ...    ...   ...        ...     ...   \n",
       "13576  13575  Wheelers Hill      12 Strada Cr      4     h  1245000.0       S   \n",
       "13577  13576   Williamstown     77 Merrett Dr      3     h  1031000.0      SP   \n",
       "13578  13577   Williamstown       83 Power St      3     h  1170000.0       S   \n",
       "13579  13578   Williamstown      96 Verdon St      4     h  2500000.0      PI   \n",
       "13580  13579     Yarraville        6 Agnes St      4     h  1285000.0      SP   \n",
       "\n",
       "             7           8         9   ...   13        14            15  \\\n",
       "0       SellerG        Date  Distance  ...  Car  Landsize  BuildingArea   \n",
       "1        Biggin   3/12/2016       2.5  ...  1.0     202.0         126.0   \n",
       "2        Biggin   4/02/2016       2.5  ...  0.0     156.0          79.0   \n",
       "3        Biggin   4/03/2017       2.5  ...  0.0     134.0         150.0   \n",
       "4        Biggin   4/03/2017       2.5  ...  1.0      94.0         126.0   \n",
       "...         ...         ...       ...  ...  ...       ...           ...   \n",
       "13576     Barry  26/08/2017      16.7  ...  2.0     652.0         126.0   \n",
       "13577  Williams  26/08/2017       6.8  ...  2.0     333.0         133.0   \n",
       "13578     Raine  26/08/2017       6.8  ...  4.0     436.0         126.0   \n",
       "13579   Sweeney  26/08/2017       6.8  ...  5.0     866.0         157.0   \n",
       "13580   Village  26/08/2017       6.3  ...  1.0     362.0         112.0   \n",
       "\n",
       "              16           17                   18          19  \\\n",
       "0      YearBuilt  CouncilArea            Lattitude  Longtitude   \n",
       "1         1970.0        Yarra             -37.7996    144.9984   \n",
       "2         1900.0        Yarra             -37.8079    144.9934   \n",
       "3         1900.0        Yarra             -37.8093    144.9944   \n",
       "4         1970.0        Yarra             -37.7969    144.9969   \n",
       "...          ...          ...                  ...         ...   \n",
       "13576     1981.0          NaN            -37.90562   145.16761   \n",
       "13577     1995.0          NaN            -37.85927   144.87904   \n",
       "13578     1997.0          NaN  -37.852740000000004   144.88738   \n",
       "13579     1920.0          NaN            -37.85908   144.89299   \n",
       "13580     1920.0          NaN            -37.81188   144.88449   \n",
       "\n",
       "                               20             21                    22  \n",
       "0                      Regionname  Propertycount           Coordinates  \n",
       "1           Northern Metropolitan         4019.0    -37.7996, 144.9984  \n",
       "2           Northern Metropolitan         4019.0    -37.8079, 144.9934  \n",
       "3           Northern Metropolitan         4019.0    -37.8093, 144.9944  \n",
       "4           Northern Metropolitan         4019.0    -37.7969, 144.9969  \n",
       "...                           ...            ...                   ...  \n",
       "13576  South-Eastern Metropolitan         7392.0  -37.90562, 145.16761  \n",
       "13577        Western Metropolitan         6380.0  -37.85927, 144.87904  \n",
       "13578        Western Metropolitan         6380.0  -37.85274, 144.88738  \n",
       "13579        Western Metropolitan         6380.0  -37.85908, 144.89299  \n",
       "13580        Western Metropolitan         6543.0  -37.81188, 144.88449  \n",
       "\n",
       "[13581 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Загружаем данные из файла в переменную, создавая объект DataFrame\n",
    "melb_data = pd.read_csv('data/melb_data_ps.csv', header=None) \n",
    "# Выводим содержимое DataFrame на экран\n",
    "display(melb_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### РЕШАЕМ ПРОБЛЕМУ С КОДИРОВКОЙ ИСХОДНЫХ ДАННЫХ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> При считывании файла и создании DataFrame может возникнуть проблема — при выводе на экран данные будут отображаться в виде нечитаемых символов. Это связано с кодировкой символов в исходном файле.\n",
    "\n",
    "\n",
    "Для решения проблемы выполним следующие действия:\n",
    "\n",
    "* узнаем, какая кодировка символов используется в считываемом файле, для этого обратимся к субмодулю *chardet.universaldetector* библиотеки [Universal Encoding Detector](https://chardet.readthedocs.io/en/latest/usage.html). Модуль необходимо предварительно установить с помощью стандартной команды менеджера пакетов *pip: pip install chardet*;\n",
    "* при считывании файла и создании DataFrame будем использовать параметр *encoding*  —  указывает, какой тип кодировки символов используется в считываемом файле. \n",
    "\n",
    "> ✍️ Для выполнения кода-примера скачайте файл **ErrorEnCoding.csv** по [ссылке](https://lms.skillfactory.ru/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block@ErrorEnCoding.csv) и скопируйте его в каталог data.\n",
    "\n",
    "##### ЛОКАЛИЗУЕМ ПРОБЛЕМУ\n",
    "\n",
    "Считываем файл и создаем DataFrame без использования параметра *encoding*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User_943</td>\n",
       "      <td>Accumanst@gmail.com</td>\n",
       "      <td>������</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User_908</td>\n",
       "      <td>Advismowr@mail.ru</td>\n",
       "      <td>������</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User_962</td>\n",
       "      <td>Anachso@ukr.net</td>\n",
       "      <td>���������</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>User_973</td>\n",
       "      <td>Antecia@inbox.ru</td>\n",
       "      <td>�����</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User_902</td>\n",
       "      <td>Balliaryva@ukr.net</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>User_959</td>\n",
       "      <td>UpdatesCurious@yahoo.com</td>\n",
       "      <td>������</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>User_901</td>\n",
       "      <td>V2artierso@mail.ru</td>\n",
       "      <td>�����������</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>User_970</td>\n",
       "      <td>Vashoterlo@bk.ru</td>\n",
       "      <td>�������</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>User_965</td>\n",
       "      <td>Visuareda@yahoo.com</td>\n",
       "      <td>�������</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>User_921</td>\n",
       "      <td>Aavast@ya.ru</td>\n",
       "      <td>������</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                           1             2\n",
       "0   User_943         Accumanst@gmail.com         ������\n",
       "1   User_908           Advismowr@mail.ru         ������\n",
       "2   User_962             Anachso@ukr.net      ���������\n",
       "3   User_973            Antecia@inbox.ru          �����\n",
       "4   User_902          Balliaryva@ukr.net               \n",
       "..        ...                         ...           ...\n",
       "95  User_959    UpdatesCurious@yahoo.com         ������\n",
       "96  User_901          V2artierso@mail.ru    �����������\n",
       "97  User_970            Vashoterlo@bk.ru        �������\n",
       "98  User_965         Visuareda@yahoo.com        �������\n",
       "99  User_921                Aavast@ya.ru         ������\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Считываем данные из файла с неизвестной кодировкой в переменную, создавая объект DataFrame\n",
    "data=pd.read_csv('data/ErrorEnCoding.csv', header=None, encoding_errors='replace') \n",
    "# Выводим содержимое DataFrame на экран\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выявлена проблема: при стандартном считывании содержимое файла читается некорректно. Необходимо указать кодировку файла при считывании.\n",
    "\n",
    "##### ОПРЕДЕЛЯЕМ КОДИРОВКУ ФАЙЛА\n",
    "\n",
    "Приведённый ниже код поможет нам определить используемую кодировку в файле, степень достоверности, используемый язык."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'KOI8-R', 'confidence': 0.8773902118791048, 'language': 'Russian'}\n"
     ]
    }
   ],
   "source": [
    "# Импортируем субмодуль chardet.universal\n",
    "from chardet.universaldetector import UniversalDetector\n",
    "\n",
    "detector = UniversalDetector()\n",
    "\n",
    "with open('data/ErrorEnCoding.csv', 'rb') as fh:\n",
    "    for line in fh:\n",
    "        detector.feed(line)\n",
    "        if detector.done:\n",
    "            break\n",
    "print(detector.close())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С достоверностью примерно 84 % тип используемой в файле кодировки — koi8-r. Повторим считывание файла, используя полученные данные.\n",
    "\n",
    "##### СЧИТЫВАЕМ ФАЙЛ, УКАЗАВ КОДИРОВКУ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User_943</td>\n",
       "      <td>Accumanst@gmail.com</td>\n",
       "      <td>Ижевск</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>User_908</td>\n",
       "      <td>Advismowr@mail.ru</td>\n",
       "      <td>Ижевск</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>User_962</td>\n",
       "      <td>Anachso@ukr.net</td>\n",
       "      <td>Краснодар</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>User_973</td>\n",
       "      <td>Antecia@inbox.ru</td>\n",
       "      <td>Пермь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>User_902</td>\n",
       "      <td>Balliaryva@ukr.net</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>User_959</td>\n",
       "      <td>UpdatesCurious@yahoo.com</td>\n",
       "      <td>Тюмень</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>User_901</td>\n",
       "      <td>V2artierso@mail.ru</td>\n",
       "      <td>Арзангелтск</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>User_970</td>\n",
       "      <td>Vashoterlo@bk.ru</td>\n",
       "      <td>Воронеж</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>User_965</td>\n",
       "      <td>Visuareda@yahoo.com</td>\n",
       "      <td>Воронеж</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>User_921</td>\n",
       "      <td>Aavast@ya.ru</td>\n",
       "      <td>Ижевск</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0                           1             2\n",
       "0   User_943         Accumanst@gmail.com         Ижевск\n",
       "1   User_908           Advismowr@mail.ru         Ижевск\n",
       "2   User_962             Anachso@ukr.net      Краснодар\n",
       "3   User_973            Antecia@inbox.ru          Пермь\n",
       "4   User_902          Balliaryva@ukr.net               \n",
       "..        ...                         ...           ...\n",
       "95  User_959    UpdatesCurious@yahoo.com         Тюмень\n",
       "96  User_901          V2artierso@mail.ru    Арзангелтск\n",
       "97  User_970            Vashoterlo@bk.ru        Воронеж\n",
       "98  User_965         Visuareda@yahoo.com        Воронеж\n",
       "99  User_921                Aavast@ya.ru         Ижевск\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Создаем DataFrame из файла, явно указав кодировку символов, и выводим его содержимое на экран\n",
    "data=pd.read_csv('data/ErrorEnCoding.csv', encoding='koi8-r', header=None)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ЧТЕНИЕ ФАЙЛА ПО ССЫЛКЕ, ИСПОЛЬЗУЯ ФУНКЦИЮ READ_TABLE()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее вы уже считывали данные из файла *melb_data.csv*, который находится в свободном доступе в интернете, используя функцию **read_csv()**.    \n",
    "Попробуем использовать функцию **read_table()**, указав в качестве разделителя данных запятую — ','.\n",
    "\n",
    "Как видим, функция read_table() сработала и с CSV-файлом — достаточно было указать, какой разделитель используется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Price</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "      <th>...</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>85 Turner St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1480000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>3/12/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.79960</td>\n",
       "      <td>144.99840</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>25 Bloomburg St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>1035000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/02/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.80790</td>\n",
       "      <td>144.99340</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>5 Charles St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>1465000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/03/2017</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1900.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.80930</td>\n",
       "      <td>144.99440</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>40 Federation La</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>850000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>Biggin</td>\n",
       "      <td>4/03/2017</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.79690</td>\n",
       "      <td>144.99690</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Abbotsford</td>\n",
       "      <td>55a Park St</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>1600000.0</td>\n",
       "      <td>VB</td>\n",
       "      <td>Nelson</td>\n",
       "      <td>4/06/2016</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>Yarra</td>\n",
       "      <td>-37.80720</td>\n",
       "      <td>144.99410</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>4019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18391</th>\n",
       "      <td>23540</td>\n",
       "      <td>Williamstown</td>\n",
       "      <td>8/2 Thompson St</td>\n",
       "      <td>2</td>\n",
       "      <td>t</td>\n",
       "      <td>622500.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Greg</td>\n",
       "      <td>26/08/2017</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.86393</td>\n",
       "      <td>144.90484</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18392</th>\n",
       "      <td>23541</td>\n",
       "      <td>Williamstown</td>\n",
       "      <td>96 Verdon St</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>2500000.0</td>\n",
       "      <td>PI</td>\n",
       "      <td>Sweeney</td>\n",
       "      <td>26/08/2017</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>866.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.85908</td>\n",
       "      <td>144.89299</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18393</th>\n",
       "      <td>23544</td>\n",
       "      <td>Yallambie</td>\n",
       "      <td>17 Amaroo Wy</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>S</td>\n",
       "      <td>Buckingham</td>\n",
       "      <td>26/08/2017</td>\n",
       "      <td>12.7</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.72006</td>\n",
       "      <td>145.10547</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>1369.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18394</th>\n",
       "      <td>23545</td>\n",
       "      <td>Yarraville</td>\n",
       "      <td>6 Agnes St</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>1285000.0</td>\n",
       "      <td>SP</td>\n",
       "      <td>Village</td>\n",
       "      <td>26/08/2017</td>\n",
       "      <td>6.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>362.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>1920.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.81188</td>\n",
       "      <td>144.88449</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>6543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18395</th>\n",
       "      <td>23546</td>\n",
       "      <td>Yarraville</td>\n",
       "      <td>33 Freeman St</td>\n",
       "      <td>4</td>\n",
       "      <td>h</td>\n",
       "      <td>1050000.0</td>\n",
       "      <td>VB</td>\n",
       "      <td>Village</td>\n",
       "      <td>26/08/2017</td>\n",
       "      <td>6.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.81829</td>\n",
       "      <td>144.87404</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>6543.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18396 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0        Suburb           Address  Rooms Type      Price  \\\n",
       "0               1    Abbotsford      85 Turner St      2    h  1480000.0   \n",
       "1               2    Abbotsford   25 Bloomburg St      2    h  1035000.0   \n",
       "2               4    Abbotsford      5 Charles St      3    h  1465000.0   \n",
       "3               5    Abbotsford  40 Federation La      3    h   850000.0   \n",
       "4               6    Abbotsford       55a Park St      4    h  1600000.0   \n",
       "...           ...           ...               ...    ...  ...        ...   \n",
       "18391       23540  Williamstown   8/2 Thompson St      2    t   622500.0   \n",
       "18392       23541  Williamstown      96 Verdon St      4    h  2500000.0   \n",
       "18393       23544     Yallambie      17 Amaroo Wy      4    h  1100000.0   \n",
       "18394       23545    Yarraville        6 Agnes St      4    h  1285000.0   \n",
       "18395       23546    Yarraville     33 Freeman St      4    h  1050000.0   \n",
       "\n",
       "      Method     SellerG        Date  Distance  ...  Bathroom  Car  Landsize  \\\n",
       "0          S      Biggin   3/12/2016       2.5  ...       1.0  1.0     202.0   \n",
       "1          S      Biggin   4/02/2016       2.5  ...       1.0  0.0     156.0   \n",
       "2         SP      Biggin   4/03/2017       2.5  ...       2.0  0.0     134.0   \n",
       "3         PI      Biggin   4/03/2017       2.5  ...       2.0  1.0      94.0   \n",
       "4         VB      Nelson   4/06/2016       2.5  ...       1.0  2.0     120.0   \n",
       "...      ...         ...         ...       ...  ...       ...  ...       ...   \n",
       "18391     SP        Greg  26/08/2017       6.8  ...       2.0  1.0       NaN   \n",
       "18392     PI     Sweeney  26/08/2017       6.8  ...       1.0  5.0     866.0   \n",
       "18393      S  Buckingham  26/08/2017      12.7  ...       3.0  2.0       NaN   \n",
       "18394     SP     Village  26/08/2017       6.3  ...       1.0  1.0     362.0   \n",
       "18395     VB     Village  26/08/2017       6.3  ...       2.0  2.0       NaN   \n",
       "\n",
       "       BuildingArea  YearBuilt  CouncilArea  Lattitude Longtitude  \\\n",
       "0               NaN        NaN        Yarra  -37.79960  144.99840   \n",
       "1              79.0     1900.0        Yarra  -37.80790  144.99340   \n",
       "2             150.0     1900.0        Yarra  -37.80930  144.99440   \n",
       "3               NaN        NaN        Yarra  -37.79690  144.99690   \n",
       "4             142.0     2014.0        Yarra  -37.80720  144.99410   \n",
       "...             ...        ...          ...        ...        ...   \n",
       "18391          89.0     2010.0          NaN  -37.86393  144.90484   \n",
       "18392         157.0     1920.0          NaN  -37.85908  144.89299   \n",
       "18393           NaN        NaN          NaN  -37.72006  145.10547   \n",
       "18394         112.0     1920.0          NaN  -37.81188  144.88449   \n",
       "18395         139.0     1950.0          NaN  -37.81829  144.87404   \n",
       "\n",
       "                  Regionname  Propertycount  \n",
       "0      Northern Metropolitan         4019.0  \n",
       "1      Northern Metropolitan         4019.0  \n",
       "2      Northern Metropolitan         4019.0  \n",
       "3      Northern Metropolitan         4019.0  \n",
       "4      Northern Metropolitan         4019.0  \n",
       "...                      ...            ...  \n",
       "18391   Western Metropolitan         6380.0  \n",
       "18392   Western Metropolitan         6380.0  \n",
       "18393  Northern Metropolitan         1369.0  \n",
       "18394   Western Metropolitan         6543.0  \n",
       "18395   Western Metropolitan         6543.0  \n",
       "\n",
       "[18396 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_table('https://raw.githubusercontent.com/esabunor/MLWorkspace/master/melb_data.csv', sep=',')\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ЧТЕНИЕ/ЗАПИСЬ АРХИВИРОВАННЫХ CSV-ФАЙЛОВ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Механизм, используемый в функции *read_csv()*, позволяет проводить чтение текстового файла из архива, не распаковывая его.    \n",
    "Функция *read_csv()* сама распознает архив и извлекает из него данные (работает практически со всеми zip-архивами).    \n",
    "Есть ограничение — файл в zip-архиве должен быть один (если файлов в архиве несколько, то можно разархивировать файлы и работать с каждым вне архива.    \n",
    "Подробнее об этом поговорим в юните Итоги).\n",
    "\n",
    "Ранее вы работали с датасетом *students_performance.csv*, упакованным в архив.   \n",
    "Для работы с файлом вы предварительно проводили распаковку архива. Попробуем начать работу с файлом, не распаковывая его.\n",
    "\n",
    "✍️ Скачайте заархивированный датасет в CSV-формате *students_performance.zip* по [ссылке](https://lms.skillfactory.ru/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block@students_performance.zip)  и скопируйте его в каталог data, не распаковывая архив.\n",
    "\n",
    "Используя функцию *read_csv()*, загрузите данные из заархивированного датасета  в переменную *data()* и выведите её содержимое на экран, используя приведённый ниже код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>female</td>\n",
       "      <td>group E</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>88</td>\n",
       "      <td>99</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>high school</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>high school</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>completed</td>\n",
       "      <td>59</td>\n",
       "      <td>71</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>female</td>\n",
       "      <td>group D</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>68</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>female</td>\n",
       "      <td>group D</td>\n",
       "      <td>some college</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>77</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gender race/ethnicity parental level of education         lunch  \\\n",
       "0    female        group B           bachelor's degree      standard   \n",
       "1    female        group C                some college      standard   \n",
       "2    female        group B             master's degree      standard   \n",
       "3      male        group A          associate's degree  free/reduced   \n",
       "4      male        group C                some college      standard   \n",
       "..      ...            ...                         ...           ...   \n",
       "995  female        group E             master's degree      standard   \n",
       "996    male        group C                 high school  free/reduced   \n",
       "997  female        group C                 high school  free/reduced   \n",
       "998  female        group D                some college      standard   \n",
       "999  female        group D                some college  free/reduced   \n",
       "\n",
       "    test preparation course  math score  reading score  writing score  \n",
       "0                      none          72             72             74  \n",
       "1                 completed          69             90             88  \n",
       "2                      none          90             95             93  \n",
       "3                      none          47             57             44  \n",
       "4                      none          76             78             75  \n",
       "..                      ...         ...            ...            ...  \n",
       "995               completed          88             99             95  \n",
       "996                    none          62             55             55  \n",
       "997               completed          59             71             65  \n",
       "998               completed          68             78             77  \n",
       "999                    none          77             86             86  \n",
       "\n",
       "[1000 rows x 8 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.read_csv('data/students_performance.zip')\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В функции *to_csv()* предусмотрен механизм, позволяющий проводить упаковку CSV-файлов в zip-архив.    \n",
    "Проделаем обратную операцию — данные из DataFrame data запишем в CSV-файл, упакуем полученный файл в zip-архив «на лету» и сохраним полученный архив в папке data, выполнив следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем параметры архивирования — метод сжатия, имя файла в архиве\n",
    "compression_opts = dict(method='zip', archive_name='out.csv') \n",
    "data.to_csv('data/out.zip', index=False, compression=compression_opts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе выполнения кода содержимое DataFrame сохранено в файле *out.csv*, файл упакован в архив *out.zip*, а архив записан в каталог *data*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Работа с файлами Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### СЧИТЫВАНИЕ ДАННЫХ ИЗ ФАЙЛА EXCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "одобно уже хорошо нам известной функции *read_csv()*, в pandas предусмотрена функция для удобного чтения **XLS**- и **XLSX**- файлов: *read_excel()* (англ. читать_Excel). Синтаксис обеих функций практически идентичен.\n",
    "\n",
    "✍️ Для примера попробуем открыть файл *grades.xlsx*, содержащий оценки студентов за прослушанные курсы.    \n",
    "[Скачайте](https://lms.skillfactory.ru/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block@grades.xlsx) его и скопируйте в папку data. Для чтения файла предварительно потребуется установить библиотеку openpyxl через команду *pip install openpyxl*.\n",
    "\n",
    "Попробуем прочитать наш файл-пример. Для этого передадим в *read_excel*() путь к нему.    \n",
    "Чтобы его открыть и сохранить данные в переменную grades, необходимо выполнить следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\rybachkov.s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\rybachkov.s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1140\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m grades \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/grades.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m display(grades\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32mc:\\Users\\rybachkov.s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\rybachkov.s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1567\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[1;32m-> 1567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\rybachkov.s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:552\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    539\u001b[0m     engine_kwargs: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    540\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    541\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;124;03m        Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 552\u001b[0m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    553\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    554\u001b[0m         filepath_or_buffer,\n\u001b[0;32m    555\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    556\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    557\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\rybachkov.s\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\compat\\_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 138\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl."
     ]
    }
   ],
   "source": [
    "grades = pd.read_excel('data/grades.xlsx')\n",
    "display(grades.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Так же, как и read_csv(), функция read_excel() может принимать на вход не только путь к файлу на компьютере, но и интернет-ссылку на него."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### СЧИТЫВАНИЕ ДАННЫХ ИЗ ФАЙЛА EXCEL ПО ССЫЛКЕ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если файл находится в открытом доступе по ссылке (например, на Google Диске или GitHub), его можно прочитать и из интернета — для этого достаточно в функции *read_excel*() вместо пути до файла указать ссылку на файл. Например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('https://github.com/asaydn/test/raw/master/january.xlsx', skiprows=3)\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Основные параметры метода *read_excel*()**   \n",
    "\n",
    "* ***io*** — первый параметр, в который мы передаём адрес файла, который хотим прочитать. Кроме адреса на диске, можно передавать адрес в интернете.\n",
    "\n",
    "* ***sheet_name*** —  ссылка на лист в Excel-файле (возможные значения данного параметра: 0 — значение по умолчанию, загружается первый лист; '*Sheet1*' — можно передать название листа; обычно листы называются '*SheetX*', где X — номер листа, но могут использоваться и другие названия; *[0, 1, 'Sheet3']* — список, содержащий номера или названия листов; в таком случае Pandas вернёт словарь, в котором ключами будут номера или названия листов, а значениями — их содержимое в виде DataFrame; None — если передать такое значение, то pandas прочитает все листы и вернёт их в виде словаря, как в предыдущем пункте).\n",
    "\n",
    "* ***na_values*** — список значений, которые будут считаться пропусками ( ‘’, ‘#N/A’, ‘ N/A’, ‘#NA’, ‘-1.#IND’, ‘-1.#QNAN’, ‘-NaN’, ‘-nan’, ‘1.#IND’, ‘1.#QNAN’, ‘NA’, ‘NULL’, ‘NaN’, ‘n/a’, ‘nan’, ‘null’).\n",
    "\n",
    "Следует также учесть, что нормальное поведение pandas — это считывание значений (формулы из Excel-файла не считываются).\n",
    "\n",
    "Как упоминалось выше, один Excel-файл может включать в себя несколько листов, которые отображаются в разных вкладках (англ. sheet, рус. лист). Например, в нашем файле два листа — *Maths* и *ML*.\n",
    "\n",
    "По умолчанию в DataFrame читается информация из первого листа, однако *read_excel*()  позволяет выбрать, из какого именно листа загружать данные.    \n",
    "Сделать это можно с помощью параметра sheet_name (рус. имя_листа). Например, чтобы прочесть данные из второго листа (ML) файла, выполним код:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Student name</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Аня</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Катя</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Маша</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Миша</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Женя</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID Student name  Grade\n",
       "0           1          Аня      7\n",
       "1           2         Катя      5\n",
       "2           3         Маша      9\n",
       "3           4         Миша      8\n",
       "4           5         Женя      9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grades = pd.read_excel('data/grades.xlsx', sheet_name='ML')\n",
    "display(grades.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВЫГРУЗКА ДАННЫХ ИЗ DATAFRAME В EXCEL-ФАЙЛ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После обработки данных (очистка, создание новых признаков и т. д.) методами и функциями pandas мы сталкиваемся с обратной задачей — сохранить данные из DataFrame в Excel-файл.\n",
    "\n",
    "Для этого в pandas есть функция ***to_excel***() (рус. в_Excel), принцип работы которой очень схож с функцией **to_csv**():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняем данные из DataFrame grades в файл grades_new.xlsx в папке data\n",
    "grades.to_excel('data/grades_new.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом случае будет создан один лист с именем по умолчанию \"*Sheet1*\". Также мы сохраним и индекс — в данных будет находиться лишний столбец.    \n",
    "Чтобы создать лист с определённым именем (например, *Example*) и не сохранять индекс, в метод  *to_excel*() необходимо передать параметры:   \n",
    "\n",
    " ***sheet_name***='Example'     \n",
    " ***index***=False:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3.3\n",
    "\n",
    "Для выполнения следующего задания вам потребуется файл *ratings+movies.xlsx*, содержащий два листа с данными: *ratings* (таблица с информацией о выставленных оценках) и *movies* (таблица c расшифровками идентификаторов кинофильмов).   \n",
    "[Скачайте](https://lms-cdn.skillfactory.ru/assets/courseware/v1/d56d7f6eded3ab0872fd91a06c970f68/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/ratings_movies.xlsx) его и посмотрите, как он выглядит.\n",
    "\n",
    "\n",
    "Считайте данные из двух листов файла ratings+movies.xlsx в разные DataFrame, объедините в один, запишите данные из полученного DataFrame в файл. Сколько строк (включая строку заголовков) в результирующем файле?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читаем файл на каждом листе\n",
    "ratings_df = pd.read_excel('data/ratings_movies.xlsx', sheet_name='ratings')\n",
    "movies_df = pd.read_excel('data/ratings_movies.xlsx', sheet_name='movies')\n",
    "\n",
    "# Объединяем оба датафрейма в один\n",
    "ratmov_df = ratings_df.merge(\n",
    "    movies_df,\n",
    "    on='movieId',\n",
    "    how='left'\n",
    ")    \n",
    "ratmov_df.to_excel('data/ratmov_df.xlsx') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. JSON. Что это?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> → JSON — это простой, структурированный формат обмена данными, основанный на использовании текста.\n",
    "\n",
    "Под обменом данных в этом контексте чаще всего подразумевается передача данных по компьютерным сетям, например пересылка данных от сервера к браузеру.\n",
    "\n",
    "Аббревиатура JSON расшифровывается как *JavaScript Object Notation*, в переводе на русский — система обозначения/записи объектов JavaScript. Несмотря на то, что JSON изначально основывался на языке программирования JavaScript, он является общепризнанным форматом обмена данными, и многие языки программирования, включая Python, содержат эффективные инструменты для работы с ним.\n",
    "\n",
    "Если вы планируете использовать в своей работе информацию, которая автоматически загружается из каких-либо веб-служб, то умение работать с форматом JSON — это критически важный навык, который обязательно необходимо приобрести.\n",
    "\n",
    "Именно этим мы сейчас и займёмся!\n",
    "\n",
    ">> Итак, JSON — это простой, структурированный, основанный на использовании текста формат обмена данными. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### МОДУЛИ ДЛЯ РАБОТЫ С JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы с данными в формате JSON используется модуль json из стандартной библиотеки языка Python, который необходимо будет загрузить перед началом работы с данными, выполнив следующую команду:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем модуль json\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также нам может быть полезен модуль ***pprint***  (от англ. *pretty print*, рус. красивый вывод на экран), а точнее — встроенная в него одноимённая функция *pprint*(), с помощью которой можно красиво выводить на экран содержимое **JSON**-файла. Для загрузки нужной нам функции перед началом работы выполним следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем функцию pprint()\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### КАК ВЫГЛЯДИТ JSON-ФАЙЛ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Информация в формате JSON представляет собой (в закодированном виде) одну из двух структур:\n",
    "\n",
    "набор пар \"ключ-значение\", где ключ — это всегда строковая величина (в Python такая структура преобразуется в словарь);\n",
    "упорядоченный набор значений (при чтении JSON-файла в Python эта структура будет преобразована в список).\n",
    "\n",
    "![img](https://lms.skillfactory.ru/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block@json_0.png)\n",
    "\n",
    "\n",
    "Формат JSON допускает неограниченное количество вложений этих структур друг в друга.\n",
    "\n",
    "Давайте на примере посмотрим, что это означает. Все упражнения раздела мы будем выполнять на примере файла, содержащего информацию об ингредиентах блюд, относящихся к кухням разных народов.\n",
    "\n",
    "> ✍️ Мы будем работать с сокращённой версией файла. [Скачайте](https://lms.skillfactory.ru/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block@recipes.json) файл, откройте его и посмотрите на содержимое (можно использовать любой текстовый редактор, например Блокнот) . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. JSON. Открываем JSON-файл и извлекаем данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ОТКРЫВАЕМ JSON-ФАЙЛ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> → Чтобы перевести данные из формата **JSON** в формат, который можно обрабатывать инструментами Python, необходимо выполнить процедуру, которая называется ***десериализация*** (декодирование данных).    \n",
    "> Обратный процесс, связанный с переводом структур данных Python в формат **JSON**, называется ***сериализацией***.\n",
    "\n",
    "Для выполнения десериализации мы воспользуемся методом load() (от англ. загрузить) модуля json, который принимает на вход ссылку на открытый JSON-файл:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Открываем файл и связываем его с объектом \"f\"\n",
    "with open('recipes.json') as f:  \n",
    "    # Загружаем содержимое открытого файла в переменную recipes  \n",
    "    recipes = json.load(f)\n",
    "    \n",
    "# Выводим на экран содержимое переменной recipes, используя функцию pprint()\n",
    "pprint(recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы видим, что рецепт каждого из блюд описан в виде словаря, который состоит из трёх пар \"ключ-значение\":\n",
    "\n",
    "* Ключ \"*cuisine*\" — обозначает принадлежность блюда к определённой национальной кухне (например, 'greek', 'southern_us', 'filipino' и т. д.);\n",
    "\n",
    "* Ключ \"*id*\" — уникальный идентификационный номер блюда;\n",
    "\n",
    "* Ключ \"*ingredients*\"— содержит перечень продуктов, входящих в состав блюда.\n",
    "\n",
    "Все рецепты (то есть все словари) хранятся в одном списке, располагаясь последовательно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ИЗВЛЕКАЕМ ДАННЫЕ ИЗ JSON-ФАЙЛА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того как мы провели **десериализацию** данных из *JSON*-файла, мы можем работать с полученным объектом как с обычными списками и словарями.    \n",
    "Единственное отличие этой работы от манипуляций с привычными нам списками и словарями заключается в том, что данных теперь больше и они помещены внутрь структуры с большим количеством уровней вложенности.\n",
    "\n",
    "Давайте выясним некоторые детали о блюде, которое записано первым в списке блюд. Его индекс — 0, и информация о нём хранится в словаре.    \n",
    "Чтобы узнать ID этого блюда, мы можем обратиться к соответствующему ключу словаря, выполнив следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10259"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes[0]['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь мы сначала извлекаем из списка первый элемент (индекс 0). Поскольку каждый элемент списка является словарём, для получения нужной информации о конкретном блюде нам нужно указать ключ словаря.    \n",
    "ID блюда доступно по ключу '*id*', и мы указываем этот ключ в отдельной паре квадратных скобок:\n",
    "\n",
    "![img](https://lms.skillfactory.ru/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block@json_1.png)\n",
    "\n",
    "Аналогичным образом, для получения списка ингредиентов первого блюда в списке мы можем использовать тот же код, заменив в нём ключ '*id*' на '*ingredients*'.\n",
    "\n",
    "> Мы также можем извлечь информацию о конкретном блюде по его ID. Для этого необходимо с помощью цикла, например for, перебрать все элементы списка, проверяя ключ 'id',  и извлечь нужную информацию, когда мы наконец найдем нужное блюдо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какое количество уникальных национальных кухонь присутствуют в нашем наборе данных?\n",
    "\n",
    "> **ВАРИАНТ РЕШЕНИЯ С ИСПОЛЬЗОВАНИЕМ СПИСКА**\n",
    "> Чтобы извлечь эту информацию, нам нужно создать пустой список и последовательно заполнять его уникальными значениями, доступными по ключу 'cuisine' в каждом из словарей, содержащих информацию о рецептах. Поскольку словари объединены в список recipes, не получится применить известный нам метод unique() (этот метод неприменим к словарям), и для извлечения всех уникальных значений нужно перебирать элементы списка в цикле с параметром.\n",
    "\n",
    ">**ВАРИАНТ РЕШЕНИЯ С ИСПОЛЬЗОВАНИЕМ МНОЖЕСТВА**\n",
    "> Другой способ решения этой же задачи — использование для хранения данных о разных кухнях не списка, а множества (set). Множество содержит только уникальные элементы, поэтому при работе с ним нет необходимости проверять, содержится ли там тот или иной элемент. Если элемент (в нашем примере — название типа кухни) уже есть, то команда \"добавить во множество такое же значение\" будет проигнорирована компьютером."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Используя список        \n",
    "\n",
    "# Импортируем модуль json\n",
    "import json \n",
    "\n",
    "# Импортируем функцию pprint()\n",
    "from pprint import pprint \n",
    "\n",
    "# Открываем файл и связываем его с объектом \"f\"\n",
    "with open('recipes.json') as f:\n",
    "    # Загружаем содержимое открытого файла в переменную recipes \n",
    "    recipes = json.load(f) \n",
    "\n",
    "# Создаём пустой список для хранения уникальных значений кухонь\n",
    "cuisines = [] \n",
    "\n",
    "# Начинаем перебор всех рецептов\n",
    "for recipe in recipes: \n",
    "    # Если тип кухни текущего блюда ещё не встречался\n",
    "    if not(recipe['cuisine'] in cuisines):\n",
    "        # Добавляем его к списку cuisines \n",
    "        cuisines.append(recipe['cuisine']) \n",
    "\n",
    "# Выводим на экран полученное значение\n",
    "print(len(cuisines))\n",
    "       \n",
    "# Используя множество\n",
    "\n",
    "# Импортируем модуль json\n",
    "import json \n",
    "# Импортируем функцию pprint()\n",
    "from pprint import pprint \n",
    "\n",
    "# Открываем файл и связываем его с объектом \"f\"\n",
    "with open('recipes.json') as f: \n",
    "    # Загружаем содержимое открытого файла в переменную recipes\n",
    "    recipes = json.load(f) \n",
    "\n",
    "# Создаём пустое множество для хранения уникальных значений кухонь\n",
    "cuisines = set()  \n",
    "\n",
    "# Начинаем перебор всех рецептов\n",
    "for recipe in recipes:  \n",
    "    # Добавляем название типа кухни к множеству\n",
    "    cuisines.add(recipe['cuisine']) \n",
    "\n",
    "# Выводим на экран полученное значение\n",
    "print(len(cuisines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какой из национальных кухонь принадлежит самое большое количество рецептов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "italian\n"
     ]
    }
   ],
   "source": [
    "# Создаём пустой список для хранения уникальных значений кухонь\n",
    "cuisines = [] \n",
    "\n",
    "# Начинаем перебор всех рецептов\n",
    "for recipe in recipes: \n",
    "    # Если тип кухни текущего блюда ещё не встречался\n",
    "    if not(recipe['cuisine'] in cuisines):\n",
    "        # Добавляем его к списку cuisines \n",
    "        cuisines.append(recipe['cuisine']) \n",
    "\n",
    "# Создаём пустой словарь для хранения информации об количествах рецептов в каждой кухне\n",
    "valreccuisine = {} \n",
    "\n",
    "# Перебираем список кухонь\n",
    "for item in cuisines: \n",
    "    # Добавляем в словарь ключ, соответствующий очередной кухне\n",
    "    valreccuisine[item] = 0 \n",
    "\n",
    "# Перебираем список рецептов\n",
    "for recipe in recipes: \n",
    "    # Увеличиваем значение нужного ключа в словаре на 1\n",
    "    valreccuisine[recipe['cuisine']] += 1 \n",
    "\n",
    "# Извлекаем значения для всех ключей используя метод get(), выбираем самое максимальное значение (при наличии одинаковых значений будет выбрано первое в словаре) и выводим на экран ключ максимального значения\n",
    "print(max(valreccuisine, key=valreccuisine.get))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. JSON. Работаем с pandas. Из JSON в pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ИЗ JSON В PANDAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> → Как вы помните, после десериализации наши данные были преобразованы в список, элементами которого являются вложенные словари, содержащие по три пары \"ключ-значение\". \n",
    "\n",
    "Поскольку структура всех вложенных словарей одинакова, мы можем создать DataFrame на основе списка, не проводя с ним никаких дополнительных манипуляций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients\n",
       "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3  22213       indian                [water, vegetable oil, wheat, salt]\n",
       "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Импортируем модуль json\n",
    "import json \n",
    "# Импортируем функцию pprint()\n",
    "from pprint import pprint \n",
    "# Импортируем модуль pandas\n",
    "import pandas as pd \n",
    "# Открываем файл и связываем его с объектом \"f\"\n",
    "with open('recipes.json') as f: \n",
    "    # Загружаем содержимое открытого файла в переменную recipes\n",
    "    recipes = json.load(f) \n",
    "# Создаём объект DataFrame из списка recipes\n",
    "df = pd.DataFrame(recipes) \n",
    "# Выводим на экран первые строки полученного DataFrame\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ДОПОЛНИТЕЛЬНО**\n",
    "Для непосредственного считывания содержимого файла recipes.json в переменную df (объект DataFrame) используйте функцию *read_json()* (с англ. читать_json).\n",
    "\n",
    "Для более подробного ознакомления с функцией  *read_json()* предлагаем вам обратиться к [документации](https://pandas.pydata.org/pandas-docs/version/1.1.3/reference/api/pandas.read_json.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>[romaine lettuce, black olives, grape tomatoes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>[plain flour, ground pepper, salt, tomatoes, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>[eggs, pepper, salt, mayonaise, cooking oil, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>[water, vegetable oil, wheat, salt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>[black pepper, shallots, cornflour, cayenne pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id      cuisine                                        ingredients\n",
       "0  10259        greek  [romaine lettuce, black olives, grape tomatoes...\n",
       "1  25693  southern_us  [plain flour, ground pepper, salt, tomatoes, g...\n",
       "2  20130     filipino  [eggs, pepper, salt, mayonaise, cooking oil, g...\n",
       "3  22213       indian                [water, vegetable oil, wheat, salt]\n",
       "4  13162       indian  [black pepper, shallots, cornflour, cayenne pe..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Импортируем модуль pandas\n",
    "import pandas as pd \n",
    "# Создаём объект DataFrame, загружая содержимое файла recipes.json\n",
    "df = pd.read_json('recipes.json') \n",
    "\n",
    "# Выводим на экран первые строки полученного DataFrame\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> → Итак, получившийся DataFrame содержит информацию о рецептах из нашего JSON-файла. \n",
    "\n",
    "Каждая строка соответствует одному рецепту, в столбце *id* хранится его идентификационный номер, в столбце *cuisine* — тип кухни, а столбец *ingredients* содержит список, в котором перечислены ингредиенты, необходимые для приготовления блюда.\n",
    "\n",
    "> Такая структура не очень практична, поскольку она не позволяет осуществлять группировку данных и выполнять многие другие операции, связанные с исследованием ингредиентов разных блюд. Например, представьте, что вы хотите отфильтровать блюда, состоящие не более чем из пяти ингредиентов, или блюда, не содержащие мяса. Сделать это, когда ингредиенты блюд хранятся в списках, не очень просто.\n",
    "\n",
    "Для полноценной работы с данными нам необходимо иметь возможность хранить информацию о каждом ингредиенте в отдельном столбце, например:\n",
    "\n",
    "![img](https://lms-cdn.skillfactory.ru/assets/courseware/v1/4e2c3258d0afee9cf5a6aeb3b31e4f1f/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/json_pandas_2.jpg)\n",
    "\n",
    "Работу над преобразованием DataFrame начнём с создания и заполнения столбцов, содержащих сведения о наличии или отсутствии каждого ингредиента в рецепте. Процесс заполнения выполним в два этапа:\n",
    "\n",
    "1. Создадим функцию для заполнения значения в каждой ячейке. Функция будет проверять наличие конкретного ингредиента в столбце ingredients для текущего блюда и возвращать 1, если ингредиент есть в рецепте, и 0, если он отсутствует.\n",
    "\n",
    "2. Организуем цикл, в котором будем перебирать наименования всех ингредиентов DataFrame (для этого потребуется создать реестр, то есть некий список, который содержит уникальные наименования ингредиентов). Для каждого ингредиента создадим в DataFrame столбец с соответствующим названием и заполним его единицами и нулями, применив к DataFrame, а точнее к столбцу *ingredients* функцию, созданную нами на предыдущем этапе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 6.4\n",
    "\n",
    "Создайте реестр уникальных ингредиентов all_ingredients, который будет использоваться на втором этапе. Какое количество уникальных ингредиентов в нашем DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1318\n"
     ]
    }
   ],
   "source": [
    "# Импортируем модуль json\n",
    "import json\n",
    "# Импортируем функцию pprint()\n",
    "from pprint import pprint \n",
    "# Импортируем модуль pandas\n",
    "import pandas as pd \n",
    "\n",
    "# Открываем файл и связываем его с объектом \"f\"\n",
    "with open('recipes.json') as f: \n",
    "    # Загружаем содержимое открытого файла в переменную recipes\n",
    "    recipes = json.load(f) \n",
    "\n",
    "# Создаем пустое множество для хранения реестра уникальных ингредиентов\n",
    "all_ingredients=set() \n",
    "\n",
    "# Начинаем перебор всех блюд входящих в список\n",
    "for recipe in recipes: \n",
    "    # Начинаем перебор всех ингредиентов входящих в состав текущего блюда\n",
    "    for ingredient in recipe['ingredients']: \n",
    "        # Добавляем уникальный ингредиент в реестр\n",
    "        all_ingredients.add(ingredient ) \n",
    "\n",
    "# Выводим на экран количество уникальных ингредиентов из реестра\n",
    "print(len(all_ingredients))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> → Теперь определим функцию *contains()*, с помощью которой мы будем проверять наличие конкретного ингредиента *ingredient_name* в рецепте текущего блюда, который представлен списком *ingredient_list* (значение в ячейке столбца *ingredients* текущего рецепта)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем имя функции и передаваемые аргументы    \n",
    "def contains(ingredient_list): \n",
    "    # Если ингредиент есть в текущем блюде,\n",
    "    if ingredient_name in ingredient_list:   \n",
    "        # возвращаем значение 1\n",
    "        return 1 \n",
    "    # Если ингредиента нет в текущем блюде,\n",
    "    else: \n",
    "        # возвращаем значение 0\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осталось лишь перебрать все ингредиенты из ранее созданного реестра *all_ingredients* с помощью цикла  *for*  и создать в **DataFrame** столбец с соответствующим названием, заполнив его единицами и нулями. Для этого применим к **DataFrame**, а точнее, к столбцу *ingredients* функцию *contains*()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Последовательно перебираем ингредиенты в реестре all_ingredients\n",
    "for ingredient_name in all_ingredients: \n",
    "    # В DataFrame cоздаем столбец с именем текущего ингредиента \n",
    "    # и заполняем его единицами и нулями,\n",
    "    # используя ранее созданную функцию contains\n",
    "    df[ingredient_name] = df['ingredients'].apply(contains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В завершение изменим значение столбца *ingredients* — вместо списка ингредиентов в каждом рецепте заполним столбец данными о количестве ингредиентов в нём:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>red beans</th>\n",
       "      <th>reduced fat milk</th>\n",
       "      <th>rice syrup</th>\n",
       "      <th>hot bean paste</th>\n",
       "      <th>pecorino cheese</th>\n",
       "      <th>sherry</th>\n",
       "      <th>cane sugar</th>\n",
       "      <th>...</th>\n",
       "      <th>gari</th>\n",
       "      <th>yellow peppers</th>\n",
       "      <th>branzino fillets</th>\n",
       "      <th>baby carrots</th>\n",
       "      <th>white almond bark</th>\n",
       "      <th>spinach</th>\n",
       "      <th>top round steak</th>\n",
       "      <th>chopped parsley</th>\n",
       "      <th>black pepper</th>\n",
       "      <th>star anise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10259</td>\n",
       "      <td>greek</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25693</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20130</td>\n",
       "      <td>filipino</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22213</td>\n",
       "      <td>indian</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13162</td>\n",
       "      <td>indian</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1121</td>\n",
       "      <td>chinese</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>18376</td>\n",
       "      <td>italian</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>17815</td>\n",
       "      <td>italian</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>32878</td>\n",
       "      <td>southern_us</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>24410</td>\n",
       "      <td>british</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1321 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      cuisine  ingredients  red beans  reduced fat milk  rice syrup  \\\n",
       "0    10259        greek            9          0                 0           0   \n",
       "1    25693  southern_us           11          0                 0           0   \n",
       "2    20130     filipino           12          0                 0           0   \n",
       "3    22213       indian            4          0                 0           0   \n",
       "4    13162       indian           20          0                 0           0   \n",
       "..     ...          ...          ...        ...               ...         ...   \n",
       "495   1121      chinese            9          0                 0           0   \n",
       "496  18376      italian            8          0                 0           0   \n",
       "497  17815      italian            8          0                 0           0   \n",
       "498  32878  southern_us           19          0                 0           0   \n",
       "499  24410      british           17          0                 0           0   \n",
       "\n",
       "     hot bean paste  pecorino cheese  sherry  cane sugar  ...  gari  \\\n",
       "0                 0                0       0           0  ...     0   \n",
       "1                 0                0       0           0  ...     0   \n",
       "2                 0                0       0           0  ...     0   \n",
       "3                 0                0       0           0  ...     0   \n",
       "4                 0                0       0           0  ...     0   \n",
       "..              ...              ...     ...         ...  ...   ...   \n",
       "495               0                0       0           0  ...     0   \n",
       "496               0                0       0           0  ...     0   \n",
       "497               0                0       0           0  ...     0   \n",
       "498               0                0       0           0  ...     0   \n",
       "499               0                0       0           0  ...     0   \n",
       "\n",
       "     yellow peppers  branzino fillets  baby carrots  white almond bark  \\\n",
       "0                 0                 0             0                  0   \n",
       "1                 0                 0             0                  0   \n",
       "2                 0                 0             0                  0   \n",
       "3                 0                 0             0                  0   \n",
       "4                 0                 0             0                  0   \n",
       "..              ...               ...           ...                ...   \n",
       "495               0                 0             0                  0   \n",
       "496               0                 0             0                  0   \n",
       "497               0                 0             0                  0   \n",
       "498               0                 0             0                  0   \n",
       "499               0                 0             0                  0   \n",
       "\n",
       "     spinach  top round steak  chopped parsley  black pepper  star anise  \n",
       "0          0                0                0             0           0  \n",
       "1          0                0                0             0           0  \n",
       "2          0                0                0             0           0  \n",
       "3          0                0                0             0           0  \n",
       "4          0                0                0             1           0  \n",
       "..       ...              ...              ...           ...         ...  \n",
       "495        0                0                0             0           0  \n",
       "496        0                0                0             0           0  \n",
       "497        0                0                0             0           0  \n",
       "498        0                0                0             0           0  \n",
       "499        0                0                0             0           0  \n",
       "\n",
       "[500 rows x 1321 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Заменяем список ингредиентов в рецепте на их количество \n",
    "df['ingredients'] = df['ingredients'].apply(len) \n",
    "# Выводим содержимое полученного DataFrame на экран\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6.5 (External resource)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите код для создания списка ids всех блюд, представленных в датафрейме. Нужны только уникальные значения.\n",
    "\n",
    "Порядок id должен совпадать с тем, как они расположены в исходном датафрейме.\n",
    "\n",
    "**Примечание**. Не забудьте импортировать библиотеки и прочитать файл *recipes.csv.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as json\n",
    "import pprint as pprint\n",
    "import pandas as pd\n",
    "\n",
    "# Читаем содержмиое файла и создаем объект df\n",
    "df = pd.read_csv('recipes.csv') \n",
    "\n",
    "# Создаем список уникальных значений id блюд\n",
    "ids = list(df['id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### СОХРАНЯЕМ DATAFRAME В CSV-ФАЙЛЕ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы планируем продолжать работать с **DataFrame**, созданными на основе данных, которые мы получили в *JSON*-формате, то полезно будет сохранить промежуточный **DataFrame** в виде CSV-файла. Для выполнения этой операции воспользуемся известной нам в Pandas функцией *to_csv*():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('recipes.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве основного параметра мы указали имя файла, в котором необходимо сохранить данные. Также мы установили значение параметра index как False. Такая настройка позволит нам не сохранять индексы строк в виде отдельного столбца; в результате не будут загружаться «лишние» данные при открытии файла при помощи функции read_csv()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. JSON. Работаем с pandas. Из pandas в JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "→ Решим обратную задачу и создадим JSON-файл из сохранённого ранее CSV-файла, который получили в конце предыдущего этапа. \n",
    "\n",
    "Начнём с чтения файла и создания DataFrame на его основе:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём DataFrame, читаем данные из файла в переменную df\n",
    "df = pd.read_csv('recipes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, используя только данные из этого файла, нам нужно в точности воссоздать структуру исходного JSON-файла. Мы помним, что после десериализации данные представляли собой список, состоящий из словарей. В каждом словаре хранилась информация о рецепте одного блюда. Каждый словарь состоял из трёх пар \"ключ-значение\". Первая пара содержала название кухни, к которой относилось блюдо, вторая — id блюда, и третья — список ингредиентов входящих в состав блюда.\n",
    "\n",
    "> ✍️ Поскольку по условию задачи мы не можем использовать предыдущие наработки, давайте начнём с создания списка, содержащего перечень id всех блюд, а также списка ингредиентов, встречающихся в рецептах. Эти списки в дальнейшем мы будем использовать для заполнения JSON-структуры.\n",
    "\n",
    "После десериализации JSON-файла мы получили структуру, представляющую собой список, состоящий из словарей. Каждый словарь состоял из трёх пар \"ключ-значение\", при этом в качестве значений выступали:\n",
    "\n",
    "* целое число (id блюда);\n",
    "* строковая величина (тип кухни);\n",
    "* список строковых величин (перечень ингредиентов).\n",
    "\n",
    "Сейчас нам предстоит воссоздать эту структуру, извлекая данные из DataFrame. Для этого необходимо создать:\n",
    "\n",
    "* пустой список new_recipes — для хранения итоговой структуры;\n",
    "* используя код из Задачи 7.1, список ids — для хранения id всех блюд;\n",
    "* используя код из Задачи 7.2, список ingredients — для хранения названий всех ингредиентов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**✍️ Далее необходимо реализовать следующий алгоритм:**\n",
    "\n",
    "1. Написать код функции make_list(), которая принимает на вход строку DataFrame df, содержащую полные данные об одном блюде (в виде Series), и возвращает перечень ингредиентов, входящих в состав этого блюда (в виде списка).\n",
    "2. Организовать цикл с параметром, в котором будут перебираться элементы списка ids. В результате в процессе прохождения цикла параметр должен принять значение id каждого блюда.\n",
    "3. На каждом шаге цикла создать словарь, содержащий три пары \"ключ-значение\":\n",
    "    * ключу \"id\" присвоить текущее значение параметра цикла как целого числа;\n",
    "    * ключу \"cuisine\" присвоить значение соответствующей кухни, которое мы получим, применив фильтр по текущему id к DataFrame df;\n",
    "    * ключу \"ingredients\" присвоить значение списка, воспользовавшись функцией make_list(), созданной на первом шаге алгоритма.\n",
    "4. Каждый созданный словарь добавить к списку new_recipes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём пустой список для хранения итоговой структуры\n",
    "new_recipes = [] \n",
    "# Организуем цикл с параметром current_id\n",
    "for current_id in ids: \n",
    "    # Получаем значение соответствующей кухни, применив фильтр по текущему значению параметра цикла к DataFrame;\n",
    "    cuisine = df[df['id'] == current_id]['cuisine'].iloc[0] \n",
    "    # Получаем перечень ингредиентов, входящих в состав текущего блюда\n",
    "    current_ingredients = make_list(df[df['id'] == current_id]) \n",
    "    # Создаём текущий словарь\n",
    "    current_recipe = {'cuisine': cuisine, 'id': int(current_id), 'ingredients': current_ingredients} \n",
    "    # Добавляем созданный словарь к списку\n",
    "    new_recipes.append(current_recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 7.3 (External resource)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите код функции *make_list*(), которая принимает на вход одну строку DataFrame, содержащую данные об одном рецепте (в виде **Series**), и возвращает перечень ингредиентов этого блюда (в виде списка).\n",
    "\n",
    "Функция *make_list*() должна принимать только один аргумент - row. Это будет строка датафрейма.\n",
    "\n",
    "Не забудьте импортировать необходимые бибилиотеки, считать файл *recipes.csv* и создать список *ingredients*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Читаем содержимое файла и создаем объект df\n",
    "df = pd.read_csv('recipes.csv') \n",
    "# Создаем список уникальных значений ингредиентов\n",
    "ingredients = list(df.columns)[3:]\n",
    "\n",
    "# Определяем имя функции и передаваемые аргументы\n",
    "def make_list(row): \n",
    "    # Создаем пустой список ингредиентов текущего блюда\n",
    "    ingredient_list=[] \n",
    "    # Последовательно перебираем ингредиенты из реестра\n",
    "    for ingredient in ingredients:\n",
    "        # Если текущий ингредиент входит в состав текущего блюда\n",
    "        if row[ingredient].item()==1:\n",
    "            # Добавляем ингредиент в список ингредиентов текущего блюда\n",
    "            ingredient_list.append(ingredient) \n",
    "            \n",
    "    # Возвращаем сформированный список ингредиентов\n",
    "    return ingredient_list\n",
    "\n",
    "# Создаём пустой список для хранения итоговой структуры\n",
    "new_recipes = [] \n",
    "# Организуем цикл с параметром current_id\n",
    "for current_id in ids: \n",
    "    # Получаем значение соответствующей кухни, применив фильтр по текущему значению параметра цикла к DataFrame;\n",
    "    cuisine = df[df['id'] == current_id]['cuisine'].iloc[0] \n",
    "    # Получаем перечень ингредиентов, входящих в состав текущего блюда\n",
    "    current_ingredients = make_list(df[df['id'] == current_id]) \n",
    "    # Создаём текущий словарь\n",
    "    current_recipe = {'cuisine': cuisine, 'id': int(current_id), 'ingredients': current_ingredients} \n",
    "    # Добавляем созданный словарь к списку\n",
    "    new_recipes.append(current_recipe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним сериализацию списка *new_recipes* и запишем полученные данные в файл.\n",
    "\n",
    "Для сериализации  используем функцию *dumps*(), которой в качестве параметра передадим список new_recipes. Запись в файл осуществляется с помощью метода *write*().    \n",
    "Предварительно файл необходимо открыть для записи с помощью функции *open*() c параметром 'w' (от англ. write, рус. писать):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт модуля json\n",
    "import json \n",
    "# Функция dumps() модуля json сериализирует объект Python в строку формата JSON. \n",
    "new_recipes = json.dumps(new_recipes) \n",
    "\n",
    "# Откроем файл new_recipes.json для записи\n",
    "with open(\"data/new_recipes.json\", \"w\") as write_file: \n",
    "    # Записываем содержимое подготовленные данные в файл\n",
    "    write_file.write(new_recipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. XML. Что это?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> → Аббревиатура XML расшифровывается как eXtensible Markup Language — расширяемый язык разметки. Он (язык) позволяет описывать документы, используя теги.\n",
    "\n",
    "Если вы когда-нибудь сталкивались с HTML, языком разметки для создания веб-страниц, то можете заметить, что XML очень похож на него. Однако в отличие от HTML, где теги заранее чётко заданы, в XML мы можем задавать теги сами.\n",
    "\n",
    "Например, если мы хотим описать меню в ресторане в формате XML-документа, мы можем сделать это так:\n",
    "\n",
    "![img](https://lms-cdn.skillfactory.ru/assets/courseware/v1/f92e35f47fa17ac0ddd40efde0e3389d/asset-v1:SkillFactory+DSPR-2.0+14JULY2021+type@asset+block/xml_0.jpg)\n",
    "\n",
    "В примере выше довольно жёсткая структура: у нас есть меню  — тег *menu*, где хранятся объекты, то есть конкретные блюда, помеченные тегом *dish*.    \n",
    "У каждого из блюд есть параметр name, в котором прописано имя блюда. Можно считать, что *dish* — класс этого объекта.\n",
    "\n",
    "Внутри каждого объекта-блюда находится набор значений, которые тоже задаются тегами. Например, внутри тега *price* находится значение 20, означающее цену данного блюда.    \n",
    "Тег *price* и другие теги внутри можно рассматривать как атрибуты класса *dish*.\n",
    "\n",
    "\n",
    "> Файлы XML не всегда имеют жёсткую структуру и не обязаны её иметь, но чаще всего какая-то структура внутри файла будет. Почему? Потому что обычно XML не пишут вручную.    \n",
    "Такие файлы генерируются кодом и читаются тоже кодом. Поэтому при наличии понятной структуры обработка файла становится намного проще."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. XML. Контент XML-файла"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ИЗВЛЕКАЕМ КОНТЕНТ ИЗ XML-ФАЙЛА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные в формате XML имеют древовидную структуру. \n",
    "\n",
    "> Что такое дерево? Это структура, которая имеет узлы и связи между ними. Самый верхнеуровневый узел называется **корнем**, а всё, что находится в самом низу, называется **листьями**. \n",
    "\n",
    "В примере из прошлого юнита корнем является ***menu***, а листьями, например, ***price*** и ***weight***.\n",
    "\n",
    "Кроме того, у ***menu*** есть дети (потомки) — это два узла ***dish***, имеющие разное значение атрибута ***name***.\n",
    "\n",
    "Таким образом, в файле используется набор тегов, внутри которых могут находиться другие теги со своими значениями.\n",
    "\n",
    "Для работы с XML-файлами мы будем использовать модуль *ElementTree* , входящий в стандартный пакет xml. Этот модуль позволит нам «перемещаться» по дереву XML и смотреть, что находится в каждом его узле, начиная с корня и заканчивая листьями.\n",
    "\n",
    "Импортируем этот модуль под псевдонимом *ET*: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем модуль ElementTree\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ✍ Мы будем работать с представленной выше структурой XML-файла.    \n",
    "[Скачайте](https://lms.skillfactory.ru/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block@menu.xml) файл, откройте его и посмотрите на содержимое (можно использовать любой текстовый редактор, например Блокнот).    \n",
    "Скопируйте скачанный файл menu.xml в папку, в которой будете работать (в этой же папке вы будете создавать файлы Jupyter Notebook с кодом и запускать код на выполнение).\n",
    "\n",
    "Для работы со структурой файла menu.xml считаем его содержимое в переменную tree, выполнив код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('data/menu.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### КОРЕНЬ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем в переменную root корневой узел дерева *tree* и посмотрим, как выглядит содержимое переменной *root*, для чего выполним код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'menu' at 0x000001BF557C1D00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "root = tree.getroot()\n",
    "display(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что в корне находится 'menu'. Всё правильно, мы и предполагали увидеть именно это. \n",
    "\n",
    "**Какой тип у этого объекта?**   \n",
    "Если мы вызовем встроенный в Python метод type() и передадим ему root , то увидим, что это тип *xml.etree.ElementTree.Element*. Такой тип будет у любого узла в дереве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xml.etree.ElementTree.Element"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(type(root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ПОТОМКИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для того чтобы посмотреть список потомков корневого узла, выполним следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'dish' at 0x000001BF557C1D50>,\n",
       " <Element 'dish' at 0x000001BF557C1E90>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(list(root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, использование *list(root)* возвращает список потомков указанного узла. У узла *root*, который представляет меню, два потомка, а именно — два блюда, которые представлены тегами *dish*.\n",
    "\n",
    "Для того чтобы получить список потомков второго блюда в нашем меню и вывести его на экран, выполним код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'price' at 0x000001BF557C1EE0>,\n",
       " <Element 'weight' at 0x000001BF557C1F30>,\n",
       " <Element 'class' at 0x000001BF557C1F80>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(list(root[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, у второго потомка узла root —  три потомка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### АТРИБУТЫ И ТЕГИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как было сказано ранее, у узлов могут быть параметры, или атрибуты. Например, у узлов *dish* есть атрибут name, который хранит название блюда.\n",
    "\n",
    "Мы можем непосредственно обратиться к атрибутам, используя *attrib*.\n",
    "\n",
    "Выведем на экран атрибуты первого блюда из меню:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Кура'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(root[0].attrib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В XML-узлах часто хранятся количественные показатели. Эти показатели хранятся в виде текста, и прочитать их можно, обратившись к атрибуту *text* у соответствующего объекта типа *ElementTree.Element*.\n",
    "\n",
    "Например, возьмём узел *price* первого блюда из меню:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'price' at 0x000001BF557C1DA0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(root[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь прочитаем значение этого узла с помощью *text*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(root[0][0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Все значения в XML, даже числовые, хранятся как строки, поэтому преобразовывать их к нужному типу вам нужно самим.\n",
    "\n",
    "Например, в данном случае можно обернуть значение стоимости в *int()* или *float()*.\n",
    "\n",
    "Если вы хотите прочитать наименование тега конкретного узла, необходимо использовать *tag*. Например, получим наименование тега корневого узла:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'menu'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(root.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(root[0][2].tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ИСПОЛЬЗОВАНИЕ ЦИКЛОВ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> → Итак, мы научились обращаться к отдельным узлам дерева, представляющего XML-структуру, и извлекать информацию о его атрибутах, значении и потомках.\n",
    "\n",
    "На этом шаге мы решим задачу вывода на экран наименование всех блюд из меню, а также информацию о них (иными словами, нам необходимо обойти дерево и вывести на экран значения его листьев).\n",
    "\n",
    "Используя цикл for, автоматизируем обход дерева. Для этого напишем следующий код:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кура price 40\n",
      "Кура weight 300\n",
      "Кура class Мясо\n",
      "\n",
      "Греча price 20\n",
      "Греча weight 200\n",
      "Греча class Крупа\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dish in root:\n",
    "    for param in dish:\n",
    "        print(dish.attrib['name'], param.tag, param.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍️ В этом коде реализован следующий алгоритм:\n",
    "\n",
    "1. В первом (внешнем) цикле перебираем потомков корня дерева (root). Потомки перебираются последовательно при помощи переменной dish. Это отдельные блюда из меню.\n",
    "\n",
    "2. Во втором (вложенном) цикле аналогичным образом перебираем потомков каждого блюда. Этими потомками являются параметры блюда — его цена (price), вес (weight) и класс (class).\n",
    "\n",
    "3. После этого выводим на экран название блюда (значение атрибута name), название очередного параметра (tag) и его значение (text).\n",
    "\n",
    "4. Дополнительная функция print() в цикле верхнего уровня предназначена для организации более удобного восприятия информации — между отдельными блюдами будет выведена пустая строка."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. XML. Загружаем, создаем, сохраняем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ЗАГРУЖАЕМ ДАННЫЕ ИЗ XML-ФАЙЛА В DATAFRAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✍ Реализуем следующий алгоритм:\n",
    "\n",
    "1. Загрузить данные из XML-файла *menu.xml* в переменную root.\n",
    "\n",
    "2. Создать пустой список *df_list* (в него будем добавлять строчки итоговой таблицы).\n",
    "\n",
    "3. Заранее создать список *column_names* с именами столбцов — название блюда (*name*), его цена (*price*), вес (*weight*) и класс (*class*).\n",
    "\n",
    "4. В цикле организовать обход xml-дерева из корня по всем потомкам.\n",
    "\n",
    "5. На каждой итерации цикла сформировать в виде списка строку таблицы, содержащую информацию: наименование блюда (атрибут name узла *dish*) и значения потомков этого узла — узлов *price, weight, class*.\n",
    "\n",
    "6. Добавить сформированную строку в список *df_list*, используя метод *append()*.\n",
    "\n",
    "7. Сформировать из вложенного списка **DataFrame**. Имена для столбцов взять из списка *column_names*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>weight</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Кура</td>\n",
       "      <td>40</td>\n",
       "      <td>300</td>\n",
       "      <td>Мясо</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Греча</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>Крупа</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    name price weight  class\n",
       "0   Кура    40    300   Мясо\n",
       "1  Греча    20    200  Крупа"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('data/menu.xml')\n",
    "root = tree.getroot()\n",
    "\n",
    "import pandas as pd\n",
    "column_names = ['name', 'price', 'weight', 'class']\n",
    "df_list = []\n",
    "\n",
    "for dish in root:\n",
    "    row = [dish.attrib['name'], dish[0].text, dish[1].text, dish[2].text]\n",
    "    df_list.append(row)\n",
    "\n",
    "df = pd.DataFrame(df_list, columns=column_names)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### СОЗДАЁМ XML-ФАЙЛ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> → Воссоздадим структуру нашего исходного XML-файла с нуля,  руководствуясь общими рекомендациями.\n",
    "\n",
    "Чтобы создать корень дерева, используем метод *Element*() из класса **ElementTree**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'menu' at 0x000001BF56034220>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "new_root = ET.Element('menu')\n",
    "display(new_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы можем добавлять новые узлы в наше дерево, используя метод *SubElement()* из того же класса.\n",
    "\n",
    "Добавим в наше меню двух потомков корневого узла, которые будут представлять два блюда, то есть будут узлами *dish*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'dish' at 0x000001BF560342C0>,\n",
       " <Element 'dish' at 0x000001BF56034680>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dish1 = ET.SubElement(new_root, 'dish', name='Кура')\n",
    "\n",
    "dish2 = ET.SubElement(new_root, 'dish', name='Греча')\n",
    "\n",
    "display(list(new_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В метод *SubElement()* мы передали первым аргументом узел, к которому добавляем потомка, вторым аргументом — наименование нового тега (*dish*),  третьим аргументом — наименование атрибута нового узла( *name* ) и его значение.\n",
    "\n",
    "> Аналогичным образом можно добавлять новые узлы к любым существующим узлам, не только к корню.\n",
    "\n",
    "\n",
    "Добавим в создаваемую структуру по три потомка (атрибута) к двум новым узлам, которые будут содержать информацию о блюде — о его цене (*price*), весе (*weight*) и классе (*class*), а также значение этих атрибутов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Element 'price' at 0x000001BF54186DE0>,\n",
       " <Element 'weight' at 0x000001BF54186FC0>,\n",
       " <Element 'class' at 0x000001BF644ABEC0>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[<Element 'price' at 0x000001BF54186F20>,\n",
       " <Element 'weight' at 0x000001BF652036A0>,\n",
       " <Element 'class' at 0x000001BF65203600>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "price1 = ET.SubElement(dish1, \"price\").text = \"40\"\n",
    "weight1 = ET.SubElement(dish1, \"weight\").text = \"300\"\n",
    "class1 = ET.SubElement(dish1, \"class\").text = \"Мясо\"\n",
    "display(list(dish1))\n",
    "\n",
    "price2 = ET.SubElement(dish2, \"price\").text = \"20\"\n",
    "weight2 = ET.SubElement(dish2, \"weight\").text = \"200\"\n",
    "class2 = ET.SubElement(dish2, \"class\").text = \"Крупа\"\n",
    "display(list(dish2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим визуально корректность созданной нами структуры, выполнив фрагмент кода, разработанного ранее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кура price 40\n",
      "Кура weight 300\n",
      "Кура class Мясо\n",
      "\n",
      "Греча price 20\n",
      "Греча weight 200\n",
      "Греча class Крупа\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dish in new_root:    \n",
    "    for param in dish:\n",
    "        print(dish.attrib['name'], param.tag, param.text)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### СОХРАНЕНИЕ XML-ФАЙЛА"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> → В финале работы с файлом XML-формата запишем созданную нами структуру как XML-файл на диск.\n",
    "\n",
    "Преобразуем созданный нами объект типа *ElementTree.Element* в строку c помощью метода *tostring()*, передав наше новое дерево как аргумент. Сохраним эту строку на диске, используя стандартные средства Python::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_root_string = ET.tostring(new_root)\n",
    "\n",
    "with open(\"new_menu.xml\", \"wb\") as f:\n",
    "    f.write(new_root_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно, вы увидите проблему, связанную с кодировкой. Что делать в этом случае? Как вариант — записать файл, используя сам класс *ElementTree()* :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ET.ElementTree(new_root).write('new_menu_good.xml', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого мы передаём в класс ElementTree() наше дерево (не его строковое представление) и вызываем метод write(). В метод мы передаём путь к новому файлу и нужную нам кодировку."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
