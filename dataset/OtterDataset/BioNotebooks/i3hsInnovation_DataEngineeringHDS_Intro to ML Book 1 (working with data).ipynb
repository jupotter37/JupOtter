{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./intro_images/HDSbanner.jpg\" width=\"100%\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"float:right;\">\n",
    "    <tr>\n",
    "        <td>                      \n",
    "            <div style=\"text-align: right\"><a href=\"https://alandavies.netlify.com\" target=\"_blank\">Dr Alan Davies</a></div>\n",
    "            <div style=\"text-align: right\">Senior Lecturer health data science</div>\n",
    "            <div style=\"text-align: right\">University of Manchester</div>\n",
    "         </td>\n",
    "         <td>\n",
    "             <img src=\"https://github.com/i3hsInnovation/resources/blob/efa61022d0b8893200dad308f6590e694291f8c7/images/alan.PNG?raw=true\" width=\"30%\" />\n",
    "         </td>\n",
    "     </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Data\n",
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### About this Notebook\n",
    "This notebook introduces the importance of data management and quality especially when using machine learning algorithms.  It will also outline some key tools such as Python and SciKitLearn as well as introduce some useful functions to help you load, sort, filter and see the structure of your data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"><b>Learning Objectives:</b> \n",
    "    \n",
    "- Explain the challenges and opportunities of big data \n",
    "    \n",
    "- Investigate the basic data manipulation stages required to pre-process data for use with machine learning algorithms\n",
    "\n",
    "- Explore some essential Machine Learning Python libraries to implement Machine Learning algorithms\n",
    "\n",
    "- Explain the rationale for choosing different algorithms\n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "<b>Table of contents</b><br/>\n",
    "\n",
    "1.0 [The Data Challenge / Opportunity](#datachallenge)\n",
    "\n",
    "2.0 [Data and Machine Learning](#dataandmachine)\n",
    "\n",
    "3.0 [Using Python](#python)\n",
    "\n",
    "4.0 [Data Visualisation](#datavisualisation)\n",
    "\n",
    "5.0 [Data Distribution and Transformation](#datadistribution)\n",
    "\n",
    "6.0 [Missing Values](#missingvalues)\n",
    "\n",
    "7.0 [Introducing SciKit Learn](#scikit)\n",
    "\n",
    "8.0 [Choosing an Algorithm](#Choosealgorithm)\n",
    "\n",
    "9.0 [Further Reading](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"datachallenge\"></a>\n",
    "\n",
    "## 1.0 The Data Challenge / Opportunity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has been quoted that:<br>\n",
    "<blockquote>\n",
    "    Data is the new oil.<br>\n",
    "       - <i>Clive Humby (2006)</i>\n",
    "</blockquote> \n",
    "This refers to the business value that is derived from the insights gained by applying data-driven analysis to data. This goes beyond the routine analytics of data toward mining the data for patterns and trends that can add real value to a business. What <code>value</code> actually is will depend on the business in question. For healthcare, this could be improved patient outcomes and safety among others. The amount of data that we now have available is increasing dramatically following the prevalence and ubiquity of digital technology. The graph below shows <code>exabytes</code> of data over time. One exabyte = one quintillion bytes ($10^{18}$ bytes). You can see the exponential increase from the year 2009 to 2020. The increase in computing power coupled with the growing amount of data provides us with new opportunities and challenges to make sense of this data and extract value from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./ml_files/datagrowth.jpeg\" width=\"60%\" align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with this <code>big data</code> come increasing challenges for its collection and analysis. Some traditional methods do not work well with the scale of data that is now available. These challenges can be defined as the 4 v's and include; <code>volume</code>, <code>variety</code>, <code>velocity</code> and <code>veracity</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./ml_files/bigdata.jpg\" width=\"100%\" align=\"center\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#top)\n",
    "\n",
    "\n",
    "----------\n",
    "\n",
    "\n",
    "<a id=\"dataandmachine\"></a>\n",
    "\n",
    "## 2. Data and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modern Machine Learning methods are tools that can help with gaining insights from large volumes of data. To work with the various Machine Learning algorithms, you must first be able to manipulate data to ensure that data is in the right format to apply the various algorithms. We typically refer to data used as a <code>dataset</code>. Data can be <code>structured</code> where it is presented in a table like structure with rows and columns. Each row represents a unique record (<code>observation</code>) in the dataset. Data can also be <code>unstructured</code>. Unstructured data can include things like images, text and audio/visual recordings. For this introductory workshop we will be working with structured data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a very small (made up) sample dataset. Here we have a set of <code>features</code> typically denoted with the capital letter <code>X</code>. We also have some <code>labels</code>. These are categories or classes of something (discrete labels) and are often represented with the lower case letter <code>y</code>. In this example we have several groups of people (group 1 or 2) and data on their <code>age</code>, <code>systolic blood pressure</code>, <code>sex</code> and a label that has 3 classes (low, medium and high)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./ml_files/dataset.png\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a go at loading some real data. Below we will load some data about A&E (accident and emergency) Attendances and Emergency Admissions in 2019-20. This data is provided by <code>NHS England</code> and can viewed here <a href=\"https://www.england.nhs.uk/statistics/statistical-work-areas/ae-waiting-times-and-activity/ae-attendances-and-emergency-admissions-2019-20/\" target=\"_bank\">england.nhs.uk</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#top)\n",
    "\n",
    "------------\n",
    "\n",
    "\n",
    "\n",
    "<a id=\"python\"></a>\n",
    "\n",
    "## 3.0 Using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has many pre-written libraries (modules) that have been programmed by others. We can import and use these libraries to save us having to write long and complicated code. There are currently over 221.000 Python libraries available to us that can be used for all kinds of tasks including Machine Learning and data processing. In fact most healthcare data scientists use either Python or R for analysis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <strong>Note:</strong> If you are interested in learning about which analysis and visualisation tools healthcare data scientists use, have a look at this paper: <a href=\"https://academic.oup.com/jamia/article/26/5/383/5369358\" target=\"_blank\">Healthcare data scientist qualifications, skills, and job focus: a content analysis of job postings</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is in the form of a <code>CSV</code> file. This stands for <code>comma separated values</code>. We can use a Python library called <code>pandas</code> to load this type of file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above loads this library. We can access various functions from the library by typing <code>pd</code> followed by a period (full stop) and the name of the function we want to use. In this case we will use the <code>read_csv()</code> function to load our CSV file. We can store this data in a variable which we will call <code>ae_dataset</code>, short for accident emergency dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <strong>Note:</strong> There is <a href=\"https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\" target=\"_blank\">cheat sheet</a> for the Pandas library that you may find useful.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_dataset = pd.read_csv(\"./ml_files/January-2020-CSV-js7fh.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some datasets can be very large. In these cases we wouldn't want to view all the data, as this can take a long time to load. Instead we can view the <code>head</code> of the data. This shows us the first few records so that we can see the structure of the data. There is a useful function for doing this in the pandas library called <code>head()</code> which we use below to display the first few records in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <strong>Note:</strong> There is also a <code>tail()</code> function that works like the <code>head()</code> function only it returns the last n rows of the dataset rather than the first n. For example <code>ae_dataset.tail(5)</code> will output the last 5 rows of the dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 1:</b>\n",
    "<br> \n",
    "1. Have a look at the data presented above. <br>\n",
    "2. Have a look at the <a href=\"https://www.england.nhs.uk/statistics/wp-content/uploads/sites/2/2019/07/AE-Attendances-Emergency-Definitions-v4.0-final-July-2019.pdf\" target=\"_blank\">definitions</a> to try to understand what this data represents. <br/>\n",
    "3. Make a note of these definitions.<br>\n",
    "    4. Try outputting the head of data again using the <code>head()</code> function as above, only this time try adding a number between the brackets. What does this do?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "ae_dataset.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "It outputs the number of records you specify by passing in a number as a parameter to the function. Note this starts at 0 and not 1. So 8 records will be 0 - 7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have some understanding of the data, we can also look at some other properties of the data. Such as the number of observations in the dataset. We can do this with the length function <code>len()</code> which is short for <strong>length</strong>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ae_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that there are 232 observations (records) in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to view the <code>shape</code> of the data set that shows the number of rows (232) and columns (16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_dataset.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two other useful functions are <code>info()</code> and <code>nunique()</code>. \n",
    "<br>\n",
    "The info function will provide an overview of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The nunique function will tell you the number of unique observations in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_dataset.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When dealing with <code>categorical</code> data (data in categories), you can inspect the column by placing the column name in square brackets and quotation marks and then apply the <code>value_counts()</code> function. This will show you how many times a certain value occurs in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_dataset['Org name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For analysis and modeling of data, you may only be interested in a portion of the relevant data. For this we need to extract a <code>subset</code> of the data. Let's say we are only interested in the number of <code>Type 1</code> attendances that are greater than 0 for particular organizations. We can extract just the columns or features we are interested in by specifying them by name within quotation marks (this denotes a text string [text data] in Python). Here we extract just the columns <code>Org name</code> and <code>Number of A&amp;E attendances Type 1</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1 = ae_dataset[[\"Org name\", \"Number of A&E attendances Type 1\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also <code>query</code> and <code>filter</code> the data. For example, we could choose to extract all results where there were more than (>) zero admissions. We can use this to filter the data and view the head of the data as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_zero_admissions = type1[\"Number of A&E attendances Type 1\"] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_filtered = type1[gt_zero_admissions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_filtered.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <strong>Note:</strong> If you click on the little up and down arrows in the table above in the column headings next to the number of attendances, you can order the table in ascending or descending results.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 2:</b>\n",
    "<br> \n",
    "    1. How many rows does the <code>type1_filtered</code> dataset have now? (<strong>Hint:</strong> use the <code>len()</code> function)<br>\n",
    "    2. Using the code above, try filtering the data for <code>Type 2</code> admissions.<br>\n",
    "    3. Display the data using the <code>head()</code> function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "len(type1_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "type2 = ae_dataset[[\"Org name\", \"Number of A&E attendances Type 2\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "type2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 3:</b>\n",
    "<br> \n",
    "1. Filter the results for Task 2 for admissions greater than zero.<br>\n",
    "    2. Display the data using the <code>head()</code> function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "gt_zero_admissions = type2[\"Number of A&E attendances Type 2\"] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "type2_filtered = type2[gt_zero_admissions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "type2_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <strong>Note:</strong> To subset by groups, there is a useful <code>groupby()</code> function. If you want to see some examples, have a look at <a href=\"https://www.geeksforgeeks.org/pandas-groupby/\" target=\"_blank\">this</a>. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also the ability to generate some plots (graphs/charts) of the data in a given dataframe. Below we can see an example of a bar plot on the filtered data for type 1 admissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_filtered.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 4:</b>\n",
    "<br> \n",
    "With reference to the very high value on the right of the plot:<br>\n",
    "1. Look at the original data to try and determine where this very high value is coming from.<br/>\n",
    "    2. <strong>Hint:</strong> use the <code>tail()</code> function that works like the <code>head()</code> function but shows the last few records instead of the first few.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "type1_filtered.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden"
   },
   "source": [
    "Here we can see that this is caused by a row containing totaled data. Let's go ahead and remove this final row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_filtered = type1_filtered[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_filtered.plot.bar();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is still a lot of data here. Let's take a look at the top 10 with the <code>nlargest</code> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten = type1_filtered.nlargest(10, \"Number of A&E attendances Type 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ten.plot.bar(x=\"Org name\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 5:</b>\n",
    "<br> \n",
    "Now let's look at a different dataset which we will revisit several times. This is the <code>pima-indians-diabetes</code> <a href=\"https://www.kaggle.com/kumargh/pimaindiansdiabetescsv/data\" target=\"_blank\">dataset</a> from Kaggle. Click on the dataset link above and read the description of the data fields (columns) in the section called <code>About this file</code> so that you understand what sort of data is contained in the dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we read in the file as a CSV file again and display the first few records with the <code>head()</code> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./ml_files/pima-indians-diabetes.csv\"\n",
    "data = pd.read_csv(path)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at some of the basic statistical properties of the data set with the <code>describe()</code> function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also want to see if there is any <a href=\"https://www.bmj.com/about-bmj/resources-readers/publications/statistics-square-one/11-correlation-and-regression\" target=\"_blank\">correlation</a> between any of our variables to measure the strength of relationship. We can view this using the <code>corr()</code> function from the <code>numpy</code> (numerical Python) library. Here we choose the <code>Pearson</code> correlation coefficient. There is more information on correlation in the notebook about Linear Regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "corr_data = data.corr(method=\"pearson\")\n",
    "corr_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#top)\n",
    "\n",
    "\n",
    "----------------\n",
    "\n",
    "\n",
    "<a id=\"datavisualisation\"></a>\n",
    "\n",
    "\n",
    "## 4.0 Data visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualise data to better understand its structure and to find any relationships between variables in the dataset.\n",
    "We could start by looking at the dispersion and variability of the data with a <code>boxplot</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot.box(rot=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./ml_files/bp.png\" align=\"left\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Source:</strong> towardsdatascience.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<strong>Note:</strong> To see an example of why visualising data is so important, have a look at <code>Anscombe's quartet</code>. Here is a <a href=\"https://en.wikipedia.org/wiki/Anscombe%27s_quartet\" target=\"_blank\">link</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a different library for plotting data called <code>seaborn</code>, we can create a <code>pairs</code> plot to compare all the variables against one another. This can be very useful for visualising relationships between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(data, hue='Class');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have changed the colour <code>hue</code> to represent the different class (either has diabetes 1, or does not have diabetes 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful plotting library that you may come across is <code>matplotlib</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this library to create a single <code>scatter</code> plot for two variables. In this case <code>Glucose</code> and <code>BMI</code> <a href=\"https://www.nhs.uk/live-well/healthy-weight/bmi-calculator/\" target=\"_blank\">(Body Mass Index)</a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data['Glucose'], data['BMI'], c=data['Class']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this plot to make sense, we need to add some additional information like axis labels and a legend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add some colours \n",
    "colours = ListedColormap(['#3886BC','#FF7F0F'])\n",
    "\n",
    "# label the classes so they make sense\n",
    "classes = ['No diabetes','Diabetes']\n",
    "\n",
    "# create the scatter plot\n",
    "scatter = plt.scatter(data['Glucose'], data['BMI'], c=data['Class'], cmap=colours);\n",
    "\n",
    "# add some axis label text\n",
    "plt.xlabel('Glucose');\n",
    "plt.ylabel('BMI');\n",
    "\n",
    "# finally add a legend for the classes\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=classes);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <strong>Note:</strong> The hash <code>#</code> character is used in Python to denote a comment. Comments are not run by the interpreter and are for adding notes/explanations to code. Python also has multi-line comments that can be placed between two sets of triple speech marks i.e. <code>\"\"\" This is multiline comment. \"\"\"</code>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 6:</b>\n",
    "<br> \n",
    "Create scatterplot like the one above for <code>Glucose</code> and <code>Blood pressure</code>.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# add some colours \n",
    "colours = ListedColormap(['#3886BC','#FF7F0F'])\n",
    "\n",
    "# label the classes so they make sense\n",
    "classes = ['No diabetes','Diabetes']\n",
    "\n",
    "# create the scatter plot\n",
    "scatter = plt.scatter(data['Glucose'], data['BloodPressure'], c=data['Class'], cmap=colours);\n",
    "\n",
    "# add some axis label text\n",
    "plt.xlabel('Glucose');\n",
    "plt.ylabel('Blood pressure');\n",
    "\n",
    "# finally add a legend for the classes\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=classes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how may cases are labeled as having and not having diabetes. Remember 0 = \"no diabetes\" and 1 = \"diabetes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a (True/False) list of all the diabetes labels for filtering \n",
    "no = data['Class'] == 0\n",
    "yes = data['Class'] == 1\n",
    "\n",
    "# now count the number times they are labeled as 0 and 1\n",
    "no_diabetes = data['Class'][no].count()\n",
    "diabetes = data['Class'][yes].count()\n",
    "\n",
    "# lets output these values\n",
    "print(\"Number of cases labeled as NOT having diabetes =\",no_diabetes)\n",
    "print(\"Number of cases labeled as having diabetes =\",diabetes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Task 7:</b>\n",
    "<br> \n",
    "    Given this information, display these results with a bar plot using the <code>plt.bar()</code> function.<br>\n",
    "<strong>Hint:</strong> You may want to use following information:<br><br>\n",
    "<code>class_labels = ['No diabetes','Diabetes']</code><br>\n",
    "<code>classes = [no_diabetes, diabetes]</code>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "class_labels = ['No diabetes','Diabetes']\n",
    "classes = [no_diabetes, diabetes]\n",
    "plt.bar(class_labels, classes);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#top)\n",
    "\n",
    "------------\n",
    "\n",
    "\n",
    "<a id=\"datadistribution\"></a>\n",
    "\n",
    "## 5.0 Data Distribution and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of data can effect the subsequent analysis that can be carried out on the data. Certain statistical tests rely on assumptions, such as the data following a <code>normal</code> distribution (sometimes called a bell curve). The code below produces a <code>density</code> plot showing the <code>standard normal</code> distribution. We can use the Probability Density Function (PDF) in the <code>scipy</code> library to do this with a mean of 0 and a standard deviation (SD) of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "dist = np.linspace(-3,3,1000)\n",
    "plt.plot(dist, norm.pdf(dist,0,1))\n",
    "plt.xlabel(\"Values\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualisation of your data is a good way to see what the distribution of that data looks like. More information on common data distributions can be seen <a href=\"https://www.analyticsvidhya.com/blog/2017/09/6-probability-distributions-data-science/\" target=\"_blank\">here</a>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<strong>Note:</strong> Other methods for exploring normal distribution of data include:<br>\n",
    "    <ul>\n",
    "        <li>Looking at the Skew and Kurtosis</li>\n",
    "        <li>Plotting a histogram</li>\n",
    "        <li>A density plot</li>\n",
    "        <li>A QQ (Quantile-Quantile) plot</li>\n",
    "        <li>Using a statistical test i.e. Shapiro-Wilk test</li>\n",
    "    </ul>\n",
    "    <br />\n",
    "    It is often useful to use a combination of these methods to test for normality in a dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already saw how can plot the distribution of data using the <code>pairplot</code> function from the <code>seaborn</code> library earlier. We can also produce histograms of our data using the built in <code>pandas</code> function <code>hist()</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If our data is normally distributed it is said to be <code>parametric</code>, otherwise it is <code>nonparametric</code>. To deal with this as well as for dealing with outliers, we can use a <code>transformation</code>. The idea is that we maintain the relationship between variables while changing the overall unit of measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skewnorm\n",
    "dist = np.linspace(-3,6,1000)\n",
    "plt.plot(dist, skewnorm.pdf(dist,0,1))\n",
    "plt.xlabel(\"Values\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot shows negatively skewed data. You can determine a positive or negative skew by looking at the tail of the distribution. If the tail is pointing to the lower end of the numbers (to the left) then it is negatively skewed. If the tail points to the right it is positively skewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = skewnorm.rvs(a=-5,loc=100,size=10000)  \n",
    "random = random - min(random)      \n",
    "random = random / max(random)      \n",
    "random = random * 100         \n",
    "plt.hist(random,30,density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next plot shows positively skewed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random = skewnorm.rvs(a=5,loc=100,size=10000)  \n",
    "random = random - min(random)      \n",
    "random = random / max(random)      \n",
    "random = random * 100        \n",
    "plt.hist(random,30,density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming data refers to applying a mathematical function to the data to try and normalise the data. Three commonly used transformations include the <code>log transformation</code> $\\text{log}(x_i)$, <code>square root transformation</code> $\\sqrt{x_i}$, <code>reciprocal transformation</code> $\\frac{1}{x_i}$. These 3 methods will help to deal with data that is positively skewed and also with unequal variance in the data. To deal with negatively skewed data one must first <code>reverse score</code> the data and then run one of aforementioned transformations. For more detailed information on how to transform skewed data see this towards data science article <a href=\"https://towardsdatascience.com/transforming-skewed-data-73da4c2d0d16\" target=\"_blank\">Transforming Skewed Data</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#top)\n",
    "\n",
    "\n",
    "------------\n",
    "\n",
    "\n",
    "\n",
    "<a id=\"missingvalues\"></a>\n",
    "\n",
    "## 6.0 Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing values in data can cause many issues including biasing the data, reducing the representativeness of the sample and reducing statistical power. There are two useful functions for dealing with missing data in Python in the pandas library. These are <code>dropna()</code> which removes rows with any columns that have NA or null data values. The second is <code>fillna()</code> which will replace NA and null values with some value. For example the average value in the data i.e. <code>df.fillna(df.mean())</code>. We use these functions in the notebook about Linear Regression if you want to see an example with real data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to learn more about dealing with missing values, have a look at this paper: <a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3668100/\" target=\"_blank\">The prevention and handling of the missing data</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<strong>Note:</strong> When working with data, you should check/consider the following things:<br>\n",
    "    <ul>\n",
    "        <li>Are there any missing data?</li>\n",
    "        <li>What data types the data represent (e.g. categorical, ordinal etc.). For more information see <a href=\"https://towardsdatascience.com/data-types-in-statistics-347e152e8bee\" target=\"_blank\">Types of data</a>.</li>\n",
    "        <li>That the data are not mislabeled or inconsistent</li>\n",
    "        <li>The amount of data and its dimensions (rows/columns) of the dataset</li>\n",
    "        <li>Metadata about the data set (e.g. a data dictionary to define what the columns represent)</li>\n",
    "        <li>The quality of the data, it it good enough to run an analysis? (garbage in = garbage out)</li>\n",
    "        <li>How you intend to analyse it (what are your questions and which tools/techniques will you use)</li>\n",
    "        <li>The distribution of the data (as this may determine which methods you can apply)</li>\n",
    "        <li>Do we need to apply any transformations to the data before we start working with it</li>\n",
    "        <li>Do we need to convert the data from <a href=\"https://www.theanalysisfactor.com/wide-and-long-data/\" target=\"_blank\">wide to long format</a> or the other way around?</li>\n",
    "        <li>How are we going to manage outliers that may skew the results of our analysis?</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#top)\n",
    "\n",
    "\n",
    "----------------\n",
    "\n",
    "<a id=\"scikit\"></a>\n",
    "\n",
    "## 7.0 Introduction Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned previously, Python has many libraries that have already been written for us. This is also true for Machine Learning. The Machine Learning libraries work in a very similar way to one another making it easier to switch between different algorithms. So far we have looked at some essential skills used to process data which we need to use regardless of the machine learning algorithms we go on to use. The Python library that we will be using for the machine learning notebooks is called <code>scikit-learn</code>. You can see the website <a href=\"https://scikit-learn.org/stable/\" target=\"_blank\">Here</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you recall, we said earlier that in Machine Learning we often split the data into features <code>X</code> and labels <code>y</code>. We can do this easily with a technique called <code>integer location indexing</code>. This is where we can use numbers to represent the column names in our dataset. These numbers range from <code>0</code> to the number of columns. If we recall the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the features by using numbers to get all rows and then all but the last column (our labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, 0:-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has extracted the feature data in a format (a matrix) suitable for processing by our machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's extract the labels. Here we will get all rows and just the last column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above will be a common step that we will use when using machine learning algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#top)\n",
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "<a id=\"Choosealgorithm\"></a>\n",
    "\n",
    "## 8.0 Choosing an Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deciding on which Machine Learning algorithm to apply depends on several factors, including the type of data you have, the amount of data and what your aims are. scikit-learn have produced a useful cheat sheet to help you answer some of these questions. Select the link to find the sheet <a href=\"https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\" target=\"_blank\">Choosing the right estimator</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Return to top](#top)\n",
    "\n",
    "\n",
    "---------------\n",
    "\n",
    "<a id=\"Choosealgorithm\"></a>\n",
    "\n",
    "## 9.0 Further Reading\n",
    "\n",
    "Netherton, G. (2018) More Data, More Problems. Lean and Six Sigma Review, Nov 2018: 18(1):10-13 <a href=\"https://search.proquest.com/docview/2158109793?accountid=12253&rfr_id=info%3Axri%2Fsid%3Aprimo\" target=\"_blank\">Link to paper</a>\n",
    "\n",
    "Ekmekci, B., McAnany, C., and Mura, C. (2016) <u><i>An Introduction to Programming for Bioscientists: A Python-Based Primer</u></i> PLOS Computational Biology, June 2016: DOI:10.1371/journal.pcbi.1004867</li>\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "#### Notebook details\n",
    "\n",
    "<i>Notebook created by Dr. Alan Davies with, Frances Hooley and Dr. Jon Parkinson\n",
    "Publish date: September 2020\n",
    "Review date: Semptember 2021</i>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"typeform-share button\" href=\"https://hub11.typeform.com/to/FoThMPWi\" data-mode=\"popup\" style=\"display:inline-block;text-decoration:none;background-color:#3A7685;color:white;cursor:pointer;font-family:Helvetica,Arial,sans-serif;font-size:18px;line-height:45px;text-align:center;margin:0;height:45px;padding:0px 30px;border-radius:22px;max-width:100%;white-space:nowrap;overflow:hidden;text-overflow:ellipsis;font-weight:bold;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;\" target=\"_blank\">Rate this notebook </a> <script> (function() { var qs,js,q,s,d=document, gi=d.getElementById, ce=d.createElement, gt=d.getElementsByTagName, id=\"typef_orm_share\", b=\"https://embed.typeform.com/\"; if(!gi.call(d,id)){ js=ce.call(d,\"script\"); js.id=id; js.src=b+\"embed.js\"; q=gt.call(d,\"script\")[0]; q.parentNode.insertBefore(js,q) } })() </script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
