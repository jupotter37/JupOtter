{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "name": "analysis_clean.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muslim-picnic"
      },
      "source": [
        "# Using Machine Learning to Predict School Dropout in India"
      ],
      "id": "muslim-picnic"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naval-republican"
      },
      "source": [
        "We import the required packages"
      ],
      "id": "naval-republican"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adaptive-governor"
      },
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 100)\n",
        "pd.set_option('display.max_columns', 1500)\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "import pickle"
      ],
      "id": "adaptive-governor",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIWdOn3o621M"
      },
      "source": [
        "We mount the Google Drive"
      ],
      "id": "mIWdOn3o621M"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RitJyEHd6vlS"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "RitJyEHd6vlS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "solved-alaska"
      },
      "source": [
        "Then we set the working directories"
      ],
      "id": "solved-alaska"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seventh-finder"
      },
      "source": [
        "wdir = os.path.join('/your','directory','to','the','project','folder')\n",
        "input_dir = os.path.join(wdir,'data','input')\n",
        "outut_dir = os.path.join(wdir,'data','output')"
      ],
      "id": "seventh-finder",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "representative-tuner"
      },
      "source": [
        "## Individual Level Data"
      ],
      "id": "representative-tuner"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "facial-challenge"
      },
      "source": [
        "We read the India Human Development Survey data. This dataset contains both waves (2005 and 2001-20012) of the IHDS. Mong various topics, it covers education and has extensive information about current students. It is also possible to link information from school and village survey."
      ],
      "id": "facial-challenge"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "respiratory-johnston"
      },
      "source": [
        "data_ind_raw = pd.read_feather(os.path.join(input_dir,'ind_data_2.feather'))"
      ],
      "id": "respiratory-johnston",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "above-attempt"
      },
      "source": [
        "### Data Cleaning and Variable Selection"
      ],
      "id": "above-attempt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "living-aggregate"
      },
      "source": [
        "This data has many interesting variables, but only a small subset is relevant for our problem given that this information should be available to school principals. We select interesting variables and rename them so that their meaning can be inferred directly from the variable name."
      ],
      "id": "living-aggregate"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "friendly-norfolk"
      },
      "source": [
        "ind_rename_dict = {'HHBASE':'hh_id',\n",
        "                   'HHSPLITID':'hh_split_id',\n",
        "                   'PBASE':'person_id',\n",
        "                   'STATEID':'state_id',\n",
        "                   'DISTID':'district_id',\n",
        "                   'PSUID':'village_id',\n",
        "                   'PWAVES':'waves_present',\n",
        "                   'SURVEY':'wave',\n",
        "                   'URBAN4':'area_type',\n",
        "                   'METRO6':'largest_6_metros',\n",
        "                   'RO3':'sex', \n",
        "                   'RO5':'age', \n",
        "                   'RO9':'father_id',\n",
        "                   'RO10':'mother_id',\n",
        "                   'ED5':'enrolled',\n",
        "                   'ED6':'completed_edu_years',\n",
        "                   'ED7':'ever_repeated',\n",
        "                   'CS4':'school_type',\n",
        "                   'CS5':'school_distance',\n",
        "                   'CS9':'year_eng_taught',\n",
        "                   'CS10':'school_hrs_week',\n",
        "                   'CS11':'hw_hrs_week',\n",
        "                   'CS12':'pvt_tuitions_hrs_week',\n",
        "                   'CS13':'days_absent',\n",
        "                   'CS14Y':'mid_day_meal',\n",
        "                   'CS21':'free_books',\n",
        "                   'CS22':'govt_school_fees',\n",
        "                   'CS23':'free_uniform',\n",
        "                   'CS24Y':'scholarship',\n",
        "                   'CS25':'spent_school_fees',\n",
        "                   'CS26_27':'spent_other',\n",
        "                   'CS28':'spent_pvt_tuitions',\n",
        "                   'CH15':'average_student',\n",
        "                   'CH17':'num_of_repeats',\n",
        "                   'CH18':'ever_praised',\n",
        "                   'CH19':'ever_beaten'\n",
        "                  }"
      ],
      "id": "friendly-norfolk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sapphire-millennium"
      },
      "source": [
        "data_ind = data_ind_raw[ind_rename_dict.keys()]\n",
        "data_ind_renamed = data_ind.rename(columns=ind_rename_dict)"
      ],
      "id": "sapphire-millennium",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "occasional-louisville"
      },
      "source": [
        "We create a unique idetifier for each individual and we create two new variables to link respondents to their parents."
      ],
      "id": "occasional-louisville"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yellow-nature"
      },
      "source": [
        "data_ind_renamed['hh_id'] = data_ind_renamed['hh_id'].astype(int).astype(str)\n",
        "data_ind_renamed['person_id'] = data_ind_renamed['person_id'].astype(int).astype(str)"
      ],
      "id": "yellow-nature",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "female-circuit"
      },
      "source": [
        "data_ind_renamed['respid'] = data_ind_renamed['hh_id'] + data_ind_renamed['person_id']\n",
        "data_ind_renamed['father_respid'] = data_ind_renamed['hh_id'] + data_ind_renamed['father_id'].astype(str)\n",
        "data_ind_renamed['mother_respid'] = data_ind_renamed['hh_id'] + data_ind_renamed['mother_id'].astype(str)"
      ],
      "id": "female-circuit",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gentle-terrorism"
      },
      "source": [
        "data_ind_renamed['father_respid'] = data_ind_renamed['father_respid'].str.replace('nan','').str.replace('\\.0','')\n",
        "data_ind_renamed['mother_respid'] = data_ind_renamed['mother_respid'].str.replace('nan','').str.replace('\\.0','')"
      ],
      "id": "gentle-terrorism",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opponent-burlington"
      },
      "source": [
        "We know recode categorical variables, assigning integer values to each category. While recoding the data in this way we also create a dictionary to keep track of the mapping between categories and integer values."
      ],
      "id": "opponent-burlington"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veterinary-jones"
      },
      "source": [
        "def recode_cats(data):\n",
        "\n",
        "    '''\n",
        "        Returns a data frame where categorical columns have been converted to integers and\n",
        "        a dictionary that maps categories to numerical values.\n",
        "        Arguments:\n",
        "            data is a dataframe\n",
        "        Returns:\n",
        "            a dataframe and a dictionary\n",
        "    '''\n",
        "\n",
        "    recode_dict = {}\n",
        "    cat_cols = data.columns[data.dtypes == 'category']\n",
        "\n",
        "    for col in cat_cols:\n",
        "        categories = data[col].cat.categories\n",
        "        recode_dict[col] = dict(zip(categories,range(len(categories))))\n",
        "    \n",
        "    data = data.replace(to_replace = recode_dict)\n",
        "    \n",
        "    return (data,recode_dict)"
      ],
      "id": "veterinary-jones",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unusual-planning"
      },
      "source": [
        "data_ind_recoded, recode_ind_dict = recode_cats(data_ind_renamed)"
      ],
      "id": "unusual-planning",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prepared-syndication"
      },
      "source": [
        "We won't be using information from the second wave (at least for the moment). We thus subset the data to keep only observation from wave 1. The idea is that we cannot build a model to predict dropout using information from the future (relative to the time of prediction)."
      ],
      "id": "prepared-syndication"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nervous-implementation"
      },
      "source": [
        "data_ind_w1 = data_ind_recoded[data_ind_recoded.wave == 0].copy()"
      ],
      "id": "nervous-implementation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atmospheric-input"
      },
      "source": [
        "## Linking Parents' Info"
      ],
      "id": "atmospheric-input"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRtEhxGb4M9i"
      },
      "source": [
        "As I mentioned before, we wish to merge individual information with parents' information which should prove useful to model each kid's social and economic background. To create the combined dataframe, we first create two separate dataframes for mothers and fathers, then, using the unique ids we generated in the previous step, we can merge all individuals with their parents (if they are in the data)."
      ],
      "id": "YRtEhxGb4M9i"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "binding-purple"
      },
      "source": [
        "parents_features = ['respid','age','completed_edu_years']\n",
        "\n",
        "data_ind_w1 = data_ind_w1.merge(data_ind_w1[parents_features].rename(columns={'respid':'father_respid',\n",
        "                                                                              'age':'father_age',\n",
        "                                                                              'completed_edu_years':'father_edu'}),\n",
        "                                on='father_respid',\n",
        "                                how='left')\n",
        "\n",
        "data_ind_w1 = data_ind_w1.merge(data_ind_w1[parents_features].rename(columns={'respid':'mother_respid',\n",
        "                                                                              'age':'mother_age',\n",
        "                                                                              'completed_edu_years':'mother_edu'}),\n",
        "                                on='mother_respid',\n",
        "                                how='left')"
      ],
      "id": "binding-purple",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1LkBm-t6ccC"
      },
      "source": [
        "## Who's at Risk of Dropping Out?"
      ],
      "id": "T1LkBm-t6ccC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "latest-vertex"
      },
      "source": [
        "Only kids who were still in education in the first wave are at risk of droppng out. We are thus not interested in individuals who were out of education in the first wave, and can drop them from the sample."
      ],
      "id": "latest-vertex"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alone-disorder"
      },
      "source": [
        "students_data = data_ind_w1[data_ind_w1.enrolled == 1]"
      ],
      "id": "alone-disorder",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "international-donor"
      },
      "source": [
        "The only information from wave 2 we want to preserve is whether the respondent is still enrolled in education and how many years they have completed. This infomation allows us to identify respondents who dropped out in the period between waves and to determine at what grade they did so. "
      ],
      "id": "international-donor"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "automotive-celtic"
      },
      "source": [
        "enrolled_w2 = data_ind_recoded.loc[data_ind_recoded.wave == 1,\n",
        "                                   ['respid','enrolled','completed_edu_years']].rename(columns={'enrolled':'enrolled_w2',\n",
        "                                                                                                'completed_edu_years':'final_edu'})"
      ],
      "id": "automotive-celtic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "friendly-sense"
      },
      "source": [
        "students_data = students_data.merge(enrolled_w2,on='respid')"
      ],
      "id": "friendly-sense",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coated-biology"
      },
      "source": [
        "To construct our target variable, we need to know whether students enrolled in wave 1 left education before wave 2 and when they left. We thus drop observations for which this information is not available. "
      ],
      "id": "coated-biology"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "looking-familiar"
      },
      "source": [
        "students_data = students_data.dropna(subset=['enrolled_w2','final_edu'])"
      ],
      "id": "looking-familiar",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hindu-recovery"
      },
      "source": [
        "## Household Level Data"
      ],
      "id": "hindu-recovery"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dHb5wNk8fIa"
      },
      "source": [
        "We have a set of variables for the kids, and their parents. There is however, a third set of variables which may prove relevant, information on the kid's household. This information is stored in a different dataset, which we thus need to import, clean, and then merge."
      ],
      "id": "-dHb5wNk8fIa"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "split-split"
      },
      "source": [
        "data_hh_raw = pd.read_feather(os.path.join(input_dir,'house_data_1.feather'))"
      ],
      "id": "split-split",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYPS-OPp833J"
      },
      "source": [
        "We again select just a subset of the available variables and give them intuitive names."
      ],
      "id": "tYPS-OPp833J"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urban-point"
      },
      "source": [
        "hh_rename_dict = {'HHBASE':'hh_id',\n",
        "                  'XGROUPS6':'caste_religion',\n",
        "                  'XID14':'main_income_source',\n",
        "                  'XID15':'years_in_place',\n",
        "                  'XDB5':'total_debt',\n",
        "                  'XCI7S':'confidence_schools',\n",
        "                  'XASSETS5':'std_of_living_quint',\n",
        "                  'XINCOME5':'income_quint',\n",
        "                  'XNPERSONS':'hh_size',\n",
        "                  'XNCHILDM':'boys_0_14',\n",
        "                  'XNCHILDF':'girls_0_14',\n",
        "                  'XNTEENM':'boys_15_21',\n",
        "                  'XNTEENF':'girls_15_21',\n",
        "                  'XNELDERM':'men_over_60',\n",
        "                  'XNELDERF':'women_over_60',\n",
        "                  'XNWKSALARY':'num_emp_with_salary',\n",
        "                  'XCG1':'owns_house',\n",
        "                  'XCG4':'owns_bicycle',\n",
        "                  'XCGVEHICLE':'owns_vehicle',\n",
        "                  'XCG5':'owns_sewing_mac',\n",
        "                  'XCG6':'owns_generator',\n",
        "                  'XCG7':'owns_mixer',\n",
        "                  'XCG8':'owns_motor_cycle',\n",
        "                  'XCGMOTORV':'owns_motor_vehicle',\n",
        "                  'XCGTV':'owns_tv',\n",
        "                  'XCG11':'owns_air_cooler', \n",
        "                  'XCG12':'owns_watch', \n",
        "                  'XCG13':'owns_electric_fan',\n",
        "                  'XCG14':'owns_chair_table',\n",
        "                  'XCG15':'owns_cot',\n",
        "                  'XCG16':'owns_telephone',\n",
        "                  'XCG17':'owns_mobile_phone',\n",
        "                  'XCG18':'owns_fridge',\n",
        "                  'XCG19':'owns_pressure_cooker',\n",
        "                  'XCG23':'owns_washing_mac',\n",
        "                  'XCG24':'owns_computer',\n",
        "                  'XCG26':'owns_credit_card',\n",
        "                  'XCG28':'owns_two_clothes',\n",
        "                  'XCG29':'owns_footwear'\n",
        "                 }"
      ],
      "id": "urban-point",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dietary-jones"
      },
      "source": [
        "data_hh = data_hh_raw[hh_rename_dict.keys()]\n",
        "data_hh_renamed = data_hh.rename(columns=hh_rename_dict)\n",
        "data_hh_renamed['hh_id'] = data_hh_renamed['hh_id'].astype(int).astype(str)"
      ],
      "id": "dietary-jones",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81bYlxzY9a2q"
      },
      "source": [
        "There are some households with multiple records, we thus remove duplicates."
      ],
      "id": "81bYlxzY9a2q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "endless-socket"
      },
      "source": [
        "data_hh_renamed = data_hh_renamed.drop_duplicates(['hh_id','std_of_living_quint','income_quint','hh_size'])"
      ],
      "id": "endless-socket",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85WNGqKd9lrO"
      },
      "source": [
        "We recode the categorical variables with numeric values and store the mapping into a dictionary as before."
      ],
      "id": "85WNGqKd9lrO"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "developing-shepherd"
      },
      "source": [
        "data_hh_recoded, recode_hh_dict = recode_cats(data_hh_renamed)"
      ],
      "id": "developing-shepherd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORjjxKd990Hd"
      },
      "source": [
        "Finally, we merge the houseold data with the students' data"
      ],
      "id": "ORjjxKd990Hd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "appreciated-rubber"
      },
      "source": [
        "students_data = students_data.merge(data_hh_recoded, on='hh_id', how='left')"
      ],
      "id": "appreciated-rubber",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA1THBim99T2"
      },
      "source": [
        "## Building the Target Variable"
      ],
      "id": "cA1THBim99T2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "operational-objective"
      },
      "source": [
        "We are finally ready to build the target variable: whether a kid left education before grade 9."
      ],
      "id": "operational-objective"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clear-simulation"
      },
      "source": [
        "students_data['left_edu'] = students_data['enrolled'] - students_data['enrolled_w2'] "
      ],
      "id": "clear-simulation",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "electrical-bunch"
      },
      "source": [
        "left_before_9th_old = (students_data['left_edu'] == 1) & (students_data['completed_edu_years'] <9)"
      ],
      "id": "electrical-bunch",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwm7j2ZC-bnI"
      },
      "source": [
        "left_before_9th = (students_data['left_edu'] == 1) & (students_data['final_edu'] <9)"
      ],
      "id": "qwm7j2ZC-bnI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "billion-blackberry"
      },
      "source": [
        "students_data['left_before_9th'] = students_data['left_edu'].where(left_before_9th,0)"
      ],
      "id": "billion-blackberry",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCg4IzZvFFoM"
      },
      "source": [
        "## Selecting Predictors and Cleaning the Data\n",
        "We select only some of the the predictors based on what variables seem relevant and which ones are likely to be potentially available to school principals. You'll see an additional list of additional household predictors. I have tried adding those to the models but the performance did not significantly improve. In the interest of parsimony, I decided to drop them."
      ],
      "id": "aCg4IzZvFFoM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "useful-territory"
      },
      "source": [
        "ind_predictors = ['state_id','area_type','largest_6_metros','sex','age',\n",
        "                  'ever_repeated','school_type','school_distance','year_eng_taught',\n",
        "                  'school_hrs_week','hw_hrs_week','pvt_tuitions_hrs_week','days_absent',\n",
        "                  'mid_day_meal','free_books','govt_school_fees','free_uniform','scholarship',\n",
        "                  'spent_school_fees','spent_other','spent_pvt_tuitions','average_student',\n",
        "                  'num_of_repeats','ever_praised','ever_beaten']\n",
        "\n",
        "parent_predictors = ['father_age','father_edu','mother_age','mother_edu']\n",
        "\n",
        "hh_predictors = ['std_of_living_quint','income_quint','hh_size','caste_religion','main_income_source',\n",
        "                 'years_in_place','total_debt','confidence_schools','boys_0_14','girls_0_14',\n",
        "                 'boys_15_21','girls_15_21','men_over_60','women_over_60','num_emp_with_salary']\n",
        "\n",
        "add_hh_predictors = ['owns_house','owns_bicycle','owns_vehicle','owns_sewing_mac',\n",
        "                     'owns_generator','owns_mixer','owns_motor_cycle','owns_motor_vehicle',\n",
        "                     'owns_tv','owns_air_cooler','owns_watch','owns_electric_fan',\n",
        "                     'owns_chair_table','owns_cot','owns_telephone','owns_mobile_phone',\n",
        "                     'owns_fridge','owns_pressure_cooker','owns_washing_mac','owns_computer',\n",
        "                     'owns_credit_card','owns_two_clothes','owns_footwear']\n",
        "\n",
        "predictors = ind_predictors + parent_predictors + hh_predictors\n",
        "\n",
        "cat_exceptions = ['year_eng_taught']"
      ],
      "id": "useful-territory",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz8AtN1uHiOS"
      },
      "source": [
        "The preprocessing function performs the following operations on the data:\n",
        "\n",
        "1.   It standardises continous features using the mean and the standard deviation for the training set;\n",
        "2.   I fills NA for continuous features with the training set mean;\n",
        "3.   It fills NA for categorical features with the value 9999;\n",
        "4.   It applies one-hot-encoding to all categorical features.\n",
        "\n"
      ],
      "id": "Gz8AtN1uHiOS"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "horizontal-third"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def preprocess(data,cat_cols,test=False,scaler=None):\n",
        "    \n",
        "    '''\n",
        "        Returns the original numpy array on which we have performed as set of preprocessing operations.\n",
        "        Arguments:\n",
        "            data is a dataframe\n",
        "            cat_cols is a list-like object listing categorical columns in data\n",
        "            test is a boolean indicating whether the data passed is from the test set\n",
        "            scaler is an instance of scikit learn StandardScaler class, needed only for the test set\n",
        "        Returns:\n",
        "            a numpy array\n",
        "            the scaler\n",
        "    '''\n",
        "    \n",
        "    non_cat_cols = [col for col in data.columns if col not in cat_cols]\n",
        "    \n",
        "    cat_features = data[cat_cols]\n",
        "    non_cat_features = data[non_cat_cols]\n",
        "    \n",
        "    if test:\n",
        "        non_cat_features_st = pd.DataFrame(scaler.transform(non_cat_features))\n",
        "    else:\n",
        "        scaler = StandardScaler()\n",
        "        non_cat_features_st = pd.DataFrame(scaler.fit_transform(non_cat_features))\n",
        "        \n",
        "    non_cat_features_st.columns = non_cat_features.columns\n",
        "    non_cat_features_st = non_cat_features_st.fillna(0)\n",
        "    \n",
        "    cat_features = cat_features.fillna(9999)\n",
        "    dummy_cat_features = pd.get_dummies(cat_features,columns=cat_cols).reset_index(drop=True)\n",
        "\n",
        "    prepro_data = pd.concat([non_cat_features_st,dummy_cat_features],axis=1)\n",
        "        \n",
        "    return (prepro_data,scaler)"
      ],
      "id": "horizontal-third",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MmhOv0rJtMB"
      },
      "source": [
        "We import some additional modules from sklearn and create the preprocessed training and test sets using a 0.9 - 0.1 split."
      ],
      "id": "8MmhOv0rJtMB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dutch-fighter"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn import tree\n",
        "from sklearn import svm\n",
        "\n",
        "X = students_data.loc[:,predictors]\n",
        "y = students_data.iloc[:,-1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "cat_cols = [col for col in X_train.columns if col in recode_ind_dict.keys()]\n",
        "cat_cols = cat_cols + [col for col in X_train.columns if col in recode_hh_dict.keys()]\n",
        "cat_cols = list(set(cat_cols) - set(cat_exceptions))\n",
        "X_train_pp, scaler = preprocess(X_train, cat_cols)\n",
        "X_test_pp, _ = preprocess(X_test, cat_cols, test=True, scaler=scaler)"
      ],
      "id": "dutch-fighter",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFkYdXXbIV73"
      },
      "source": [
        "The last thing we need to do is to build a performance dictionary to store the performace metrics for all the models."
      ],
      "id": "yFkYdXXbIV73"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDl2MtcxIUVg"
      },
      "source": [
        "perform_dict = {}"
      ],
      "id": "VDl2MtcxIUVg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0A--IqworK-"
      },
      "source": [
        "def find_treshold(clf,X,y,is_nn=False):\n",
        "\n",
        "  recall = 0\n",
        "  threshold = 0\n",
        "  change = 0.00001\n",
        "  i = 0\n",
        "  update = 1\n",
        "\n",
        "  if is_nn:\n",
        "    scores = model(X.to(device))\n",
        "\n",
        "  while not (recall >= 0.7 and recall < 0.72):\n",
        "\n",
        "    if abs(update) < 0.001:\n",
        "      change *= 1.1\n",
        "    if abs(update) > 0.005:\n",
        "      change *= 0.9\n",
        "\n",
        "    if recall - 0.7 > 0:\n",
        "      threshold -= change\n",
        "    else:\n",
        "      threshold += change\n",
        "\n",
        "    if is_nn:\n",
        "      y_pred = torch.where(scores[:,0] > threshold, 0, 1).cpu().detach().numpy()\n",
        "    else:\n",
        "      y_pred = np.where(clf.predict_proba(X)[:,0] > threshold, 0, 1)\n",
        "\n",
        "    update = recall_score(y, y_pred) - recall\n",
        "    recall += update\n",
        "    i +=1\n",
        "\n",
        "    if i%10 == 9:\n",
        "      print(f'Threshold: {threshold}, Recall: {recall}')\n",
        "\n",
        "  print(f'Final Threshold: {threshold}, Final Recall: {recall}')\n",
        "  return threshold\n"
      ],
      "id": "M0A--IqworK-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKD-WEgn_Blt"
      },
      "source": [
        "## Defining the Baseline\n",
        "\n",
        "Because this is a binary classification task, a decision three seems a good model to use as the baseline. I tuned the three's depth with cross validation and selected a value of 7 and, given this value, I select the cost-complexity-pruning alpha paramer using the `cost_complexity_pruning_path` function in sklearn and 5-folds cross validation."
      ],
      "id": "UKD-WEgn_Blt"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HK9bM1efwAJL"
      },
      "source": [
        "def automatic_dt_pruning(dt_classifier, X, y):\n",
        "    \"\"\"\n",
        "    Returns the pruning parameter (i.e., ccp_alpha) with the highest cross-validated accuracy\n",
        "\n",
        "    Args:\n",
        "        dt_classifier           : An Sklearn DecisionTreeClassifier (e.g., created by \"tree.DecisionTreeClassifier(criterion='entropy')\")      \n",
        "        X (Pandas.DataFrame)    : Input Features\n",
        "        y (Pandas.Series)       : Labels\n",
        "\n",
        "\n",
        "    Returns:\n",
        "        best_ccp_alpha : Tuned pruning paramter with highest cross-validated accuracy\n",
        "\n",
        "    Notes:\n",
        "        1. Don't change any other Decision Tree Classifier parameters other than ccp_alpha\n",
        "        2. Use the sklearn.model_selection.cross_val_score to find the cross-validation accuracies\n",
        "        3. For cross_val_score, please use 5-fold cross validation\n",
        "    \"\"\"\n",
        "\n",
        "    np.random.seed(42)\n",
        "    ccp_alphas = dt_classifier.cost_complexity_pruning_path(X, y)['ccp_alphas']\n",
        "    scores = []\n",
        "    print(f'Trying {len(ccp_alphas)} values for alpha')\n",
        "\n",
        "    for ccp_alpha in ccp_alphas :\n",
        "      dt_classifier.set_params(ccp_alpha=ccp_alpha)\n",
        "      score = cross_val_score(dt_classifier,X,y,cv=5).mean()\n",
        "      scores.append(score)\n",
        "\n",
        "    return ccp_alphas[np.argmax(scores)]"
      ],
      "id": "HK9bM1efwAJL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "behind-transcript"
      },
      "source": [
        "clf = DecisionTreeClassifier(random_state=0, max_depth=7, class_weight='balanced')\n",
        "#ccp_alpha = automatic_dt_pruning(clf, X_train_pp, y_train)\n",
        "print(f'The best value for ccp alpha is: {ccp_alpha}')\n",
        "clf.set_params(ccp_alpha=ccp_alpha)\n",
        "clf.fit(X_train_pp,y_train)"
      ],
      "id": "behind-transcript",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHcDeK1PNSj_"
      },
      "source": [
        "threshold = find_treshold(clf,X_test_pp,y_test)\n",
        "start_time = time.time()\n",
        "y_train_pred = np.where(clf.predict_proba(X_train_pp)[:,0] > threshold, 0, 1)\n",
        "y_test_pred = np.where(clf.predict_proba(X_test_pp)[:,0] > threshold, 0, 1)\n",
        "prediction_time = round(time.time() - start_time,3)"
      ],
      "id": "tHcDeK1PNSj_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbAoXz18Ekkw"
      },
      "source": [
        "p = pickle.dumps(clf)\n",
        "model_size = sys.getsizeof(p)/(1024**2)\n",
        "\n",
        "accuracy_train = round(accuracy_score(y_train, y_train_pred),3)\n",
        "precision_train = round(precision_score(y_train, y_train_pred),3)\n",
        "recall_train = round(recall_score(y_train, y_train_pred),3)\n",
        "f1_score_train = round(f1_score(y_train, y_train_pred),3)\n",
        "roc_auc_train = round(roc_auc_score(y_train, y_train_pred),3)\n",
        "pct_positive_train = round((sum(y_train_pred)/len(y_train_pred))*100,3)\n",
        "\n",
        "accuracy_test = round(accuracy_score(y_test, y_test_pred),3)\n",
        "precision_test = round(precision_score(y_test, y_test_pred),3)\n",
        "recall_test = round(recall_score(y_test, y_test_pred),3)\n",
        "f1_score_test = round(f1_score(y_test, y_test_pred),3)\n",
        "roc_auc_test = round(roc_auc_score(y_test, y_test_pred),3)\n",
        "pct_positive_test = round((sum(y_test_pred)/len(y_test_pred))*100,3)\n",
        "\n",
        "perform_dict['Decision Tree'] = {'Training':{'Accuracy':accuracy_train,\n",
        "                                             'Recall':recall_train,\n",
        "                                              'Precision':precision_train,\n",
        "                                              'F1-Score':f1_score_train,\n",
        "                                              'ROC AUC':roc_auc_train,\n",
        "                                              'Pct. Positive':pct_positive_train},\n",
        "                                  'Test':{'Accuracy':accuracy_test,\n",
        "                                          'Recall':recall_test,\n",
        "                                          'Precision':precision_test,\n",
        "                                          'F1-Score':f1_score_test,\n",
        "                                          'ROC AUC':roc_auc_test,\n",
        "                                          'Pct. Positive':pct_positive_test},\n",
        "                                  'Model':{'Prediction Time':prediction_time,\n",
        "                                           'Model Size':model_size}}\n",
        "\n",
        "print(f'Model Prediction Time: {prediction_time} Seconds')\n",
        "if model_size > 1:\n",
        "  print(f'Model Size: {round(model_size,3)} MB')\n",
        "else:\n",
        "  print(f'Model Size: {round(model_size*1024)} KB')\n",
        "\n",
        "print(f'We are classifying {pct_positive_test}% of the test observations as positive.\\n')\n",
        "\n",
        "print(f'Test Accuracy: {accuracy_test}, Test F1 Score: {f1_score_test}')\n",
        "print(f'Test Precision: {precision_test}, Test Recall: {recall_test}')\n",
        "print(f'Test Area Under the ROC Curve: {roc_auc_test}\\n')\n",
        "\n",
        "print(f'We are classifying {pct_positive_train}% of the training observations as positive.\\n')\n",
        "\n",
        "print(f'Train Accuracy: {accuracy_train}, Train F1 Score: {f1_score_train}')\n",
        "print(f'Train Precision: {precision_train}, Train Recall: {recall_train}')\n",
        "\n",
        "print(f'Train Area Under the ROC Curve: {roc_auc_train}')"
      ],
      "id": "fbAoXz18Ekkw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSN_YG0ACKZL"
      },
      "source": [
        "## Exploring Different Models\n",
        "\n",
        "The first alternative algorithm we tried is AdaBoost with 500 logistic regressions as base estimators."
      ],
      "id": "YSN_YG0ACKZL"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBMGgbagEcd0"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "clf = AdaBoostClassifier(base_estimator=LogisticRegression(),\n",
        "                         n_estimators=500, random_state=0)\n",
        "\n",
        "clf.fit(X_train_pp,y_train)"
      ],
      "id": "fBMGgbagEcd0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLEK-O4SM7li"
      },
      "source": [
        "threshold = find_treshold(clf,X_test_pp,y_test)\n",
        "start_time = time.time()\n",
        "y_train_pred = np.where(clf.predict_proba(X_train_pp)[:,0] > threshold, 0, 1)\n",
        "y_test_pred = np.where(clf.predict_proba(X_test_pp)[:,0] > threshold, 0, 1)\n",
        "prediction_time = round(time.time() - start_time,3)"
      ],
      "id": "nLEK-O4SM7li",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0dLHXL9EeGL"
      },
      "source": [
        "p = pickle.dumps(clf)\n",
        "model_size = sys.getsizeof(p)/(1024**2)\n",
        "\n",
        "accuracy_train = round(accuracy_score(y_train, y_train_pred),3)\n",
        "precision_train = round(precision_score(y_train, y_train_pred),3)\n",
        "recall_train = round(recall_score(y_train, y_train_pred),3)\n",
        "f1_score_train = round(f1_score(y_train, y_train_pred),3)\n",
        "roc_auc_train = round(roc_auc_score(y_train, y_train_pred),3)\n",
        "pct_positive_train = round((sum(y_train_pred)/len(y_train_pred))*100,3)\n",
        "\n",
        "accuracy_test = round(accuracy_score(y_test, y_test_pred),3)\n",
        "precision_test = round(precision_score(y_test, y_test_pred),3)\n",
        "recall_test = round(recall_score(y_test, y_test_pred),3)\n",
        "f1_score_test = round(f1_score(y_test, y_test_pred),3)\n",
        "roc_auc_test = round(roc_auc_score(y_test, y_test_pred),3)\n",
        "pct_positive_test = round((sum(y_test_pred)/len(y_test_pred))*100,3)\n",
        "\n",
        "perform_dict['AdaBoost'] = {'Training':{'Accuracy':accuracy_train,\n",
        "                                        'Recall':recall_train,\n",
        "                                              'Precision':precision_train,\n",
        "                                              'F1-Score':f1_score_train,\n",
        "                                              'ROC AUC':roc_auc_train,\n",
        "                                              'Pct. Positive':pct_positive_train},\n",
        "                                  'Test':{'Accuracy':accuracy_test,\n",
        "                                          'Recall':recall_test,\n",
        "                                          'Precision':precision_test,\n",
        "                                          'F1-Score':f1_score_test,\n",
        "                                          'ROC AUC':roc_auc_test,\n",
        "                                          'Pct. Positive':pct_positive_test},\n",
        "                                  'Model':{'Prediction Time':prediction_time,\n",
        "                                           'Model Size':model_size}}\n",
        "\n",
        "print(f'Model Prediction Time: {prediction_time} Seconds')\n",
        "if model_size > 1:\n",
        "  print(f'Model Size: {round(model_size,3)} MB')\n",
        "else:\n",
        "  print(f'Model Size: {round(model_size*1024)} KB')\n",
        "\n",
        "print(f'We are classifying {pct_positive_test}% of the test observations as positive.\\n')\n",
        "\n",
        "print(f'Test Accuracy: {accuracy_test}, Test F1 Score: {f1_score_test}')\n",
        "print(f'Test Precision: {precision_test}, Test Recall: {recall_test}')\n",
        "print(f'Test Area Under the ROC Curve: {roc_auc_test}\\n')\n",
        "\n",
        "print(f'We are classifying {pct_positive_train}% of the training observations as positive.\\n')\n",
        "\n",
        "print(f'Train Accuracy: {accuracy_train}, Train F1 Score: {f1_score_train}')\n",
        "print(f'Train Precision: {precision_train}, Train Recall: {recall_train}')\n",
        "\n",
        "print(f'Train Area Under the ROC Curve: {roc_auc_train}')"
      ],
      "id": "M0dLHXL9EeGL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcFH7JdlClVq"
      },
      "source": [
        "We then tried with a Random Forest classifier with 1000 base estimators with a max depth of 2. Random Forest has be successful in the past for this type of task."
      ],
      "id": "fcFH7JdlClVq"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "contrary-tuition"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(max_depth=3,class_weight='balanced',\n",
        "                             n_estimators=1000, random_state=0)\n",
        "\n",
        "clf.fit(X_train_pp,y_train)"
      ],
      "id": "contrary-tuition",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WICj8irRHxg"
      },
      "source": [
        "threshold = find_treshold(clf,X_test_pp,y_test)\n",
        "start_time = time.time()\n",
        "y_train_pred = np.where(clf.predict_proba(X_train_pp)[:,0] > threshold, 0, 1)\n",
        "y_test_pred = np.where(clf.predict_proba(X_test_pp)[:,0] > threshold, 0, 1)\n",
        "prediction_time = round(time.time() - start_time,3)"
      ],
      "id": "2WICj8irRHxg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUI_lqByEAR1"
      },
      "source": [
        "p = pickle.dumps(clf)\n",
        "model_size = sys.getsizeof(p)/(1024**2)\n",
        "\n",
        "accuracy_train = round(accuracy_score(y_train, y_train_pred),3)\n",
        "precision_train = round(precision_score(y_train, y_train_pred),3)\n",
        "recall_train = round(recall_score(y_train, y_train_pred),3)\n",
        "f1_score_train = round(f1_score(y_train, y_train_pred),3)\n",
        "roc_auc_train = round(roc_auc_score(y_train, y_train_pred),3)\n",
        "pct_positive_train = round((sum(y_train_pred)/len(y_train_pred))*100,3)\n",
        "\n",
        "accuracy_test = round(accuracy_score(y_test, y_test_pred),3)\n",
        "precision_test = round(precision_score(y_test, y_test_pred),3)\n",
        "recall_test = round(recall_score(y_test, y_test_pred),3)\n",
        "f1_score_test = round(f1_score(y_test, y_test_pred),3)\n",
        "roc_auc_test = round(roc_auc_score(y_test, y_test_pred),3)\n",
        "pct_positive_test = round((sum(y_test_pred)/len(y_test_pred))*100,3)\n",
        "\n",
        "perform_dict['Random Forest'] = {'Training':{'Accuracy':accuracy_train,\n",
        "                                             'Recall':recall_train,\n",
        "                                              'Precision':precision_train,\n",
        "                                              'F1-Score':f1_score_train,\n",
        "                                              'ROC AUC':roc_auc_train,\n",
        "                                              'Pct. Positive':pct_positive_train},\n",
        "                                  'Test':{'Accuracy':accuracy_test,\n",
        "                                          'Recall':recall_test,\n",
        "                                          'Precision':precision_test,\n",
        "                                          'F1-Score':f1_score_test,\n",
        "                                          'ROC AUC':roc_auc_test,\n",
        "                                          'Pct. Positive':pct_positive_test},\n",
        "                                  'Model':{'Prediction Time':prediction_time,\n",
        "                                           'Model Size':model_size}}\n",
        "\n",
        "print(f'Model Prediction Time: {prediction_time} Seconds')\n",
        "if model_size > 1:\n",
        "  print(f'Model Size: {round(model_size,3)} MB')\n",
        "else:\n",
        "  print(f'Model Size: {round(model_size*1024)} KB')\n",
        "\n",
        "print(f'We are classifying {pct_positive_test}% of the test observations as positive.\\n')\n",
        "\n",
        "print(f'Test Accuracy: {accuracy_test}, Test F1 Score: {f1_score_test}')\n",
        "print(f'Test Precision: {precision_test}, Test Recall: {recall_test}')\n",
        "print(f'Test Area Under the ROC Curve: {roc_auc_test}\\n')\n",
        "\n",
        "print(f'We are classifying {pct_positive_train}% of the training observations as positive.\\n')\n",
        "\n",
        "print(f'Train Accuracy: {accuracy_train}, Train F1 Score: {f1_score_train}')\n",
        "print(f'Train Precision: {precision_train}, Train Recall: {recall_train}')\n",
        "\n",
        "print(f'Train Area Under the ROC Curve: {roc_auc_train}')"
      ],
      "id": "yUI_lqByEAR1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_G3JJghC4C9"
      },
      "source": [
        "The final standard ML model is Stacking Classifier with two layers:\n",
        "\n",
        "1.   The first layer has two learners, both Random Forests with 250 base estimators.\n",
        "2.   The second layer has two learners, both Random Forests with 250 base estimators.\n",
        "\n",
        "the final estimator is a Logistic Regression\n"
      ],
      "id": "r_G3JJghC4C9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "static-polyester"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create Learners per layer\n",
        "layer_one_estimators = [\n",
        "                        ('rf_1', RandomForestClassifier(n_estimators=250, random_state=42,class_weight='balanced')),\n",
        "                        ('rf_2', RandomForestClassifier(n_estimators=250, random_state=42,class_weight='balanced')),         \n",
        "                       ]\n",
        "layer_two_estimators = [\n",
        "                        ('rf_3',RandomForestClassifier(n_estimators=250, random_state=42,class_weight='balanced')),\n",
        "                        ('rf_4', RandomForestClassifier(n_estimators=250, random_state=42,class_weight='balanced')),\n",
        "                       ]\n",
        "layer_two = StackingClassifier(estimators=layer_two_estimators, \n",
        "                               final_estimator=LogisticRegression(class_weight='balanced'))\n",
        "\n",
        "# Create Final model by \n",
        "clf = StackingClassifier(estimators=layer_one_estimators, final_estimator=layer_two)\n",
        "\n",
        "clf.fit(X_train_pp,y_train)"
      ],
      "id": "static-polyester",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlfQRlkC_JQu"
      },
      "source": [
        "threshold = find_treshold(clf,X_test_pp,y_test)\n",
        "start_time = time.time()\n",
        "y_train_pred = np.where(clf.predict_proba(X_train_pp)[:,0] > threshold, 0, 1)\n",
        "y_test_pred = np.where(clf.predict_proba(X_test_pp)[:,0] > threshold, 0, 1)\n",
        "prediction_time = round(time.time() - start_time,3)"
      ],
      "id": "qlfQRlkC_JQu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YePWj2r6-tq8"
      },
      "source": [
        "p = pickle.dumps(clf)\n",
        "model_size = sys.getsizeof(p)/(1024**2)\n",
        "\n",
        "accuracy_train = round(accuracy_score(y_train, y_train_pred),3)\n",
        "precision_train = round(precision_score(y_train, y_train_pred),3)\n",
        "recall_train = round(recall_score(y_train, y_train_pred),3)\n",
        "f1_score_train = round(f1_score(y_train, y_train_pred),3)\n",
        "roc_auc_train = round(roc_auc_score(y_train, y_train_pred),3)\n",
        "pct_positive_train = round((sum(y_train_pred)/len(y_train_pred))*100,3)\n",
        "\n",
        "accuracy_test = round(accuracy_score(y_test, y_test_pred),3)\n",
        "precision_test = round(precision_score(y_test, y_test_pred),3)\n",
        "recall_test = round(recall_score(y_test, y_test_pred),3)\n",
        "f1_score_test = round(f1_score(y_test, y_test_pred),3)\n",
        "roc_auc_test = round(roc_auc_score(y_test, y_test_pred),3)\n",
        "pct_positive_test = round((sum(y_test_pred)/len(y_test_pred))*100,3)\n",
        "\n",
        "perform_dict['Stacking Classifier'] = {'Training':{'Accuracy':accuracy_train,\n",
        "                                                   'Recall':recall_train,\n",
        "                                              'Precision':precision_train,\n",
        "                                              'F1-Score':f1_score_train,\n",
        "                                              'ROC AUC':roc_auc_train,\n",
        "                                              'Pct. Positive':pct_positive_train},\n",
        "                                  'Test':{'Accuracy':accuracy_test,\n",
        "                                          'Recall':recall_test,\n",
        "                                          'Precision':precision_test,\n",
        "                                          'F1-Score':f1_score_test,\n",
        "                                          'ROC AUC':roc_auc_test,\n",
        "                                          'Pct. Positive':pct_positive_test},\n",
        "                                  'Model':{'Prediction Time':prediction_time,\n",
        "                                           'Model Size':model_size}}\n",
        "\n",
        "print(f'Model Prediction Time: {prediction_time} Seconds')\n",
        "if model_size > 1:\n",
        "  print(f'Model Size: {round(model_size,3)} MB')\n",
        "else:\n",
        "  print(f'Model Size: {round(model_size*1024)} KB')\n",
        "\n",
        "print(f'We are classifying {pct_positive_test}% of the test observations as positive.\\n')\n",
        "\n",
        "print(f'Test Accuracy: {accuracy_test}, Test F1 Score: {f1_score_test}')\n",
        "print(f'Test Precision: {precision_test}, Test Recall: {recall_test}')\n",
        "print(f'Test Area Under the ROC Curve: {roc_auc_test}\\n')\n",
        "\n",
        "print(f'We are classifying {pct_positive_train}% of the training observations as positive.\\n')\n",
        "\n",
        "print(f'Train Accuracy: {accuracy_train}, Train F1 Score: {f1_score_train}')\n",
        "print(f'Train Precision: {precision_train}, Train Recall: {recall_train}')\n",
        "\n",
        "print(f'Train Area Under the ROC Curve: {roc_auc_train}')"
      ],
      "id": "YePWj2r6-tq8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A5RQJOxmYCp"
      },
      "source": [
        "## What About Neural Networks?\n",
        "The final competitor I have considered is a 4-layer neural networks with dropout applied to each output and ReLU activation functions."
      ],
      "id": "7A5RQJOxmYCp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "automated-graphics"
      },
      "source": [
        "# Import torch, torchvision libraries\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Import numpy for some computation\n",
        "import numpy as np\n",
        "\n",
        "# Import matplotlib for plotting\n",
        "import matplotlib.pyplot as plt\n",
        " \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "id": "automated-graphics",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMBR0-B0Wmdr"
      },
      "source": [
        "import math\n",
        "\n",
        "def init_weights(net):\n",
        "    \"\"\"\n",
        "    Usage: net = Model()\n",
        "           net.apply(init_weights)\n",
        "    \"\"\"\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.kaiming_normal_(m.weight)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            nn.init.ones_(m.weight)\n",
        "            nn.init.zeros_(m.bias)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "            if m.bias is not None:\n",
        "                stdv = 1. / math.sqrt(m.weight.size(1))\n",
        "                nn.init.uniform_(m.bias, -stdv, stdv)\n"
      ],
      "id": "xMBR0-B0Wmdr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "searching-japan"
      },
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self,input_size):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, input_size) \n",
        "        self.fc2 = nn.Linear(input_size, 50)\n",
        "        self.fc3 = nn.Linear(50, 25)\n",
        "        self.fc4 = nn.Linear(25, 2)\n",
        "        self.soft = nn.Softmax(dim=1)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.soft(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "\n",
        "model = Net(input_size = X_train_pp.shape[1])"
      ],
      "id": "searching-japan",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clear-pickup"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "tensor_x_train = torch.Tensor(np.array(X_train_pp)) # transform to torch tensor\n",
        "tensor_y_train = torch.Tensor(np.array(y_train))\n",
        "tensor_y_train = tensor_y_train.type(torch.LongTensor)\n",
        "\n",
        "my_train_dataset = TensorDataset(tensor_x_train,tensor_y_train) # create your datset\n",
        "\n",
        "tensor_x_test = torch.Tensor(np.array(X_test_pp)) # transform to torch tensor\n",
        "tensor_y_test = torch.Tensor(np.array(y_test))\n",
        "tensor_y_test = tensor_y_test.type(torch.LongTensor)\n",
        "\n",
        "my_test_dataset = TensorDataset(tensor_x_test,tensor_y_test) # create your dataset"
      ],
      "id": "clear-pickup",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXqmQnY9mImf"
      },
      "source": [
        "def load_data(data, batch_size=600):\n",
        "    return DataLoader(data, batch_size=batch_size, shuffle=True)"
      ],
      "id": "YXqmQnY9mImf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j56JUy8ghv07"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "def train(args, model, data):\n",
        "    \"\"\"\n",
        "    @Brief: training your model. This should include the following items:\n",
        "        - Initialize the model (already given). Only need to map the model to the device on which you would want to run the model on \n",
        "                using the following syntax: \n",
        "                model = model.to(device) \n",
        "                where device = torch.device(<device_name>), \n",
        "                i.e: device = torch.device(\"cuda:0\") or device = torech.device(\"cpu\")\n",
        "                    \n",
        "        - Initialize data loaders (you need to code up)\n",
        "        - Initialize the optimizer (you need to code up. Type is of your choice)\n",
        "        - Initialize the loss function (you should have coded up above)\n",
        "        - A for loop to iterate through many epochs (up to your choice). In each epoch:\n",
        "                - Iterate through every mini-batches (remember to map data and labels to the device that you would want to run the model on)\n",
        "                        - Run the forward path\n",
        "                        - Get loss\n",
        "                        - Calculate gradients \n",
        "                        - Update the model's parameters\n",
        "                - Evaluate your model on the validation set\n",
        "                - Save the model if the performance on the validation set is better using exactly the following line:\n",
        "                        save_model(model, model_name) \n",
        "                 \n",
        "    @Inputs: \n",
        "        Args: object of your choice to carry arguments that you want to use within your training function. \n",
        "    @Output: \n",
        "        No return is necessary here. \n",
        "    \"\"\"\n",
        "\n",
        "    init_weights(model)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device) \n",
        "\n",
        "    # Initialize data loaders \n",
        "                                     \n",
        "    trainloader = load_data(data)\n",
        "\n",
        "    # Initialize the optimizer\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss(reduction='mean', weight=args.weights)\n",
        "    #optimizer = torch.optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.learning_rate, momentum=args.momentum)\n",
        "    \n",
        "    for epoch in range(args.epochs):  # loop over the dataset multiple times\n",
        "\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          # get the inputs; data is a list of [inputs, labels]\n",
        "          inputs, labels = data\n",
        "          inputs = inputs.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          # zero the parameter gradients\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          # forward + backward + optimize\n",
        "          inputs = inputs.float()\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # print statistics\n",
        "          running_loss += loss.item()\n",
        "          if i%50 == 49:    # print every 5 mini-batches\n",
        "              print('[%d, %5d] loss: %.3f' %\n",
        "                    (epoch + 1, i + 1, running_loss / 50))\n",
        "              running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n"
      ],
      "id": "j56JUy8ghv07",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXDEM-uw5P8D"
      },
      "source": [
        "class Args(object):\n",
        "    def __init__(self,learning_rate=0.01,epochs=500,momentum=None,weights=None):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.momentum = momentum\n",
        "        self.epochs = epochs\n",
        "        self.weights = weights\n",
        "\n",
        "# We set weights inversely proportional to the proportion of each class\n",
        "\n",
        "prop_positive = sum(y_train)/len(y_train)\n",
        "weights = torch.tensor([1/(1-prop_positive),1/prop_positive]).to(device)\n",
        "args = Args(learning_rate=0.015, epochs=500, momentum=0.9, weights=weights)"
      ],
      "id": "yXDEM-uw5P8D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ49PNA3j7_Q"
      },
      "source": [
        "train(args, model=model,data=my_train_dataset)\n",
        "model.eval() # Set the model in evaluation mode once it is trained"
      ],
      "id": "QJ49PNA3j7_Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDCWeHhuMIPF"
      },
      "source": [
        "threshold = find_treshold(model,tensor_x_test,y_test,is_nn=True)\n",
        "start_time = time.time()\n",
        "test_scores = model(tensor_x_test.to(device))\n",
        "train_scores = model(tensor_x_train.to(device))\n",
        "y_test_pred = torch.where(test_scores[:,0] > threshold, 0, 1).cpu().detach().numpy()\n",
        "y_train_test = torch.where(train_scores[:,0] > threshold, 0, 1).cpu().detach().numpy()\n",
        "prediction_time = round(time.time() - start_time,3)"
      ],
      "id": "cDCWeHhuMIPF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSXEe0MuNjsV"
      },
      "source": [
        "from torchsummary import summary\n",
        "summary(model,input_size=(1,144))"
      ],
      "id": "JSXEe0MuNjsV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hispanic-allah"
      },
      "source": [
        "p = pickle.dumps(model)\n",
        "model_size = sys.getsizeof(p)/(1024**2)\n",
        "\n",
        "accuracy_train = round(accuracy_score(y_train, y_train_pred),3)\n",
        "precision_train = round(precision_score(y_train, y_train_pred),3)\n",
        "recall_train = round(recall_score(y_train, y_train_pred),3)\n",
        "f1_score_train = round(f1_score(y_train, y_train_pred),3)\n",
        "roc_auc_train = round(roc_auc_score(y_train, y_train_pred),3)\n",
        "pct_positive_train = round((sum(y_train_pred)/len(y_train_pred))*100,3)\n",
        "\n",
        "accuracy_test = round(accuracy_score(y_test, y_test_pred),3)\n",
        "precision_test = round(precision_score(y_test, y_test_pred),3)\n",
        "recall_test = round(recall_score(y_test, y_test_pred),3)\n",
        "f1_score_test = round(f1_score(y_test, y_test_pred),3)\n",
        "roc_auc_test = round(roc_auc_score(y_test, y_test_pred),3)\n",
        "pct_positive_test = round((sum(y_test_pred)/len(y_test_pred))*100,3)\n",
        "\n",
        "perform_dict['Neural Network'] = {'Training':{'Accuracy':accuracy_train,\n",
        "                                              'Recall':recall_train,\n",
        "                                              'Precision':precision_train,\n",
        "                                              'F1-Score':f1_score_train,\n",
        "                                              'ROC AUC':roc_auc_train,\n",
        "                                              'Pct. Positive':pct_positive_train},\n",
        "                                  'Test':{'Accuracy':accuracy_test,\n",
        "                                          'Recall':recall_test,\n",
        "                                          'Precision':precision_test,\n",
        "                                          'F1-Score':f1_score_test,\n",
        "                                          'ROC AUC':roc_auc_test,\n",
        "                                          'Pct. Positive':pct_positive_test},\n",
        "                                  'Model':{'Prediction Time':prediction_time,\n",
        "                                           'Model Size':model_size}}\n",
        "\n",
        "print(f'Model Prediction Time: {prediction_time} Seconds')\n",
        "if model_size > 1:\n",
        "  print(f'Model Size: {round(model_size,3)} MB')\n",
        "else:\n",
        "  print(f'Model Size: {round(model_size*1024)} KB')\n",
        "\n",
        "print(f'We are classifying {pct_positive_test}% of the test observations as positive.\\n')\n",
        "\n",
        "print(f'Test Accuracy: {accuracy_test}, Test F1 Score: {f1_score_test}')\n",
        "print(f'Test Precision: {precision_test}, Test Recall: {recall_test}')\n",
        "print(f'Test Area Under the ROC Curve: {roc_auc_test}\\n')\n",
        "\n",
        "print(f'We are classifying {pct_positive_train}% of the training observations as positive.\\n')\n",
        "\n",
        "print(f'Train Accuracy: {accuracy_train}, Train F1 Score: {f1_score_train}')\n",
        "print(f'Train Precision: {precision_train}, Train Recall: {recall_train}')\n",
        "\n",
        "print(f'Train Area Under the ROC Curve: {roc_auc_train}')"
      ],
      "id": "hispanic-allah",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcKtybJAnA_O"
      },
      "source": [
        "It is finally time to write the dictionary to a json file."
      ],
      "id": "CcKtybJAnA_O"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cB_5LKF3Nkot"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('performance.json', 'w') as fp:\n",
        "    json.dump(perform_dict, fp)"
      ],
      "id": "cB_5LKF3Nkot",
      "execution_count": null,
      "outputs": []
    }
  ]
}