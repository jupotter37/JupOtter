{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faker in /home/gitpod/.pyenv/versions/3.12.6/lib/python3.12/site-packages (30.3.0)\n",
      "Requirement already satisfied: pandas in /home/gitpod/.pyenv/versions/3.12.6/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /home/gitpod/.pyenv/versions/3.12.6/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /home/gitpod/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from faker) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions in /home/gitpod/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from faker) (4.12.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/gitpod/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/gitpod/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/gitpod/.pyenv/versions/3.12.6/lib/python3.12/site-packages (from python-dateutil>=2.4->faker) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install faker pandas numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types for file: attendance_table.csv\n",
      "Student_ID        object\n",
      "Days_Attended      int64\n",
      "Days_Missed        int64\n",
      "Absence_Reason    object\n",
      "dtype: object\n",
      "\n",
      "Data types for file: class_resources_table.csv\n",
      "Class_ID                         object\n",
      "Number_of_Students                int64\n",
      "Number_of_Teachers                int64\n",
      "Weekly_Teaching_Hours             int64\n",
      "Weekly_Library_Time               int64\n",
      "Weekly_Computer_Training_Time     int64\n",
      "Weekly_Lab_Hours                  int64\n",
      "Chalkboard                        int64\n",
      "Basic_Textbooks                   int64\n",
      "Chairs_Desks                      int64\n",
      "Functional_Fans                   int64\n",
      "dtype: object\n",
      "\n",
      "Data types for file: extracurricular_activity.csv\n",
      "Student_ID                  object\n",
      "Extracurricular_Activity    object\n",
      "Weekly_Hours                 int64\n",
      "dtype: object\n",
      "\n",
      "Data types for file: parent_table.csv\n",
      "Student_ID                       object\n",
      "Fathers Name                     object\n",
      "Mothers Name                     object\n",
      "Family Name                      object\n",
      "Father_Education                 object\n",
      "Mother_Education                 object\n",
      "Father_Occupation                object\n",
      "Mother_Occupation                object\n",
      "Annual_Household_Income(NGN)     object\n",
      "Household_Size                    int64\n",
      "Involvement_in_Kids_Education    object\n",
      "dtype: object\n",
      "\n",
      "Data types for file: ss3_student_survey.csv\n",
      "Student_ID                object\n",
      "Reason_For_Performance    object\n",
      "Access_To_Resources       object\n",
      "Study_Hours_Per_Week       int64\n",
      "Health_Issues             object\n",
      "Teacher_Support            int64\n",
      "Parental_Support           int64\n",
      "Stress_Level              object\n",
      "Peer_Influence            object\n",
      "Additional_Tutoring       object\n",
      "Use_Of_Study_Groups       object\n",
      "Exam_Anxiety              object\n",
      "Jamb_Scores                int64\n",
      "Num_Credit_Passes_WAEC     int64\n",
      "verdict                   object\n",
      "dtype: object\n",
      "\n",
      "Data types for file: staff_table.csv\n",
      "Staff_ID               object\n",
      "Name                   object\n",
      "Gender                 object\n",
      "Position               object\n",
      "Monthly Pay             int64\n",
      "Years of Experience     int64\n",
      "Education Level        object\n",
      "Date of Hire           object\n",
      "Full-time                bool\n",
      "dtype: object\n",
      "\n",
      "Data types for file: student_performance.csv\n",
      "Student_ID           object\n",
      "Mathematics           int64\n",
      "English Language      int64\n",
      "Civic Education       int64\n",
      "Economics             int64\n",
      "CRS/Islam             int64\n",
      "Government          float64\n",
      "Commerce            float64\n",
      "Literature          float64\n",
      "History             float64\n",
      "Accounting          float64\n",
      "Physics             float64\n",
      "Chemistry           float64\n",
      "Biology             float64\n",
      "Geography           float64\n",
      "Computer Science    float64\n",
      "dtype: object\n",
      "\n",
      "Data types for file: student_table.csv\n",
      "Student_ID             object\n",
      "Class_ID               object\n",
      "First_Name             object\n",
      "Family_Name            object\n",
      "Gender                 object\n",
      "Date_of_Birth          object\n",
      "State of Origin        object\n",
      "engagement_in_class    object\n",
      "health_condition       object\n",
      "Class Spec             object\n",
      "dtype: object\n",
      "\n",
      "Data types for file: teachers_table.csv\n",
      "Teacher_ID                object\n",
      "Staff_ID                  object\n",
      "Name                      object\n",
      "Teacher Type              object\n",
      "Subject specialization    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder path where the CSV files are stored\n",
    "folder_path = '/workspace/Datafest/data'\n",
    "\n",
    "# Iterate through every file in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Print the file name and the data types of each column\n",
    "        print(f\"\\nData types for file: {filename}\")\n",
    "        print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_884/1478016514.py:34: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  table_df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Access the variables\n",
    "\n",
    "database_url = os.getenv(\"DATABASE_URL\")\n",
    "\n",
    "\n",
    "# Connect to PostgreSQL database\n",
    "conn = psycopg2.connect(database_url)\n",
    "\n",
    "# Create a cursor object\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Get all table names from the current schema\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema = 'public'\n",
    "\"\"\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "# Create a dictionary to hold the data from each table\n",
    "table_data = {}\n",
    "\n",
    "# Loop through each table and load the data into a variable (as a pandas DataFrame)\n",
    "for table in tables:\n",
    "    table_name = table[0]\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    table_df = pd.read_sql(query, conn)\n",
    "    \n",
    "    # Store each table's data as a DataFrame in the dictionary, with the table name as the key\n",
    "    table_data[table_name] = table_df\n",
    "\n",
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "# Access data of each table from `table_data` dictionary\n",
    "# Example: To access the 'student_table' data\n",
    "student_data = table_data['student_table']\n",
    "attendance_table = table_data['attendance_table']\n",
    "class_resources_table = table_data['class_resources_table']\n",
    "extracurricular_activity = table_data['extracurricular_activity']\n",
    "parent_table = table_data['parent_table']\n",
    "ss3_student_survey = table_data['ss3_student_survey']\n",
    "staff_table = table_data['staff_table']\n",
    "student_performance = table_data['student_performance']\n",
    "teachers_table = table_data['teachers_table']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bdd640fb06674ad19c80317fa3b1799d'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from faker import Faker\n",
    "import numpy as np\n",
    "fake = Faker()\n",
    "Faker.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "fake.unique.uuid4().replace('-','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SS1 Class D', 'SS1 Class C', 'SS3 Class F', 'SS1 Class E',\n",
       "       'SS2 Class E', 'SS2 Class A', 'SS2 Class B', 'SS3 Class A',\n",
       "       'SS1 Class B', 'SS2 Class D', 'SS3 Class C', 'SS1 Class F',\n",
       "       'SS3 Class D', 'SS3 Class B', 'SS3 Class E', 'SS2 Class C',\n",
       "       'SS1 Class A', 'SS2 Class F'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data.class_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abeni': 'Yoruba',\n",
       " 'Abidemi': 'Yoruba',\n",
       " 'Abimbola': 'Yoruba',\n",
       " 'Abiodun': 'Yoruba',\n",
       " 'Abiola': 'Yoruba',\n",
       " 'Abioye': 'Yoruba',\n",
       " 'Abosede': 'Yoruba',\n",
       " 'Adaeze': 'Igbo',\n",
       " 'Adanna': 'Igbo',\n",
       " 'Adannaya': 'Igbo',\n",
       " 'Ade': 'Yoruba',\n",
       " 'Adebola': 'Yoruba',\n",
       " 'Adebowale': 'Yoruba',\n",
       " 'Adedayo': 'Yoruba',\n",
       " 'Adenike': 'Yoruba',\n",
       " 'Adeola': 'Yoruba',\n",
       " 'Adetokunbo': 'Yoruba',\n",
       " 'Adisa': 'Yoruba',\n",
       " 'Aisha': 'Hausa',\n",
       " 'Aishatu': 'Hausa',\n",
       " 'Akachi': 'Igbo',\n",
       " 'Akpofure': 'Urhobo',\n",
       " 'Akuchi': 'Igbo',\n",
       " 'Alaba': 'Yoruba',\n",
       " 'Alheri': 'Hausa',\n",
       " 'Amaka': 'Igbo',\n",
       " 'Amara': 'Igbo',\n",
       " 'Amarachi': 'Igbo',\n",
       " 'Amina': 'Hausa',\n",
       " 'Anuli': 'Igbo',\n",
       " 'Asabe': 'Hausa',\n",
       " \"Asma'u\": 'Hausa',\n",
       " 'Ayo': 'Yoruba',\n",
       " 'Ayodele': 'Yoruba',\n",
       " 'Ayomide': 'Yoruba',\n",
       " 'Ayotunde': 'Yoruba',\n",
       " 'Bamidele': 'Yoruba',\n",
       " 'Bilƙisu': 'Hausa',\n",
       " 'Bolanle': 'Yoruba',\n",
       " 'Bose': 'Yoruba',\n",
       " 'Bosede': 'Yoruba',\n",
       " 'Bukola': 'Yoruba',\n",
       " 'Chi': 'Igbo',\n",
       " 'Chiamaka': 'Igbo',\n",
       " 'Chibuzo': 'Igbo',\n",
       " 'Chichi': 'Igbo',\n",
       " 'Chidi': 'Igbo',\n",
       " 'Chidiebele': 'Igbo',\n",
       " 'Chidiebere': 'Igbo',\n",
       " 'Chidiebube': 'Igbo',\n",
       " 'Chidimma': 'Igbo',\n",
       " 'Chidinma': 'Igbo',\n",
       " 'Chidubem': 'Igbo',\n",
       " 'Chiemeka': 'Igbo',\n",
       " 'Chigozie': 'Igbo',\n",
       " 'Chijindum': 'Igbo',\n",
       " 'Chika': 'Igbo',\n",
       " 'Chikelu': 'Igbo',\n",
       " 'Chikere': 'Igbo',\n",
       " 'Chima': 'Igbo',\n",
       " 'Chimezie': 'Igbo',\n",
       " 'Chinasa': 'Igbo',\n",
       " 'Chinenye': 'Igbo',\n",
       " 'Chinonso': 'Igbo',\n",
       " 'Chinwe': 'Igbo',\n",
       " 'Chinwendu': 'Igbo',\n",
       " 'Chinyelu': 'Igbo',\n",
       " 'Chinyere': 'Igbo',\n",
       " 'Chioma': 'Igbo',\n",
       " 'Chisom': 'Igbo',\n",
       " 'Chizoba': 'Igbo',\n",
       " 'Dada': 'Yoruba',\n",
       " 'Dayo': 'Yoruba',\n",
       " 'Ebele': 'Igbo',\n",
       " 'Ebere': 'Igbo',\n",
       " 'Efe': 'Urhobo',\n",
       " 'Efemena': 'Urhobo',\n",
       " 'Ejiro': 'Urhobo',\n",
       " 'Ejiroghene': 'Urhobo',\n",
       " 'Ekene': 'Igbo',\n",
       " 'Ekenedilichukwu': 'Igbo',\n",
       " 'Ekundayo': 'Yoruba',\n",
       " 'Emem': 'Ibibio',\n",
       " 'Eniola': 'Yoruba',\n",
       " 'Enitan': 'Yoruba',\n",
       " 'Ese': 'Urhobo',\n",
       " 'Eseoghene': 'Urhobo',\n",
       " 'Faɗimatu': 'Hausa',\n",
       " 'Folami': 'Yoruba',\n",
       " 'Fumnanya': 'Igbo',\n",
       " 'Funke': 'Yoruba',\n",
       " 'Funmilayo': 'Yoruba',\n",
       " 'Gbemisola': 'Yoruba',\n",
       " 'Hadiza': 'Hausa',\n",
       " 'Hadizatu': 'Hausa',\n",
       " 'Hafsat': 'Hausa',\n",
       " 'Hafsatu': 'Hausa',\n",
       " 'Halima': 'Hausa',\n",
       " 'Halimat': 'Hausa',\n",
       " 'Halimatu': 'Hausa',\n",
       " 'Hauwa': 'Hausa',\n",
       " \"Hauwa'u\": 'Hausa',\n",
       " 'Idowu': 'Yoruba',\n",
       " 'Ife': 'Yoruba',\n",
       " 'Ifeoma': 'Igbo',\n",
       " 'Ifiok': 'Ibibio',\n",
       " 'Ifunanya': 'Igbo',\n",
       " 'Ige': 'Yoruba',\n",
       " 'Ijeoma': 'Igbo',\n",
       " 'Ime': 'Ibibio',\n",
       " 'Iniobong': 'Ibibio',\n",
       " 'Inyene': 'Ibibio',\n",
       " 'Itoro': 'Ibibio',\n",
       " 'Iyabo': 'Yoruba',\n",
       " 'Jamila': 'Hausa',\n",
       " 'Jummai': 'Hausa',\n",
       " 'Kayin': 'Yoruba',\n",
       " 'Kehinde': 'Yoruba',\n",
       " 'Kelechi': 'Igbo',\n",
       " 'Kyauta': 'Hausa',\n",
       " 'Ladi': 'Hausa',\n",
       " 'Maryamu': 'Hausa',\n",
       " 'Mojisola': 'Yoruba',\n",
       " 'Monifa': 'Yoruba',\n",
       " 'Ndidi': 'Igbo',\n",
       " 'Ngozi': 'Igbo',\n",
       " 'Nkechi': 'Igbo',\n",
       " 'Nkechinyere': 'Igbo',\n",
       " 'Nkemdilim': 'Igbo',\n",
       " 'Nkiru': 'Igbo',\n",
       " 'Nkiruka': 'Igbo',\n",
       " 'Nneka': 'Igbo',\n",
       " 'Nnenna': 'Igbo',\n",
       " 'Nnenne': 'Igbo',\n",
       " 'Nwanneka': 'Igbo',\n",
       " 'Obi': 'Igbo',\n",
       " 'Ogechi': 'Igbo',\n",
       " 'Ogechukwu': 'Igbo',\n",
       " 'Ogechukwukamma': 'Igbo',\n",
       " 'Oghenekaro': 'Urhobo',\n",
       " 'Oghenekevwe': 'Urhobo',\n",
       " 'Oghenero': 'Urhobo',\n",
       " 'Ogochukwu': 'Igbo',\n",
       " 'Ola': 'Yoruba',\n",
       " 'Olamide': 'Yoruba',\n",
       " 'Olayinka': 'Yoruba',\n",
       " 'Olubunmi': 'Yoruba',\n",
       " 'Oluchi': 'Igbo',\n",
       " 'Olufunke': 'Yoruba',\n",
       " 'Olufunmilayo': 'Yoruba',\n",
       " 'Olufunmilola': 'Yoruba',\n",
       " 'Olusola': 'Yoruba',\n",
       " 'Oluwafunmilayo': 'Yoruba',\n",
       " 'Oluwakanyinsola': 'Yoruba',\n",
       " 'Oluwaseun': 'Yoruba',\n",
       " 'Oluwaseyi': 'Yoruba',\n",
       " 'Oluwatoyin': 'Yoruba',\n",
       " 'Oluwayemisi': 'Yoruba',\n",
       " 'Omobolanle': 'Yoruba',\n",
       " 'Omolara': 'Yoruba',\n",
       " 'Oni': 'Yoruba',\n",
       " 'Onyeka': 'Igbo',\n",
       " 'Onyekachi': 'Igbo',\n",
       " 'Onyekachukwu': 'Igbo',\n",
       " 'Onyinye': 'Igbo',\n",
       " 'Onyinyechi': 'Igbo',\n",
       " 'Opeyemi': 'Yoruba',\n",
       " 'Otobong': 'Ibibio',\n",
       " 'Oyibo': 'Urhobo',\n",
       " 'Rakiya': 'Hausa',\n",
       " 'Safiya': 'Hausa',\n",
       " 'Simisola': 'Yoruba',\n",
       " 'Taiwo': 'Yoruba',\n",
       " 'Talatu': 'Hausa',\n",
       " 'Temitope': 'Yoruba',\n",
       " 'Titilayo': 'Yoruba',\n",
       " 'Tochukwu': 'Igbo',\n",
       " 'Toyin': 'Yoruba',\n",
       " 'Uche': 'Igbo',\n",
       " 'Uchenna': 'Igbo',\n",
       " 'Udo': 'Igbo',\n",
       " 'Uduak': 'Ibibio',\n",
       " 'Uduakobong': 'Ibibio',\n",
       " 'Ufuoma': 'Urhobo',\n",
       " 'Ugochi': 'Igbo',\n",
       " 'Uju': 'Igbo',\n",
       " 'Uzochi': 'Igbo',\n",
       " 'Uzoma': 'Igbo',\n",
       " 'Yalwa': 'Hausa',\n",
       " 'Yejide': 'Yoruba',\n",
       " 'Yetunde': 'Yoruba',\n",
       " 'Yewande': 'Yoruba',\n",
       " 'Zainab': 'Hausa',\n",
       " 'Zainabu': 'Hausa'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "def scrape_behindthename(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    names = soup.select('div.browsename')\n",
    "    return [name.text.strip() for name in names]\n",
    "\n",
    "def scrape_momjunction(base_url, gender):\n",
    "    all_names = []\n",
    "    page = 1\n",
    "    while True:\n",
    "        url = f\"{base_url}?gender={gender}&page={page}\"\n",
    "        response = requests.get(url)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        table = soup.find('table', {'id': f'baby-name-{gender}'})\n",
    "        \n",
    "        if not table:\n",
    "            break\n",
    "        \n",
    "        rows = table.find_all('tr')[1:]  # Skip header row\n",
    "        names = [row.find_all('td')[1].text.strip() for row in rows]\n",
    "        \n",
    "        if not names:\n",
    "            break\n",
    "        \n",
    "        all_names.extend(names)\n",
    "        page += 1\n",
    "    \n",
    "    return all_names\n",
    "\n",
    "\n",
    "female_names = scrape_behindthename('https://www.behindthename.com/names/gender/feminine/usage/nigerian')\n",
    "male_names = scrape_behindthename('https://www.behindthename.com/names/gender/masculine/usage/nigerian')\n",
    "unisex_names = scrape_behindthename('https://www.behindthename.com/names/gender/unisex/usage/nigerian')\n",
    "\n",
    "momjunction_url = 'https://www.momjunction.com/baby-names/nigerian/'\n",
    "female_names.extend(scrape_momjunction(momjunction_url, 'girl'))\n",
    "male_names.extend(scrape_momjunction(momjunction_url, 'boy'))\n",
    "\n",
    "# Remove duplicates and sort\n",
    "female_names = sorted(set(female_names))\n",
    "male_names = sorted(set(male_names))\n",
    "unisex_names = sorted(set(unisex_names))\n",
    "\n",
    "def parse_name_data(name_data):\n",
    "    parts = name_data.split(' ')\n",
    "    first_name = parts[0]  \n",
    "    ethnic_group = (\n",
    "        'Hausa' if 'Hausa' in name_data else\n",
    "        'Yoruba' if 'Yoruba' in name_data else\n",
    "        'Igbo' if 'Igbo' in name_data else\n",
    "        'Urhobo' if 'Urhobo' in name_data else\n",
    "        'Ibibio' if 'Ibibio' in name_data else\n",
    "        'Other'\n",
    "    )\n",
    "    return first_name, ethnic_group\n",
    "\n",
    "# Create dictionary by parsing each entry\n",
    "name_ethnic_male = {parse_name_data(name)[0]: parse_name_data(name)[1] for name in male_names}\n",
    "name_ethnic_female = {parse_name_data(name)[0]: parse_name_data(name)[1] for name in female_names}\n",
    "name_ethnic_female\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student_ID</th>\n",
       "      <th>Reason_For_Performance</th>\n",
       "      <th>Access_To_Resources</th>\n",
       "      <th>Study_Hours_Per_Week</th>\n",
       "      <th>Health_Issues</th>\n",
       "      <th>Teacher_Support</th>\n",
       "      <th>Parental_Support</th>\n",
       "      <th>Stress_Level</th>\n",
       "      <th>Peer_Influence</th>\n",
       "      <th>Additional_Tutoring</th>\n",
       "      <th>Use_Of_Study_Groups</th>\n",
       "      <th>Exam_Anxiety</th>\n",
       "      <th>Jamb_Scores</th>\n",
       "      <th>Num_Credit_Passes_WAEC</th>\n",
       "      <th>verdict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>310c0c003fa741049bf90e27dc96925e</td>\n",
       "      <td>Confidence issues</td>\n",
       "      <td>Yes</td>\n",
       "      <td>38</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>200</td>\n",
       "      <td>7</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23e2fcb472d8467d894a05e430b187ef</td>\n",
       "      <td>Personal issues</td>\n",
       "      <td>No</td>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>136</td>\n",
       "      <td>4</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>766ecb15474e4c19aef912766c006f61</td>\n",
       "      <td>Lack of resources</td>\n",
       "      <td>No</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>108</td>\n",
       "      <td>6</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>db20a56edc814fe78eda8bbb71710434</td>\n",
       "      <td>Confidence issues</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>283</td>\n",
       "      <td>9</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03c72ba8d60547708a63f881ffd0f9d5</td>\n",
       "      <td>Confidence issues</td>\n",
       "      <td>No</td>\n",
       "      <td>30</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>248</td>\n",
       "      <td>5</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>49646b96fa3c4628892621df465568b7</td>\n",
       "      <td>Health challenges</td>\n",
       "      <td>Yes</td>\n",
       "      <td>40</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>399</td>\n",
       "      <td>5</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>f090f5a0ce614199ae3a0ba8ac8d6c7d</td>\n",
       "      <td>Lack of preparation</td>\n",
       "      <td>No</td>\n",
       "      <td>28</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>316</td>\n",
       "      <td>8</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>409e7a8086c541d69ea9f50831227592</td>\n",
       "      <td>Difficulty understanding topics</td>\n",
       "      <td>Yes</td>\n",
       "      <td>24</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>186</td>\n",
       "      <td>5</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>79db78628d7d4772a08e2f5c61177270</td>\n",
       "      <td>Personal issues</td>\n",
       "      <td>Yes</td>\n",
       "      <td>14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>207</td>\n",
       "      <td>6</td>\n",
       "      <td>Pass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>47c68688ecf34053af36b8cc13087974</td>\n",
       "      <td>Lack of preparation</td>\n",
       "      <td>No</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>148</td>\n",
       "      <td>8</td>\n",
       "      <td>Fail</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Student_ID           Reason_For_Performance  \\\n",
       "0    310c0c003fa741049bf90e27dc96925e                Confidence issues   \n",
       "1    23e2fcb472d8467d894a05e430b187ef                  Personal issues   \n",
       "2    766ecb15474e4c19aef912766c006f61                Lack of resources   \n",
       "3    db20a56edc814fe78eda8bbb71710434                Confidence issues   \n",
       "4    03c72ba8d60547708a63f881ffd0f9d5                Confidence issues   \n",
       "..                                ...                              ...   \n",
       "309  49646b96fa3c4628892621df465568b7                Health challenges   \n",
       "310  f090f5a0ce614199ae3a0ba8ac8d6c7d              Lack of preparation   \n",
       "311  409e7a8086c541d69ea9f50831227592  Difficulty understanding topics   \n",
       "312  79db78628d7d4772a08e2f5c61177270                  Personal issues   \n",
       "313  47c68688ecf34053af36b8cc13087974              Lack of preparation   \n",
       "\n",
       "    Access_To_Resources  Study_Hours_Per_Week Health_Issues  Teacher_Support  \\\n",
       "0                   Yes                    38            No                1   \n",
       "1                    No                    37           Yes                4   \n",
       "2                    No                     9            No                2   \n",
       "3                    No                     6            No                2   \n",
       "4                    No                    30           Yes                2   \n",
       "..                  ...                   ...           ...              ...   \n",
       "309                 Yes                    40            No                2   \n",
       "310                  No                    28           Yes                3   \n",
       "311                 Yes                    24           Yes                3   \n",
       "312                 Yes                    14           Yes                5   \n",
       "313                  No                     9            No                2   \n",
       "\n",
       "     Parental_Support Stress_Level Peer_Influence Additional_Tutoring  \\\n",
       "0                   3          Yes             No                 Yes   \n",
       "1                   4          Yes             No                  No   \n",
       "2                   2           No             No                 Yes   \n",
       "3                   2          Yes            Yes                 Yes   \n",
       "4                   3           No            Yes                 Yes   \n",
       "..                ...          ...            ...                 ...   \n",
       "309                 3          Yes             No                 Yes   \n",
       "310                 5           No            Yes                 Yes   \n",
       "311                 5           No             No                  No   \n",
       "312                 2          Yes             No                 Yes   \n",
       "313                 1          Yes            Yes                  No   \n",
       "\n",
       "    Use_Of_Study_Groups Exam_Anxiety  Jamb_Scores  Num_Credit_Passes_WAEC  \\\n",
       "0                   Yes           No          200                       7   \n",
       "1                   Yes           No          136                       4   \n",
       "2                    No          Yes          108                       6   \n",
       "3                   Yes          Yes          283                       9   \n",
       "4                    No           No          248                       5   \n",
       "..                  ...          ...          ...                     ...   \n",
       "309                 Yes          Yes          399                       5   \n",
       "310                  No           No          316                       8   \n",
       "311                  No           No          186                       5   \n",
       "312                  No          Yes          207                       6   \n",
       "313                  No          Yes          148                       8   \n",
       "\n",
       "    verdict  \n",
       "0      Pass  \n",
       "1      Fail  \n",
       "2      Fail  \n",
       "3      Pass  \n",
       "4      Pass  \n",
       "..      ...  \n",
       "309    Pass  \n",
       "310    Pass  \n",
       "311    Fail  \n",
       "312    Pass  \n",
       "313    Fail  \n",
       "\n",
       "[314 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize Faker\n",
    "fake = Faker()\n",
    "Faker.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define constants\n",
    "regions = ['North Central', 'North East', 'North West', 'South East', 'South South', 'South West']\n",
    "nigeria_states = [\n",
    "    \"Abia\", \"Adamawa\", \"Akwa Ibom\", \"Anambra\", \"Bauchi\", \"Bayelsa\", \"Benue\",\n",
    "    \"Borno\", \"Cross River\", \"Delta\", \"Ebonyi\", \"Edo\", \"Ekiti\", \"Enugu\", \"Gombe\",\n",
    "    \"Imo\", \"Jigawa\", \"Kaduna\", \"Kano\", \"Katsina\", \"Kebbi\", \"Kogi\", \"Kwara\",\n",
    "    \"Lagos\", \"Nasarawa\", \"Niger\", \"Ogun\", \"Ondo\", \"Osun\", \"Oyo\", \"Plateau\",\n",
    "    \"Rivers\", \"Sokoto\", \"Taraba\", \"Yobe\", \"Zamfara\", \"FCT\"\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "education_levels = ['None', 'Primary', 'Secondary', 'Tertiary']\n",
    "occupations = ['Farmer', 'Trader', 'Teacher', 'Civil Servant', 'Engineer', 'Unemployed', 'Doctor', 'Nurse']\n",
    "extracurricular_activities = ['Sports', 'Drama', 'Debate Club', 'Art','Jet club','Press club','Literature club']\n",
    "common_subjects = ['Mathematics', 'English Language', 'Civic Education', 'Economics', 'CRS/Islam']\n",
    "science_subjects = ['Physics', 'Chemistry', 'Biology', 'Geography', 'Computer Science']\n",
    "art_subjects = ['Government', 'Commerce', 'Literature','History', 'Accounting']\n",
    "subjects = common_subjects + science_subjects + art_subjects\n",
    "health_condition = ['Asthma'] * 3 + ['Sickle Cell'] * 2 + ['Ulcer'] * 3 + ['Epilepsy']*1 + ['Dyslexia']*20 + ['None']*91\n",
    "teacher_type =  ['Corper','Regular']\n",
    "weights = [0.2, 0.8]  \n",
    "\n",
    "# Define staff positions with number of positions and pay grade\n",
    "staff_positions = {\n",
    "    \"Teacher\": {\"count\": len(subjects), \"pay_grade\": 100000},\n",
    "    \"Principal\": {\"count\": 1, \"pay_grade\": 170000},\n",
    "    \"Vice Principal\": {\"count\": 1, \"pay_grade\": 150000},\n",
    "    \"Librarian\": {\"count\": 2, \"pay_grade\": 80000},\n",
    "    \"School Nurse\": {\"count\": 2, \"pay_grade\": 120000},\n",
    "    \"Administrative Assistant\": {\"count\": 3, \"pay_grade\": 80000},\n",
    "    \"Cleaner\": {\"count\": 3, \"pay_grade\": 30000},\n",
    "    \"Vendor\": {\"count\": 2, \"pay_grade\": 40000},\n",
    "    \"Bus Driver\": {\"count\": 2, \"pay_grade\": 70000},\n",
    "    \"Lab attendant\": {\"count\": 2, \"pay_grade\": 90000},\n",
    "    \"Security Guard\": {\"count\": 2, \"pay_grade\": 70000}\n",
    "}\n",
    "\n",
    "def random_dobs(min_age, max_age):\n",
    "    now = datetime.now()\n",
    "    return (now - timedelta(days=random.randint(min_age*365, max_age*365))).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def assign_scores(subjects):\n",
    "    return {subject: random.randint(0, 100) for subject in subjects}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_dim_class_resources():\n",
    "    data = []\n",
    "    \n",
    "    # Class levels and segments\n",
    "    levels = ['SS1', 'SS2', 'SS3']\n",
    "    segments = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "    \n",
    "    for level in levels:\n",
    "        for segment in segments:\n",
    "            class_name = f\"{level} Class {segment}\"\n",
    "            num_students = random.randint(50, 60)  # Number of students per class\n",
    "            num_teachers = random.randint(5, 10)  # Number of teachers per class\n",
    "            \n",
    "            # Weekly hours and classroom resources\n",
    "            weekly_teaching_hours = random.randint(20, 35)  # Weekly teaching hours\n",
    "            weekly_library_time = random.randint(1, 5)  # Weekly library hours\n",
    "            weekly_computer_training_time = random.randint(2, 3)  # Computer training hours\n",
    "            weekly_lab_hours = random.randint(0, 4)  # Weekly lab hours\n",
    "            \n",
    "            # Classroom resources (boolean values)\n",
    "            chalkboard = random.randint(1, 3)\n",
    "            basic_textbooks = random.randint(0, 4)\n",
    "            chairs_desks = num_students\n",
    "            functional_fans = random.randint(0, 4)\n",
    "            \n",
    "            # Append class information to the list\n",
    "            data.append({\n",
    "                'Class_ID': class_name,\n",
    "                'Number_of_Students': num_students,\n",
    "                'Number_of_Teachers': num_teachers,\n",
    "                'Weekly_Teaching_Hours': weekly_teaching_hours,\n",
    "                'Weekly_Library_Time': weekly_library_time,\n",
    "                'Weekly_Computer_Training_Time': weekly_computer_training_time,\n",
    "                'Weekly_Lab_Hours': weekly_lab_hours,\n",
    "                'Chalkboard': chalkboard,\n",
    "                'Basic_Textbooks': basic_textbooks,\n",
    "                'Chairs_Desks': chairs_desks,\n",
    "                'Functional_Fans': functional_fans\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "dim_class_resources = generate_dim_class_resources()\n",
    "\n",
    "# Number of records\n",
    "NUM_STUDENTS = sum(dim_class_resources.Number_of_Students)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Generate staff data\n",
    "def generate_staff_data():\n",
    "    data = []\n",
    "    for position, details in staff_positions.items():\n",
    "        for _ in range(details[\"count\"]):\n",
    "            staff_member = {\n",
    "                'Staff_ID': fake.unique.uuid4(),\n",
    "                \"Name\": ', '.join(random.sample(list(name_ethnic_male.keys()), 2)),\n",
    "                'Gender': random.choice(['Male', 'Female']),\n",
    "                \"Position\": position,\n",
    "                \"Monthly Pay\": details[\"pay_grade\"],\n",
    "                \"Years of Experience\": random.randint(0, 30),\n",
    "                \"Education Level\": fake.random_element(elements=(\"High School\", \"Associate's\", \"Bachelor's\", \"Master's\", \"PhD\")),\n",
    "                \"Date of Hire\": fake.date_between(start_date=\"-30y\", end_date=\"today\"),\n",
    "                \"Full-time\": fake.boolean(chance_of_getting_true=80)\n",
    "            }\n",
    "            data.append(staff_member)\n",
    "    return data\n",
    "\n",
    "# Generate staff data and create DataFrame\n",
    "staff_data = generate_staff_data()\n",
    "staff_table = pd.DataFrame(staff_data)\n",
    "staff_table['Staff_ID'] = staff_table['Staff_ID'].str.replace('-', '', regex=False)\n",
    "\n",
    "# Generate Dim Teacher\n",
    "def generate_teacher_table():\n",
    "    teachers_table = staff_table[staff_table['Position'] == 'Teacher'][['Staff_ID', 'Name']].copy()\n",
    "    teachers_table['Teacher_ID'] = [fake.unique.uuid4() for i in range(len(teachers_table))]\n",
    "    teachers_table['Teacher_ID'] = teachers_table['Teacher_ID'].str.replace('-', '', regex=False)\n",
    "    teachers_table['Teacher Type'] = random.choices(teacher_type, weights=weights, k=len(teachers_table))\n",
    "    teachers_table['Subject specialization'] = subjects\n",
    "    teachers_table = teachers_table[['Teacher_ID', 'Staff_ID', 'Name', 'Teacher Type', 'Subject specialization']]\n",
    "    return teachers_table\n",
    "\n",
    "teachers_table = generate_teacher_table()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Generate Dim Event\n",
    "# def generate_dim_event(num_events, dim_class):\n",
    "#     data = []\n",
    "#     for _ in range(num_events):\n",
    "#         event_id = fake.unique.uuid4()\n",
    "#         event_name = random.choice(['Sports Day', 'Annual Meeting', 'Science Fair', 'Art Exhibition', 'Debate Competition'])\n",
    "#         event_type = random.choice(['Academic', 'Sports', 'Cultural'])\n",
    "#         date = fake.date_between(start_date='-3y', end_date='today')\n",
    "#         class_id = random.choice(dim_class['Class_Name'].tolist())\n",
    "#         data.append({\n",
    "#             'Event_ID': event_id,\n",
    "#             'Event_Name': event_name,\n",
    "#             'Event_Type': event_type,\n",
    "#             'Date': date,\n",
    "#             'class_ID': class_id\n",
    "#         })\n",
    "#     return pd.DataFrame(data)\n",
    "\n",
    "# dim_event = generate_dim_event(NUM_EVENTS, dim_class)\n",
    "\n",
    "# Generate Dim Student\n",
    "def generate_dim_student(num_students, dim_class):\n",
    "    data = []\n",
    "    for _ in range(num_students):\n",
    "        student_id = fake.unique.uuid4()\n",
    "        gender = random.choice(['Male', 'Female'])\n",
    "        DOB = random_dobs(14, 18) \n",
    "        region = random.choice(regions)\n",
    "        class_id = random.choice(dim_class['Class_ID'].tolist())\n",
    "        data.append({\n",
    "            'Student_ID': student_id,\n",
    "            'Class_ID': class_id,\n",
    "            'First_Name': ', '.join(random.sample(list(name_ethnic_male.keys()), 1)),\n",
    "            'Family_Name': ', '.join(random.sample(list(name_ethnic_male.keys()), 1)),\n",
    "            'Gender': gender,\n",
    "            'Date_of_Birth': DOB,\n",
    "            'State of Origin': random.choice(nigeria_states),\n",
    "            'engagement_in_class': random.choice(['Troublesome','Unactive','Slightly active','Active','Highly active']),\n",
    "            'health_condition': random.choice(health_condition),\n",
    "            'Class Spec': random.choice(['Art','Science'])\n",
    "        })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "dim_student = generate_dim_student(NUM_STUDENTS, dim_class_resources)\n",
    "dim_student['Student_ID'] = dim_student['Student_ID'].str.replace('-', '', regex=False)\n",
    "\n",
    "# Generate Dim Parent Demographics\n",
    "def generate_dim_parent_demographics(dim_student):\n",
    "    data = []\n",
    "    for _, student in dim_student.iterrows():\n",
    "        father_education = random.choice(education_levels)\n",
    "        mother_education = random.choice(education_levels)\n",
    "        father_occupation = random.choice(occupations)\n",
    "        mother_occupation = random.choice(occupations)\n",
    "        data.append({\n",
    "            'Student_ID': student['Student_ID'],\n",
    "            'Fathers Name': ', '.join(random.sample(list(name_ethnic_male.keys()), 1)),\n",
    "            'Mothers Name': ', '.join(random.sample(list(name_ethnic_female.keys()), 1)),\n",
    "            'Family Name' : ', '.join(random.sample(list(name_ethnic_male.keys()), 1)),\n",
    "            'Father_Education': father_education,\n",
    "            'Mother_Education': mother_education,\n",
    "            'Father_Occupation': father_occupation,\n",
    "            'Mother_Occupation': mother_occupation,\n",
    "            'Annual_Household_Income(NGN)': random.choice(['Below 200,000', '200,000-400,000', '400,000-600,000', 'Above 600,000']),\n",
    "            'Household_Size': random.choice(np.arange(2, 7)),\n",
    "            'Involvement_in_Kids_Education': random.choice(['Always busy', 'Slightly involved', 'Involved', 'Very Involved'])\n",
    "        })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "dim_parent_demographics = generate_dim_parent_demographics(dim_student)\n",
    "\n",
    "# Generate Dim Extracurricular Activity\n",
    "def generate_dim_extracurricular_activity(dim_student):\n",
    "    data = []\n",
    "    for _, student in dim_student.iterrows():\n",
    "        extracurricular = random.choice(extracurricular_activities)\n",
    "        weekly_hours_in_activity = random.randint(1, 10) if extracurricular != 'None' else 0\n",
    "        data.append({\n",
    "            'Student_ID': student['Student_ID'],\n",
    "            'Extracurricular_Activity': extracurricular,\n",
    "            'Weekly_Hours': weekly_hours_in_activity\n",
    "        })\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "dim_extracurricular_activity = generate_dim_extracurricular_activity(dim_student)\n",
    "\n",
    "\n",
    "# Generate Fact School Operations\n",
    "# def generate_fact_school_operations(dim_class):\n",
    "#     data = []\n",
    "#     for _, row in dim_class.iterrows():# Iterate over the rows properly\n",
    "#         # Each class can have operational records\n",
    "#         budget = random.randint(500000, 5000000)  # Annual budget in Naira\n",
    "#         spending_on_library = random.randint(100000, 1000000)\n",
    "#         spending_on_teachers = random.randint(200000, 2000000)\n",
    "#         number_of_classrooms = len(dim_class)  # Use the total number of classrooms\n",
    "#         library_books = random.randint(500, 10000)\n",
    "#         health_staff = random.randint(1, 10)\n",
    "\n",
    "#         # Append the data for each class\n",
    "#         data.append({\n",
    "#             'Class_ID': row['Class_Name'],  # Correctly assign the class name\n",
    "#             'Budget': budget,\n",
    "#             'Spending_On_Library': spending_on_library,\n",
    "#             'Spending_On_Teachers': spending_on_teachers,\n",
    "#             'Number_of_Classrooms': number_of_classrooms,\n",
    "#             'Library_Books': library_books,\n",
    "#             'Health_Staff': health_staff\n",
    "#         })\n",
    "    \n",
    "#     return pd.DataFrame(data)\n",
    "\n",
    "# fact_school_operations = generate_fact_school_operations(dim_class_resources)\n",
    "\n",
    "\n",
    "\n",
    "def generate_fact_attendance(dim_student): \n",
    "    data = []\n",
    "    \n",
    "    # Randomly select a subset of students to miss school (between 10 and 50 students)\n",
    "    students_missing_school = random.sample(dim_student.index.tolist(), random.randint(10, 50))\n",
    "    \n",
    "    for idx, student in dim_student.iterrows():\n",
    "        if idx in students_missing_school:\n",
    "            # Students who miss school\n",
    "            days_attended = random.randint(60, 94)  # Randomly decide attended days between 80 and 94\n",
    "            days_missed = 95 - days_attended\n",
    "            absence_reason = random.choice(['Illness', 'Family Event', 'Other','Truancy','School fees drive','Insecurity'])\n",
    "        else:\n",
    "            # Students who don't miss school\n",
    "            days_attended = 95\n",
    "            days_missed = 0\n",
    "            absence_reason = 'Full Attendance'\n",
    "        \n",
    "        data.append({\n",
    "            'Student_ID': student['Student_ID'],\n",
    "            'Days_Attended': days_attended,\n",
    "            'Days_Missed': days_missed,\n",
    "            'Absence_Reason': absence_reason\n",
    "        })\n",
    "        \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Generate attendance fact data\n",
    "fact_attendance = generate_fact_attendance(dim_student)\n",
    "\n",
    "\n",
    "\n",
    "def generate_student_performance(dim_student):\n",
    "    dim_student_copy = dim_student[['Student_ID', 'Class Spec']].copy()  # Copy to avoid altering original DataFrame\n",
    "    data = []\n",
    "    \n",
    "    # Iterate over each row in the DataFrame\n",
    "    for _, row in dim_student_copy.iterrows():\n",
    "        student_id = row['Student_ID']\n",
    "        class_spec = row['Class Spec']\n",
    "        \n",
    "        # Common subjects (shared between both Art and Science students)\n",
    "        performance = assign_scores(common_subjects)\n",
    "        \n",
    "        # Additional subjects depending on the stream\n",
    "        if class_spec == 'Science':\n",
    "            performance.update(assign_scores(science_subjects))\n",
    "            # Art subjects will have None for Science students\n",
    "            performance.update({subject: None for subject in art_subjects})\n",
    "        else:\n",
    "            performance.update(assign_scores(art_subjects))\n",
    "            # Science subjects will have None for Art students\n",
    "            performance.update({subject: None for subject in science_subjects})\n",
    "        \n",
    "        # Append student data to list\n",
    "        data.append({\n",
    "            'Student_ID': student_id,\n",
    "            **performance\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Generate student performance data\n",
    "student_performance = generate_student_performance(dim_student)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assuming dim_student contains all students with their respective class information\n",
    "def generate_ss3_student_performance_survey(dim_student):\n",
    "    # Filter students from SS3A to SS3F\n",
    "    ss3_students = dim_student[dim_student['Class_ID'].str.startswith('SS3')]\n",
    "\n",
    "    # List of reasons for performance issues\n",
    "    reasons_for_performance = ['Lack of preparation', 'Difficulty understanding topics', \n",
    "                               'Personal issues', 'Health challenges', 'Confidence issues', \n",
    "                               'Lack of resources']\n",
    "\n",
    "    data = []\n",
    "    for _, student in ss3_students.iterrows():\n",
    "        # Generate random survey responses\n",
    "        reason = random.choice(reasons_for_performance)\n",
    "        access_to_resources = random.choice(['Yes', 'No'])\n",
    "        study_hours_per_week = random.randint(0, 40)  # Study hours ranging from 0 to 40\n",
    "        health_issues = random.choice(['Yes', 'No'])\n",
    "        teacher_support = random.randint(1, 5)  # Rating from 1 to 5\n",
    "        parental_support = random.randint(1, 5)  # Rating from 1 to 5\n",
    "        stress_level = random.choice(['Yes', 'No'])\n",
    "        peer_influence = random.choice(['Yes', 'No'])\n",
    "        additional_tutoring = random.choice(['Yes', 'No'])\n",
    "        exam_anxiety = random.choice(['Yes', 'No'])\n",
    "        use_of_study_groups = random.choice(['Yes', 'No'])\n",
    "                # JAMB Mock Scores and Credit Passes in WAEC\n",
    "        jamb_mock_scores = random.randint(100, 400)\n",
    "        num_credit_passes_waec = random.randint(2, 9)\n",
    "\n",
    "        # Append the survey data for each student\n",
    "        data.append({\n",
    "            'Student_ID': student['Student_ID'],\n",
    "            'Reason_For_Performance': reason,\n",
    "            'Access_To_Resources': access_to_resources,\n",
    "            'Study_Hours_Per_Week': study_hours_per_week,\n",
    "            'Health_Issues': health_issues,\n",
    "            'Teacher_Support': teacher_support,\n",
    "            'Parental_Support': parental_support,\n",
    "            'Stress_Level': stress_level,\n",
    "            'Peer_Influence': peer_influence,\n",
    "            'Additional_Tutoring': additional_tutoring,\n",
    "            'Use_Of_Study_Groups': use_of_study_groups,\n",
    "            'Exam_Anxiety': exam_anxiety,\n",
    "            'Jamb_Scores': jamb_mock_scores,\n",
    "            'Num_Credit_Passes_WAEC': num_credit_passes_waec\n",
    "            \n",
    "        })\n",
    "    \n",
    "    # Create a DataFrame from the generated data\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "\n",
    "# Generate the SS3 student performance survey table\n",
    "ss3_student_survey = generate_ss3_student_performance_survey(dim_student)\n",
    "ss3_student_survey['verdict'] = ss3_student_survey.apply(lambda row: 'Pass' if row['Jamb_Scores'] >= 200 and row['Num_Credit_Passes_WAEC'] >= 5 else 'Fail', axis=1)\n",
    "\n",
    "\n",
    "# def art_science_grades():\n",
    "#         # Example: Predefined high school art and science courses\n",
    "#     art_courses = ['Government', 'Literature', 'Economics', 'CRK/Islam']\n",
    "#     science_courses = ['Biology', 'Physics', 'Chemistry', 'Intro. Tech']\n",
    "\n",
    "#     # Function to calculate rank based on score\n",
    "#     def calculate_rank(score):\n",
    "#         if score >= 70:\n",
    "#             return 'A'\n",
    "#         elif score >= 60:\n",
    "#             return 'B'\n",
    "#         elif score >= 50:\n",
    "#             return 'C'\n",
    "#         elif score >= 40:\n",
    "#             return 'D'\n",
    "#         else:\n",
    "#             return 'F'\n",
    "\n",
    "#     # Example DataFrame: dim_student with a 'student_id' and 'Class Spec' column\n",
    "#     dim_student_copy = dim_student[['Student_ID','Class Spec']]\n",
    "\n",
    "#     # Create art_discipline and science_discipline DataFrames based on the 'Class Spec' column\n",
    "#     art_discipline = dim_student_copy[dim_student_copy['Class Spec'] == 'Art'].copy()\n",
    "#     science_discipline = dim_student_copy[dim_student_copy['Class Spec'] == 'Science'].copy()\n",
    "\n",
    "#     # Assign scores for art and science students\n",
    "#     for course in art_courses:\n",
    "#         art_discipline[course] = art_discipline.apply(lambda x: random.randint(50, 100), axis=1)\n",
    "\n",
    "#     for course in science_courses:\n",
    "#         science_discipline[course] = science_discipline.apply(lambda x: random.randint(50, 100), axis=1)\n",
    "\n",
    "#     # Calculate average score for each student in art_discipline and science_discipline\n",
    "#     art_discipline['Average_Score'] = art_discipline[art_courses].mean(axis=1)\n",
    "#     science_discipline['Average_Score'] = science_discipline[science_courses].mean(axis=1)\n",
    "\n",
    "#     # Calculate ranks based on the average score\n",
    "#     art_discipline['Grade'] = art_discipline['Average_Score'].apply(calculate_rank)\n",
    "#     science_discipline['Grade'] = science_discipline['Average_Score'].apply(calculate_rank)\n",
    "\n",
    "    \n",
    "#     art_discipline = art_discipline[['Student_ID'] + art_courses + ['Average_Score', 'Grade']]\n",
    "\n",
    "    \n",
    "#     science_discipline = science_discipline[['Student_ID'] + science_courses + ['Average_Score', 'Grade']]\n",
    "\n",
    "#     return art_discipline, science_discipline\n",
    "\n",
    "# art_scores_2021 ,science_scores_2021 = art_science_grades()\n",
    "# art_scores_2022  ,science_scores_2022  = art_science_grades()\n",
    "# art_scores_2023  ,science_scores_2023  = art_science_grades()\n",
    "\n",
    "\n",
    "\n",
    "# Save all tables to CSV files\n",
    "dim_class_resources\n",
    "dim_student\n",
    "dim_parent_demographics\n",
    "dim_extracurricular_activity\n",
    "teachers_table\n",
    "student_performance\n",
    "fact_attendance\n",
    "staff_table\n",
    "ss3_student_survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No null values found in any columns.\n",
      "All Student_IDs are unique.\n",
      "All Class_IDs exist in class_resources_table.\n",
      "All Date_of_Births are in a consistent format.\n",
      "All data quality checks passed. Data saved as Parquet.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "attendance_df = fact_attendance\n",
    "student_df = dim_student\n",
    "class_resources_df = dim_class_resources\n",
    "extracurricular_df = dim_extracurricular_activity\n",
    "parent_df = dim_parent_demographics\n",
    "survey_df = ss3_student_survey\n",
    "staff_df = staff_table\n",
    "performance_df = student_performance\n",
    "teachers_df = teachers_table\n",
    "\n",
    "def attendance_quality_checks():\n",
    "    # Define total number of school days\n",
    "    total_school_days = 95\n",
    "\n",
    "    # 1. Check for null values in all columns\n",
    "    if attendance_df.isnull().values.any():\n",
    "        print(\"Null values found in the dataframe:\\n\", attendance_df.isnull().sum())\n",
    "    else:\n",
    "        print(\"No null values found.\")\n",
    "\n",
    "    # 2. Ensure Student_ID is unique and matches with student_table\n",
    "    if not attendance_df['Student_ID'].is_unique:\n",
    "        print(\"Duplicate Student_IDs found.\")\n",
    "    else:\n",
    "        print(\"Student_ID is unique.\")\n",
    "\n",
    "    unmatched_ids = attendance_df[~attendance_df['Student_ID'].isin(student_df['Student_ID'])]\n",
    "    if not unmatched_ids.empty:\n",
    "        print(f\"Unmatched Student_IDs found:\\n{unmatched_ids['Student_ID'].values}\")\n",
    "    else:\n",
    "        print(\"All Student_IDs match with student_table.\")\n",
    "\n",
    "    # 3. Verify Days_Attended and Days_Missed are non-negative\n",
    "    if (attendance_df['Days_Attended'] < 0).any() or (attendance_df['Days_Missed'] < 0).any():\n",
    "        print(\"Found negative values in Days_Attended or Days_Missed.\")\n",
    "    else:\n",
    "        print(\"Days_Attended and Days_Missed are non-negative.\")\n",
    "\n",
    "    # 4. Check if Days_Attended + Days_Missed equals total school days\n",
    "    if (attendance_df['Days_Attended'] + attendance_df['Days_Missed'] != total_school_days).any():\n",
    "        mismatches = attendance_df[attendance_df['Days_Attended'] + attendance_df['Days_Missed'] != total_school_days]\n",
    "        print(f\"Mismatches found:\\n{mismatches[['Student_ID', 'Days_Attended', 'Days_Missed']]}\")\n",
    "    else:\n",
    "        print(\"Days_Attended + Days_Missed matches total school days.\")\n",
    "\n",
    "    # 5. Ensure Absence_Reason is filled for all records where Days_Missed > 0\n",
    "    missing_reasons = attendance_df[(attendance_df['Days_Missed'] > 0) & (attendance_df['Absence_Reason'].isnull())]\n",
    "    if not missing_reasons.empty:\n",
    "        print(f\"Absence_Reason missing for records where Days_Missed > 0:\\n{missing_reasons[['Student_ID', 'Days_Missed']]}\")\n",
    "    else:\n",
    "        print(\"Absence_Reason is filled for all records where Days_Missed > 0.\")\n",
    "\n",
    "    # Save to parquet if all checks pass\n",
    "    if (attendance_df.isnull().values.any() == False and\n",
    "        attendance_df['Student_ID'].is_unique and\n",
    "        unmatched_ids.empty and\n",
    "        (attendance_df['Days_Attended'] >= 0).all() and\n",
    "        (attendance_df['Days_Missed'] >= 0).all() and\n",
    "        (attendance_df['Days_Attended'] + attendance_df['Days_Missed'] == total_school_days).all() and\n",
    "        missing_reasons.empty):\n",
    "        \n",
    "        attendance_df.to_parquet('./passed_basic_quality_checks/attendance_table.parquet')\n",
    "        print(\"All attendance data quality checks passed. Data saved as Parquet.\")\n",
    "    else:\n",
    "        print(\"Data quality checks failed.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def class_resources_quality_checks():\n",
    "    # 1. Check for null values in all columns\n",
    "    if class_resources_df.isnull().values.any():\n",
    "        print(\"Null values found in the dataframe:\\n\", class_resources_df.isnull().sum())\n",
    "    else:\n",
    "        print(\"No null values found.\")\n",
    "\n",
    "    # 2. Ensure Class_ID is unique\n",
    "    if not class_resources_df['Class_ID'].is_unique:\n",
    "        print(\"Duplicate Class_IDs found.\")\n",
    "    else:\n",
    "        print(\"Class_ID is unique.\")\n",
    "\n",
    "    # 3. Verify all numeric columns have non-negative values\n",
    "    numeric_columns = ['Number_of_Students', 'Number_of_Teachers', 'Weekly_Teaching_Hours', \n",
    "                    'Weekly_Library_Time', 'Weekly_Computer_Training_Time', 'Weekly_Lab_Hours',\n",
    "                    'Chalkboard', 'Basic_Textbooks', 'Chairs_Desks', 'Functional_Fans']\n",
    "\n",
    "    if (class_resources_df[numeric_columns] < 0).any().any():\n",
    "        print(\"Found negative values in numeric columns.\")\n",
    "    else:\n",
    "        print(\"All numeric columns have non-negative values.\")\n",
    "\n",
    "    # 4. Check if Number_of_Students and Number_of_T are reasonable\n",
    "    if class_resources_df['Number_of_Students'].max() > 100 or class_resources_df['Number_of_Teachers'].max() > 20:\n",
    "        print(\"Unreasonable values in Number_of_Students or Number_of_Teachers.\")\n",
    "    else:\n",
    "        print(\"Number_of_Students and Number_of_Teachers are within reasonable limits.\")\n",
    "\n",
    "    # 5. Ensure Weekly_Teaching_Hours is within a realistic range (e.g., 20-50 hours)\n",
    "    if not class_resources_df['Weekly_Teaching_Hours'].between(20, 50).all():\n",
    "        print(\"Weekly_Teaching_Hours not within realistic range (20-50 hours).\")\n",
    "    else:\n",
    "        print(\"Weekly_Teaching_Hours is within realistic range.\")\n",
    "\n",
    "\n",
    "\n",
    "    # Save to parquet if all checks pass\n",
    "    if (class_resources_df.isnull().values.any() == False and\n",
    "        class_resources_df['Class_ID'].is_unique and\n",
    "        (class_resources_df[numeric_columns] >= 0).all().all() and\n",
    "        class_resources_df['Number_of_Students'].max() <= 100 and\n",
    "        class_resources_df['Number_of_Teachers'].max() <= 20 and\n",
    "        class_resources_df['Weekly_Teaching_Hours'].between(20, 50).all()):\n",
    "        \n",
    "        class_resources_df.to_parquet('./passed_basic_quality_checks/class_resources_table.parquet')\n",
    "        print(\"All data quality checks passed. Data saved as Parquet.\")\n",
    "    else:\n",
    "        print(\"Data quality checks failed.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def extracurricular_activities_data_checks():\n",
    "    # 1. Check for null values in all columns\n",
    "    if extracurricular_df.isnull().values.any():\n",
    "        print(\"Null values found in the dataframe:\\n\", extracurricular_df.isnull().sum())\n",
    "    else:\n",
    "        print(\"No null values found.\")\n",
    "\n",
    "    # 2. Ensure Student_ID exists in student_table\n",
    "    missing_students = extracurricular_df[~extracurricular_df['Student_ID'].isin(student_df['Student_ID'])]\n",
    "    if not missing_students.empty:\n",
    "        print(\"Student_ID(s) missing in student_table:\\n\", missing_students['Student_ID'].unique())\n",
    "    else:\n",
    "        print(\"All Student_IDs exist in student_table.\")\n",
    "\n",
    "    # 3. Verify Weekly_Hours is non-negative and within a realistic range (0-20 hours)\n",
    "    if not extracurricular_df['Weekly_Hours'].between(0, 20).all():\n",
    "        print(\"Weekly_Hours not in the realistic range (0-20 hours) or contains negative values.\")\n",
    "    else:\n",
    "        print(\"Weekly_Hours is within a realistic range (0-20 hours) and non-negative.\")\n",
    "\n",
    "    # Save to parquet if all checks pass\n",
    "    if (extracurricular_df.isnull().values.any() == False and\n",
    "        missing_students.empty and\n",
    "        extracurricular_df['Weekly_Hours'].between(0, 20).all()):\n",
    "        \n",
    "        extracurricular_df.to_parquet('./passed_basic_quality_checks/extracurricular_activity.parquet')\n",
    "        print(\"All data quality checks passed. Data saved as Parquet.\")\n",
    "    else:\n",
    "        print(\"Data quality checks failed.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def parent_data_quality_checks():\n",
    "    # 1. Check for null values in all columns\n",
    "    if parent_df.isnull().values.any():\n",
    "        print(\"Null values found:\\n\", parent_df.isnull().sum())\n",
    "    else:\n",
    "        print(\"No null values found.\")\n",
    "\n",
    "    # 2. Ensure Student_ID is unique and matches with student_table\n",
    "    duplicate_student_ids = parent_df['Student_ID'].duplicated().sum()\n",
    "    if duplicate_student_ids > 0:\n",
    "        print(f\"Found {duplicate_student_ids} duplicate Student_IDs.\")\n",
    "    else:\n",
    "        print(\"All Student_IDs are unique.\")\n",
    "\n",
    "    missing_students = parent_df[~parent_df['Student_ID'].isin(student_df['Student_ID'])]\n",
    "    if not missing_students.empty:\n",
    "        print(\"Student_ID(s) missing in student_table:\\n\", missing_students['Student_ID'].unique())\n",
    "    else:\n",
    "        print(\"All Student_IDs exist in student_table.\")\n",
    "\n",
    "    # 3. Verify Household_Size is positive and within a realistic range (e.g., 1-15)\n",
    "    if not parent_df['Household_Size'].between(1, 15).all():\n",
    "        print(\"Household_Size contains values outside the realistic range (1-15).\")\n",
    "    else:\n",
    "        print(\"Household_Size is within the realistic range.\")\n",
    "\n",
    "    # 4. Check if Annual_Household_Income(NGN) is valid\n",
    "    valid_income_ranges = ['Below 200,000', '200,000-400,000', '400,000-600,000', 'Above 600,000']\n",
    "    if not parent_df['Annual_Household_Income(NGN)'].isin(valid_income_ranges).all():\n",
    "        print(\"Invalid values found in Annual_Household_Income(NGN).\")\n",
    "    else:\n",
    "        print(\"Annual_Household_Income(NGN) has valid values.\")\n",
    "\n",
    "    # 5. Ensure Father_Education, Mother_Education, Father_Occupation, Mother_Occupation, and Involvement_in_Kids_Education have consistent categories\n",
    "    consistent_columns = ['Father_Education', 'Mother_Education', 'Father_Occupation', 'Mother_Occupation', 'Involvement_in_Kids_Education']\n",
    "    for col in consistent_columns:\n",
    "        print(f\"Unique values in {col}:\\n\", parent_df[col].unique())\n",
    "\n",
    "    # Save to parquet if all checks pass\n",
    "    if (parent_df.isnull().values.any() == False and\n",
    "        duplicate_student_ids == 0 and\n",
    "        missing_students.empty and\n",
    "        parent_df['Household_Size'].between(1, 15).all() and\n",
    "        parent_df['Annual_Household_Income(NGN)'].isin(valid_income_ranges).all()):\n",
    "        \n",
    "        parent_df.to_parquet('./passed_basic_quality_checks/parent_table.parquet')\n",
    "        print(\"All data quality checks passed. Data saved as Parquet.\")\n",
    "    else:\n",
    "        print(\"Data quality checks failed.\")\n",
    "\n",
    "\n",
    "\n",
    "def survey_data_quality():\n",
    "    # 1. Check for null values in all columns\n",
    "    if survey_df.isnull().values.any():\n",
    "        print(\"Null values found:\\n\", survey_df.isnull().sum())\n",
    "    else:\n",
    "        print(\"No null values found.\")\n",
    "\n",
    "    # 2. Ensure Student_ID is unique and matches with student_table\n",
    "    if survey_df['Student_ID'].duplicated().any():\n",
    "        print(\"Duplicate Student_IDs found.\")\n",
    "    else:\n",
    "        print(\"All Student_IDs are unique.\")\n",
    "\n",
    "    missing_students_survey = survey_df[~survey_df['Student_ID'].isin(student_df['Student_ID'])]\n",
    "    if not missing_students_survey.empty:\n",
    "        print(\"Student_ID(s) missing in student_table:\\n\", missing_students_survey['Student_ID'].unique())\n",
    "    else:\n",
    "        print(\"All Student_IDs exist in student_table.\")\n",
    "\n",
    "    # 3. Verify Study_Hours_Per_Week is non-negative and within a realistic range (0-50)\n",
    "    if not survey_df['Study_Hours_Per_Week'].between(0, 50).all():\n",
    "        print(\"Study_Hours_Per_Week contains values outside the realistic range (0-50).\")\n",
    "    else:\n",
    "        print(\"Study_Hours_Per_Week is within the realistic range.\")\n",
    "\n",
    "    # 4. Check if Teacher_Support and Parental_Support are within a specific range (1-5)\n",
    "    support_cols = ['Teacher_Support', 'Parental_Support']\n",
    "    for col in support_cols:\n",
    "        if not survey_df[col].between(1, 5).all():\n",
    "            print(f\"{col} contains values outside the range 1-5.\")\n",
    "        else:\n",
    "            print(f\"{col} is within the range 1-5.\")\n",
    "\n",
    "    # 5. Ensure Stress_Level has consistent categories\n",
    "    print(\"Unique values in Stress_Level:\", survey_df['Stress_Level'].unique())\n",
    "\n",
    "    # 6. Verify Jamb_Scores and Num_Credit_Passes_WAEC are within expected ranges\n",
    "    if not survey_df['Jamb_Scores'].between(0, 400).all():\n",
    "        print(\"Jamb_Scores contain values outside the expected range (0-400).\")\n",
    "    else:\n",
    "        print(\"Jamb_Scores are within the expected range.\")\n",
    "\n",
    "    if not survey_df['Num_Credit_Passes_WAEC'].between(0, 9).all():\n",
    "        print(\"Num_Credit_Passes_WAEC contains values outside the expected range (0-9).\")\n",
    "    else:\n",
    "        print(\"Num_Credit_Passes_WAEC is within the expected range.\")\n",
    "\n",
    "    # 7. Check if verdict has consistent categories\n",
    "    print(\"Unique values in verdict:\", survey_df['verdict'].unique())\n",
    "\n",
    "    # Save to parquet if all checks pass\n",
    "    if (survey_df.isnull().values.any() == False and\n",
    "        not survey_df['Student_ID'].duplicated().any() and\n",
    "        missing_students_survey.empty and\n",
    "        survey_df['Study_Hours_Per_Week'].between(0, 50).all() and\n",
    "        survey_df[support_cols].apply(lambda x: x.between(1, 5).all()).all() and\n",
    "        survey_df['Jamb_Scores'].between(0, 400).all() and\n",
    "        survey_df['Num_Credit_Passes_WAEC'].between(0, 9).all()):\n",
    "        \n",
    "        survey_df.to_parquet('./passed_basic_quality_checks/ss3_student_survey.parquet')\n",
    "        print(\"All data quality checks passed. Data saved as Parquet.\")\n",
    "    else:\n",
    "        print(\"Data quality checks failed.\")\n",
    "\n",
    "\n",
    "def staff_data_quality():\n",
    "    # 1. Check for null values in all columns\n",
    "    if staff_df.isnull().values.any():\n",
    "        print(\"Null values found:\\n\", staff_df.isnull().sum())\n",
    "    else:\n",
    "        print(\"No null values found.\")\n",
    "\n",
    "    # 2. Ensure Staff_ID is unique\n",
    "    if staff_df['Staff_ID'].duplicated().any():\n",
    "        print(\"Duplicate Staff_IDs found.\")\n",
    "    else:\n",
    "        print(\"All Staff_IDs are unique.\")\n",
    "\n",
    "    # 3. Verify Monthly Pay and Years of Experience are non-negative\n",
    "    if (staff_df[['Monthly Pay', 'Years of Experience']] < 0).any().any():\n",
    "        print(\"Monthly Pay or Years of Experience contains negative values.\")\n",
    "    else:\n",
    "        print(\"Monthly Pay and Years of Experience are non-negative.\")\n",
    "\n",
    "    # 4. Check if Date of Hire is in a consistent date format and not in the future\n",
    "    staff_df['Date of Hire'] = pd.to_datetime(staff_df['Date of Hire'], errors='coerce')\n",
    "    future_dates = staff_df[staff_df['Date of Hire'] > pd.Timestamp.now()]\n",
    "    if not future_dates.empty:\n",
    "        print(\"Future Date of Hire values found:\\n\", future_dates['Date of Hire'])\n",
    "    else:\n",
    "        print(\"All Date of Hire values are valid.\")\n",
    "\n",
    "    # 5. Ensure Gender, Position, and Education Level have consistent categories\n",
    "    print(\"Unique values in Gender:\", staff_df['Gender'].unique())\n",
    "    print(\"Unique values in Position:\", staff_df['Position'].unique())\n",
    "    print(\"Unique values in Education Level:\", staff_df['Education Level'].unique())\n",
    "\n",
    "    # Save to parquet if all checks pass\n",
    "    if (staff_df.isnull().values.any() == False and\n",
    "        not staff_df['Staff_ID'].duplicated().any() and\n",
    "        not (staff_df[['Monthly Pay', 'Years of Experience']] < 0).any().any() and\n",
    "        future_dates.empty):\n",
    "        \n",
    "        staff_df.to_parquet('./passed_basic_quality_checks/staff_table.parquet')\n",
    "        print(\"All data quality checks passed. Data saved as Parquet.\")\n",
    "    else:\n",
    "        print(\"Data quality checks failed.\")\n",
    "\n",
    "\n",
    "\n",
    "def performance_data_quality():\n",
    "\n",
    "    # 1. Check for null values in relevant columns\n",
    "    if performance_df[['Mathematics', 'English Language', 'Civic Education', 'Economics', 'CRS/Islam']].isnull().any().any():\n",
    "        print(\"Null values found in key columns:\\n\", performance_df[['Mathematics', 'English Language', 'Civic Education', 'Economics', 'CRS/Islam']].isnull().sum())\n",
    "    else:\n",
    "        print(\"No null values found in the relevant columns.\")\n",
    "\n",
    "    # 2. Ensure Student_ID is unique and matches with student_table\n",
    "    if performance_df['Student_ID'].duplicated().any():\n",
    "        print(\"Duplicate Student_IDs found.\")\n",
    "    else:\n",
    "        print(\"All Student_IDs are unique.\")\n",
    "\n",
    "    # Check if Student_IDs exist in student_table\n",
    "    missing_students_perf = performance_df[~performance_df['Student_ID'].isin(student_df['Student_ID'])]\n",
    "    if not missing_students_perf.empty:\n",
    "        print(\"Student_ID(s) missing in student_table:\\n\", missing_students_perf['Student_ID'].unique())\n",
    "    else:\n",
    "        print(\"All Student_IDs exist in student_table.\")\n",
    "\n",
    "    # 3. Verify that scores for 'Mathematics', 'English Language', 'Civic Education', 'Economics', 'CRS/Islam' are within the expected range (0-100)\n",
    "    columns_to_check = ['Mathematics', 'English Language', 'Civic Education', 'Economics', 'CRS/Islam']\n",
    "    valid_scores = performance_df[columns_to_check].apply(lambda x: x.between(0, 100) | x.isna()).all()\n",
    "    if not valid_scores.all():\n",
    "        print(\"Some scores are outside the expected range (0-100) in these columns:\", valid_scores[~valid_scores].index.tolist())\n",
    "    else:\n",
    "        print(\"All non-null scores are within the expected range (0-100).\")\n",
    "\n",
    "    # 4. Check for any outliers in the scores (based on z-scores), ignoring NaN\n",
    "    z_scores = (performance_df[columns_to_check] - performance_df[columns_to_check].mean()) / performance_df[columns_to_check].std()\n",
    "    outliers = z_scores.abs() > 3  # Threshold for outliers (z-score > 3)\n",
    "    if outliers.any().any():\n",
    "        print(\"Outliers found in the following columns:\\n\", outliers.columns[outliers.any()])\n",
    "    else:\n",
    "        print(\"No significant outliers found.\")\n",
    "\n",
    "    # 5. Ignore NaN columns, ensure decimal places for float64 columns are consistent\n",
    "    float_columns = performance_df[columns_to_check].select_dtypes(include=['float64']).columns\n",
    "    if performance_df[float_columns].apply(lambda x: x.apply(lambda v: len(str(v).split('.')[-1]) if '.' in str(v) else 0).nunique() > 1).any():\n",
    "        print(\"Inconsistent decimal places in float64 columns.\")\n",
    "    else:\n",
    "        print(\"Decimal places are consistent in float64 columns.\")\n",
    "\n",
    "    # Save to parquet if all checks pass\n",
    "    if (performance_df[['Mathematics', 'English Language', 'Civic Education', 'Economics', 'CRS/Islam']].isnull().any().any() == False and\n",
    "        not performance_df['Student_ID'].duplicated().any() and\n",
    "        missing_students_perf.empty and\n",
    "        valid_scores.all() and\n",
    "        not outliers.any().any()):\n",
    "\n",
    "\n",
    "        \n",
    "        performance_df.to_parquet('./passed_basic_quality_checks/student_performance.parquet')\n",
    "        print(\"All data quality checks passed. Data saved as Parquet.\")\n",
    "    else:\n",
    "        print(\"Data quality checks failed.\")\n",
    "\n",
    "\n",
    "\n",
    "def student_data_quality_checks():\n",
    "    # 1. Check for null values in all columns\n",
    "    if student_df.isnull().any().any():\n",
    "        print(\"Null values found in the following columns:\\n\", student_df.isnull().sum())\n",
    "    else:\n",
    "        print(\"No null values found in any columns.\")\n",
    "\n",
    "    # 2. Ensure Student_ID is unique\n",
    "    if student_df['Student_ID'].duplicated().any():\n",
    "        print(\"Duplicate Student_IDs found.\")\n",
    "    else:\n",
    "        print(\"All Student_IDs are unique.\")\n",
    "\n",
    "    # 3. Verify Class_ID exists in class_resources_table\n",
    "    missing_class_ids = student_df[~student_df['Class_ID'].isin(class_resources_df['Class_ID'])]\n",
    "    if not missing_class_ids.empty:\n",
    "        print(\"Class_ID(s) missing in class_resources_table:\\n\", missing_class_ids['Class_ID'].unique())\n",
    "    else:\n",
    "        print(\"All Class_IDs exist in class_resources_table.\")\n",
    "\n",
    "    # 4. Check if Date_of_Birth is in a consistent date format and makes sense for a student\n",
    "    # Assuming the format is 'YYYY-MM-DD'\n",
    "    def check_date_format(date_str):\n",
    "        try:\n",
    "            return pd.to_datetime(date_str, format='%Y-%m-%d', errors='raise')\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "    invalid_dates = student_df['Date_of_Birth'].apply(check_date_format).isnull()\n",
    "    if invalid_dates.any():\n",
    "        print(\"Invalid Date_of_Birth found:\\n\", student_df[invalid_dates]['Date_of_Birth'])\n",
    "    else:\n",
    "        print(\"All Date_of_Births are in a consistent format.\")\n",
    "\n",
    "    # 5. Ensure Gender, State of Origin, engagement_in_class, health_condition, and Class Spec have consistent categories\n",
    "    # Example categories\n",
    "    gender_categories = ['Male', 'Female']\n",
    "    state_origin_categories = nigeria_states  \n",
    "    engagement_categories = ['Troublesome','Unactive','Slightly active','Active','Highly active']\n",
    "    health_condition_categories = health_condition\n",
    "    class_spec_categories = ['Science', 'Art']  \n",
    "\n",
    "    if not student_df['Gender'].isin(gender_categories).all():\n",
    "        print(\"Inconsistent categories found in Gender column.\")\n",
    "    if not student_df['State of Origin'].isin(state_origin_categories).all():\n",
    "        print(\"Inconsistent categories found in State of Origin column.\")\n",
    "    if not student_df['engagement_in_class'].isin(engagement_categories).all():\n",
    "        print(\"Inconsistent categories found in engagement_in_class column.\")\n",
    "    if not student_df['health_condition'].isin(health_condition_categories).all():\n",
    "        print(\"Inconsistent categories found in health_condition column.\")\n",
    "    if not student_df['Class Spec'].isin(class_spec_categories).all():\n",
    "        print(\"Inconsistent categories found in Class Spec column.\")\n",
    "\n",
    "    # Save to parquet if all checks pass\n",
    "    if (not student_df.isnull().any().any() and\n",
    "        not student_df['Student_ID'].duplicated().any() and\n",
    "        missing_class_ids.empty and not invalid_dates.any()):\n",
    "        \n",
    "        student_df.to_parquet('./passed_basic_quality_checks/student_table.parquet')\n",
    "        print(\"All data quality checks passed. Data saved as Parquet.\")\n",
    "    else:\n",
    "        print(\"Data quality checks failed.\")\n",
    "\n",
    "\n",
    "\n",
    "def teacher_data_quality_checks():\n",
    "\n",
    "    # 1. Check for null values in all columns\n",
    "    if teachers_df.isnull().any().any():\n",
    "        print(\"Null values found in the following columns:\\n\", teachers_df.isnull().sum())\n",
    "    else:\n",
    "        print(\"No null values found in any columns.\")\n",
    "\n",
    "    # 2. Ensure Teacher_ID is unique\n",
    "    if teachers_df['Teacher_ID'].duplicated().any():\n",
    "        print(\"Duplicate Teacher_IDs found.\")\n",
    "    else:\n",
    "        print(\"All Teacher_IDs are unique.\")\n",
    "\n",
    "    # 3. Verify Staff_ID exists in staff_table\n",
    "    missing_staff_ids = teachers_df[~teachers_df['Staff_ID'].isin(staff_df['Staff_ID'])]\n",
    "    if not missing_staff_ids.empty:\n",
    "        print(\"Staff_ID(s) missing in staff_table:\\n\", missing_staff_ids['Staff_ID'].unique())\n",
    "    else:\n",
    "        print(\"All Staff_IDs exist in staff_table.\")\n",
    "\n",
    "    # 4. Ensure Teacher Type and Subject specialization have consistent categories\n",
    "    # Example categories\n",
    "    teacher_type_categories = ['Full-Time', 'Part-Time', 'Substitute']  # Update as per your data\n",
    "    subject_specialization_categories = ['Math', 'Science', 'English', 'History']  # Update as per your data\n",
    "\n",
    "    if not teachers_df['Teacher Type'].isin(teacher_type_categories).all():\n",
    "        print(\"Inconsistent categories found in Teacher Type column.\")\n",
    "    if not teachers_df['Subject specialization'].isin(subject_specialization_categories).all():\n",
    "        print(\"Inconsistent categories found in Subject specialization column.\")\n",
    "\n",
    "    # Save to parquet if all checks pass\n",
    "    if (not teachers_df.isnull().any().any() and\n",
    "        not teachers_df['Teacher_ID'].duplicated().any() and\n",
    "        missing_staff_ids.empty):\n",
    "        \n",
    "        teachers_df.to_parquet('./passed_basic_quality_checks/teachers_table.parquet')\n",
    "        print(\"All data quality checks passed. Data saved as Parquet.\")\n",
    "    else:\n",
    "        print(\"Data quality checks failed.\")\n",
    "\n",
    "student_data_quality_checks()\n",
    "\n",
    "performance_data_quality()\n",
    "\n",
    "staff_data_quality()\n",
    "\n",
    "survey_data_quality()\n",
    "\n",
    "parent_data_quality_checks()\n",
    "\n",
    "extracurricular_activities_data_checks()\n",
    "\n",
    "class_resources_quality_checks()\n",
    "\n",
    "attendance_quality_checks()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
