{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxttG4x-SW_T",
        "outputId": "4b670b9b-4bda-48f3-bffe-7fb236892278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading PyMuPDF-1.24.13-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (19.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.13\n"
          ]
        }
      ],
      "source": [
        "!pip install PyMuPDF\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF for PDF extraction\n",
        "import json   # For JSON structure\n"
      ],
      "metadata": {
        "id": "Xy3xS5JFSetS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_pdf_text(pdf_path):\n",
        "    # Open the PDF file using fitz\n",
        "    doc = fitz.open(pdf_path)\n",
        "\n",
        "    # Initialize a variable to store the extracted text\n",
        "    full_text = \"\"\n",
        "\n",
        "    # Loop through all pages and extract text\n",
        "    for page_num in range(doc.page_count):\n",
        "        page = doc.load_page(page_num)\n",
        "        full_text += page.get_text()  # Extract text from the page\n",
        "\n",
        "    # Close the PDF document\n",
        "    doc.close()\n",
        "\n",
        "    return full_text\n",
        "\n"
      ],
      "metadata": {
        "id": "aWNu7T_9SkdM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def structure_pdf_to_json(pdf_path):\n",
        "    extracted_text = extract_pdf_text(pdf_path)\n",
        "\n",
        "    # Initialize a dictionary to store the structured data\n",
        "    structured_data = {}\n",
        "\n",
        "    # Split the extracted text into sections based on some pattern, e.g., newlines or headers\n",
        "    lines = extracted_text.split(\"\\n\")\n",
        "\n",
        "    # Example logic: You may need to customize this based on your document's format\n",
        "    headers = []\n",
        "    list_items = []\n",
        "\n",
        "    for line in lines:\n",
        "        if line.strip():  # Avoid empty lines\n",
        "            if line.startswith(\"Table\"):  # Assuming table starts with \"Table\"\n",
        "                list_items.append(line)  # Add to list_items if it's a table\n",
        "            else:\n",
        "                headers.append(line)  # Otherwise, consider it a header or paragraph\n",
        "\n",
        "    # Store the extracted headers and list items into the structured_data dictionary\n",
        "    structured_data[\"headers\"] = headers\n",
        "    structured_data[\"List_items\"] = list_items\n",
        "\n",
        "    return structured_data\n"
      ],
      "metadata": {
        "id": "4JqpiqB8So_A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_json(structured_data, output_file):\n",
        "    # Save the structured data as a JSON file\n",
        "    with open(output_file, \"w\") as json_file:\n",
        "        json.dump(structured_data, json_file, indent=4)\n",
        "\n",
        "# Path to the PDF file\n",
        "pdf_path = \"/Cognitive neuroscience and robotics.pdf\"\n",
        "\n",
        "# Structure the extracted text into a JSON format\n",
        "structured_data = structure_pdf_to_json(pdf_path)\n",
        "\n",
        "# Save the JSON output\n",
        "save_to_json(structured_data, \"/content/output_file.json\")\n",
        "\n",
        "print(\"JSON file has been saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQQzZEFBSw5B",
        "outputId": "a6bf07c6-4630-4978-fd40-a9ad274db0d2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JSON file has been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/output_file.json')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "N1gjSOVATheh",
        "outputId": "af0433ae-4aa9-4714-8e3c-cbe355ebd920"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1daddf28-02af-4eb3-9011-0bc4c122c537\", \"output_file.json\", 205708)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/output_file.json', 'r') as f:\n",
        "    print(f.read())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VULyWB7T93s",
        "outputId": "7021638a-4581-48ce-9c81-8f1282f41fb1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"headers\": [\n",
            "        \"Robotics and Computer\\u2013Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"Available online 24 July 2023\",\n",
            "        \"0736-5845/\\u00a9 2023 The Authors. Published by Elsevier Ltd. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).\",\n",
            "        \"Contents lists available at ScienceDirect\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing\",\n",
            "        \"journal homepage: www.elsevier.com/locate/rcim\",\n",
            "        \"Review\",\n",
            "        \"Cognitive neuroscience and robotics: Advancements and future research\",\n",
            "        \"directions\",\n",
            "        \"Sichao Liu a,b,\\u2217, Lihui Wang a,\\u2217\\u2217, Robert X. Gao c\",\n",
            "        \"a Department of Production Engineering, KTH Royal Institute of Technology, Sweden\",\n",
            "        \"b ABB Corporate Research, V\\u00e4ster\\u00e5s, Sweden\",\n",
            "        \"c Department of Mechanical and Aerospace Engineering, Case Western Reserve University, Cleveland, OH, USA\",\n",
            "        \"A R T I C L E\",\n",
            "        \"I N F O\",\n",
            "        \"Keywords:\",\n",
            "        \"Brain robotics\",\n",
            "        \"Brain\\u2013computer interface\",\n",
            "        \"Brainwave/electroencephalography\",\n",
            "        \"Signal processing\",\n",
            "        \"Deep learning\",\n",
            "        \"Robot control\",\n",
            "        \"A B S T R A C T\",\n",
            "        \"In recent years, brain-based technologies that capitalise on human abilities to facilitate human\\u2013system/robot\",\n",
            "        \"interactions have been actively explored, especially in brain robotics. Brain\\u2013computer interfaces, as applications\",\n",
            "        \"of this conception, have set a path to convert neural activities recorded by sensors from the human scalp via\",\n",
            "        \"electroencephalography into valid commands for robot control and task execution. Thanks to the advancement\",\n",
            "        \"of sensor technologies, non-invasive and invasive sensor headsets have been designed and developed to\",\n",
            "        \"achieve stable recording of brainwave signals. However, robust and accurate extraction and interpretation\",\n",
            "        \"of brain signals in brain robotics are critical to reliable task-oriented and opportunistic applications such\",\n",
            "        \"as brainwave-controlled robotic interactions. In response to this need, pervasive technologies and advanced\",\n",
            "        \"analytical approaches to translating and merging critical brain functions, behaviours, tasks, and environmental\",\n",
            "        \"information have been a focus in brain-controlled robotic applications. These methods are composed of signal\",\n",
            "        \"processing, feature extraction, representation of neural activities, command conversion and robot control.\",\n",
            "        \"Artificial intelligence algorithms, especially deep learning, are used for the classification, recognition, and\",\n",
            "        \"identification of patterns and intent underlying brainwaves as a form of electroencephalography. Within the\",\n",
            "        \"context, this paper provides a comprehensive review of the past and the current status at the intersection of\",\n",
            "        \"robotics, neuroscience, and artificial intelligence and highlights future research directions.\",\n",
            "        \"1. Introduction\",\n",
            "        \"Brain\\u2013computer interfaces allow control of applications or exter-\",\n",
            "        \"nal devices solely by brain neural activities, measured by different\",\n",
            "        \"neuroimages techniques, e.g., electroencephalography or functional\",\n",
            "        \"near-infrared spectroscopy [1]. It works as a neurofeedback tool to\",\n",
            "        \"allow the use of a brainwave-based communication channel for human\\u2013\",\n",
            "        \"computer/machine or human-to-object interactions and offers comple-\",\n",
            "        \"mentary support to multimodal interaction scenarios as an alternative\",\n",
            "        \"to auditory, haptics, gestures, and vision [2]. Thanks to the develop-\",\n",
            "        \"ment of neurophysiological sensor technologies, the BCIs as wearable\",\n",
            "        \"and portable devices undergo rapid iterations and evolution and enable\",\n",
            "        \"a wide range of possible applications both in clinical and non-clinical\",\n",
            "        \"domains [3]. Within the context, roboticists have utilised insights from\",\n",
            "        \"neuroscience to facilitate the development of better-performing robots\",\n",
            "        \"and relevant applications, and this involves the interdisciplinary fusion\",\n",
            "        \"of robotics, neuroscience, and artificial intelligence [4], which has\",\n",
            "        \"led to the inception of a nascent research area: brain robotics as\",\n",
            "        \"\\u2217Corresponding author at: Department of Production Engineering, KTH Royal Institute of Technology, Sweden.\",\n",
            "        \"\\u2217\\u2217Corresponding author.\",\n",
            "        \"E-mail addresses: sicliu@kth.se (S. Liu), lihui.wang@iip.kth.se (L. Wang), Robert.Gao@case.edu (R.X. Gao).\",\n",
            "        \"shown in Fig. 1, emphasising the utilisation of such neuro-engineering\",\n",
            "        \"approaches. In parallel, BRIs inherited from BCIs are developed to\",\n",
            "        \"achieve brain-enabled robot control, mapping brain neural activities\",\n",
            "        \"that represent behavioural intentions to tasks performed by robots.\",\n",
            "        \"In the last decade, research efforts on brain robotics have been\",\n",
            "        \"numerous. Varying approaches to facilitating the design and devel-\",\n",
            "        \"opment of headset electrodes, brain modelling in neuroscience/brain\",\n",
            "        \"science, brain signal processing for feature extraction, classification\",\n",
            "        \"and identification of users\\u2019 thoughts and emotional states, and brain\",\n",
            "        \"feedback to control robots have been explored in the literature [5].\",\n",
            "        \"Applications of brain\\u2013robot interface systems have been increasingly\",\n",
            "        \"expanded from rehabilitation of people with mental traumas such as\",\n",
            "        \"cerebral stroke to diagnosis of psychological and neural disorders as\",\n",
            "        \"well as applications of component assembly [6]. However, several\",\n",
            "        \"scientific and engineering challenges in brain robotics remain such as\",\n",
            "        \"https://doi.org/10.1016/j.rcim.2023.102610\",\n",
            "        \"Received 25 April 2023; Received in revised form 30 June 2023; Accepted 3 July 2023\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"2\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Nomenclature\",\n",
            "        \"2D\",\n",
            "        \"Two-Dimensional\",\n",
            "        \"3D\",\n",
            "        \"Three-Dimensional\",\n",
            "        \"AI\",\n",
            "        \"Artificial Intelligence\",\n",
            "        \"AR\",\n",
            "        \"Augmented Reality\",\n",
            "        \"BCI\",\n",
            "        \"Brain\\u2013Computer Interface\",\n",
            "        \"BiLSTM\",\n",
            "        \"Bidirectional Long Short-Term Memory\",\n",
            "        \"BRI\",\n",
            "        \"Brain\\u2013Robot Interface\",\n",
            "        \"BSS\",\n",
            "        \"Blind Source Separation\",\n",
            "        \"CAR\",\n",
            "        \"Common Average Reference\",\n",
            "        \"CCA\",\n",
            "        \"Canonical Correlation Analysis\",\n",
            "        \"CNN\",\n",
            "        \"Convolutional Neural Network\",\n",
            "        \"CSP\",\n",
            "        \"Common Spatial Pattern\",\n",
            "        \"CT\",\n",
            "        \"Computerised Tomography\",\n",
            "        \"DBN\",\n",
            "        \"Deep Belief Network\",\n",
            "        \"DBS\",\n",
            "        \"Deep Brain Stimulation\",\n",
            "        \"DL\",\n",
            "        \"Deep Learning\",\n",
            "        \"DoF\",\n",
            "        \"Degree of Freedom\",\n",
            "        \"ECoG\",\n",
            "        \"Electrocorticogram\",\n",
            "        \"EEG\",\n",
            "        \"Electroencephalography\",\n",
            "        \"EMD\",\n",
            "        \"Empirical Mode Decomposition\",\n",
            "        \"ENE\",\n",
            "        \"Elastic Net Electrochemistry\",\n",
            "        \"EOG\",\n",
            "        \"Electrooculography\",\n",
            "        \"ERP\",\n",
            "        \"Event-Related Potential\",\n",
            "        \"ErrP\",\n",
            "        \"Error Related Potential\",\n",
            "        \"FFT\",\n",
            "        \"Fast Fourier Transform\",\n",
            "        \"fMRI\",\n",
            "        \"Functional Magnetic Resonance Imaging\",\n",
            "        \"GAN\",\n",
            "        \"Generative Adversarial Network\",\n",
            "        \"GCN\",\n",
            "        \"Graph Convolutional Neural Network\",\n",
            "        \"GNN\",\n",
            "        \"Graph Neural Network\",\n",
            "        \"GRU\",\n",
            "        \"Gated Recurrent Unit\",\n",
            "        \"HRC\",\n",
            "        \"Human\\u2013Robot Collaboration\",\n",
            "        \"ICA\",\n",
            "        \"Independent Component Analysis\",\n",
            "        \"ISO\",\n",
            "        \"International Organization for Standardiza-\",\n",
            "        \"tion\",\n",
            "        \"LDA\",\n",
            "        \"Linear Discriminant Analysis\",\n",
            "        \"LSTM\",\n",
            "        \"Long Short-Term Memory\",\n",
            "        \"MEG\",\n",
            "        \"Magnetoencephalography\",\n",
            "        \"MI\",\n",
            "        \"Motor Imagery\",\n",
            "        \"MRI\",\n",
            "        \"Magnetic Resonance Imaging\",\n",
            "        \"NIRS\",\n",
            "        \"Near-Infrared Spectroscopy\",\n",
            "        \"OPM\",\n",
            "        \"Optically Pumped Magnetometer\",\n",
            "        \"P300\",\n",
            "        \"P300 Visual-Evoked Potential\",\n",
            "        \"PCA\",\n",
            "        \"Principal Component Analysis\",\n",
            "        \"PET\",\n",
            "        \"Positron Emission Tomography\",\n",
            "        \"PSD\",\n",
            "        \"Power Spectral Density\",\n",
            "        \"RCNN\",\n",
            "        \"Region-Based CNN\",\n",
            "        \"RL\",\n",
            "        \"Reinforcement Learning\",\n",
            "        \"RNN\",\n",
            "        \"Recurrent Neural Network\",\n",
            "        \"ROS\",\n",
            "        \"Robot Operating System\",\n",
            "        \"SCA\",\n",
            "        \"Sparse Component Analysis\",\n",
            "        \"SNR\",\n",
            "        \"Signal-Noise Ratio\",\n",
            "        \"SPECT\",\n",
            "        \"Single Photon Emission Computed Tomog-\",\n",
            "        \"raphy\",\n",
            "        \"SSA\",\n",
            "        \"Singular Spectrum Analysis\",\n",
            "        \"SSVEP\",\n",
            "        \"Steady-State Visually Evoked Potential\",\n",
            "        \"STFT\",\n",
            "        \"Short-Time Fourier Transform\",\n",
            "        \"STGCN\",\n",
            "        \"Spatial\\u2013Temporal GCN\",\n",
            "        \"SVM\",\n",
            "        \"Support Vector Machine\",\n",
            "        \"tDCS\",\n",
            "        \"Transcranial Direct Current Stimulation\",\n",
            "        \"TMS\",\n",
            "        \"Transcranial Magnetic Stimulation\",\n",
            "        \"VR\",\n",
            "        \"Virtual Reality\",\n",
            "        \"WT\",\n",
            "        \"Wavelet Transform\",\n",
            "        \"human-grade technology for chronic interfacing with the brain, ac-\",\n",
            "        \"curate elaboration of neural activities decoders, translation of hu-\",\n",
            "        \"man brainwaves into robot control commands, and advanced control\",\n",
            "        \"schemes of human\\u2013robot adaption. Motivated by these challenges, this\",\n",
            "        \"paper provides a systematic review and analysis of this very subject.\",\n",
            "        \"This paper starts with an introduction to BCI-based robotics. The\",\n",
            "        \"remainder of the paper is organised as follows. Section 2 introduces\",\n",
            "        \"brain functions and signals as well as widely-used BCI sensor headsets\",\n",
            "        \"together with a performance comparison. Section 3 presents tech-\",\n",
            "        \"nologies and tools for brain signal acquisition and processing. Sec-\",\n",
            "        \"tion 4 presents a comprehensive review of learning-based algorithms\",\n",
            "        \"in brain signal classification, especially DL and statistical learning. Sec-\",\n",
            "        \"tion 5 summarises brain-controlled robotic applications based on neural\",\n",
            "        \"interfaces. Section 6 highlights key challenges and future research\",\n",
            "        \"directions. Finally, Section 7 draws conclusions.\",\n",
            "        \"2. From brain science to brain signals\",\n",
            "        \"Brain neurons can send and receive chemical and electrical signals\",\n",
            "        \"that are associated with different process control. From a high-level\",\n",
            "        \"perspective of brain science, the brain can be divided into the cere-\",\n",
            "        \"brum, brainstem, and cerebellum as shown in Fig. 2 [7]. Firstly, the\",\n",
            "        \"cerebrum is located in the front of the brain and consists of white\",\n",
            "        \"matter (at the centre area) and grey matter. The cerebrum is the largest\",\n",
            "        \"part of the brain and is covered by the cerebral cortex which describes\",\n",
            "        \"the outer grey matter. The cerebral cortex is divided into two halves\",\n",
            "        \"called hemispheres and is often characterised as being made up of three\",\n",
            "        \"types of areas: sensory, motor, and association areas. Each cerebral\",\n",
            "        \"hemisphere is divided into four sections called lobes and they are the\",\n",
            "        \"frontal lobe, the parietal lobe, the occipital lobe, and the temporal\",\n",
            "        \"lobe [8]. The functions of each lobe are summarised in Table 1. The\",\n",
            "        \"brainstem connects with the cerebrum through the spinal cord, which\",\n",
            "        \"is composed of a midbrain, a pons, and a medulla. The midbrain has a\",\n",
            "        \"very complex structure with a range of different neuron clusters, neural\",\n",
            "        \"pathways and other structures. These features define various functions,\",\n",
            "        \"from hearing and movement to calculating responses and environmen-\",\n",
            "        \"tal changes. The pons, as the origin for four of the 12 cranial nerves,\",\n",
            "        \"are associated with function control (e.g., chewing, blinking, focusing\",\n",
            "        \"vision, balance, hearing and facial expression). The pons serves as a\",\n",
            "        \"connection bridge between the midbrain and the medulla [9]. The\",\n",
            "        \"cerebellum is a fist-sized portion of the brain located at the back\",\n",
            "        \"of the head, below the temporal and occipital lobes and above the\",\n",
            "        \"brainstem. The outer portion of the cerebellum contains neurons, and\",\n",
            "        \"its inner area communicates with the cerebral cortex. The cerebellum\",\n",
            "        \"is mainly associated with coordinating and regulating a wide range\",\n",
            "        \"of functions and processes in both brain and body, and the functions\",\n",
            "        \"relating to movement and coordination include maintaining balance,\",\n",
            "        \"coordinating movement, vision, motor learning and other cerebellum\",\n",
            "        \"roles in thought, emotions and social behaviour [10].\",\n",
            "        \"As the centre of the brain\\u2019s nervous system, the cerebral cortex is\",\n",
            "        \"made up primarily of a grey structure composed of nerve cells that\",\n",
            "        \"cover the surface of the cerebral hemisphere as shown in Fig. 3 [13]. It\",\n",
            "        \"forms extensive connections with the subcortical areas and is involved\",\n",
            "        \"in multitudinous brain functions. The human brain is a complex neural\",\n",
            "        \"system that consists of 86 billion neurons. Neurons send and receive\",\n",
            "        \"information, and are connected with each other through synapses.\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"3\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Fig. 1. Concept and workflow of brain robotics.\",\n",
            "        \"Fig. 2. Human brain sagittal view [11].\",\n",
            "        \"As shown in Fig. 4, neuron anatomy is generally composed of three\",\n",
            "        \"parts: a dendrite, a cell body (a soma), and an axon, which receives,\",\n",
            "        \"computes, and sends a signal out, respectively. Therefore, neurons can\",\n",
            "        \"carry information about everything we see, feel, touch, or think through\",\n",
            "        \"communication with electric signals [14]. The neural activities can be\",\n",
            "        \"measured by the electric signals and they are substantially indicated\",\n",
            "        \"by action potentials, which cause synapses to release neurotransmitters.\",\n",
            "        \"These small molecules bind to receptors on dendrites, opening channels\",\n",
            "        \"that cause current to flow across the neuron\\u2019s membrane. When a\",\n",
            "        \"neuron receives the \\u2018right\\u2019 combination of spatial\\u2013temporal synaptic\",\n",
            "        \"inputs, it initiates an action potential. Finally, these electric signals\",\n",
            "        \"can be recorded by electrodes placed near neurons in the form of EEG\",\n",
            "        \"signals used for decoding neural activities.\",\n",
            "        \"In the brain\\u2019s neural activities, the electric signal from one neuron to\",\n",
            "        \"another is too weak and not recordable. When the millions of neurons\",\n",
            "        \"synchronise and fire, the electric action potential field produced can\",\n",
            "        \"be measured from the scalp. The EEG signal is a mixture of multiple\",\n",
            "        \"underlying base frequencies, which is considered to reflect cognitive\",\n",
            "        \"activities and functional brain states over time. The EEG frequency is\",\n",
            "        \"classified into five sub-frequency ranges and they are delta (0.5\\u20134 Hz),\",\n",
            "        \"theta (4\\u20137 Hz), alpha (7\\u201312 Hz), beta (13\\u201330 Hz), and gamma-band\",\n",
            "        \"waveforms (>30 Hz) [15]. Different frequency ranges of EEG signals are\",\n",
            "        \"associated with specific functions of neural activities, and the summary\",\n",
            "        \"of these connections between brain frequencies and functions is as\",\n",
            "        \"follows:\",\n",
            "        \"\\u2219Delta-band activities are associated with deep stages of sleep and\",\n",
            "        \"are characterised by low-frequency and high-amplitude waves.\",\n",
            "        \"Delta rhythms can be present during wakefulness and delta waves\",\n",
            "        \"have been recorded interictally in patients with absence seizures,\",\n",
            "        \"which have the feature of brief, sudden lapses in attention.\",\n",
            "        \"\\u2219Theta waveform is often associated with the behavioural states of\",\n",
            "        \"alertness, attention, orientation, and working memory including\",\n",
            "        \"the enhancement of cognitive and perceptual performances. The\",\n",
            "        \"theta rhythm detected in EEG measurement is often found in\",\n",
            "        \"young adults, particularly over the temporal regions and during\",\n",
            "        \"hyperventilation.\",\n",
            "        \"\\u2219Alpha waves are often associated with a relaxed, calm and lucid\",\n",
            "        \"state of mind. Alpha waves can be found in the occipital and\",\n",
            "        \"posterior regions of the brain. Alpha waves can be induced by\",\n",
            "        \"closing one\\u2019s eyes and when humans are in relaxing states, and\",\n",
            "        \"they are rarely present during intense cognitive processes like\",\n",
            "        \"thinking, mental calculus and problem-solving.\",\n",
            "        \"\\u2219Beta waves are most closely associated with being conscious or in\",\n",
            "        \"an awake, attentive and alert state. Low-amplitude beta waves are\",\n",
            "        \"associated with active concentration, or with a busy or anxious\",\n",
            "        \"state of mind. Beta waves are also associated with motor decisions\",\n",
            "        \"(suppression of movement and sensory feedback of motion).\",\n",
            "        \"\\u2219Gamma frequencies are distributed widely throughout cerebral\",\n",
            "        \"structures and participate in various cerebral functions, such as\",\n",
            "        \"perception, attention, memory, consciousness, synaptic plasticity,\",\n",
            "        \"and motor control.\",\n",
            "        \"The commonly used measurement techniques of the electric signals\",\n",
            "        \"produced by neural activities are classified into two types, namely\",\n",
            "        \"invasive and non-invasive neuroimaging techniques. Table 2 lists a\",\n",
            "        \"wide range of neuroimaging instruments for the measurement of neural\",\n",
            "        \"activities. The invasive technique uses implantable microelectrodes to\",\n",
            "        \"measure the signals of the brain directly from the cortex\\u2019s surface.\",\n",
            "        \"Implantable BCIs have received a great deal of attention in recent\",\n",
            "        \"years, with a number of high-profile companies entering the race\",\n",
            "        \"to develop BCI technologies for advanced applications. The typical\",\n",
            "        \"invasive techniques include electrocorticogram, DBS, and elastic net\",\n",
            "        \"electrochemistry [19]. The detailed introduction to these three types\",\n",
            "        \"of invasive techniques is summarised in Table 2. These invasive in-\",\n",
            "        \"struments have good performances in spatial and temporal resolutions,\",\n",
            "        \"signal amplitude, signal-noise ratio, artefact rejection, and frequency\",\n",
            "        \"range. However, the invasive technique still faces challenges of (1)\",\n",
            "        \"scaling up the number of wireless and fully implanted electrodes; (2)\",\n",
            "        \"reducing per-channel chip size and power consumption for on-chip,\",\n",
            "        \"real-time identification and characterisation of neural spikes; and (3)\",\n",
            "        \"neurosurgery clinical requirements which involve high risks of safety\",\n",
            "        \"and ethics [20]. Given the potential risk and drawbacks, non-invasive\",\n",
            "        \"measurement tools are widely used to enable their users to interact with\",\n",
            "        \"the environment through their brain activities alone, by performing\",\n",
            "        \"mental tasks such as mental calculation or MI. Some of the common\",\n",
            "        \"non-invasive neuroimaging techniques include (1) magnetic resonance\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"4\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Fig. 3. Structure of human brain and waveform functions [12].\",\n",
            "        \"Functionalities of human brain areas [16].\",\n",
            "        \"Area\",\n",
            "        \"Functionality\",\n",
            "        \"Frontal\",\n",
            "        \"Cognitive decision making, personality characteristics, movement, speaking, emotion,\",\n",
            "        \"and self-awareness\",\n",
            "        \"Parietal\",\n",
            "        \"Object identification, understanding spatial relationships, interpreting language, sense\",\n",
            "        \"of touch/pain/temperature\",\n",
            "        \"Occipital\",\n",
            "        \"Location integration and visual processing (colour, light, movement)\",\n",
            "        \"Temporal\",\n",
            "        \"Short-term memory, speech, musical rhythm and some degrees of smell recognition,\",\n",
            "        \"language understanding, sequencing and organisation\",\n",
            "        \"Summary of instruments to measure neural activities of human brain.\",\n",
            "        \"Technique\",\n",
            "        \"Name\",\n",
            "        \"Specifications\",\n",
            "        \"Invasive\",\n",
            "        \"neuroimaging\",\n",
            "        \"DBS\",\n",
            "        \"Involves implanting electrodes within certain areas of the brain and these electrodes\",\n",
            "        \"produce electrical impulses that regulate abnormal impulses\",\n",
            "        \"ENE\",\n",
            "        \"Detects rapidly changing electrochemical signals from human brains\",\n",
            "        \"ECoG\",\n",
            "        \"Uses electrodes placed directly on the exposed surface of the brain to record\",\n",
            "        \"electrical activities from the cerebral cortex.\",\n",
            "        \"Non-invasive\",\n",
            "        \"neuroimaging\",\n",
            "        \"MRI\",\n",
            "        \"fMRI detects changes in blood flow and oxygenation associated with neural activities\",\n",
            "        \"in the brain when the person being imaged carries out a specific task\",\n",
            "        \"MEG\",\n",
            "        \"Views electromagnetic changes resulting from the brain activity at the millisecond\",\n",
            "        \"timescale\",\n",
            "        \"OPM\",\n",
            "        \"Scalar-type quantum sensors for magnetic fields based on the Zeeman effect\",\n",
            "        \"EEG\",\n",
            "        \"A recording of the electrical activity of the brain from the scalp\",\n",
            "        \"CT\",\n",
            "        \"A CT scan uses X-rays to produce 2D images of organs, bones, and tissues\",\n",
            "        \"PET\",\n",
            "        \"Provides 2D and 3D pictures of the brain activity by measuring radioactive isotopes\",\n",
            "        \"that are injected into the bloodstream\",\n",
            "        \"SPECT\",\n",
            "        \"Provides 3D (tomographic) images of the distribution of radioactive tracer molecules\",\n",
            "        \"that have been introduced into the patient\\u2019s body\",\n",
            "        \"NIRS\",\n",
            "        \"A non-invasive optical imaging technique used to monitor tissue oxygen status\",\n",
            "        \"Non-invasive\",\n",
            "        \"stimulus\",\n",
            "        \"neuroimaging\",\n",
            "        \"tDCS\",\n",
            "        \"Passes small electrical currents directly on the scalp, to stimulate the nerve cells in\",\n",
            "        \"the brain\",\n",
            "        \"TMS\",\n",
            "        \"Uses magnetic fields to stimulate nerve cells in the brain\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"5\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Fig. 4. Neuron anatomy.\",\n",
            "        \"Source:\",\n",
            "        \"Adapted\",\n",
            "        \"from [17]\",\n",
            "        \"Fig. 5. Spatial\\u2013temporal resolution of invasive and non-invasive instrument techniques\",\n",
            "        \"(in which SUA: single-unit activity; MUA: multi-unit activity; LFP: local field potential;\",\n",
            "        \"ESI: electromagnetic source imaging).\",\n",
            "        \"Source: Adapted from [18].\",\n",
            "        \"imaging; (2) magnetoencephalography; (3) optically pumped magne-\",\n",
            "        \"tometer; (4) EEG; (5) CT scan; (6) positron emission tomography; (7)\",\n",
            "        \"SPECT; (8) NIRS; (9) transcranial direct current stimulation, and (10)\",\n",
            "        \"transcranial magnetic stimulation [18]. The introduction of these non-\",\n",
            "        \"invasive techniques is summarised in Table 2. Also, the comparison\",\n",
            "        \"of the spatial and temporal resolution of these invasive and non-\",\n",
            "        \"invasive instrumentation techniques is shown in Fig. 5. Among these\",\n",
            "        \"neural recording methods, fMRI provides a high spatial resolution\",\n",
            "        \"in imaging brain activities but is limited in temporal resolution and\",\n",
            "        \"interpretation in terms of the underlying neuronal activities. The other\",\n",
            "        \"electrophysiological modalities (e.g., EEG and MEG) share the superior\",\n",
            "        \"temporal resolution of the invasive recordings, which can be used\",\n",
            "        \"for studying cognitive functions and assessing human mental states.\",\n",
            "        \"However, their limited spatial resolutions pose challenges to realise\",\n",
            "        \"high spatial\\u2013temporal mapping of the electromagnetic brain signals and\",\n",
            "        \"the coordinated brain network imaging. Also, the PET-based technique\",\n",
            "        \"is limited by the low spatial resolution and is time-consuming and\",\n",
            "        \"costly.\",\n",
            "        \"3. Brain signal acquisition and processing\",\n",
            "        \"3.1. Brain\\u2013computer interface\",\n",
            "        \"A BCI builds direct, online communication between the brain and\",\n",
            "        \"computers, independent from the user\\u2019s physical abilities, and is widely\",\n",
            "        \"used to augment human capabilities and restore patient functions. Us-\",\n",
            "        \"ing brain activities to control a computer or external device has major\",\n",
            "        \"Fig. 6. Category of BCI systems and related brain signals .\",\n",
            "        \"Source: Adapted and modified from [24]\",\n",
            "        \"applications in restoring once-lost bodily functions [21,22]. BCIs trans-\",\n",
            "        \"late human intentions into outputs or actions by means of machine-\",\n",
            "        \"learning techniques, operating in either a synchronous or asynchronous\",\n",
            "        \"mode. The former presents a stimulus (e.g., visual aids) to an operator\",\n",
            "        \"and waits for the corresponding response, and the latter monitors\",\n",
            "        \"the operator\\u2019s cognitive activity and responds accordingly. Also, there\",\n",
            "        \"are some emerging applications in neuroengineering, neuroeconomics,\",\n",
            "        \"communication and control, education and self-regulation, as well as\",\n",
            "        \"games and entertainment [3]. Thanks to the advancement of neu-\",\n",
            "        \"roscience, sensor and semiconductor technologies, component minia-\",\n",
            "        \"turisation, and biocompatibility of materials, recent advances in BCIs\",\n",
            "        \"(e.g., BCI2000) have been accelerated with applications in both clinical\",\n",
            "        \"and non-clinical domains [23]. From a perspective of usage, the type\",\n",
            "        \"of BCIs can be classified as active, reactive, and passive as follows:\",\n",
            "        \"\\u2219Active BCI: produces its outputs from brain activities, in which\",\n",
            "        \"users directly and consciously control BCI-based applications not\",\n",
            "        \"necessarily relying on external events.\",\n",
            "        \"\\u2219Reactive BCI: with specific external stimuli such as visual/audio\",\n",
            "        \"stimulus, derives outputs from brain activities.\",\n",
            "        \"\\u2219Passive BCI: its outputs are derived from arbitrary brain activities\",\n",
            "        \"arising without the purpose of voluntary control, and it can\",\n",
            "        \"augment interactions with implicit information on the actual user\",\n",
            "        \"state and machines.\",\n",
            "        \"Invasive approaches measure the neural activities of the brain by\",\n",
            "        \"either intracortical neural interfaces with microelectrode arrays, which\",\n",
            "        \"capture spike signals and local field potentials, or cortical surface\",\n",
            "        \"electrocorticography (see Fig. 6), providing both high temporal and\",\n",
            "        \"spatial resolutions with good immunity to artefacts [24]. Invasive\",\n",
            "        \"BCIs using signals acquired with intracortical implants have achieved\",\n",
            "        \"successful BCI-based applications such as BCI-controlled robotic arms\",\n",
            "        \"for daily task assistance. However, the substantial amount of medical\",\n",
            "        \"and surgical expertise required to correctly implant and operate these\",\n",
            "        \"systems greatly limits their use beyond a few clinical cases. A BCI with\",\n",
            "        \"non-invasive electrodes requiring less intervention that can provide\",\n",
            "        \"high-quality control would profoundly improve the integration of BCIs\",\n",
            "        \"into multiple settings. Typical signals used include slow cortical poten-\",\n",
            "        \"tials, sensorimotor rhythms, P300, event-related potentials, steady-state\",\n",
            "        \"visually evoked potentials, error-related potentials, blood oxygenation\",\n",
            "        \"levels, and cerebral hemodynamic changes (see Fig. 6). The category\",\n",
            "        \"of EEG-based BCI applications mainly consists of MI-based, machine\",\n",
            "        \"learning-based, SSVEP-based, spatial filtering-based, ERP-based, and\",\n",
            "        \"online EEG-based techniques.\",\n",
            "        \"For the purpose of the headset selection in the research and appli-\",\n",
            "        \"cations, it is necessary to summarise commonly-used EEG and neural\",\n",
            "        \"feedback headsets. Table 3 provides a wide range selection of EEG\",\n",
            "        \"sensor headsets and includes the manufacturers of the headsets, avail-\",\n",
            "        \"able numbers of the electrodes, the sampling rate of the electrode,\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"6\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Summary of popular EEG sensor headsets (Statistics on 2023-03-25).\",\n",
            "        \"Manufacturer (Sensor headset)\",\n",
            "        \"Electrodes\",\n",
            "        \"Sampling rate\",\n",
            "        \"Citation Ref.\",\n",
            "        \"Compumedics Neuroscan\",\n",
            "        \"32/64/128/256\",\n",
            "        \"Up to 20 kHz\",\n",
            "        \"21,200+\",\n",
            "        \"Emotiv\",\n",
            "        \"2/5/14\",\n",
            "        \"Up to 8 kHz\",\n",
            "        \"18,100+\",\n",
            "        \"Brain Products\",\n",
            "        \"Up to 256\",\n",
            "        \"Up to 5 kHz\",\n",
            "        \"17,000+\",\n",
            "        \"BioSemi\",\n",
            "        \"Up to 256+\",\n",
            "        \"Up to 16 kHz\",\n",
            "        \"13,700+\",\n",
            "        \"g.tec\",\n",
            "        \"8/16/32/64\",\n",
            "        \"250/500 Hz\",\n",
            "        \"7,200+\",\n",
            "        \"NeuroSky\",\n",
            "        \"Up to 256\",\n",
            "        \"Up to 1 kHz\",\n",
            "        \"6,600+\",\n",
            "        \"Electrical Geodesics, Inc.\",\n",
            "        \"32/64/128/256\",\n",
            "        \"Up to 1 kHz\",\n",
            "        \"5,400+\",\n",
            "        \"Neuralink\",\n",
            "        \"Up to 3,072\",\n",
            "        \"Up to 20 kHz\",\n",
            "        \"3,300+\",\n",
            "        \"OpenBCI\",\n",
            "        \"Up to 19\",\n",
            "        \"Up to 2 KHz\",\n",
            "        \"2,100+\",\n",
            "        \"ANT Neuro\",\n",
            "        \"32/64/128/256\",\n",
            "        \"Up to 16 kHz\",\n",
            "        \"1,900+\",\n",
            "        \"Neuroelectrics\",\n",
            "        \"8/20/32\",\n",
            "        \"Up to 500 Hz\",\n",
            "        \"1,900+\",\n",
            "        \"Advanced Brain Monitoring\",\n",
            "        \"9/20\",\n",
            "        \"Up to 256 Hz\",\n",
            "        \"1,100+\",\n",
            "        \"Muse\",\n",
            "        \"Up to 256\",\n",
            "        \"Up to 100 KHz\",\n",
            "        \"600+\",\n",
            "        \"Cognionics\",\n",
            "        \"Up to 128\",\n",
            "        \"500 Hz\",\n",
            "        \"600+\",\n",
            "        \"mBrainTrain\",\n",
            "        \"Up to 32\",\n",
            "        \"Up to 1 KHz\",\n",
            "        \"200+\",\n",
            "        \"Wearable Sensing\",\n",
            "        \"Up to 64\",\n",
            "        \"Up to 16 kHz\",\n",
            "        \"100+\",\n",
            "        \"and the number of publications they are associated with (as found\",\n",
            "        \"through Google Scholar). While the selection summary in Table 3 is not\",\n",
            "        \"exhaustive and certainly subject to change, the following can represent\",\n",
            "        \"a bird\\u2019s-eye view of popular EEG hardware manufacturers currently\",\n",
            "        \"out there. The top three sensor headsets are Compumedics Neuroscan,\",\n",
            "        \"Emotiv, and Brain Products, and they use non-invasive instruments.\",\n",
            "        \"As an invasive recording device of brain signals, Neuralink can have\",\n",
            "        \"1,024-channel electrodes to stream fully-implanted neural recording\",\n",
            "        \"and data [25]. In addition, it designs two configurations, \\u2018System A\\u2019 and\",\n",
            "        \"\\u2018System B\\u2019, each differing in a number of variables. System A consists\",\n",
            "        \"of a 1,535-channel system with greater performance specifications than\",\n",
            "        \"System B with 3,072 channels.\",\n",
            "        \"During using sensor headsets for EEG signal recording, the location\",\n",
            "        \"of the sensors (electrodes) is critical to the reproducibility of exper-\",\n",
            "        \"iments and signal recording comparison for cross-subjects. For this\",\n",
            "        \"purpose, a standard that unifies procedures of the EEG measurement\",\n",
            "        \"is defined, and the 10\\u201320 system with a minimum of 21 electrodes is\",\n",
            "        \"devised to regulate the position and labels of the EEG channels. The\",\n",
            "        \"international system for EEG placement takes four universal cranial\",\n",
            "        \"landmarks (nasion, onion, and both pre-auricular points), and pro-\",\n",
            "        \"portionally distributes the EEG electrodes over the head surface. In\",\n",
            "        \"addition, the 10\\u201310 and 10\\u20135 systems were proposed as the extension\",\n",
            "        \"to the original 10\\u201320 international system [26]. The former is derived\",\n",
            "        \"from a distribution of 10% and 10% distances of the sagittal and\",\n",
            "        \"coronal central reference curves with 81 electrodes, while the latter\",\n",
            "        \"has a resolution with a distance of 5% equipped with 320 electrodes.\",\n",
            "        \"3.2. Denoising brain signals\",\n",
            "        \"The EEG signals have a weak amplitude in the range of microvolts\",\n",
            "        \"and the noise poses a major challenge in signal processing and accurate\",\n",
            "        \"feature extraction. It includes (1) environmental noise produced by\",\n",
            "        \"the environment and low-frequency electromagnetic fields through\",\n",
            "        \"significant interference; (2) motion artefacts induced by the movement\",\n",
            "        \"of the physical part of the measurement setup; and (3) physiological\",\n",
            "        \"noise induced by cardiac signals, muscle contraction, ocular signals\",\n",
            "        \"caused by eyeball movement, and irrelevant underlying brain activities\",\n",
            "        \"not pertaining to experiments [27]. To precisely extract the feature\",\n",
            "        \"of the signals, it is critical to conduct the preprocessing of the noise\",\n",
            "        \"removal. In the literature, various approaches to facilitating noise re-\",\n",
            "        \"moval and artefact reduction have been reported. Table A.1 (Appendix)\",\n",
            "        \"summarises the commonly-used noise removal techniques and includes\",\n",
            "        \"the specifications of these techniques as well as their advantages and\",\n",
            "        \"limitations.\",\n",
            "        \"The typical attempts to denoise the EEG signals are originally\",\n",
            "        \"derived from the use of simple low-, band-, and high-pass filters [27].\",\n",
            "        \"Unfortunately, these methods only work effectively under the non-\",\n",
            "        \"overlapping frequency bands between the EEG signals and interfer-\",\n",
            "        \"ence [28]. When it comes to spectral overlap, varying approaches\",\n",
            "        \"to facilitating noise and artefact reduction have been investigated\",\n",
            "        \"e.g., blind source separation, filtering methods, regression methods,\",\n",
            "        \"and empirical mode decomposition [27]. Within such a context, the\",\n",
            "        \"BSS method is derived from the component-based approach, which is\",\n",
            "        \"to identify the principal or independent components of the EEG signals\",\n",
            "        \"and then simultaneously process the signals of all the EEG channels\",\n",
            "        \"in the transformed domain. Different from the BSS, other methods\",\n",
            "        \"perform the signal cleaning either by independent channels or in the\",\n",
            "        \"time/frequency/time\\u2013frequency domains.\",\n",
            "        \"Thanks to the simplicity and reduced computation of regression\",\n",
            "        \"methods, they are the most frequently used technique of EEG artefact\",\n",
            "        \"removal, and this method performs the regression operation either\",\n",
            "        \"in the time or frequency domain by estimating the influence of the\",\n",
            "        \"reference channel on the interested signals [29]. However, the de-\",\n",
            "        \"mand for one or more reference channels limits the capacity of the\",\n",
            "        \"artefact removal of electrocardiogram and electrooculography signals.\",\n",
            "        \"The emerge of component-based approaches facilitates denoising EEG\",\n",
            "        \"signals, and the BSS algorithms mainly include independent component\",\n",
            "        \"analysis, principal component analysis, canonical correlation analysis,\",\n",
            "        \"and singular spectrum analysis [27]. The PCA converts the observations\",\n",
            "        \"of possibly correlated variables into values of linearly uncorrelated\",\n",
            "        \"variables through the use of an orthogonal transformation and has been\",\n",
            "        \"extensively used for artefact removal, especially effective in removing\",\n",
            "        \"the ocular artefacts [30]. However, the PCA cannot separate some\",\n",
            "        \"artefacts of the brain signals with similar amplitudes. The use of the\",\n",
            "        \"ICA treats the artefacts and brain activity being fully independent, and\",\n",
            "        \"then the former can be removed through investigating the statistical\",\n",
            "        \"independence of the sources [31]. Also, other component-based meth-\",\n",
            "        \"ods for artefact removal are proposed including CCA, SSA, and sparse\",\n",
            "        \"component analysis [27]. The summary of both CCA and SSA is shown\",\n",
            "        \"in Table A.1. In parallel, the filtering approaches have been proposed\",\n",
            "        \"and deployed in the artefact removal of the EEG signals. Some of the\",\n",
            "        \"typical techniques with a brief introduction, advantages and limitations\",\n",
            "        \"are shown in Table A.1 including adaptive filtering, Wiener filtering,\",\n",
            "        \"and Bayes filtering [28]. Alternatively, some sources that are either\",\n",
            "        \"signals or artefacts can be represented by a single decomposition unit.\",\n",
            "        \"Based on this fact, wavelet transform and EMD are often used for de-\",\n",
            "        \"composing individual channels into basic waveforms that describe the\",\n",
            "        \"signal and the artefacts [32], and other approaches including common\",\n",
            "        \"average reference, spatial Laplacian, and common spatial pattern are\",\n",
            "        \"introduced for signal cleaning and noise removal [27].\",\n",
            "        \"3.3. Brain signals processing\",\n",
            "        \"After noise removal of signals, accurate interpretation and classifi-\",\n",
            "        \"cation of the EEG signals are critical to reliable and wide BCI-based\",\n",
            "        \"applications. The commonly used approach was to define the raw EEG\",\n",
            "        \"signals and/or the transformed features as inputs but a DL system\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"7\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Fig. 7. EEG signals processing for feature extraction: time-domain (left), topography\",\n",
            "        \"map (centre), and time\\u2013frequency domain (right).\",\n",
            "        \"Source: Adapted from [15]\",\n",
            "        \"to recognise the patterns [33]. For this purpose, varying approaches\",\n",
            "        \"used for feature formulation, analysis, selection and extraction have\",\n",
            "        \"been reported in the literature. The features can be defined as pa-\",\n",
            "        \"rameters which provide information about the underlying patterns and\",\n",
            "        \"structure of the signals. The features of the EEG signals are mainly\",\n",
            "        \"formulated from time, frequency, and time\\u2013frequency domains [34].\",\n",
            "        \"The raw or preprocessed time-domain EEG signals and frequency trans-\",\n",
            "        \"form of the raw EEG signals are used to produce the time-domain\",\n",
            "        \"and frequency-domain features, respectively. Time\\u2013frequency features\",\n",
            "        \"are those calculated on the transformed EEG signals including time\",\n",
            "        \"and frequency information. To address feature selection criteria, a\",\n",
            "        \"comparative study of the methods for the feature extraction of EEG\",\n",
            "        \"signals and performance analysis is summarised in [34,35], and they\",\n",
            "        \"are categorised by time-domain, frequency-domain and time\\u2013frequency\",\n",
            "        \"domain-based approaches.\",\n",
            "        \"3.3.1. Time-domain feature\",\n",
            "        \"Temporal features are derived from the signals in the time domain,\",\n",
            "        \"and they are widely used for statistical analysis of the amplitude,\",\n",
            "        \"regularity, and synchronicity of the signals. As shown in Fig. 7 (left),\",\n",
            "        \"EEG signals collected from the sensor headset were visualised in the\",\n",
            "        \"time domain. These statistical parameters include (1) average mean,\",\n",
            "        \"variance, and variability and the measurements related to the proba-\",\n",
            "        \"bility density function and complexity of the signals such as entropy.\",\n",
            "        \"The features related to the amplitude measurements contain (2) energy,\",\n",
            "        \"average power, and root mean squared value; (3) amplitude-integrated\",\n",
            "        \"EEG; (4) nonlinear energy [34]. The measurement to reflect the prob-\",\n",
            "        \"ability density functions, complexity and uncertainty of the signals is\",\n",
            "        \"mainly defined as entropy-indicator features, which consists of Shannon\",\n",
            "        \"entropy, approximate entropy, sample entropy, permutation entropy,\",\n",
            "        \"weighted-permutation entropy, fuzzy entropy, distribution entropy, sin-\",\n",
            "        \"gular value decomposition entropy as well as fractal dimension [36].\",\n",
            "        \"The detailed introductions to different types of entropy are found\",\n",
            "        \"in [34]. Also, three Hjorth parameters composed of activity, mobility\",\n",
            "        \"and complexity describe the spectral properties of the signal in the\",\n",
            "        \"time domain [37]. Two bandwidths consist of amplitude modulation\",\n",
            "        \"bandwidth and frequency modulation bandwidth, and detrended fluc-\",\n",
            "        \"tuation analysis as a temporal feature measures the self-correlation of\",\n",
            "        \"a signal. The number of zero-crossings and the local extrema describes\",\n",
            "        \"the measurement of the frequency characteristics and the total number\",\n",
            "        \"of local maxima and minima in a signal, respectively [36]. In addition,\",\n",
            "        \"the measurement of a degree of time series tendency for a signal is\",\n",
            "        \"defined as the time-domain feature (Hurst exponent), and the feature\",\n",
            "        \"of the local binary pattern indicates the transformation of a partial time\",\n",
            "        \"series into encoded patterns.\",\n",
            "        \"3.3.2. Frequency-domain feature\",\n",
            "        \"In the frequency domain analysis, the time-series EEG signal is\",\n",
            "        \"transformed into the frequency domain from the time domain with\",\n",
            "        \"varying transform approaches such as Fourier transform. The frequency\",\n",
            "        \"representation of EEG signals reveals some useful information about\",\n",
            "        \"underlying patterns. The power spectral density defines the average of\",\n",
            "        \"the Fourier transform magnitude squared over a large time interval,\",\n",
            "        \"and the power partition at each frequency is defined as the normalised\",\n",
            "        \"PSD [38]. This subsection summarises the frequency-domain features\",\n",
            "        \"extracted from the PSD. Within the context, the feature of energy that\",\n",
            "        \"is calculated from some frequency ranges of the EEG signals is defined\",\n",
            "        \"to determine the EEG rhythmicity in each frequency range [36]. The\",\n",
            "        \"mean frequency and peak frequency are used to describe the mean of\",\n",
            "        \"the frequency distribution using the normalised PSD and the frequency\",\n",
            "        \"at which the PSD of the highest average power in its full-width-half-\",\n",
            "        \"max band has the highest magnitude, respectively [39]. Also, the\",\n",
            "        \"bandwidth of the peak frequency is defined as the full-width-half-max\",\n",
            "        \"band corresponding to the peak frequency. Additionally, spectral edge\",\n",
            "        \"frequency represents the frequency at which the total power of the\",\n",
            "        \"normalised PSD, and spectral entropy describes the random process\",\n",
            "        \"uncertainty from the frequency distribution [34].\",\n",
            "        \"3.3.3. Time\\u2013frequency-domain feature\",\n",
            "        \"The time-domain feature provides spatial information but with poor\",\n",
            "        \"frequency content. The frequency domain analysis extracts temporal\",\n",
            "        \"information but with the challenge of the selection of window size.\",\n",
            "        \"To address these problems, the time\\u2013frequency analysis performs the\",\n",
            "        \"extraction of the time and frequency information calculated on the\",\n",
            "        \"transformed EEG signals [40]. Fast Fourier transform and short-time\",\n",
            "        \"Fourier transform can convert the time-series EEG signals into the\",\n",
            "        \"spectrum including time and frequency information [41]. However, the\",\n",
            "        \"time intervals are predefined in FFT analysis, and narrow and wide\",\n",
            "        \"windows in the STFT analysis cause a poor frequency resolution and\",\n",
            "        \"the time localisation unprecise, respectively [41]. It is also common to\",\n",
            "        \"use the statistical parameters in the time\\u2013frequency domain, and these\",\n",
            "        \"statistics are the measures derived from the EEG signals, which consist\",\n",
            "        \"of the mean, standard deviation/variance, skewness, kurtosis, median,\",\n",
            "        \"minimum and maximum [42]. The energy, average power, and RMS\",\n",
            "        \"are used to observe the amplitudes of signals corresponding to specific\",\n",
            "        \"frequency sub-bands, and the entropy-based feature is used to describe\",\n",
            "        \"the uncertainty and complexity of the decomposed signals [34]. In addi-\",\n",
            "        \"tion, autoregressive moving-average model parameters of a time-series\",\n",
            "        \"model vary with each input and are fitted to discrete WT coefficient\",\n",
            "        \"sequences. The autoregressive model-based method can better reflect\",\n",
            "        \"brain states, and works well with stationary EEG signals but has limita-\",\n",
            "        \"tions for the non-stationary EEG signals such as motor imagery [43]. To\",\n",
            "        \"overcome the limitations of these methods, the WT has the capability of\",\n",
            "        \"varying frequency based on the frequency component. The continuous\",\n",
            "        \"WT calculates the correlation between the signal and the wavelet func-\",\n",
            "        \"tion, and the discrete WT decomposes the signal into time\\u2013frequency\",\n",
            "        \"representations to depict their distributions [44]. Right-side subfigure\",\n",
            "        \"of Fig. 7 shows the time\\u2013frequency feature generated by continuous\",\n",
            "        \"WT. In addition, the topography of EEG power and the activation areas\",\n",
            "        \"of the brain at a certain time slot is shown in the middle subfigure\",\n",
            "        \"of Fig. 7 and it visualises the neuron activities during issuing the EEG\",\n",
            "        \"signals. The blue areas have fewer neurons firing while the red areas\",\n",
            "        \"signify the most neuron activities.\",\n",
            "        \"Before signal processing and analysis, signal recording and acquisi-\",\n",
            "        \"tion are necessary but costly. The numerous studies of EEG both in the\",\n",
            "        \"clinical and non-clinical domains have produced many EEG datasets.\",\n",
            "        \"The summary of these public EEG datasets provides important reference\",\n",
            "        \"data for comparative study e.g., performance analysis [45]. This can\",\n",
            "        \"facilitate a wider range of applications and studies of EEG, especially\",\n",
            "        \"for using AI tools for processing EEG signals and BCI-controlled ap-\",\n",
            "        \"plications. The category of these datasets is composed of MI, emotion\",\n",
            "        \"recognition, ErrPs, SSVEPs, ERPs, slow-cortical potentials, resting state,\",\n",
            "        \"music and EEG, eye-blinks/movements, miscellaneous, and clinical\",\n",
            "        \"EEG.\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"8\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Review papers on DL for EEG classification.\",\n",
            "        \"No.\",\n",
            "        \"Title\",\n",
            "        \"Source title\",\n",
            "        \"Year\",\n",
            "        \"1\",\n",
            "        \"Deep learning techniques for EEG signal applications \\u2014 a review [47]\",\n",
            "        \"Journal of Neural\",\n",
            "        \"Engineering\",\n",
            "        \"2018\",\n",
            "        \"2\",\n",
            "        \"A review of classification algorithms for EEG-based brain\\u2013computer interfaces: a\",\n",
            "        \"10-year update [48]\",\n",
            "        \"Journal of Neural\",\n",
            "        \"Engineering\",\n",
            "        \"2018\",\n",
            "        \"3\",\n",
            "        \"Deep learning-based electroencephalography analysis: a systematic review [49]\",\n",
            "        \"Journal of Neural\",\n",
            "        \"Engineering\",\n",
            "        \"2019\",\n",
            "        \"4\",\n",
            "        \"Deep learning algorithms in EEG signal decoding application: a review [50]\",\n",
            "        \"IEEE access\",\n",
            "        \"2021\",\n",
            "        \"5\",\n",
            "        \"Deep learning for electroencephalogram (EEG) classification tasks: a review [51]\",\n",
            "        \"IETE Journal of Research\",\n",
            "        \"2022\",\n",
            "        \"6\",\n",
            "        \"Review of machine learning techniques for EEG-based brain\\u2013computer interface [52]\",\n",
            "        \"Archives of Computational\",\n",
            "        \"Methods in Engineering\",\n",
            "        \"2022\",\n",
            "        \"Fig. 8. Statistics from Scopus: DL for EEG signal classification (Updated by March\",\n",
            "        \"2023).\",\n",
            "        \"4. Deep learning-based brain signal classification\",\n",
            "        \"The introduction of machine learning into the field of BCIs, which\",\n",
            "        \"began almost two decades ago, has enabled unprecedented perfor-\",\n",
            "        \"mance on classification tasks. This section summarises machine learn-\",\n",
            "        \"ing techniques on the classification of EEG signals but with a focus on\",\n",
            "        \"DL for EEG signal classification tasks.\",\n",
            "        \"4.1. Overview of literature survey\",\n",
            "        \"DL algorithms can use a large amount of EEG data to directly\",\n",
            "        \"learn features and capture the data structure in an efficient way. This\",\n",
            "        \"study provides an overview of DL used for EEG signals and reviews\",\n",
            "        \"publications between 2012 and 2023, including English journal and\",\n",
            "        \"conference papers as well as electronic preprints. Here, the selected\",\n",
            "        \"search items related to DL are based on its taxonomy [46].\",\n",
            "        \"The search items indexed by the Scopus dataset include (1) EEG,\",\n",
            "        \"(2) electroencephalograph, (3) deep learning, (4) neural network, (5)\",\n",
            "        \"convolutional neural network, (6) CNN, (7) recurrent neural network,\",\n",
            "        \"(8) RNN, (9) deep belief network, (10) DBN, (11) generative adversarial\",\n",
            "        \"network, (12) GAN, (13) autoencoder, (14) restricted Boltzmann ma-\",\n",
            "        \"chine; (15) graph neural network, and the search items are organised\",\n",
            "        \"with logical operators as a search entity: (1 OR 2) AND (3 OR 4 OR\",\n",
            "        \"5 OR 6 OR 7 OR 8 OR 9 OR 10 OR 11 OR 12 OR 13 OR 14 OR\",\n",
            "        \"15). The selection criteria used for including/excluding the studies\",\n",
            "        \"are defined as (1) only electroencephalograph/studies of EEG signals\",\n",
            "        \"combined with other biomedical signals; (2) only classification tasks\",\n",
            "        \"using human brain signals. The statistical analysis for DL-based EEG\",\n",
            "        \"classification is shown in Fig. 8. It can be observed the studies of\",\n",
            "        \"EEG signal classification using DL show rapid growth. Especially a fast\",\n",
            "        \"increase since 2016, the potential driving factors are the advancement\",\n",
            "        \"of BCIs combined with powerful DL tools. The former allows more\",\n",
            "        \"sensors integrated into an electrode array and wide applications in both\",\n",
            "        \"clinical and non-clinical domains that derive much more EEG signal\",\n",
            "        \"datasets. The latter facilitates robust and high-accuracy classification\",\n",
            "        \"and recognition of the patterns and structures underlying the EEG\",\n",
            "        \"signals. Given the core interest in the use of EEG signals in the robotics\",\n",
            "        \"field, only classification tasks closely related to the applications of BCI-\",\n",
            "        \"controlled robotics are investigated and reviewed, e.g., MI and emotion\",\n",
            "        \"recognition. The following sections analyse and summarise the top-six\",\n",
            "        \"DL models for EEG task classification, given their popularity and wide\",\n",
            "        \"applications.\",\n",
            "        \"To clarify the distinction of this study, similar review studies on DL-\",\n",
            "        \"based EEG task classification are listed in Table 4. Paper 1 focuses on\",\n",
            "        \"a detailed survey of applications of DL architecture in EEG signals, and\",\n",
            "        \"Papers 2 and 6 mainly investigate the use of machine learning/DL in\",\n",
            "        \"EEG-based BCIs. In addition, Papers 3, 4 and 5 conduct the survey of\",\n",
            "        \"DL in EEG signal analysis but with a different focus. Paper 3 mainly\",\n",
            "        \"performs the numerical statistical analysis of DL spanning different\",\n",
            "        \"application domains. Papers 4 and 5 are with a focus on the use of DL\",\n",
            "        \"in EEG signal decoding and EEG-based classification tasks, respectively.\",\n",
            "        \"This study considers the fusion of neuroscience and robotics facilitated\",\n",
            "        \"by DL, which gives a complete survey pipeline from the human brain\",\n",
            "        \"to robot actions. The unique contributions different from other reviews\",\n",
            "        \"are summarised as follows. Firstly, this review considers applications\",\n",
            "        \"of neuroscience, specifically EEG signals, in robotics, which has not\",\n",
            "        \"been highlighted in other reviews. Secondly, a complete and detailed\",\n",
            "        \"pipeline of brain robotics is considered from the understanding of\",\n",
            "        \"the human brain, brain signals processing, AI for EEG classification\",\n",
            "        \"to brain-controlled robots as well as applications of BCIs in robotics.\",\n",
            "        \"Finally, the challenges and future directions of brain robotics at the\",\n",
            "        \"intersection of robotics and neuroscience are summarised.\",\n",
            "        \"4.2. Deep learning algorithms in EEG signal classification\",\n",
            "        \"4.2.1. CNN\",\n",
            "        \"The success of CNNs in revealing patterns underlying grid data\",\n",
            "        \"(e.g., text and images) has made them effective at classifying EEG\",\n",
            "        \"signals, and various CNN frameworks have been proposed, e.g., VGG-\",\n",
            "        \"16 [2] and Residual-Net [53]. For example, a comparative study on\",\n",
            "        \"the 14 pre-trained CNNs was discussed in [54]. These networks were\",\n",
            "        \"trained a priori to perform image classification using real-world images,\",\n",
            "        \"and then the 14 representative networks were trained using the EEG\",\n",
            "        \"signals, either in images or in vectorised form, depending on if a\",\n",
            "        \"network is convolutional or fully-connected [2]. Finally, the VGG16\",\n",
            "        \"convolutional network is chosen, given its high accuracy of 97% and\",\n",
            "        \"efficiency (150 epochs for convergence) in EEG signal classification,\",\n",
            "        \"and the architectures of the original and adapted VGG16 are shown in\",\n",
            "        \"Fig. 9. The use of the CNN model and its variants (e.g., channel-wise\",\n",
            "        \"CNN and deep CNN) on the mental load classification and decoding\",\n",
            "        \"user intention (five MI classes and resting state) was also studied [55,\",\n",
            "        \"56]. CNNs have mainly been applied to a single BCI paradigm. How-\",\n",
            "        \"ever, how these architectures generalise to other paradigms is still\",\n",
            "        \"unclear. For this purpose, Lawhern et al. [57] designed a compact\",\n",
            "        \"and single CNN architecture to accurately classify EEG signals from\",\n",
            "        \"four BCI paradigms including P300, error-related negativity response,\",\n",
            "        \"movement-related cortical potential, sensory-motor rhythm, and also\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"9\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Fig. 9. VGG16 structure and adaption for EEG signal classification.\",\n",
            "        \"Source: Adapted from [2].\",\n",
            "        \"an end-to-end CNN approach to raw MI-EEG signal classification for\",\n",
            "        \"BCIs was investigated [58].\",\n",
            "        \"However, DL models can be easily fooled with adversarial examples\",\n",
            "        \"(normal examples with small deliberate perturbations). An unsuper-\",\n",
            "        \"vised fast gradient sign method to attack three popular CNN classifiers\",\n",
            "        \"in BCIs was first proposed to investigate the vulnerability of CNN\",\n",
            "        \"classifiers in EEG-based BCIs [59], and the transferability of adversarial\",\n",
            "        \"examples in BCIs was verified. However, a single convolution scale\",\n",
            "        \"in the CNN and the limited training dataset limit and degrade the\",\n",
            "        \"classification accuracy. To address such problems, a hybrid-scale CNN\",\n",
            "        \"architecture with a data augmentation method was developed for EEG\",\n",
            "        \"MI classification with the achieved average accuracy of 91.57% and\",\n",
            "        \"87.6% on two commonly used datasets [60]. Through investigating\",\n",
            "        \"learning rates, optimisers, processed and unprocessed scalograms and\",\n",
            "        \"features, a pre-trained CNN-based new automated framework was pro-\",\n",
            "        \"posed for robust BCI systems with small and ample samples of motor\",\n",
            "        \"and mental imagery EEG training data [61]. Also, a new approach\",\n",
            "        \"based on a 10-layer 1D CNN was proposed to classify five brain states\",\n",
            "        \"using a data augmentation algorithm and a limited number of EEG\",\n",
            "        \"channels [62].\",\n",
            "        \"Statistical features derived from EEG datasets play an important\",\n",
            "        \"role in task classification and also are often defined as the control\",\n",
            "        \"input for CNN-based classification models [63]. For example, a DL\",\n",
            "        \"architecture that combines FFT, CNN, long short-term memory, and\",\n",
            "        \"an attention mechanism for extracting spatial\\u2013temporal features from\",\n",
            "        \"multi-channel EEG signals was developed to classify EEG signals with\",\n",
            "        \"high accuracy [64]. A recent study also developed a neural network\",\n",
            "        \"feature fusion algorithm that combines CNN and LSTM for the extrac-\",\n",
            "        \"tion of spatial and temporal features of EEG signals but with necessary\",\n",
            "        \"hand-crafted feature generation [65]. Within such a context, automatic\",\n",
            "        \"feature extraction is necessary and promising for high-efficiency EEG\",\n",
            "        \"signal classification, and it can be realised by the use of a resid-\",\n",
            "        \"ual block-based deep CNN for emotion classification with electrode-\",\n",
            "        \"frequency distribution maps [53]. To include the local information\",\n",
            "        \"within multichannel or multiple frequency bands in the EEG signals,\",\n",
            "        \"a novel emotion recognition method using a CNN while preserving\",\n",
            "        \"the local information was developed [66], a lightweight 3D optimised\",\n",
            "        \"CNN was modelled to extract local features and classify sparsity-based\",\n",
            "        \"reconstructed EEG signals with artefact removal [67]. However, using\",\n",
            "        \"the feature maps in the last layer of CNN can result in the loss of some\",\n",
            "        \"local and detailed information for accurate classification. To overcome\",\n",
            "        \"the limitations of feature extraction-based methods, the combination\",\n",
            "        \"of time\\u2013frequency analysis and CNN was used to learn the intended\",\n",
            "        \"movement of upper limbs and the time\\u2013frequency maps of the EEG\",\n",
            "        \"signals at the source level are defined as model inputs and finally,\",\n",
            "        \"whether the brain intends to trigger a movement and which movement\",\n",
            "        \"will be performed are the outputs [68]. Also, multi-scale CNN models\",\n",
            "        \"have been investigated for solving these problems. For example, a\",\n",
            "        \"multi-scale CNN model-based EEG signal classification method was\",\n",
            "        \"proposed, in which the time\\u2013frequency images converted by STFT serve\",\n",
            "        \"as inputs to the multi-scale CNN model for EEG signal classification\",\n",
            "        \"by considering the local and global information [69]. A multilevel and\",\n",
            "        \"multiscale feature fusion CNN was designed for WT-based multidimen-\",\n",
            "        \"sional images derived from EEG signals, which have dense information,\",\n",
            "        \"low SNR, and strong spatial distribution [70]. Moreover, an efficient\",\n",
            "        \"multi-scale CNN model was proposed with intrinsic feature integration\",\n",
            "        \"for MI EEG subject classification in BCIs, in which multi-scale convolu-\",\n",
            "        \"tion block extracts the features of several non-overlapping canonical\",\n",
            "        \"frequency bands of EEG signal from multiple scales [71]. In recent\",\n",
            "        \"years, reinforcement learning and CNN are combined together for EEG\",\n",
            "        \"signals [72], and a Q-learning method to enable fast reconstructions\",\n",
            "        \"of CNN was developed to support EEG discrimination adapting to the\",\n",
            "        \"individuality of subjects under examination [73]. Despite the great\",\n",
            "        \"success of CNN models in EEG signal classification, it is difficult to\",\n",
            "        \"derive a high-efficiency approach that is suitable to CNN for revealing\",\n",
            "        \"all the information carried by EEG signals.\",\n",
            "        \"4.2.2. Autoencoders\",\n",
            "        \"An autoencoder is an unsupervised learning algorithm that utilises\",\n",
            "        \"unlabelled data to get the initial weights of each layer by pre-training\",\n",
            "        \"so that the network could extract the data features with high efficiency.\",\n",
            "        \"Since theautoencoder has the capability of learning the essential rep-\",\n",
            "        \"resentations of data from a small number of sample sets, the wide\",\n",
            "        \"applications of autoencoder used in areas such as image encoding and\",\n",
            "        \"EEG signal decoding have been reported. A denoising autoencoder\",\n",
            "        \"was trained to learn a low-dimensional representation of temporal and\",\n",
            "        \"spectral inter-channel EEG connectivity matrices [74]. Then, to predict\",\n",
            "        \"the class of MI datasets, an unsupervised denoising autoencoder-based\",\n",
            "        \"neural network was developed based on the spectral power estimated\",\n",
            "        \"by the Lomb\\u2013Scargle periodogram [75]. Given the complexity of EEG\",\n",
            "        \"denoising, the dimensionality reduction during EEG signal classification\",\n",
            "        \"was performed by an autoencoder with six layers [76], and a denois-\",\n",
            "        \"ing approach using a deep convolutional autoencoder was proposed\",\n",
            "        \"to reduce the effort of projecting denoising filters [77]. In parallel,\",\n",
            "        \"the denoising sparse autoencoder, as an improved unsupervised deep\",\n",
            "        \"neural network over sparse autoencoder and denoising autoencoder,\",\n",
            "        \"has been used to learn the closest representation of the data [78].\",\n",
            "        \"The variants of the autoencoder for EEG signal classification tasks\",\n",
            "        \"have been investigated in the literature. For instance, variational au-\",\n",
            "        \"toencoders were used to learn generative-discriminative representa-\",\n",
            "        \"tions from EEG data for the classification of three distinct emotion\",\n",
            "        \"categories [79], and to determine the latent factors from the multi-\",\n",
            "        \"channel EEG [80,81]. To determine personalised properties in high\",\n",
            "        \"dimensional EEG indicators, a feature mapping layer in a stacked\",\n",
            "        \"denoising autoencoder was proposed to preserve the local information\",\n",
            "        \"in EEG dynamics [82]. However, it is difficult to realise high-accuracy\",\n",
            "        \"emotion recognition in the case of a small number of calibration\",\n",
            "        \"samples or across different tasks. To address this challenge, the mul-\",\n",
            "        \"timodal concept has been applied to the design of the autoencoder\",\n",
            "        \"for EEG signal classification such as a multimodal domain adaptive\",\n",
            "        \"variational autoencoder [83] and a multimodal sequence-to-sequence\",\n",
            "        \"autoencoder [84]. The former was developed to learn shared cross-\",\n",
            "        \"domain latent representations of the multimodal data for EEG-based\",\n",
            "        \"emotion recognition, and the latter was combined with LSTM units and\",\n",
            "        \"CNNs to predict brain hemodynamics (fNIRS) from encoded neural data\",\n",
            "        \"(EEG) in the resting human epileptic brain.\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"10\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Fig. 10. A transfer learning-based CNN and LSTM hybrid model to classify motor\",\n",
            "        \"imagery EEG signals.\",\n",
            "        \"Source: Adapted from [85].\",\n",
            "        \"4.2.3. Recurrent neural networks\",\n",
            "        \"RNN is characterised by its connections between computing units\",\n",
            "        \"and forms a directed graph along a sequence. Thus, it has shown\",\n",
            "        \"good performance in time-series data analysis e.g., speech recognition\",\n",
            "        \"and time-series prediction. Given its advantages, the use of RNN in\",\n",
            "        \"time-series EEG signals has been widely investigated [86]. A typi-\",\n",
            "        \"cal example is the LSTM network-based classification system of EEG\",\n",
            "        \"signals. It utilised 1D-aggregate approximation together with the use\",\n",
            "        \"of the channel weighting technique for the enhanced classification\",\n",
            "        \"effectiveness [87]. A deep region-based CNN was also adopted to\",\n",
            "        \"learn robust representation from the topology-preserving multispectral\",\n",
            "        \"images translated by the EEG signals on cognitive load classifica-\",\n",
            "        \"tion [88]. For RNN, training a network by a gradient descent algorithm\",\n",
            "        \"is still a challenge and it is also insensitive to inputs fed to a network\",\n",
            "        \"earlier, which degrades the classification accuracy [89]. To improve\",\n",
            "        \"recognition accuracy, hybrid neural networks that combine two or\",\n",
            "        \"more types of neural networks are used for EEG signal translation.\",\n",
            "        \"Within a hybrid model, the CNN is to extract the spatial features of\",\n",
            "        \"the EEG signal, which are fed as a time series into LSTM to extract\",\n",
            "        \"the temporal features [90]. Moreover, a hybrid neural network that\",\n",
            "        \"combines CNNs and RNNs was developed to classify human emotion\",\n",
            "        \"states by learning compositional spatial\\u2013temporal representation of raw\",\n",
            "        \"EEG streams [91], and extracting task-related features, mining inter-\",\n",
            "        \"channel correlation and incorporating contextual information from\",\n",
            "        \"those frames [92]. To extract spatial\\u2013temporal features across EEG\",\n",
            "        \"channels, a novel hybrid convolutional-RNN model consisting of CNN\",\n",
            "        \"and an RNN with gated recurrent units was developed, in which\",\n",
            "        \"spatial\\u2013temporal features extracted by 1D CNN layers are fed into the\",\n",
            "        \"GRUs to reveal temporal features pertinent to the classification [93].\",\n",
            "        \"The feature learning from both spatial and temporal information of sig-\",\n",
            "        \"nal sources in a spatial\\u2013temporal RNN model can be further integrated\",\n",
            "        \"into a unified spatial\\u2013temporal dependency model for accurate emotion\",\n",
            "        \"recognition [94].\",\n",
            "        \"Fig. 10 shows an architecture of transfer learning-based CNN and\",\n",
            "        \"LSTM hybrid DL to classify MI EEG signals [85], and it can extract and\",\n",
            "        \"learn the spatial and temporal sequence features of the MI signal simul-\",\n",
            "        \"taneously. As shown in Fig. 10, two different pre-trained CNN networks\",\n",
            "        \"namely Inception-v3 and ResNet-50 were adopted (left side of Fig. 10),\",\n",
            "        \"and to use these pre-trained networks for MI classification, all fully\",\n",
            "        \"connected layers in pre-trained networks were replaced with the LSTM\",\n",
            "        \"network and a new fully-connected layer to classify four MI tasks (right\",\n",
            "        \"side of Fig. 10). In addition, the combination of bidirectional LSTM and\",\n",
            "        \"graph convolutional neural network models was developed for human\",\n",
            "        \"MI EEG signals, in which the former with an attention mechanism\",\n",
            "        \"derives the feature underlying raw EEG signals, and the latter enhances\",\n",
            "        \"the decoding performance by including the topological structure of\",\n",
            "        \"features [95]. Variant RNN architectures, namely RNN, LSTM, and\",\n",
            "        \"GRU, were also investigated to classify the emotions from EEG signals\",\n",
            "        \"and validated these networks\\u2019 efficiency and performance [81].\",\n",
            "        \"During the use of a BCI-based robot system, the evaluation of the\",\n",
            "        \"mental workload of the human is important to assess human fatigue and\",\n",
            "        \"well-being, but also to collect high-quality signals for task classification.\",\n",
            "        \"Within the context, a deep RNN architecture was proposed to learn\",\n",
            "        \"robust features and predict the levels of cognitive load from EEG\",\n",
            "        \"recordings [96], followed by the investigation of various RNN models\",\n",
            "        \"(e.g., LSTM, BiLSTM, and GRU) for cognitive workload tasks. To model\",\n",
            "        \"cognitive events from EEG data, a deep neural network with CNN\",\n",
            "        \"and RNN was proposed for the EEG classification task by using EEG\",\n",
            "        \"video and optical flow, in which the problem of EEG classification\",\n",
            "        \"was finally reduced to a video classification problem [97], and cross-\",\n",
            "        \"participant cognitive workload assessment was performed by the use\",\n",
            "        \"of a multi-path convolutional RNNs model [98]. Different from EEG\",\n",
            "        \"video-based classification, robust representation of EEG signals learned\",\n",
            "        \"from the sequence of images calculated by themselves was realised by a\",\n",
            "        \"deep recurrent-convolutional network, and it can preserve the spatial\\u2013\",\n",
            "        \"temporal and spectral structure of EEG signals for modelling cognitive\",\n",
            "        \"events [88]. In parallel, a back-propagation through a time-based RNN\",\n",
            "        \"approach was proposed for cognitive mental state classification [99]. In\",\n",
            "        \"addition, the use of RNN in recognising the human intent of movement\",\n",
            "        \"was also investigated. Both cascade and parallel convolutional RNN\",\n",
            "        \"models were used to identify the human intended movements through\",\n",
            "        \"learning compositional spatial\\u2013temporal representations of raw EEG\",\n",
            "        \"streams [100]. Encoding spatial and temporal sequential raw EEG data\",\n",
            "        \"simultaneously was implemented by the use of a pure RNN-based\",\n",
            "        \"parallel method with bidirectional and standard LSTM [101].\",\n",
            "        \"In parallel, confusion detection in the human mind in real time by\",\n",
            "        \"analysing EEG signals is challenging but important to be applied to\",\n",
            "        \"mutual cognitive interactions between humans and robots. A bidirec-\",\n",
            "        \"tional LSTM RNN was proposed to classify students\\u2019 confusions with the\",\n",
            "        \"accuracy of 73.3% from the EEG signals [102]. To identify whether the\",\n",
            "        \"brain activity is abnormal or normal, a novel RNN architecture termed\",\n",
            "        \"ChronoNet that was formed by stacking multiple 1D convolution layers\",\n",
            "        \"followed by deep GRU layers was developed to work with EEG data\",\n",
            "        \"and then for abnormal EEG identification [103]. However, individual\",\n",
            "        \"differences and complex, nonlinear natures of the EEG signals make it\",\n",
            "        \"difficult to the detection of human brain decisions. To solve such a chal-\",\n",
            "        \"lenge, a recurrent t-distributed stochastic neighbour embedding neural\",\n",
            "        \"network was proposed to classify the EEG signals and to precisely\",\n",
            "        \"predict the participants\\u2019 decisions [104]. Despite the use of variants of\",\n",
            "        \"the RNN model and new concepts (e.g., Quantum [105]) in the EEG\",\n",
            "        \"signal classification, it is still challenging to differentiate brain states\",\n",
            "        \"by explainable and generalisable DL approaches. For this purpose,\",\n",
            "        \"multiple random fragments search-based multilayer RNN was proposed\",\n",
            "        \"to improve the differentiating performance and explore meaningful\",\n",
            "        \"patterns from EEG datasets [106].\",\n",
            "        \"4.2.4. Deep belief networks\",\n",
            "        \"DBNs have demonstrated good performance in high-dimensional\",\n",
            "        \"data processing, especially for feature extraction [108,109]. For ex-\",\n",
            "        \"ample, the use of DBN models on feature learning from multichannel\",\n",
            "        \"EEG data (e.g., differential entropy feature and auto-encoded features)\",\n",
            "        \"within the context of emotion category was investigated [110,111].\",\n",
            "        \"Since many EEG channels are irrelevant to the specific learning tasks,\",\n",
            "        \"this can introduce noises to the system and further degrade the perfor-\",\n",
            "        \"mance of classification systems such as emotional state classification.\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"11\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Fig. 11. Common spatial GANs based EEG data augmentation.\",\n",
            "        \"Source: Adapted and modified from [107].\",\n",
            "        \"To address the problem, a novel DBN-based method was developed\",\n",
            "        \"to examine critical channels and frequency bands of the EEG signals\",\n",
            "        \"for accurate emotion recognition [112,113]. However, it is difficult to\",\n",
            "        \"detect the pathologic EEG waveforms due to highly variable individual\",\n",
            "        \"differences. For this purpose, DBNs as a type of multi-layer generative\",\n",
            "        \"neural network have shown efficient capabilities on EEG anomaly de-\",\n",
            "        \"tection [114], and they are also applied in a semi-supervised paradigm\",\n",
            "        \"to model the EEG signals for classification [115]. A representative\",\n",
            "        \"study is to use sparse DBNs as a semi-supervised learning method to\",\n",
            "        \"detect driver fatigue from EEG signals, and it uses unsupervised and\",\n",
            "        \"supervised learning for feature modelling in the pre-training layer and\",\n",
            "        \"classification in the following layer [116]. Also, to demonstrate the\",\n",
            "        \"performance of different neural networks on pervasive EEG diagnosis of\",\n",
            "        \"depression, a comparison analysis of a DBN-based learning model with\",\n",
            "        \"K-nearest neighbours, support vector machine, and artificial neural\",\n",
            "        \"network was investigated [117].\",\n",
            "        \"For EEG task classification, it often involves the processing of in-\",\n",
            "        \"complete MI EEG signals, the conventional approach often rejects\",\n",
            "        \"the entire severely contaminated EEG segments but leads to results\",\n",
            "        \"with the loss of decoding information during that certain period. For\",\n",
            "        \"this problem, a novel decoding scheme based on the combination of\",\n",
            "        \"Lomb\\u2013Scargle periodogram and BDN was proposed to recognise the\",\n",
            "        \"incomplete MI EEG signals [118]. In addition, DBN and its variants\",\n",
            "        \"have also demonstrated a good capability of detecting and classifying\",\n",
            "        \"human brain states (e.g., brain activity and emotional state) [119,120].\",\n",
            "        \"For example, a new switching DBN with adaptive weights was used to\",\n",
            "        \"detect variations of mental workload, mental fatigue, and the coupling\",\n",
            "        \"effect of the two variables across multiple subjects [121], and also\",\n",
            "        \"a single-channel EEG-based mental fatigue detection method based\",\n",
            "        \"on DBN was investigated [122]. However, the DBN model cannot\",\n",
            "        \"realise good classification results when working alone. A scheme of\",\n",
            "        \"combining DBN models with other neural networks was investigated for\",\n",
            "        \"enhanced performance by utilising their strength. For example, a DBN\",\n",
            "        \"was developed with four restricted Boltzmann machines that extract the\",\n",
            "        \"time and frequency domain information of EEG signals [123].\",\n",
            "        \"4.2.5. Generative adversarial networks\",\n",
            "        \"GANs are recently highly successful in generative applications and\",\n",
            "        \"start being applied to time-series data analysis. However, it is challeng-\",\n",
            "        \"ing to have a robust classification of EEG signals with the small size\",\n",
            "        \"of the datasets and the limited training samples. To address the chal-\",\n",
            "        \"lenge, the attempt to synthesise EEG data for different cognitive events\",\n",
            "        \"was firstly considered [124]. For example, using a conditional deep\",\n",
            "        \"convolutional GAN method can generate more artificial EEG signals\",\n",
            "        \"automatically for data augmentation [125], and also produce artificial\",\n",
            "        \"EEG signals from existing data [126]. Further, it can expand the scale of\",\n",
            "        \"the EEG signal dataset [127], to improve the performance of CNN in the\",\n",
            "        \"BCI field with competitive classification accuracy. Moreover, a GAN-\",\n",
            "        \"based synthetic generation method for time-series data was applied\",\n",
            "        \"to data augmentation for biosignals [128]. Then, a novel GAN model\",\n",
            "        \"was adopted to learn the statistical characteristics of the EEG signal\",\n",
            "        \"and augment its dataset size to enhance the performance of classifica-\",\n",
            "        \"tion models [129,130]. The recording of high spatial resolution EEG\",\n",
            "        \"data heavily relies on the use of high-performance sensor headsets,\",\n",
            "        \"which are often very expensive. To reduce the need for expensive\",\n",
            "        \"EEG devices, a novel GAN-based deep EEG super-resolution approach\",\n",
            "        \"was proposed to produce high spatial resolution EEG data from low-\",\n",
            "        \"resolution samples, by generating channel-wise upsampled data to\",\n",
            "        \"effectively interpolate numerous missing channels [131]. However,\",\n",
            "        \"random noise in the EEG data poses a typical challenge to accurate\",\n",
            "        \"classification and interpretation. Therefore, using GAN to denoise the\",\n",
            "        \"multichannel EEG signals automatically was investigated [132] and\",\n",
            "        \"can enable a large amount of data processing with reduced processing\",\n",
            "        \"time. For efficient artefact removal, a GAN-based framework as a data-\",\n",
            "        \"driven assistive tool was developed for ocular artefact removal from\",\n",
            "        \"EEG signals [133]. In parallel, to increase the robustness of classifiers, a\",\n",
            "        \"deep convolutional GANs-based framework was developed to generate\",\n",
            "        \"artificial EEG to augment the training set for the purpose of improving\",\n",
            "        \"the performance of a BCI classifier [134]. Variants of the GAN model to\",\n",
            "        \"enhance the classification performance have also been developed. For\",\n",
            "        \"example, a Wasserstein GAN with gradient penalty was used to perform\",\n",
            "        \"event-related classification and predict rapid serial visual presentation\",\n",
            "        \"from EEG signals [135], and a conditional GAN model as another\",\n",
            "        \"variant inferred the amplitude and timing of scalp potentials and their\",\n",
            "        \"functional neuroanatomical sources [136].\",\n",
            "        \"Despite the competitive performance of DL in learning the sequen-\",\n",
            "        \"tial information of the EEG signals, few considered the recognition of\",\n",
            "        \"the unknown EEG signals which have never been seen in the training\",\n",
            "        \"dataset. For this purpose, a new scheme for Zero-Shot EEG signal\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"12\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Fig. 12. A STGCN model for EEG signal classification.\",\n",
            "        \"Source: Adapted from [33].\",\n",
            "        \"classification based on GAN was developed, and it consists of a GAN\",\n",
            "        \"for generating 128-D EEG features, a GAN model for recognising the\",\n",
            "        \"unknown EEG labels, and a classification network to learn the unseen\",\n",
            "        \"EEG signals from the fake EEG features [137]. Unlabelled EEG signals\",\n",
            "        \"can be treated as unseen data for the model training, and they are\",\n",
            "        \"used to train a GAN model in an unsupervised manner for the clas-\",\n",
            "        \"sification of unlabelled EEG signals. In parallel, it becomes impossible\",\n",
            "        \"to decode different categories of EEG signals without enough subject-\",\n",
            "        \"specific data even using transfer learning methods pre-training with\",\n",
            "        \"amounts of subject-independent data. Therefore, a cross-subject EEG\",\n",
            "        \"classification framework with a common spatial GAN-based method\",\n",
            "        \"was used to obtain high-quality data augmentation for improved cross-\",\n",
            "        \"subject classification accuracy, as shown in Fig. 11 [107], and the\",\n",
            "        \"developed model contains a generator and a discriminator (EEG module\",\n",
            "        \"and common spatial module). In addition, GANs have been used to\",\n",
            "        \"condition image generation from the learned EEG representation [138]\",\n",
            "        \"and to reconstruct EEG signals using ERP, which has similar raw noisy\",\n",
            "        \"EEG signals during walking [139].\",\n",
            "        \"4.2.6. Graph neural networks\",\n",
            "        \"Various end-to-end DL paradigms like CNN, RNN, or autoencoders\",\n",
            "        \"are good at capturing hidden patterns of Euclidean data (images, text,\",\n",
            "        \"and videos). However, EEG channels placed on the scalp are in a\",\n",
            "        \"non-Euclidean space and can be represented as graphs with complex\",\n",
            "        \"relationships and interdependencies between channels. Thus, the com-\",\n",
            "        \"plexity of the graph data has posed significant challenges to existing\",\n",
            "        \"DL algorithms. This motivates many research efforts on the use of\",\n",
            "        \"graph neural networks in the feature extraction and classification of\",\n",
            "        \"EEG signals, especially for emotion recognition tasks. For example, a\",\n",
            "        \"Bayesian GNN framework was proposed to detect the latent commu-\",\n",
            "        \"nities between EEG channels based on the SJTU Emotion EEG dataset,\",\n",
            "        \"which is facilitated by the use of a sparse graph variational autoencoder\",\n",
            "        \"to encode channel features into a sparse latent space [140]. Meanwhile,\",\n",
            "        \"some variants of the GNN models have been adopted to improve the\",\n",
            "        \"classification accuracy and training efficiency of emotion recognition\",\n",
            "        \"such as a Granger causality analysis-based GCN model [141], a graph\",\n",
            "        \"convolutional broad network [142] and a hierarchical aggregation-\",\n",
            "        \"based GNN [143]. However, information flow between different EEG\",\n",
            "        \"channels and their internal relationship was not fully considered and\",\n",
            "        \"investigated in these studies due to its complexity and uncertainty.\",\n",
            "        \"Inspired by this challenge, the relationship between adjacent electrodes\",\n",
            "        \"and the information between transverse and longitudinal electrodes\",\n",
            "        \"were explored. Using an attentive simple GCN, the coarse-grained\",\n",
            "        \"and fine-grained inter-channel relationship in the EEG-based human\",\n",
            "        \"decision confidence measurement can be captured [144], and also a\",\n",
            "        \"hierarchy GCN model was developed to extract deeper spatial features\",\n",
            "        \"during motion recognition tasks [145]. Results show that information\",\n",
            "        \"on spatial features can facilitate the description of the internal relation-\",\n",
            "        \"ship of the channels. Further, how to extract the spatial and temporal\",\n",
            "        \"information of EEG signals simultaneously and how such information\",\n",
            "        \"affects emotion recognition were investigated. Sun et al. [146] used\",\n",
            "        \"an adaptive spatial\\u2013temporal GCN to extract the time-domain char-\",\n",
            "        \"acteristics of EEG signals and the channel correlations in the spatial\",\n",
            "        \"domain simultaneously by information aggregation from EEG channels.\",\n",
            "        \"Also, a spatiotemporal and self-adaptive GCN has demonstrated the\",\n",
            "        \"capability of adaptively capturing significant sequential segments and\",\n",
            "        \"spatial location information in EEG signals for single and multi-view\",\n",
            "        \"EEG-based emotion recognition [147].\",\n",
            "        \"An attention mechanism was applied in the GNN model given\",\n",
            "        \"its good ability to extract information from key channels. A typical\",\n",
            "        \"example is that a self-attention dynamic GCN was used to obtain the\",\n",
            "        \"spatial structure information and temporal evolution characteristics\",\n",
            "        \"of brain networks for improving the EEG-based emotion recognition\",\n",
            "        \"system [148]. Then, a recent study utilised inter-temporal attention\",\n",
            "        \"blocks in a dynamic STGCN to explore the intra-frame dependency of\",\n",
            "        \"each electrode in the brain region and to extract spatial and tempo-\",\n",
            "        \"ral features separately [149]. Also, the attention block was used to\",\n",
            "        \"capture the long-range dependencies between different electrodes for\",\n",
            "        \"accurate classification. To have a remarkable response time in the MI\",\n",
            "        \"recognition, a GCN model combined with the attention mechanism of\",\n",
            "        \"BiLSTM was to enhance the recognition performance by considering the\",\n",
            "        \"topological structure of features [150]. As shown in Fig. 12, an STGCN-\",\n",
            "        \"based command classification system was developed for a reliable and\",\n",
            "        \"accurate translation of brainwave command phrases into robot com-\",\n",
            "        \"mands. Within this STGCN model, a standard convolution operation\",\n",
            "        \"was used to obtain the temporal features of the EEG signals, and the\",\n",
            "        \"graph convolution was for aggregating information from neighbour\",\n",
            "        \"nodes to obtain the spatial features [33]. However, emotion recognition\",\n",
            "        \"may also involve the situation of multi-task classification. Therefore,\",\n",
            "        \"by integrating multiple self-supervised tasks, a graph-based multi-task\",\n",
            "        \"self-supervised learning model can learn more general representations\",\n",
            "        \"from EEG signals during emotion recognition. However, the training\",\n",
            "        \"of GCN models often needs a large number of data to be labelled,\",\n",
            "        \"and a novel combination of self-organising incremental neural network\",\n",
            "        \"and GCN self-training was adopted to solve such a problem [151]. Be-\",\n",
            "        \"sides, various GNN models with different regularisation strategies were\",\n",
            "        \"developed to model the functional neural connectivity between EEG\",\n",
            "        \"electrode sites, and show better performance on the classification tasks\",\n",
            "        \"across ErrP and rapid serial visual presentation datasets compared with\",\n",
            "        \"CNN models [152]. Then, the functional neural connectivity subject to\",\n",
            "        \"a cognitive task between different electrode sites was explored, and it\",\n",
            "        \"uses a multi-head attention mechanism-based GNN model to simulta-\",\n",
            "        \"neously learn the unsupervised graph topology in conjunction with the\",\n",
            "        \"parameters of graph convolutional kernels [153]. Finally, a detailed\",\n",
            "        \"application of the classification of the functional brain network was\",\n",
            "        \"validated by the fatigue driving detection implemented by a B-spline\",\n",
            "        \"curve spatial convolution-based GNN [154].\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"13\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"4.3. Statistical methods in brain signals classification\",\n",
            "        \"Despite the success of DL algorithms on EEG signal classification,\",\n",
            "        \"research efforts on conventional statistical methods for EEG signal\",\n",
            "        \"classification tasks have been widely investigated given their low com-\",\n",
            "        \"putational complexity. Hand-crafted features are often defined as the\",\n",
            "        \"control inputs to these methods that output the classification and\",\n",
            "        \"recognition results. They are usually derived and categorised into the\",\n",
            "        \"statistical classification originally calculated from probabilistic meth-\",\n",
            "        \"ods. The statistical method divides the feature space into different\",\n",
            "        \"classes by calculating the probability of a certain feature belonging to\",\n",
            "        \"a specific class. As a linear method, linear discriminant analysis uses\",\n",
            "        \"the data of each class to generate a model of the probability density\",\n",
            "        \"function and then classify the new data. LDA divides the feature space\",\n",
            "        \"into several classes by hyper-planes [155]. In addition, SVM has been\",\n",
            "        \"widely used for EEG signal classification given its capacity for high\",\n",
            "        \"accuracy and dealing with a large number of predictors as well as low\",\n",
            "        \"computational complexity. Many studies on the SVM and its variants\",\n",
            "        \"for EEG signals classification (e.g., MI and emotion recognition) have\",\n",
            "        \"been reported in the literature. Different from LDA, SVM maps the\",\n",
            "        \"current input feature vector into a new higher-dimensional feature\",\n",
            "        \"space for linear separation of the features. This is executed by the use\",\n",
            "        \"of some nonlinear mapping and then using the optimal hyperplanes to\",\n",
            "        \"separate these nonlinear functions of the features. Moreover, a tunable-\",\n",
            "        \"Q WT-based method was developed for feature extraction of MI EEG\",\n",
            "        \"signals, and the extracted features act as inputs to a least-squares\",\n",
            "        \"SVM classifier for the classification of right-hand and right-foot MI\",\n",
            "        \"tasks [156]. A comprehensive study of the SVM on the EEG signal\",\n",
            "        \"classification, specifically detecting physiological patterns can be found\",\n",
            "        \"in [157]. Another mostly used statistical classifier is the hidden Markov\",\n",
            "        \"model, which is derived from a Markov model. It is a class of a\",\n",
            "        \"probabilistic graphical model that allows us to predict a sequence of\",\n",
            "        \"unknown (hidden) variables from a set of observed variables. It has\",\n",
            "        \"been used for the analysis of non-stationary signals by dividing the\",\n",
            "        \"signal into segments and computing feature sets for each segment.\",\n",
            "        \"Given the non-stationary characteristics of the EEG signals, the hidden\",\n",
            "        \"Markov model and its variants have been widely used for EEG signal\",\n",
            "        \"classification tasks such as PhysioNet EEG recordings with eyes open\",\n",
            "        \"and eyes-closed [158].\",\n",
            "        \"In addition, a recursive Bayesian decision framework applicable to\",\n",
            "        \"discrete task and brain phenomena was investigated (e.g., P300, SSVEP,\",\n",
            "        \"and MI), and it includes context prior distributions and considers\",\n",
            "        \"varying brain symbol accuracy. The adopted maximum mutual infor-\",\n",
            "        \"mation coding maximises a generalisation of the information transfer\",\n",
            "        \"rate [159]. A kernel extreme learning machine on EEG brain signals\",\n",
            "        \"was used to classify the P300 wave during the subject development of\",\n",
            "        \"an oddball paradigm [160].\",\n",
            "        \"5. Brain\\u2013computer interface-controlled robot and applications\",\n",
            "        \"A BCI is a system that establishes direct communication between\",\n",
            "        \"the brain and a computer. The electrical changes, produced when\",\n",
            "        \"neurons fire and communicate with each other, are processed and\",\n",
            "        \"decoded into commands that are sent to an output device to carry\",\n",
            "        \"out a desired action. These actions cover diverse applications from\",\n",
            "        \"rehabilitation to human augmentation. To interact with and control\",\n",
            "        \"external devices such as robots, brain signals can be modulated by using\",\n",
            "        \"either an intention-driven (endogenous) BCI or a stimulus-driven (ex-\",\n",
            "        \"ogenous) BCI. Endogenous BCIs depend on user-generated commands\",\n",
            "        \"for intuitive control of external devices, while exogenous signals are\",\n",
            "        \"defined as any brain signals that require an external stimulus to be\",\n",
            "        \"evoked. In terms of stimulation sources, the former mainly includes\",\n",
            "        \"visual, auditory or somatosensory, e.g., P300 and SSVEP, and the latter\",\n",
            "        \"contain MI, facial movement, spelling- and emotion-based paradigms,\",\n",
            "        \"and mixed paradigms that combined two or more of these methods.\",\n",
            "        \"Fig. 13 shows the statistical category of the BCI-controlled robotic\",\n",
            "        \"Fig. 13. Statistical category of the BCI-controlled robotic devices within applications.\",\n",
            "        \"Source: Updated based on the statistical data of [161].\",\n",
            "        \"applications, and robots controlled by EEG signals can be categorised as\",\n",
            "        \"(1) exoskeletons, orthotics, and haptic robots; (2) robotic hands/arms;\",\n",
            "        \"(3) mobile robots; (4) wheelchairs; (5) prosthetics; and (6) others\",\n",
            "        \"such as assistive devices. It can be seen from Fig. 13 that BCI-based\",\n",
            "        \"applications of exoskeletons, orthotics, and haptic robots take account\",\n",
            "        \"of the majority of the percentages (28%), and the BCI is purposely\",\n",
            "        \"designed to support the use of daily life activities of users such as\",\n",
            "        \"motor rehabilitation and restoration. The robotic arms/hands with a\",\n",
            "        \"percentage of 23% are widely applied in multiple applications such\",\n",
            "        \"as assistive tasks. In addition, given the capability of mobile robots\",\n",
            "        \"in mobility and flexibility, mobile robots make up 17% of BCI-based\",\n",
            "        \"robotic applications. The minority of the use of BCI-based robots is\",\n",
            "        \"prosthetics. The statistical data of Fig. 13 may not cover all BCI-based\",\n",
            "        \"robots, but it can give an overview of robotic applications facilitated\",\n",
            "        \"by non-invasive electrode-based BCIs.\",\n",
            "        \"5.1. Control of BCI-based robotic devices\",\n",
            "        \"Brain commands can be used to control different types of robots.\",\n",
            "        \"This novel type of interaction has opened a new world of applications.\",\n",
            "        \"For example, BCIs with non-invasive electrodes have been used to\",\n",
            "        \"control robotic arms and hands, autonomous navigation robots, drones\",\n",
            "        \"and wheelchairs. Recent advances in the BCI and robotic fields allow\",\n",
            "        \"researchers to design a new generation of brain-actuated neuropros-\",\n",
            "        \"theses for the control of a variety of assistive devices. The types of\",\n",
            "        \"mental paradigms exploited for this include MI and ERPs, such as P300\",\n",
            "        \"or SSVEPs. A prototype of a wheelchair controlled with a BCI based on\",\n",
            "        \"the P300 paradigm was first investigated. Tanaka et al. [162] presented\",\n",
            "        \"a study on EEG-based BCI for controlling the direction of an electric\",\n",
            "        \"wheelchair. Motivated by this study, a hybrid BCI paradigm to provide\",\n",
            "        \"both direction and speed control commands to a simulated or real\",\n",
            "        \"wheelchair was investigated [163]. To have a better user experience,\",\n",
            "        \"a hybrid BCI for the asynchronous operation of a brain-controlled\",\n",
            "        \"wheelchair based on the combined MI and P300 potential can allow\",\n",
            "        \"users to control the wheelchair\\u2019s motion and directions by the embed-\",\n",
            "        \"ded functions [164]. The hybrid BCI-based system was further extended\",\n",
            "        \"to control complex robotic operations (e.g., robotic grasping) [165],\",\n",
            "        \"in which one MI command was used to control the robot to execute\",\n",
            "        \"the grasp motion together with three SSVEP commands for robot\",\n",
            "        \"movement control such as moving forward, turning left and right. In\",\n",
            "        \"parallel, Wang et al. [166] proposed a Bayesian-based shared controller\",\n",
            "        \"for intelligently combining robot automatic control and brain-actuated\",\n",
            "        \"control, and it can realise the optimal control of a brain-actuated shared\",\n",
            "        \"control system. Finally, the all-time continuous wheelchair navigation\",\n",
            "        \"task controlled by an SSVEP-based BCI validated the effectiveness of\",\n",
            "        \"the proposed method.\",\n",
            "        \"Many research efforts on BCI-controlled robots have been reported\",\n",
            "        \"in the literature. For example, a new brain\\u2013robot interaction system\",\n",
            "        \"that fuses human and machine intelligence improves the real-time\",\n",
            "        \"control performance of the NAO humanoid robot, and brainwaves are\",\n",
            "        \"used to guide the robot to its destinations. Within such a system, a\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"14\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Fig. 14. ErrP-based assistive robotic manipulators through a noninvasive BCI.\",\n",
            "        \"Source: adapted and modified from [167].\",\n",
            "        \"human operator performs high-level supervision on the system, while\",\n",
            "        \"machine intelligence-assisting-robots in accomplishing tasks, and the\",\n",
            "        \"SSVEP takes over the situations in which machine intelligence cannot\",\n",
            "        \"make decisions [168]. Meanwhile, a new BRI system using a portable\",\n",
            "        \"brain signal collector to control a LEGO robot to a certain destination\",\n",
            "        \"was developed, in which three commands were identified from SSVEP\",\n",
            "        \"patterns corresponding to three robot actions [169]. It can be observed\",\n",
            "        \"that the use of the SSVEP signals in the robotic control has shown good\",\n",
            "        \"performance, especially in robot manipulation. For example, utilising\",\n",
            "        \"SSVEP for controlling a 4-degree-of-freedom robotic manipulator and\",\n",
            "        \"four types of robot behaviours were investigated, respectively [170],\",\n",
            "        \"and an SSVEP-based BCI system can generate seven control com-\",\n",
            "        \"mands for the operation of the service robot, which can provide three\",\n",
            "        \"fundamental services: mobility, manipulation, and delivery [171]. In\",\n",
            "        \"addition, the use of EEG-based BCI in high-level control of a robotic\",\n",
            "        \"manipulator was also studied for accurate and reliable control during\",\n",
            "        \"the execution of complex tasks [172]. Another study used MI EEG\",\n",
            "        \"signals to control a multijoint redundant robot system (e.g., robot\",\n",
            "        \"directions) [173], and it allows users only to think about the end-point\",\n",
            "        \"movement of the robot arm as a triggering command to simultaneous\",\n",
            "        \"robot control. However, most BCI-controlled robotic applications only\",\n",
            "        \"rely on the brainwave-to-robot control scheme and do not consider the\",\n",
            "        \"mutual human brain\\u2013robot adaptation. For this purpose, a closed-loop\",\n",
            "        \"BCI-based control scheme for an exoskeleton robot system was devel-\",\n",
            "        \"oped to allow the robot to perform manipulation tasks controlled by\",\n",
            "        \"EEG signals of human operators, and an intention decoding algorithm\",\n",
            "        \"converts the neural activities into control commands of the exoskeleton\",\n",
            "        \"robot [174]. Nevertheless, the non-stationary nature of EEG signals\",\n",
            "        \"makes it impossible to safely control tasks where errors may let the\",\n",
            "        \"user in a high-risk situation. Targeting this problem, the combination\",\n",
            "        \"of ErrP-BCI and Gaussian process-based inverse RL was adopted to refer\",\n",
            "        \"to users\\u2019 preference by detecting the occurrence of ErrP signals and\",\n",
            "        \"then generate personalised robot trajectories when the robot performed\",\n",
            "        \"collision avoidance tasks [167], and its overall control architecture is\",\n",
            "        \"shown in Fig. 14, and the left-side subfigure illustrates the detection\",\n",
            "        \"of ErrP signals elicited by a feeling of uncertainty to the user as the\",\n",
            "        \"robot may collide with the glass, and the right-side subfigure shows\",\n",
            "        \"the assistive robotic manipulations (i.e., grasping and placing objects)\",\n",
            "        \"supported by the RL algorithm that learns user\\u2019s preference and adapts\",\n",
            "        \"the robot behaviour rapidly.\",\n",
            "        \"During the use of BCIs for robot control, users often need to learn\",\n",
            "        \"how to modulate their sensorimotor brain rhythms by MI practices us-\",\n",
            "        \"ing a visual feedback-based training protocol. An efficient BCI training\",\n",
            "        \"protocol using a human-like android robot was developed to provide\",\n",
            "        \"realistic visual feedback [175]. The EEG-based BRI architecture can\",\n",
            "        \"recognise users\\u2019 mental state accordingly to the biofeedback factor,\",\n",
            "        \"based on users\\u2019 attention, intention, and focus, that is used to elicit\",\n",
            "        \"a robot to exhibit customised behaviours [176]. Online experiments\",\n",
            "        \"carried out with a real robot demonstrate an accurate detection of\",\n",
            "        \"target objects solely based on the natural brain responses to high-\",\n",
            "        \"lighted objects [177]. However, realising continuous robot control by\",\n",
            "        \"using brainwave signals is complicated and difficult in some appli-\",\n",
            "        \"cation settings. One study explored the use of a novel BCI-driven\",\n",
            "        \"control scheme based on dynamical systems to support users in sending\",\n",
            "        \"commands to continuously drive a mobile robot [178]. To decouple\",\n",
            "        \"the user from the loop to improve the system design and testing\",\n",
            "        \"process, a brain-controlled mobile robot steering model including a\",\n",
            "        \"queuing network cognitive architecture-based operator decision model\",\n",
            "        \"and a BCI performance model was investigated. The former can mimic\",\n",
            "        \"the human decision process with individual differences considered,\",\n",
            "        \"and the latter represents the accuracy of BCI during brain-controlled\",\n",
            "        \"operations [179].\",\n",
            "        \"In brain-actuated robotic systems, two typical categories of inter-\",\n",
            "        \"actions namely direct control [162,163,180] and shared control [181,\",\n",
            "        \"182] are often adopted, and it depends on whether the human and\",\n",
            "        \"the robot are in close proximity to each other and on the level of\",\n",
            "        \"interaction [183]. The direct control mode represents that the robot\",\n",
            "        \"is controlled directly by means of the decoded BCI commands, and\",\n",
            "        \"this control mode has a relatively low control cost and computational\",\n",
            "        \"complexity but poses large stress and burden on the subjects. Zhang\",\n",
            "        \"et al. [184] proposed a brain-actuated robotic manipulator based on\",\n",
            "        \"shared control, and the system perceives environmental information\",\n",
            "        \"through vision sensors to generate candidate objects. Shared control\",\n",
            "        \"and shared autonomy play an important role in assistive technologies,\",\n",
            "        \"allowing the offloading of the cognitive burden required for control\",\n",
            "        \"from the user to the intelligent robotic device. Measurement of a\",\n",
            "        \"person\\u2019s brain activity as ErrPs is used to provide passive adaptation\",\n",
            "        \"of an external semi-autonomous system to the human. It was achieved\",\n",
            "        \"in an online robot learning task, where the user\\u2019s evaluation of the\",\n",
            "        \"robot\\u2019s actions through the detected ErrP was used to update a reward\",\n",
            "        \"function in an RL framework [185]. In addition, the use of EEG signals\",\n",
            "        \"for industrial robot control during human\\u2013robot collaborative assembly\",\n",
            "        \"was investigated as shown in Fig. 15 [11]. Human instructions in the\",\n",
            "        \"form of EEG signals recorded by an Emotiv sensor headset were trans-\",\n",
            "        \"lated into true robot control commands for assembly task execution\",\n",
            "        \"during the assembly of a car engine manifold, and function blocks\",\n",
            "        \"emulated in RobotStudio software were adopted to facilitate robotic\",\n",
            "        \"assembly planning and control. During the collaborative assembly, an\",\n",
            "        \"industrial robot was controlled by EEG signals to put the parts together\",\n",
            "        \"for a human worker to assemble them. The major advantages of such\",\n",
            "        \"a framework are its easy integration with voice, gestures and haptic\",\n",
            "        \"commands and the ability to free up the mental and physical capacity\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"15\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Fig. 15. EEG-based BCI-controlled human\\u2013robot collaborative assembly.\",\n",
            "        \"Source: Adapted from [11].\",\n",
            "        \"Fig. 16. A BCI-controlled lower-limb exoskeleton supported by shared control.\",\n",
            "        \"Source: Adapted from [192].\",\n",
            "        \"of the operators to allow them to control the robot while performing\",\n",
            "        \"a shared task. In addition to these applications, a multimodal BCI\",\n",
            "        \"that combines EOG, EEG, and EMG signals can generate numerous\",\n",
            "        \"control instructions for real-time control of a soft robot hand [186],\",\n",
            "        \"and a brain-actuated humanoid robot navigation system using an EEG-\",\n",
            "        \"BCI to translate different human intentions into appropriate movement\",\n",
            "        \"commands for robotic applications [187]. Several innovative robotic\",\n",
            "        \"neuronavigation systems based on industrial robots have been devel-\",\n",
            "        \"oped and even applied in clinical practice [188\\u2013190]. In addition, a\",\n",
            "        \"BRI allowing children to mentally drive a robot was explored, in which\",\n",
            "        \"P300-based BCI and a shared-autonomy approach are combined to\",\n",
            "        \"achieve reliable robot navigation [191].\",\n",
            "        \"Safety is of paramount importance in any BCI-based robotic system.\",\n",
            "        \"To address the safety of brain-controlled vehicles under emergency\",\n",
            "        \"situations, EEG signals were used to detect the driver\\u2019s emergency\",\n",
            "        \"braking intentions [193]. Motivated by ameliorating BCI end-users\\u2019\",\n",
            "        \"experience and safety concerns in controlling external devices, the\",\n",
            "        \"combination of an immersive P300-based BCI application with a head-\",\n",
            "        \"mounted display for virtual-local and robotic-remote social interactions\",\n",
            "        \"was developed to provide the users with additional information for safe\",\n",
            "        \"operations [194]. The low number of brain-based commands that can\",\n",
            "        \"be decoded does not allow a supernumerary robotic limb to achieve a\",\n",
            "        \"high number of actions. To solve this challenge, an intelligent brain-\",\n",
            "        \"controlled supernumerary robotic limb system with context-aware ca-\",\n",
            "        \"pabilities was proposed and increased actions were controlled by the\",\n",
            "        \"same BCI-based command. The proposed system includes a human-like\",\n",
            "        \"robotic limb that can be controlled by a non-invasive EEG-based BCI\",\n",
            "        \"when the human operator imagines the action [195]. Within the robot\",\n",
            "        \"control, the robot operating system as an open-source platform has\",\n",
            "        \"a critical role in building robot applications, especially for BCI-based\",\n",
            "        \"robot applications. For example, a combination of a non-invasive sensor\",\n",
            "        \"headset and ROS was investigated to mentally drive a telepresence\",\n",
            "        \"robot [196], and a ROS-Neuro-based middleware was developed for\",\n",
            "        \"neural signals acquisition from different commercial acquisition devices\",\n",
            "        \"and saving the signals with common data formats [197].\",\n",
            "        \"5.2. BCI-controlled robotic rehabilitation\",\n",
            "        \"BCIs for motor rehabilitation are generally developed for patients\",\n",
            "        \"who have suffered a stroke or spinal cord injury, causing upper- or\",\n",
            "        \"lower-limb paralysis. The typical goal is to train patients with a BCI\",\n",
            "        \"for a certain time, after which they will achieve improvements in their\",\n",
            "        \"motor function. These improvements are facilitated by establishing\",\n",
            "        \"an associative link between the areas of the brain responsible for\",\n",
            "        \"performing the movement and peripheral feedback, which promotes\",\n",
            "        \"the reorganisation of cortical and cortico-spinal circuits. The most\",\n",
            "        \"common protocols for training are either requesting the patients to\",\n",
            "        \"try to move their paralysed limb (motor attempt), or asking them\",\n",
            "        \"to mentally simulate the movement (MI), and then supporting that\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"16\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"action with a robotic exoskeleton, as shown in Fig. 16 or electrical\",\n",
            "        \"stimulation of the muscles. After the training, the use of BCI-controlled\",\n",
            "        \"robotic rehabilitation for upper limbs is actively studied. A typical\",\n",
            "        \"example is that a patient\\u2019s EEG signals of left or right upper limb\",\n",
            "        \"movement can be translated to directly control an upper-limb reha-\",\n",
            "        \"bilitation robot [198]. In addition, a BCI system for the neuro-motor\",\n",
            "        \"rehabilitation of upper limbs in stroke survivors was investigated, and\",\n",
            "        \"it consists of a passive robotic device (Trackhold) for kinematic tracking\",\n",
            "        \"and gravity compensation, five dedicated virtual reality applications\",\n",
            "        \"for the training of distinct movement patterns, and high-resolution\",\n",
            "        \"EEG for synchronous monitoring of cortical activity [199]. However,\",\n",
            "        \"how to realise the high efficiency of BCI-controlled robotic upper-limb\",\n",
            "        \"rehabilitation is still a challenge. Accordingly, Ang et al. [200] explored\",\n",
            "        \"the efficiency of an EEG-based MI BCI system coupled with MIT-\",\n",
            "        \"Manus shoulder-elbow robotic feedback for subjects with chronic stroke\",\n",
            "        \"with upper-limb hemiparesis. The study of using BCI for lower limb\",\n",
            "        \"rehabilitation control also attracted much attention. For example, a\",\n",
            "        \"brain-controlled lower extremity exoskeleton rehabilitation robot with\",\n",
            "        \"an MI-based BCI to enhance active rehabilitation participation was\",\n",
            "        \"presented [201]. Nevertheless, most of the existing non-invasive hybrid\",\n",
            "        \"BCI devices have only been subjected to offline testing or limitation\",\n",
            "        \"to one DoF. For this purpose, an EEG-EMG-hybrid BCI was proposed\",\n",
            "        \"to allow the simultaneous control of 7-DoFs of the upper limb with\",\n",
            "        \"a robotic exoskeleton, and it built a biologically-inspired hierarchical\",\n",
            "        \"control scheme through active participation of central and peripheral\",\n",
            "        \"structures of the nervous system [202]. During the movement, passive\",\n",
            "        \"velocity field control was used as an underlying robot controller to map\",\n",
            "        \"instantaneous levels of MI to the speed of contour following tasks [203].\",\n",
            "        \"Many research efforts on applications of different BCI-based rehabil-\",\n",
            "        \"itation robots have been reported such as daily-life operations assisted\",\n",
            "        \"by robots. For example, a P300-based BCI and an assistive robot were\",\n",
            "        \"combined together to provide daily-life assistance to users with severe\",\n",
            "        \"motion disabilities [204]. However, BCI-based robotic rehabilitation\",\n",
            "        \"on patients or people with certain disability may be easily affected\",\n",
            "        \"by distributions. Therefore, predicting the potential of recovery using\",\n",
            "        \"biomarkers specific to an intervention hence becomes important to\",\n",
            "        \"have a reliable and robust application, and the intervention-specific\",\n",
            "        \"prognostic and monitory biomarkers of motor function improvements\",\n",
            "        \"were investigated using quantitative EEG features in 19 chronic stroke\",\n",
            "        \"patients following two different upper extremity rehabilitative inter-\",\n",
            "        \"ventions [205].\",\n",
            "        \"5.3. BCI-robot supported motor intention and restoration\",\n",
            "        \"BCI studies have shown that the motor intention for gross motor\",\n",
            "        \"skills, such as reaching, grasping or moving a computer cursor, can\",\n",
            "        \"be realised by BCIs. Meng et al. [206] used EEG signals to control\",\n",
            "        \"a robotic arm in a reaching and grasping task, in which the EEG\",\n",
            "        \"commands are used to control the robotic arm movement towards the\",\n",
            "        \"desired object and then the same mental task is used to enable the\",\n",
            "        \"grasping action once the object is reached. As shown in Fig. 17, Meng\",\n",
            "        \"et al. [206] implemented non-invasive EEG-based robotic arm control\",\n",
            "        \"for completing reach-grasp tasks, and Fig. 17(b), (c) and (d) show\",\n",
            "        \"MI tasks used to drive 2D virtual cursor or robotic arm movement,\",\n",
            "        \"reaching-and-grasping experiments, and trial structure of a single trial\",\n",
            "        \"task, respectively. The detailed introduction of the figure can be found\",\n",
            "        \"in [206]. The possible applications of non-invasive BCI technologies\",\n",
            "        \"were extended to include real-time multidimensional movement control\",\n",
            "        \"of the robotic device, and the result validated that it may not be\",\n",
            "        \"necessary to utilise implanted BCI electrodes for robust multidimen-\",\n",
            "        \"sional control [207]. This is further validated by studies of non-invasive\",\n",
            "        \"BCI systems for multi-dimensional robot control [208]. For example,\",\n",
            "        \"the use of non-invasive BCIs to allow users to manipulate a robotic\",\n",
            "        \"arm movement in a 3D space [181], complete a pick-place task of\",\n",
            "        \"multiple objects [209], and realise 2D movement control plus grasping\",\n",
            "        \"control [210] has been investigated. However, decoding brain signals to\",\n",
            "        \"explain the intended motion of the user in real time during interaction\",\n",
            "        \"with robots is still challenging, especially to control wearable robots\",\n",
            "        \"with multiple DoFs. To address the challenge, a new approach was\",\n",
            "        \"developed to control several DoFs of a wearable robot, and then esti-\",\n",
            "        \"mating the user\\u2019s motion intention in real time for performing the user\\u2019s\",\n",
            "        \"intended tasks investigated its feasibility by using EEG signals measured\",\n",
            "        \"from the scalp of the user [211]. The increase in the number of DoFs\",\n",
            "        \"under complex control and tasks to be accomplished (i.e., object ma-\",\n",
            "        \"nipulation and robotic grasping) make it difficult for BCI-based robotic\",\n",
            "        \"arm control [212]. Motivated by this challenge, more recent studies\",\n",
            "        \"reported the capability of using neuronal activities to control a robotic\",\n",
            "        \"arm in performing complicated reaching/grasping movement [213].\",\n",
            "        \"For example, a full upper-limb exoskeleton for motor rehabilitation\",\n",
            "        \"of reaching, grasping and releasing in post-stroke patients [214], and\",\n",
            "        \"using EEG signals to perform a multi-step grasping task of robotic\",\n",
            "        \"arm control in healthy and poststroke subjects [215] were actively\",\n",
            "        \"investigated, respectively.\",\n",
            "        \"In the case of lower-limb representation, reliably distinguishing leg\",\n",
            "        \"movement intentions and differentiating them in BCI systems is still a\",\n",
            "        \"problem. For this purpose, a foot MI-based BCI was used to collect EEG\",\n",
            "        \"signals as inputs for the designed control system that can allow one to\",\n",
            "        \"work online when the exoskeleton is performing a movement, and it\",\n",
            "        \"can differentiate the movement of the right and left legs with a high\",\n",
            "        \"degree of reliability [217]. Before this, a study realised the control of a\",\n",
            "        \"lower-limb exoskeleton to follow the wearer\\u2019s motion intention through\",\n",
            "        \"decoding EEG signals and multimodal cognition [218]. Additionally,\",\n",
            "        \"there is no arrangement to detect accidental falls. Therefore, a brain-\",\n",
            "        \"controlled lower limb exoskeleton was used to tackle this issue. Within\",\n",
            "        \"the context, EEG signals collected from a sensor headset were used to\",\n",
            "        \"detect human intentions and further control the exoskeleton movement\",\n",
            "        \"based on the user intention through a microcontroller [219]. Compared\",\n",
            "        \"with the exoskeleton control, BCI-based teleoperation for a dual-arm\",\n",
            "        \"robot performing object manipulation tasks can be controlled by human\",\n",
            "        \"intentions, which were classified and covered into reference commands\",\n",
            "        \"in task space for the robot [220].\",\n",
            "        \"The study of BCI-based motor restoration in hand exoskeletons has\",\n",
            "        \"been investigated to handle complex grasping operations. For example,\",\n",
            "        \"a novel hand exoskeleton based on BCIs was designed to assist and\",\n",
            "        \"restore the hand functions of people with motor disabilities in daily-\",\n",
            "        \"life environments. Through eliciting EEG brain patterns by using the\",\n",
            "        \"designed device, motor intention can be decoded for continuous control\",\n",
            "        \"of the hand exoskeleton [221]. During grasping motions of a hand\",\n",
            "        \"exoskeleton, the control performance was improved and enhanced by\",\n",
            "        \"the use of a novel brain/neural\\u2013computer interaction system in which\",\n",
            "        \"the EEG and EOG signals are defined as control inputs to the assistive\",\n",
            "        \"robots [222]. Within the context of HRC production systems, a worker-\",\n",
            "        \"centred collaborative framework was proposed for a harmonised and\",\n",
            "        \"safe HRC workspace through monitoring human workers\\u2019 mental state\",\n",
            "        \"and adjustment of robot behaviours [216]. As shown in Fig. 18, humans\",\n",
            "        \"and mobile robots work together on the collaborative tasks of construc-\",\n",
            "        \"tion, and human workers\\u2019 near-real-time brainwave signals streamed\",\n",
            "        \"from a 32-channel Emotiv Flex were defined as the control input to\",\n",
            "        \"evaluate their task-related cognitive load. The translated biosignals\",\n",
            "        \"were sent to a ROS-based robotic system to generate the robot control\",\n",
            "        \"commands executed through the robotic kinetic function, and finally a\",\n",
            "        \"three-level adjustment of the robot\\u2019s performance with high certainty\",\n",
            "        \"based on the prediction streams was performed with the support of a\",\n",
            "        \"field-oriented robotic mechanism.\",\n",
            "        \"5.4. BCI-controlled industrial robotic applications\",\n",
            "        \"BCIs can be used not only for active control of devices but also as a\",\n",
            "        \"tool to passively facilitate task execution in dynamic yet constrained\",\n",
            "        \"environments such as EEG-controlled robotic production. To have a\",\n",
            "        \"safe HRC, workers\\u2019 brainwaves from wearable EEG were collected to\",\n",
            "        \"evaluate task-related cognitive load, and then the robotic system will\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"17\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Fig. 17. Non-invasive EEG-based robotic arm control for reaching and grasping task.\",\n",
            "        \"Source: Adapted from [206].\",\n",
            "        \"Fig. 18. Brainwave-driven collaborative tasks within construction production systems.\",\n",
            "        \"Source: Adapted and modified from [216]\",\n",
            "        \"convert EEG signals into robot control commands, engage the robotic\",\n",
            "        \"kinetic function, and regulate the robot\\u2019s performance based on a field-\",\n",
            "        \"oriented robotic mechanism [216]. Within a collaborative assembly,\",\n",
            "        \"EEG signals were defined as control inputs to a robotic system, and\",\n",
            "        \"it allows users to use EEG signals to control the behaviour of robots by\",\n",
            "        \"generating explicit information in the form of assembly orders [223],\",\n",
            "        \"and error correction instructions [224]. In the case of human-multi-\",\n",
            "        \"robot cooperation, Dai et al. [225] investigated the use of BCIs as the\",\n",
            "        \"means of input for human intention to construct the shared intention\",\n",
            "        \"of the human and robots, and then various velocity components for\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"18\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Fig. 19. Overall implementation workflow of EEG-driven HRC assembly.\",\n",
            "        \"Source: Adapted and modified from [2]\",\n",
            "        \"shared intention, formation control, and obstacle avoidance were fused\",\n",
            "        \"to enable the robot team to efficiently, safely and flexibly complete all\",\n",
            "        \"tasks. However, the lack of information feedback makes it challenging\",\n",
            "        \"for BCI to control robots with a high DoF and a limited number of\",\n",
            "        \"classifiable mental states. To tackle this problem, a closed-loop BCI with\",\n",
            "        \"contextual visual feedback by an augmented reality headset was pro-\",\n",
            "        \"posed to allow users to perform an industrial HRC assembly task [226].\",\n",
            "        \"With the increasing use of collaborative robots in the workstation, an\",\n",
            "        \"implementation method of the BCI devices for industrial applications\",\n",
            "        \"was explored to make the cobots easy to use and interact with. Within\",\n",
            "        \"the context, the SSVEP signals were converted into executable machine\",\n",
            "        \"commands to manipulate a collaborative robotic arm for a multi-\",\n",
            "        \"task interaction with humans [227]. During the task execution, the\",\n",
            "        \"support of decision-making for a BCI-controlled brain\\u2013robot system is\",\n",
            "        \"necessary. For this purpose, an industrial robotic co-worker equipped\",\n",
            "        \"with a vision system can pick defective parts out of a conveyor based\",\n",
            "        \"on the operator\\u2019s decisions by constantly monitoring the operator using\",\n",
            "        \"BCI sensors [228], and also the robot can understand the operator\\u2019s\",\n",
            "        \"choice by analysing his/her brain signals when selecting the actual\",\n",
            "        \"welding seam from automatically generated possible ones [229].\",\n",
            "        \"In addition, brainwave-controlled robotics is considered a central\",\n",
            "        \"element in human-centric assembly [231]. Within this context, brain-\",\n",
            "        \"waves are used to control robots which are especially effective in noisy\",\n",
            "        \"factory environments and when operators are occupied with other tasks\",\n",
            "        \"in their hands. For this purpose, Wang et al. [2] investigated the use\",\n",
            "        \"of the BCI to facilitate the HRC assembly, and Fig. 19 introduced the\",\n",
            "        \"overall implementation workflow of EEG-driven HRC assembly. The\",\n",
            "        \"workflow starts with the recording of a control command/phrase in the\",\n",
            "        \"form of EEG signals collected from a g.tec sensor headset in Module\",\n",
            "        \"1. Then the command phrase is decomposed into three individual\",\n",
            "        \"command words (a subject, a predicate and an object, which represent\",\n",
            "        \"the executor, action, and component to be acted on, respectively)\",\n",
            "        \"in Module 2 where the time-series EEG signals are transformed into\",\n",
            "        \"time\\u2013frequency images through wavelet transform. Then, a true macro\",\n",
            "        \"control command on what to do, e.g., \\u2018robot place cylinder\\u2019, was recog-\",\n",
            "        \"nised by a DL-based command classification system, and transmitted to\",\n",
            "        \"Module 3 to activate the execution of the predefined function blocks.\",\n",
            "        \"Finally, micro control commands on how to perform robotic assembly\",\n",
            "        \"generated by these function blocks were sent to Module 4 for control\",\n",
            "        \"and task execution on the level of a robot controller through a human\\u2013\",\n",
            "        \"robot interface. However, the use of BCIs in manufacturing systems\",\n",
            "        \"often accompanies the safety concerns of users, and it also hinders\",\n",
            "        \"the wide acceptance of BCI-controlled robots in this field. To enhance\",\n",
            "        \"safety in symbiotic HRC settings, a mobile EEG-based upper-limb move-\",\n",
            "        \"ment intentions detection prior to a movement supported by a vision\",\n",
            "        \"system was investigated to have an early warning of an upcoming\",\n",
            "        \"movement [230], and the system design of an EEG-based safe HRC\",\n",
            "        \"scheme in a collaborative setting is shown in Fig. 20. In safe critical\",\n",
            "        \"zones defined by the reach of human arms, the intersection of a robot\\u2019s\",\n",
            "        \"path with such a safety sphere will trigger the robot motion to be either\",\n",
            "        \"halted or significantly slowed down, as a human operator works with\",\n",
            "        \"a cobot on collaborative assembly tasks. In parallel, the vision system\",\n",
            "        \"can capture and monitor the position of human limbs, and the EEG\",\n",
            "        \"signals recorded from a mobile EEG device were analysed to detect\",\n",
            "        \"the intention of whether an imminent movement of either the left or\",\n",
            "        \"the right arm is in place. A faster robot motion planning and collision\",\n",
            "        \"avoidance strategy can be triggered, once the mobile EEG sends a\",\n",
            "        \"warning of an imminent movement. In addition, the combination of\",\n",
            "        \"VR/AR technologies and non-invasive sensor headsets has been used\",\n",
            "        \"to achieve EEG-driven safe interaction between human workers and\",\n",
            "        \"robots such as EEG-controlled emergence stop of a robot [232,233] and\",\n",
            "        \"BCI-based closed loop HRC assembly supported by AR feedback [226].\",\n",
            "        \"6. Challenges and future directions\",\n",
            "        \"Although brain robotics, specifically BCI-controlled robotics, have\",\n",
            "        \"demonstrated significant progress in the past two decades, there are still\",\n",
            "        \"a set of challenges in many aspects such as electrodes and chips, com-\",\n",
            "        \"plex signal processing, elaboration of neural decoders, high-perform-\",\n",
            "        \"ance algorithms, advanced control schemes and bi-directional human\\u2013\",\n",
            "        \"robot adaption. Motivated by these challenges, future directions can be\",\n",
            "        \"identified and highlighted.\",\n",
            "        \"6.1. Towards new standards for safe brain robotics\",\n",
            "        \"Safety is of paramount importance in any brain\\u2013robot system, and\",\n",
            "        \"such a system often requires interactions between humans/brains and\",\n",
            "        \"robots. However, safety concern poses a huge challenge to the natural\",\n",
            "        \"acceptance of brain robotics in a wide range of applications. Although\",\n",
            "        \"research efforts on safety strategies and schemes have been numerous\",\n",
            "        \"and applied in university laboratories, real application settings are\",\n",
            "        \"often in complex and dynamic environments, which makes the current\",\n",
            "        \"existing solution impractical in brain\\u2013robot systems. In addition, the\",\n",
            "        \"existing ISO standards are mainly focused on the robot side and ignore\",\n",
            "        \"safety measurements of humans/brains. For example, ISO for collabora-\",\n",
            "        \"tive robots is purposely designed for safe cooperation between humans\",\n",
            "        \"and robots. However, there is no safety ISO standard for brain robotics,\",\n",
            "        \"and also the existing ISO standards in the field of robotics cannot\",\n",
            "        \"be well applied to brain robotics. For this purpose, new standards\",\n",
            "        \"for safe brain robotics are urgent to be investigated and proposed to\",\n",
            "        \"regulate safety strategies, solutions, and schemes. In addition, safety\",\n",
            "        \"measurement in brain\\u2013robot systems is also worth to be studied in the\",\n",
            "        \"future for the purpose of increasing their acceptance.\",\n",
            "        \"6.2. Mechanism and principles of neuroscience\",\n",
            "        \"The human brain is a very complex system with billions of neural\",\n",
            "        \"cells, and the advancement in neuroscience in terms of technologies\",\n",
            "        \"and tools is important to in-depth investigations of the underlying\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"19\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Fig. 20. EEG-based HRC scheme with enhanced safety in a collaborative setting.\",\n",
            "        \"Source: Adapted from [230],\",\n",
            "        \"mechanism and principle of neural firing. Brain signals can be gener-\",\n",
            "        \"ated in the forms of (1) (silent) speaking of a command in a person\\u2019s\",\n",
            "        \"head (e.g., imagined speech) [234], (2) motor imagery of body parts\",\n",
            "        \"(e.g., legs and arms) [65], (3) vision-based stimulus (e.g., P300) [235]\",\n",
            "        \"when different parts of the brain are activated. The corresponding\",\n",
            "        \"functions of each of the brain parts are shown in Table 1. For exam-\",\n",
            "        \"ple, the occipital area of the brain is mainly associated with visual\",\n",
            "        \"processing (colour, light, movement, etc.) These different manners of\",\n",
            "        \"generating brain signals can accordingly activate neural activities in\",\n",
            "        \"different brain areas. But the mechanism and principles of how the\",\n",
            "        \"human brain transmits neural signals are still unclear, and depending\",\n",
            "        \"on how the brain signals are produced, the brainwave patterns could be\",\n",
            "        \"significantly different even for the same EEG command. These represent\",\n",
            "        \"a major challenge to brainwave signal processing. Therefore, exploring\",\n",
            "        \"the working principles of neural cells and functions of brain areas\",\n",
            "        \"associated with specific EEG signals such as silent speaking is worth to\",\n",
            "        \"be studied. In addition, billions of neural nodes produce a complicated\",\n",
            "        \"network connection. The temporal variation of all the EEG channels\",\n",
            "        \"provides a temporal-spatial demonstration, and another dimension of\",\n",
            "        \"spectral contents of each channel is also associated with the analysis.\",\n",
            "        \"The study of prioritising coding of task-relevant information in the\",\n",
            "        \"brain areas is challenging but important to EEG signal processing and\",\n",
            "        \"BCI-based robotics.\",\n",
            "        \"6.3. High-performance and non-invasive electrodes of BCI\",\n",
            "        \"The electrodes of sensor headsets are for EEG signals collection,\",\n",
            "        \"and the commonly used types of non-invasive electrodes can be cat-\",\n",
            "        \"egorised into gel-based and dry electrodes. However, the electrodes\",\n",
            "        \"are often limited by several factors during real applications such as\",\n",
            "        \"SNR, signal resolutions, sensitivity, etc. Therefore, high-performance\",\n",
            "        \"electrodes with high SNR, high resolutions, and user-friendly materials\",\n",
            "        \"are urgent for advanced and easy-to-use BCI applications. In addition,\",\n",
            "        \"the electrodes should be on the same size scale as neighbouring neurons\",\n",
            "        \"and as flexible as possible. One challenge is how to build a safe and\",\n",
            "        \"effective BCI that is wireless and can scale up the number of electrodes.\",\n",
            "        \"Also, new microfabrication processes and advances in materials science\",\n",
            "        \"should be used to increase the performance of electrodes. BCIs need to\",\n",
            "        \"convert small neural activities (microvolts) recorded by electrodes into\",\n",
            "        \"real-time neural signals. Therefore, high-performance signal amplifiers\",\n",
            "        \"are required to produce recordable and high-quality EEG signals. Then,\",\n",
            "        \"the increased number of electrodes in an electrode array (e.g., 1024\",\n",
            "        \"electrodes) is expected to be able to record much more informative\",\n",
            "        \"signals, and the real-time transmission of such information requires\",\n",
            "        \"advanced on-chips with scaling-down per-channel chip size and low\",\n",
            "        \"power consumption. Thanks to the advancement of device fabrication,\",\n",
            "        \"the state-of-the-art microelectrode array can provide more than ten\",\n",
            "        \"thousand recording channels simultaneously and provides simultane-\",\n",
            "        \"ous stimulations. However, when the number of channels increases,\",\n",
            "        \"the computational throughput performance usually degrades. In this\",\n",
            "        \"case, high-performance computation devices such as mini graphics\",\n",
            "        \"processing units that can be embedded in BCI systems are necessary.\",\n",
            "        \"In addition, the influence of BCI devices on neural cells should be\",\n",
            "        \"investigated to measure the induced impact on the human brain.\",\n",
            "        \"6.4. EEG signal processing\",\n",
            "        \"EEG signals processing is a long-term and complicated challenge\",\n",
            "        \"in neuroengineering or neuroscience due to the inherent complexity\",\n",
            "        \"of signals. Although varying approaches to facilitating signal noise\",\n",
            "        \"removal, artefact reduction and BCI calibration have been reported\",\n",
            "        \"in the literature, many factors during data collection and processing\",\n",
            "        \"such as individual differences, sensor location, random environments,\",\n",
            "        \"algorithms and application settings prohibit to derive a generalised\",\n",
            "        \"solution for high-performance signal processing. In parallel, the dif-\",\n",
            "        \"ference between EEG signal-based applications also poses a significant\",\n",
            "        \"challenge to data processing with the generalisation capability across\",\n",
            "        \"application settings. In addition, EEG signals are commonly created\",\n",
            "        \"using external stimuli, such as visual aids, and stimulus-based EEG is\",\n",
            "        \"impractical for general use. Circumventing constraints associated with\",\n",
            "        \"stimulus-based EEG is also a big challenge, while the study of stimulus-\",\n",
            "        \"free EEG signals-based approaches is promising but the underlying\",\n",
            "        \"mechanism of stimulus-free EEG signals is not well investigated, and\",\n",
            "        \"much more difficulties on weaker signals extraction and classification\",\n",
            "        \"compared with those on stimulus-based EEG signals are obvious. The\",\n",
            "        \"poor signal quality can further complicate the ability to decode neural\",\n",
            "        \"events, especially when using non-invasive signals such as EEG.\",\n",
            "        \"6.5. Neural decoder\",\n",
            "        \"Within BCI-controlled robotics, real-time neural decoding of human\",\n",
            "        \"intent is a bottleneck to the accurate translation of EEG signals into\",\n",
            "        \"a robot control command during the interaction between humans and\",\n",
            "        \"robots, and it has high-demanding requirements for decoding per-\",\n",
            "        \"formance, accuracy, computational efficiency, and generalisation on\",\n",
            "        \"cross-subjects scenarios. Real-time decoding often relies on limited in-\",\n",
            "        \"put data which is determined by a sampling frequency, and further, the\",\n",
            "        \"algorithm of neural decoding is one of the key limitations in achieving\",\n",
            "        \"precise and robust information decoding. In addition, the optimisation\",\n",
            "        \"of neural decoders to individually varying brain activities is another\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"20\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"challenge. Given redundant robots with more DoFs, sensing human\",\n",
            "        \"states and intentions used for controlling robots (i.e., exoskeleton)\",\n",
            "        \"facilitated by real-time decoders will be also complicated. Therefore,\",\n",
            "        \"the elaboration of advanced neural decoders for signal decoding with\",\n",
            "        \"high accuracy, low latency, and high computational efficiency is an\",\n",
            "        \"important research direction.\",\n",
            "        \"6.6. Generalisation of learning-based models\",\n",
            "        \"Both conventional statistics learning methods and DL approaches\",\n",
            "        \"in EEG signals classification have achieved significant progress for\",\n",
            "        \"various applications such as MI classification and emotion recognition.\",\n",
            "        \"However, their robustness and generalisation across different use cases\",\n",
            "        \"are limited. For slightly varying cases even though the same scope\",\n",
            "        \"of the classification, in-depth investigation and much more effort on\",\n",
            "        \"algorithm design are often necessary, which is time-consuming and less\",\n",
            "        \"efficient. Therefore, the methodologies of learning-based models for the\",\n",
            "        \"purpose of general use will be an emerging challenge. The robustness\",\n",
            "        \"and accuracy of algorithms are also critical to reliable BCI-controlled\",\n",
            "        \"robotic applications. Using learning-based algorithms to extract infor-\",\n",
            "        \"mative contents of brain activities and to relate them to important\",\n",
            "        \"brain functions such as memory mechanisms are still unrecognised and\",\n",
            "        \"considered research gaps.\",\n",
            "        \"6.7. Bidirectional BCI to human/brain\\u2013robot adaptation\",\n",
            "        \"The adaptation of BCIs in robotics allows humans to use brainwaves\",\n",
            "        \"to directly control robots and task execution. However, closed loop-\",\n",
            "        \"based interfaces with feedback from a robot to a human brain, which\",\n",
            "        \"can allow seamless and natural acceptance of the robot by the hu-\",\n",
            "        \"man/brain, are still missing and challenging. Most BCI control relies on\",\n",
            "        \"vision alone and lacks a critical feedback dimension such as sensory.\",\n",
            "        \"The advancement of materials science such as electronic skins makes\",\n",
            "        \"it possible to receive indirect feedback to a processor together with\",\n",
            "        \"brain signals but is still far from direct and seamless bidirectional\",\n",
            "        \"brain\\u2013robot assistance. In addition, the type and modalities of feedback,\",\n",
            "        \"their spatiotemporal accuracy and resolutions, timing and duration\",\n",
            "        \"of feedback, and safety concerns pose a huge challenge to a mutual\",\n",
            "        \"adaptation of humans and robots. Meanwhile, the robots are expected\",\n",
            "        \"to amplify humans self-adaptably so that humans are empowered to\",\n",
            "        \"interact with work using the full potential of artificial and anthropolog-\",\n",
            "        \"ical co-intelligence. Continuous feedback control to enable brain\\u2013robot\",\n",
            "        \"adaptation through advanced control schemes within human/brain\\u2013\",\n",
            "        \"robot interaction loops and its generalisation across use cases and\",\n",
            "        \"applications are also a challenge.\",\n",
            "        \"6.8. Realistic and holistic open-source platform for brain robotics\",\n",
            "        \"Although BCIs have been used for brain-controlled robotic arms,\",\n",
            "        \"there is a lack of accessible and open-source platforms across varying\",\n",
            "        \"BCI devices and robotic arms. The platform not only needs to represent\",\n",
            "        \"genuine models that are easy to use for neuroengineering and neuro-\",\n",
            "        \"scientific studies but also be open-source and accessible to different\",\n",
            "        \"robotic devices. ROS as a set of software libraries and tools for build-\",\n",
            "        \"ing robot applications combined with BCIs is considered a promising\",\n",
            "        \"solution for such a platform. In conventional BCI-controlled robotics,\",\n",
            "        \"robots often execute tasks and control commands generated by BCIs.\",\n",
            "        \"However, sensing and merging robot states, tasks, and behavioural\",\n",
            "        \"and environmental information during human/brain\\u2013robot interactions\",\n",
            "        \"as control input reference to BCIs is important for the human brain\",\n",
            "        \"to perform decision-making and regulate robot actions in a closed\",\n",
            "        \"loop. In addition, self-regulating one\\u2019s brain activity through mental\",\n",
            "        \"tasks to interact is an acquired skill that requires appropriate training.\",\n",
            "        \"Yet several studies have shown that current training procedures do\",\n",
            "        \"not enable mental task-based BCI users to reach adequate levels of\",\n",
            "        \"performance. Thus, end-user training and understanding the processes\",\n",
            "        \"that underlie task-based BCI performance and user learning are other\",\n",
            "        \"challenges.\",\n",
            "        \"6.9. Brain-AI interface\",\n",
            "        \"The introduction of machine learning into the field of BCIs, which\",\n",
            "        \"began almost two decades ago, enabled unprecedented progress. Today,\",\n",
            "        \"machine learning algorithms have become an indispensable compo-\",\n",
            "        \"nent of a BCI. Machine learning, however, has undergone a radical\",\n",
            "        \"transformation in the past two decades, resulting in AI systems that\",\n",
            "        \"surpass human performance in many real-world tasks. Thanks to the\",\n",
            "        \"advancement of AI, it is time for the BCI community to embrace\",\n",
            "        \"these developments and build brain-AI interfaces, i.e., systems that\",\n",
            "        \"leverage the power of modern AI systems to enable natural human\\u2013\",\n",
            "        \"computer interaction. In particular, the AI system will take a dominant\",\n",
            "        \"role in deciding the level of granularity at which cognitive processes\",\n",
            "        \"are represented in neural signals. With the advancement of sensor\",\n",
            "        \"technologies, specifically electrodes, more and more EEG signals will\",\n",
            "        \"be recorded, and the combination of big data analytics and AI-driven\",\n",
            "        \"systems is a promising solution to support the realisation of the brain-AI\",\n",
            "        \"interface.\",\n",
            "        \"6.10. Social and ethic aspects\",\n",
            "        \"There are many thoughts surrounding the social and ethical issues\",\n",
            "        \"behind BCI as it considers physical, psychological, and social factors.\",\n",
            "        \"The main ethical issues include (i) user safety, (ii) autonomy, (iii)\",\n",
            "        \"responsibility, (iv) research ethics and informed consent, (v) privacy\",\n",
            "        \"and security, and (vi) justice [236]. Wearing a sensor headset is always\",\n",
            "        \"risky for users and can harm the human body to some worse extent.\",\n",
            "        \"The neural correlations of psychological phenomena are inexact and\",\n",
            "        \"poorly understood, which means that signals from human brains are\",\n",
            "        \"increasingly being processed by AI software before reaching prostheses,\",\n",
            "        \"and this procedure can inevitably include uncertain and uncontrolled\",\n",
            "        \"factors for the safe use of BCIs in applications. Strict requirements\",\n",
            "        \"during the use of BCI such as strict maintenance of the human body,\",\n",
            "        \"and long-time participation acting what electrodes need can have a\",\n",
            "        \"substantial impact on the human body.\",\n",
            "        \"7. Conclusions\",\n",
            "        \"This paper presents a state-of-the-art on brain robotics empow-\",\n",
            "        \"ered by AI and brain science. Research on BCI-controlled robotics\",\n",
            "        \"has been active for many years. Despite the advancement of brain\",\n",
            "        \"robotics in recent years, there are still a set of typical challenges from\",\n",
            "        \"high-performance electrodes to bidirectional brain\\u2013robot adaptation.\",\n",
            "        \"This paper aims at addressing these challenges together with recent\",\n",
            "        \"technological advancements. Within the context of brain robotics, this\",\n",
            "        \"paper provides an overview of the past and current status at the inter-\",\n",
            "        \"section of AI, robotics, and neuroscience, and topics covered include\",\n",
            "        \"brain science, BCIs, EEG signals acquisition and processing, learning-\",\n",
            "        \"based signal classification, BCI-controlled robotic applications, and also\",\n",
            "        \"highlights future research directions. Ten research directions driven\",\n",
            "        \"by underlying challenges are identified, hoping to shed some light\",\n",
            "        \"on further advancement in the future. With the support of the latest\",\n",
            "        \"technologies of sensors, computing, and control, brain robotics will\",\n",
            "        \"facilitate various nascent practical applications in this research domain.\",\n",
            "        \"Declaration of competing interest\",\n",
            "        \"The authors declare that they have no known competing finan-\",\n",
            "        \"cial interests or personal relationships that could have appeared to\",\n",
            "        \"influence the work reported in this paper.\",\n",
            "        \"Data availability\",\n",
            "        \"No data was used for the research described in the article.\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"21\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"Summary of algorithms for signal noise removal.\",\n",
            "        \"Category\",\n",
            "        \"Algorithm\",\n",
            "        \"Specification\",\n",
            "        \"Advantage\",\n",
            "        \"Limitation\",\n",
            "        \"Regression\",\n",
            "        \"Methods\",\n",
            "        \"Linear\",\n",
            "        \"regression\",\n",
            "        \"Define the amplitude relation between the\",\n",
            "        \"reference channel and EEG channel by\",\n",
            "        \"transmission factors, and then subtract the\",\n",
            "        \"estimated artefacts from EEG\",\n",
            "        \"Simplified model and reduced computational\",\n",
            "        \"demands\",\n",
            "        \"Need for one or more good regression\",\n",
            "        \"reference channels and not always available\",\n",
            "        \"anastomotic regression channels for muscle\",\n",
            "        \"artefact removal\",\n",
            "        \"BSS\",\n",
            "        \"ICA\",\n",
            "        \"Involve linear data projections to maximise\",\n",
            "        \"the mutual independence of the data\",\n",
            "        \"High performance when the same number of\",\n",
            "        \"sensors and sources, and linear mixing\",\n",
            "        \"medium with negligible propagation delay\",\n",
            "        \"More computation when decomposing signals\",\n",
            "        \"and rely on human intervention to remove\",\n",
            "        \"artifactual components, thus have limited use\",\n",
            "        \"in real-time applications\",\n",
            "        \"PCA\",\n",
            "        \"A dimensionality-reduction method that is\",\n",
            "        \"often used to reduce the dimensionality of\",\n",
            "        \"large data sets and converts observations of\",\n",
            "        \"correlated variables into a set of linearly\",\n",
            "        \"uncorrelated orthogonal variables\",\n",
            "        \"Effective at removing ocular artefacts and for\",\n",
            "        \"source localisation, improving algorithm\",\n",
            "        \"performance, and reducing overfitting\",\n",
            "        \"Cannot distinguish some artefact signals from\",\n",
            "        \"brain\\u2019s signals if amplitudes are not\",\n",
            "        \"comparable\",\n",
            "        \"CCA\",\n",
            "        \"Determine linear transformation of EEG that is\",\n",
            "        \"maximally correlated with a transformed\",\n",
            "        \"version of neural response to imagined\",\n",
            "        \"movement\",\n",
            "        \"High performance in removal of muscle\",\n",
            "        \"artefacts\",\n",
            "        \"Only reflect the variance shared by the linear\",\n",
            "        \"composites, not the variances extracted from\",\n",
            "        \"variables\",\n",
            "        \"SSA\",\n",
            "        \"Artefacts removal by clustering the columns of\",\n",
            "        \"the signal trajectory matrix formed with its\",\n",
            "        \"time-delayed versions and applying singular\",\n",
            "        \"value decomposition\",\n",
            "        \"A model-free method, structure identification\",\n",
            "        \"of nonlinear and non-stationary signal\",\n",
            "        \"Wavelet coherence could be influenced by the\",\n",
            "        \"choice of the mother wavelet function\",\n",
            "        \"Source\",\n",
            "        \"decomposition\",\n",
            "        \"methods\",\n",
            "        \"WT\",\n",
            "        \"Decompose EEG signals, discard the signals\",\n",
            "        \"that contain artefacts using the thresholding\",\n",
            "        \"and finally produce the clean signals through\",\n",
            "        \"adding the remaining details\",\n",
            "        \"Tunable time\\u2013frequency tradeoff and\",\n",
            "        \"superiority\",\n",
            "        \"Unable to detect artefacts that overlap with\",\n",
            "        \"spectral features fully\",\n",
            "        \"EMD\",\n",
            "        \"Decompose the EEG signal into a set of\",\n",
            "        \"components with amplitude\\u2013frequency\",\n",
            "        \"modulated (intrinsic mode functions), and\",\n",
            "        \"reflect, determine, and remove the artefact\",\n",
            "        \"components of the EEG\",\n",
            "        \"An effective empirical and data-driven\",\n",
            "        \"technique for the analysis of non-linear and\",\n",
            "        \"non-stationary signals\",\n",
            "        \"Sensitivity to noise, which incurs mode\",\n",
            "        \"mixing complications\",\n",
            "        \"Filtering\",\n",
            "        \"methods\",\n",
            "        \"Adaptive\",\n",
            "        \"filters\",\n",
            "        \"Change the coefficients of the linear filter,\",\n",
            "        \"and hence its frequency response, to generate\",\n",
            "        \"a signal similar to the noise present in the\",\n",
            "        \"signal to be filtered\",\n",
            "        \"Self-adjusted filter coefficients to\",\n",
            "        \"movement-specific artefacts\",\n",
            "        \"Applying the filters consumes computational\",\n",
            "        \"resources and would take time to process the\",\n",
            "        \"EEG signals\",\n",
            "        \"Wiener\",\n",
            "        \"filtering\",\n",
            "        \"Produces a linear time-invariant filter that\",\n",
            "        \"minimises the mean square error between the\",\n",
            "        \"desired signal and its estimate\",\n",
            "        \"Eliminates the limitation of extra reference\",\n",
            "        \"Calibration is needed prior to usage and it\",\n",
            "        \"cannot run in real time\",\n",
            "        \"Bayes\",\n",
            "        \"filtering\",\n",
            "        \"A probabilistic system estimation method\",\n",
            "        \"starting from noisy observations, based on\",\n",
            "        \"assuming that the system is Markov\",\n",
            "        \"No need of a reference signal and can work\",\n",
            "        \"in real time\",\n",
            "        \"Algorithm needs to be calibrated\",\n",
            "        \"Other\",\n",
            "        \"methods\",\n",
            "        \"CAR\",\n",
            "        \"Create an average of all scalp channels and\",\n",
            "        \"subtract the resulting signal from each\",\n",
            "        \"channel through an inactive reference for the\",\n",
            "        \"noise elimination\",\n",
            "        \"The highest classification accuracy if having\",\n",
            "        \"good recognition rates and ability to control\",\n",
            "        \"thoughts, and effective in reducing the\",\n",
            "        \"common electric noise\",\n",
            "        \"Have counterproductive effects when there is\",\n",
            "        \"no correlated noise between the reference and\",\n",
            "        \"recordings sites\",\n",
            "        \"Spatial\",\n",
            "        \"Laplacian\",\n",
            "        \"Transform the scalp-recorded EEG into the\",\n",
            "        \"estimation of radial current flow at scalp\",\n",
            "        \"Eliminate the blurring effect of current\",\n",
            "        \"diffusion and remove ocular movements\",\n",
            "        \"during signal acquisition\",\n",
            "        \"Sensitive to the selection of spline parameters\",\n",
            "        \"during spline interpolation\",\n",
            "        \"CSP\",\n",
            "        \"Use spatial filters to maximise the\",\n",
            "        \"discriminability of two classes for feature\",\n",
            "        \"extraction\",\n",
            "        \"Effectively detect abnormal EEG activity and\",\n",
            "        \"improve the SNR of single trail EEG signal\",\n",
            "        \"Extremely susceptible to noise and likely to\",\n",
            "        \"overfit and mainly for two-class features\",\n",
            "        \"Appendix\",\n",
            "        \"See Table A.1.\",\n",
            "        \"References\",\n",
            "        \"[1] S.N. Flesher, J.E. Downey, J.M. Weiss, C.L. Hughes, A.J. Herrera, E.C. Tyler-\",\n",
            "        \"Kabara, M.L. Boninger, J.L. Collinger, R.A. Gaunt, A brain-computer interface\",\n",
            "        \"that evokes tactile sensations improves robotic arm control, Science 372 (6544)\",\n",
            "        \"(2021) 831\\u2013836.\",\n",
            "        \"[2] L. Wang, S. Liu, C. Cooper, X.V. Wang, R.X. Gao, Function block-based human-\",\n",
            "        \"robot collaborative assembly driven by brainwaves, CIRP Ann. 70 (1) (2021)\",\n",
            "        \"5\\u20138.\",\n",
            "        \"[3] L.F. Nicolas-Alonso, J. Gomez-Gil, Brain computer interfaces, a review, Sensors\",\n",
            "        \"12 (2) (2012) 1211\\u20131279.\",\n",
            "        \"[4] G. Cheng, S.K. Ehrlich, M. Lebedev, M.A. Nicolelis, Neuroengineering challenges\",\n",
            "        \"of fusing robotics and neuroscience, Science Robotics 5 (49) (2020) eabd1911.\",\n",
            "        \"[5] T.O. Zander, C. Kothe, Towards passive brain\\u2013computer interfaces: applying\",\n",
            "        \"brain\\u2013computer interface technology to human\\u2013machine systems in general, J.\",\n",
            "        \"Neural Eng. 8 (2) (2011) 025005.\",\n",
            "        \"[6] E.\",\n",
            "        \"I\\u00e1\\u00f1ez,\",\n",
            "        \"J.M.\",\n",
            "        \"Azor\\u00edn,\",\n",
            "        \"A.\",\n",
            "        \"\\u00dabeda,\",\n",
            "        \"J.M.\",\n",
            "        \"Ferr\\u00e1ndez,\",\n",
            "        \"E.\",\n",
            "        \"Fern\\u00e1ndez,\",\n",
            "        \"Men-\",\n",
            "        \"tal tasks-based brain\\u2013robot interface, Robot. Auton. Syst. 58 (12) (2010)\",\n",
            "        \"1238\\u20131245.\",\n",
            "        \"[7] G. Salamon, Y.P. Huang, Radiologic Anatomy of the Brain, Springer Science &\",\n",
            "        \"Business Media, 2012.\",\n",
            "        \"[8] T. Bui, et al., Neuroanatomy, cerebral hemisphere, 2019.\",\n",
            "        \"[9] G. Paxinos, X.-F. Huang, Atlas of the Human Brainstem, Elsevier, 2013.\",\n",
            "        \"[10] P.L. Strick, R.P. Dum, J.A. Fiez, Cerebellum and nonmotor function, Annu. Rev.\",\n",
            "        \"Neurosci. 32 (2009) 413\\u2013434.\",\n",
            "        \"[11] A.\",\n",
            "        \"Mohammed,\",\n",
            "        \"L.\",\n",
            "        \"Wang,\",\n",
            "        \"Brainwaves\",\n",
            "        \"driven\",\n",
            "        \"human-robot\",\n",
            "        \"collaborative\",\n",
            "        \"assembly, CIRP Ann. 67 (1) (2018) 13\\u201316.\",\n",
            "        \"[12] L.\",\n",
            "        \"Wang,\",\n",
            "        \"X.V.\",\n",
            "        \"Wang,\",\n",
            "        \"J.\",\n",
            "        \"V\\u00e1ncza,\",\n",
            "        \"Z.\",\n",
            "        \"Kem\\u00e9ny,\",\n",
            "        \"Advanced\",\n",
            "        \"Human-Robot\",\n",
            "        \"Collaboration in Manufacturing, Springer, 2021.\",\n",
            "        \"[13] O. Sporns, J.D. Zwi, The small world of the cerebral cortex, Neuroinformatics\",\n",
            "        \"2 (2004) 145\\u2013162.\",\n",
            "        \"[14] A.D. Suthar, Neuralink technology: The future of neural engineering, J. Biomed.\",\n",
            "        \"Sci. (2021).\",\n",
            "        \"[15] S. Liu, L. Wang, X.V. Wang, C. Cooper, R.X. Gao, Leveraging multimodal\",\n",
            "        \"data for intuitive robot control towards human-robot collaborative assembly,\",\n",
            "        \"Procedia CIRP 104 (2021) 206\\u2013211.\",\n",
            "        \"[16] P.C. Fletcher, R.N.A. Henson, Frontal lobes and human memory: insights from\",\n",
            "        \"functional neuroimaging, Brain 124 (5) (2001) 849\\u2013881.\",\n",
            "        \"[17] An easy guide to neuron anatomy with diagrams, 2022, URL: https://www.\",\n",
            "        \"healthline.com/health/neurons.\",\n",
            "        \"[18] B. He, Z. Liu, Multimodal functional neuroimaging: integrating functional MRI\",\n",
            "        \"and EEG/MEG, IEEE Rev. Biomed. Eng. 1 (2008) 23\\u201340.\",\n",
            "        \"[19] R. Polan\\u00eda, M.A. Nitsche, C.C. Ruff, Studying and modifying brain function with\",\n",
            "        \"non-invasive brain stimulation, Nature Neurosci. 21 (2) (2018) 174\\u2013187.\",\n",
            "        \"[20] K. Bazaka, M.V. Jacob, Implantable devices: issues and challenges, Electronics\",\n",
            "        \"2 (1) (2012) 1\\u201334.\",\n",
            "        \"[21] J. Donoghue, D. Mijail, G. Serruya, L. Hatsopoulos, F. Matthew, Brain-machine\",\n",
            "        \"interface: Instant neural control of a movement signal, Nature 416 (2002) 14.\",\n",
            "        \"[22] M. Velliste, S. Perel, M.C. Spalding, A.S. Whitford, A.B. Schwartz, Corti-\",\n",
            "        \"cal control of a prosthetic arm for self-feeding, Nature 453 (7198) (2008)\",\n",
            "        \"1098\\u20131101.\",\n",
            "        \"[23] G. Schalk, D.J. McFarland, T. Hinterberger, N. Birbaumer, J.R. Wolpaw,\",\n",
            "        \"Bci2000: a general-purpose brain-computer interface (BCI) system, IEEE Trans.\",\n",
            "        \"Biomed. Eng. 51 (6) (2004) 1034\\u20131043.\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"22\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"[24] U. Chaudhary, N. Birbaumer, A. Ramos-Murguialday, Brain\\u2013computer interfaces\",\n",
            "        \"for communication and rehabilitation, Nat. Rev. Neurol. 12 (9) (2016) 513\\u2013525.\",\n",
            "        \"[25] A. Kulshreshth, A. Anand, A. Lakanpal, Neuralink-an Elon Musk start-up achieve\",\n",
            "        \"symbiosis with artificial intelligence, in: 2019 International Conference on\",\n",
            "        \"Computing, Communication, and Intelligent Systems, ICCCIS, IEEE, 2019, pp.\",\n",
            "        \"105\\u2013109.\",\n",
            "        \"[26] A. Morley, L. Hill, A. Kaditis, 10-20 System EEG Placement, European\",\n",
            "        \"Respiratory Society, 2016.\",\n",
            "        \"[27] J.A. Urig\\u00fcen, B. Garcia-Zapirain, EEG artifact removal\\u2014state-of-the-art and\",\n",
            "        \"guidelines, J. Neural Eng. 12 (3) (2015) 031001.\",\n",
            "        \"[28] K.T. Sweeney, T.E. Ward, S.F. McLoone, Artifact removal in physiological\",\n",
            "        \"signals\\u2014Practices and possibilities, IEEE Trans. Inf. Technol. Biomed. 16 (3)\",\n",
            "        \"(2012) 488\\u2013500.\",\n",
            "        \"[29] P. He, G. Wilson, C. Russell, M. Gerschutz, Removal of ocular artifacts from\",\n",
            "        \"the EEG: a comparison between time-domain regression method and adaptive\",\n",
            "        \"filtering method using simulated data, Med. Biol. Eng. Comput. 45 (2007)\",\n",
            "        \"495\\u2013503.\",\n",
            "        \"[30] E.M. ter Braack, B. de Jonge, M.J. Van Putten, Reduction of TMS induced\",\n",
            "        \"artifacts in EEG using principal component analysis, IEEE Trans. Neural Syst.\",\n",
            "        \"Rehabil. Eng. 21 (3) (2013) 376\\u2013382.\",\n",
            "        \"[31] A. Delorme, S. Makeig, EEGLAB: an open source toolbox for analysis of single-\",\n",
            "        \"trial EEG dynamics including independent component analysis, J. Neurosci.\",\n",
            "        \"Methods 134 (1) (2004) 9\\u201321.\",\n",
            "        \"[32] E. Alickovic, J. Kevric, A. Subasi, Performance evaluation of empirical mode de-\",\n",
            "        \"composition, discrete wavelet transform, and wavelet packed decomposition for\",\n",
            "        \"automated epileptic seizure detection and prediction, Biomed. Signal Process.\",\n",
            "        \"Control 39 (2018) 94\\u2013102.\",\n",
            "        \"[33] S. Liu, Multimodal Human-Robot Collaboration in Assembly (Ph.D. thesis), KTH\",\n",
            "        \"Royal Institute of Technology, 2022.\",\n",
            "        \"[34] P. Boonyakitanont, A. Lek-Uthai, K. Chomtho, J. Songsiri, A review of feature\",\n",
            "        \"extraction and performance evaluation in epileptic seizure detection using EEG,\",\n",
            "        \"Biomed. Signal Process. Control 57 (2020) 101702.\",\n",
            "        \"[35] S. Pahuja, K. Veer, et al., Recent approaches on classification and feature\",\n",
            "        \"extraction of EEG signal: A review, Robotica 40 (1) (2022) 77\\u2013101.\",\n",
            "        \"[36] U.R. Acharya, H. Fujita, V.K. Sudarshan, S. Bhat, J.E. Koh, Application of\",\n",
            "        \"entropies for automated diagnosis of epilepsy using EEG signals: A review,\",\n",
            "        \"Knowl.-Based Syst. 88 (2015) 85\\u201396.\",\n",
            "        \"[37] B. Hjorth, EEG analysis based on time domain properties, Electroencephalogr.\",\n",
            "        \"Clin. Neurophysiol. 29 (3) (1970) 306\\u2013310.\",\n",
            "        \"[38] R. Wang, J. Wang, H. Yu, X. Wei, C. Yang, B. Deng, Power spectral density and\",\n",
            "        \"coherence analysis of Alzheimer\\u2019s EEG, Cogn. Neurodyn. 9 (2015) 291\\u2013304.\",\n",
            "        \"[39] M. Penttil\\u00e4, J.V. Partanen, H. Soininen, P. Riekkinen, Quantitative analysis of\",\n",
            "        \"occipital EEG in different stages of Alzheimer\\u2019s disease, Electroencephalogr.\",\n",
            "        \"Clin. Neurophysiol. 60 (1) (1985) 1\\u20136.\",\n",
            "        \"[40] K. Polat, S. G\\u00fcne\\u015f, Classification of epileptiform EEG using a hybrid system\",\n",
            "        \"based on decision tree classifier and fast fourier transform, Appl. Math. Comput.\",\n",
            "        \"187 (2) (2007) 1017\\u20131026.\",\n",
            "        \"[41] V.K. Harpale, V.K. Bairagi, Time and frequency domain analysis of EEG\",\n",
            "        \"signals for seizure detection: A review, in: 2016 International Conference on\",\n",
            "        \"Microelectronics, Computing and Communications, MicroCom, IEEE, 2016, pp.\",\n",
            "        \"1\\u20136.\",\n",
            "        \"[42] S. Ayd\\u0131n, H.M. Sarao\\u011flu, S. Kara, Log energy entropy-based EEG classification\",\n",
            "        \"with multilayer neural networks in seizure, Ann. Biomed. Eng. 37 (2009)\",\n",
            "        \"2626\\u20132630.\",\n",
            "        \"[43] E.D. \\u00dcbeyli, Least squares support vector machine employing model-based\",\n",
            "        \"methods coefficients for analysis of EEG signals, Expert Syst. Appl. 37 (1) (2010)\",\n",
            "        \"233\\u2013239.\",\n",
            "        \"[44] M. Murugappan, N. Ramachandran, Y. Sazali, et al., Classification of human\",\n",
            "        \"emotion from EEG using discrete wavelet transform, J. Biomed. Sci. Eng. 3\",\n",
            "        \"(04) (2010) 390.\",\n",
            "        \"[45] A list of all public EEG-datasets, 2023.\",\n",
            "        \"[46] D. Buongiorno, G.D. Cascarano, I. De Feudis, A. Brunetti, L. Carnimeo, G. Di-\",\n",
            "        \"mauro, V. Bevilacqua, Deep learning for processing electromyographic signals:\",\n",
            "        \"A taxonomy-based survey, Neurocomputing 452 (2021) 549\\u2013565.\",\n",
            "        \"[47] D. Merlin Praveena, D. Angelin Sarah, S. Thomas George, Deep learning\",\n",
            "        \"techniques for EEG signal applications \\u2013 A review, IETE J. Res. 68 (4) (2022)\",\n",
            "        \"3030\\u20133037.\",\n",
            "        \"[48] F. Lotte, L. Bougrain, A. Cichocki, M. Clerc, M. Congedo, A. Rakotomamonjy,\",\n",
            "        \"F. Yger, A review of classification algorithms for EEG-based brain\\u2013Computer\",\n",
            "        \"interfaces: A 10 year update, J. Neural Eng. 15 (3) (2018) 031005.\",\n",
            "        \"[49] Y. Roy, H. Banville, I. Albuquerque, A. Gramfort, T.H. Falk, J. Faubert, Deep\",\n",
            "        \"learning-based electroencephalography analysis: A systematic review, J. Neural\",\n",
            "        \"Eng. 16 (5) (2019) 051001.\",\n",
            "        \"[50] R.B. Vallabhaneni, P. Sharma, V. Kumar, V. Kulshreshtha, K.J. Reddy, S.S.\",\n",
            "        \"Kumar, V.S. Kumar, S.K. Bitra, Deep learning algorithms in EEG signal decoding\",\n",
            "        \"application: A review, IEEE Access 9 (2021) 125778\\u2013125786.\",\n",
            "        \"[51] A. Craik, Y. He, J.L. Contreras-Vidal, Deep learning for electroencephalogram\",\n",
            "        \"(EEG) classification tasks: a review, J. Neural Eng. 16 (3) (2019) 031001.\",\n",
            "        \"[52] S. Aggarwal, N. Chugh, Review of machine learning techniques for EEG\",\n",
            "        \"based brain computer interface, Arch. Comput. Methods Eng. 29 (5) (2022)\",\n",
            "        \"3001\\u20133020.\",\n",
            "        \"[53] F. Wang, S. Wu, W. Zhang, Z. Xu, Y. Zhang, C. Wu, S. Coleman, Emo-\",\n",
            "        \"tion recognition with convolutional neural network and EEG-based EFDMs,\",\n",
            "        \"Neuropsychologia 146 (2020) 107506.\",\n",
            "        \"[54] A. Canziani, A. Paszke, E. Culurciello, An analysis of deep neural network\",\n",
            "        \"models for practical applications, 2016, arXiv preprint arXiv:1605.07678.\",\n",
            "        \"[55] Y. Hou, L. Zhou, S. Jia, X. Lun, A novel approach of decoding EEG four-class\",\n",
            "        \"motor imagery tasks via scout ESI and CNN, J. Neural Eng. 17 (1) (2020)\",\n",
            "        \"016048.\",\n",
            "        \"[56] K.-H. Shim, J.-H. Jeong, B.-H. Kwon, B.-H. Lee, S.-W. Lee, Assistive robotic\",\n",
            "        \"arm control based on brain-machine interface with vision guidance using\",\n",
            "        \"convolution neural network, in: 2019 IEEE International Conference on Systems,\",\n",
            "        \"Man and Cybernetics, SMC, IEEE, 2019, pp. 2785\\u20132790.\",\n",
            "        \"[57] V.J. Lawhern, A.J. Solon, N.R. Waytowich, S.M. Gordon, C.P. Hung, B.J. Lance,\",\n",
            "        \"EEGNet: a compact convolutional neural network for EEG-based brain\\u2013computer\",\n",
            "        \"interfaces, J. Neural Eng. 15 (5) (2018) 056013.\",\n",
            "        \"[58] H. Dose, J.S. M\\u00f8ller, H.K. Iversen, S. Puthusserypady, An end-to-end deep\",\n",
            "        \"learning approach to MI-EEG signal classification for BCIs, Expert Syst. Appl.\",\n",
            "        \"114 (2018) 532\\u2013542.\",\n",
            "        \"[59] X. Zhang, D. Wu, On the vulnerability of CNN classifiers in EEG-based BCIs,\",\n",
            "        \"IEEE Trans. Neural Syst. Rehabil. Eng. 27 (5) (2019) 814\\u2013825.\",\n",
            "        \"[60] G. Dai, J. Zhou, J. Huang, N. Wang, HS-CNN: a CNN with hybrid convolution\",\n",
            "        \"scale for EEG motor imagery classification, J. Neural Eng. 17 (1) (2020)\",\n",
            "        \"016025.\",\n",
            "        \"[61] M.T. Sadiq, M.Z. Aziz, A. Almogren, A. Yousaf, S. Siuly, A.U. Rehman,\",\n",
            "        \"Exploiting pretrained CNN models for the development of an EEG-based robust\",\n",
            "        \"BCI framework, Comput. Biol. Med. 143 (2022) 105242.\",\n",
            "        \"[62] F. Mattioli, C. Porcaro, G. Baldassarre, A 1D CNN for high accuracy clas-\",\n",
            "        \"sification and transfer learning in motor imagery EEG-based brain-computer\",\n",
            "        \"interface, J. Neural Eng. 18 (6) (2022) 066053.\",\n",
            "        \"[63] J.J. Bird, D.R. Faria, L.J. Manso, P.P. Ayrosa, A. Ekart, A study on CNN image\",\n",
            "        \"classification of EEG signals represented in 2D and 3D, J. Neural Eng. 18 (2)\",\n",
            "        \"(2021) 026005.\",\n",
            "        \"[64] V. Singhal, J. Mathew, R.K. Behera, et al., Detection of alcoholism using\",\n",
            "        \"EEG signals and a CNN-LSTM-ATTN network, Comput. Biol. Med. 138 (2021)\",\n",
            "        \"104940.\",\n",
            "        \"[65] H. Li, M. Ding, R. Zhang, C. Xiu, Motor imagery EEG classification algorithm\",\n",
            "        \"based on CNN-LSTM feature fusion network, Biomed. Signal Process. Control\",\n",
            "        \"72 (2022) 103342.\",\n",
            "        \"[66] S. Hwang, K. Hong, G. Son, H. Byun, Learning CNN features from DE features\",\n",
            "        \"for EEG-based emotion recognition, Pattern Anal. Appl. 23 (2020) 1323\\u20131335.\",\n",
            "        \"[67] B.P. Prathaban, R. Balasubramanian, Dynamic learning framework for epileptic\",\n",
            "        \"seizure prediction using sparsity based EEG Reconstruction with Optimized CNN\",\n",
            "        \"classifier, Expert Syst. Appl. 170 (2021) 114533.\",\n",
            "        \"[68] N. Mammone, C. Ieracitano, F.C. Morabito, A deep CNN approach to decode\",\n",
            "        \"motor preparation of upper limbs from time\\u2013frequency maps of EEG signals at\",\n",
            "        \"source level, Neural Netw. 124 (2020) 357\\u2013372.\",\n",
            "        \"[69] C. Huang, Y. Xiao, G. Xu, Predicting human intention-behavior through EEG sig-\",\n",
            "        \"nal analysis using multi-scale CNN, IEEE/ACM Trans. Comput. Biol. Bioinform.\",\n",
            "        \"18 (5) (2020) 1722\\u20131729.\",\n",
            "        \"[70] M.-a. Li, J.-f. Han, J.-f. Yang, Automatic feature extraction and fusion recogni-\",\n",
            "        \"tion of motor imagery EEG using multilevel multiscale CNN, Med. Biol. Eng.\",\n",
            "        \"Comput. 59 (10) (2021) 2037\\u20132050.\",\n",
            "        \"[71] A.M. Roy, An efficient multi-scale CNN model with intrinsic feature integration\",\n",
            "        \"for motor imagery EEG subject classification in brain-machine interfaces,\",\n",
            "        \"Biomed. Signal Process. Control 74 (2022) 103496.\",\n",
            "        \"[72] Y. Yang, Z. Gao, Y. Li, H. Wang, A CNN identified by reinforcement learning-\",\n",
            "        \"based optimization framework for EEG-based state evaluation, J. Neural Eng.\",\n",
            "        \"18 (4) (2021) 046059.\",\n",
            "        \"[73] H. Dong, D. Chen, L. Zhang, H. Ke, X. Li, Subject sensitive EEG discrimination\",\n",
            "        \"with fast reconstructable CNN driven by reinforcement learning: A case study\",\n",
            "        \"of ASD evaluation, Neurocomputing 449 (2021) 136\\u2013145.\",\n",
            "        \"[74] F.J. Martinez-Murcia, A. Ortiz, J.M. Gorriz, J. Ramirez, P.J. Lopez-Abarejo,\",\n",
            "        \"M. Lopez-Zamora, J.L. Luque, EEG connectivity analysis using denoising au-\",\n",
            "        \"toencoders for the detection of dyslexia, Int. J. Neural Syst. 30 (07) (2020)\",\n",
            "        \"2050037.\",\n",
            "        \"[75] J. Li, Z. Struzik, L. Zhang, A. Cichocki, Feature learning from incomplete EEG\",\n",
            "        \"with denoising autoencoder, Neurocomputing 165 (2015) 23\\u201331.\",\n",
            "        \"[76] A. Shoeibi, N. Ghassemi, M. Khodatars, P. Moridian, R. Alizadehsani, A. Zare, A.\",\n",
            "        \"Khosravi, A. Subasi, U.R. Acharya, J.M. Gorriz, Detection of epileptic seizures on\",\n",
            "        \"EEG signals using ANFIS classifier, autoencoders and fuzzy entropies, Biomed.\",\n",
            "        \"Signal Process. Control 73 (2022) 103417.\",\n",
            "        \"[77] N.M.N. Leite, E.T. Pereira, E.C. Gurjao, L.R. Veloso, Deep convolutional au-\",\n",
            "        \"toencoder for EEG noise filtering, in: 2018 IEEE International Conference on\",\n",
            "        \"Bioinformatics and Biomedicine, BIBM, IEEE, 2018, pp. 2605\\u20132612.\",\n",
            "        \"[78] Y. Qiu, W. Zhou, N. Yu, P. Du, Denoising sparse autoencoder-based ictal EEG\",\n",
            "        \"classification, IEEE Trans. Neural Syst. Rehabil. Eng. 26 (9) (2018) 1717\\u20131726.\",\n",
            "        \"[79] D. Bethge, P. Hallgarten, T. Grosse-Puppendahl, M. Kari, L.L. Chuang, O.\",\n",
            "        \"\\u00d6zdenizci, A. Schmidt, EEG2Vec: learning affective EEG representations via\",\n",
            "        \"variational autoencoders, in: 2022 IEEE International Conference on Systems,\",\n",
            "        \"Man, and Cybernetics, SMC, IEEE, 2022, pp. 3150\\u20133157.\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"23\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"[80] X. Li, Z. Zhao, D. Song, Y. Zhang, C. Niu, J. Zhang, J. Huo, J. Li, Variational\",\n",
            "        \"autoencoder based latent factor decoding of multichannel EEG for emotion\",\n",
            "        \"recognition, in: 2019 IEEE International Conference on Bioinformatics and\",\n",
            "        \"Biomedicine, BIBM, IEEE, 2019, pp. 684\\u2013687.\",\n",
            "        \"[81] X. Li, Z. Zhao, D. Song, Y. Zhang, J. Pan, L. Wu, J. Huo, C. Niu, D. Wang,\",\n",
            "        \"Latent factor decoding of multi-channel EEG for emotion recognition through\",\n",
            "        \"autoencoder-like neural networks, Front. Neurosci. 14 (2020) 87.\",\n",
            "        \"[82] S. Yang, Z. Yin, Y. Wang, W. Zhang, Y. Wang, J. Zhang, Assessing cognitive\",\n",
            "        \"mental workload via EEG signals and an ensemble deep learning classifier based\",\n",
            "        \"on denoising autoencoders, Comput. Biol. Med. 109 (2019) 159\\u2013170.\",\n",
            "        \"[83] Y. Wang, S. Qiu, D. Li, C. Du, B.-L. Lu, H. He, Multi-modal domain adapta-\",\n",
            "        \"tion variational autoencoder for EEG-based emotion recognition, IEEE/CAA J.\",\n",
            "        \"Autom. Sin. 9 (9) (2022) 1612\\u20131626.\",\n",
            "        \"[84] P. Sirpal, R. Damseh, K. Peng, D.K. Nguyen, F. Lesage, Multimodal autoencoder\",\n",
            "        \"predicts fNIRS resting state from EEG signals, Neuroinformatics 20 (3) (2022)\",\n",
            "        \"537\\u2013558.\",\n",
            "        \"[85] Z. Khademi, F. Ebrahimi, H.M. Kordy, A transfer learning-based CNN and LSTM\",\n",
            "        \"hybrid deep learning model to classify motor imagery EEG signals, Comput.\",\n",
            "        \"Biol. Med. 143 (2022) 105288.\",\n",
            "        \"[86] S. Alhagry, A.A. Fahmy, R.A. El-Khoribi, Emotion recognition based on EEG\",\n",
            "        \"using LSTM recurrent neural network, Int. J. Adv. Comput. Sci. Appl. 8 (10)\",\n",
            "        \"(2017).\",\n",
            "        \"[87] P. Wang, A. Jiang, X. Liu, J. Shang, L. Zhang, LSTM-based EEG classification\",\n",
            "        \"in motor imagery tasks, IEEE Trans. Neural Syst. Rehabil. Eng. 26 (11) (2018)\",\n",
            "        \"2086\\u20132095.\",\n",
            "        \"[88] P. Bashivan, I. Rish, M. Yeasin, N. Codella, Learning representations from\",\n",
            "        \"EEG with deep recurrent-convolutional neural networks, 2015, arXiv preprint\",\n",
            "        \"arXiv:1511.06448.\",\n",
            "        \"[89] Y. Bengio, P. Simard, P. Frasconi, Learning long-term dependencies with\",\n",
            "        \"gradient descent is difficult, IEEE Trans. Neural Netw. 5 (2) (1994) 157\\u2013166.\",\n",
            "        \"[90] R. Zhang, Q. Zong, L. Dou, X. Zhao, A novel hybrid deep learning scheme for\",\n",
            "        \"four-class motor imagery classification, J. Neural Eng. 16 (6) (2019) 066004.\",\n",
            "        \"[91] Y. Yang, Q. Wu, M. Qiu, Y. Wang, X. Chen, Emotion recognition from multi-\",\n",
            "        \"channel EEG through parallel convolutional recurrent neural network, in: 2018\",\n",
            "        \"international joint conference on neural networks, IJCNN, IEEE, 2018, pp. 1\\u20137.\",\n",
            "        \"[92] X. Li, D. Song, P. Zhang, G. Yu, Y. Hou, B. Hu, Emotion recognition from\",\n",
            "        \"multi-channel EEG data through convolutional recurrent neural network, in:\",\n",
            "        \"2016 IEEE International Conference on Bioinformatics and Biomedicine, BIBM,\",\n",
            "        \"IEEE, 2016, pp. 352\\u2013359.\",\n",
            "        \"[93] S. Lee, R. Hussein, R. Ward, Z.J. Wang, M.J. McKeown, A convolutional-\",\n",
            "        \"recurrent\",\n",
            "        \"neural\",\n",
            "        \"network\",\n",
            "        \"approach\",\n",
            "        \"to\",\n",
            "        \"resting-state\",\n",
            "        \"EEG\",\n",
            "        \"classification\",\n",
            "        \"in\",\n",
            "        \"Parkinson\\u2019s disease, J. Neurosci. Methods 361 (2021) 109282.\",\n",
            "        \"[94] T. Zhang, W. Zheng, Z. Cui, Y. Zong, Y. Li, Spatial\\u2013temporal recurrent neural\",\n",
            "        \"network for emotion recognition, IEEE Trans. Cybern. 49 (3) (2018) 839\\u2013847.\",\n",
            "        \"[95] Y. Hou, S. Jia, X. Lun, Y. Shi, Y. Li, Deep feature mining via attention-\",\n",
            "        \"based BiLSTM-GCN for human motor imagery recognition, 2020, arXiv preprint\",\n",
            "        \"arXiv:2005.00777.\",\n",
            "        \"[96] S. Kuanar, V. Athitsos, N. Pradhan, A. Mishra, K.R. Rao, Cognitive analysis\",\n",
            "        \"of working memory load from EEG, by a deep recurrent neural network, in:\",\n",
            "        \"2018 IEEE International Conference on Acoustics, Speech and Signal Processing,\",\n",
            "        \"ICASSP, IEEE, 2018, pp. 2576\\u20132580.\",\n",
            "        \"[97] C. Tan, F. Sun, W. Zhang, J. Chen, C. Liu, Multimodal classification with\",\n",
            "        \"deep convolutional-recurrent neural networks for electroencephalography, in:\",\n",
            "        \"Neural Information Processing: 24th International Conference, ICONIP 2017,\",\n",
            "        \"Guangzhou, China, November 14\\u201318, 2017, Proceedings, Part II, Vol. 24,\",\n",
            "        \"Springer, 2017, pp. 767\\u2013776.\",\n",
            "        \"[98] R. Hefron, B. Borghetti, C. Schubert Kabban, J. Christensen, J. Estepp, Cross-\",\n",
            "        \"participant EEG-based assessment of cognitive workload using multi-path\",\n",
            "        \"convolutional recurrent neural networks, Sensors 18 (5) (2018) 1339.\",\n",
            "        \"[99] A. Mazumder, A. Rakshit, D. Tibarewala, A back-propagation through time\",\n",
            "        \"based recurrent neural network approach for classification of cognitive EEG\",\n",
            "        \"states, in: 2015 IEEE International Conference on Engineering and Technology,\",\n",
            "        \"ICETECH, IEEE, 2015, pp. 1\\u20135.\",\n",
            "        \"[100] D. Zhang, L. Yao, X. Zhang, S. Wang, W. Chen, R. Boots, EEG-based inten-\",\n",
            "        \"tion recognition from spatio-temporal representations via cascade and parallel\",\n",
            "        \"convolutional recurrent neural networks, 2017, pp. 1\\u20138, arXiv preprint arXiv:\",\n",
            "        \"1708.06578.\",\n",
            "        \"[101] X. Ma, S. Qiu, C. Du, J. Xing, H. He, Improving EEG-based motor imagery\",\n",
            "        \"classification via spatial and temporal recurrent neural networks, in: 2018\",\n",
            "        \"40th Annual International Conference of the IEEE Engineering in Medicine and\",\n",
            "        \"Biology Society, EMBC, IEEE, 2018, pp. 1903\\u20131906.\",\n",
            "        \"[102] Z. Ni, A.C. Yuksel, X. Ni, M.I. Mandel, L. Xie, Confused or not confused?\",\n",
            "        \"Disentangling brain activity from EEG data using bidirectional LSTM recurrent\",\n",
            "        \"neural networks, in: Proceedings of the 8th ACM International Conference\",\n",
            "        \"on Bioinformatics, Computational Biology, and Health Informatics, 2017, pp.\",\n",
            "        \"241\\u2013246.\",\n",
            "        \"[103] S. Roy, I. Kiral-Kornek, S. Harrer, ChronoNet: a deep recurrent neural network\",\n",
            "        \"for abnormal EEG identification, in: Artificial Intelligence in Medicine: 17th\",\n",
            "        \"Conference on Artificial Intelligence in Medicine, AIME 2019, Poznan, Poland,\",\n",
            "        \"June 26\\u201329, 2019, Proceedings 17, Springer, 2019, pp. 47\\u201356.\",\n",
            "        \"[104] Q. Ma, M. Wang, L. Hu, L. Zhang, Z. Hua, A novel recurrent neural network\",\n",
            "        \"to classify EEG signals for customers\\u2019 decision-making behavior prediction in\",\n",
            "        \"brand extension scenario, Front. Hum. Neurosci. 15 (2021) 610890.\",\n",
            "        \"[105] S.M. Taha, Z.K. Taha, EEG signals classification based on autoregressive and\",\n",
            "        \"inherently quantum recurrent neural network, Int. J. Comput. Appl. Technol.\",\n",
            "        \"58 (4) (2018) 340\\u2013351.\",\n",
            "        \"[106] S. Zhang, L. Wu, S. Yu, E. Shi, N. Qiang, H. Gao, J. Zhao, S. Zhao, An explain-\",\n",
            "        \"able and generalizable recurrent neural network approach for differentiating\",\n",
            "        \"human brain states on EEG dataset, IEEE Trans. Neural Netw. Learn. Syst.\",\n",
            "        \"(2022).\",\n",
            "        \"[107] Y. Song, L. Yang, X. Jia, L. Xie, Common spatial generative adversarial networks\",\n",
            "        \"based EEG data augmentation for cross-subject brain-computer interface, 2021,\",\n",
            "        \"arXiv preprint arXiv:2102.04456.\",\n",
            "        \"[108] N. Lu, T. Li, X. Ren, H. Miao, A deep learning scheme for motor imagery\",\n",
            "        \"classification based on restricted Boltzmann machines, IEEE Trans. Neural Syst.\",\n",
            "        \"Rehabil. Eng. 25 (6) (2016) 566\\u2013576.\",\n",
            "        \"[109] M.-A. Moinnereau, T. Brienne, S. Brodeur, J. Rouat, K. Whittingstall, E. Plourde,\",\n",
            "        \"Classification of auditory stimuli from EEG signals with a regulated recurrent\",\n",
            "        \"neural network reservoir, 2018, arXiv preprint arXiv:1804.10322.\",\n",
            "        \"[110] Y. Ren, Y. Wu, Convolutional deep belief networks for feature extraction of EEG\",\n",
            "        \"signal, in: 2014 International Joint Conference on Neural Networks, IJCNN,\",\n",
            "        \"IEEE, 2014, pp. 2850\\u20132853.\",\n",
            "        \"[111] W.-L. Zheng, J.-Y. Zhu, Y. Peng, B.-L. Lu, EEG-based emotion classification using\",\n",
            "        \"deep belief networks, in: 2014 IEEE International Conference on Multimedia\",\n",
            "        \"and Expo, ICME, IEEE, 2014, pp. 1\\u20136.\",\n",
            "        \"[112] W.-L. Zheng, H.-T. Guo, B.-L. Lu, Revealing critical channels and frequency\",\n",
            "        \"bands for emotion recognition from EEG with deep belief network, in: 2015\",\n",
            "        \"7th International IEEE/EMBS Conference on Neural Engineering, NER, IEEE,\",\n",
            "        \"2015, pp. 154\\u2013157.\",\n",
            "        \"[113] K. Li, X. Li, Y. Zhang, A. Zhang, Affective state recognition from EEG with deep\",\n",
            "        \"belief networks, in: 2013 IEEE International Conference on Bioinformatics and\",\n",
            "        \"Biomedicine, IEEE, 2013, pp. 305\\u2013310.\",\n",
            "        \"[114] D. Wulsin, J. Blanco, R. Mani, B. Litt, Semi-supervised anomaly detection for\",\n",
            "        \"EEG waveforms using deep belief nets, in: 2010 Ninth International Conference\",\n",
            "        \"on Machine Learning and Applications, IEEE, 2010, pp. 436\\u2013441.\",\n",
            "        \"[115] D. Wulsin, J. Gupta, R. Mani, J. Blanco, B. Litt, Modeling electroencephalog-\",\n",
            "        \"raphy waveforms with semi-supervised deep belief nets: fast classification and\",\n",
            "        \"anomaly measurement, J. Neural Eng. 8 (3) (2011) 036015.\",\n",
            "        \"[116] R. Chai, S.H. Ling, P.P. San, G.R. Naik, T.N. Nguyen, Y. Tran, A. Craig, H.T.\",\n",
            "        \"Nguyen, Improving EEG-based driver fatigue classification using sparse-deep\",\n",
            "        \"belief networks, Front. Neurosci. 11 (2017) 103.\",\n",
            "        \"[117] H. Cai, X. Sha, X. Han, S. Wei, B. Hu, Pervasive EEG diagnosis of depression\",\n",
            "        \"using deep belief network with three-electrodes EEG collector, in: 2016 IEEE\",\n",
            "        \"International Conference on Bioinformatics and Biomedicine, BIBM, IEEE, 2016,\",\n",
            "        \"pp. 1239\\u20131246.\",\n",
            "        \"[118] Y. Chu, X. Zhao, Y. Zou, W. Xu, J. Han, Y. Zhao, A decoding scheme for\",\n",
            "        \"incomplete motor imagery EEG with deep belief network, Front. Neurosci. 12\",\n",
            "        \"(2018) 680.\",\n",
            "        \"[119] G. Altan, Y. Kutlu, N. Allahverdi, Deep belief networks based brain activity\",\n",
            "        \"classification using EEG from slow cortical potentials in stroke, Int. J. Appl.\",\n",
            "        \"Math. Electron. Comput. (Special Issue-1) (2016) 205\\u2013210.\",\n",
            "        \"[120] P. Kawde, G.K. Verma, Deep belief network based affect recognition from\",\n",
            "        \"physiological signals, in: 2017 4th IEEE Uttar Pradesh Section International\",\n",
            "        \"Conference on Electrical, Computer and Electronics, UPCON, IEEE, 2017, pp.\",\n",
            "        \"587\\u2013592.\",\n",
            "        \"[121] Z. Yin, J. Zhang, Cross-subject recognition of operator functional states via EEG\",\n",
            "        \"and switching deep belief networks with adaptive weights, Neurocomputing 260\",\n",
            "        \"(2017) 349\\u2013366.\",\n",
            "        \"[122] P. Li, W. Jiang, F. Su, Single-channel EEG-based mental fatigue detection based\",\n",
            "        \"on deep belief network, in: 2016 38th Annual International Conference of the\",\n",
            "        \"IEEE Engineering in Medicine and Biology Society, EMBC, IEEE, 2016, pp.\",\n",
            "        \"367\\u2013370.\",\n",
            "        \"[123] A. Bablani, D.R. Edla, V. Kuppili, Deceit identification test on EEG data using\",\n",
            "        \"deep belief network, in: 2018 9th International Conference on Computing,\",\n",
            "        \"Communication and Networking Technologies, ICCCNT, IEEE, 2018, pp. 1\\u20136.\",\n",
            "        \"[124] S. Panwar, P. Rad, J. Quarles, Y. Huang, Generating EEG signals of an RSVP\",\n",
            "        \"experiment by a class conditioned wasserstein generative adversarial network,\",\n",
            "        \"in: 2019 IEEE International Conference on Systems, Man and Cybernetics, SMC,\",\n",
            "        \"IEEE, 2019, pp. 1304\\u20131310.\",\n",
            "        \"[125] Q. Zhang, Y. Liu, Improving brain computer interface performance by data aug-\",\n",
            "        \"mentation with conditional deep convolutional generative adversarial networks,\",\n",
            "        \"2018, arXiv preprint arXiv:1806.07108.\",\n",
            "        \"[126] V.M. Petru\\u0163iu, L.D. Palcu, C. Lemnaru, M. D\\u00een\\u015foreanu, R. Potolea, R. Murse\\u015fan,\",\n",
            "        \"V.V. Moca, Enhancing the classification of EEG signals using wasserstein\",\n",
            "        \"generative adversarial networks, in: 2020 IEEE 16th International Conference\",\n",
            "        \"on Intelligent Computer Communication and Processing, ICCP, IEEE, 2020, pp.\",\n",
            "        \"29\\u201334.\",\n",
            "        \"[127] F. Xu, G. Dong, J. Li, Q. Yang, L. Wang, Y. Zhao, Y. Yan, J. Zhao, S.\",\n",
            "        \"Pang, D. Guo, et al., Deep convolution generative adversarial network-based\",\n",
            "        \"electroencephalogram data augmentation for post-stroke rehabilitation with\",\n",
            "        \"motor imagery, Int. J. Neural Syst. 32 (9) (2022) 2250039.\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"24\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"[128] S. Haradal, H. Hayashi, S. Uchida, Biosignal data augmentation based on\",\n",
            "        \"generative adversarial networks, in: 2018 40th Annual International Conference\",\n",
            "        \"of the IEEE Engineering in Medicine and Biology Society, EMBC, IEEE, 2018,\",\n",
            "        \"pp. 368\\u2013371.\",\n",
            "        \"[129] S.M. Abdelfattah, G.M. Abdelrahman, M. Wang, Augmenting the size of EEG\",\n",
            "        \"datasets using generative adversarial networks, in: 2018 International Joint\",\n",
            "        \"Conference on Neural Networks, IJCNN, IEEE, 2018, pp. 1\\u20136.\",\n",
            "        \"[130] K.G. Hartmann, R.T. Schirrmeister, T. Ball, EEG-GAN: Generative adversarial\",\n",
            "        \"networks for electroencephalograhic (EEG) brain signals, 2018, arXiv preprint\",\n",
            "        \"arXiv:1806.01875.\",\n",
            "        \"[131] I.A. Corley, Y. Huang, Deep EEG super-resolution: Upsampling EEG spatial res-\",\n",
            "        \"olution with generative adversarial networks, in: 2018 IEEE EMBS International\",\n",
            "        \"Conference on Biomedical & Health Informatics, BHI, IEEE, 2018, pp. 100\\u2013103.\",\n",
            "        \"[132] Y. An, H.K. Lam, S.H. Ling, Auto-denoising for EEG signals using generative\",\n",
            "        \"adversarial network, Sensors 22 (5) (2022) 1750.\",\n",
            "        \"[133] P. Sawangjai, M. Trakulruangroj, C. Boonnag, M. Piriyajitakonkij, R.K. Tripathy,\",\n",
            "        \"T. Sudhawiyangkul, T. Wilaiprasitporn, EEGANet: Removal of ocular artifacts\",\n",
            "        \"from the EEG signal using generative adversarial networks, IEEE J. Biomed.\",\n",
            "        \"Health Inf. 26 (10) (2021) 4913\\u20134924.\",\n",
            "        \"[134] F. Fahimi, S. Dosen, K.K. Ang, N. Mrachacz-Kersting, C. Guan, Generative\",\n",
            "        \"adversarial networks-based data augmentation for brain\\u2013computer interface,\",\n",
            "        \"IEEE Trans. Neural Netw. Learn. Syst. 32 (9) (2020) 4039\\u20134051.\",\n",
            "        \"[135] S. Panwar, P. Rad, T.-P. Jung, Y. Huang, Modeling EEG data distribution with a\",\n",
            "        \"Wasserstein generative adversarial network to predict RSVP events, IEEE Trans.\",\n",
            "        \"Neural Syst. Rehabil. Eng. 28 (8) (2020) 1720\\u20131730.\",\n",
            "        \"[136] A. Vahid, M. M\\u00fcckschel, S. Stober, A.-K. Stock, C. Beste, Conditional generative\",\n",
            "        \"adversarial networks applied to EEG data can inform about the inter-relation\",\n",
            "        \"of antagonistic behaviors on a neural level, Commun. Biol. 5 (1) (2022) 148.\",\n",
            "        \"[137] S. Hwang, K. Hong, G. Son, H. Byun, EZSL-GAN: EEG-based zero-shot learning\",\n",
            "        \"approach using a generative adversarial network, in: 2019 7th International\",\n",
            "        \"Winter Conference on Brain-Computer Interface, BCI, IEEE, 2019, pp. 1\\u20134.\",\n",
            "        \"[138] S. Palazzo, C. Spampinato, I. Kavasidis, D. Giordano, M. Shah, Generative\",\n",
            "        \"adversarial networks conditioned by brain signals, in: Proceedings of the IEEE\",\n",
            "        \"International Conference on Computer Vision, 2017, pp. 3410\\u20133418.\",\n",
            "        \"[139] Y.-E. Lee, M. Lee, S.-W. Lee, Reconstructing ERP signals using generative\",\n",
            "        \"adversarial networks for mobile brain-machine interface, 2020, arXiv preprint\",\n",
            "        \"arXiv:2005.08430.\",\n",
            "        \"[140] J. Chen, H. Qian, X. Gong, Bayesian graph neural networks for EEG-based\",\n",
            "        \"emotion recognition, in: Clinical Image-Based Procedures, Distributed and\",\n",
            "        \"Collaborative Learning, Artificial Intelligence for Combating COVID-19 and\",\n",
            "        \"Secure and Privacy-Preserving Machine Learning, Springer, 2021, pp. 24\\u201333.\",\n",
            "        \"[141] J. Zhang, X. Zhang, Q. Zhao, Improved graph convolutional neural networks\",\n",
            "        \"based on Granger causality analysis for EEG emotion recognition, in: 2022\",\n",
            "        \"International Conference on Computer Engineering and Artificial Intelligence,\",\n",
            "        \"ICCEAI, IEEE, Shijiazhuang, China, 2022, pp. 684\\u2013688, http://dx.doi.org/10.\",\n",
            "        \"1109/ICCEAI55464.2022.00146.\",\n",
            "        \"[142] T. Zhang, X. Wang, X. Xu, C.L.P. Chen, GCB-Net: Graph Convolutional Broad\",\n",
            "        \"Network and its application in emotion recognition, IEEE Trans. Affect. Comput.\",\n",
            "        \"13 (1) (2022) 379\\u2013388.\",\n",
            "        \"[143] H. Liu, J. Zhang, Q. Liu, J. Cao, Minimum spanning tree based graph\",\n",
            "        \"neural network for emotion classification using EEG, Neural Netw. 145 (2022)\",\n",
            "        \"308\\u2013318.\",\n",
            "        \"[144] L.-D. Liu, R. Li, Y.-Z. Liu, H.-L. Li, B.-L. Lu, EEG-based human decision\",\n",
            "        \"confidence measurement using graph neural networks, in: T. Mantoro, M. Lee,\",\n",
            "        \"M.A. Ayu, K.W. Wong, A.N. Hidayanto (Eds.), Neural Information Processing,\",\n",
            "        \"Vol. 1517, Springer International Publishing, Cham, 2021, pp. 291\\u2013298, http:\",\n",
            "        \"//dx.doi.org/10.1007/978-3-030-92310-5_34.\",\n",
            "        \"[145] F. Zheng, B. Hu, S. Zhang, Y. Li, X. Zheng, EEG emotion recognition based on\",\n",
            "        \"hierarchy graph convolution network, in: 2021 IEEE International Conference\",\n",
            "        \"on Bioinformatics and Biomedicine, BIBM, IEEE, Houston, TX, USA, 2021, pp.\",\n",
            "        \"1628\\u20131632, http://dx.doi.org/10.1109/BIBM52615.2021.9669465.\",\n",
            "        \"[146] B. Sun, H. Zhang, Z. Wu, Y. Zhang, T. Li, Adaptive spatiotemporal graph\",\n",
            "        \"convolutional networks for motor imagery classification, IEEE Signal Process.\",\n",
            "        \"Lett. 28 (2021) 219\\u2013223.\",\n",
            "        \"[147] Y. Gao, X. Fu, T. Ouyang, Y. Wang, EEG-GCN: Spatio-temporal and self-adaptive\",\n",
            "        \"graph convolutional networks for single and multi-view EEG-based emotion\",\n",
            "        \"recognition, IEEE Signal Process. Lett. 29 (2022) 1574\\u20131578.\",\n",
            "        \"[148] C. Li, Y. Sheng, H. Wang, M. Niu, P. Jing, Z. Zhao, B.W. Schuller, EEG emotion\",\n",
            "        \"recognition based on self-attention dynamic graph neural networks, in: 2022\",\n",
            "        \"44th Annual International Conference of the IEEE Engineering in Medicine &\",\n",
            "        \"Biology Society, EMBC, IEEE, Glasgow, Scotland, United Kingdom, 2022, pp.\",\n",
            "        \"292\\u2013296, http://dx.doi.org/10.1109/EMBC48229.2022.9871072.\",\n",
            "        \"[149] M.\",\n",
            "        \"Li,\",\n",
            "        \"H.\",\n",
            "        \"Chen,\",\n",
            "        \"Z.\",\n",
            "        \"Cheng,\",\n",
            "        \"An\",\n",
            "        \"attention-guided\",\n",
            "        \"spatiotemporal\",\n",
            "        \"graph\",\n",
            "        \"convolutional network for sleep stage classification, Life 12 (5) (2022) 622.\",\n",
            "        \"[150] Y. Hou, S. Jia, X. Lun, S. Zhang, T. Chen, F. Wang, J. Lv, Deep feature\",\n",
            "        \"mining via the attention-based bidirectional long short term memory graph\",\n",
            "        \"convolutional neural network for human motor imagery recognition, Front.\",\n",
            "        \"Bioeng. Biotechnol. 9 (2022) 706229.\",\n",
            "        \"[151] D. Wang, C. Lei, X. Zhang, H. Wu, S. Zheng, J. Chao, H. Peng, Identification of\",\n",
            "        \"depression with a semi-supervised GCN based on EEG data, in: 2021 IEEE Inter-\",\n",
            "        \"national Conference on Bioinformatics and Biomedicine, BIBM, IEEE, Houston,\",\n",
            "        \"TX, USA, 2021, pp. 2338\\u20132345, http://dx.doi.org/10.1109/BIBM52615.2021.\",\n",
            "        \"9669572.\",\n",
            "        \"[152] A. Demir, T. Koike-Akino, Y. Wang, M. Haruna, D. Erdogmus, EEG-GNN:\",\n",
            "        \"Graph Neural Networks for classification of electroencephalogram (EEG) signals,\",\n",
            "        \"in: 2021 43rd Annual International Conference of the IEEE Engineering in\",\n",
            "        \"Medicine & Biology Society, EMBC, IEEE, Mexico, 2021, pp. 1061\\u20131067, http:\",\n",
            "        \"//dx.doi.org/10.1109/EMBC46164.2021.9630194.\",\n",
            "        \"[153] A. Demir, T. Koike-Akino, Y. Wang, D. Erdogmus, EEG-GAT: Graph Attention\",\n",
            "        \"Networks for classification of electroencephalogram (EEG) signals, in: 2022 44th\",\n",
            "        \"Annual International Conference of the IEEE Engineering in Medicine & Biology\",\n",
            "        \"Society, EMBC, IEEE, Glasgow, Scotland, United Kingdom, 2022, pp. 30\\u201335,\",\n",
            "        \"http://dx.doi.org/10.1109/EMBC48229.2022.9871984.\",\n",
            "        \"[154] Z. Lin, T. Qiu, P. Liu, L. Zhang, S. Zhang, Z. Mu, Fatigue driving recognition\",\n",
            "        \"based on deep learning and graph neural network, Biomed. Signal Process.\",\n",
            "        \"Control 68 (2021) 102598.\",\n",
            "        \"[155] W. Zhou, Y. Liu, Q. Yuan, X. Li, Epileptic seizure detection using lacunarity and\",\n",
            "        \"Bayesian linear discriminant analysis in intracranial EEG, IEEE Trans. Biomed.\",\n",
            "        \"Eng. 60 (12) (2013) 3375\\u20133381.\",\n",
            "        \"[156] S. Taran, V. Bajaj, Motor imagery tasks-based EEG signals classification using\",\n",
            "        \"tunable-Q wavelet transform, Neural Comput. Appl. 31 (2019) 6925\\u20136932.\",\n",
            "        \"[157] L. Quitadamo, F. Cavrini, L. Sbernini, F. Riillo, L. Bianchi, S. Seri, G. Saggio,\",\n",
            "        \"Support vector machines to detect physiological patterns for EEG and EMG-\",\n",
            "        \"based human\\u2013computer interaction: a review, J. Neural Eng. 14 (1) (2017)\",\n",
            "        \"011001.\",\n",
            "        \"[158] M. Wang, S. Abdelfattah, N. Moustafa, J. Hu, Deep gaussian mixture-hidden\",\n",
            "        \"markov model for classification of EEG signals, IEEE Trans. Emerg. Top.\",\n",
            "        \"Comput. Intell. 2 (4) (2018) 278\\u2013287.\",\n",
            "        \"[159] M. Higger, F. Quivira, M. Akcakaya, M. Moghadamfalahi, H. Nezamfar, M.\",\n",
            "        \"Cetin, D. Erdogmus, Recursive Bayesian coding for BCIs, IEEE Trans. Neural\",\n",
            "        \"Syst. Rehabil. Eng. 25 (6) (2016) 704\\u2013714.\",\n",
            "        \"[160] C. Flores, C. Fonseca, D. Achanccaray, J. Andreu-Perez, Performance evaluation\",\n",
            "        \"of a P300 brain-computer interface using a kernel extreme learning machine\",\n",
            "        \"classifier, in: 2018 IEEE International Conference on Systems, Man, and\",\n",
            "        \"Cybernetics, SMC, IEEE, 2018, pp. 3715\\u20133719.\",\n",
            "        \"[161] N. Padfield, K. Camilleri, T. Camilleri, S. Fabri, M. Bugeja, A comprehensive\",\n",
            "        \"review of endogenous EEG-based BCIs for dynamic device control, Sensors 22\",\n",
            "        \"(15) (2022) 5802.\",\n",
            "        \"[162] K. Tanaka, K. Matsunaga, H.O. Wang, Electroencephalogram-based control of\",\n",
            "        \"an electric wheelchair, IEEE Trans. Robot. 21 (4) (2005) 762\\u2013766.\",\n",
            "        \"[163] J. Long, Y. Li, H. Wang, T. Yu, J. Pan, F. Li, A hybrid brain computer interface\",\n",
            "        \"to control the direction and speed of a simulated or real wheelchair, IEEE Trans.\",\n",
            "        \"Neural Syst. Rehabil. Eng. 20 (5) (2012) 720\\u2013729.\",\n",
            "        \"[164] Y. Yu, Z. Zhou, Y. Liu, J. Jiang, E. Yin, N. Zhang, Z. Wang, Y. Liu, X. Wu,\",\n",
            "        \"D. Hu, Self-paced operation of a wheelchair based on a hybrid brain-computer\",\n",
            "        \"interface combining motor imagery and P300 potential, IEEE Trans. Neural Syst.\",\n",
            "        \"Rehabil. Eng. 25 (12) (2017) 2516\\u20132526.\",\n",
            "        \"[165] F. Duan, D. Lin, W. Li, Z. Zhang, Design of a multimodal EEG-based hybrid BCI\",\n",
            "        \"system with visual servo module, IEEE Trans. Auton. Ment. Dev. 7 (4) (2015)\",\n",
            "        \"332\\u2013341.\",\n",
            "        \"[166] X. Deng, Z.L. Yu, C. Lin, Z. Gu, Y. Li, A Bayesian shared control approach\",\n",
            "        \"for wheelchair robot with brain machine interface, IEEE Trans. Neural Syst.\",\n",
            "        \"Rehabil. Eng. 28 (1) (2019) 328\\u2013338.\",\n",
            "        \"[167] I. Batzianoulis, F. Iwane, S. Wei, C.G.P.R. Correia, R. Chavarriaga, J.d.R. Mill\\u00e1n,\",\n",
            "        \"A. Billard, Customizing skills for assistive robotic manipulators, an inverse\",\n",
            "        \"reinforcement learning approach with error-related potentials, Commun. Biol.\",\n",
            "        \"4 (1) (2021) 1406.\",\n",
            "        \"[168] X. Mao, W. Li, C. Lei, J. Jin, F. Duan, S. Chen, A brain\\u2013robot interaction system\",\n",
            "        \"by fusing human and machine intelligence, IEEE Trans. Neural Syst. Rehabil.\",\n",
            "        \"Eng. 27 (3) (2019) 533\\u2013542.\",\n",
            "        \"[169] D. Zhi, X. Du, J. Zhao, Z. Wu, W. Li, Brain-robot interaction system based\",\n",
            "        \"on portable brain signal collector, J. Electron. Meas. Instrum. 30 (5) (2016)\",\n",
            "        \"694\\u2013701.\",\n",
            "        \"[170] C. Lin, X. Deng, Z.L. Yu, Z. Gu, A SSVEP-based BCI for controlling a 4-DOF\",\n",
            "        \"robotic manipulator, in: 2019 IEEE International Conference on Systems, Man\",\n",
            "        \"and Cybernetics, SMC, IEEE, 2019, pp. 2174\\u20132179.\",\n",
            "        \"[171] S. Sheng, P. Song, L. Xie, Z. Luo, W. Chang, S. Jiang, H. Yu, C. Zhu, J.T.C. Tan,\",\n",
            "        \"F. Duan, Design of an SSVEP-based BCI system with visual servo module for a\",\n",
            "        \"service robot to execute multiple tasks, in: 2017 IEEE International Conference\",\n",
            "        \"on Robotics and Automation, ICRA, IEEE, 2017, pp. 2267\\u20132272.\",\n",
            "        \"[172] N. Waytowich, A. Henderson, D. Krusienski, D. Cox, Robot application of a\",\n",
            "        \"brain computer interface to staubli tx40 robots-early stages, in: 2010 World\",\n",
            "        \"Automation Congress, IEEE, 2010, pp. 1\\u20136.\",\n",
            "        \"[173] S. Bhattacharyya, S. Shimoda, M. Hayashibe, A synergetic brain-machine inter-\",\n",
            "        \"facing paradigm for multi-DOF robot control, IEEE Trans. Syst. Man Cybern. A\",\n",
            "        \"46 (7) (2016) 957\\u2013968.\",\n",
            "        \"[174] Z. Li, J. Li, S. Zhao, Y. Yuan, Y. Kang, C.P. Chen, Adaptive neural control of\",\n",
            "        \"a kinematically redundant exoskeleton robot using brain\\u2013machine interfaces,\",\n",
            "        \"IEEE Trans. Neural Netw. Learn. Syst. 30 (12) (2018) 3558\\u20133571.\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"25\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"[175] C.I. Penaloza, M. Alimardani, S. Nishio, Android feedback-based training\",\n",
            "        \"modulates sensorimotor rhythms during motor imagery, IEEE Trans. Neural\",\n",
            "        \"Syst. Rehabil. Eng. 26 (3) (2018) 666\\u2013674.\",\n",
            "        \"[176] R. Sorbello, S. Tramonte, M.E. Giardina, V. La Bella, R. Spataro, B. Allison,\",\n",
            "        \"C. Guger, A. Chella, A human\\u2013humanoid interaction through the use of BCI\",\n",
            "        \"for locked-in ALS patients using neuro-biological feedback fusion, IEEE Trans.\",\n",
            "        \"Neural Syst. Rehabil. Eng. 26 (2) (2017) 487\\u2013497.\",\n",
            "        \"[177] H. Kolkhorst, M. Tangermann, W. Burgard, Guess what I attend: Interface-free\",\n",
            "        \"object selection using brain signals, in: 2018 IEEE/RSJ International Conference\",\n",
            "        \"on Intelligent Robots and Systems, IROS, IEEE, 2018, pp. 7111\\u20137116.\",\n",
            "        \"[178] L. Tonin, F.C. Bauer, J.d.R. Mill\\u00e1n, The role of the control framework for\",\n",
            "        \"continuous teleoperation of a brain\\u2013machine interface-driven mobile robot,\",\n",
            "        \"IEEE Trans. Robot. 36 (1) (2019) 78\\u201391.\",\n",
            "        \"[179] H. Li, L. Bi, H. Shi, Modeling of human operator behavior for brain-actuated\",\n",
            "        \"mobile robots steering, IEEE Trans. Neural Syst. Rehabil. Eng. 28 (9) (2020)\",\n",
            "        \"2063\\u20132072.\",\n",
            "        \"[180] S. Dasgupta, M. Fanton, J. Pham, M. Willard, H. Nezamfar, B. Shafai, D.\",\n",
            "        \"Erdogmus, Brain controlled robotic platform using steady state visual evoked\",\n",
            "        \"potentials acquired by EEG, in: 2010 Conference Record of the Forty Fourth\",\n",
            "        \"Asilomar Conference on Signals, Systems and Computers, IEEE, 2010, pp.\",\n",
            "        \"1371\\u20131374.\",\n",
            "        \"[181] J.R. Mill\\u00e1n, F. Renkens, J. Mourino, W. Gerstner, Noninvasive brain-actuated\",\n",
            "        \"control of a mobile robot by human EEG, IEEE Trans. Biomed. Eng. 51 (6)\",\n",
            "        \"(2004) 1026\\u20131033.\",\n",
            "        \"[182] A.R. Satti, D. Coyle, G. Prasad, Self-paced brain-controlled wheelchair method-\",\n",
            "        \"ology with shared and automated assistive control, in: 2011 IEEE Symposium\",\n",
            "        \"on Computational Intelligence, Cognitive Algorithms, Mind, and Brain, CCMB,\",\n",
            "        \"IEEE, 2011, pp. 1\\u20138.\",\n",
            "        \"[183] L. Bi, X.-A. Fan, Y. Liu, EEG-based brain-controlled mobile robots: a survey,\",\n",
            "        \"IEEE Trans. Hum.-Mach. Syst. 43 (2) (2013) 161\\u2013176.\",\n",
            "        \"[184] Z. Zhang, Y. Huang, S. Chen, J. Qu, X. Pan, T. Yu, Y. Li, An intention-driven\",\n",
            "        \"semi-autonomous intelligent robotic system for drinking, Front. Neurorobotics\",\n",
            "        \"11 (2017) 48.\",\n",
            "        \"[185] L. Schiatti, J. Tessadori, N. Deshpande, G. Barresi, L.C. King, L.S. Mattos, Human\",\n",
            "        \"in the loop of robot learning: eeg-based reward signal for target identification\",\n",
            "        \"and reaching task, in: 2018 IEEE International Conference on Robotics and\",\n",
            "        \"Automation, ICRA, IEEE, 2018, pp. 4473\\u20134480.\",\n",
            "        \"[186] J. Zhang, B. Wang, C. Zhang, Y. Xiao, M.Y. Wang, An EEG/EMG/EOG-based\",\n",
            "        \"multimodal human-machine interface to real-time control of a soft robot hand,\",\n",
            "        \"Front. Neurorobotics 13 (2019) 7.\",\n",
            "        \"[187] C.J. Bell, P. Shenoy, R. Chalodhorn, R.P. Rao, Control of a humanoid robot by\",\n",
            "        \"a noninvasive brain\\u2013computer interface in humans, J. Neural Eng. 5 (2) (2008)\",\n",
            "        \"214.\",\n",
            "        \"[188] E. Beretta, E. De Momi, F. Rodriguez y Baena, G. Ferrigno, Adaptive hands-on\",\n",
            "        \"control for reaching and targeting tasks in surgery, Int. J. Adv. Robot. Syst. 12\",\n",
            "        \"(5) (2015) 50.\",\n",
            "        \"[189] C. Faria, C. Vale, M. Rito, W. Erlhagen, E. Bicho, A simple control approach\",\n",
            "        \"for stereotactic neurosurgery using a robotic manipulator, in: CONTROLO 2016:\",\n",
            "        \"Proceedings of the 12th Portuguese Conference on Automatic Control, Springer,\",\n",
            "        \"2017, pp. 397\\u2013408.\",\n",
            "        \"[190] L. Wu, M. Zhang, J. Cui, S. Wu, K. Shu, T. Zhao, Nursing cooperation of remote\",\n",
            "        \"medical robot assisted stereotactic biopsy of brain tissue, Chin. J. Nurs. 2 (2018)\",\n",
            "        \"43\\u201344.\",\n",
            "        \"[191] G. Beraldo, S. Tortora, E. Menegatti, Towards a brain-robot interface for chil-\",\n",
            "        \"dren, in: 2019 IEEE International Conference on Systems, Man and Cybernetics,\",\n",
            "        \"SMC, IEEE, 2019, pp. 2799\\u20132805.\",\n",
            "        \"[192] Y. He, D. Eguren, J.M. Azor\\u00edn, R.G. Grossman, T.P. Luu, J.L. Contreras-Vidal,\",\n",
            "        \"Brain\\u2013machine interfaces for controlling lower-limb powered robotic systems,\",\n",
            "        \"J. Neural Eng. 15 (2) (2018) 021004.\",\n",
            "        \"[193] L. Bi, H. Wang, T. Teng, C. Guan, A novel method of emergency situation detec-\",\n",
            "        \"tion for a brain-controlled vehicle by combining EEG signals with surrounding\",\n",
            "        \"information, IEEE Trans. Neural Syst. Rehabil. Eng. 26 (10) (2018) 1926\\u20131934.\",\n",
            "        \"[194] E. Tidoni, M. Abu-Alqumsan, D. Leonardis, C. Kapeller, G. Fusco, C. Guger, C.\",\n",
            "        \"Hinterm\\u00fcller, A. Peer, A. Frisoli, F. Tecchia, et al., Local and remote cooperation\",\n",
            "        \"with virtual and robotic agents: a P300 BCI study in healthy and people living\",\n",
            "        \"with spinal cord injury, IEEE Trans. Neural Syst. Rehabil. Eng. 25 (9) (2016)\",\n",
            "        \"1622\\u20131632.\",\n",
            "        \"[195] C. Penaloza, D. Hernandez-Carmona, S. Nishio, Towards intelligent brain-\",\n",
            "        \"controlled body augmentation robotic limbs, in: 2018 IEEE International\",\n",
            "        \"Conference\",\n",
            "        \"on\",\n",
            "        \"Systems,\",\n",
            "        \"Man,\",\n",
            "        \"and\",\n",
            "        \"Cybernetics,\",\n",
            "        \"SMC,\",\n",
            "        \"IEEE,\",\n",
            "        \"2018,\",\n",
            "        \"pp.\",\n",
            "        \"1011\\u20131015.\",\n",
            "        \"[196] G. Beraldo, M. Antonello, A. Cimolato, E. Menegatti, L. Tonin, Brain-computer\",\n",
            "        \"interface meets ROS: a robotic approach to mentally drive telepresence robots,\",\n",
            "        \"in: 2018 IEEE International Conference on Robotics and Automation, ICRA,\",\n",
            "        \"IEEE, 2018, pp. 4459\\u20134464.\",\n",
            "        \"[197] L. Tonin, G. Beraldo, S. Tortora, L. Tagliapietra, J.d.R. Mill\\u00e1n, E. Menegatti,\",\n",
            "        \"ROS-Neuro: A common middleware for BMI and robotics. the acquisition and\",\n",
            "        \"recorder packages, in: 2019 IEEE International Conference on Systems, Man\",\n",
            "        \"and Cybernetics, SMC, IEEE, 2019, pp. 2767\\u20132772.\",\n",
            "        \"[198] B. Xu, S. Peng, A. Song, R. Yang, L. Pan, Robot-aided upper-limb rehabilitation\",\n",
            "        \"based on motor imagery EEG, Int. J. Adv. Robot. Syst. 8 (4) (2011) 40.\",\n",
            "        \"[199] M. Steinisch, M.G. Tana, S. Comani, A post-stroke rehabilitation system inte-\",\n",
            "        \"grating robotics, VR and high-resolution EEG imaging, IEEE Trans. Neural Syst.\",\n",
            "        \"Rehabil. Eng. 21 (5) (2013) 849\\u2013859.\",\n",
            "        \"[200] K.K. Ang, K.S.G. Chua, K.S. Phua, C. Wang, Z.Y. Chin, C.W.K. Kuah, W. Low,\",\n",
            "        \"C. Guan, A randomized controlled trial of EEG-based motor imagery brain-\",\n",
            "        \"computer interface robotic rehabilitation for stroke, Clin. EEG Neurosci. 46 (4)\",\n",
            "        \"(2015) 310\\u2013320.\",\n",
            "        \"[201] G. Yu, J. Wang, W. Chen, J. Zhang, EEG-based brain-controlled lower extremity\",\n",
            "        \"exoskeleton rehabilitation robot, in: 2017 IEEE International Conference on\",\n",
            "        \"Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics,\",\n",
            "        \"Automation and Mechatronics, RAM, IEEE, 2017, pp. 763\\u2013767.\",\n",
            "        \"[202] A. Sarasola-Sanz, N. Irastorza-Landa, E. L\\u00f3pez-Larraz, C. Bibi\\u00e1n, F. Helmhold, D.\",\n",
            "        \"Broetz, N. Birbaumer, A. Ramos-Murguialday, A hybrid brain-machine interface\",\n",
            "        \"based on EEG and EMG activity for the motor rehabilitation of stroke patients,\",\n",
            "        \"in: 2017 International Conference on Rehabilitation Robotics, ICORR, IEEE,\",\n",
            "        \"2017, pp. 895\\u2013900.\",\n",
            "        \"[203] M. Sarac, E. Koyas, A. Erdogan, M. Cetin, V. Patoglu, Brain computer interface\",\n",
            "        \"based robotic rehabilitation with online modification of task speed, in: 2013\",\n",
            "        \"IEEE 13th International Conference on Rehabilitation Robotics, ICORR, IEEE,\",\n",
            "        \"2013, pp. 1\\u20137.\",\n",
            "        \"[204] F. Arrichiello, P. Di Lillo, D. Di Vito, G. Antonelli, S. Chiaverini, Assistive robot\",\n",
            "        \"operated via P300-based brain computer interface, in: 2017 IEEE International\",\n",
            "        \"Conference on Robotics and Automation, ICRA, IEEE, 2017, pp. 6032\\u20136037.\",\n",
            "        \"[205] R. Mane, E. Chew, K.S. Phua, K.K. Ang, N. Robinson, A. Vinod, C. Guan, Prog-\",\n",
            "        \"nostic and monitory EEG-biomarkers for BCI upper-limb stroke rehabilitation,\",\n",
            "        \"IEEE Trans. Neural Syst. Rehabil. Eng. 27 (8) (2019) 1654\\u20131664.\",\n",
            "        \"[206] J. Meng, S. Zhang, A. Bekyo, J. Olsoe, B. Baxter, B. He, Noninvasive electroen-\",\n",
            "        \"cephalogram based control of a robotic arm for reach and grasp tasks, Sci. Rep.\",\n",
            "        \"6 (1) (2016) 38565.\",\n",
            "        \"[207] J.R. Wolpaw, D.J. McFarland, Control of a two-dimensional movement signal\",\n",
            "        \"by a noninvasive brain-computer interface in humans, Proc. Natl. Acad. Sci.\",\n",
            "        \"101 (51) (2004) 17849\\u201317854.\",\n",
            "        \"[208] X. Chen, O. Bai, Towards multi-dimensional robotic control via noninvasive\",\n",
            "        \"brain-computer interface, in: 2009 ICME International Conference on Complex\",\n",
            "        \"Medical Engineering, IEEE, 2009, pp. 1\\u20135.\",\n",
            "        \"[209] L. Cao, G. Li, Y. Xu, H. Zhang, X. Shu, D. Zhang, A brain-actuated robotic arm\",\n",
            "        \"system using non-invasive hybrid brain\\u2013computer interface and shared control\",\n",
            "        \"strategy, J. Neural Eng. 18 (4) (2021) 046045.\",\n",
            "        \"[210] D.J. McFarland, W.A. Sarnacki, J.R. Wolpaw, Electroencephalographic (EEG)\",\n",
            "        \"control of three-dimensional movement, J. Neural Eng. 7 (3) (2010) 036007.\",\n",
            "        \"[211] D. Bandara, J. Arata, K. Kiguchi, A noninvasive brain\\u2013computer interface\",\n",
            "        \"approach for predicting motion intention of activities of daily living tasks\",\n",
            "        \"for an upper-limb wearable robot, Int. J. Adv. Robot. Syst. 15 (2) (2018)\",\n",
            "        \"1729881418767310.\",\n",
            "        \"[212] Y. Xu, H. Zhang, L. Cao, X. Shu, D. Zhang, A shared control strategy\",\n",
            "        \"for reach and grasp of multiple objects using robot vision and noninvasive\",\n",
            "        \"brain\\u2013computer interface, IEEE Trans. Autom. Sci. Eng. 19 (1) (2020) 360\\u2013372.\",\n",
            "        \"[213] J.M. Carmena, M.A. Lebedev, R.E. Crist, J.E. O\\u2019Doherty, D.M. Santucci, D.F.\",\n",
            "        \"Dimitrov, P.G. Patil, C.S. Henriquez, M.A.L. Nicolelis, Learning to control a\",\n",
            "        \"brain\\u2013machine interface for reaching and grasping by primates, PLoS Biol. 1\",\n",
            "        \"(2) (2003) e42.\",\n",
            "        \"[214] M. Barsotti, D. Leonardis, C. Loconsole, M. Solazzi, E. Sotgiu, C. Procopio,\",\n",
            "        \"C. Chisari, M. Bergamasco, A. Frisoli, A full upper limb robotic exoskeleton\",\n",
            "        \"for reaching and grasping rehabilitation triggered by MI-BCI, in: 2015 IEEE\",\n",
            "        \"International Conference on Rehabilitation Robotics, ICORR, IEEE, 2015, pp.\",\n",
            "        \"49\\u201354.\",\n",
            "        \"[215] B.S. Baxter, A. Decker, B. He, Noninvasive control of a robotic arm in mul-\",\n",
            "        \"tiple dimensions using scalp electroencephalogram, in: 2013 6th International\",\n",
            "        \"IEEE/EMBS Conference on Neural Engineering, NER, IEEE, 2013, pp. 45\\u201347.\",\n",
            "        \"[216] Y. Liu, M. Habibnezhad, H. Jebelli, Brainwave-driven human-robot collabora-\",\n",
            "        \"tion in construction, Autom. Constr. 124 (2021) 103556.\",\n",
            "        \"[217] S.Y. Gordleeva, S.A. Lobov, N.A. Grigorev, A.O. Savosenkov, M.O. Shamshin,\",\n",
            "        \"M.V. Lukoyanov, M.A. Khoruzhko, V.B. Kazantsev, Real-time EEG\\u2013EMG human\\u2013\",\n",
            "        \"machine interface-based control system for a lower-limb exoskeleton, IEEE\",\n",
            "        \"Access 8 (2020) 84070\\u201384081.\",\n",
            "        \"[218] C. Wang, X. Wu, Z. Wang, Y. Ma, Implementation of a brain-computer interface\",\n",
            "        \"on a lower-limb exoskeleton, IEEE Access 6 (2018) 38524\\u201338534.\",\n",
            "        \"[219] P. Vinoj, S. Jacob, V.G. Menon, S. Rajesh, M.R. Khosravi, Brain-controlled\",\n",
            "        \"adaptive lower limb exoskeleton for rehabilitation of post-stroke paralyzed, IEEE\",\n",
            "        \"Access 7 (2019) 132628\\u2013132648.\",\n",
            "        \"[220] Y. Liu, W. Su, Z. Li, G. Shi, X. Chu, Y. Kang, W. Shang, Motor-imagery-based\",\n",
            "        \"teleoperation of a dual-arm robot performing manipulation tasks, IEEE Trans.\",\n",
            "        \"Cogn. Dev. Syst. 11 (3) (2018) 414\\u2013424.\",\n",
            "        \"[221] L. Randazzo, I. Iturrate, S. Perdikis, J.d.R. Mill\\u00e1n, Mano: A wearable hand\",\n",
            "        \"exoskeleton for activities of daily living and neurorehabilitation, IEEE Robot.\",\n",
            "        \"Autom. Lett. 3 (1) (2017) 500\\u2013507.\",\n",
            "        \"[222] S.R. Soekadar, M. Witkowski, N. Vitiello, N. Birbaumer, An EEG/EOG-based hy-\",\n",
            "        \"brid brain-neural computer interaction (BNCI) system to control an exoskeleton\",\n",
            "        \"for the paralyzed hand, Biomed. Eng./Biomed. Tech. 60 (3) (2015) 199\\u2013205.\",\n",
            "        \"Robotics and Computer-Integrated Manufacturing 85 (2024) 102610\",\n",
            "        \"26\",\n",
            "        \"S. Liu et al.\",\n",
            "        \"[223] Y. Liu, M. Habibnezhad, H. Jebelli, Brain-computer interface for hands-free\",\n",
            "        \"teleoperation of construction robots, Autom. Constr. 123 (2021) 103523.\",\n",
            "        \"[224] A.F. Salazar-Gomez, J. DelPreto, S. Gil, F.H. Guenther, D. Rus, Correcting robot\",\n",
            "        \"mistakes in real time using EEG signals, in: 2017 IEEE International Conference\",\n",
            "        \"on Robotics and Automation, ICRA, IEEE, 2017, pp. 6570\\u20136577.\",\n",
            "        \"[225] W. Dai, Y. Liu, H. Lu, Z. Zhou, Z. Zhen, Shared control based on a brain-\",\n",
            "        \"computer interface for human-multirobot cooperation, IEEE Robot. Autom. Lett.\",\n",
            "        \"6 (3) (2021) 6123\\u20136130.\",\n",
            "        \"[226] Z. Ji, Q. Liu, W. Xu, B. Yao, J. Liu, Z. Zhou, A closed-loop brain-computer inter-\",\n",
            "        \"face with augmented reality feedback for industrial human-robot collaboration,\",\n",
            "        \"Int. J. Adv. Manuf. Technol. (2021) 1\\u201316.\",\n",
            "        \"[227] Y. Dmytriyev, A.M.A. Zaki, M. Carnevale, F. Insero, H. Giberti, Brain computer\",\n",
            "        \"interface for human-cobot interaction in industrial applications, in: 2021\",\n",
            "        \"3rd International Congress on Human-Computer Interaction, Optimization and\",\n",
            "        \"Robotic Applications, HORA, IEEE, 2021, pp. 1\\u20136.\",\n",
            "        \"[228] Y. Li, T. Kesavadas, Brain computer interface robotic co-workers: defective\",\n",
            "        \"part picking system, in: International Manufacturing Science and Engineering\",\n",
            "        \"Conference, Vol. 51371, American Society of Mechanical Engineers, 2018,\",\n",
            "        \"V003T02A044.\",\n",
            "        \"[229] Y. Li, T. Kesavadas, Welding robotic co-worker using brain computer interface,\",\n",
            "        \"in: ASME International Mechanical Engineering Congress and Exposition, Vol.\",\n",
            "        \"52019, American Society of Mechanical Engineers, 2018, V002T02A097.\",\n",
            "        \"[230] A. Buerkle, W. Eaton, N. Lohse, T. Bamber, P. Ferreira, EEG based arm move-\",\n",
            "        \"ment intention recognition towards enhanced safety in symbiotic Human-Robot\",\n",
            "        \"Collaboration, Robot. Comput.-Integr. Manuf. 70 (2021) 102137.\",\n",
            "        \"[231] L. Wang, A futuristic perspective on human-centric assembly, J. Manuf. Syst.\",\n",
            "        \"62 (2022) 199\\u2013201.\",\n",
            "        \"[232] P. Arpaia, L. Duraccio, N. Moccaldi, S. Rossi, Wearable brain\\u2013computer interface\",\n",
            "        \"instrumentation for robot-based rehabilitation by augmented reality, IEEE\",\n",
            "        \"Trans. Instrum. Meas. 69 (9) (2020) 6362\\u20136371.\",\n",
            "        \"[233] H. Si-Mohammed, J. Petit, C. Jeunet, F. Argelaguet, F. Spindler, A. Evain, N.\",\n",
            "        \"Roussel, G. Casiez, A. L\\u00e9cuyer, Towards BCI-based interfaces for augmented\",\n",
            "        \"reality: feasibility, design and evaluation, IEEE Trans. Vis. Comput. Graphics\",\n",
            "        \"26 (3) (2018) 1608\\u20131621.\",\n",
            "        \"[234] K. Servick, Computers Turn Neural Signals into Speech, American Association\",\n",
            "        \"for the Advancement of Science, 2019.\",\n",
            "        \"[235] J. Jin, B.Z. Allison, X. Wang, C. Neuper, A combined brain\\u2013computer inter-\",\n",
            "        \"face based on P300 potentials and motion-onset visual evoked potentials, J.\",\n",
            "        \"Neurosci. Methods 205 (2) (2012) 265\\u2013276.\",\n",
            "        \"[236] A. Coin, M. Mulder, V. Dubljevi\\u0107, Ethical aspects of BCI technology: what is\",\n",
            "        \"the state of the art? Philosophies 5 (4) (2020) 31.\"\n",
            "    ],\n",
            "    \"List_items\": [\n",
            "        \"Table 1\",\n",
            "        \"Table 2\",\n",
            "        \"Table 3\",\n",
            "        \"Table 4\",\n",
            "        \"Table A.1\"\n",
            "    ]\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}