{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undiscoverable\n"
     ]
    }
   ],
   "source": [
    "def word(word: str) -> str:\n",
    "    \"\"\"Adds prefix \"un\" to word.\"\"\"\n",
    "    return \"un\" + word\n",
    "\n",
    "print(word(\"discoverable\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This ample string.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_by_index(word: str, start: int, stop: int) -> str:\n",
    "    \"\"\"Removes characters by index.\"\"\"\n",
    "    if len(word) > stop :\n",
    "        word = word[0: start:] + word[stop + 1::]\n",
    "    return word\n",
    "\n",
    "sample_string = \"This is a sample string.\"\n",
    "\n",
    "# This example removes charactes from index 5 to 10\n",
    "remove_by_index(sample_string,5,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 HP: Philosophy 101\n",
      "20 HP: Advanced Poetry Using Artificial Calculus\n",
      "20 HP: Pseudo Cyber Security Is NOT Instant Dropshipping\n",
      "40 HP: Advanced Rhethorics And 18th Century UX-Design\n",
      "10 HP: Poetry 101\n",
      "40 HP: Developing Cyber Security And Enviromental UX-Design\n",
      "60 HP: Writing better Success Without Artificial Python\n",
      "20 HP: Theoretical Algebra In Artificial Psychology\n",
      "70 HP: Introduction to Biology Using Modern Health Care\n",
      "50 HP: Social Impact of Philosophy Using 18th Century Archery\n",
      "40 HP: Introduction to Biology In Enviromental Science\n",
      "0 HP: Advanced Biology With Enviromental Ray Tracing\n",
      "20 HP: Developing Success Before The History of Methodology\n",
      "90 HP: Swedish Rhethorics Using The Future of Health Care\n",
      "20 HP: Developing Cyber Security Before Artificial Methodology\n",
      "30 HP: Introduction to Cyber Security With The History of UX-Design\n",
      "\n",
      "Total HP:\n",
      "550\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# Numpy array because why not\n",
    "number_of_courses = np.arange(16)\n",
    "\n",
    "# Lists to store randomised course names and points\n",
    "points_li=[]\n",
    "course_li=[]\n",
    "\n",
    "# Generates random int not lower than 1\n",
    "def get_rand(i):\n",
    "    return rnd.randint(1,i)\n",
    "\n",
    "# Generating random points\n",
    "for i in range(len(number_of_courses)):\n",
    "    q = round(get_rand(4*25), -1)\n",
    "    points_li.append(q)\n",
    "\n",
    "# Course randomiser constructor\n",
    "prefix = [\"Advanced\", \"Introduction to\", \"Object-oriented\", \"Theoretical\", \"Social Impact of\", \"Pseudo\", \"Swedish\", \"Writing better\", \"Developing\"]\n",
    "infix = [\"Algebra\", \"Biology\", \"Philosophy\", \"Programming\", \"Success\", \"Cyber Security\", \"Rhethorics\", \"Poetry\"]\n",
    "preposition = [\"101\", \"In\", \"With\", \"Before\", \"And\", \"Using\", \"Without\", \"Is NOT\"]\n",
    "adverb = [\"The History of\", \"Roman\", \"Instant\", \"Modern\", \"18th Century\", \"Artificial\", \"Machine Learning\", \"Enviromental\", \"The Future of\"]\n",
    "suffix = [\"Calculus\", \"Python\", \"Dropshipping\", \"C#\", \"Java\", \"Ray Tracing\", \"Psychology\", \"Music Theory\", \"Set Theory\", \"UX-Design\", \"Health Care\", \"Leadership\", \"Archery\", \"Methodology\", \"Linguistics\", \"Science\"]\n",
    "\n",
    "for i in range (len(number_of_courses)):\n",
    "\n",
    "    # Randomise two first words\n",
    "    pref = prefix[rnd.randint(0,len(prefix)-1)]\n",
    "    infx = infix[rnd.randint(0,len(infix)-1)]\n",
    "\n",
    "    # Randomise third word, if word is \"101\" stop, else, continue generation\n",
    "    rand_prep = rnd.randint(0,len(preposition)-1)\n",
    "    prep = preposition[rand_prep]\n",
    "\n",
    "    if rand_prep == 0:\n",
    "        name =f\"{infx} {prep}\"\n",
    "    else:\n",
    "        adv = adverb[rnd.randint(0,len(adverb)-1)]\n",
    "        suf = suffix[rnd.randint(0,len(suffix)-1)]\n",
    "        name = f\"{pref} {infx} {prep} {adv} {suf}\" \n",
    "\n",
    "    course_li.append(name)\n",
    "\n",
    "# Dictionary comprehension to convert lists to dictionary\n",
    "curriculum = {course_li[i]: points_li[i] for i in range(len(course_li))}\n",
    "  \n",
    "# Printing dictionary\n",
    "for key, value in curriculum.items():\n",
    "    print(f\"{value} HP: {key}\")\n",
    "\n",
    "values = curriculum.values()\n",
    "print(f\"\\nTotal HP:\\n{sum(values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en :: enclose :: enjoy :: enlighten'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_word_group(vocab_word: list) -> str:\n",
    "    \"\"\"Function to make wordgroups from list, where first index in list is prefix.\"\"\"\n",
    "    result = vocab_word[0]\n",
    "    for i in range(len(vocab_word)):\n",
    "        if i > 0:\n",
    "            result += \" :: \" + vocab_word[0] + vocab_word [i]\n",
    "    return result\n",
    "\n",
    "vocab_words = [\"en\", \"close\", \"joy\", \"lighten\"]\n",
    "make_word_group(vocab_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'compulsive'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_suffix_ness(word: str) -> str:\n",
    "    \"\"\"Removes suffix from english words ending in \"iness\" or \"ness\".\"\"\"\n",
    "    if word[-5] == \"i\":\n",
    "        return word.replace(\"iness\", \"y\")\n",
    "    else:\n",
    "        return word.replace(\"ness\", \"\")\n",
    "\n",
    "remove_suffix_ness(\"compulsiveness\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'darken'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def adjective_to_verb(sentence: str, index: int) -> str:\n",
    "    word_list = sentence.split()\n",
    "    return word_list[index].strip(\".\") + \"en\"\n",
    "\n",
    "adjective_to_verb(\"It got dark.\", -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('helvetica-vDNe7t5J')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87963c44df63088d167d5530105c3e3af538607c5bfb8dea2d5d486a9477964e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
