{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "import fitz  # PyMuPDF\n",
    "import camelot\n",
    "\n",
    "def extract_text_from_directory(directory_path):\n",
    "    loader = PyPDFDirectoryLoader(directory_path)\n",
    "    documents = loader.load()\n",
    "    text = [doc.page_content for doc in documents]\n",
    "    return text\n",
    "\n",
    "def extract_images_from_directory(directory_path):\n",
    "    images = []\n",
    "    for pdf_file in os.listdir(directory_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(directory_path, pdf_file)\n",
    "            pdf_document = fitz.open(pdf_path)\n",
    "            for page_num in range(len(pdf_document)):\n",
    "                page = pdf_document.load_page(page_num)\n",
    "                image_list = page.get_images(full=True)\n",
    "                for img_index, img in enumerate(image_list):\n",
    "                    xref = img[0]\n",
    "                    base_image = pdf_document.extract_image(xref)\n",
    "                    image_bytes = base_image[\"image\"]\n",
    "                    images.append((pdf_file, page_num, image_bytes))\n",
    "    return images\n",
    "\n",
    "def extract_tables_from_directory(directory_path):\n",
    "    tables = []\n",
    "    for pdf_file in os.listdir(directory_path):\n",
    "        if pdf_file.endswith(\".pdf\"):\n",
    "            pdf_path = os.path.join(directory_path, pdf_file)\n",
    "            tables.extend(camelot.read_pdf(pdf_path, pages='all'))\n",
    "    return tables\n",
    "\n",
    "def process_directory(directory_path):\n",
    "    text = extract_text_from_directory(directory_path)\n",
    "    images = extract_images_from_directory(directory_path)\n",
    "    tables = extract_tables_from_directory(directory_path)\n",
    "    return text, images, tables\n",
    "\n",
    "# Example usage\n",
    "directory_path = 'data/'\n",
    "text, images, tables = process_directory(directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "def save_text(text, file_path):\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(text, f)\n",
    "\n",
    "def load_text(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "def save_images(images, directory_path):\n",
    "    os.makedirs(directory_path, exist_ok=True)\n",
    "    for i, (pdf_file, page_num, image_bytes) in enumerate(images):\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        # Convert image to RGB mode if it's in CMYK mode\n",
    "        if image.mode == 'CMYK':\n",
    "            image = image.convert('RGB')\n",
    "        image_path = os.path.join(directory_path, f'image_{i}.png')\n",
    "        image.save(image_path)\n",
    "\n",
    "        \n",
    "def load_images(directory_path):\n",
    "    images = []\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        if file_name.endswith('.png'):\n",
    "            image_path = os.path.join(directory_path, file_name)\n",
    "            with open(image_path, 'rb') as f:\n",
    "                images.append(f.read())\n",
    "    return images\n",
    "\n",
    "def save_tables(tables, directory_path):\n",
    "    os.makedirs(directory_path, exist_ok=True)\n",
    "    for i, table in enumerate(tables):\n",
    "        df = table.df\n",
    "        csv_path = os.path.join(directory_path, f'table_{i}.csv')\n",
    "        df.to_csv(csv_path, index=False)\n",
    "\n",
    "def load_tables(directory_path):\n",
    "    tables = []\n",
    "    for file_name in os.listdir(directory_path):\n",
    "        if file_name.endswith('.csv'):\n",
    "            csv_path = os.path.join(directory_path, file_name)\n",
    "            df = pd.read_csv(csv_path)\n",
    "            tables.append(df)\n",
    "    return tables\n",
    "\n",
    "\n",
    "\n",
    "text_file_path = 'extracted_text.json'\n",
    "images_directory_path = 'extracted_images'\n",
    "tables_directory_path = 'extracted_tables'\n",
    "\n",
    "save_text(text, text_file_path)\n",
    "save_images(images, images_directory_path)\n",
    "save_tables(tables, tables_directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data\n",
    "loaded_text = load_text(text_file_path)\n",
    "loaded_images = load_images(images_directory_path)\n",
    "loaded_tables = load_tables(tables_directory_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load SciBERT model and tokenizer\n",
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def generate_sciBERT_embeddings(texts):\n",
    "    inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\", max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "    return embeddings\n",
    "\n",
    "# Example texts\n",
    "texts = [\n",
    "    \"This is a sample text about human anatomy.\",\n",
    "    \"Another text related to biology.\"\n",
    "]\n",
    "\n",
    "# Generate embeddings\n",
    "embeddings = generate_sciBERT_embeddings(texts)\n",
    "\n",
    "# Initialize FAISS index\n",
    "dimension = embeddings.shape[1]  # Embedding dimension\n",
    "index = faiss.IndexFlatL2(dimension)  # L2 distance for similarity search\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save the FAISS index to a file\n",
    "faiss.write_index(index, \"sciBERT_faiss_index.index\")\n",
    "\n",
    "# Save metadata (if needed)\n",
    "metadata = [{\"text\": text, \"id\": i} for i, text in enumerate(texts)]\n",
    "np.save(\"sciBERT_metadata.npy\", metadata)\n",
    "\n",
    "# To load the FAISS index and metadata later\n",
    "index = faiss.read_index(\"sciBERT_faiss_index.index\")\n",
    "metadata = np.load(\"sciBERT_metadata.npy\", allow_pickle=True).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extracted and saved to anatomy_vol_3.txt\n"
     ]
    }
   ],
   "source": [
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Set path to the Tesseract executable if it's not in your PATH\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Directories\n",
    "pdf_path = \"data/anatomy_vol_3.pdf\"\n",
    "text_output_folder = 'output/text/'\n",
    "os.makedirs(text_output_folder, exist_ok=True)\n",
    "pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "\n",
    "# Convert PDF to images\n",
    "images = convert_from_path(pdf_path)\n",
    "\n",
    "# Extract text from each image using OCR\n",
    "text = \"\"\n",
    "for i, image in enumerate(images):\n",
    "    text += pytesseract.image_to_string(image) + \"\\n\"  # Extract text from image and append to text\n",
    "\n",
    "# Save text to file\n",
    "with open(os.path.join(text_output_folder, f\"{pdf_name}.txt\"), 'w', encoding='utf-8') as text_file:\n",
    "    text_file.write(text)\n",
    "\n",
    "print(f\"Text extracted and saved to {pdf_name}.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
