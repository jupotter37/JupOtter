{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e3b3595-6ad0-43c5-b16a-dfc11fd919c4",
   "metadata": {},
   "source": [
    "## PYOPNECL \n",
    "\n",
    "Use it to make run my AMD FirePro W6100 GPU instead of current CPU. \n",
    "\n",
    "#### [Examples](https://github.com/benshope/PyOpenCL-Tutorial/tree/master)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8167cc7d-3d36-40c1-bd3d-f7822d1fcadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyopencl as cl\n",
    "import pyopencl.array as pycl_array  # Import PyOpenCL Array (a Numpy array plus an OpenCL buffer object)\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f39cec43-26f5-46f2-85ad-11b0a7de6be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "OpenCL Platforms and Devices\n"
     ]
    }
   ],
   "source": [
    "print('\\n' + '=' * 60 + '\\nOpenCL Platforms and Devices')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c35568-665f-4684-895c-1704d5d80e17",
   "metadata": {},
   "source": [
    "#### 1. Introspection Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3607afc-5498-49ba-a338-eeaf909c9ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Platform - Name:  Portable Computing Language\n",
      "Platform - Vendor:  The pocl project\n",
      "Platform - Version:  OpenCL 3.0 PoCL 3.1+debian  Linux, None+Asserts, RELOC, SPIR, LLVM 15.0.6, SLEEF, DISTRO, POCL_DEBUG\n",
      "Platform - Profile:  FULL_PROFILE\n",
      "    --------------------------------------------------------\n",
      "    Device - Name:  pthread-haswell-Intel(R) Core(TM) i7-4940MX CPU @ 3.10GHz\n",
      "    Device - Type:  ALL | CPU\n",
      "    Device - Max Clock Speed:  4000 Mhz\n",
      "    Device - Compute Units:  8\n",
      "    Device - Local Memory:  256 KB\n",
      "    Device - Constant Memory:  256 KB\n",
      "    Device - Global Memory: 29 GB\n",
      "    Device - Max Buffer/Image Size: 8192 MB\n",
      "    Device - Max Work Group Size: 4096\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print each platform on this computer\n",
    "for platform in cl.get_platforms():\n",
    "    print('=' * 60)\n",
    "    print('Platform - Name:  ' + platform.name)\n",
    "    print('Platform - Vendor:  ' + platform.vendor)\n",
    "    print('Platform - Version:  ' + platform.version)\n",
    "    print('Platform - Profile:  ' + platform.profile)\n",
    "    # Print each device per-platform\n",
    "    for device in platform.get_devices():\n",
    "        print('    ' + '-' * 56)\n",
    "        print('    Device - Name:  ' + device.name)\n",
    "        print('    Device - Type:  ' + cl.device_type.to_string(device.type))\n",
    "        print('    Device - Max Clock Speed:  {0} Mhz'.format(device.max_clock_frequency))\n",
    "        print('    Device - Compute Units:  {0}'.format(device.max_compute_units))\n",
    "        print('    Device - Local Memory:  {0:.0f} KB'.format(device.local_mem_size/1024.0))\n",
    "        print('    Device - Constant Memory:  {0:.0f} KB'.format(device.max_constant_buffer_size/1024.0))\n",
    "        print('    Device - Global Memory: {0:.0f} GB'.format(device.global_mem_size/1073741824.0))\n",
    "        print('    Device - Max Buffer/Image Size: {0:.0f} MB'.format(device.max_mem_alloc_size/1048576.0))\n",
    "        print('    Device - Max Work Group Size: {0:.0f}'.format(device.max_work_group_size))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0935513-e7f3-4389-990a-b4b0a9c248c6",
   "metadata": {},
   "source": [
    "#### 2. Array Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "211869ea-53d5-4ed2-81c9-71d1cc14085d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [0.6768151  0.4705016  0.29403326 ... 0.3135677  0.22435978 0.30134153]\n",
      "b: [0.7292723  0.36326006 0.74379843 ... 0.20424864 0.8937321  0.20668831]\n",
      "c: [1.4060874 0.8337617 1.0378317 ... 0.5178163 1.1180918 0.5080298]\n"
     ]
    }
   ],
   "source": [
    "context = cl.create_some_context()  # Initialize the Context\n",
    "queue = cl.CommandQueue(context)  # Instantiate a Queue\n",
    "\n",
    "a = pycl_array.to_device(queue, np.random.rand(50000).astype(np.float32))\n",
    "b = pycl_array.to_device(queue, np.random.rand(50000).astype(np.float32))  \n",
    "# Create two random pyopencl arrays\n",
    "c = pycl_array.empty_like(a)  # Create an empty pyopencl destination array\n",
    "\n",
    "program = cl.Program(context, \"\"\"\n",
    "__kernel void sum(__global const float *a, __global const float *b, __global float *c)\n",
    "{\n",
    "  int i = get_global_id(0);\n",
    "  c[i] = a[i] + b[i];\n",
    "}\"\"\").build()  # Create the OpenCL program\n",
    "\n",
    "program.sum(queue, a.shape, None, a.data, b.data, c.data)  # Enqueue the program for execution and store the result in c\n",
    "\n",
    "print(\"a: {}\".format(a))\n",
    "print(\"b: {}\".format(b))\n",
    "print(\"c: {}\".format(c))  \n",
    "# Print all three arrays, to show sum() worked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2794be55-671e-40d3-bd28-dd1dadf64b51",
   "metadata": {},
   "source": [
    "#### Array Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "645cfb55-6ce1-4731-a7e6-4e3cc0c26d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58116364 0.74863946 0.47366244 ... 0.1514267  0.7095471  0.83504415]\n",
      "[0.49211323 0.15861951 0.29594713 ... 0.08172266 0.6146435  0.08802199]\n",
      "[1.3445025e+23 4.5720165e-41 1.3445025e+23 ... 1.6763866e+00 4.7700565e+27\n",
      " 1.6951832e+00]\n"
     ]
    }
   ],
   "source": [
    "platform = cl.get_platforms()[0]  # Select the first platform [0]\n",
    "device = platform.get_devices()[0]  # Select the first device on this platform [0]\n",
    "context = cl.Context([device])  # Create a context with your device\n",
    "queue = cl.CommandQueue(context)  # Create a command queue with your context\n",
    "\n",
    "np_a = np.random.rand(50000).astype(np.float32)  # Create a random np array\n",
    "np_b = np.random.rand(50000).astype(np.float32)  # Create a random np array\n",
    "np_c = np.empty_like(np_a)  # Create an empty destination array\n",
    "\n",
    "cl_a = cl.Buffer(context, cl.mem_flags.COPY_HOST_PTR, hostbuf=np_a)\n",
    "cl_b = cl.Buffer(context, cl.mem_flags.COPY_HOST_PTR, hostbuf=np_b)\n",
    "cl_c = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, np_c.nbytes)\n",
    "# Create three buffers (plans for areas of memory on the device)\n",
    "\n",
    "kernel = \"\"\"__kernel void sum(__global float* a, __global float* b, __global float* c)\n",
    "{\n",
    "    int i = get_global_id(0);\n",
    "    c[i] = a[i] + b[i];\n",
    "}\"\"\"  # Create a kernel (a string containing C-like OpenCL device code)\n",
    "\n",
    "program = cl.Program(context, kernel).build()\n",
    "# Compile the kernel code into an executable OpenCL program\n",
    "\n",
    "program.sum(queue, np_a.shape, None, cl_a, cl_b, cl_c)\n",
    "# Enqueue the program for execution, causing data to be copied to the device\n",
    "#  - queue: the command queue the program will be sent to\n",
    "#  - np_a.shape: a tuple of the arrays' dimensions\n",
    "#  - cl_a, cl_b, cl_c: the memory spaces this program deals with\n",
    "\n",
    "np_arrays = [np_a, np_b, np_c]\n",
    "cl_arrays = [cl_a, cl_b, cl_c]\n",
    "\n",
    "for x in range(3):\n",
    "    cl.enqueue_copy(queue, cl_arrays[x], np_arrays[x])\n",
    "queue.finish()\n",
    "# Copy the data for array c back to the host\n",
    "\n",
    "for x in np_arrays:\n",
    "\tprint(x)\n",
    "# Print all three host arrays, to show sum() worked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d4e68e-65f8-48e7-b520-498ae9f95d99",
   "metadata": {},
   "source": [
    "#### Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6880bf3-31e7-42bf-9aad-fbb0d87f5707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Kernel Time: 1.5422000000000002e-05 s\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pyopencl' has no attribute 'enqueue_read_buffer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m c_gpu  \u001b[38;5;66;03m# Return the sum of the two arrays\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m#cpu_array_sum(a, b)  # Call the function that sums two arrays on the CPU\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m \u001b[43mgpu_array_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Call the function that sums two arrays on the GPU\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 42\u001b[0m, in \u001b[0;36mgpu_array_sum\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU Kernel Time: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(elapsed))  \u001b[38;5;66;03m# Print the time it took to execute the kernel\u001b[39;00m\n\u001b[1;32m     41\u001b[0m c_gpu \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty_like(a)  \u001b[38;5;66;03m# Create an empty array the same size as array a\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m \u001b[43mcl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menqueue_read_buffer\u001b[49m(queue, c_buffer, c_gpu)\u001b[38;5;241m.\u001b[39mwait()  \u001b[38;5;66;03m# Read back the data from GPU memory into array c_gpu\u001b[39;00m\n\u001b[1;32m     43\u001b[0m gpu_end_time \u001b[38;5;241m=\u001b[39m time()  \u001b[38;5;66;03m# Get the GPU end time\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU Time: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m s\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(gpu_end_time \u001b[38;5;241m-\u001b[39m gpu_start_time))  \u001b[38;5;66;03m# Print the time the GPU program took, including both memory copies\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyopencl' has no attribute 'enqueue_read_buffer'"
     ]
    }
   ],
   "source": [
    "# Test the speed of your PyOpenCL program\n",
    "from time import time  # Import time tools\n",
    "\n",
    "import pyopencl as cl  # Import the OpenCL GPU computing API\n",
    "import numpy as np  # Import number tools\n",
    " \n",
    "a = np.random.rand(1000).astype(np.float32)  # Create a random array to add\n",
    "b = np.random.rand(1000).astype(np.float32)  # Create a random array to add\n",
    "\n",
    "def cpu_array_sum(a, b):  # Sum two arrays on the CPU\n",
    "    c_cpu = np.empty_like(a)  # Create the destination array\n",
    "    cpu_start_time = time()  # Get the CPU start time\n",
    "    for i in range(1000):\n",
    "            for j in range(1000):  # 1000 times add each number and store it\n",
    "                    c_cpu[i] = a[i] + b[i]  # This add operation happens 1,000,000 times XXX\n",
    "    cpu_end_time = time()  # Get the CPU end time\n",
    "    print(\"CPU Time: {0} s\".format(cpu_end_time - cpu_start_time))  # Print how long the CPU took\n",
    "    return c_cpu  # Return the sum of the arrays\n",
    "\n",
    "def gpu_array_sum(a, b):\n",
    "    context = cl.create_some_context()  # Initialize the Context\n",
    "    queue = cl.CommandQueue(context, properties=cl.command_queue_properties.PROFILING_ENABLE)  # Instantiate a Queue with profiling (timing) enabled\n",
    "    a_buffer = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=a)\n",
    "    b_buffer = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=b)\n",
    "    c_buffer = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, b.nbytes)  # Create three buffers (plans for areas of memory on the device)\n",
    "    program = cl.Program(context, \"\"\"\n",
    "    __kernel void sum(__global const float *a, __global const float *b, __global float *c)\n",
    "    {\n",
    "        int i = get_global_id(0);\n",
    "        int j;\n",
    "        for(j = 0; j < 1000; j++)\n",
    "        {\n",
    "            c[i] = a[i] + b[i];\n",
    "        }\n",
    "    }\"\"\").build()  # Compile the device program\n",
    "    gpu_start_time = time()  # Get the GPU start time\n",
    "    event = program.sum(queue, a.shape, None, a_buffer, b_buffer, c_buffer)  # Enqueue the GPU sum program XXX\n",
    "    event.wait()  # Wait until the event finishes XXX\n",
    "    elapsed = 1e-9*(event.profile.end - event.profile.start)  # Calculate the time it took to execute the kernel\n",
    "    print(\"GPU Kernel Time: {0} s\".format(elapsed))  # Print the time it took to execute the kernel\n",
    "    c_gpu = np.empty_like(a)  # Create an empty array the same size as array a\n",
    "    cl.enqueue_read_buffer(queue, c_buffer, c_gpu).wait()  # Read back the data from GPU memory into array c_gpu\n",
    "    gpu_end_time = time()  # Get the GPU end time\n",
    "    print(\"GPU Time: {0} s\".format(gpu_end_time - gpu_start_time))  # Print the time the GPU program took, including both memory copies\n",
    "    return c_gpu  # Return the sum of the two arrays\n",
    "\n",
    "cpu_array_sum(a, b)  # Call the function that sums two arrays on the CPU\n",
    "gpu_array_sum(a, b)  # Call the function that sums two arrays on the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c25fc-5ba7-443d-be79-bec1dfdc949c",
   "metadata": {},
   "source": [
    "#### Elementwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8f40a7d-f757-455a-abc7-47f9d7065ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: [-0.98626065  0.14764626  1.2202305  -0.6494197   4.181771    0.89241695\n",
      " -1.0080472  -0.63106495  1.3194379  -2.555591  ]\n",
      "b: [-2.1421616   1.3045945  -0.3321204   1.5764713   1.0893279  -3.354001\n",
      " -1.765326    0.8525419   0.60728836  0.49931896]\n",
      "c: [-3.1284223   1.4522408   0.88811004  0.9270516   5.2710986  -2.461584\n",
      " -2.7733731   0.22147697  1.9267262  -2.056272  ]\n"
     ]
    }
   ],
   "source": [
    "context = cl.create_some_context()  # Initialize the Context\n",
    "queue = cl.CommandQueue(context)  # Instantiate a Queue\n",
    "\n",
    "a = pycl_array.to_device(queue, np.random.randn(10).astype(np.float32))  # Create a random pyopencl array\n",
    "b = pycl_array.to_device(queue, np.random.randn(10).astype(np.float32))  # Create a random pyopencl array\n",
    "c = pycl_array.empty_like(a)  # Create an empty pyopencl destination array\n",
    "\n",
    "sum = cl.elementwise.ElementwiseKernel(context, \"float *a, float *b, float *c\", \"c[i] = a[i] + b[i]\", \"sum\")\n",
    "# Create an elementwise kernel object\n",
    "#  - Arguments: a string formatted as a C argument list\n",
    "#  - Operation: a snippet of C that carries out the desired map operatino\n",
    "#  - Name: the fuction name as which the kernel is compiled\n",
    "\n",
    "sum(a, b, c)  # Call the elementwise kernel\n",
    "\n",
    "print(\"a: {}\".format(a))\n",
    "print(\"b: {}\".format(b))\n",
    "print(\"c: {}\".format(c))\n",
    "# Print all three arrays, to show sum() worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d73aef-e49a-4aaa-9830-0a2cdaa42b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
