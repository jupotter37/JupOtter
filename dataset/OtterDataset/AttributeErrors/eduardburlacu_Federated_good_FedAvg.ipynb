{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Install Dependencies"
   ],
   "metadata": {
    "id": "wkbcPVOBpHCy"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -q flwr[simulation] torch torchvision matplotlib"
   ],
   "metadata": {
    "id": "nvIYJ8mwALnZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from collections import OrderedDict\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR10, MNIST\n",
    "import flwr as fl\n",
    "from flwr.common import Metrics\n"
   ],
   "metadata": {
    "id": "xaVMMsvq_7xb",
    "ExecuteTime": {
     "end_time": "2023-07-10T12:50:40.351320800Z",
     "start_time": "2023-07-10T12:50:40.346316200Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reconstructing neural networks from papers: FedAvg, DFedAvgM, FedProx"
   ],
   "metadata": {
    "id": "PomYZJGWik-T"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5, padding='same') #  32*28*28\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)                  #  32*14*14\n",
    "        self.conv2 = nn.Conv2d(32,64, 5, padding='same') #  64*14*14\n",
    "        self.pool2 = nn.MaxPool2d(2,2)                   #  64*7*7\n",
    "        self.fc1 = nn.Linear(64* 7* 7, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool1(self.conv1(x))\n",
    "        x = self.pool2(self.conv2(x))\n",
    "        x = x.view(-1, 64* 7* 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "  def __init__(self, input_size:int = 28*28*1):\n",
    "    super(MLP, self).__init__()\n",
    "    self.fc1 = nn.Linear(input_size, 200)\n",
    "    self.fc2 = nn.Linear(200,200)\n",
    "    self.fc3 = nn.Linear(200, 10)\n",
    "\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "    x = x.view(-1, 28*28*1)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    x = F.relu(self.fc2(x))\n",
    "    x = F.softmax(self.fc3(x), dim=1)\n",
    "    return x\n",
    "\n",
    "class LSTM1(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM1, self).__init__()\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers   #number of layers\n",
    "        self.input_size = input_size   #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length   #sequence length\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True) #lstm\n",
    "        self.fc_1 =  nn.Linear(hidden_size, 128) #fully connected 1\n",
    "        self.fc = nn.Linear(128, num_classes) #fully connected last layer\n",
    "\n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "        # Propagate input through LSTM\n",
    "        output, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        hn = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        out = F.relu(hn)\n",
    "        out = self.fc_1(out) #first Dense\n",
    "        out = F.relu(out) #relu\n",
    "        out = self.fc(out) #Final Output\n",
    "        return out\n"
   ],
   "metadata": {
    "id": "s-j7W81lNOAI",
    "ExecuteTime": {
     "end_time": "2023-07-10T12:50:42.748074100Z",
     "start_time": "2023-07-10T12:50:42.733070600Z"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check paper dimensionality"
   ],
   "metadata": {
    "id": "JHCTyYSoOA-n"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "net1 = MLP()\n",
    "total_params1 = sum(p.numel() for p in net1.parameters())\n",
    "print(f\"Number of parameters MLP: {total_params1}\")\n",
    "assert total_params1==199210\n",
    "\n",
    "net2 = CNN()\n",
    "total_params2 = sum(p.numel() for p in net2.parameters())\n",
    "print(f\"Number of parameters CNN: {total_params2}\")\n",
    "assert total_params2==1663370"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wga86jrlOAKW",
    "outputId": "130b3f1d-a8a0-406c-cde3-e0c9298f3677",
    "ExecuteTime": {
     "end_time": "2023-07-10T12:50:46.276783400Z",
     "start_time": "2023-07-10T12:50:46.171018900Z"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters MLP: 199210\n",
      "Number of parameters CNN: 1663370\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create DatasetNode object to store dataset and model parameters"
   ],
   "metadata": {
    "id": "N2A0vcG2NcHB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "class DatasetNode():\n",
    "  def __init__(self, dataset:str):\n",
    "    self.name = dataset\n",
    "    if dataset=='CIFAR10':\n",
    "      self.dataset = torchvision.datasets.CIFAR10\n",
    "      self.archs = ['MLP','CNN']\n",
    "      self.input_size = (3, 32, 32)\n",
    "      self.classes = (\n",
    "          \"plane\",\n",
    "          \"car\",\n",
    "          \"bird\",\n",
    "          \"cat\",\n",
    "          \"deer\",\n",
    "          \"dog\",\n",
    "          \"frog\",\n",
    "          \"horse\",\n",
    "          \"ship\",\n",
    "          \"truck\",)\n",
    "\n",
    "    elif dataset=='MNIST':\n",
    "      self.dataset = torchvision.datasets.MNIST\n",
    "      self.archs= ['MLP','CNN']\n",
    "      self.input_size = (1,28, 28)\n",
    "      self.classes = tuple(i for i in range(1,10))\n",
    "\n",
    "    elif dataset=='FEMNIST':\n",
    "      self.dataset = torchvision.datasets.FEMNIST"
   ],
   "metadata": {
    "id": "mamWXdVWAAZ8",
    "ExecuteTime": {
     "end_time": "2023-07-10T12:50:56.403848200Z",
     "start_time": "2023-07-10T12:50:56.396868600Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simulation Input variables"
   ],
   "metadata": {
    "id": "qxXk6rS-suWn"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Federated variables\n",
    "NUM_CLIENTS = 20\n",
    "NUM_ROUNDS = 3\n",
    "CLIENT_FRAC = 1.0\n",
    "MIN_FIT_CLIENTS = 10\n",
    "MIN_EVALUABLE_CLIENTS = 5\n",
    "MIN_AVAILABLE_CLIENTS = 10\n",
    "\n",
    "#Data loading and training variables\n",
    "DATASET = MNIST\n",
    "SHAPE = (1,28,28)\n",
    "SPLIT_FN = random_split # ADD SIGNATURE OF FUNCTION\n",
    "SEED = 42\n",
    "VAL_SPLIT = 0.1\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "\n",
    "#Evaluation variables\n",
    "LOSS_FN = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#Device Variables\n",
    "NUM_GPU = torch.cuda.device_count()\n",
    "if torch.cuda.is_available():\n",
    "  DEVICE = torch.device('cuda')\n",
    "else: DEVICE = torch.device('cpu')\n",
    "print(print(\n",
    "    f\"Training on {NUM_GPU} X {DEVICE} using PyTorch {torch.__version__} and Flower {fl.__version__}\")\n",
    ")\n",
    "\n",
    "# Specify client resources if you need GPU (defaults to 1 CPU and 0 GPU)\n",
    "client_resources = None\n",
    "if DEVICE.type == \"cuda\":\n",
    "    client_resources = {\"num_gpus\": NUM_GPU}"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1atA5Ew5Mv_w",
    "outputId": "fba70cba-4da7-4036-a441-8d6abb6f877b",
    "ExecuteTime": {
     "end_time": "2023-07-10T12:51:51.949446200Z",
     "start_time": "2023-07-10T12:51:51.923419200Z"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 1 X cuda using PyTorch 2.0.1 and Flower 1.4.0\n",
      "None\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Local Training Pipeline"
   ],
   "metadata": {
    "id": "l0HBFlF1pskE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def load_datasets(dataset = DATASET, batch_size = BATCH_SIZE, split_fn = SPLIT_FN, val_split = VAL_SPLIT ,seed:int = SEED):\n",
    "    '''\n",
    "    Given a dataset, batch size, and validation dataset fraction, it returns 3 lists of corresponding DataLoaders for train, validation, test\n",
    "    :param val_split: float\n",
    "    :param seed: int\n",
    "    '''\n",
    "    # Download and transform dataset (train and test)\n",
    "    normalizer=transforms.Normalize([0.5]*SHAPE[0], [0.5]*SHAPE[0])\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "         normalizer,\n",
    "         ]\n",
    "    )\n",
    "    trainset = dataset(\"./dataset\", train=True, download=True, transform=transform)\n",
    "    testset  = dataset(\"./dataset\", train=False,download=True, transform=transform)\n",
    "\n",
    "    # Split training set into partitions to simulate the individual dataset\n",
    "    partition_size = len(trainset) // NUM_CLIENTS\n",
    "    lengths = [partition_size] * NUM_CLIENTS\n",
    "    datasets = split_fn(trainset, lengths, torch.Generator().manual_seed(seed))\n",
    "\n",
    "    # Split each partition into train/val and create DataLoader\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "\n",
    "    for ds in datasets:\n",
    "        len_val = int( len(ds) * val_split )\n",
    "        len_train = len(ds) - len_val\n",
    "        lengths = [len_train, len_val]\n",
    "        ds_train, ds_val = split_fn(ds, lengths, torch.Generator().manual_seed(seed))\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=BATCH_SIZE, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=BATCH_SIZE))\n",
    "    testloader = DataLoader(testset, batch_size=BATCH_SIZE)\n",
    "\n",
    "    return trainloaders, valloaders, testloader\n"
   ],
   "metadata": {
    "id": "Ndx6FcKPpveB",
    "ExecuteTime": {
     "end_time": "2023-07-10T12:52:10.262971700Z",
     "start_time": "2023-07-10T12:52:10.209975Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "trainloaders, valloaders, testloader =load_datasets()"
   ],
   "metadata": {
    "id": "be0Uqj9QrQ8t",
    "ExecuteTime": {
     "end_time": "2023-07-10T12:52:28.335097Z",
     "start_time": "2023-07-10T12:52:12.019767700Z"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.3%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./dataset/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/MNIST/raw/train-images-idx3-ubyte.gz to ./dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "6.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/MNIST/raw/train-labels-idx1-ubyte.gz to ./dataset/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to ./dataset/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./dataset/MNIST/raw\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def train(net, trainloader, epochs: int = EPOCHS, loss_fn = LOSS_FN,verbose=False):\n",
    "    \"\"\"Train the network on the training set.\"\"\"\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "    net.train()\n",
    "    for epoch in range(epochs):\n",
    "        correct, total, epoch_loss = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Metrics\n",
    "            epoch_loss += loss\n",
    "            total += labels.size(0)\n",
    "            correct += (torch.max(outputs.data, 1)[1] == labels).sum().item()\n",
    "        epoch_loss /= len(trainloader.dataset)\n",
    "        epoch_acc = correct / total\n",
    "        if verbose:\n",
    "            print(f\"Epoch {epoch+1}: train loss {epoch_loss}, accuracy {epoch_acc}\")\n"
   ],
   "metadata": {
    "id": "ppAh14uet2Jk",
    "ExecuteTime": {
     "end_time": "2023-07-10T12:53:50.028075900Z",
     "start_time": "2023-07-10T12:53:49.959525700Z"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def test(net, testloader, loss_fn=LOSS_FN):\n",
    "    \"\"\"Evaluate the network on the entire test set.\"\"\"\n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += loss_fn(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    loss /= len(testloader.dataset)\n",
    "    accuracy = correct / total\n",
    "    return loss, accuracy"
   ],
   "metadata": {
    "id": "_TNVwUsvt5LI",
    "ExecuteTime": {
     "end_time": "2023-07-10T12:53:53.307687Z",
     "start_time": "2023-07-10T12:53:53.302628200Z"
    }
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Federated Client"
   ],
   "metadata": {
    "id": "hOiayuT52le_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def get_parameters(net) -> List[np.ndarray]:\n",
    "    return [val.cpu().numpy() for _, val in net.state_dict().items()]\n",
    "\n",
    "def set_parameters(net, parameters: List[np.ndarray]):\n",
    "    params_dict = zip(net.state_dict().keys(), parameters)\n",
    "    state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
    "    net.load_state_dict(state_dict, strict=True)\n",
    "\n",
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, net, trainloader, valloader):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        return get_parameters(self.net)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        train(self.net, self.trainloader, epochs=1)\n",
    "        return get_parameters(self.net), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        set_parameters(self.net, parameters)\n",
    "        loss, accuracy = test(self.net, self.valloader)\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ],
   "metadata": {
    "id": "pCitlB65y5TO",
    "ExecuteTime": {
     "end_time": "2023-07-10T12:53:57.880660Z",
     "start_time": "2023-07-10T12:53:57.837662900Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wcg7lL_miGnU",
    "ExecuteTime": {
     "end_time": "2023-07-10T12:54:00.271288Z",
     "start_time": "2023-07-10T12:54:00.261335700Z"
    }
   },
   "outputs": [],
   "source": [
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
    "    net = MLP().to(DEVICE)  # <-- pass the Model\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    return FlowerClient(net, trainloader, valloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Metrics aggregators"
   ],
   "metadata": {
    "id": "O_6KnYJF5Qc7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    # Multiply accuracy of each client by number of examples used\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "\n",
    "    # Aggregate and return custom metric (weighted average)\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
   ],
   "metadata": {
    "id": "H0Qb1--e3xMY",
    "ExecuteTime": {
     "end_time": "2023-07-10T12:54:13.793082800Z",
     "start_time": "2023-07-10T12:54:13.788084Z"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create FedAvg strategy"
   ],
   "metadata": {
    "id": "WIMnjRpQ69LY"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "strategy = fl.server.strategy.FedAvg(\n",
    "    fraction_fit= CLIENT_FRAC,\n",
    "    fraction_evaluate= CLIENT_FRAC,\n",
    "    min_fit_clients= MIN_FIT_CLIENTS,\n",
    "    min_evaluate_clients=  MIN_EVALUABLE_CLIENTS,\n",
    "    min_available_clients= MIN_AVAILABLE_CLIENTS,\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,  # <-- pass the metric aggregation function\n",
    ")\n"
   ],
   "metadata": {
    "id": "P3DW4xSQ56W9",
    "ExecuteTime": {
     "end_time": "2023-07-10T12:54:50.672862500Z",
     "start_time": "2023-07-10T12:54:50.667863900Z"
    }
   },
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start simulation"
   ],
   "metadata": {
    "id": "MEfGP0Yp7AnV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=NUM_CLIENTS,\n",
    "    config=fl.server.ServerConfig(num_rounds=NUM_ROUNDS),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources,\n",
    ")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4__IMV9C7DnO",
    "outputId": "9abf9e0f-d508-42ee-c5e0-57c50b7d07bc",
    "ExecuteTime": {
     "end_time": "2023-07-10T12:55:00.689651200Z",
     "start_time": "2023-07-10T12:54:53.735811400Z"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2023-07-10 12:56:01,897 | app.py:146 | Starting Flower simulation, config: ServerConfig(num_rounds=3, round_timeout=None)\n",
      "2023-07-10 12:56:04,437\tERROR services.py:1207 -- Failed to start the dashboard , return code 1\n",
      "2023-07-10 12:56:04,439\tERROR services.py:1232 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/ray-logging.html#logging-directory-structure' to find where the log file is.\n",
      "2023-07-10 12:56:04,440\tERROR services.py:1276 -- \n",
      "The last 20 lines of /tmp/ray/session_2023-07-10_12-56-01_927618_3475/logs/dashboard.log (it contains the error message from the dashboard): \n",
      "  File \"/home/eduardburlacu/miniconda3/envs/torch/lib/python3.9/importlib/__init__.py\", line 127, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"<frozen importlib._bootstrap>\", line 1030, in _gcd_import\n",
      "  File \"<frozen importlib._bootstrap>\", line 1007, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 986, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 680, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 850, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"/home/eduardburlacu/miniconda3/envs/torch/lib/python3.9/site-packages/ray/dashboard/modules/log/log_manager.py\", line 8, in <module>\n",
      "    from ray.util.state.common import (\n",
      "  File \"/home/eduardburlacu/miniconda3/envs/torch/lib/python3.9/site-packages/ray/util/state/__init__.py\", line 1, in <module>\n",
      "    from ray.util.state.api import (\n",
      "  File \"/home/eduardburlacu/miniconda3/envs/torch/lib/python3.9/site-packages/ray/util/state/api.py\", line 17, in <module>\n",
      "    from ray.util.state.common import (\n",
      "  File \"/home/eduardburlacu/miniconda3/envs/torch/lib/python3.9/site-packages/ray/util/state/common.py\", line 120, in <module>\n",
      "    @dataclass(init=True)\n",
      "  File \"/home/eduardburlacu/miniconda3/envs/torch/lib/python3.9/site-packages/pydantic/dataclasses.py\", line 139, in dataclass\n",
      "    assert init is False, 'pydantic.dataclasses.dataclass only supports init=False'\n",
      "AssertionError: pydantic.dataclasses.dataclass only supports init=False\n",
      "2023-07-10 12:56:04,593\tINFO worker.py:1636 -- Started a local Ray instance.\n",
      "INFO flwr 2023-07-10 12:56:08,914 | app.py:180 | Flower VCE: Ray initialized with resources: {}\n",
      "INFO flwr 2023-07-10 12:56:08,916 | server.py:86 | Initializing global parameters\n",
      "INFO flwr 2023-07-10 12:56:08,918 | server.py:273 | Requesting initial parameters from one random client\n",
      "\u001B[2m\u001B[33m(raylet)\u001B[0m [2023-07-10 12:56:08,876 E 4125 4172] (raylet) agent_manager.cc:135: The raylet exited immediately because the Ray agent failed. The raylet fate shares with the agent. This can happen because the Ray agent was unexpectedly killed or failed. Agent can fail when\n",
      "\u001B[2m\u001B[33m(raylet)\u001B[0m - The version of `grpcio` doesn't follow Ray's requirement. Agent can segfault with the incorrect `grpcio` version. Check the grpcio version `pip freeze | grep grpcio`.\n",
      "\u001B[2m\u001B[33m(raylet)\u001B[0m - The agent failed to start because of unexpected error or port conflict. Read the log `cat /tmp/ray/session_latest/logs/dashboard_agent.log`. You can find the log file structure here https://docs.ray.io/en/master/ray-observability/ray-logging.html#logging-directory-structure.\n",
      "\u001B[2m\u001B[33m(raylet)\u001B[0m - The agent is killed by the OS (e.g., out of memory).\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pydantic.fields' has no attribute 'ModelField'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mfl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msimulation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart_simulation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_clients\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mNUM_CLIENTS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mserver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mServerConfig\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mNUM_ROUNDS\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient_resources\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient_resources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/flwr/simulation/app.py:197\u001B[0m, in \u001B[0;36mstart_simulation\u001B[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised)\u001B[0m\n\u001B[1;32m    194\u001B[0m     initialized_server\u001B[38;5;241m.\u001B[39mclient_manager()\u001B[38;5;241m.\u001B[39mregister(client\u001B[38;5;241m=\u001B[39mclient_proxy)\n\u001B[1;32m    196\u001B[0m \u001B[38;5;66;03m# Start training\u001B[39;00m\n\u001B[0;32m--> 197\u001B[0m hist \u001B[38;5;241m=\u001B[39m \u001B[43m_fl\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    198\u001B[0m \u001B[43m    \u001B[49m\u001B[43mserver\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitialized_server\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    199\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitialized_config\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    200\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    202\u001B[0m event(EventType\u001B[38;5;241m.\u001B[39mSTART_SIMULATION_LEAVE)\n\u001B[1;32m    204\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m hist\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/flwr/server/app.py:217\u001B[0m, in \u001B[0;36m_fl\u001B[0;34m(server, config)\u001B[0m\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_fl\u001B[39m(\n\u001B[1;32m    213\u001B[0m     server: Server,\n\u001B[1;32m    214\u001B[0m     config: ServerConfig,\n\u001B[1;32m    215\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m History:\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;66;03m# Fit model\u001B[39;00m\n\u001B[0;32m--> 217\u001B[0m     hist \u001B[38;5;241m=\u001B[39m \u001B[43mserver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnum_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_rounds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mround_timeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m     log(INFO, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapp_fit: losses_distributed \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mstr\u001B[39m(hist\u001B[38;5;241m.\u001B[39mlosses_distributed))\n\u001B[1;32m    219\u001B[0m     log(INFO, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapp_fit: metrics_distributed_fit \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28mstr\u001B[39m(hist\u001B[38;5;241m.\u001B[39mmetrics_distributed_fit))\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/flwr/server/server.py:87\u001B[0m, in \u001B[0;36mServer.fit\u001B[0;34m(self, num_rounds, timeout)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;66;03m# Initialize parameters\u001B[39;00m\n\u001B[1;32m     86\u001B[0m log(INFO, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInitializing global parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 87\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparameters \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_initial_parameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m log(INFO, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEvaluating initial parameters\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     89\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstrategy\u001B[38;5;241m.\u001B[39mevaluate(\u001B[38;5;241m0\u001B[39m, parameters\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparameters)\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/flwr/server/server.py:276\u001B[0m, in \u001B[0;36mServer._get_initial_parameters\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    274\u001B[0m random_client \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client_manager\u001B[38;5;241m.\u001B[39msample(\u001B[38;5;241m1\u001B[39m)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    275\u001B[0m ins \u001B[38;5;241m=\u001B[39m GetParametersIns(config\u001B[38;5;241m=\u001B[39m{})\n\u001B[0;32m--> 276\u001B[0m get_parameters_res \u001B[38;5;241m=\u001B[39m \u001B[43mrandom_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_parameters\u001B[49m\u001B[43m(\u001B[49m\u001B[43mins\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mins\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    277\u001B[0m log(INFO, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReceived initial parameters from one random client\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m get_parameters_res\u001B[38;5;241m.\u001B[39mparameters\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/flwr/simulation/ray_transport/ray_client_proxy.py:66\u001B[0m, in \u001B[0;36mRayClientProxy.get_parameters\u001B[0;34m(self, ins, timeout)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_parameters\u001B[39m(\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;28mself\u001B[39m, ins: common\u001B[38;5;241m.\u001B[39mGetParametersIns, timeout: Optional[\u001B[38;5;28mfloat\u001B[39m]\n\u001B[1;32m     64\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m common\u001B[38;5;241m.\u001B[39mGetParametersRes:\n\u001B[1;32m     65\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return the current local model parameters.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 66\u001B[0m     future_paramseters_res \u001B[38;5;241m=\u001B[39m \u001B[43mlaunch_and_get_parameters\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore\u001B[39;49;00m\n\u001B[1;32m     67\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     68\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mremote\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclient_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mins\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     70\u001B[0m         res \u001B[38;5;241m=\u001B[39m ray\u001B[38;5;241m.\u001B[39mget(future_paramseters_res, timeout\u001B[38;5;241m=\u001B[39mtimeout)\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/ray/remote_function.py:230\u001B[0m, in \u001B[0;36mRemoteFunction.options.<locals>.FuncWrapper.remote\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    229\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mremote\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 230\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc_cls\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_remote\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mupdated_options\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/ray/util/tracing/tracing_helper.py:306\u001B[0m, in \u001B[0;36m_tracing_task_invocation.<locals>._invocation_remote_span\u001B[0;34m(self, args, kwargs, *_args, **_kwargs)\u001B[0m\n\u001B[1;32m    304\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    305\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_ray_trace_ctx\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m kwargs\n\u001B[0;32m--> 306\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_ray_trace_ctx\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m kwargs\n\u001B[1;32m    309\u001B[0m tracer \u001B[38;5;241m=\u001B[39m _opentelemetry\u001B[38;5;241m.\u001B[39mtrace\u001B[38;5;241m.\u001B[39mget_tracer(\u001B[38;5;18m__name__\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/ray/remote_function.py:422\u001B[0m, in \u001B[0;36mRemoteFunction._remote\u001B[0;34m(self, args, kwargs, **task_options)\u001B[0m\n\u001B[1;32m    419\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decorator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    420\u001B[0m     invocation \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decorator(invocation)\n\u001B[0;32m--> 422\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43minvocation\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/ray/remote_function.py:391\u001B[0m, in \u001B[0;36mRemoteFunction._remote.<locals>.invocation\u001B[0;34m(args, kwargs)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m worker\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m ray\u001B[38;5;241m.\u001B[39m_private\u001B[38;5;241m.\u001B[39mworker\u001B[38;5;241m.\u001B[39mLOCAL_MODE:\n\u001B[1;32m    388\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[1;32m    389\u001B[0m         \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_cross_language\n\u001B[1;32m    390\u001B[0m     ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCross language remote function cannot be executed locally.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 391\u001B[0m object_refs \u001B[38;5;241m=\u001B[39m \u001B[43mworker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcore_worker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msubmit_task\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    392\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_language\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    393\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_function_descriptor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    394\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlist_args\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    395\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mis\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    396\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_returns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    397\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresources\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    398\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    399\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretry_exceptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    400\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretry_exception_allowlist\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    401\u001B[0m \u001B[43m    \u001B[49m\u001B[43mscheduling_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    402\u001B[0m \u001B[43m    \u001B[49m\u001B[43mworker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdebugger_breakpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    403\u001B[0m \u001B[43m    \u001B[49m\u001B[43mserialized_runtime_env_info\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m{}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    404\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    405\u001B[0m \u001B[38;5;66;03m# Reset worker's debug context from the last \"remote\" command\u001B[39;00m\n\u001B[1;32m    406\u001B[0m \u001B[38;5;66;03m# (which applies only to this .remote call).\u001B[39;00m\n\u001B[1;32m    407\u001B[0m worker\u001B[38;5;241m.\u001B[39mdebugger_breakpoint \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32mpython/ray/_raylet.pyx:2898\u001B[0m, in \u001B[0;36mray._raylet.CoreWorker.submit_task\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpython/ray/_raylet.pyx:2902\u001B[0m, in \u001B[0;36mray._raylet.CoreWorker.submit_task\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpython/ray/_raylet.pyx:671\u001B[0m, in \u001B[0;36mray._raylet.prepare_args_and_increment_put_refs\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpython/ray/_raylet.pyx:662\u001B[0m, in \u001B[0;36mray._raylet.prepare_args_and_increment_put_refs\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpython/ray/_raylet.pyx:708\u001B[0m, in \u001B[0;36mray._raylet.prepare_args_internal\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/ray/_private/worker.py:618\u001B[0m, in \u001B[0;36mWorker.get_serialization_context\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    616\u001B[0m         context_map[job_id] \u001B[38;5;241m=\u001B[39m context_map\u001B[38;5;241m.\u001B[39mpop(JobID\u001B[38;5;241m.\u001B[39mnil())\n\u001B[1;32m    617\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 618\u001B[0m         context_map[job_id] \u001B[38;5;241m=\u001B[39m \u001B[43mserialization\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSerializationContext\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    619\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m context_map[job_id]\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/ray/_private/serialization.py:151\u001B[0m, in \u001B[0;36mSerializationContext.__init__\u001B[0;34m(self, worker)\u001B[0m\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ObjectRefGenerator, (obj\u001B[38;5;241m.\u001B[39m_refs,)\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_register_cloudpickle_reducer(\n\u001B[1;32m    148\u001B[0m     ObjectRefGenerator, object_ref_generator_reducer\n\u001B[1;32m    149\u001B[0m )\n\u001B[0;32m--> 151\u001B[0m \u001B[43mserialization_addons\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/ray/util/serialization_addons.py:58\u001B[0m, in \u001B[0;36mapply\u001B[0;34m(serialization_context)\u001B[0m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;129m@DeveloperAPI\u001B[39m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(serialization_context):\n\u001B[0;32m---> 58\u001B[0m     \u001B[43mregister_pydantic_serializer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mserialization_context\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     59\u001B[0m     register_starlette_serializer(serialization_context)\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sys\u001B[38;5;241m.\u001B[39mplatform \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mwin32\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/miniconda3/envs/torch/lib/python3.9/site-packages/ray/util/serialization_addons.py:21\u001B[0m, in \u001B[0;36mregister_pydantic_serializer\u001B[0;34m(serialization_context)\u001B[0m\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Pydantic's Cython validators are not serializable.\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# https://github.com/cloudpipe/cloudpickle/issues/408\u001B[39;00m\n\u001B[1;32m     20\u001B[0m serialization_context\u001B[38;5;241m.\u001B[39m_register_cloudpickle_serializer(\n\u001B[0;32m---> 21\u001B[0m     \u001B[43mpydantic\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfields\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mModelField\u001B[49m,\n\u001B[1;32m     22\u001B[0m     custom_serializer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m o: {\n\u001B[1;32m     23\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: o\u001B[38;5;241m.\u001B[39mname,\n\u001B[1;32m     24\u001B[0m         \u001B[38;5;66;03m# outer_type_ is the original type for ModelFields,\u001B[39;00m\n\u001B[1;32m     25\u001B[0m         \u001B[38;5;66;03m# while type_ can be updated later with the nested type\u001B[39;00m\n\u001B[1;32m     26\u001B[0m         \u001B[38;5;66;03m# like int for List[int].\u001B[39;00m\n\u001B[1;32m     27\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtype_\u001B[39m\u001B[38;5;124m\"\u001B[39m: o\u001B[38;5;241m.\u001B[39mouter_type_,\n\u001B[1;32m     28\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclass_validators\u001B[39m\u001B[38;5;124m\"\u001B[39m: o\u001B[38;5;241m.\u001B[39mclass_validators,\n\u001B[1;32m     29\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_config\u001B[39m\u001B[38;5;124m\"\u001B[39m: o\u001B[38;5;241m.\u001B[39mmodel_config,\n\u001B[1;32m     30\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdefault\u001B[39m\u001B[38;5;124m\"\u001B[39m: o\u001B[38;5;241m.\u001B[39mdefault,\n\u001B[1;32m     31\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdefault_factory\u001B[39m\u001B[38;5;124m\"\u001B[39m: o\u001B[38;5;241m.\u001B[39mdefault_factory,\n\u001B[1;32m     32\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequired\u001B[39m\u001B[38;5;124m\"\u001B[39m: o\u001B[38;5;241m.\u001B[39mrequired,\n\u001B[1;32m     33\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124malias\u001B[39m\u001B[38;5;124m\"\u001B[39m: o\u001B[38;5;241m.\u001B[39malias,\n\u001B[1;32m     34\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfield_info\u001B[39m\u001B[38;5;124m\"\u001B[39m: o\u001B[38;5;241m.\u001B[39mfield_info,\n\u001B[1;32m     35\u001B[0m     },\n\u001B[1;32m     36\u001B[0m     custom_deserializer\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mlambda\u001B[39;00m kwargs: pydantic\u001B[38;5;241m.\u001B[39mfields\u001B[38;5;241m.\u001B[39mModelField(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs),\n\u001B[1;32m     37\u001B[0m )\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'pydantic.fields' has no attribute 'ModelField'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Replicate Experiments on FedAvg paper"
   ],
   "metadata": {
    "id": "cHKB8hIBh7VA"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Un86-Rhuh_Lw"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
