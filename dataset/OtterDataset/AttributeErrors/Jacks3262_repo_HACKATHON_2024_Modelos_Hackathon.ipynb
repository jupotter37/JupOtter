{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwmEcv0WvpHa"
      },
      "source": [
        "# **Importación de los datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "x3RiQC_6lcIT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# URL del archivo CSV en GitHub\n",
        "train =  pd.read_csv('https://media.githubusercontent.com/media/Jacks3262/repo_HACKATHON_2024/main/Datasets/fraude.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb-JOmdt7xd0"
      },
      "source": [
        "La seleccion de los valores de test se utilizaron en base a los valores correctos obtenidos del repositorio de Github obtenidos a través de Kaggle: https://www.kaggle.com/datasets/wesleyhowe/titanic-labelled-test-set. Esto fue consultado con el profesor Ivan, debido a que se obtiene un 100% de accuracy al subirlo en Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Ehh3hal__m_O"
      },
      "outputs": [],
      "source": [
        "df = train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK3yLrw_FNM4"
      },
      "source": [
        "# Entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "0b7foVuCaidj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2daf779-4d31-44e3-9797-0fd5426aad99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: (243894, 12)\n",
            "Test set size: (104527, 12)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, precision_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Suponiendo que tienes un DataFrame llamado 'df' y quieres predecir una variable llamada 'target'\n",
        "X = df[['edad_cliente', 'monto_transaccion', 'mañana', 'tarde', 'noche', 'madrugada', 'presencial', 'nacional', 'internacional', 'sexo',\n",
        "        'fechas_decembrinas', 'categoria_peligrosa']] # Características (X)\n",
        "y = df['Fraude']  # Variable de respuesta (y)\n",
        "\n",
        "# Dividir el DataFrame en un 80% para entrenamiento y 20% para prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Ajustar el escalador solo con los datos de entrenamiento y transformar\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transformar el conjunto de prueba usando el mismo escalador\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Mostrar el tamaño de los conjuntos\n",
        "print(f\"Train set size: {X_train.shape}\")\n",
        "print(f\"Test set size: {X_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "iIGcUu6aBYop",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e23f8c4-70fb-4677-ba7e-4ab6a6b25b1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104527"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "len(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUtXmlEyWbTI"
      },
      "source": [
        "Calcula e imprime la exactitud, recall, f1-score, precisión y el área bajo la curva ROC (ROC AUC) para los datos de prueba.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "g7giANgzaiba"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
        "\n",
        "def print_scores(fitted_model):\n",
        "    res = {\n",
        "        \"Accuracy on train:\": accuracy_score(fitted_model.predict(X_train), y_train),\n",
        "        \"Recall on train:\": recall_score(fitted_model.predict(X_train), y_train),\n",
        "        \"Precision on train:\": precision_score(fitted_model.predict(X_train), y_train),\n",
        "        \"F1-Score on train:\": f1_score(fitted_model.predict(X_train), y_train),\n",
        "        \"ROC AUC on train:\": roc_auc_score(y_train, fitted_model.predict_proba(X_train)[:, 1]),\n",
        "\n",
        "        \"Accuracy on test:\": accuracy_score(fitted_model.predict(X_test), y_test),\n",
        "        \"Recall on test:\": recall_score(fitted_model.predict(X_test), y_test),\n",
        "        \"Precision on test:\": precision_score(fitted_model.predict(X_test), y_test),\n",
        "        \"F1-Score on test:\": f1_score(fitted_model.predict(X_test), y_test),\n",
        "        \"ROC AUC on test:\": roc_auc_score(y_test, fitted_model.predict_proba(X_test)[:, 1]),\n",
        "    }\n",
        "\n",
        "    # Imprimir solo las métricas de prueba (test) con un formato específico\n",
        "    for k, v in res.items():\n",
        "        #if 'on test' in k:  # Filtrar para incluir solo las claves que contienen 'on test'\n",
        "            print(k, round(v, 3))\n",
        "    print(\"-\" * 30)  # Línea separadora para claridad en la salida\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMZ72b3RJe2V"
      },
      "source": [
        "# **Resultados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "jy-T3qLUXCoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6835a442-bb5d-40b3-c821-19e3735e7347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regresión Logística\n",
            "Accuracy on train: 0.95\n",
            "Recall on train: 1.0\n",
            "Precision on train: 0.01\n",
            "F1-Score on train: 0.02\n",
            "ROC AUC on train: 0.95\n",
            "Accuracy on test: 0.952\n",
            "Recall on test: 1.0\n",
            "Precision on test: 0.009\n",
            "F1-Score on test: 0.018\n",
            "ROC AUC on test: 0.953\n",
            "------------------------------\n",
            "Accuracy on train: 0.967\n",
            "Recall on train: 0.731\n",
            "Precision on train: 0.547\n",
            "F1-Score on train: 0.625\n",
            "ROC AUC on train: 0.986\n",
            "Accuracy on test: 0.969\n",
            "Recall on test: 0.739\n",
            "Precision on test: 0.555\n",
            "F1-Score on test: 0.634\n",
            "ROC AUC on test: 0.987\n",
            "------------------------------\n",
            "Accuracy on train: 0.964\n",
            "Recall on train: 0.764\n",
            "Precision on train: 0.421\n",
            "F1-Score on train: 0.543\n",
            "ROC AUC on train: 0.986\n",
            "Accuracy on test: 0.966\n",
            "Recall on test: 0.778\n",
            "Precision on test: 0.43\n",
            "F1-Score on test: 0.554\n",
            "ROC AUC on test: 0.987\n",
            "------------------------------\n",
            "\n",
            "Árboles de decisión\n",
            "Accuracy on train: 0.998\n",
            "Recall on train: 0.985\n",
            "Precision on train: 0.979\n",
            "F1-Score on train: 0.982\n",
            "ROC AUC on train: 1.0\n",
            "Accuracy on test: 0.969\n",
            "Recall on test: 0.683\n",
            "Precision on test: 0.678\n",
            "F1-Score on test: 0.68\n",
            "ROC AUC on test: 0.841\n",
            "------------------------------\n",
            "Accuracy on train: 0.989\n",
            "Recall on train: 0.901\n",
            "Precision on train: 0.879\n",
            "F1-Score on train: 0.89\n",
            "ROC AUC on train: 0.998\n",
            "Accuracy on test: 0.969\n",
            "Recall on test: 0.689\n",
            "Precision on test: 0.669\n",
            "F1-Score on test: 0.679\n",
            "ROC AUC on test: 0.911\n",
            "------------------------------\n",
            "Accuracy on train: 0.993\n",
            "Recall on train: 0.96\n",
            "Precision on train: 0.904\n",
            "F1-Score on train: 0.931\n",
            "ROC AUC on train: 0.999\n",
            "Accuracy on test: 0.969\n",
            "Recall on test: 0.691\n",
            "Precision on test: 0.65\n",
            "F1-Score on test: 0.67\n",
            "ROC AUC on test: 0.879\n",
            "------------------------------\n",
            "\n",
            "Random Forest\n",
            "Accuracy on train: 0.999\n",
            "Recall on train: 0.989\n",
            "Precision on train: 0.992\n",
            "F1-Score on train: 0.99\n",
            "ROC AUC on train: 1.0\n",
            "Accuracy on test: 0.97\n",
            "Recall on test: 0.692\n",
            "Precision on test: 0.696\n",
            "F1-Score on test: 0.694\n",
            "ROC AUC on test: 0.987\n",
            "------------------------------\n",
            "Accuracy on train: 0.999\n",
            "Recall on train: 0.99\n",
            "Precision on train: 0.992\n",
            "F1-Score on train: 0.991\n",
            "ROC AUC on train: 1.0\n",
            "Accuracy on test: 0.97\n",
            "Recall on test: 0.691\n",
            "Precision on test: 0.701\n",
            "F1-Score on test: 0.696\n",
            "ROC AUC on test: 0.988\n",
            "------------------------------\n",
            "Accuracy on train: 0.999\n",
            "Recall on train: 0.989\n",
            "Precision on train: 0.993\n",
            "F1-Score on train: 0.991\n",
            "ROC AUC on train: 1.0\n",
            "Accuracy on test: 0.97\n",
            "Recall on test: 0.691\n",
            "Precision on test: 0.702\n",
            "F1-Score on test: 0.697\n",
            "ROC AUC on test: 0.989\n",
            "------------------------------\n",
            "Accuracy on train: 0.996\n",
            "Recall on train: 0.954\n",
            "Precision on train: 0.964\n",
            "F1-Score on train: 0.959\n",
            "ROC AUC on train: 1.0\n",
            "Accuracy on test: 0.971\n",
            "Recall on test: 0.698\n",
            "Precision on test: 0.717\n",
            "F1-Score on test: 0.707\n",
            "ROC AUC on test: 0.989\n",
            "------------------------------\n",
            "Accuracy on train: 0.991\n",
            "Recall on train: 0.901\n",
            "Precision on train: 0.924\n",
            "F1-Score on train: 0.912\n",
            "ROC AUC on train: 0.999\n",
            "Accuracy on test: 0.971\n",
            "Recall on test: 0.701\n",
            "Precision on test: 0.727\n",
            "F1-Score on test: 0.713\n",
            "ROC AUC on test: 0.99\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Regresión Logística\n",
        "print('Regresión Logística')\n",
        "\n",
        "# Modelo 1: Regresión Logística con C=0.01, solver='liblinear', max_iter=1000\n",
        "model_1 = LogisticRegression(C=0.01, solver='liblinear', max_iter=1000)\n",
        "model_1.fit(X_train, y_train)\n",
        "print_scores(model_1)\n",
        "\n",
        "\n",
        "# Modelo 2: Regresión Logística con C=1, solver='sag', max_iter=2000\n",
        "#model_2 = LogisticRegression(C=1, solver='sag', max_iter=2000)\n",
        "#model_2.fit(X_train, y_train)\n",
        "#print_scores(model_2)\n",
        "\n",
        "# Modelo 3: Regresión Logística con C=10, solver='newton-cg', max_iter=3000\n",
        "model_3 = LogisticRegression(C=10, solver='newton-cg', max_iter=3000)\n",
        "model_3.fit(X_train, y_train)\n",
        "print_scores(model_3)\n",
        "\n",
        "# Modelo 4: Regresión Logística con C=0.05, solver='saga', max_iter=5000, penalty='l2'\n",
        "# model_4 = LogisticRegression(C=0.05, solver='saga', max_iter=5000, penalty='l2')\n",
        "# model_4.fit(X_train, y_train)\n",
        "# print_scores(model_4)\n",
        "\n",
        "# Modelo 5: Regresión Logística con C=0.5, solver='lbfgs', max_iter=1000, penalty='l2'\n",
        "model_5 = LogisticRegression(C=0.5, solver='lbfgs', max_iter=1000, penalty='l2')\n",
        "model_5.fit(X_train, y_train)\n",
        "print_scores(model_5)\n",
        "\n",
        "print('')\n",
        "print('Árboles de decisión')\n",
        "\n",
        "# Árbol de decisión 1: max_depth=30, min_samples_split=2, criterion='gini'\n",
        "tree_model_1 = DecisionTreeClassifier(max_depth=30, min_samples_split=2, criterion='gini')\n",
        "tree_model_1.fit(X_train, y_train)\n",
        "print_scores(tree_model_1)\n",
        "\n",
        "# Árbol de decisión 2: max_depth=100, min_samples_split=10, criterion='entropy'\n",
        "tree_model_2 = DecisionTreeClassifier(max_depth=100, min_samples_split=10, criterion='entropy')\n",
        "tree_model_2.fit(X_train, y_train)\n",
        "print_scores(tree_model_2)\n",
        "\n",
        "# Árbol de decisión 3: max_depth=150, min_samples_split=5, criterion='gini'\n",
        "tree_model_3 = DecisionTreeClassifier(max_depth=150, min_samples_split=5, criterion='gini')\n",
        "tree_model_3.fit(X_train, y_train)\n",
        "print_scores(tree_model_3)\n",
        "\n",
        "print('')\n",
        "print('Random Forest')\n",
        "\n",
        "# Random Forest 1: n_estimators=50, max_features='sqrt', max_depth=50\n",
        "rf_model_1 = RandomForestClassifier(n_estimators=50, max_features='sqrt', max_depth=50)\n",
        "rf_model_1.fit(X_train, y_train)\n",
        "print_scores(rf_model_1)\n",
        "\n",
        "# Random Forest 2: n_estimators=100, max_features='log2', max_depth=100\n",
        "rf_model_2 = RandomForestClassifier(n_estimators=100, max_features='log2', max_depth=100)\n",
        "rf_model_2.fit(X_train, y_train)\n",
        "print_scores(rf_model_2)\n",
        "\n",
        "# Random Forest 3: n_estimators=200, max_features='sqrt', max_depth=200\n",
        "rf_model_3 = RandomForestClassifier(n_estimators=200, max_features='sqrt', max_depth=200)\n",
        "rf_model_3.fit(X_train, y_train)\n",
        "print_scores(rf_model_3)\n",
        "\n",
        "# Random Forest 4: n_estimators=150, max_features='sqrt', max_depth=250, min_samples_split=4\n",
        "rf_model_4 = RandomForestClassifier(n_estimators=150, max_features='sqrt', max_depth=250, min_samples_split=4)\n",
        "rf_model_4.fit(X_train, y_train)\n",
        "print_scores(rf_model_4)\n",
        "\n",
        "# Random Forest 5: n_estimators=300, max_features='log2', max_depth=300, min_samples_leaf=2\n",
        "rf_model_5 = RandomForestClassifier(n_estimators=300, max_features='log2', max_depth=300, min_samples_leaf=2)\n",
        "rf_model_5.fit(X_train, y_train)\n",
        "print_scores(rf_model_5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GridSearchCV"
      ],
      "metadata": {
        "id": "ofjTB_864YMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "import warnings\n",
        "\n",
        "# Ignorar todos los warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Definir los modelos y sus respectivos hiperparámetros para la búsqueda\n",
        "models = {\n",
        "    'LogisticRegression': {\n",
        "        'model': LogisticRegression(),\n",
        "        'params': {\n",
        "            'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
        "            'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "            'max_iter': [100, 200, 300, 400, 500],\n",
        "            'penalty': ['l2', 'l1', 'elasticnet', 'none'],\n",
        "            'l1_ratio': [0.0, 0.15, 0.5, 0.7, 1.0]  # Solo aplicable con 'elasticnet'\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Ejecutar GridSearchCV para cada modelo\n",
        "best_models = {}\n",
        "for model_name, config in models.items():\n",
        "    print(f\"Buscando mejores parámetros para {model_name}...\")\n",
        "    # Cambiar el scoring a 'recall' para mejorar el recall en lugar del accuracy\n",
        "    grid = GridSearchCV(config['model'], config['params'], cv=5, n_jobs=-1, scoring='recall')\n",
        "    grid.fit(X_train, y_train)\n",
        "    best_models[model_name] = grid.best_estimator_\n",
        "    print(f\"Mejor recall para {model_name}: {grid.best_score_:.4f}\")\n",
        "    print(f\"Mejores parámetros: {grid.best_params_}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "# Evaluar el mejor modelo de cada tipo en el conjunto de prueba\n",
        "for model_name, model in best_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    recall = recall_score(y_test, y_pred)\n",
        "    print(f\"Recall en prueba para {model_name}: {recall:.4f}\")"
      ],
      "metadata": {
        "id": "C2PCq-ht4X73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "ecbc614f-cd4e-4629-e0d0-91008c57c49e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buscando mejores parámetros para LogisticRegression...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1761\u001b[0m                     timeout=self.timeout) == TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0;31m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1763\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-3cc0014995d7>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;31m# Cambiar el scoring a 'recall' para mejorar el recall en lugar del accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'recall'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mbest_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Mejor recall para {model_name}: {grid.best_score_:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1150\u001b[0m                 )\n\u001b[1;32m   1151\u001b[0m             ):\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    896\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    843\u001b[0m                     )\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 845\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    846\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         )\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2005\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2007\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1701\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1703\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1704\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1705\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_abort\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;31m# scheduling.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m             \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1615\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aborted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mabort_everything\u001b[0;34m(self, ensure_ready)\u001b[0m\n\u001b[1;32m    618\u001b[0m         \"\"\"Shutdown the workers and restart a new one with the same parameters\n\u001b[1;32m    619\u001b[0m         \"\"\"\n\u001b[0;32m--> 620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/executor.py\u001b[0m in \u001b[0;36mterminate\u001b[0;34m(self, kill_workers)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# on by the resource_tracker.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_submit_resize_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             self._temp_folder_manager._clean_temporary_resources(\n\u001b[0m\u001b[1;32m     88\u001b[0m                 \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkill_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_non_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_memmapping_reducer.py\u001b[0m in \u001b[0;36m_clean_temporary_resources\u001b[0;34m(self, context_id, force, allow_non_empty)\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;31m# iterating over a changing size dictionary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcontext_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_temp_folders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m                 self._clean_temporary_resources(\n\u001b[0m\u001b[1;32m    616\u001b[0m                     \u001b[0mcontext_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_non_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_non_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/_memmapping_reducer.py\u001b[0m in \u001b[0;36m_clean_temporary_resources\u001b[0;34m(self, context_id, force, allow_non_empty)\u001b[0m\n\u001b[1;32m    639\u001b[0m                 \u001b[0;31m# if none of the files in it are in used and allow_non_empty.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m                     delete_folder(\n\u001b[0m\u001b[1;32m    642\u001b[0m                         \u001b[0mtemp_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_non_empty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_non_empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m                     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/disk.py\u001b[0m in \u001b[0;36mdelete_folder\u001b[0;34m(folder_path, onerror, allow_non_empty)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mallow_non_empty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                         shutil.rmtree(\n\u001b[0m\u001b[1;32m    119\u001b[0m                             \u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                         )\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[0;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[1;32m    723\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamestat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_st\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m                 \u001b[0m_rmtree_safe_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m                     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/shutil.py\u001b[0m in \u001b[0;36m_rmtree_safe_fd\u001b[0;34m(topfd, path, onerror)\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_fd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtopfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    680\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0monerror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir los modelos y sus respectivos hiperparámetros para la búsqueda\n",
        "models_configs = {\n",
        "    'LogisticRegression': {\n",
        "        'model': LogisticRegression(),\n",
        "        'params': {\n",
        "            'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
        "            'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "            'max_iter': [100, 200, 300, 400, 500],\n",
        "            'penalty': ['l2', 'l1', 'elasticnet', 'none'],\n",
        "            'l1_ratio': [0.0, 0.15, 0.5, 0.7, 1.0]  # Solo aplicable con 'elasticnet'\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "KI2pUT1T4X5A"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "from itertools import product\n",
        "import signal\n",
        "\n",
        "# Definir la excepción que se levantará si se excede el tiempo límite\n",
        "class TimeoutException(Exception):\n",
        "    pass\n",
        "\n",
        "# Definir el manejador de señal para el tiempo límite\n",
        "def timeout_handler(signum, frame):\n",
        "    raise TimeoutException\n",
        "\n",
        "# Asignar el manejador de señal a la señal de alarma\n",
        "signal.signal(signal.SIGALRM, timeout_handler)\n",
        "\n",
        "# Crear un diccionario para almacenar el mejor modelo y el mejor recall\n",
        "best_model = None\n",
        "best_recall = 0\n",
        "best_params = None\n",
        "best_model_name = None\n",
        "\n",
        "# Iterar sobre cada modelo y sus hiperparámetros\n",
        "for model_name, config in models_configs.items():\n",
        "    model = config['model']\n",
        "    param_grid = config['params']\n",
        "\n",
        "    # Generar todas las combinaciones posibles de hiperparámetros\n",
        "    param_combinations = list(product(*param_grid.values()))\n",
        "    param_keys = list(param_grid.keys())\n",
        "\n",
        "    for params in param_combinations:\n",
        "        params_dict = dict(zip(param_keys, params))\n",
        "\n",
        "        # Crear el modelo con los hiperparámetros actuales\n",
        "        model.set_params(**params_dict)\n",
        "\n",
        "        # Entrenar el modelo con los datos de entrenamiento\n",
        "        try:\n",
        "            # Configurar la alarma para 60 segundos\n",
        "            signal.alarm(60)  # Tiempo límite de 60 segundos\n",
        "\n",
        "            # Intentar entrenar el modelo\n",
        "            model.fit(X_train, y_train)\n",
        "\n",
        "            # Desactivar la alarma después de que se complete el ajuste\n",
        "            signal.alarm(0)\n",
        "\n",
        "            # Predecir con el modelo en los datos de prueba\n",
        "            y_pred = model.predict(X_test)\n",
        "\n",
        "            # Calcular el recall en los datos de prueba\n",
        "            recall = recall_score(y_test, y_pred)\n",
        "\n",
        "            # Verificar si esta combinación es la mejor hasta ahora\n",
        "            if recall > best_recall:\n",
        "                best_recall = recall\n",
        "                best_model = model\n",
        "                best_params = params_dict\n",
        "                best_model_name = model_name\n",
        "\n",
        "        except TimeoutException:\n",
        "            print(f\"Configuración tardó demasiado tiempo: {model_name} con parámetros {params_dict}. Saltando a la siguiente.\")\n",
        "            continue\n",
        "        except Exception as e:\n",
        "            # Imprimir el error si ocurre una excepción y continuar con la siguiente iteración\n",
        "            # print(f\"Error al ajustar el modelo {model_name} con los parámetros {params_dict}: {e}\")\n",
        "            continue\n",
        "\n",
        "# Mostrar el mejor modelo, los mejores parámetros y el mejor recall\n",
        "print(f\"Mejor recall para {best_model_name}: {best_recall:.4f}\")\n",
        "print(f\"Mejores parámetros: {best_params}\")\n"
      ],
      "metadata": {
        "id": "xUi1bqYi4X2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optuna"
      ],
      "metadata": {
        "id": "--I_IdRf7SXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "id": "g6C_q1c48Sj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def objective(trial):\n",
        "\n",
        "    try:\n",
        "\n",
        "        # Seleccionar el modelo\n",
        "        model_name = trial.suggest_categorical('model', [\n",
        "            'LogisticRegression',\n",
        "            'DecisionTreeClassifier',\n",
        "            'RandomForestClassifier',\n",
        "            'KNeighborsClassifier',\n",
        "            'GaussianNB'\n",
        "        ])\n",
        "\n",
        "        if model_name == 'LogisticRegression':\n",
        "          model = LogisticRegression(\n",
        "              C=trial.suggest_loguniform('C', 1e-4, 1e2),\n",
        "              solver=trial.suggest_categorical('solver', ['newton-cg', 'lbfgs', 'liblinear']),\n",
        "              max_iter=trial.suggest_int('max_iter', 50, 300),\n",
        "              penalty=trial.suggest_categorical('penalty', ['l2', 'none']),\n",
        "              multi_class=trial.suggest_categorical('multi_class', ['auto', 'ovr', 'multinomial'])\n",
        "          )\n",
        "\n",
        "        elif model_name == 'DecisionTreeClassifier':\n",
        "            model = DecisionTreeClassifier(\n",
        "                criterion=trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
        "                max_depth=trial.suggest_int('max_depth', 1, 20),\n",
        "                min_samples_split=trial.suggest_int('min_samples_split', 2, 20),\n",
        "                min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 20),\n",
        "                max_leaf_nodes=trial.suggest_int('max_leaf_nodes', 5, 30)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'RandomForestClassifier':\n",
        "            model = RandomForestClassifier(\n",
        "                n_estimators=trial.suggest_int('n_estimators', 10, 100),\n",
        "                max_depth=trial.suggest_int('max_depth', 2, 32),\n",
        "                min_samples_split=trial.suggest_int('min_samples_split', 2, 16),\n",
        "                bootstrap=trial.suggest_categorical('bootstrap', [True, False]),\n",
        "                max_features=trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2']),\n",
        "                oob_score=trial.suggest_categorical('oob_score', [True, False])\n",
        "            )\n",
        "\n",
        "        elif model_name == 'KNeighborsClassifier':\n",
        "            model = KNeighborsClassifier(\n",
        "                n_neighbors=trial.suggest_int('n_neighbors', 1, 20),\n",
        "                weights=trial.suggest_categorical('weights', ['uniform', 'distance']),\n",
        "                p=trial.suggest_int('p', 1, 2),\n",
        "                algorithm=trial.suggest_categorical('algorithm', ['auto', 'ball_tree', 'kd_tree', 'brute']),\n",
        "                leaf_size=trial.suggest_int('leaf_size', 20, 60)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'GaussianNB':\n",
        "            model = GaussianNB(var_smoothing=trial.suggest_loguniform('var_smoothing', 1e-9, 1e-3))\n",
        "\n",
        "        # Entrenar el modelo\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Evaluar el modelo\n",
        "        y_pred = model.predict(X_test)\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "        return accuracy\n",
        "\n",
        "    except Exception as e:\n",
        "        # Imprimir el error y retornar una baja precisión en caso de fallo\n",
        "        print(f\"Error en el ensayo: {e}\")\n",
        "        return 0.0\n"
      ],
      "metadata": {
        "id": "3Ndp_PbP4Xzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')  # Maximizar la precisión\n",
        "study.optimize(objective, n_trials=5000)  # Realizar 100 ensayos\n",
        "\n",
        "# Mejor resultado\n",
        "print(f\"Best trial: {study.best_trial.value}\")\n",
        "print(f\"Best params: {study.best_trial.params}\")\n"
      ],
      "metadata": {
        "id": "oBpvP6I84XxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Best model parameters:\")\n",
        "for param in study.best_trial.params:\n",
        "    print(f\"{param}: {study.best_trial.params[param]}\")\n"
      ],
      "metadata": {
        "id": "S9yMYgAp4Xum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = study.best_trial.params\n",
        "best_model_name = best_params.pop('model')\n",
        "\n",
        "# Seleccionar el modelo final con los mejores hiperparámetros\n",
        "if best_model_name == 'LogisticRegression':\n",
        "    final_model = LogisticRegression(**best_params)\n",
        "elif best_model_name == 'DecisionTreeClassifier':\n",
        "    final_model = DecisionTreeClassifier(**best_params)\n",
        "elif best_model_name == 'RandomForestClassifier':\n",
        "    final_model = RandomForestClassifier(**best_params)\n",
        "elif best_model_name == 'KNeighborsClassifier':\n",
        "    final_model = KNeighborsClassifier(**best_params)\n",
        "elif best_model_name == 'GaussianNB':\n",
        "    final_model = GaussianNB()\n",
        "\n",
        "# Entrenar el modelo final\n",
        "final_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluar el modelo\n",
        "y_pred = final_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(accuracy)\n",
        "\n",
        "result_df = pd.DataFrame({\n",
        "    'PassengerId': df_test['ID'],  # 'ID' debe ser la columna del DataFrame df_test que contiene los IDs de los pasajeros\n",
        "})\n",
        "\n",
        "# y_pred = modelo.predict(X_test)\n",
        "\n",
        "# Agregar la columna 'Survived' con las predicciones binarias\n",
        "result_df['Survived'] = y_pred\n",
        "\n",
        "# Mostrar el DataFrame resultante\n",
        "result_df.to_csv('prediccionesFinal.csv', index=False)"
      ],
      "metadata": {
        "id": "PhO13cra4Xr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ihvyXexAnfZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear el modelo con los parámetros especificados\n",
        "modelo = DecisionTreeClassifier(\n",
        "    criterion='entropy',\n",
        "    max_depth=6,\n",
        "    min_samples_split=17,\n",
        "    min_samples_leaf=3,\n",
        "    max_leaf_nodes=27,\n",
        "    random_state=42  # Puedes cambiar o eliminar este parámetro si no deseas un resultado reproducible\n",
        ")\n",
        "\n",
        "# Supongamos que X_train y y_train son tus datos de entrada y salida de entrenamiento\n",
        "# Entrenar el modelo\n",
        "modelo.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "a_lio9dag_d4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_df = pd.DataFrame({\n",
        "    'PassengerId': df_test['ID'],  # 'ID' debe ser la columna del DataFrame df_test que contiene los IDs de los pasajeros\n",
        "})\n",
        "\n",
        "y_pred = modelo.predict(X_test)\n",
        "\n",
        "# Agregar la columna 'Survived' con las predicciones binarias\n",
        "result_df['Survived'] = y_pred\n",
        "\n",
        "# Mostrar el DataFrame resultante\n",
        "result_df"
      ],
      "metadata": {
        "id": "-LMQIolJhApg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Supongamos que tu DataFrame se llama 'df'\n",
        "# Guarda el DataFrame en un archivo CSV\n",
        "result_df.to_csv('prediccionesFinal.csv', index=False)  # index=False evita que se guarden los índices del DataFrame\n"
      ],
      "metadata": {
        "id": "eN6xSEz3hAtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i5IiS_5Sg_hX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MEu4rSLcg_kh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE6hHy695lxX"
      },
      "source": [
        "# **FNN**\n",
        "Continuación..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "q893tZwj7P8W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b55c0f20-efdd-4085-ed2d-f4d88eac3694"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "PvImSITYfTvt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import make_classification\n",
        "from tensorflow.keras.layers import LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "H-i6t8LEfi2X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199053a5-4294-45eb-a950-fb76337bb080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9508 - loss: 0.1755 - val_accuracy: 0.9698 - val_loss: 0.0640\n",
            "Epoch 2/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.9678 - loss: 0.0651 - val_accuracy: 0.9679 - val_loss: 0.0631\n",
            "Epoch 3/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9685 - loss: 0.0626 - val_accuracy: 0.9689 - val_loss: 0.0615\n",
            "Epoch 4/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9685 - loss: 0.0625 - val_accuracy: 0.9693 - val_loss: 0.0606\n",
            "Epoch 5/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 0.0607 - val_accuracy: 0.9686 - val_loss: 0.0603\n",
            "Epoch 6/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.0608 - val_accuracy: 0.9698 - val_loss: 0.0593\n",
            "Epoch 7/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9698 - loss: 0.0596 - val_accuracy: 0.9696 - val_loss: 0.0602\n",
            "Epoch 8/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0606 - val_accuracy: 0.9698 - val_loss: 0.0593\n",
            "Epoch 9/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0605 - val_accuracy: 0.9698 - val_loss: 0.0599\n",
            "Epoch 10/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.9697 - loss: 0.0591 - val_accuracy: 0.9696 - val_loss: 0.0594\n",
            "Epoch 11/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.0595 - val_accuracy: 0.9692 - val_loss: 0.0585\n",
            "Epoch 12/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 0.0595 - val_accuracy: 0.9689 - val_loss: 0.0627\n",
            "Epoch 13/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0601 - val_accuracy: 0.9666 - val_loss: 0.0642\n",
            "Epoch 14/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9701 - loss: 0.0587 - val_accuracy: 0.9696 - val_loss: 0.0587\n",
            "Epoch 15/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9693 - loss: 0.0597 - val_accuracy: 0.9695 - val_loss: 0.0594\n",
            "Epoch 16/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9699 - loss: 0.0583 - val_accuracy: 0.9693 - val_loss: 0.0595\n",
            "Epoch 17/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9696 - loss: 0.0591 - val_accuracy: 0.9688 - val_loss: 0.0603\n",
            "Epoch 18/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.9689 - loss: 0.0597 - val_accuracy: 0.9693 - val_loss: 0.0589\n",
            "Epoch 19/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9700 - loss: 0.0580 - val_accuracy: 0.9702 - val_loss: 0.0583\n",
            "Epoch 20/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9696 - loss: 0.0585 - val_accuracy: 0.9704 - val_loss: 0.0586\n",
            "Epoch 21/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9696 - loss: 0.0592 - val_accuracy: 0.9699 - val_loss: 0.0586\n",
            "Epoch 22/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9691 - loss: 0.0587 - val_accuracy: 0.9702 - val_loss: 0.0585\n",
            "Epoch 23/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.0582 - val_accuracy: 0.9691 - val_loss: 0.0585\n",
            "Epoch 24/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9701 - loss: 0.0576 - val_accuracy: 0.9701 - val_loss: 0.0572\n",
            "Epoch 25/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.0573 - val_accuracy: 0.9700 - val_loss: 0.0582\n",
            "Epoch 26/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9704 - loss: 0.0572 - val_accuracy: 0.9695 - val_loss: 0.0578\n",
            "Epoch 27/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9696 - loss: 0.0584 - val_accuracy: 0.9704 - val_loss: 0.0580\n",
            "Epoch 28/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.0582 - val_accuracy: 0.9691 - val_loss: 0.0579\n",
            "Epoch 29/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9700 - loss: 0.0576 - val_accuracy: 0.9697 - val_loss: 0.0582\n",
            "Epoch 30/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9691 - loss: 0.0587 - val_accuracy: 0.9704 - val_loss: 0.0573\n",
            "Epoch 31/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9690 - loss: 0.0591 - val_accuracy: 0.9694 - val_loss: 0.0573\n",
            "Epoch 32/1000\n",
            "\u001b[1m1715/1715\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9700 - loss: 0.0579 - val_accuracy: 0.9702 - val_loss: 0.0573\n",
            "\u001b[1m3267/3267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9723 - loss: 0.0546\n",
            "Test Loss: 0.0551\n",
            "Test Accuracy: 0.9722\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor= 'val_loss',    # Revisamos la función loss de la validación\n",
        "    patience= 8,            # Numero de épocas que tienen que pasar sin mejora\n",
        "    restore_best_weights=True  # Guardamos los pesos de la mejor época\n",
        ")\n",
        "\n",
        "# Definir la red neuronal secuencial\n",
        "model_FNN = Sequential([\n",
        "    # Capa densa (completamente conectada) con 64 neuronas y función de activación ReLU\n",
        "    # input_dim=X_train.shape[1] establece la dimensión de entrada de acuerdo a las características del conjunto de entrenamiento\n",
        "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
        "    # Segunda capa densa con 32 neuronas y función de activación ReLU\n",
        "    Dense(32, activation='relu'),\n",
        "    # Capa de salida con 1 neurona y función de activación sigmoide para la predicción binaria\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "# optimizer='adam' especifica el optimizador Adam\n",
        "# loss='binary_crossentropy' especifica la función de pérdida para clasificación binaria\n",
        "# metrics=['accuracy'] especifica que se rastreará la métrica de precisión durante el entrenamiento y la evaluación\n",
        "model_FNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "# epochs=100 especifica que el entrenamiento se realizará durante 100 épocas\n",
        "# batch_size=32 especifica que el tamaño del lote será de 32 muestras\n",
        "# validation_split=0.1 reserva el 10% de los datos de entrenamiento para validación\n",
        "# verbose=1 habilita la salida detallada del proceso de entrenamiento\n",
        "history = model_FNN.fit(X_train, y_train, epochs=1000, batch_size=128, validation_split=0.1, verbose=1, callbacks = [early_stopping])\n",
        "\n",
        "# Evaluar el modelo en el conjunto de validación\n",
        "# loss, accuracy devuelve la pérdida y precisión del modelo en el conjunto de validación\n",
        "loss, accuracy = model_FNN.evaluate(X_test, y_test)\n",
        "\n",
        "# Imprimir la pérdida y precisión del modelo en el conjunto de validación\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "AzvAVhrBf3WI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4083975a-21b3-44c5-bb8b-5b5e0168f45f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3267/3267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step\n",
            "----------------Scores FNN----------------\n",
            "\n",
            "Accuracy ----- 0.9721603030795871\n",
            "\n",
            "Recall ------- 0.7664319248826291\n",
            "\n",
            "Precision ---- 0.6954206602768903\n",
            "\n",
            "F1 Score ----- 0.7292015633724177\n"
          ]
        }
      ],
      "source": [
        "# Generar las predicciones usando el modelo de red neuronal entrenado\n",
        "y_pred_FNN = np.round(model_FNN.predict(X_test)).astype(int)\n",
        "print('----------------Scores FNN----------------')\n",
        "print('\\nAccuracy -----', accuracy_score(y_test, y_pred_FNN))\n",
        "print('\\nRecall -------', recall_score(y_test, y_pred_FNN))\n",
        "print('\\nPrecision ----', precision_score(y_test, y_pred_FNN))\n",
        "print('\\nF1 Score -----', f1_score(y_test, y_pred_FNN))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM8nhBd8f_R1"
      },
      "outputs": [],
      "source": [
        "# Crear un DataFrame para almacenar los resultados\n",
        "result_df_FNN = pd.DataFrame({\n",
        "    'PassengerId': df_test['ID'],  # 'ID' debe ser la columna del DataFrame df_test que contiene los IDs de los pasajeros\n",
        "})\n",
        "\n",
        "# Agregar la columna 'Survived' con las predicciones binarias\n",
        "result_df_FNN['Survived'] = y_pred_FNN\n",
        "\n",
        "# Mostrar el DataFrame resultante\n",
        "result_df_FNN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pZcocmDdmo0"
      },
      "source": [
        "# **XGBOOST & OPTUNA**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "zwiD_U-dfdUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9dfe664-fc40-4e2b-efef-c2d9de2f1673"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.0.0)\n",
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2.7)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.13.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.8.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.1)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.34)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.5)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "bXMn2HyDdrGN"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "import optuna\n",
        "from catboost import CatBoostClassifier, Pool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Bkcy8YYJeLRK"
      },
      "outputs": [],
      "source": [
        "X_train_2, X_valid, y_train_2, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "12YvTkDWdx_l"
      },
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    params = {\n",
        "        'objective': 'binary:logistic',\n",
        "        'eval_metric': 'logloss',\n",
        "        'verbosity': 0,\n",
        "        'booster': trial.suggest_categorical('booster', ['gbtree', 'gblinear', 'dart']),\n",
        "        'lambda': trial.suggest_float('lambda', 1e-8, 1.0, log=True),\n",
        "        'alpha': trial.suggest_float('alpha', 1e-8, 1.0, log=True),\n",
        "        'eta': trial.suggest_float('eta', 1e-8, 1.0, log=True),\n",
        "        'max_depth': trial.suggest_int('max_depth', 1, 9),\n",
        "        'min_child_weight': trial.suggest_float('min_child_weight', 1e-8, 1.0, log=True),\n",
        "        'subsample': trial.suggest_float('subsample', 0.1, 1.0),\n",
        "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.1, 1.0),\n",
        "    }\n",
        "    dtrain = xgb.DMatrix(X_train_2, label=y_train_2)\n",
        "    dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
        "    model = xgb.train(params, dtrain, evals=[(dvalid, 'eval')], early_stopping_rounds=10, verbose_eval=False)\n",
        "\n",
        "    # Make predictions\n",
        "    preds = model.predict(dvalid)\n",
        "    pred_labels = [1 if p > 0.5 else 0 for p in preds]\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_valid, pred_labels)\n",
        "\n",
        "    return 1 - accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ngamVztLfaik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7df8732-d259-47c6-be52-00be198eb270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-09-15 10:23:50,803] A new study created in memory with name: no-name-bed3b35f-cab6-424c-bbf0-270095b7bd55\n",
            "[I 2024-09-15 10:23:52,621] Trial 0 finished with value: 0.05084050840508403 and parameters: {'booster': 'gbtree', 'lambda': 1.2256562445370454e-08, 'alpha': 0.13112391924357641, 'eta': 8.310685752428571e-07, 'max_depth': 3, 'min_child_weight': 0.21045602568497507, 'subsample': 0.19645993497751946, 'colsample_bytree': 0.9743375281970863}. Best is trial 0 with value: 0.05084050840508403.\n",
            "[I 2024-09-15 10:23:54,358] Trial 1 finished with value: 0.048831488314883154 and parameters: {'booster': 'gblinear', 'lambda': 2.571665342690121e-06, 'alpha': 0.5157718668255827, 'eta': 0.21848972180024584, 'max_depth': 3, 'min_child_weight': 1.326746792761624e-08, 'subsample': 0.46243025495217904, 'colsample_bytree': 0.8199204829296128}. Best is trial 1 with value: 0.048831488314883154.\n",
            "[I 2024-09-15 10:24:00,127] Trial 2 finished with value: 0.05084050840508403 and parameters: {'booster': 'gbtree', 'lambda': 0.0051396513295230905, 'alpha': 5.075502160323734e-07, 'eta': 2.870993005212156e-06, 'max_depth': 9, 'min_child_weight': 4.246457071156839e-05, 'subsample': 0.5862877868771977, 'colsample_bytree': 0.42225392267220685}. Best is trial 1 with value: 0.048831488314883154.\n",
            "[I 2024-09-15 10:24:01,993] Trial 3 finished with value: 0.05084050840508403 and parameters: {'booster': 'gblinear', 'lambda': 0.1982952765110032, 'alpha': 0.004118750364709014, 'eta': 6.60136947771441e-05, 'max_depth': 2, 'min_child_weight': 9.328610284109765e-07, 'subsample': 0.38868666131300444, 'colsample_bytree': 0.807887366942417}. Best is trial 1 with value: 0.048831488314883154.\n",
            "[I 2024-09-15 10:24:04,210] Trial 4 finished with value: 0.05084050840508403 and parameters: {'booster': 'gblinear', 'lambda': 0.009759727885166184, 'alpha': 0.0004787662834561272, 'eta': 8.707818068079481e-05, 'max_depth': 2, 'min_child_weight': 1.4299404243440391e-05, 'subsample': 0.2347028313960095, 'colsample_bytree': 0.3833342053179475}. Best is trial 1 with value: 0.048831488314883154.\n",
            "[I 2024-09-15 10:24:06,037] Trial 5 finished with value: 0.05084050840508403 and parameters: {'booster': 'gblinear', 'lambda': 0.03268134867231017, 'alpha': 7.85958988741226e-06, 'eta': 5.72142382512561e-07, 'max_depth': 9, 'min_child_weight': 8.4511636208877e-05, 'subsample': 0.5341285505916983, 'colsample_bytree': 0.43043514732487154}. Best is trial 1 with value: 0.048831488314883154.\n",
            "[I 2024-09-15 10:24:08,750] Trial 6 finished with value: 0.05084050840508403 and parameters: {'booster': 'gbtree', 'lambda': 0.014565726861413426, 'alpha': 1.5520156790067045e-05, 'eta': 1.4557777702027472e-06, 'max_depth': 3, 'min_child_weight': 6.448341424147262e-07, 'subsample': 0.695707624177245, 'colsample_bytree': 0.8662930558390985}. Best is trial 1 with value: 0.048831488314883154.\n",
            "[I 2024-09-15 10:24:16,908] Trial 7 finished with value: 0.05084050840508403 and parameters: {'booster': 'dart', 'lambda': 4.0908551075326014e-07, 'alpha': 0.003964179405872743, 'eta': 0.0013231184872324962, 'max_depth': 7, 'min_child_weight': 0.1282644230788252, 'subsample': 0.525237808940928, 'colsample_bytree': 0.9106520097858558}. Best is trial 1 with value: 0.048831488314883154.\n",
            "[I 2024-09-15 10:24:18,780] Trial 8 finished with value: 0.05084050840508403 and parameters: {'booster': 'gblinear', 'lambda': 0.025752381942838326, 'alpha': 1.3220584576657951e-07, 'eta': 9.634331157712694e-07, 'max_depth': 4, 'min_child_weight': 0.07874405986522731, 'subsample': 0.7577685324603505, 'colsample_bytree': 0.4180929071647741}. Best is trial 1 with value: 0.048831488314883154.\n",
            "[I 2024-09-15 10:24:20,321] Trial 9 finished with value: 0.05067650676506763 and parameters: {'booster': 'gblinear', 'lambda': 1.517403883018027e-07, 'alpha': 0.00544019976474878, 'eta': 0.053457846705561585, 'max_depth': 6, 'min_child_weight': 6.32017859796602e-07, 'subsample': 0.8936259157473995, 'colsample_bytree': 0.9432293823176213}. Best is trial 1 with value: 0.048831488314883154.\n",
            "[I 2024-09-15 10:24:22,149] Trial 10 finished with value: 0.03612136121361209 and parameters: {'booster': 'dart', 'lambda': 3.494701496896893e-05, 'alpha': 0.9401447091812035, 'eta': 0.6886564850173326, 'max_depth': 1, 'min_child_weight': 2.746820993665256e-08, 'subsample': 0.9952727216298924, 'colsample_bytree': 0.6648955097371269}. Best is trial 10 with value: 0.03612136121361209.\n",
            "[I 2024-09-15 10:24:22,914] Trial 11 finished with value: 0.0351783517835178 and parameters: {'booster': 'dart', 'lambda': 2.2973894840366565e-05, 'alpha': 0.875649522463036, 'eta': 0.6296727731681334, 'max_depth': 1, 'min_child_weight': 1.3914659840705697e-08, 'subsample': 0.9652485020155852, 'colsample_bytree': 0.6402917625914452}. Best is trial 11 with value: 0.0351783517835178.\n",
            "[I 2024-09-15 10:24:23,653] Trial 12 finished with value: 0.03612136121361209 and parameters: {'booster': 'dart', 'lambda': 0.00011842121224004136, 'alpha': 0.6442391645066907, 'eta': 0.8346386245703645, 'max_depth': 1, 'min_child_weight': 1.075441576764523e-08, 'subsample': 0.9577958535311992, 'colsample_bytree': 0.636465229378869}. Best is trial 11 with value: 0.0351783517835178.\n",
            "[I 2024-09-15 10:24:25,349] Trial 13 finished with value: 0.05084050840508403 and parameters: {'booster': 'dart', 'lambda': 7.515875285319419e-05, 'alpha': 0.04005383339018532, 'eta': 0.01477789573030879, 'max_depth': 1, 'min_child_weight': 8.506926946211587e-08, 'subsample': 0.9988412570782377, 'colsample_bytree': 0.6562721543930709}. Best is trial 11 with value: 0.0351783517835178.\n",
            "[I 2024-09-15 10:24:27,924] Trial 14 finished with value: 0.05084050840508403 and parameters: {'booster': 'dart', 'lambda': 6.977752429346444e-05, 'alpha': 0.03553577235116069, 'eta': 0.005549532611887921, 'max_depth': 5, 'min_child_weight': 0.004025694690015381, 'subsample': 0.7954390001595075, 'colsample_bytree': 0.11308896652184419}. Best is trial 11 with value: 0.0351783517835178.\n",
            "[I 2024-09-15 10:24:28,669] Trial 15 finished with value: 0.05084050840508403 and parameters: {'booster': 'dart', 'lambda': 0.0005139370455438535, 'alpha': 0.00045272058956858583, 'eta': 2.1561007955307292e-08, 'max_depth': 1, 'min_child_weight': 0.0019101667895103601, 'subsample': 0.8793551847905051, 'colsample_bytree': 0.6562805960087623}. Best is trial 11 with value: 0.0351783517835178.\n",
            "[I 2024-09-15 10:24:29,478] Trial 16 finished with value: 0.04100041000410004 and parameters: {'booster': 'dart', 'lambda': 1.195999415174786e-05, 'alpha': 0.08145741706800003, 'eta': 0.8506324379556769, 'max_depth': 2, 'min_child_weight': 3.8968921451136385e-06, 'subsample': 0.6472711053840092, 'colsample_bytree': 0.5473848556234264}. Best is trial 11 with value: 0.0351783517835178.\n",
            "[I 2024-09-15 10:24:30,356] Trial 17 finished with value: 0.05084050840508403 and parameters: {'booster': 'dart', 'lambda': 0.0010218965750759279, 'alpha': 0.4528211626280594, 'eta': 0.0005453116566007397, 'max_depth': 4, 'min_child_weight': 8.436852092033784e-08, 'subsample': 0.8013165694921088, 'colsample_bytree': 0.7203250294679785}. Best is trial 11 with value: 0.0351783517835178.\n",
            "[I 2024-09-15 10:24:31,420] Trial 18 finished with value: 0.05084050840508403 and parameters: {'booster': 'dart', 'lambda': 3.837722227620166e-06, 'alpha': 5.256427679616201e-05, 'eta': 0.05479476932611766, 'max_depth': 7, 'min_child_weight': 5.153857890813353e-08, 'subsample': 0.9238470607781754, 'colsample_bytree': 0.5252066832325987}. Best is trial 11 with value: 0.0351783517835178.\n",
            "[I 2024-09-15 10:24:32,153] Trial 19 finished with value: 0.05084050840508403 and parameters: {'booster': 'dart', 'lambda': 3.7990473193296456e-07, 'alpha': 0.011967503052526024, 'eta': 0.10127329877001913, 'max_depth': 1, 'min_child_weight': 0.0008755619658459329, 'subsample': 0.3545929763308553, 'colsample_bytree': 0.2725844083590406}. Best is trial 11 with value: 0.0351783517835178.\n",
            "[I 2024-09-15 10:24:33,034] Trial 20 finished with value: 0.05084050840508403 and parameters: {'booster': 'dart', 'lambda': 1.2524972038102293e-05, 'alpha': 0.0006019860679896239, 'eta': 0.0050830835408212415, 'max_depth': 4, 'min_child_weight': 1.9175120923713664e-06, 'subsample': 0.8403056297661489, 'colsample_bytree': 0.7366667550988345}. Best is trial 11 with value: 0.0351783517835178.\n",
            "[I 2024-09-15 10:24:33,812] Trial 21 finished with value: 0.03624436244362439 and parameters: {'booster': 'dart', 'lambda': 0.00025495009484571856, 'alpha': 0.587901221266511, 'eta': 0.33007009491045014, 'max_depth': 1, 'min_child_weight': 3.033673243658108e-08, 'subsample': 0.9992479810664834, 'colsample_bytree': 0.6324384536819732}. Best is trial 11 with value: 0.0351783517835178.\n",
            "[I 2024-09-15 10:24:34,619] Trial 22 finished with value: 0.03952439524395246 and parameters: {'booster': 'dart', 'lambda': 5.522231677691463e-05, 'alpha': 0.9998435603235301, 'eta': 0.9598187870872572, 'max_depth': 2, 'min_child_weight': 1.9869905686229284e-07, 'subsample': 0.9543416193087577, 'colsample_bytree': 0.5955114984330029}. Best is trial 11 with value: 0.0351783517835178.\n",
            "[I 2024-09-15 10:24:35,400] Trial 23 finished with value: 0.05084050840508403 and parameters: {'booster': 'dart', 'lambda': 0.0020030410158988514, 'alpha': 0.16644572561696552, 'eta': 0.031127070692895574, 'max_depth': 1, 'min_child_weight': 1.1281512699788834e-08, 'subsample': 0.6897131912336045, 'colsample_bytree': 0.735980760892751}. Best is trial 11 with value: 0.0351783517835178.\n",
            "[I 2024-09-15 10:24:36,177] Trial 24 finished with value: 0.04173841738417383 and parameters: {'booster': 'dart', 'lambda': 1.709789726637767e-05, 'alpha': 0.023552977791447743, 'eta': 0.24141835966165312, 'max_depth': 2, 'min_child_weight': 1.2575766697794558e-07, 'subsample': 0.9201612286821296, 'colsample_bytree': 0.506672622600246}. Best is trial 11 with value: 0.0351783517835178.\n",
            "[I 2024-09-15 10:24:36,627] Trial 25 finished with value: 0.05084050840508403 and parameters: {'booster': 'gbtree', 'lambda': 1.7912034909451518e-06, 'alpha': 0.1967573108660929, 'eta': 0.010955454740031288, 'max_depth': 3, 'min_child_weight': 1.1531598153230521e-08, 'subsample': 0.7489073268086127, 'colsample_bytree': 0.7049309662348229}. Best is trial 11 with value: 0.0351783517835178.\n",
            "[I 2024-09-15 10:24:37,357] Trial 26 finished with value: 0.05084050840508403 and parameters: {'booster': 'dart', 'lambda': 0.00017318000928911501, 'alpha': 0.8628817029906047, 'eta': 0.0013503834119189164, 'max_depth': 1, 'min_child_weight': 5.05137010614447e-06, 'subsample': 0.8522357758412369, 'colsample_bytree': 0.5875863441557592}. Best is trial 11 with value: 0.0351783517835178.\n",
            "[I 2024-09-15 10:24:39,187] Trial 27 finished with value: 0.03243132431324314 and parameters: {'booster': 'dart', 'lambda': 2.6647226713556173e-05, 'alpha': 0.1054247327908345, 'eta': 0.5953273373266605, 'max_depth': 2, 'min_child_weight': 2.9910594971291153e-07, 'subsample': 0.9918697641823535, 'colsample_bytree': 0.7971550621857839}. Best is trial 27 with value: 0.03243132431324314.\n",
            "[I 2024-09-15 10:24:41,631] Trial 28 finished with value: 0.05084050840508403 and parameters: {'booster': 'dart', 'lambda': 2.113972027334936e-05, 'alpha': 0.0018208908492244483, 'eta': 1.6422286288773585e-05, 'max_depth': 2, 'min_child_weight': 2.692078093837984e-07, 'subsample': 0.8483889945771063, 'colsample_bytree': 0.8179562219174371}. Best is trial 27 with value: 0.03243132431324314.\n",
            "[I 2024-09-15 10:24:42,061] Trial 29 finished with value: 0.03193931939319394 and parameters: {'booster': 'gbtree', 'lambda': 1.7659512056780424e-08, 'alpha': 0.0918168201899675, 'eta': 0.18974915875649867, 'max_depth': 3, 'min_child_weight': 3.0978491583957863e-07, 'subsample': 0.9957864799068696, 'colsample_bytree': 0.9800737369266032}. Best is trial 29 with value: 0.03193931939319394.\n",
            "[I 2024-09-15 10:24:42,534] Trial 30 finished with value: 0.036490364903648986 and parameters: {'booster': 'gbtree', 'lambda': 1.151267780278233e-08, 'alpha': 1.77062195572131e-08, 'eta': 0.13261468644655378, 'max_depth': 5, 'min_child_weight': 1.905369383797328e-05, 'subsample': 0.23982238463371525, 'colsample_bytree': 0.9853295791339095}. Best is trial 29 with value: 0.03193931939319394.\n",
            "[I 2024-09-15 10:24:42,989] Trial 31 finished with value: 0.030094300943009467 and parameters: {'booster': 'gbtree', 'lambda': 6.883764139870972e-08, 'alpha': 0.11230337730547676, 'eta': 0.3392700412171308, 'max_depth': 3, 'min_child_weight': 4.1636989122425726e-07, 'subsample': 0.9775215595178164, 'colsample_bytree': 0.9073659942274991}. Best is trial 31 with value: 0.030094300943009467.\n",
            "[I 2024-09-15 10:24:43,420] Trial 32 finished with value: 0.037474374743747485 and parameters: {'booster': 'gbtree', 'lambda': 7.84029213619428e-08, 'alpha': 0.08798165660420071, 'eta': 0.19502689291016229, 'max_depth': 3, 'min_child_weight': 4.5254148670536006e-07, 'subsample': 0.9351069178188642, 'colsample_bytree': 0.8881418079751481}. Best is trial 31 with value: 0.030094300943009467.\n",
            "[I 2024-09-15 10:24:43,869] Trial 33 finished with value: 0.05084050840508403 and parameters: {'booster': 'gbtree', 'lambda': 3.308521190735439e-08, 'alpha': 0.14012100850839831, 'eta': 0.020747010753152807, 'max_depth': 3, 'min_child_weight': 0.0003830288064035298, 'subsample': 0.8808161374522084, 'colsample_bytree': 0.9552257799286336}. Best is trial 31 with value: 0.030094300943009467.\n",
            "[I 2024-09-15 10:24:44,315] Trial 34 finished with value: 0.05059450594505943 and parameters: {'booster': 'gbtree', 'lambda': 1.0102823326023905e-06, 'alpha': 0.01218312288699063, 'eta': 0.07624566828424323, 'max_depth': 4, 'min_child_weight': 2.2339379050321064e-06, 'subsample': 0.11500591769797053, 'colsample_bytree': 0.7845672993746812}. Best is trial 31 with value: 0.030094300943009467.\n",
            "[I 2024-09-15 10:24:44,727] Trial 35 finished with value: 0.043091430914309115 and parameters: {'booster': 'gbtree', 'lambda': 5.286101656987371e-08, 'alpha': 0.20724480403548412, 'eta': 0.1715072397429061, 'max_depth': 2, 'min_child_weight': 0.8593347072231766, 'subsample': 0.9503779530803734, 'colsample_bytree': 0.8420872718789537}. Best is trial 31 with value: 0.030094300943009467.\n",
            "[I 2024-09-15 10:24:45,177] Trial 36 finished with value: 0.030381303813038163 and parameters: {'booster': 'gbtree', 'lambda': 4.8881635279736716e-06, 'alpha': 0.04281921983844032, 'eta': 0.4304179880672821, 'max_depth': 3, 'min_child_weight': 1.2767397010849215e-06, 'subsample': 0.8056267291314985, 'colsample_bytree': 0.777017110192863}. Best is trial 31 with value: 0.030094300943009467.\n",
            "[I 2024-09-15 10:24:45,605] Trial 37 finished with value: 0.05084050840508403 and parameters: {'booster': 'gbtree', 'lambda': 4.664397432297155e-06, 'alpha': 0.0011975341248552278, 'eta': 1.8310327770772712e-07, 'max_depth': 3, 'min_child_weight': 9.187077539894331e-06, 'subsample': 0.8066907343891769, 'colsample_bytree': 0.9995627692673642}. Best is trial 31 with value: 0.030094300943009467.\n",
            "[I 2024-09-15 10:24:46,071] Trial 38 finished with value: 0.05084050840508403 and parameters: {'booster': 'gbtree', 'lambda': 2.3970818687946394e-08, 'alpha': 0.01265148531483257, 'eta': 0.0003290910049852332, 'max_depth': 4, 'min_child_weight': 3.9678354852321784e-05, 'subsample': 0.5794744898374418, 'colsample_bytree': 0.9097513034692575}. Best is trial 31 with value: 0.030094300943009467.\n",
            "[I 2024-09-15 10:24:46,540] Trial 39 finished with value: 0.05084050840508403 and parameters: {'booster': 'gbtree', 'lambda': 2.0860415309084447e-07, 'alpha': 0.00017020645913965414, 'eta': 0.0022960073474412508, 'max_depth': 5, 'min_child_weight': 8.309795675799839e-07, 'subsample': 0.7320199331687458, 'colsample_bytree': 0.7960702110617252}. Best is trial 31 with value: 0.030094300943009467.\n",
            "[I 2024-09-15 10:24:47,032] Trial 40 finished with value: 0.05084050840508403 and parameters: {'booster': 'gbtree', 'lambda': 7.597710194731023e-07, 'alpha': 0.04914183568876874, 'eta': 1.2835925784873755e-05, 'max_depth': 6, 'min_child_weight': 1.6297491171753138e-06, 'subsample': 0.661954112997923, 'colsample_bytree': 0.8731667028897694}. Best is trial 31 with value: 0.030094300943009467.\n",
            "[I 2024-09-15 10:24:47,449] Trial 41 finished with value: 0.03620336203362029 and parameters: {'booster': 'gbtree', 'lambda': 0.2616430811894483, 'alpha': 0.2993079028044479, 'eta': 0.33980596136979585, 'max_depth': 2, 'min_child_weight': 3.119304017487567e-07, 'subsample': 0.8948893594462247, 'colsample_bytree': 0.7891729005016498}. Best is trial 31 with value: 0.030094300943009467.\n",
            "[I 2024-09-15 10:24:47,896] Trial 42 finished with value: 0.029561295612956173 and parameters: {'booster': 'gbtree', 'lambda': 5.3446925474155374e-06, 'alpha': 3.541290092992722e-06, 'eta': 0.46959489020789086, 'max_depth': 3, 'min_child_weight': 3.2769805075775504e-08, 'subsample': 0.9576427343265794, 'colsample_bytree': 0.9377178003498913}. Best is trial 42 with value: 0.029561295612956173.\n",
            "[I 2024-09-15 10:24:48,325] Trial 43 finished with value: 0.05084050840508403 and parameters: {'booster': 'gbtree', 'lambda': 4.290232036657773e-06, 'alpha': 1.4201214488239543e-06, 'eta': 0.036543725718853, 'max_depth': 3, 'min_child_weight': 4.6731459967949436e-08, 'subsample': 0.9184492178682004, 'colsample_bytree': 0.9334090352889479}. Best is trial 42 with value: 0.029561295612956173.\n",
            "[I 2024-09-15 10:24:48,760] Trial 44 finished with value: 0.030381303813038163 and parameters: {'booster': 'gbtree', 'lambda': 1.4363534328209472e-07, 'alpha': 1.5878309261673877e-06, 'eta': 0.34961106563826383, 'max_depth': 3, 'min_child_weight': 1.4774309621179162e-07, 'subsample': 0.9773460689284991, 'colsample_bytree': 0.8537631065934477}. Best is trial 42 with value: 0.029561295612956173.\n",
            "[I 2024-09-15 10:24:49,226] Trial 45 finished with value: 0.047847478474784766 and parameters: {'booster': 'gbtree', 'lambda': 1.3456444064868175e-07, 'alpha': 4.167716521183495e-06, 'eta': 0.10256136842840499, 'max_depth': 4, 'min_child_weight': 1.1857246240580967e-07, 'subsample': 0.4303224866673644, 'colsample_bytree': 0.8587089147238517}. Best is trial 42 with value: 0.029561295612956173.\n",
            "[I 2024-09-15 10:24:49,669] Trial 46 finished with value: 0.03062730627306276 and parameters: {'booster': 'gbtree', 'lambda': 1.5812704895116082e-08, 'alpha': 2.0162289313101386e-07, 'eta': 0.327698656901206, 'max_depth': 3, 'min_child_weight': 8.786946015892813e-07, 'subsample': 0.8317804517504073, 'colsample_bytree': 0.9535803990797095}. Best is trial 42 with value: 0.029561295612956173.\n",
            "[I 2024-09-15 10:24:50,136] Trial 47 finished with value: 0.043788437884378806 and parameters: {'booster': 'gblinear', 'lambda': 7.939480894851883e-08, 'alpha': 2.9504241155867237e-07, 'eta': 0.3286448387433185, 'max_depth': 4, 'min_child_weight': 0.011042779483555231, 'subsample': 0.8354610993934063, 'colsample_bytree': 0.9202159901677794}. Best is trial 42 with value: 0.029561295612956173.\n",
            "[I 2024-09-15 10:24:50,565] Trial 48 finished with value: 0.05084050840508403 and parameters: {'booster': 'gbtree', 'lambda': 3.1041470167183736e-07, 'alpha': 4.475690794379322e-08, 'eta': 0.006709269195831381, 'max_depth': 3, 'min_child_weight': 1.0950601506846031e-06, 'subsample': 0.7736917065317549, 'colsample_bytree': 0.8465887668145483}. Best is trial 42 with value: 0.029561295612956173.\n",
            "[I 2024-09-15 10:24:51,054] Trial 49 finished with value: 0.05084050840508403 and parameters: {'booster': 'gbtree', 'lambda': 8.216364637928682e-07, 'alpha': 1.1461571692234853e-06, 'eta': 0.020256736676594823, 'max_depth': 3, 'min_child_weight': 0.0001769256905453036, 'subsample': 0.8828186577622299, 'colsample_bytree': 0.8930907315843013}. Best is trial 42 with value: 0.029561295612956173.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best trial:\n",
            "  Value: 0.029561295612956173\n",
            "  Params: \n",
            "    booster: gbtree\n",
            "    lambda: 5.3446925474155374e-06\n",
            "    alpha: 3.541290092992722e-06\n",
            "    eta: 0.46959489020789086\n",
            "    max_depth: 3\n",
            "    min_child_weight: 3.2769805075775504e-08\n",
            "    subsample: 0.9576427343265794\n",
            "    colsample_bytree: 0.9377178003498913\n"
          ]
        }
      ],
      "source": [
        "study = optuna.create_study(direction='minimize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "print(\"  Value: {}\".format(trial.value))\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "q5C_bbbDeEBC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "afa16055-62c1-4060-be47-793320bd260e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(alpha=3.541290092992722e-06, base_score=None, booster='gbtree',\n",
              "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.9377178003498913, device=None,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eta=0.46959489020789086, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, lambda=5.3446925474155374e-06,\n",
              "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
              "              max_leaves=None, min_child_weight=3.2769805075775504e-08,\n",
              "              missing=nan, monotone_constraints=None, multi_strategy=None,\n",
              "              n_estimators=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(alpha=3.541290092992722e-06, base_score=None, booster=&#x27;gbtree&#x27;,\n",
              "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.9377178003498913, device=None,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eta=0.46959489020789086, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, lambda=5.3446925474155374e-06,\n",
              "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
              "              max_leaves=None, min_child_weight=3.2769805075775504e-08,\n",
              "              missing=nan, monotone_constraints=None, multi_strategy=None,\n",
              "              n_estimators=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(alpha=3.541290092992722e-06, base_score=None, booster=&#x27;gbtree&#x27;,\n",
              "              callbacks=None, colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=0.9377178003498913, device=None,\n",
              "              early_stopping_rounds=None, enable_categorical=False,\n",
              "              eta=0.46959489020789086, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, lambda=5.3446925474155374e-06,\n",
              "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
              "              max_cat_to_onehot=None, max_delta_step=None, max_depth=3,\n",
              "              max_leaves=None, min_child_weight=3.2769805075775504e-08,\n",
              "              missing=nan, monotone_constraints=None, multi_strategy=None,\n",
              "              n_estimators=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "best_params = trial.params\n",
        "model_xgb = xgb.XGBClassifier(**best_params)\n",
        "model_xgb.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "S4Z7nAFyfzCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a85eef04-1400-4489-e66c-961b8ee1143f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------Scores XGB----------------\n",
            "\n",
            "Accuracy ----- 0.9705147952203736\n",
            "\n",
            "Recall ------- 0.7597809076682316\n",
            "\n",
            "Precision ---- 0.6768909027535727\n",
            "\n",
            "F1 Score ----- 0.7159447004608294\n"
          ]
        }
      ],
      "source": [
        "y_pred_xgb = np.round(model_xgb.predict(X_test)).astype(int)\n",
        "print('----------------Scores XGB----------------')\n",
        "print('\\nAccuracy -----', accuracy_score(y_test, y_pred_xgb))\n",
        "print('\\nRecall -------', recall_score(y_test, y_pred_xgb))\n",
        "print('\\nPrecision ----', precision_score(y_test, y_pred_xgb))\n",
        "print('\\nF1 Score -----', f1_score(y_test, y_pred_xgb))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FNN con Optuna**"
      ],
      "metadata": {
        "id": "cUcCXaLA3vJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nwso-SfEO3jW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FNNModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout):\n",
        "        super(FNNModel, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(input_size, hidden_size))\n",
        "        layers.append(nn.ReLU())\n",
        "        for _ in range(num_layers - 1):\n",
        "            layers.append(nn.Linear(hidden_size, hidden_size))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.Dropout(dropout))\n",
        "        layers.append(nn.Linear(hidden_size, output_size))\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n"
      ],
      "metadata": {
        "id": "YyTP-aeC3xIk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "315646a9-7021-4b27-b7d8-710efb6da921"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-162aeb3c1614>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mFNNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFNNModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "    # Suggest hyperparameters for the FNN\n",
        "    hidden_size = trial.suggest_int('hidden_size', 32, 128)\n",
        "    num_layers = trial.suggest_int('num_layers', 1, 3)\n",
        "    dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n",
        "\n",
        "    # Define the FNN model\n",
        "    model = FNNModel(input_size=X_train_tensor.shape[1], hidden_size=hidden_size, num_layers=num_layers, output_size=2, dropout=dropout)\n",
        "\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Train the model\n",
        "    model.train()\n",
        "    for epoch in range(10):  # For simplicity, we use 20 epochs\n",
        "        for inputs, targets in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "    y_pred = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    return accuracy\n"
      ],
      "metadata": {
        "id": "oAviYPkK3zxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a study object\n",
        "study = optuna.create_study(direction='maximize')\n",
        "\n",
        "# Optimize the study\n",
        "study.optimize(objective, n_trials=15)\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best hyperparameters: \", study.best_params)\n",
        "print(\"Best accuracy: \", study.best_value)\n"
      ],
      "metadata": {
        "id": "hPhK30sK324J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "skSp_br1I97j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor= 'val_loss',    # Revisamos la función loss de la validación\n",
        "    patience= 8,            # Numero de épocas que tienen que pasar sin mejora\n",
        "    restore_best_weights=True  # Guardamos los pesos de la mejor época\n",
        ")\n",
        "\n",
        "# Reajustar los datos de entrenamiento y validación para adaptarse a la entrada LSTM\n",
        "X_train_reshaped = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test_reshaped = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Definir el modelo LSTM secuencial\n",
        "model_LSTM = Sequential([\n",
        "    # Primera capa LSTM con 256 unidades, que devuelve secuencias completas (return_sequences=True)\n",
        "    LSTM(64, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True),\n",
        "    # Segunda capa LSTM con 128 unidades, que también devuelve secuencias completas\n",
        "    LSTM(32, return_sequences=False),\n",
        "    # Capa densa con 32 unidades y función de activación ReLU\n",
        "    Dense(16, activation='relu'),\n",
        "    # Capa de salida con 1 unidad y función de activación sigmoide para predicción binaria\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compilar el modelo\n",
        "# optimizer='adam' especifica el optimizador Adam\n",
        "# loss='binary_crossentropy' especifica la función de pérdida para clasificación binaria\n",
        "# metrics=['accuracy'] especifica que se rastreará la métrica de precisión durante el entrenamiento y la evaluación\n",
        "model_LSTM.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "# epochs=100 especifica que el entrenamiento se realizará durante 100 épocas\n",
        "# batch_size=32 especifica que el tamaño del lote será de 32 muestras\n",
        "# validation_split=0.1 reserva el 10% de los datos de entrenamiento para validación\n",
        "# verbose=1 habilita la salida detallada del proceso de entrenamiento\n",
        "history = model_LSTM.fit(X_train_reshaped, y_train, epochs=100, batch_size=128, validation_split= 0.1, verbose=1,   callbacks=[early_stopping])\n",
        "\n",
        "# Evaluar el modelo en el conjunto de validación\n",
        "# loss, accuracy devuelve la pérdida y precisión del modelo en el conjunto de validación\n",
        "loss, accuracy = model_LSTM.evaluate(X_test_reshaped, y_test)\n",
        "\n",
        "# Imprimir la pérdida y precisión del modelo en el conjunto de validación\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "5_IqfN2LI94w",
        "outputId": "33758227-cf52-4bd3-d91f-e9ad8eed9de2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'DataFrame' object has no attribute 'reshape'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-635005a6e6dd>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Reajustar los datos de entrenamiento y validación para adaptarse a la entrada LSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_train_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mX_test_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6202\u001b[0m         ):\n\u001b[1;32m   6203\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6204\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6206\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'reshape'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_LSTM = np.round(model_LSTM.predict(X_test_reshaped)).astype(int)\n",
        "print('----------------Scores LSTM----------------')\n",
        "print('\\nAccuracy -----', accuracy_score(y_test, y_pred_LSTM))\n",
        "print('\\nRecall -------', recall_score(y_test, y_pred_LSTM))\n",
        "print('\\nPrecision ----', precision_score(y_test, y_pred_LSTM))\n",
        "print('\\nF1 Score -----', f1_score(y_test, y_pred_LSTM))"
      ],
      "metadata": {
        "id": "7-_CVdopI9zy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HEr8_v-4I9xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ylRx5zJ0I9tk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}