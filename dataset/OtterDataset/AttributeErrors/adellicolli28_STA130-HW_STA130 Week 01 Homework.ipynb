{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d3effe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca7f001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "villagers_df = pd.read_csv(url)\n",
    "\n",
    "# Getting the number of rows and columns\n",
    "rows, columns = villagers_df.shape\n",
    "\n",
    "# Printing the number of rows and columns\n",
    "print(f\"Number of rows: {rows}\")\n",
    "print(f\"Number of columns: {columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb13060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Using df.describe() to get descriptive statistics for numerical columns\n",
    "print(\"Descriptive Statistics:\")\n",
    "print(villagers_df.describe())\n",
    "\n",
    "# Example 2: Using df['column'].value_counts() to get the counts of unique values in the 'species' column\n",
    "print(\"\\nValue Counts for the 'species' column:\")\n",
    "print(villagers_df['species'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cbf519",
   "metadata": {},
   "source": [
    "2) Write your own general definitions of the meaning of \"observations\" and \"variables\" based on asking the ChatBot to explain these terms in the context of your dataset.\n",
    "\n",
    "Observations are the individual records in the dataset.\n",
    "Variables are the characteristics that describe the observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb3b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "titanic_df = pd.read_csv(url)\n",
    "\n",
    "# Display the shape of the dataset\n",
    "print(\"Shape of the dataset:\", titanic_df.shape)\n",
    "\n",
    "# Display descriptive statistics for numeric columns\n",
    "print(\"\\nDescriptive Statistics for Numeric Columns:\")\n",
    "print(titanic_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a865a",
   "metadata": {},
   "source": [
    "4) If the dataset you're using has (a) non-numeric variables and (b) missing values in numeric variables, explain (perhaps using help from a ChatBot if needed) the discrepancies between size of the dataset given by df.shape and what is reported by df.describe() with respect to (a) the number of columns it analyzes and (b) the values it reports in the \"count\" column\n",
    "\n",
    "The differences stem from the fact that df.describe() focuses on numeric columns and excludes rows with missing values, whereas df.shape shows the full structure of the dataset.\n",
    "\n",
    "5) Use your ChatBot session to help understand the difference between the following and then provide your own paraphrasing summarization of that difference\n",
    "an \"attribute\", such as df.shape which does not end with ()\n",
    "and a \"method\", such as df.describe() which does end with ()\n",
    "\n",
    "attribute: information about the object\n",
    "method: actions the object can perform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b50741",
   "metadata": {},
   "source": [
    "Chatbot Link: https://chatgpt.com/share/411ab39e-605d-4d07-9cef-6942bb0e7011"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859fe145",
   "metadata": {},
   "source": [
    "6) The df.describe() method provides the 'count', 'mean', 'std', 'min', '25%', '50%', '75%', and 'max' summary statistics for each variable it analyzes. Give the definitions (perhaps using help from the ChatBot if needed) of each of these summary statistics\n",
    "\n",
    "Count: number of non null observations in each column\n",
    "Mean: average values in each column\n",
    "std (Standard Deviation): measure of variation in the values\n",
    "min (Minimum): minumum value in each column\n",
    "25%: value below which 25% of the observations fall\n",
    "50%: median value\n",
    "75%: value below which 75% of the observations fall\n",
    "max (Maximum): maximum value in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e07705e",
   "metadata": {},
   "source": [
    "7) Missing data can be considered \"across rows\" or \"down columns\". Consider how df.dropna() or del df['col'] should be applied to most efficiently use the available non-missing data in your dataset and briefly answer the following questions in your own words\n",
    "\n",
    "1) Provide an example of a \"use case\" in which using df.dropna() might be peferred over using del df['col']\n",
    "\n",
    "You are collecting data on sales in the New College dining hall including: student ID, purchase date, and purchase amount. There is some missing data including purchase amount, but it is crucial for your analysis. You will use df.dropna() to remove the rows where the purchase amount is missing so the data that was missing is excluded from your analysis, but other crucial information is still present. By dropping only rows with missing values in specific columns, you maintain a larger portion of your dataset compared to dropping entire columns, which could result in losing valuable information.\n",
    "\n",
    "2) Provide an example of \"the opposite use case\" in which using del df['col'] might be preferred over using df.dropna()\n",
    "\n",
    "You are collecting data on satisfaction levels for New College dining including: age, gender, satisfaction score, and suggestions. The suggestion column was very empty and not many people filled it out. Additionally, since it is not the main focus of the data analysis, you will use delf df['col'] to delete the column of data and narrow your focus on the more esssential data. \n",
    "\n",
    "3) Discuss why applying del df['col'] before df.dropna() when both are used together could be important\n",
    "\n",
    "It could be important to apply del df['col'] first because it can narrow your scope of research further when a column is no longer needed if not much information is gathered. Then it would be helpful to use df.dropna() after so the other missing values can be filtered out further for most efficient results. \n",
    "\n",
    "4) Remove all missing data from one of the datasets you're considering using some combination of del df['col'] and/or df.dropna() and give a justification for your approach, including a \"before and after\" report of the results of your approach for your dataset.\n",
    "\n",
    "I would use del df['col'] to remove the column \"song\" because it has the most missing values and not many other values are missing for the other columns. Additionally, I would use df.dropna() to remove a row which consists of the ID information missing only once. This would then eliminate the column that is missing a lot of information, therfore does not benefit the data analysis as much and then eliminate the one row with a missing value to ensure all the data in the table is complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaf621f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Display the columns before removal\n",
    "print(\"Columns before removal:\")\n",
    "print(df.columns)\n",
    "\n",
    "# Remove the column named \"song\"\n",
    "del df['song']\n",
    "\n",
    "# Display the columns after removal\n",
    "print(\"\\nColumns after removal:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79d1127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'id' column has missing values\n",
    "df_cleaned = df.dropna(subset=['id'])\n",
    "\n",
    "# Verify that the rows with missing 'id' values have been removed\n",
    "print(\"\\nDataFrame after dropping rows with missing 'id':\")\n",
    "print(df_cleaned.head())\n",
    "print(\"\\nMissing data summary after removal:\")\n",
    "print(df_cleaned.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090e082d",
   "metadata": {},
   "source": [
    "ChatBot Link: https://chatgpt.com/share/95181bd5-b4fa-4561-858d-0c28b08334bb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4a7ea8",
   "metadata": {},
   "source": [
    "8) Give brief explanations in your own words for any requested answers to the questions below\n",
    "\n",
    "1) Use your ChatBot session to understand what df.groupby(\"col1\")[\"col2\"].describe() does and then demonstrate and explain this using a different example from the \"titanic\" data set other than what the ChatBot automatically provide for you\n",
    "\n",
    "dr.groupy(\"col1\")[\"col2\"].describe(): generate descriptive statistics for a column of a DataFrame, grouped by another column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa8ad7d",
   "metadata": {},
   "source": [
    "ChatBot Link: https://chatgpt.com/share/57662dd9-5728-4db7-b36b-1c810f5c8df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf67788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "result = df.groupby(\"gender\")[\"personality\"].describe()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c211ce48",
   "metadata": {},
   "source": [
    "2) Assuming you've not yet removed missing values in the manner of question \"7\" above, df.describe() would have different values in the count value for different data columns depending on the missingness present in the original data. Why do these capture something fundamentally different from the values in the count that result from doing something like df.groupby(\"col1\")[\"col2\"].describe()?\n",
    "\n",
    "df.describe(): overall picture of missing data in each column.\n",
    "df.groupby(\"col1\")[\"col2\"].describe(): tells you how many non-missing values there are in \"col2\" for each group defined by \"col1\". This helps you see if some groups have more missing values than others.\n",
    "\n",
    "When you use df.groupby(\"col1\")[\"col2\"].describe(), the count tells you how many data points (or entries) are present in each group for the column \"col2\". This is crucial for understanding the distribution of data across different groups.\n",
    "\n",
    "3) Intentionally introduce the following errors into your code and report your opinion as to whether it's easier to (a) work in a ChatBot session to fix the errors, or (b) use google to search for and fix errors: first share the errors you get in the ChatBot session and see if you can work with ChatBot to troubleshoot and fix the coding errors, and then see if you think a google search for the error provides the necessary toubleshooting help more quickly than ChatGPT\n",
    "\n",
    "\n",
    "A) Forget to include import pandas as pd in your code\n",
    "Use Kernel->Restart from the notebook menu to restart the jupyter notebook session unload imported libraries and start over so you can create this error\n",
    "\n",
    "It is more helpful to ask Chat because it articulated what the error meant and produced code that corrected it. Google is not as easy because you have to do more digging for your answer.\n",
    "\n",
    "\n",
    "B) Mistype \"titanic.csv\" as \"titanics.csv\"\n",
    "If ChatBot troubleshooting is based on downloading the file, just replace the whole url with \"titanics.csv\" and try to troubleshoot the subsequent FileNotFoundError: [Errno 2] No such file or directory: 'titanics.csv' (assuming the file is indeed not present)\n",
    "\n",
    "Explore introducing typos into a couple other parts of the url and note the slightly different errors this produces\n",
    "\n",
    "Misspelled \"titanic\" - HTTPError: HTTP Error 404: Not Found\n",
    "Misspelled \"seaborn\" - HTTPError: HTTP Error 404: Not Found\n",
    "Missed a \"/\" - HTTPError: HTTP Error 400: Bad Request\n",
    "\n",
    "Chat was very clear on telling me what went wrong and telling me to check the url. Google was not as heloful because the answer is never direct. \n",
    "\n",
    "\n",
    "C) Try to use a dataframe before it's been assigned into the variable\n",
    "You can simulate this by just misnaming the variable. For example, if you should write df.groupby(\"col1\")[\"col2\"].describe() based on how you loaded the data, then instead write DF.groupby(\"col1\")[\"col2\"].describe()\n",
    "\n",
    "Make sure you've fixed your file name so that's not the error any more\n",
    "\n",
    "NameError - name 'DF' is not defined. \n",
    "\n",
    "Chat was very straight forward and easy to spot what is missing while also wallking me through the correct way to code it. \n",
    "\n",
    "\n",
    "D) Forget one of the parentheses somewhere the code\n",
    "For example, if the code should be pd.read_csv(url) the change it to pd.read_csv(url\n",
    "\n",
    "SyntaxError: '(' was never closed. \n",
    "\n",
    "Chat was very helpful because it showed me how to properly close the parenthesis to correct the mistake.\n",
    "\n",
    "\n",
    "E) Mistype one of the names of the chained functions with the code\n",
    "For example, try something like df.group_by(\"col1\")[\"col2\"].describe() and df.groupby(\"col1\")[\"col2\"].describle()\n",
    "\n",
    "Mistype a function - AttributeError: 'DataFrame' object has no attribute 'group_by'\n",
    "Mistype a method - AttributeError: 'SeriesGroupBy' object has no attribute 'describle'\n",
    "\n",
    "Chat easily showed me how to fix these errors, but google brought me to websites that didn't have answers I was looking for. \n",
    "\n",
    "F) Use a column name that's not in your data for the groupby and column selection\n",
    "For example, try capitalizing the columns for example replacing \"sex\" with \"Sex\" in titanic_df.groupby(\"sex\")[\"age\"].describe(), and then instead introducing the same error of \"age\"\n",
    "\n",
    "\"sex\" / \"Sex\" - KeyError: 'Sex'\n",
    "\"age\" / \"Age\" - KeyError: 'Column not found: Age'\n",
    "\n",
    "Chat was very easy to follow and helped me spot what is missing while also wallking me through the correct way to code it. \n",
    "\n",
    "G) Forget to put the column name as a string in quotes for the groupby and column selection, and see if the ChatBot and google are still as helpful as they were for the previous question\n",
    "For example, something like titanic_df.groupby(sex)[\"age\"].describe(), and then titanic_df.groupby(\"sex\")[age].describe()\n",
    "\n",
    "NameError: name 'sex' is not defined\n",
    "NameError: name 'age' is not defined\n",
    "\n",
    "Both resources came up with defining the variable before using it. Unfortunately, that was not quite the mistake we made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9467f892",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeeee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url= \"https://raw.githubusercontent.com/mwaskomseaborn-data/master/titanics.csv\"\n",
    "df=pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2441e89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url=\"https://raw.githubusercontent.com/mwaskom/seabrn-data/master/titanic.csv\"\n",
    "df=pd.read_css"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb92b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Suppose this is the correct variable name\n",
    "df = pd.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]})\n",
    "\n",
    "# Now, use the incorrect variable name to cause the error\n",
    "result = DF.groupby(\"col1\")[\"col2\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548b48cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-05-05/villagers.csv\"\n",
    "df = pd.read_csv(url\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f445cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]})\n",
    "\n",
    "# Mistype 'groupby' as 'group_by'\n",
    "result = df.group_by(\"col1\")[\"col2\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c181223b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'col1': [1, 2, 3], 'col2': [4, 5, 6]})\n",
    "\n",
    "# Mistype 'describe' as 'describle'\n",
    "result = df.groupby(\"col1\")[\"col2\"].describle()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8df74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df=pd.read_csv(url)\n",
    "titanic_df.groupby(\"Sex\")[\"age\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d180ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url= \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/titanic.csv\"\n",
    "df=pd.read_csv(url)\n",
    "titanic_df.groupby(\"sex\")[age].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
