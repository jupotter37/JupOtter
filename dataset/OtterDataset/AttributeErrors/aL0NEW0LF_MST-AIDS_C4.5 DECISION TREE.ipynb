{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import treePlotter as tpl\n",
    "import numpy\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "import operator\n",
    "import csv\n",
    "from sklearn import datasets\n",
    "\n",
    "def createDataSet():\n",
    "    with open('PlayTennis.csv', 'r') as f:\n",
    "        reader = csv.reader(f,delimiter=',')\n",
    "        dataSet = list(reader)\n",
    "    return dataSet[1:], dataSet[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[[5.1 3.5 1.4 0.2 0. ]\n",
      " [4.9 3.  1.4 0.2 0. ]\n",
      " [4.7 3.2 1.3 0.2 0. ]\n",
      " [4.6 3.1 1.5 0.2 0. ]\n",
      " [5.  3.6 1.4 0.2 0. ]\n",
      " [5.4 3.9 1.7 0.4 0. ]\n",
      " [4.6 3.4 1.4 0.3 0. ]\n",
      " [5.  3.4 1.5 0.2 0. ]\n",
      " [4.4 2.9 1.4 0.2 0. ]\n",
      " [4.9 3.1 1.5 0.1 0. ]\n",
      " [5.4 3.7 1.5 0.2 0. ]\n",
      " [4.8 3.4 1.6 0.2 0. ]\n",
      " [4.8 3.  1.4 0.1 0. ]\n",
      " [4.3 3.  1.1 0.1 0. ]\n",
      " [5.8 4.  1.2 0.2 0. ]\n",
      " [5.7 4.4 1.5 0.4 0. ]\n",
      " [5.4 3.9 1.3 0.4 0. ]\n",
      " [5.1 3.5 1.4 0.3 0. ]\n",
      " [5.7 3.8 1.7 0.3 0. ]\n",
      " [5.1 3.8 1.5 0.3 0. ]\n",
      " [5.4 3.4 1.7 0.2 0. ]\n",
      " [5.1 3.7 1.5 0.4 0. ]\n",
      " [4.6 3.6 1.  0.2 0. ]\n",
      " [5.1 3.3 1.7 0.5 0. ]\n",
      " [4.8 3.4 1.9 0.2 0. ]\n",
      " [5.  3.  1.6 0.2 0. ]\n",
      " [5.  3.4 1.6 0.4 0. ]\n",
      " [5.2 3.5 1.5 0.2 0. ]\n",
      " [5.2 3.4 1.4 0.2 0. ]\n",
      " [4.7 3.2 1.6 0.2 0. ]\n",
      " [4.8 3.1 1.6 0.2 0. ]\n",
      " [5.4 3.4 1.5 0.4 0. ]\n",
      " [5.2 4.1 1.5 0.1 0. ]\n",
      " [5.5 4.2 1.4 0.2 0. ]\n",
      " [4.9 3.1 1.5 0.2 0. ]\n",
      " [5.  3.2 1.2 0.2 0. ]\n",
      " [5.5 3.5 1.3 0.2 0. ]\n",
      " [4.9 3.6 1.4 0.1 0. ]\n",
      " [4.4 3.  1.3 0.2 0. ]\n",
      " [5.1 3.4 1.5 0.2 0. ]\n",
      " [5.  3.5 1.3 0.3 0. ]\n",
      " [4.5 2.3 1.3 0.3 0. ]\n",
      " [4.4 3.2 1.3 0.2 0. ]\n",
      " [5.  3.5 1.6 0.6 0. ]\n",
      " [5.1 3.8 1.9 0.4 0. ]\n",
      " [4.8 3.  1.4 0.3 0. ]\n",
      " [5.1 3.8 1.6 0.2 0. ]\n",
      " [4.6 3.2 1.4 0.2 0. ]\n",
      " [5.3 3.7 1.5 0.2 0. ]\n",
      " [5.  3.3 1.4 0.2 0. ]\n",
      " [7.  3.2 4.7 1.4 1. ]\n",
      " [6.4 3.2 4.5 1.5 1. ]\n",
      " [6.9 3.1 4.9 1.5 1. ]\n",
      " [5.5 2.3 4.  1.3 1. ]\n",
      " [6.5 2.8 4.6 1.5 1. ]\n",
      " [5.7 2.8 4.5 1.3 1. ]\n",
      " [6.3 3.3 4.7 1.6 1. ]\n",
      " [4.9 2.4 3.3 1.  1. ]\n",
      " [6.6 2.9 4.6 1.3 1. ]\n",
      " [5.2 2.7 3.9 1.4 1. ]\n",
      " [5.  2.  3.5 1.  1. ]\n",
      " [5.9 3.  4.2 1.5 1. ]\n",
      " [6.  2.2 4.  1.  1. ]\n",
      " [6.1 2.9 4.7 1.4 1. ]\n",
      " [5.6 2.9 3.6 1.3 1. ]\n",
      " [6.7 3.1 4.4 1.4 1. ]\n",
      " [5.6 3.  4.5 1.5 1. ]\n",
      " [5.8 2.7 4.1 1.  1. ]\n",
      " [6.2 2.2 4.5 1.5 1. ]\n",
      " [5.6 2.5 3.9 1.1 1. ]\n",
      " [5.9 3.2 4.8 1.8 1. ]\n",
      " [6.1 2.8 4.  1.3 1. ]\n",
      " [6.3 2.5 4.9 1.5 1. ]\n",
      " [6.1 2.8 4.7 1.2 1. ]\n",
      " [6.4 2.9 4.3 1.3 1. ]\n",
      " [6.6 3.  4.4 1.4 1. ]\n",
      " [6.8 2.8 4.8 1.4 1. ]\n",
      " [6.7 3.  5.  1.7 1. ]\n",
      " [6.  2.9 4.5 1.5 1. ]\n",
      " [5.7 2.6 3.5 1.  1. ]\n",
      " [5.5 2.4 3.8 1.1 1. ]\n",
      " [5.5 2.4 3.7 1.  1. ]\n",
      " [5.8 2.7 3.9 1.2 1. ]\n",
      " [6.  2.7 5.1 1.6 1. ]\n",
      " [5.4 3.  4.5 1.5 1. ]\n",
      " [6.  3.4 4.5 1.6 1. ]\n",
      " [6.7 3.1 4.7 1.5 1. ]\n",
      " [6.3 2.3 4.4 1.3 1. ]\n",
      " [5.6 3.  4.1 1.3 1. ]\n",
      " [5.5 2.5 4.  1.3 1. ]\n",
      " [5.5 2.6 4.4 1.2 1. ]\n",
      " [6.1 3.  4.6 1.4 1. ]\n",
      " [5.8 2.6 4.  1.2 1. ]\n",
      " [5.  2.3 3.3 1.  1. ]\n",
      " [5.6 2.7 4.2 1.3 1. ]\n",
      " [5.7 3.  4.2 1.2 1. ]\n",
      " [5.7 2.9 4.2 1.3 1. ]\n",
      " [6.2 2.9 4.3 1.3 1. ]\n",
      " [5.1 2.5 3.  1.1 1. ]\n",
      " [5.7 2.8 4.1 1.3 1. ]\n",
      " [6.3 3.3 6.  2.5 2. ]\n",
      " [5.8 2.7 5.1 1.9 2. ]\n",
      " [7.1 3.  5.9 2.1 2. ]\n",
      " [6.3 2.9 5.6 1.8 2. ]\n",
      " [6.5 3.  5.8 2.2 2. ]\n",
      " [7.6 3.  6.6 2.1 2. ]\n",
      " [4.9 2.5 4.5 1.7 2. ]\n",
      " [7.3 2.9 6.3 1.8 2. ]\n",
      " [6.7 2.5 5.8 1.8 2. ]\n",
      " [7.2 3.6 6.1 2.5 2. ]\n",
      " [6.5 3.2 5.1 2.  2. ]\n",
      " [6.4 2.7 5.3 1.9 2. ]\n",
      " [6.8 3.  5.5 2.1 2. ]\n",
      " [5.7 2.5 5.  2.  2. ]\n",
      " [5.8 2.8 5.1 2.4 2. ]\n",
      " [6.4 3.2 5.3 2.3 2. ]\n",
      " [6.5 3.  5.5 1.8 2. ]\n",
      " [7.7 3.8 6.7 2.2 2. ]\n",
      " [7.7 2.6 6.9 2.3 2. ]\n",
      " [6.  2.2 5.  1.5 2. ]\n",
      " [6.9 3.2 5.7 2.3 2. ]\n",
      " [5.6 2.8 4.9 2.  2. ]\n",
      " [7.7 2.8 6.7 2.  2. ]\n",
      " [6.3 2.7 4.9 1.8 2. ]\n",
      " [6.7 3.3 5.7 2.1 2. ]\n",
      " [7.2 3.2 6.  1.8 2. ]\n",
      " [6.2 2.8 4.8 1.8 2. ]\n",
      " [6.1 3.  4.9 1.8 2. ]\n",
      " [6.4 2.8 5.6 2.1 2. ]\n",
      " [7.2 3.  5.8 1.6 2. ]\n",
      " [7.4 2.8 6.1 1.9 2. ]\n",
      " [7.9 3.8 6.4 2.  2. ]\n",
      " [6.4 2.8 5.6 2.2 2. ]\n",
      " [6.3 2.8 5.1 1.5 2. ]\n",
      " [6.1 2.6 5.6 1.4 2. ]\n",
      " [7.7 3.  6.1 2.3 2. ]\n",
      " [6.3 3.4 5.6 2.4 2. ]\n",
      " [6.4 3.1 5.5 1.8 2. ]\n",
      " [6.  3.  4.8 1.8 2. ]\n",
      " [6.9 3.1 5.4 2.1 2. ]\n",
      " [6.7 3.1 5.6 2.4 2. ]\n",
      " [6.9 3.1 5.1 2.3 2. ]\n",
      " [5.8 2.7 5.1 1.9 2. ]\n",
      " [6.8 3.2 5.9 2.3 2. ]\n",
      " [6.7 3.3 5.7 2.5 2. ]\n",
      " [6.7 3.  5.2 2.3 2. ]\n",
      " [6.3 2.5 5.  1.9 2. ]\n",
      " [6.5 3.  5.2 2.  2. ]\n",
      " [6.2 3.4 5.4 2.3 2. ]\n",
      " [5.9 3.  5.1 1.8 2. ]]\n"
     ]
    }
   ],
   "source": [
    "classes = [0, 1, 2]\n",
    "bc = datasets.load_iris()\n",
    "a, b = bc.data, bc.target\n",
    "\n",
    "c = numpy.column_stack([a, b])\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def log(x: float)->float:\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return math.log(x, 2)\n",
    "\n",
    "def calcShannonEnt(dataSet):\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts = {}\n",
    "    for featVec in dataSet: # Le nombre d'occurrences pour chaque attribut\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] = 0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    shannonEnt = 0.0\n",
    "    for key in labelCounts:\n",
    "        prob = float(labelCounts[key])/numEntries\n",
    "        shannonEnt -= prob * log(prob) # log base 2\n",
    "    return shannonEnt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calcShannonEnt(a)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def gain(unionSet, subsets):\n",
    "    # input : data and disjoint subsets of it\n",
    "    # output : information gain\n",
    "    S = len(unionSet)\n",
    "    # calculate impurity before split\n",
    "    impurityBeforeSplit = entropy(unionSet)\n",
    "    # calculate impurity after split\n",
    "    weights = [len(subset) / S for subset in subsets]\n",
    "    impurityAfterSplit = 0\n",
    "    for i in range(len(subsets)):\n",
    "        impurityAfterSplit += weights[i] * entropy(subsets[i])\n",
    "    # calculate total gain\n",
    "    totalGain = impurityBeforeSplit - impurityAfterSplit\n",
    "    return totalGain\n",
    "\n",
    "def entropy(dataSet):\n",
    "    S = len(dataSet)\n",
    "    if S == 0:\n",
    "        return 0\n",
    "    num_classes = [0 for i in classes]\n",
    "    for row in dataSet:\n",
    "        classIndex = list(classes).index(row[-1])\n",
    "        num_classes[classIndex] += 1\n",
    "    num_classes = [x / S for x in num_classes]\n",
    "    ent = 0\n",
    "    for num in num_classes:\n",
    "        ent += num * log(num)\n",
    "    return ent * -1\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "entropy(c)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet, axis, value):\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis] # Mettre dehors l'axe utilisé pour la subdivision\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 []\n"
     ]
    }
   ],
   "source": [
    "c = splitDataSet(a,0,'Overcast')\n",
    "print(len(c),c)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "[]"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitDataSet(c,2,'weak')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures = len(dataSet[0]) - 1 # Dernière colonne contient la classe d'appartenance\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGain = 0.0; bestFeature = -1\n",
    "    for i in range(numFeatures): # Pour chaque attribut\n",
    "        featList = [example[i] for example in dataSet] # Liste des valeurs\n",
    "        uniqueVals = set(featList) # Liste des valeurs sans doublons\n",
    "        newEntropy = 0.0\n",
    "        for value in uniqueVals:\n",
    "            subDataSet = splitDataSet(dataSet, i, value)\n",
    "            prob = len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "        infoGain = baseEntropy - newEntropy # Calculer le gain\n",
    "        if (infoGain > bestInfoGain): # Garder le meilleur gain\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature # rang de l'attribut: entier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'extend'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[48], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m ra \u001B[38;5;241m=\u001B[39m \u001B[43mchooseBestFeatureToSplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(ra)\n",
      "Cell \u001B[1;32mIn[47], line 10\u001B[0m, in \u001B[0;36mchooseBestFeatureToSplit\u001B[1;34m(dataSet)\u001B[0m\n\u001B[0;32m      8\u001B[0m newEntropy \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m value \u001B[38;5;129;01min\u001B[39;00m uniqueVals:\n\u001B[1;32m---> 10\u001B[0m     subDataSet \u001B[38;5;241m=\u001B[39m \u001B[43msplitDataSet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataSet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m     prob \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(subDataSet)\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;28mlen\u001B[39m(dataSet))\n\u001B[0;32m     12\u001B[0m     newEntropy \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m prob \u001B[38;5;241m*\u001B[39m calcShannonEnt(subDataSet)\n",
      "Cell \u001B[1;32mIn[44], line 6\u001B[0m, in \u001B[0;36msplitDataSet\u001B[1;34m(dataSet, axis, value)\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m featVec[axis] \u001B[38;5;241m==\u001B[39m value:\n\u001B[0;32m      5\u001B[0m         reducedFeatVec \u001B[38;5;241m=\u001B[39m featVec[:axis] \u001B[38;5;66;03m# Mettre dehors l'axe utilisé pour la subdivision\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m         \u001B[43mreducedFeatVec\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mextend\u001B[49m(featVec[axis\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m:])\n\u001B[0;32m      7\u001B[0m         retDataSet\u001B[38;5;241m.\u001B[39mappend(reducedFeatVec)\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m retDataSet\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'extend'"
     ]
    }
   ],
   "source": [
    "ra = chooseBestFeatureToSplit(a)\n",
    "print(ra)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def splitDataSetNum(dataSet, axis, value, dir):\n",
    "    # dir==0 for <=, 1 for >\n",
    "    retDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if dir == 0:\n",
    "            if featVec[axis] <= value:\n",
    "                reducedFeatVec = featVec[:axis]\n",
    "                reducedFeatVec.extend(featVec[axis+1:])\n",
    "                retDataSet.append(reducedFeatVec)\n",
    "        else:\n",
    "            if featVec[axis] > value:\n",
    "                reducedFeatVec = featVec[:axis]\n",
    "                reducedFeatVec.extend(featVec[axis+1:])\n",
    "                retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet\n",
    "\n",
    "def chooseBestSplitNum(dataSet, labels):\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    bestInfoGain = 0.0; bestFeature = -1; bestSplitDict = {}\n",
    "    for i in range(numFeatures):\n",
    "        featList = [example[i] for example in dataSet]\n",
    "        uniqueVals = set(featList)\n",
    "        newEntropy = 0.0\n",
    "        if isinstance(featList[0], int) or isinstance(featList[0], float):\n",
    "            # Numerical feature\n",
    "            mean = numpy.mean(featList)\n",
    "            if mean == 0:\n",
    "                continue\n",
    "            gain0 = baseEntropy - calcShannonEnt(splitDataSetNum(dataSet, i, mean, 0))\n",
    "            gain1 = baseEntropy - calcShannonEnt(splitDataSetNum(dataSet, i, mean, 1))\n",
    "            if gain0>gain1 and gain0>bestInfoGain:\n",
    "                bestInfoGain = gain0\n",
    "                bestFeature = i\n",
    "                bestSplitDict['index'] = i\n",
    "                bestSplitDict['value'] = mean\n",
    "                bestSplitDict['dir'] = 0 # <=\n",
    "            elif gain1>gain0 and gain1>bestInfoGain:\n",
    "                bestInfoGain = gain1\n",
    "                bestFeature = i\n",
    "                bestSplitDict['index'] = i\n",
    "                bestSplitDict['value'] = mean\n",
    "                bestSplitDict['dir'] = 1 # >\n",
    "        else:\n",
    "            for value in uniqueVals:\n",
    "                subDataSet = splitDataSet(dataSet, i, value)\n",
    "                prob = len(subDataSet)/float(len(dataSet))\n",
    "                newEntropy += prob * calcShannonEnt(subDataSet)\n",
    "            infoGain = baseEntropy - newEntropy # Calculer le gain\n",
    "        if (infoGain > bestInfoGain): # Garder le meilleur gain\n",
    "            bestInfoGain = infoGain\n",
    "            bestFeature = i\n",
    "    return bestFeature, bestSplitDict\n",
    "\n",
    "# Rest same as ID3 algorithm but use splitDataSetNum and chooseBestSplitNum"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[58], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m rc\u001B[38;5;241m=\u001B[39m\u001B[43mchooseBestFeatureToSplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(rc)\n",
      "Cell \u001B[1;32mIn[47], line 2\u001B[0m, in \u001B[0;36mchooseBestFeatureToSplit\u001B[1;34m(dataSet)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mchooseBestFeatureToSplit\u001B[39m(dataSet):\n\u001B[1;32m----> 2\u001B[0m     numFeatures \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[43mdataSet\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m) \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;66;03m# Dernière colonne contient la classe d'appartenance\u001B[39;00m\n\u001B[0;32m      3\u001B[0m     baseEntropy \u001B[38;5;241m=\u001B[39m calcShannonEnt(dataSet)\n\u001B[0;32m      4\u001B[0m     bestInfoGain \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m; bestFeature \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n",
      "\u001B[1;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "rc=chooseBestFeatureToSplit(c)\n",
    "print(rc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "'no'"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def majorityCnt(classList): # Retourner la classe avec la majorité de vote\n",
    "    classCount={}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys(): classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.items(), key=lambda item: item[1], reverse=True)\n",
    "    #print(sortedClassCount)\n",
    "    return sortedClassCount[0][0]\n",
    "majorityCnt(['no','no','no','yes'])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "def createTree(dataSet,labels):\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0] # Arrêter la decomposition (Exemples de la même classe)\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList) # Arrêter s'il ne reste qu'un seul attribut\n",
    "    bestFeat = chooseBestSplitNum(dataSet, labels)\n",
    "    bestFeatLabel = labels[bestFeat]\n",
    "    print(bestFeatLabel)\n",
    "    myTree = {bestFeatLabel:{}} # Initialiser le dictionnaire\n",
    "    del(labels[bestFeat])\n",
    "    featValues = [example[bestFeat] for example in dataSet]\n",
    "    uniqueVals = set(featValues)\n",
    "    for value in uniqueVals:\n",
    "        subLabels = labels.copy() # Copier chaque fois les noms des attributs\n",
    "        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value),subLabels)\n",
    "    return myTree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[61], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m dataSet, labels\u001B[38;5;241m=\u001B[39mcreateDataSet()\n\u001B[1;32m----> 2\u001B[0m tr\u001B[38;5;241m=\u001B[39m\u001B[43mcreateTree\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataSet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(tr)\n",
      "Cell \u001B[1;32mIn[60], line 8\u001B[0m, in \u001B[0;36mcreateTree\u001B[1;34m(dataSet, labels)\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m majorityCnt(classList) \u001B[38;5;66;03m# Arrêter s'il ne reste qu'un seul attribut\u001B[39;00m\n\u001B[0;32m      7\u001B[0m bestFeat \u001B[38;5;241m=\u001B[39m chooseBestSplitNum(dataSet, labels)\n\u001B[1;32m----> 8\u001B[0m bestFeatLabel \u001B[38;5;241m=\u001B[39m \u001B[43mlabels\u001B[49m\u001B[43m[\u001B[49m\u001B[43mbestFeat\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28mprint\u001B[39m(bestFeatLabel)\n\u001B[0;32m     10\u001B[0m myTree \u001B[38;5;241m=\u001B[39m {bestFeatLabel:{}} \u001B[38;5;66;03m# Initialiser le dictionnaire\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "dataSet, labels=createDataSet()\n",
    "tr=createTree(dataSet, labels)\n",
    "print(tr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[54], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m tpl\u001B[38;5;241m.\u001B[39mcreatePlot(\u001B[43mtr\u001B[49m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'tr' is not defined"
     ]
    }
   ],
   "source": [
    "tpl.createPlot(tr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
