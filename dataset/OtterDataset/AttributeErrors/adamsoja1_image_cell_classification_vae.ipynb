{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d02458ea-ae80-48ed-b9f3-b2747232bbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/miniconda3/envs/cells/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils_cells import get_images_list, transform_image, transform_target, resize_with_padding\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import torchvision.transforms.functional as F\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18\n",
    "from torchmetrics import Precision, Recall\n",
    "import numpy as np\n",
    "import datetime\n",
    "import random\n",
    "import time\n",
    "import torchvision.models as models\n",
    "\n",
    "import random\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data_path, transform=None, target_transform=None, reduce=False):\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.dataset = shuffle(self.load_dataset(data_path))\n",
    "\n",
    "    def load_dataset(self, path):\n",
    "        path = []\n",
    "        classes = []\n",
    "        for image_class in os.listdir('cells_final'):\n",
    "            for img in os.listdir(f'cells_final/{image_class}'):\n",
    "                path.append(f'cells_final/{image_class}/{img}')\n",
    "                classes.append(image_class)\n",
    "\n",
    "        dataset_final = pd.DataFrame()\n",
    "        dataset_final['path'] = path\n",
    "        dataset_final['class'] = classes\n",
    "        return dataset_final                \n",
    "                          \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = cv2.imread(f'{self.dataset[\"path\"].loc[idx]}')\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        #image = cv2.resize(image, (32, 32), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        image = resize_with_padding(image, (32, 32))\n",
    "        image = image.astype(np.float32)\n",
    "        image = image/255.0\n",
    "        image = self.transform(image = image)['image'] if self.transform is not None else image\n",
    "\n",
    "        target = self.dataset['class'].loc[idx]\n",
    "\n",
    "        if target.strip() == 'normal':\n",
    "            target_ = [1, 0, 0, 0]\n",
    "        elif target.strip() == 'inflammatory':\n",
    "            target_ = [0, 1, 0, 0]\n",
    "        elif target.strip() == 'tumor':\n",
    "            target_ = [0, 0, 1, 0]\n",
    "        elif target.strip() == 'other':\n",
    "            target_ = [0, 0, 0, 1]\n",
    "        else:\n",
    "            print(target)\n",
    "        \n",
    "        image = F.to_tensor(image)\n",
    "        \n",
    "\n",
    "        return image.float(), torch.Tensor(np.array(target_, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0082330-1335-4321-a3a9-fb6463c20617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as F\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, latent_dim=256):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder_conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),  # [3, 32, 32] -> [32, 32, 32]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),                             # [32, 32, 32] -> [32, 16, 16]\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1), # [32, 16, 16] -> [64, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),                             # [64, 16, 16] -> [64, 8, 8]\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),# [64, 8, 8] -> [128, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),                             # [128, 8, 8] -> [128, 4, 4]\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),# [128, 4, 4] -> [256, 4, 4]\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2)                              # [256, 4, 4] -> [256, 2, 2]\n",
    "        )\n",
    "        \n",
    "        self.fc_mu = nn.Linear(256 * 2 * 2, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(256 * 2 * 2, latent_dim)\n",
    "        self.fc_decode = nn.Linear(latent_dim, 256 * 2 * 2)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_conv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1), # [256, 2, 2] -> [128, 4, 4]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  # [128, 4, 4] -> [64, 8, 8]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),   # [64, 8, 8] -> [32, 16, 16]\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 3, kernel_size=3, stride=2, padding=1, output_padding=1),    # [32, 16, 16] -> [3, 32, 32]\n",
    "            nn.Sigmoid()  # To ensure the output pixel values are between 0 and 1\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder_conv(x)\n",
    "        h = h.view(h.size(0), -1)\n",
    "        mu = self.fc_mu(h)\n",
    "        logvar = self.fc_logvar(h)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = self.fc_decode(z)\n",
    "        h = h.view(h.size(0), 256, 2, 2)\n",
    "        x_reconstructed = self.decoder_conv(h)\n",
    "        return x_reconstructed\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_reconstructed = self.decode(z)\n",
    "        return x_reconstructed, mu, logvar\n",
    "\n",
    "# Example usage\n",
    "model = VAE(latent_dim=256)\n",
    "\n",
    "# Assuming input_images is your batch of images with shape [batch_size, 3, 32, 32]\n",
    "# input_images = ...\n",
    "\n",
    "# Get reconstructed images, mu, and logvar\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# Sample input\n",
    "x = torch.randn(1, 3, 32, 32)\n",
    "reconstructed_img, _ , _ = model(x)\n",
    "\n",
    "print(reconstructed_img.shape)  # Should output torch.Size([1, 3, 32, 32])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e49822e-7d64-42a0-8568-19a61c89334f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b4f8bd1-7fa3-42e4-9ec9-635772b8bb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "EPOCH: 0\n",
      "Epoch 0 Average Loss: 416492.1204324938\n",
      "Saved new best model with loss 416492.1204324938\n",
      "Epoch 0 time: 0.1153156077833349 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 1\n",
      "Epoch 1 Average Loss: 384082.41360445914\n",
      "Saved new best model with loss 384082.41360445914\n",
      "Epoch 1 time: 0.11531722726667036 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 2\n",
      "Epoch 2 Average Loss: 376550.1344188687\n",
      "Saved new best model with loss 376550.1344188687\n",
      "Epoch 2 time: 0.11553437976666979 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 3\n",
      "Epoch 3 Average Loss: 371349.18832576385\n",
      "Saved new best model with loss 371349.18832576385\n",
      "Epoch 3 time: 0.11593330524999601 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 4\n",
      "Epoch 4 Average Loss: 368925.88785094966\n",
      "Saved new best model with loss 368925.88785094966\n",
      "Epoch 4 time: 0.11586450438333032 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 5\n",
      "Epoch 5 Average Loss: 367677.29753303056\n",
      "Saved new best model with loss 367677.29753303056\n",
      "Epoch 5 time: 0.11586596838333207 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 6\n",
      "Epoch 6 Average Loss: 366825.4547120149\n",
      "Saved new best model with loss 366825.4547120149\n",
      "Epoch 6 time: 0.11658585816666497 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 7\n",
      "Epoch 7 Average Loss: 366253.2800371594\n",
      "Saved new best model with loss 366253.2800371594\n",
      "Epoch 7 time: 0.11716573638332951 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 8\n",
      "Epoch 8 Average Loss: 365732.57277043763\n",
      "Saved new best model with loss 365732.57277043763\n",
      "Epoch 8 time: 0.11544476651666476 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 9\n",
      "Epoch 9 Average Loss: 365319.9595375722\n",
      "Saved new best model with loss 365319.9595375722\n",
      "Epoch 9 time: 0.11659988846666541 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 10\n",
      "Epoch 10 Average Loss: 364817.411849711\n",
      "Saved new best model with loss 364817.411849711\n",
      "Epoch 10 time: 0.11693964843332955 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 11\n",
      "Epoch 11 Average Loss: 364343.4093982246\n",
      "Saved new best model with loss 364343.4093982246\n",
      "Epoch 11 time: 0.11639287493333086 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 12\n",
      "Epoch 12 Average Loss: 364284.3633876961\n",
      "Saved new best model with loss 364284.3633876961\n",
      "Epoch 12 time: 0.11694189521666279 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 13\n",
      "Epoch 13 Average Loss: 363925.65947564\n",
      "Saved new best model with loss 363925.65947564\n",
      "Epoch 13 time: 0.11718922879999809 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 14\n",
      "Epoch 14 Average Loss: 363577.3986632948\n",
      "Saved new best model with loss 363577.3986632948\n",
      "Epoch 14 time: 0.11693215314999937 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 15\n",
      "Epoch 15 Average Loss: 363507.7144663501\n",
      "Saved new best model with loss 363507.7144663501\n",
      "Epoch 15 time: 0.11548270239999663 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 16\n",
      "Epoch 16 Average Loss: 363345.49499380676\n",
      "Saved new best model with loss 363345.49499380676\n",
      "Epoch 16 time: 0.11680691716667298 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 17\n",
      "Epoch 17 Average Loss: 363118.47442712635\n",
      "Saved new best model with loss 363118.47442712635\n",
      "Epoch 17 time: 0.11524232758332952 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 18\n",
      "Epoch 18 Average Loss: 363039.27389554086\n",
      "Saved new best model with loss 363039.27389554086\n",
      "Epoch 18 time: 0.11652986530000362 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 19\n",
      "Epoch 19 Average Loss: 362853.81562241947\n",
      "Saved new best model with loss 362853.81562241947\n",
      "Epoch 19 time: 0.11570266534999973 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 20\n",
      "Epoch 20 Average Loss: 363137.82470582164\n",
      "Epoch 20 time: 0.11429860613332797 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 21\n",
      "Epoch 21 Average Loss: 362656.07289946324\n",
      "Saved new best model with loss 362656.07289946324\n",
      "Epoch 21 time: 0.11600101854999896 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 22\n",
      "Epoch 22 Average Loss: 362633.1084589182\n",
      "Saved new best model with loss 362633.1084589182\n",
      "Epoch 22 time: 0.11659508048333009 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 23\n",
      "Epoch 23 Average Loss: 362550.17919075146\n",
      "Saved new best model with loss 362550.17919075146\n",
      "Epoch 23 time: 0.11781599771666909 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 24\n",
      "Epoch 24 Average Loss: 362494.9526992155\n",
      "Saved new best model with loss 362494.9526992155\n",
      "Epoch 24 time: 0.11593147463333177 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 25\n",
      "Epoch 25 Average Loss: 362434.2289688274\n",
      "Saved new best model with loss 362434.2289688274\n",
      "Epoch 25 time: 0.11748188951666332 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 26\n",
      "Epoch 26 Average Loss: 362426.7717279108\n",
      "Saved new best model with loss 362426.7717279108\n",
      "Epoch 26 time: 0.1168335479999996 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 27\n",
      "Epoch 27 Average Loss: 362341.2401682494\n",
      "Saved new best model with loss 362341.2401682494\n",
      "Epoch 27 time: 0.11626650703333326 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 28\n",
      "Epoch 28 Average Loss: 362413.54229459126\n",
      "Epoch 28 time: 0.11488931011666258 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 29\n",
      "Epoch 29 Average Loss: 362230.9003922378\n",
      "Saved new best model with loss 362230.9003922378\n",
      "Epoch 29 time: 0.11672084856666819 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 30\n",
      "Epoch 30 Average Loss: 362240.74687758053\n",
      "Epoch 30 time: 0.11370762276666634 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 31\n",
      "Epoch 31 Average Loss: 362209.4279521057\n",
      "Saved new best model with loss 362209.4279521057\n",
      "Epoch 31 time: 0.11582331285000388 minutes\n",
      "--------------------------------\n",
      "========================================\n",
      "EPOCH: 32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     44\u001b[0m reconstructed_images, mu, logvar \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m---> 45\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreconstructed_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogvar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[5], line 23\u001b[0m, in \u001b[0;36mloss_function\u001b[0;34m(reconstructed_x, x, mu, logvar)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_function\u001b[39m(reconstructed_x, x, mu, logvar):\n\u001b[1;32m     22\u001b[0m     BCE \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(reconstructed_x, x, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m     KLD \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogvar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlogvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BCE \u001b[38;5;241m+\u001b[39m KLD\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Initialize WandB\n",
    "run_name = f'conv_autoencoder_training_{datetime.datetime.now()}'\n",
    "\n",
    "# Configuration\n",
    "batch_size = 256\n",
    "learning_rate = 1e-4\n",
    "num_epochs = 200\n",
    "early_stop_patience = 15  # Number of epochs to wait for improvement\n",
    "run_path = f'training_checkpoints/{run_name}'\n",
    "\n",
    "# DataLoader\n",
    "trainset = ImageDataset(data_path='train_data')\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=3)\n",
    "\n",
    "def loss_function(reconstructed_x, x, mu, logvar):\n",
    "    BCE = torch.nn.functional.binary_cross_entropy(reconstructed_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "    \n",
    "# Model, loss function, optimizer\n",
    "criterion = nn.BCELoss().to('cuda')\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Early Stopping\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('========================================')\n",
    "    print(f'EPOCH: {epoch}')\n",
    "    time_start = time.perf_counter()\n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (inputs, _) in enumerate(trainloader):\n",
    "        inputs = inputs.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        reconstructed_images, mu, logvar = model(inputs)\n",
    "        loss = loss_function(reconstructed_images, inputs, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(trainloader)\n",
    "    print(f'Epoch {epoch} Average Loss: {avg_loss}')\n",
    "    \n",
    "    \n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        torch.save(model.state_dict(), f'{run_path}.pth')\n",
    "        print(f'Saved new best model with loss {best_loss}')\n",
    "        patience_counter = 0  # Reset patience counter\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= early_stop_patience:\n",
    "        print(f'Early stopping at epoch {epoch} with best loss {best_loss}')\n",
    "        break\n",
    "    \n",
    "    time_epoch = time.perf_counter() - time_start\n",
    "    print(f'Epoch {epoch} time: {time_epoch/60} minutes')\n",
    "    print('--------------------------------')\n",
    "\n",
    "# Load the best model state dict\n",
    "print(f'Loading model from {run_path}.pth')\n",
    "model.load_state_dict(torch.load(f'{run_path}.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a081ee83-45bc-4398-a7b1-0c444c5eba3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'{run_path}.pth'))\n",
    "features = []\n",
    "classes = []\n",
    "paths = []\n",
    "model.eval()\n",
    "trainset = ImageDataset(data_path='train_data')\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "model = model.to('cuda')\n",
    "with torch.no_grad():\n",
    "    for idx in range(0, len(trainset)-1):\n",
    "        img, cls = trainset[idx]\n",
    "        classes.append(cls.cpu().detach().numpy())\n",
    "        feature = model.encoder(img.to('cuda').reshape(1, 3, 32, 32))\n",
    "        features.append(feature.cpu().detach().numpy())\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83477d2d-a936-46da-b622-94880b4c3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = np.argmax(np.array(classes), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a12b6f-df9d-4747-bcee-04f543c94f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6dfe3c-4f72-4bb0-b163-59a466ca86e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [feature[0] for feature in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfac9ec-f7a0-4aec-9847-717a25c60334",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1516c03d-97c6-4929-9d6c-74237240cfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3ea9ff-c13d-4a89-a083-555ee70e8877",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# The default of 1,000 iterations gives fine results, but I'm training for longer just to eke\n",
    "# out some marginal improvements. NB: This takes almost an hour!\n",
    "tsne = TSNE(metric=\"euclidean\", n_jobs=-1)\n",
    "\n",
    "embs = tsne.fit_transform(np.array(arr))\n",
    "# Add to dataframe for convenience\n",
    "df['x'] = embs[:, 0]\n",
    "df['y'] = embs[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76277950-70e9-4e9b-bf67-1179ba5279ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_embs = pca.fit_transform(np.array(arr))\n",
    "\n",
    "# Add to dataframe for convenience\n",
    "df['pca_x'] = pca_embs[:, 0]\n",
    "df['pca_y'] = pca_embs[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3affa286-a99a-428d-8c58-3c2e4c1bf36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "# Perform UMAP\n",
    "umap_reducer = umap.UMAP(n_components=2, metric=\"euclidean\", n_jobs=-1)\n",
    "umap_embs = umap_reducer.fit_transform(np.array(arr))\n",
    "\n",
    "# Add to dataframe for convenience\n",
    "df['umap_x'] = umap_embs[:, 0]\n",
    "df['umap_y'] = umap_embs[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6473f996-23b4-476b-a1fb-f9c3de326e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "df['class'] = cls\n",
    "# Define figure size and number of subplots\n",
    "FS = (18, 6)\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=FS)\n",
    "\n",
    "# t-SNE plot\n",
    "sns.scatterplot(ax=axes[0], x='x', y='y', hue='class', data=df, palette='tab10', alpha=0.7)\n",
    "axes[0].set_title('t-SNE')\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('y')\n",
    "\n",
    "# PCA plot\n",
    "sns.scatterplot(ax=axes[1], x='pca_x', y='pca_y', hue='class', data=df, palette='tab10', alpha=0.7)\n",
    "axes[1].set_title('PCA')\n",
    "axes[1].set_xlabel('pca_x')\n",
    "axes[1].set_ylabel('pca_y')\n",
    "\n",
    "# UMAP plot\n",
    "sns.scatterplot(ax=axes[2], x='umap_x', y='umap_y', hue='class', data=df, palette='tab10', alpha=0.7)\n",
    "axes[2].set_title('UMAP')\n",
    "axes[2].set_xlabel('umap_x')\n",
    "axes[2].set_ylabel('umap_y')\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6360bd-17b6-465f-9871-3ebdcddb9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assuming df and cls are already defined\n",
    "df['class'] = cls\n",
    "FS = (18, 6)\n",
    "\n",
    "# Get unique classes\n",
    "unique_classes = df['class'].unique()\n",
    "\n",
    "# Loop through each class and create a separate figure\n",
    "for i, class_label in enumerate(unique_classes):\n",
    "    # Filter the dataframe for the current class\n",
    "    df_class = df[df['class'] == class_label]\n",
    "    \n",
    "    # Create a figure with 4 subplots\n",
    "    fig, axes = plt.subplots(1, 4, figsize=FS)\n",
    "\n",
    "    # t-SNE plot\n",
    "    sns.scatterplot(ax=axes[0], x='x', y='y', hue='class', data=df_class, palette='tab10', alpha=0.7)\n",
    "    axes[0].set_title(f't-SNE (Class {class_label})')\n",
    "    axes[0].set_xlabel('x')\n",
    "    axes[0].set_ylabel('y')\n",
    "\n",
    "    # PCA plot\n",
    "    sns.scatterplot(ax=axes[1], x='pca_x', y='pca_y', hue='class', data=df_class, palette='tab10', alpha=0.7)\n",
    "    axes[1].set_title(f'PCA (Class {class_label})')\n",
    "    axes[1].set_xlabel('pca_x')\n",
    "    axes[1].set_ylabel('pca_y')\n",
    "\n",
    "    # UMAP plot\n",
    "    sns.scatterplot(ax=axes[2], x='umap_x', y='umap_y', hue='class', data=df_class, palette='tab10', alpha=0.7)\n",
    "    axes[2].set_title(f'UMAP (Class {class_label})')\n",
    "    axes[2].set_xlabel('umap_x')\n",
    "    axes[2].set_ylabel('umap_y')\n",
    "\n",
    "    # You can add a fourth plot here if needed\n",
    "\n",
    "    # Adjust layout for better spacing\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aef978-bde9-4ff2-a59c-41438c5c62a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eec5f26-6caa-4ae8-ad02-f471ad483a46",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'albumentations' has no attribute 'set_seed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mA\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_seed\u001b[49m(\u001b[38;5;241m3333\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'albumentations' has no attribute 'set_seed'"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "A.set_seed(3333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77047fd-608d-43c6-8c1d-fc42c598c580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
