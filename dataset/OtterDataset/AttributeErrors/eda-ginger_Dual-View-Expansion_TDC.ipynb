{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-19T03:51:34.219182Z",
     "start_time": "2024-08-19T03:51:16.233530Z"
    }
   },
   "cell_type": "code",
   "source": "# !pip install PyTDC",
   "id": "e6f99ea24e53933e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyTDC\n",
      "  Downloading PyTDC-1.0.6.tar.gz (142 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting biopython<2.0,>=1.78 (from PyTDC)\n",
      "  Downloading biopython-1.83-cp38-cp38-win_amd64.whl.metadata (13 kB)\n",
      "Collecting dataclasses<1.0,>=0.6 (from PyTDC)\n",
      "  Using cached dataclasses-0.6-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting fuzzywuzzy<1.0,>=0.18.0 (from PyTDC)\n",
      "  Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting huggingface_hub<1.0,>=0.20.3 (from PyTDC)\n",
      "  Downloading huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting mygene<4.0.0,>=3.2.2 (from PyTDC)\n",
      "  Using cached mygene-3.2.2-py2.py3-none-any.whl.metadata (10 kB)\n",
      "INFO: pip is looking at multiple versions of pytdc to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting PyTDC\n",
      "  Downloading PyTDC-1.0.5.tar.gz (142 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading PyTDC-1.0.4.tar.gz (151 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading PyTDC-1.0.3.tar.gz (151 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading PyTDC-1.0.2.tar.gz (151 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading PyTDC-1.0.1.tar.gz (147 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading PyTDC-1.0.0.tar.gz (141 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Downloading PyTDC-0.4.17.tar.gz (141 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "INFO: pip is still looking at multiple versions of pytdc to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached PyTDC-0.4.16.tar.gz (137 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting biopython==1.78 (from PyTDC)\n",
      "  Using cached biopython-1.78-cp38-cp38-win_amd64.whl.metadata (12 kB)\n",
      "Collecting huggingface_hub==0.20.3 (from PyTDC)\n",
      "  Using cached huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting PyTDC\n",
      "  Using cached PyTDC-0.4.15.tar.gz (135 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached PyTDC-0.4.14.tar.gz (134 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached PyTDC-0.4.13.tar.gz (134 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting DeepPurpose (from PyTDC)\n",
      "  Using cached DeepPurpose-0.1.5.tar.gz (158 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting descriptastorus (from PyTDC)\n",
      "  Using cached descriptastorus-2.6.1-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting dgl (from PyTDC)\n",
      "  Using cached dgl-2.2.1-cp38-cp38-win_amd64.whl.metadata (595 bytes)\n",
      "Collecting PyTDC\n",
      "  Using cached PyTDC-0.4.12.tar.gz (126 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached PyTDC-0.4.11.tar.gz (126 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached PyTDC-0.4.10.tar.gz (126 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached PyTDC-0.4.9.tar.gz (126 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting descriptastorus==2.4.2 (from PyTDC)\n",
      "  Using cached descriptastorus-2.4.2-py3-none-any.whl.metadata (368 bytes)\n",
      "Collecting PyTDC\n",
      "  Using cached PyTDC-0.4.8.tar.gz (126 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached PyTDC-0.4.7.tar.gz (126 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached PyTDC-0.4.6.tar.gz (119 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached PyTDC-0.4.5.tar.gz (119 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached PyTDC-0.4.4.tar.gz (119 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached PyTDC-0.4.3.tar.gz (115 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached PyTDC-0.4.1-py3-none-any.whl\n",
      "Requirement already satisfied: rdkit-pypi in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from PyTDC) (2022.9.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from PyTDC) (1.24.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from PyTDC) (2.0.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from PyTDC) (4.66.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from PyTDC) (1.3.2)\n",
      "Collecting seaborn (from PyTDC)\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from PyTDC) (2.32.3)\n",
      "Collecting filelock (from huggingface_hub<1.0,>=0.20.3->PyTDC)\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface_hub<1.0,>=0.20.3->PyTDC)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from huggingface_hub<1.0,>=0.20.3->PyTDC) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from huggingface_hub<1.0,>=0.20.3->PyTDC) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from huggingface_hub<1.0,>=0.20.3->PyTDC) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from tqdm->PyTDC) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from pandas->PyTDC) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from pandas->PyTDC) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from pandas->PyTDC) (2024.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from rdkit-pypi->PyTDC) (9.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from requests->PyTDC) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from requests->PyTDC) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from requests->PyTDC) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from requests->PyTDC) (2024.7.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from scikit-learn->PyTDC) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from scikit-learn->PyTDC) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from scikit-learn->PyTDC) (3.5.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from seaborn->PyTDC) (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->PyTDC) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->PyTDC) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->PyTDC) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->PyTDC) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->PyTDC) (3.1.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn->PyTDC) (6.4.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->PyTDC) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\park\\anaconda3\\envs\\gnn_tutorial\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.4->seaborn->PyTDC) (3.20.0)\n",
      "Using cached dataclasses-0.6-py3-none-any.whl (14 kB)\n",
      "Using cached fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Downloading huggingface_hub-0.24.5-py3-none-any.whl (417 kB)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Installing collected packages: fuzzywuzzy, dataclasses, fsspec, filelock, huggingface_hub, seaborn, PyTDC\n",
      "Successfully installed PyTDC-0.4.1 dataclasses-0.6 filelock-3.15.4 fsspec-2024.6.1 fuzzywuzzy-0.18.0 huggingface_hub-0.24.5 seaborn-0.13.2\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-11T04:28:17.956956Z",
     "start_time": "2024-10-11T04:28:16.224420Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tdc.multi_pred import DDI, DTI, PPI\n",
    "from tdc.utils import get_label_map"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DDI",
   "id": "ef7d77d1b62d0574"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T04:28:42.342207Z",
     "start_time": "2024-10-11T04:28:18.227007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dt in ['DrugBank', 'TWOSIDES']:\n",
    "    folder = Path(f'TDC/DDI/{dt}/')\n",
    "    folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    data = DDI(name = dt)\n",
    "    data.get_data().to_csv(folder / 'total.csv', index=False, header=True)\n",
    "\n",
    "    split = data.get_split(frac=[0.7, 0.1, 0.2], seed=42)\n",
    "    for k, v in split.items():\n",
    "        v.to_csv(folder / f\"{k}.csv\", index=False, header=True)\n",
    "    \n",
    "    if dt == 'TWOSIDES':\n",
    "        labels = get_label_map(name = dt, task = 'DDI', name_column = 'Side Effect Name')\n",
    "    else:\n",
    "        labels = get_label_map(name = 'DrugBank', task = 'DDI')\n",
    "    \n",
    "    label_df =pd.DataFrame({'label': labels.keys(), 'description': labels.values()}).sort_values(by='label', ascending=True)\n",
    "    label_df.to_csv(folder / f\"label_description.csv\", index=False, header=True)\n",
    "print('finish')"
   ],
   "id": "13df6824e2f9e10b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DTA",
   "id": "156f9fed3534eb59"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T04:30:16.279878Z",
     "start_time": "2024-10-11T04:28:42.342207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for dt in ['BindingDB_Kd', 'BindingDB_IC50', 'BindingDB_Ki', 'DAVIS', 'KIBA']:\n",
    "    total = False\n",
    "    # if 'BindingDB' in dt:\n",
    "    #     continue\n",
    "    \n",
    "    if 'BindingDB' in dt:\n",
    "        for md in ['raw', 'max_affinity', 'mean']:\n",
    "            data = DTI(name = dt)\n",
    "            if not total:\n",
    "                data.get_data().to_csv(folder / 'total.csv', index=False, header=True)\n",
    "                total = True\n",
    "\n",
    "            if md != 'raw':\n",
    "                data.harmonize_affinities(mode=md)\n",
    "            for sp in ['random', 'cold_split']:\n",
    "                if sp == 'cold_split':\n",
    "                    for c in ['Drug', 'Target']:\n",
    "                        folder = Path(f'TDC/DTA/BindingDB/{dt.split(\"_\")[1]}/{sp}/{c}/{md}')\n",
    "                        folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "                        split = data.get_split(method=sp, column_name=c, frac=[0.7, 0.1, 0.2], seed=42)\n",
    "                        for k, v in split.items():\n",
    "                            v.to_csv(folder / f\"{k}.csv\", index=False, header=True)\n",
    "                else:\n",
    "                    folder = Path(f'TDC/DTA/BindingDB/{dt.split(\"_\")[1]}/{sp}/{md}')\n",
    "                    folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "                    split = data.get_split(frac=[0.7, 0.1, 0.2], seed=42)\n",
    "                    for k, v in split.items():\n",
    "                        v.to_csv(folder / f\"{k}.csv\", index=False, header=True)\n",
    "    \n",
    "    else:            \n",
    "        data = DTI(name = dt)\n",
    "        if dt == 'DAVIS':\n",
    "            data.convert_to_log(form='binding')\n",
    "        \n",
    "        if not total:\n",
    "            data.get_data().to_csv(folder / 'total.csv', index=False, header=True)\n",
    "            total = True\n",
    "\n",
    "        for sp in ['random', 'cold_split']:\n",
    "            if sp == 'cold_split':\n",
    "                for c in ['Drug', 'Target']:\n",
    "                    folder = Path(f'TDC/DTA/{dt}/{sp}/{c}')\n",
    "                    folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "                    split = data.get_split(method=sp, column_name=c, frac=[0.7, 0.1, 0.2], seed=42)\n",
    "                    for k, v in split.items():\n",
    "                        v.to_csv(folder / f\"{k}.csv\", index=False, header=True)\n",
    "            else:\n",
    "                folder = Path(f'TDC/DTA/{dt}/{sp}')\n",
    "                folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "                split = data.get_split(frac=[0.7, 0.1, 0.2], seed=42)\n",
    "                for k, v in split.items():\n",
    "                    v.to_csv(folder / f\"{k}.csv\", index=False, header=True)\n",
    "print('finish')"
   ],
   "id": "4559cbac1c2e9c52",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "The scale is in original affinity scale, so we will take the minimum!\n",
      "The original data has been updated!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "The original data has been updated!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "The scale is in original affinity scale, so we will take the minimum!\n",
      "The original data has been updated!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "The original data has been updated!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "The scale is in original affinity scale, so we will take the minimum!\n",
      "The original data has been updated!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "The original data has been updated!\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "To log space...\n",
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# PPI",
   "id": "5816f607aa75d2d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T04:30:17.624130Z",
     "start_time": "2024-10-11T04:30:16.279878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = PPI(name = 'HuRI')\n",
    "data = data.neg_sample(frac = 1)\n",
    "data.get_data().to_csv(folder / 'total.csv', index=False, header=True)\n",
    "\n",
    "for sp in ['random', 'cold_split']:\n",
    "    if sp == 'cold_split':\n",
    "        for c in ['Protein1', 'Protein2']:\n",
    "            folder = Path(f'TDC/PPI/HuRI/{sp}/{c}')\n",
    "            folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "            split = data.get_split(method=sp, column_name=c, frac=[0.7, 0.1, 0.2], seed=42)\n",
    "            for k, v in split.items():\n",
    "                v.to_csv(folder / f\"{k}.csv\", index=False, header=True)\n",
    "    else:\n",
    "        folder = Path(f'TDC/PPI/HuRI/{sp}')\n",
    "        folder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        split = data.get_split(frac=[0.7, 0.1, 0.2], seed=42)\n",
    "        for k, v in split.items():\n",
    "            v.to_csv(folder / f\"{k}.csv\", index=False, header=True)\n",
    "print('finish')"
   ],
   "id": "4e482d36ec5657e0",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m data \u001B[38;5;241m=\u001B[39m PPI(name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHuRI\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mneg_sample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfrac\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m data\u001B[38;5;241m.\u001B[39mget_data()\u001B[38;5;241m.\u001B[39mto_csv(folder \u001B[38;5;241m/\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtotal.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, header\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m sp \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrandom\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcold_split\u001B[39m\u001B[38;5;124m'\u001B[39m]:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dve\\Lib\\site-packages\\tdc\\multi_pred\\bi_pred_dataset.py:205\u001B[0m, in \u001B[0;36mDataLoader.neg_sample\u001B[1;34m(self, frac)\u001B[0m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mneg_sample\u001B[39m(\u001B[38;5;28mself\u001B[39m, frac\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m    197\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"negative sampling \u001B[39;00m\n\u001B[0;32m    198\u001B[0m \u001B[38;5;124;03m    \u001B[39;00m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    203\u001B[0m \u001B[38;5;124;03m        DataLoader, the class itself. \u001B[39;00m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 205\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mNegSample\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_data\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdf\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    206\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mcolumn_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mentity1_name\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m_ID\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    207\u001B[0m \u001B[43m                                 \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mentity1_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    208\u001B[0m \u001B[43m                                 \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mentity2_name\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m_ID\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    209\u001B[0m \u001B[43m                                 \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mentity2_name\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfrac\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfrac\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtwo_types\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtwo_types\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    210\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentity1_idx \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentity1_name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_ID\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m    211\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentity2_idx \u001B[38;5;241m=\u001B[39m df[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mentity2_name \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_ID\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dve\\Lib\\site-packages\\tdc\\utils\\label.py:193\u001B[0m, in \u001B[0;36mNegSample\u001B[1;34m(df, column_names, frac, two_types)\u001B[0m\n\u001B[0;32m    190\u001B[0m \t\u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m neg_list:\n\u001B[0;32m    191\u001B[0m \t\tneg_list_val\u001B[38;5;241m.\u001B[39mappend([i[\u001B[38;5;241m0\u001B[39m], id2seq[i[\u001B[38;5;241m0\u001B[39m]], i[\u001B[38;5;241m1\u001B[39m], id2seq[i[\u001B[38;5;241m1\u001B[39m]], \u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m--> 193\u001B[0m \tdf \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappend\u001B[49m(pd\u001B[38;5;241m.\u001B[39mDataFrame(neg_list_val)\u001B[38;5;241m.\u001B[39mrename(columns \u001B[38;5;241m=\u001B[39m {\u001B[38;5;241m0\u001B[39m: id1, \u001B[38;5;241m1\u001B[39m: x1, \u001B[38;5;241m2\u001B[39m: id2, \u001B[38;5;241m3\u001B[39m: x2, \u001B[38;5;241m4\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mY\u001B[39m\u001B[38;5;124m'\u001B[39m}))\u001B[38;5;241m.\u001B[39mreset_index(drop \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    194\u001B[0m \t\u001B[38;5;28;01mreturn\u001B[39;00m df\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\dve\\Lib\\site-packages\\pandas\\core\\generic.py:6299\u001B[0m, in \u001B[0;36mNDFrame.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   6292\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   6293\u001B[0m     name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_internal_names_set\n\u001B[0;32m   6294\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_metadata\n\u001B[0;32m   6295\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m name \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_accessors\n\u001B[0;32m   6296\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info_axis\u001B[38;5;241m.\u001B[39m_can_hold_identifiers_and_holds_name(name)\n\u001B[0;32m   6297\u001B[0m ):\n\u001B[0;32m   6298\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m[name]\n\u001B[1;32m-> 6299\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mobject\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattribute__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'append'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T04:30:42.120769Z",
     "start_time": "2024-10-11T04:30:42.117789Z"
    }
   },
   "cell_type": "code",
   "source": "print('All finish')",
   "id": "334a63213c29f333",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All finish\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T03:55:28.205066Z",
     "start_time": "2024-10-09T03:55:28.205066Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9f493197addc099b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T11:56:24.921699Z",
     "start_time": "2024-10-08T11:56:24.907700Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "eddcbfcfcb0014d2",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "9e07441deb7e6669",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e52781ee717eaab2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
