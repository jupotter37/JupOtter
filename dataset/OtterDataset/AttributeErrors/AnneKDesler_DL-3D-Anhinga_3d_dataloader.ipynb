{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "astropy module not found\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import monai\n",
    "import numpy as np\n",
    "import torch\n",
    "from monai.data import DataLoader, Dataset\n",
    "from pathlib import Path\n",
    "from monai.transforms.utils import allow_missing_keys_mode\n",
    "from monai.transforms import BatchInverseTransform\n",
    "from monai.networks.nets import ResNet\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import medpy.metric as metric\n",
    "import os\n",
    "import dxchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2267\n"
     ]
    }
   ],
   "source": [
    "def getBugData(dataset_path: Path):\n",
    "    dataset = []\n",
    "    for idx, item in enumerate(os.listdir(dataset_path)):\n",
    "            one_hot_v = np.zeros(12)\n",
    "            one_hot_v[idx] = 1\n",
    "            if item == \"BC\" or item == \"BF\" or item == \"BL\":\n",
    "                for file in os.listdir(str(dataset_path) + \"/\"+ item):\n",
    "                    # read tif file \n",
    "                    #f = dxchange.read_tiff(str(dataset_path) + \"/\"+ item + \"/\" + file)\n",
    "                    # convert to nii\n",
    "                    #f = nib.Nifti1Image(f, np.eye(4))\n",
    "\n",
    "                    # save as nii.gz\n",
    "                    #nib.save(f, \"/dtu/3d-imaging-center/courses/02510/groups/group_Anhinga/Linea/data_test/\"+ file[:-4] + \".nii.gz\")\n",
    "                    #dataset_path_new = \"/dtu/3d-imaging-center/courses/02510/groups/group_Anhinga/Linea/data_test/\"\n",
    "                    #print(file)\n",
    "                    dataset.append({'image':str(dataset_path) + \"/\"+ item + \"/\" + file,#[:-4] + \".nii.gz\",\n",
    "                                    \"class\": str(item),\n",
    "                                    \"label\": one_hot_v})\n",
    "    return dataset\n",
    "\n",
    "DATA_PATH = \"/dtu/3d-imaging-center/courses/02510/data/Bugs/bugnist_128/\"\n",
    "#Files = [{\"image\": \"/dtu/3d-imaging-center/courses/02510/groups/group_Anhinga/Linea/data_test/image2.nii.gz\", \"label\": \"test\", \"class\": [0]}]\n",
    "\n",
    "# 1. Data. Make a 70-10-20% train-validation-test split here\n",
    "Files = getBugData(dataset_path=Path(DATA_PATH))\n",
    "print(len(Files))\n",
    "#valFiles = getBugData(dataset_path=Path(DATA_PATH))  \n",
    "#testFiles = getBugData(dataset_path=Path(DATA_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 64, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "train_transforms = monai.transforms.Compose([\n",
    "    monai.transforms.LoadImaged(keys='image'),\n",
    "    monai.transforms.EnsureChannelFirstd(keys=['image']),\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "train_dataset = Dataset(data=Files, transform=train_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "#val_dataset = Dataset(data=valFiles, transform=val_transforms)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# 2. Model. Now, use your model to do inference in a few images\n",
    "for i, dummy_data in enumerate(train_loader):\n",
    "    print(dummy_data['image'].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2267\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# More design decisions (model, loss, optimizer) #\u001b[39;00m\n\u001b[1;32m     59\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss() \u001b[38;5;66;03m# Apply \"softmax\" to the output of the network and don't convert to onehot because this is done already by the transforms.\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m) \n\u001b[1;32m     62\u001b[0m inferer \u001b[38;5;241m=\u001b[39m monai\u001b[38;5;241m.\u001b[39minferers\u001b[38;5;241m.\u001b[39mSliceInferer(roi_size\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], spatial_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, sw_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     64\u001b[0m train_losses \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import monai\n",
    "import numpy as np\n",
    "import torch\n",
    "from monai.data import DataLoader, Dataset\n",
    "from pathlib import Path\n",
    "from monai.transforms.utils import allow_missing_keys_mode\n",
    "from monai.transforms import BatchInverseTransform\n",
    "from monai.networks.nets import ResNet\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import medpy.metric as metric\n",
    "import os\n",
    "import dxchange\n",
    "\n",
    "def getBugData(dataset_path: Path):\n",
    "    dataset = []\n",
    "    for idx, item in enumerate(os.listdir(dataset_path)):\n",
    "            one_hot_v = np.zeros(12)\n",
    "            one_hot_v[idx] = 1\n",
    "            if item == \"BC\" or item == \"BF\" or item == \"BL\":\n",
    "                for file in os.listdir(str(dataset_path) + \"/\"+ item):\n",
    "                    dataset.append({'image':str(dataset_path) + \"/\"+ item + \"/\" + file,#[:-4] + \".nii.gz\",\n",
    "                                    \"class\": str(item),\n",
    "                                    \"label\": one_hot_v})\n",
    "    return dataset\n",
    "\n",
    "DATA_PATH = \"/dtu/3d-imaging-center/courses/02510/data/Bugs/bugnist_128/\"\n",
    "\n",
    "# 1. Data. Make a 70-10-20% train-validation-test split here\n",
    "Files = getBugData(dataset_path=Path(DATA_PATH))\n",
    "print(len(Files))\n",
    "#valFiles = getBugData(dataset_path=Path(DATA_PATH))  \n",
    "#testFiles = getBugData(dataset_path=Path(DATA_PATH))\n",
    "\n",
    "train_transforms = monai.transforms.Compose([\n",
    "    monai.transforms.LoadImaged(keys='image'),\n",
    "    monai.transforms.EnsureChannelFirstd(keys=['image']),\n",
    "])\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "train_dataset = Dataset(data=Files, transform=train_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Hyper-parameters (next three lines) #\n",
    "NUM_EPOCHS = 10\n",
    "EVAL_EVERY = 1\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "train_dataset = Dataset(data=Files, transform=train_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_dataset = None\n",
    "val_loader = None\n",
    "\n",
    "model = ResNet(\n",
    "    spatial_dims=3,\n",
    "    in_channels=1,\n",
    "    out_channels=3,\n",
    "    channels=(16, 32, 64, 128, 256),\n",
    "    strides=(2, 2, 2, 2),\n",
    "    num_res_units=2,\n",
    ").cuda()\n",
    "\n",
    "\n",
    "# More design decisions (model, loss, optimizer) #\n",
    "loss_fn = torch.nn.CrossEntropyLoss() # Apply \"softmax\" to the output of the network and don't convert to onehot because this is done already by the transforms.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) \n",
    "\n",
    "inferer = monai.inferers.SliceInferer(roi_size=[-1, -1], spatial_dim=2, sw_batch_size=1)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for tr_data in train_loader:\n",
    "        inputs = tr_data['image'].cuda()\n",
    "        targets = tr_data['label'].cuda()\n",
    "\n",
    "        # Forward -> Backward -> Step\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.detach()\n",
    "        step += 1\n",
    "        \n",
    "    # Log and store average epoch loss\n",
    "    epoch_loss = epoch_loss.item() / step\n",
    "    train_losses.append(epoch_loss)\n",
    "    print(f'Mean training loss: {epoch_loss}')\n",
    "\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    if epoch % EVAL_EVERY == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():  # Do not need gradients for this part\n",
    "            for val_data in val_loader:\n",
    "                inputs = val_data['image'].cuda()\n",
    "                targets = val_data['label'].cuda()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                epoch_loss += loss.detach()\n",
    "                step += 1\n",
    "        \n",
    "        # Log and store average epoch loss\n",
    "        epoch_loss = epoch_loss.item() / step\n",
    "        val_losses.append(epoch_loss)\n",
    "        print(f'Mean validation loss: {epoch_loss}')\n",
    "\n",
    "\n",
    "# Code for the task here\n",
    "# Plot the training loss over time\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot validation dice coefficients over time\n",
    "plt.plot(val_losses, label=['Class 1', 'Class 2', 'Class 3'])\n",
    "plt.title('Validation dice coefficients')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Dice Loss')\n",
    "plt.legend()\n",
    "plt.save(\"/dtu/3d-imaging-center/courses/02510/groups/group_Anhinga/Linea/DL-3D-Anhinga/project/test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
