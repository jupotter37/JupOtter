{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vp_2aGxUJgf6",
    "outputId": "5a408365-bcec-4dc1-c500-e50041a98c6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (4.10.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (from beautifulsoup4) (2.2.1)\n",
      "Requirement already satisfied: Selenium in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (from Selenium) (1.26.7)\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (3.4.2)\n",
      "Requirement already satisfied: crayons in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (from webdriver-manager) (0.4.0)\n",
      "Requirement already satisfied: configparser in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (from webdriver-manager) (5.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (from webdriver-manager) (2.26.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (from crayons->webdriver-manager) (0.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (from requests->webdriver-manager) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (from requests->webdriver-manager) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (from requests->webdriver-manager) (3.2)\n",
      "Requirement already satisfied: html_table_parser in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (0.1.0)\n",
      "Collecting beautifulsoup4==4.4.1\n",
      "  Using cached beautifulsoup4-4.4.1-py3-none-any.whl (81 kB)\n",
      "Installing collected packages: beautifulsoup4\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.10.0\n",
      "    Uninstalling beautifulsoup4-4.10.0:\n",
      "      Successfully uninstalled beautifulsoup4-4.10.0\n",
      "Successfully installed beautifulsoup4-4.4.1\n",
      "Requirement already satisfied: chromedriver-autoinstaller in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (4.4.1)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (from beautifulsoup4) (2.2.1)\n",
      "Installing collected packages: beautifulsoup4\n",
      "  Attempting uninstall: beautifulsoup4\n",
      "    Found existing installation: beautifulsoup4 4.4.1\n",
      "    Uninstalling beautifulsoup4-4.4.1:\n",
      "      Successfully uninstalled beautifulsoup4-4.4.1\n",
      "Successfully installed beautifulsoup4-4.10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "html-table-parser 0.1.0 requires beautifulsoup4==4.4.1, but you have beautifulsoup4 4.10.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: html5lib in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (1.1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (from html5lib) (1.15.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages (from html5lib) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install beautifulsoup4\n",
    "!pip install Selenium\n",
    "!pip install webdriver-manager\n",
    "!pip install html_table_parser\n",
    "!pip install chromedriver-autoinstaller\n",
    "!pip install --upgrade beautifulsoup4\n",
    "!pip install --upgrade html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IbtK_w0jTYCI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from selenium import webdriver \n",
    "from bs4 import BeautifulSoup as bs\n",
    "import time\n",
    "import pandas as pd\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import requests\n",
    "from html_table_parser import parser_functions as parser\n",
    "from urllib.request import urlopen\n",
    "from time import *\n",
    "\n",
    "\n",
    "import chromedriver_autoinstaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "id": "EyGIaLSFUGXa",
    "outputId": "68f28315-c244-4827-c144-57654be07890"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "Trying to download new driver from https://chromedriver.storage.googleapis.com/94.0.4606.61/chromedriver_win32.zip\n",
      "Driver has been saved in cache [C:\\Users\\hongr\\.wdm\\drivers\\chromedriver\\win32\\94.0.4606.61]\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "sleep(5)\n",
    "url = 'https://www.shutterstock.com/ko/search/%EC%BA%90%EB%A6%AD%ED%84%B0?pl=PPC_GOO_KR_IG-264131595792&cr=ec&kw=%EC%A0%80%EC%9E%91%EA%B6%8C%20%EC%97%86%EB%8A%94%20%EC%BA%90%EB%A6%AD%ED%84%B0&c3apidt=p19213837397&gclid=Cj0KCQjwwY-LBhD6ARIsACvT72Pqq67jZau_n_WGvLNYIddV-puPu2HtIGu6-Owqs5oJL9BB218T0N4aAjdgEALw_wcB&gclsrc=aw.ds&image_type=illustration&orientation=vertical&page=2'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-k KEYWORDS] [-kf KEYWORDS_FROM_FILE]\n",
      "                             [-sk SUFFIX_KEYWORDS] [-pk PREFIX_KEYWORDS]\n",
      "                             [-l LIMIT] [-f {jpg,gif,png,bmp,svg,webp,ico}]\n",
      "                             [-u URL] [-x SINGLE_IMAGE] [-o OUTPUT_DIRECTORY]\n",
      "                             [-i IMAGE_DIRECTORY] [-n] [-d DELAY]\n",
      "                             [-co {red,orange,yellow,green,teal,blue,purple,pink,white,gray,black,brown}]\n",
      "                             [-ct {full-color,black-and-white,transparent}]\n",
      "                             [-r {labeled-for-reuse-with-modifications,labeled-for-reuse,labeled-for-noncommercial-reuse-with-modification,labeled-for-nocommercial-reuse}]\n",
      "                             [-s {large,medium,icon,>400*300,>640*480,>800*600,>1024*768,>2MP,>4MP,>6MP,>8MP,>10MP,>12MP,>15MP,>20MP,>40MP,>70MP}]\n",
      "                             [-es EXACT_SIZE]\n",
      "                             [-t {face,photo,clipart,line-drawing,animated}]\n",
      "                             [-w {past-24-hours,past-7-days,past-month,past-year}]\n",
      "                             [-wr TIME_RANGE]\n",
      "                             [-a {tall,square,wide,panoramic}]\n",
      "                             [-si SIMILAR_IMAGES] [-ss SPECIFIC_SITE] [-p]\n",
      "                             [-ps] [-pp] [-m] [-e] [-st SOCKET_TIMEOUT] [-th]\n",
      "                             [-tho]\n",
      "                             [-la {Arabic,Chinese Simplified),Chinese (Traditional,Czech,Danish,Dutch,English,Estonian,Finnish,French,German,Greek,Hebrew,Hungarian,Icelandic,Italian,Japanese,Korean,Latvian,Lithuanian,Norwegian,Portuguese,Polish,Romanian,Russian,Spanish,Swedish,Turkish}]\n",
      "                             [-pr PREFIX] [-px PROXY] [-cd CHROMEDRIVER] [-ri]\n",
      "                             [-sa] [-nn] [-of OFFSET] [-nd] [-iu IGNORE_URLS]\n",
      "                             [-sil] [-is SAVE_SOURCE]\n",
      "ipykernel_launcher.py: error: argument -f/--format: invalid choice: 'C:\\\\Users\\\\hongr\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-8f7fbebf-03e3-485d-a5a3-ec28259b5424.json' (choose from 'jpg', 'gif', 'png', 'bmp', 'svg', 'webp', 'ico')\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hongr\\anaconda3\\envs\\test\\lib\\argparse.py\", line 1853, in parse_known_args\n",
      "    namespace, args = self._parse_known_args(args, namespace)\n",
      "  File \"C:\\Users\\hongr\\anaconda3\\envs\\test\\lib\\argparse.py\", line 2062, in _parse_known_args\n",
      "    start_index = consume_optional(start_index)\n",
      "  File \"C:\\Users\\hongr\\anaconda3\\envs\\test\\lib\\argparse.py\", line 2002, in consume_optional\n",
      "    take_action(action, args, option_string)\n",
      "  File \"C:\\Users\\hongr\\anaconda3\\envs\\test\\lib\\argparse.py\", line 1914, in take_action\n",
      "    argument_values = self._get_values(action, argument_strings)\n",
      "  File \"C:\\Users\\hongr\\anaconda3\\envs\\test\\lib\\argparse.py\", line 2446, in _get_values\n",
      "    self._check_value(action, value)\n",
      "  File \"C:\\Users\\hongr\\anaconda3\\envs\\test\\lib\\argparse.py\", line 2502, in _check_value\n",
      "    raise ArgumentError(action, msg % args)\n",
      "argparse.ArgumentError: argument -f/--format: invalid choice: 'C:\\\\Users\\\\hongr\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-8f7fbebf-03e3-485d-a5a3-ec28259b5424.json' (choose from 'jpg', 'gif', 'png', 'bmp', 'svg', 'webp', 'ico')\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\hongr\\AppData\\Local\\Temp/ipykernel_45808/2488577287.py\", line 1009, in <module>\n",
      "    main()\n",
      "  File \"C:\\Users\\hongr\\AppData\\Local\\Temp/ipykernel_45808/2488577287.py\", line 988, in main\n",
      "    records = user_input()\n",
      "  File \"C:\\Users\\hongr\\AppData\\Local\\Temp/ipykernel_45808/2488577287.py\", line 119, in user_input\n",
      "    args = parser.parse_args()\n",
      "  File \"C:\\Users\\hongr\\anaconda3\\envs\\test\\lib\\argparse.py\", line 1820, in parse_args\n",
      "    args, argv = self.parse_known_args(args, namespace)\n",
      "  File \"C:\\Users\\hongr\\anaconda3\\envs\\test\\lib\\argparse.py\", line 1856, in parse_known_args\n",
      "    self.error(str(err))\n",
      "  File \"C:\\Users\\hongr\\anaconda3\\envs\\test\\lib\\argparse.py\", line 2577, in error\n",
      "    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n",
      "  File \"C:\\Users\\hongr\\anaconda3\\envs\\test\\lib\\argparse.py\", line 2564, in exit\n",
      "    _sys.exit(status)\n",
      "SystemExit: 2\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\hongr\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\hongr\\anaconda3\\envs\\test\\lib\\inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1852\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m                 \u001b[0mnamespace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\argparse.py\u001b[0m in \u001b[0;36m_parse_known_args\u001b[1;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[0;32m   2061\u001b[0m             \u001b[1;31m# consume the next optional and any arguments for it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2062\u001b[1;33m             \u001b[0mstart_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconsume_optional\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2063\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\argparse.py\u001b[0m in \u001b[0;36mconsume_optional\u001b[1;34m(start_index)\u001b[0m\n\u001b[0;32m   2001\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moption_string\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maction_tuples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2002\u001b[1;33m                 \u001b[0mtake_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moption_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2003\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\argparse.py\u001b[0m in \u001b[0;36mtake_action\u001b[1;34m(action, argument_strings, option_string)\u001b[0m\n\u001b[0;32m   1913\u001b[0m             \u001b[0mseen_actions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1914\u001b[1;33m             \u001b[0margument_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margument_strings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\argparse.py\u001b[0m in \u001b[0;36m_get_values\u001b[1;34m(self, action, arg_strings)\u001b[0m\n\u001b[0;32m   2445\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2446\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\argparse.py\u001b[0m in \u001b[0;36m_check_value\u001b[1;34m(self, action, value)\u001b[0m\n\u001b[0;32m   2501\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid choice: %(value)r (choose from %(choices)s)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2502\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mArgumentError\u001b[0m: argument -f/--format: invalid choice: 'C:\\\\Users\\\\hongr\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-8f7fbebf-03e3-485d-a5a3-ec28259b5424.json' (choose from 'jpg', 'gif', 'png', 'bmp', 'svg', 'webp', 'ico')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45808/2488577287.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m   1008\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1009\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1010\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45808/2488577287.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 988\u001b[1;33m     \u001b[0mrecords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    989\u001b[0m     \u001b[0mtotal_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45808/2488577287.py\u001b[0m in \u001b[0;36muser_input\u001b[1;34m()\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[0marguments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1819\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1820\u001b[1;33m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1821\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[1;34m(self, args, namespace)\u001b[0m\n\u001b[0;32m   1855\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1856\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1857\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\argparse.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, message)\u001b[0m\n\u001b[0;32m   2576\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'prog'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'message'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2577\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\argparse.py\u001b[0m in \u001b[0;36mexit\u001b[1;34m(self, status, message)\u001b[0m\n\u001b[0;32m   2563\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2564\u001b[1;33m         \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2052\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[0;32m   2053\u001b[0m                            'the full traceback.\\n']\n\u001b[1;32m-> 2054\u001b[1;33m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[0;32m   2055\u001b[0m                                                                      value))\n\u001b[0;32m   2056\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \"\"\"\n\u001b[1;32m--> 754\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m             out_list = (\n\u001b[1;32m--> 629\u001b[1;33m                 self.structured_traceback(\n\u001b[0m\u001b[0;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0metb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# In[ ]:\n",
    "#  coding: utf-8\n",
    "\n",
    "###### Searching and Downloading Google Images to the local disk ######\n",
    "\n",
    "# Import Libraries\n",
    "import sys\n",
    "version = (3, 0)\n",
    "cur_version = sys.version_info\n",
    "if cur_version >= version:  # If the Current Version of Python is 3.0 or above\n",
    "    import urllib.request\n",
    "    from urllib.request import Request, urlopen\n",
    "    from urllib.request import URLError, HTTPError\n",
    "    from urllib.parse import quote\n",
    "    import http.client\n",
    "    from http.client import IncompleteRead, BadStatusLine\n",
    "    http.client._MAXHEADERS = 1000\n",
    "else:  # If the Current Version of Python is 2.x\n",
    "    import urllib2\n",
    "    from urllib2 import Request, urlopen\n",
    "    from urllib2 import URLError, HTTPError\n",
    "    from urllib import quote\n",
    "    import httplib\n",
    "    from httplib import IncompleteRead, BadStatusLine\n",
    "    httplib._MAXHEADERS = 1000\n",
    "import time  # Importing the time library to check the time of code execution\n",
    "import os\n",
    "import argparse\n",
    "import ssl\n",
    "import datetime\n",
    "import json\n",
    "import re\n",
    "import codecs\n",
    "import socket\n",
    "\n",
    "args_list = [\"keywor\", \"keywords_from_file\", \"prefix_keywords\", \"suffix_keywords\",\n",
    "             \"limit\", \"format\", \"color\", \"color_type\", \"usage_rights\", \"size\",\n",
    "             \"exact_size\", \"aspect_ratio\", \"type\", \"time\", \"time_range\", \"delay\", \"url\", \"single_image\",\n",
    "             \"output_directory\", \"image_directory\", \"no_directory\", \"proxy\", \"similar_images\", \"specific_site\",\n",
    "             \"print_urls\", \"print_size\", \"print_paths\", \"metadata\", \"extract_metadata\", \"socket_timeout\",\n",
    "             \"thumbnail\", \"thumbnail_only\", \"language\", \"prefix\", \"chromedriver\", \"related_images\", \"safe_search\", \"no_numbering\",\n",
    "             \"offset\", \"no_download\",\"save_source\",\"silent_mode\",\"ignore_urls\"]\n",
    "\n",
    "\n",
    "def user_input():\n",
    "    config = argparse.ArgumentParser()\n",
    "    config.add_argument('-cf', '--config_file', help='config file name', default='', type=str, required=False)\n",
    "    config_file_check = config.parse_known_args()\n",
    "    object_check = vars(config_file_check[0])\n",
    "\n",
    "    if object_check['config_file'] != '':\n",
    "        records = []\n",
    "        json_file = json.load(open(config_file_check[0].config_file))\n",
    "        for record in range(0,len(json_file['Records'])):\n",
    "            arguments = {}\n",
    "            for i in args_list:\n",
    "                arguments[i] = None\n",
    "            for key, value in json_file['Records'][record].items():\n",
    "                arguments[key] = value\n",
    "            records.append(arguments)\n",
    "        records_count = len(records)\n",
    "    else:\n",
    "        # Taking command line arguments from users\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('-k', '--keywords', help='delimited list input', type=str, required=False)\n",
    "        parser.add_argument('-kf', '--keywords_from_file', help='extract list of keywords from a text file', type=str, required=False)\n",
    "        parser.add_argument('-sk', '--suffix_keywords', help='comma separated additional words added after to main keyword', type=str, required=False)\n",
    "        parser.add_argument('-pk', '--prefix_keywords', help='comma separated additional words added before main keyword', type=str, required=False)\n",
    "        parser.add_argument('-l', '--limit', help='delimited list input', type=str, required=False)\n",
    "        parser.add_argument('-f', '--format', help='download images with specific format', type=str, required=False,\n",
    "                            choices=['jpg', 'gif', 'png', 'bmp', 'svg', 'webp', 'ico'])\n",
    "        parser.add_argument('-u', '--url', help='search with google image URL', type=str, required=False)\n",
    "        parser.add_argument('-x', '--single_image', help='downloading a single image from URL', type=str, required=False)\n",
    "        parser.add_argument('-o', '--output_directory', help='download images in a specific main directory', type=str, required=False)\n",
    "        parser.add_argument('-i', '--image_directory', help='download images in a specific sub-directory', type=str, required=False)\n",
    "        parser.add_argument('-n', '--no_directory', default=False, help='download images in the main directory but no sub-directory', action=\"store_true\")\n",
    "        parser.add_argument('-d', '--delay', help='delay in seconds to wait between downloading two images', type=int, required=False)\n",
    "        parser.add_argument('-co', '--color', help='filter on color', type=str, required=False,\n",
    "                            choices=['red', 'orange', 'yellow', 'green', 'teal', 'blue', 'purple', 'pink', 'white', 'gray', 'black', 'brown'])\n",
    "        parser.add_argument('-ct', '--color_type', help='filter on color', type=str, required=False,\n",
    "                            choices=['full-color', 'black-and-white', 'transparent'])\n",
    "        parser.add_argument('-r', '--usage_rights', help='usage rights', type=str, required=False,\n",
    "                            choices=['labeled-for-reuse-with-modifications','labeled-for-reuse','labeled-for-noncommercial-reuse-with-modification','labeled-for-nocommercial-reuse'])\n",
    "        parser.add_argument('-s', '--size', help='image size', type=str, required=False,\n",
    "                            choices=['large','medium','icon','>400*300','>640*480','>800*600','>1024*768','>2MP','>4MP','>6MP','>8MP','>10MP','>12MP','>15MP','>20MP','>40MP','>70MP'])\n",
    "        parser.add_argument('-es', '--exact_size', help='exact image resolution \"WIDTH,HEIGHT\"', type=str, required=False)\n",
    "        parser.add_argument('-t', '--type', help='image type', type=str, required=False,\n",
    "                            choices=['face','photo','clipart','line-drawing','animated'])\n",
    "        parser.add_argument('-w', '--time', help='image age', type=str, required=False,\n",
    "                            choices=['past-24-hours','past-7-days','past-month','past-year'])\n",
    "        parser.add_argument('-wr', '--time_range', help='time range for the age of the image. should be in the format {\"time_min\":\"MM/DD/YYYY\",\"time_max\":\"MM/DD/YYYY\"}', type=str, required=False)\n",
    "        parser.add_argument('-a', '--aspect_ratio', help='comma separated additional words added to keywords', type=str, required=False,\n",
    "                            choices=['tall', 'square', 'wide', 'panoramic'])\n",
    "        parser.add_argument('-si', '--similar_images', help='downloads images very similar to the image URL you provide', type=str, required=False)\n",
    "        parser.add_argument('-ss', '--specific_site', help='downloads images that are indexed from a specific website', type=str, required=False)\n",
    "        parser.add_argument('-p', '--print_urls', default=False, help=\"Print the URLs of the images\", action=\"store_true\")\n",
    "        parser.add_argument('-ps', '--print_size', default=False, help=\"Print the size of the images on disk\", action=\"store_true\")\n",
    "        parser.add_argument('-pp', '--print_paths', default=False, help=\"Prints the list of absolute paths of the images\",action=\"store_true\")\n",
    "        parser.add_argument('-m', '--metadata', default=False, help=\"Print the metadata of the image\", action=\"store_true\")\n",
    "        parser.add_argument('-e', '--extract_metadata', default=False, help=\"Dumps all the logs into a text file\", action=\"store_true\")\n",
    "        parser.add_argument('-st', '--socket_timeout', default=False, help=\"Connection timeout waiting for the image to download\", type=float)\n",
    "        parser.add_argument('-th', '--thumbnail', default=False, help=\"Downloads image thumbnail along with the actual image\", action=\"store_true\")\n",
    "        parser.add_argument('-tho', '--thumbnail_only', default=False, help=\"Downloads only thumbnail without downloading actual images\", action=\"store_true\")\n",
    "        parser.add_argument('-la', '--language', default=False, help=\"Defines the language filter. The search results are authomatically returned in that language\", type=str, required=False,\n",
    "                            choices=['Arabic','Chinese (Simplified)','Chinese (Traditional)','Czech','Danish','Dutch','English','Estonian','Finnish','French','German','Greek','Hebrew','Hungarian','Icelandic','Italian','Japanese','Korean','Latvian','Lithuanian','Norwegian','Portuguese','Polish','Romanian','Russian','Spanish','Swedish','Turkish'])\n",
    "        parser.add_argument('-pr', '--prefix', default=False, help=\"A word that you would want to prefix in front of each image name\", type=str, required=False)\n",
    "        parser.add_argument('-px', '--proxy', help='specify a proxy address and port', type=str, required=False)\n",
    "        parser.add_argument('-cd', '--chromedriver', help='specify the path to chromedriver executable in your local machine', type=str, required=False)\n",
    "        parser.add_argument('-ri', '--related_images', default=False, help=\"Downloads images that are similar to the keyword provided\", action=\"store_true\")\n",
    "        parser.add_argument('-sa', '--safe_search', default=False, help=\"Turns on the safe search filter while searching for images\", action=\"store_true\")\n",
    "        parser.add_argument('-nn', '--no_numbering', default=False, help=\"Allows you to exclude the default numbering of images\", action=\"store_true\")\n",
    "        parser.add_argument('-of', '--offset', help=\"Where to start in the fetched links\", type=str, required=False)\n",
    "        parser.add_argument('-nd', '--no_download', default=False, help=\"Prints the URLs of the images and/or thumbnails without downloading them\", action=\"store_true\")\n",
    "        parser.add_argument('-iu', '--ignore_urls', default=False, help=\"delimited list input of image urls/keywords to ignore\", type=str)\n",
    "        parser.add_argument('-sil', '--silent_mode', default=False, help=\"Remains silent. Does not print notification messages on the terminal\", action=\"store_true\")\n",
    "        parser.add_argument('-is', '--save_source', help=\"creates a text file containing a list of downloaded images along with source page url\", type=str, required=False)\n",
    "\n",
    "        args = parser.parse_args()\n",
    "        arguments = vars(args)\n",
    "        records = []\n",
    "        records.append(arguments)\n",
    "    return records\n",
    "\n",
    "\n",
    "class googleimagesdownload:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # Downloading entire Web Document (Raw Page Content)\n",
    "    def download_page(self,url):\n",
    "        version = (3, 0)\n",
    "        cur_version = sys.version_info\n",
    "        if cur_version >= version:  # If the Current Version of Python is 3.0 or above\n",
    "            try:\n",
    "                headers = {}\n",
    "                headers['User-Agent'] = \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36\"\n",
    "                req = urllib.request.Request(url, headers=headers)\n",
    "                resp = urllib.request.urlopen(req)\n",
    "                respData = str(resp.read())\n",
    "                return respData\n",
    "            except Exception as e:\n",
    "                print(\"Could not open URL. Please check your internet connection and/or ssl settings \\n\"\n",
    "                      \"If you are using proxy, make sure your proxy settings is configured correctly\")\n",
    "                sys.exit()\n",
    "        else:  # If the Current Version of Python is 2.x\n",
    "            try:\n",
    "                headers = {}\n",
    "                headers['User-Agent'] = \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.27 Safari/537.17\"\n",
    "                req = urllib2.Request(url, headers=headers)\n",
    "                try:\n",
    "                    response = urllib2.urlopen(req)\n",
    "                except URLError:  # Handling SSL certificate failed\n",
    "                    context = ssl._create_unverified_context()\n",
    "                    response = urlopen(req, context=context)\n",
    "                page = response.read()\n",
    "                return page\n",
    "            except:\n",
    "                print(\"Could not open URL. Please check your internet connection and/or ssl settings \\n\"\n",
    "                      \"If you are using proxy, make sure your proxy settings is configured correctly\")\n",
    "                sys.exit()\n",
    "                return \"Page Not found\"\n",
    "\n",
    "\n",
    "    # Download Page for more than 100 images\n",
    "    def download_extended_page(self,url,chromedriver):\n",
    "        from selenium import webdriver\n",
    "        from selenium.webdriver.common.keys import Keys\n",
    "        if sys.version_info[0] < 3:\n",
    "            reload(sys)\n",
    "            sys.setdefaultencoding('utf8')\n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument('--no-sandbox')\n",
    "        options.add_argument(\"--headless\")\n",
    "\n",
    "        try:\n",
    "            browser = webdriver.Chrome(chromedriver, chrome_options=options)\n",
    "        except Exception as e:\n",
    "            print(\"Looks like we cannot locate the path the 'chromedriver' (use the '--chromedriver' \"\n",
    "                  \"argument to specify the path to the executable.) or google chrome browser is not \"\n",
    "                  \"installed on your machine (exception: %s)\" % e)\n",
    "            sys.exit()\n",
    "        browser.set_window_size(1024, 768)\n",
    "\n",
    "        # Open the link\n",
    "        browser.get(url)\n",
    "        time.sleep(1)\n",
    "        print(\"Getting you a lot of images. This may take a few moments...\")\n",
    "\n",
    "        element = browser.find_element_by_tag_name(\"body\")\n",
    "        # Scroll down\n",
    "        for i in range(30):\n",
    "            element.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(0.3)\n",
    "\n",
    "        try:\n",
    "            browser.find_element_by_id(\"smb\").click()\n",
    "            for i in range(50):\n",
    "                element.send_keys(Keys.PAGE_DOWN)\n",
    "                time.sleep(0.3)  # bot id protection\n",
    "        except:\n",
    "            for i in range(10):\n",
    "                element.send_keys(Keys.PAGE_DOWN)\n",
    "                time.sleep(0.3)  # bot id protection\n",
    "\n",
    "        print(\"Reached end of Page.\")\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        source = browser.page_source #page source\n",
    "        #close the browser\n",
    "        browser.close()\n",
    "\n",
    "        return source\n",
    "\n",
    "\n",
    "    #Correcting the escape characters for python2\n",
    "    def replace_with_byte(self,match):\n",
    "        return chr(int(match.group(0)[1:], 8))\n",
    "\n",
    "    def repair(self,brokenjson):\n",
    "        invalid_escape = re.compile(r'\\\\[0-7]{1,3}')  # up to 3 digits for byte values up to FF\n",
    "        return invalid_escape.sub(self.replace_with_byte, brokenjson)\n",
    "\n",
    "\n",
    "    # Finding 'Next Image' from the given raw page\n",
    "    def get_next_tab(self,s):\n",
    "        start_line = s.find('class=\"dtviD\"')\n",
    "        if start_line == -1:  # If no links are found then give an error!\n",
    "            end_quote = 0\n",
    "            link = \"no_tabs\"\n",
    "            return link,'',end_quote\n",
    "        else:\n",
    "            start_line = s.find('class=\"dtviD\"')\n",
    "            start_content = s.find('href=\"', start_line + 1)\n",
    "            end_content = s.find('\">', start_content + 1)\n",
    "            url_item = \"https://www.google.com\" + str(s[start_content + 6:end_content])\n",
    "            url_item = url_item.replace('&amp;', '&')\n",
    "\n",
    "            start_line_2 = s.find('class=\"dtviD\"')\n",
    "            s = s.replace('&amp;', '&')\n",
    "            start_content_2 = s.find(':', start_line_2 + 1)\n",
    "            end_content_2 = s.find('&usg=', start_content_2 + 1)\n",
    "            url_item_name = str(s[start_content_2 + 1:end_content_2])\n",
    "\n",
    "            chars = url_item_name.find(',g_1:')\n",
    "            chars_end = url_item_name.find(\":\", chars + 6)\n",
    "            if chars_end == -1:\n",
    "                updated_item_name = (url_item_name[chars + 5:]).replace(\"+\", \" \")\n",
    "            else:\n",
    "                updated_item_name = (url_item_name[chars+5:chars_end]).replace(\"+\", \" \")\n",
    "\n",
    "            return url_item, updated_item_name, end_content\n",
    "\n",
    "\n",
    "    # Getting all links with the help of '_images_get_next_image'\n",
    "    def get_all_tabs(self,page):\n",
    "        tabs = {}\n",
    "        while True:\n",
    "            item,item_name,end_content = self.get_next_tab(page)\n",
    "            if item == \"no_tabs\":\n",
    "                break\n",
    "            else:\n",
    "                if len(item_name) > 100 or item_name == \"background-color\":\n",
    "                    break\n",
    "                else:\n",
    "                    tabs[item_name] = item  # Append all the links in the list named 'Links'\n",
    "                    time.sleep(0.1)  # Timer could be used to slow down the request for image downloads\n",
    "                    page = page[end_content:]\n",
    "        return tabs\n",
    "\n",
    "\n",
    "    #Format the object in readable format\n",
    "    def format_object(self,object):\n",
    "        formatted_object = {}\n",
    "        formatted_object['image_format'] = object['ity']\n",
    "        formatted_object['image_height'] = object['oh']\n",
    "        formatted_object['image_width'] = object['ow']\n",
    "        formatted_object['image_link'] = object['ou']\n",
    "        formatted_object['image_description'] = object['pt']\n",
    "        formatted_object['image_host'] = object['rh']\n",
    "        formatted_object['image_source'] = object['ru']\n",
    "        formatted_object['image_thumbnail_url'] = object['tu']\n",
    "        return formatted_object\n",
    "\n",
    "\n",
    "    #function to download single image\n",
    "    def single_image(self,image_url):\n",
    "        main_directory = \"downloads\"\n",
    "        extensions = (\".jpg\", \".gif\", \".png\", \".bmp\", \".svg\", \".webp\", \".ico\")\n",
    "        url = image_url\n",
    "        try:\n",
    "            os.makedirs(main_directory)\n",
    "        except OSError as e:\n",
    "            if e.errno != 17:\n",
    "                raise\n",
    "            pass\n",
    "        req = Request(url, headers={\n",
    "            \"User-Agent\": \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.27 Safari/537.17\"})\n",
    "\n",
    "        response = urlopen(req, None, 10)\n",
    "        data = response.read()\n",
    "        response.close()\n",
    "\n",
    "        image_name = str(url[(url.rfind('/')) + 1:])\n",
    "        if '?' in image_name:\n",
    "            image_name = image_name[:image_name.find('?')]\n",
    "        # if \".jpg\" in image_name or \".gif\" in image_name or \".png\" in image_name or \".bmp\" in image_name or \".svg\" in image_name or \".webp\" in image_name or \".ico\" in image_name:\n",
    "        if any(map(lambda extension: extension in image_name, extensions)):\n",
    "            file_name = main_directory + \"/\" + image_name\n",
    "        else:\n",
    "            file_name = main_directory + \"/\" + image_name + \".jpg\"\n",
    "            image_name = image_name + \".jpg\"\n",
    "\n",
    "        try:\n",
    "            output_file = open(file_name, 'wb')\n",
    "            output_file.write(data)\n",
    "            output_file.close()\n",
    "        except IOError as e:\n",
    "            raise e\n",
    "        except OSError as e:\n",
    "            raise e\n",
    "        print(\"completed ====> \" + image_name.encode('raw_unicode_escape').decode('utf-8'))\n",
    "        return\n",
    "\n",
    "    def similar_images(self,similar_images):\n",
    "        version = (3, 0)\n",
    "        cur_version = sys.version_info\n",
    "        if cur_version >= version:  # If the Current Version of Python is 3.0 or above\n",
    "            try:\n",
    "                searchUrl = 'https://www.google.com/searchbyimage?site=search&sa=X&image_url=' + similar_images\n",
    "                headers = {}\n",
    "                headers['User-Agent'] = \"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36\"\n",
    "\n",
    "                req1 = urllib.request.Request(searchUrl, headers=headers)\n",
    "                resp1 = urllib.request.urlopen(req1)\n",
    "                content = str(resp1.read())\n",
    "                l1 = content.find('AMhZZ')\n",
    "                l2 = content.find('&', l1)\n",
    "                urll = content[l1:l2]\n",
    "\n",
    "                newurl = \"https://www.google.com/search?tbs=sbi:\" + urll + \"&site=search&sa=X\"\n",
    "                req2 = urllib.request.Request(newurl, headers=headers)\n",
    "                resp2 = urllib.request.urlopen(req2)\n",
    "                l3 = content.find('/search?sa=X&amp;q=')\n",
    "                l4 = content.find(';', l3 + 19)\n",
    "                urll2 = content[l3 + 19:l4]\n",
    "                return urll2\n",
    "            except:\n",
    "                return \"Cloud not connect to Google Images endpoint\"\n",
    "        else:  # If the Current Version of Python is 2.x\n",
    "            try:\n",
    "                searchUrl = 'https://www.google.com/searchbyimage?site=search&sa=X&image_url=' + similar_images\n",
    "                headers = {}\n",
    "                headers['User-Agent'] = \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.27 Safari/537.17\"\n",
    "\n",
    "                req1 = urllib2.Request(searchUrl, headers=headers)\n",
    "                resp1 = urllib2.urlopen(req1)\n",
    "                content = str(resp1.read())\n",
    "                l1 = content.find('AMhZZ')\n",
    "                l2 = content.find('&', l1)\n",
    "                urll = content[l1:l2]\n",
    "\n",
    "                newurl = \"https://www.google.com/search?tbs=sbi:\" + urll + \"&site=search&sa=X\"\n",
    "                req2 = urllib2.Request(newurl, headers=headers)\n",
    "                resp2 = urllib2.urlopen(req2)\n",
    "                l3 = content.find('/search?sa=X&amp;q=')\n",
    "                l4 = content.find(';', l3 + 19)\n",
    "                urll2 = content[l3 + 19:l4]\n",
    "                return(urll2)\n",
    "            except:\n",
    "                return \"Cloud not connect to Google Images endpoint\"\n",
    "\n",
    "    #Building URL parameters\n",
    "    def build_url_parameters(self,arguments):\n",
    "        if arguments['language']:\n",
    "            lang = \"&lr=\"\n",
    "            lang_param = {\"Arabic\":\"lang_ar\",\"Chinese (Simplified)\":\"lang_zh-CN\",\"Chinese (Traditional)\":\"lang_zh-TW\",\"Czech\":\"lang_cs\",\"Danish\":\"lang_da\",\"Dutch\":\"lang_nl\",\"English\":\"lang_en\",\"Estonian\":\"lang_et\",\"Finnish\":\"lang_fi\",\"French\":\"lang_fr\",\"German\":\"lang_de\",\"Greek\":\"lang_el\",\"Hebrew\":\"lang_iw \",\"Hungarian\":\"lang_hu\",\"Icelandic\":\"lang_is\",\"Italian\":\"lang_it\",\"Japanese\":\"lang_ja\",\"Korean\":\"lang_ko\",\"Latvian\":\"lang_lv\",\"Lithuanian\":\"lang_lt\",\"Norwegian\":\"lang_no\",\"Portuguese\":\"lang_pt\",\"Polish\":\"lang_pl\",\"Romanian\":\"lang_ro\",\"Russian\":\"lang_ru\",\"Spanish\":\"lang_es\",\"Swedish\":\"lang_sv\",\"Turkish\":\"lang_tr\"}\n",
    "            lang_url = lang+lang_param[arguments['language']]\n",
    "        else:\n",
    "            lang_url = ''\n",
    "\n",
    "        if arguments['time_range']:\n",
    "            json_acceptable_string = arguments['time_range'].replace(\"'\", \"\\\"\")\n",
    "            d = json.loads(json_acceptable_string)\n",
    "            time_range = ',cdr:1,cd_min:' + d['time_min'] + ',cd_max:' + d['time_max']\n",
    "        else:\n",
    "            time_range = ''\n",
    "\n",
    "        if arguments['exact_size']:\n",
    "            size_array = [x.strip() for x in arguments['exact_size'].split(',')]\n",
    "            exact_size = \",isz:ex,iszw:\" + str(size_array[0]) + \",iszh:\" + str(size_array[1])\n",
    "        else:\n",
    "            exact_size = ''\n",
    "\n",
    "        built_url = \"&tbs=\"\n",
    "        counter = 0\n",
    "        params = {'color':[arguments['color'],{'red':'ic:specific,isc:red', 'orange':'ic:specific,isc:orange', 'yellow':'ic:specific,isc:yellow', 'green':'ic:specific,isc:green', 'teal':'ic:specific,isc:teel', 'blue':'ic:specific,isc:blue', 'purple':'ic:specific,isc:purple', 'pink':'ic:specific,isc:pink', 'white':'ic:specific,isc:white', 'gray':'ic:specific,isc:gray', 'black':'ic:specific,isc:black', 'brown':'ic:specific,isc:brown'}],\n",
    "                  'color_type':[arguments['color_type'],{'full-color':'ic:color', 'black-and-white':'ic:gray','transparent':'ic:trans'}],\n",
    "                  'usage_rights':[arguments['usage_rights'],{'labeled-for-reuse-with-modifications':'sur:fmc','labeled-for-reuse':'sur:fc','labeled-for-noncommercial-reuse-with-modification':'sur:fm','labeled-for-nocommercial-reuse':'sur:f'}],\n",
    "                  'size':[arguments['size'],{'large':'isz:l','medium':'isz:m','icon':'isz:i','>400*300':'isz:lt,islt:qsvga','>640*480':'isz:lt,islt:vga','>800*600':'isz:lt,islt:svga','>1024*768':'visz:lt,islt:xga','>2MP':'isz:lt,islt:2mp','>4MP':'isz:lt,islt:4mp','>6MP':'isz:lt,islt:6mp','>8MP':'isz:lt,islt:8mp','>10MP':'isz:lt,islt:10mp','>12MP':'isz:lt,islt:12mp','>15MP':'isz:lt,islt:15mp','>20MP':'isz:lt,islt:20mp','>40MP':'isz:lt,islt:40mp','>70MP':'isz:lt,islt:70mp'}],\n",
    "                  'type':[arguments['type'],{'face':'itp:face','photo':'itp:photo','clipart':'itp:clipart','line-drawing':'itp:lineart','animated':'itp:animated'}],\n",
    "                  'time':[arguments['time'],{'past-24-hours':'qdr:d','past-7-days':'qdr:w','past-month':'qdr:m','past-year':'qdr:y'}],\n",
    "                  'aspect_ratio':[arguments['aspect_ratio'],{'tall':'iar:t','square':'iar:s','wide':'iar:w','panoramic':'iar:xw'}],\n",
    "                  'format':[arguments['format'],{'jpg':'ift:jpg','gif':'ift:gif','png':'ift:png','bmp':'ift:bmp','svg':'ift:svg','webp':'webp','ico':'ift:ico','raw':'ift:craw'}]}\n",
    "        for key, value in params.items():\n",
    "            if value[0] is not None:\n",
    "                ext_param = value[1][value[0]]\n",
    "                # counter will tell if it is first param added or not\n",
    "                if counter == 0:\n",
    "                    # add it to the built url\n",
    "                    built_url = built_url + ext_param\n",
    "                    counter += 1\n",
    "                else:\n",
    "                    built_url = built_url + ',' + ext_param\n",
    "                    counter += 1\n",
    "        built_url = lang_url+built_url+exact_size+time_range\n",
    "        return built_url\n",
    "\n",
    "\n",
    "    #building main search URL\n",
    "    def build_search_url(self,search_term,params,url,similar_images,specific_site,safe_search):\n",
    "        #check safe_search\n",
    "        safe_search_string = \"&safe=active\"\n",
    "        # check the args and choose the URL\n",
    "        if url:\n",
    "            url = url\n",
    "        elif similar_images:\n",
    "            print(similar_images)\n",
    "            keywordem = self.similar_images(similar_images)\n",
    "            url = 'https://www.google.com/search?q=' + keywordem + '&espv=2&biw=1366&bih=667&site=webhp&source=lnms&tbm=isch&sa=X&ei=XosDVaCXD8TasATItgE&ved=0CAcQ_AUoAg'\n",
    "        elif specific_site:\n",
    "            url = 'https://www.google.com/search?q=' + quote(\n",
    "                search_term.encode('utf-8')) + '&as_sitesearch=' + specific_site + '&espv=2&biw=1366&bih=667&site=webhp&source=lnms&tbm=isch' + params + '&sa=X&ei=XosDVaCXD8TasATItgE&ved=0CAcQ_AUoAg'\n",
    "        else:\n",
    "            url = 'https://www.google.com/search?q=' + quote(\n",
    "                search_term.encode('utf-8')) + '&espv=2&biw=1366&bih=667&site=webhp&source=lnms&tbm=isch' + params + '&sa=X&ei=XosDVaCXD8TasATItgE&ved=0CAcQ_AUoAg'\n",
    "\n",
    "        #safe search check\n",
    "        if safe_search:\n",
    "            url = url + safe_search_string\n",
    "\n",
    "        return url\n",
    "\n",
    "\n",
    "    #measures the file size\n",
    "    def file_size(self,file_path):\n",
    "        if os.path.isfile(file_path):\n",
    "            file_info = os.stat(file_path)\n",
    "            size = file_info.st_size\n",
    "            for x in ['bytes', 'KB', 'MB', 'GB', 'TB']:\n",
    "                if size < 1024.0:\n",
    "                    return \"%3.1f %s\" % (size, x)\n",
    "                size /= 1024.0\n",
    "            return size\n",
    "\n",
    "    #keywords from file\n",
    "    def keywords_from_file(self,file_name):\n",
    "        search_keyword = []\n",
    "        with codecs.open(file_name, 'r', encoding='utf-8-sig') as f:\n",
    "            if '.csv' in file_name:\n",
    "                for line in f:\n",
    "                    if line in ['\\n', '\\r\\n']:\n",
    "                        pass\n",
    "                    else:\n",
    "                        search_keyword.append(line.replace('\\n', '').replace('\\r', ''))\n",
    "            elif '.txt' in file_name:\n",
    "                for line in f:\n",
    "                    if line in ['\\n', '\\r\\n']:\n",
    "                        pass\n",
    "                    else:\n",
    "                        search_keyword.append(line.replace('\\n', '').replace('\\r', ''))\n",
    "            else:\n",
    "                print(\"Invalid file type: Valid file types are either .txt or .csv \\n\"\n",
    "                      \"exiting...\")\n",
    "                sys.exit()\n",
    "        return search_keyword\n",
    "\n",
    "    # make directories\n",
    "    def create_directories(self,main_directory, dir_name,thumbnail,thumbnail_only):\n",
    "        dir_name_thumbnail = dir_name + \" - thumbnail\"\n",
    "        # make a search keyword  directory\n",
    "        try:\n",
    "            if not os.path.exists(main_directory):\n",
    "                os.makedirs(main_directory)\n",
    "                time.sleep(0.2)\n",
    "                path = (dir_name)\n",
    "                sub_directory = os.path.join(main_directory, path)\n",
    "                if not os.path.exists(sub_directory):\n",
    "                    os.makedirs(sub_directory)\n",
    "                if thumbnail or thumbnail_only:\n",
    "                    sub_directory_thumbnail = os.path.join(main_directory, dir_name_thumbnail)\n",
    "                    if not os.path.exists(sub_directory_thumbnail):\n",
    "                        os.makedirs(sub_directory_thumbnail)\n",
    "            else:\n",
    "                path = (dir_name)\n",
    "                sub_directory = os.path.join(main_directory, path)\n",
    "                if not os.path.exists(sub_directory):\n",
    "                    os.makedirs(sub_directory)\n",
    "                if thumbnail or thumbnail_only:\n",
    "                    sub_directory_thumbnail = os.path.join(main_directory, dir_name_thumbnail)\n",
    "                    if not os.path.exists(sub_directory_thumbnail):\n",
    "                        os.makedirs(sub_directory_thumbnail)\n",
    "        except OSError as e:\n",
    "            if e.errno != 17:\n",
    "                raise\n",
    "            pass\n",
    "        return\n",
    "\n",
    "\n",
    "    # Download Image thumbnails\n",
    "    def download_image_thumbnail(self,image_url,main_directory,dir_name,return_image_name,print_urls,socket_timeout,print_size,no_download,save_source,img_src,ignore_urls):\n",
    "        if print_urls or no_download:\n",
    "            print(\"Image URL: \" + image_url)\n",
    "        if no_download:\n",
    "            return \"success\",\"Printed url without downloading\"\n",
    "        try:\n",
    "            req = Request(image_url, headers={\n",
    "                \"User-Agent\": \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.27 Safari/537.17\"})\n",
    "            try:\n",
    "                # timeout time to download an image\n",
    "                if socket_timeout:\n",
    "                    timeout = float(socket_timeout)\n",
    "                else:\n",
    "                    timeout = 10\n",
    "\n",
    "                response = urlopen(req, None, timeout)\n",
    "                data = response.read()\n",
    "                response.close()\n",
    "\n",
    "                path = main_directory + \"/\" + dir_name + \" - thumbnail\" + \"/\" + return_image_name\n",
    "\n",
    "                try:\n",
    "                    output_file = open(path, 'wb')\n",
    "                    output_file.write(data)\n",
    "                    output_file.close()\n",
    "                    if save_source:\n",
    "                        list_path = main_directory + \"/\" + save_source + \".txt\"\n",
    "                        list_file = open(list_path,'a')\n",
    "                        list_file.write(path + '\\t' + img_src + '\\n')\n",
    "                        list_file.close()\n",
    "                except OSError as e:\n",
    "                    download_status = 'fail'\n",
    "                    download_message = \"OSError on an image...trying next one...\" + \" Error: \" + str(e)\n",
    "                except IOError as e:\n",
    "                    download_status = 'fail'\n",
    "                    download_message = \"IOError on an image...trying next one...\" + \" Error: \" + str(e)\n",
    "\n",
    "                download_status = 'success'\n",
    "                download_message = \"Completed Image Thumbnail ====> \" + return_image_name\n",
    "\n",
    "                # image size parameter\n",
    "                if print_size:\n",
    "                    print(\"Image Size: \" + str(self.file_size(path)))\n",
    "\n",
    "            except UnicodeEncodeError as e:\n",
    "                download_status = 'fail'\n",
    "                download_message = \"UnicodeEncodeError on an image...trying next one...\" + \" Error: \" + str(e)\n",
    "\n",
    "        except HTTPError as e:  # If there is any HTTPError\n",
    "            download_status = 'fail'\n",
    "            download_message = \"HTTPError on an image...trying next one...\" + \" Error: \" + str(e)\n",
    "\n",
    "        except URLError as e:\n",
    "            download_status = 'fail'\n",
    "            download_message = \"URLError on an image...trying next one...\" + \" Error: \" + str(e)\n",
    "\n",
    "        except ssl.CertificateError as e:\n",
    "            download_status = 'fail'\n",
    "            download_message = \"CertificateError on an image...trying next one...\" + \" Error: \" + str(e)\n",
    "\n",
    "        except IOError as e:  # If there is any IOError\n",
    "            download_status = 'fail'\n",
    "            download_message = \"IOError on an image...trying next one...\" + \" Error: \" + str(e)\n",
    "        return download_status, download_message\n",
    "\n",
    "\n",
    "    # Download Images\n",
    "    def download_image(self,image_url,image_format,main_directory,dir_name,count,print_urls,socket_timeout,prefix,print_size,no_numbering,no_download,save_source,img_src,silent_mode,thumbnail_only,format,ignore_urls):\n",
    "        if not silent_mode:\n",
    "            if print_urls or no_download:\n",
    "                print(\"Image URL: \" + image_url)\n",
    "        if ignore_urls:\n",
    "            if any(url in image_url for url in ignore_urls.split(',')):\n",
    "                return \"fail\", \"Image ignored due to 'ignore url' parameter\", None, image_url\n",
    "        if thumbnail_only:\n",
    "            return \"success\", \"Skipping image download...\", str(image_url[(image_url.rfind('/')) + 1:]), image_url\n",
    "        if no_download:\n",
    "            return \"success\",\"Printed url without downloading\",None,image_url\n",
    "        try:\n",
    "            req = Request(image_url, headers={\n",
    "                \"User-Agent\": \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.27 Safari/537.17\"})\n",
    "            try:\n",
    "                # timeout time to download an image\n",
    "                if socket_timeout:\n",
    "                    timeout = float(socket_timeout)\n",
    "                else:\n",
    "                    timeout = 10\n",
    "\n",
    "                response = urlopen(req, None, timeout)\n",
    "                data = response.read()\n",
    "                response.close()\n",
    "\n",
    "                extensions = [\".jpg\", \".jpeg\", \".gif\", \".png\", \".bmp\", \".svg\", \".webp\", \".ico\"]\n",
    "                # keep everything after the last '/'\n",
    "                image_name = str(image_url[(image_url.rfind('/')) + 1:])\n",
    "                if format:\n",
    "                    if not image_format or image_format != format:\n",
    "                        download_status = 'fail'\n",
    "                        download_message = \"Wrong image format returned. Skipping...\"\n",
    "                        return_image_name = ''\n",
    "                        absolute_path = ''\n",
    "                        return download_status, download_message, return_image_name, absolute_path\n",
    "\n",
    "                if image_format == \"\" or not image_format or \".\" + image_format not in extensions:\n",
    "                    download_status = 'fail'\n",
    "                    download_message = \"Invalid or missing image format. Skipping...\"\n",
    "                    return_image_name = ''\n",
    "                    absolute_path = ''\n",
    "                    return download_status, download_message, return_image_name, absolute_path\n",
    "                elif image_name.lower().find(\".\" + image_format) < 0:\n",
    "                    image_name = image_name + \".\" + image_format\n",
    "                else:\n",
    "                    image_name = image_name[:image_name.lower().find(\".\" + image_format) + (len(image_format) + 1)]\n",
    "\n",
    "                # prefix name in image\n",
    "                if prefix:\n",
    "                    prefix = prefix + \" \"\n",
    "                else:\n",
    "                    prefix = ''\n",
    "\n",
    "                if no_numbering:\n",
    "                    path = main_directory + \"/\" + dir_name + \"/\" + prefix + image_name\n",
    "                else:\n",
    "                    path = main_directory + \"/\" + dir_name + \"/\" + prefix + str(count) + \".\" + image_name\n",
    "\n",
    "                try:\n",
    "                    output_file = open(path, 'wb')\n",
    "                    output_file.write(data)\n",
    "                    output_file.close()\n",
    "                    if save_source:\n",
    "                        list_path = main_directory + \"/\" + save_source + \".txt\"\n",
    "                        list_file = open(list_path,'a')\n",
    "                        list_file.write(path + '\\t' + img_src + '\\n')\n",
    "                        list_file.close()\n",
    "                    absolute_path = os.path.abspath(path)\n",
    "                except OSError as e:\n",
    "                    download_status = 'fail'\n",
    "                    download_message = \"OSError on an image...trying next one...\" + \" Error: \" + str(e)\n",
    "                    return_image_name = ''\n",
    "                    absolute_path = ''\n",
    "\n",
    "                #return image name back to calling method to use it for thumbnail downloads\n",
    "                download_status = 'success'\n",
    "                download_message = \"Completed Image ====> \" + prefix + str(count) + \".\" + image_name\n",
    "                return_image_name = prefix + str(count) + \".\" + image_name\n",
    "\n",
    "                # image size parameter\n",
    "                if not silent_mode:\n",
    "                    if print_size:\n",
    "                        print(\"Image Size: \" + str(self.file_size(path)))\n",
    "\n",
    "            except UnicodeEncodeError as e:\n",
    "                download_status = 'fail'\n",
    "                download_message = \"UnicodeEncodeError on an image...trying next one...\" + \" Error: \" + str(e)\n",
    "                return_image_name = ''\n",
    "                absolute_path = ''\n",
    "\n",
    "            except URLError as e:\n",
    "                download_status = 'fail'\n",
    "                download_message = \"URLError on an image...trying next one...\" + \" Error: \" + str(e)\n",
    "                return_image_name = ''\n",
    "                absolute_path = ''\n",
    "                \n",
    "            except BadStatusLine as e:\n",
    "                download_status = 'fail'\n",
    "                download_message = \"BadStatusLine on an image...trying next one...\" + \" Error: \" + str(e)\n",
    "                return_image_name = ''\n",
    "                absolute_path = ''\n",
    "\n",
    "        except HTTPError as e:  # If there is any HTTPError\n",
    "            download_status = 'fail'\n",
    "            download_message = \"HTTPError on an image...trying next one...\" + \" Error: \" + str(e)\n",
    "            return_image_name = ''\n",
    "            absolute_path = ''\n",
    "\n",
    "        except URLError as e:\n",
    "            download_status = 'fail'\n",
    "            download_message = \"URLError on an image...trying next one...\" + \" Error: \" + str(e)\n",
    "            return_image_name = ''\n",
    "            absolute_path = ''\n",
    "\n",
    "        except ssl.CertificateError as e:\n",
    "            download_status = 'fail'\n",
    "            download_message = \"CertificateError on an image...trying next one...\" + \" Error: \" + str(e)\n",
    "            return_image_name = ''\n",
    "            absolute_path = ''\n",
    "\n",
    "        except IOError as e:  # If there is any IOError\n",
    "            download_status = 'fail'\n",
    "            download_message = \"IOError on an image...trying next one...\" + \" Error: \" + str(e)\n",
    "            return_image_name = ''\n",
    "            absolute_path = ''\n",
    "\n",
    "        except IncompleteRead as e:\n",
    "            download_status = 'fail'\n",
    "            download_message = \"IncompleteReadError on an image...trying next one...\" + \" Error: \" + str(e)\n",
    "            return_image_name = ''\n",
    "            absolute_path = ''\n",
    "\n",
    "        return download_status,download_message,return_image_name,absolute_path\n",
    "\n",
    "\n",
    "    # Finding 'Next Image' from the given raw page\n",
    "    def _get_next_item(self,s):\n",
    "        start_line = s.find('rg_meta notranslate')\n",
    "        if start_line == -1:  # If no links are found then give an error!\n",
    "            end_quote = 0\n",
    "            link = \"no_links\"\n",
    "            return link, end_quote\n",
    "        else:\n",
    "            start_line = s.find('class=\"rg_meta notranslate\">')\n",
    "            start_object = s.find('{', start_line + 1)\n",
    "            end_object = s.find('</div>', start_object + 1)\n",
    "            object_raw = str(s[start_object:end_object])\n",
    "            #remove escape characters based on python version\n",
    "            version = (3, 0)\n",
    "            cur_version = sys.version_info\n",
    "            if cur_version >= version: #python3\n",
    "                try:\n",
    "                    object_decode = bytes(object_raw, \"utf-8\").decode(\"unicode_escape\")\n",
    "                    final_object = json.loads(object_decode)\n",
    "                except:\n",
    "                    final_object = \"\"\n",
    "            else:  #python2\n",
    "                try:\n",
    "                    final_object = (json.loads(self.repair(object_raw)))\n",
    "                except:\n",
    "                    final_object = \"\"\n",
    "            return final_object, end_object\n",
    "\n",
    "\n",
    "    # Getting all links with the help of '_images_get_next_image'\n",
    "    def _get_all_items(self,page,main_directory,dir_name,limit,arguments):\n",
    "        items = []\n",
    "        abs_path = []\n",
    "        errorCount = 0\n",
    "        i = 0\n",
    "        count = 1\n",
    "        while count < limit+1:\n",
    "            object, end_content = self._get_next_item(page)\n",
    "            if object == \"no_links\":\n",
    "                break\n",
    "            elif object == \"\":\n",
    "                page = page[end_content:]\n",
    "            elif arguments['offset'] and count < int(arguments['offset']):\n",
    "                    count += 1\n",
    "                    page = page[end_content:]\n",
    "            else:\n",
    "                #format the item for readability\n",
    "                object = self.format_object(object)\n",
    "                if arguments['metadata']:\n",
    "                    if not arguments[\"silent_mode\"]:\n",
    "                        print(\"\\nImage Metadata: \" + str(object))\n",
    "\n",
    "                #download the images\n",
    "                download_status,download_message,return_image_name,absolute_path = self.download_image(object['image_link'],object['image_format'],main_directory,dir_name,count,arguments['print_urls'],arguments['socket_timeout'],arguments['prefix'],arguments['print_size'],arguments['no_numbering'],arguments['no_download'],arguments['save_source'],object['image_source'],arguments[\"silent_mode\"],arguments[\"thumbnail_only\"],arguments['format'],arguments['ignore_urls'])\n",
    "                if not arguments[\"silent_mode\"]:\n",
    "                    print(download_message)\n",
    "                if download_status == \"success\":\n",
    "\n",
    "                    # download image_thumbnails\n",
    "                    if arguments['thumbnail'] or arguments[\"thumbnail_only\"]:\n",
    "                        download_status, download_message_thumbnail = self.download_image_thumbnail(object['image_thumbnail_url'],main_directory,dir_name,return_image_name,arguments['print_urls'],arguments['socket_timeout'],arguments['print_size'],arguments['no_download'],arguments['save_source'],object['image_source'],arguments['ignore_urls'])\n",
    "                        if not arguments[\"silent_mode\"]:\n",
    "                            print(download_message_thumbnail)\n",
    "\n",
    "                    count += 1\n",
    "                    object['image_filename'] = return_image_name\n",
    "                    items.append(object)  # Append all the links in the list named 'Links'\n",
    "                    abs_path.append(absolute_path)\n",
    "                else:\n",
    "                    errorCount += 1\n",
    "\n",
    "                #delay param\n",
    "                if arguments['delay']:\n",
    "                    time.sleep(int(arguments['delay']))\n",
    "\n",
    "                page = page[end_content:]\n",
    "            i += 1\n",
    "        if count < limit:\n",
    "            print(\"\\n\\nUnfortunately all \" + str(\n",
    "                limit) + \" could not be downloaded because some images were not downloadable. \" + str(\n",
    "                count-1) + \" is all we got for this search filter!\")\n",
    "        return items,errorCount,abs_path\n",
    "\n",
    "\n",
    "    # Bulk Download\n",
    "    def download(self,arguments):\n",
    "        paths_agg = {}\n",
    "        # for input coming from other python files\n",
    "        if __name__ != \"__main__\":\n",
    "            # if the calling file contains config_file param\n",
    "            if 'config_file' in arguments:\n",
    "                records = []\n",
    "                json_file = json.load(open(arguments['config_file']))\n",
    "                for record in range(0, len(json_file['Records'])):\n",
    "                    arguments = {}\n",
    "                    for i in args_list:\n",
    "                        arguments[i] = None\n",
    "                    for key, value in json_file['Records'][record].items():\n",
    "                        arguments[key] = value\n",
    "                    records.append(arguments)\n",
    "                total_errors = 0\n",
    "                for rec in records:\n",
    "                    paths, errors = self.download_executor(rec)\n",
    "                    for i in paths:\n",
    "                        paths_agg[i] = paths[i]\n",
    "                    if not arguments[\"silent_mode\"]:\n",
    "                        if arguments['print_paths']:\n",
    "                            print(paths.encode('raw_unicode_escape').decode('utf-8'))\n",
    "                    total_errors = total_errors + errors\n",
    "                return paths_agg,total_errors\n",
    "            # if the calling file contains params directly\n",
    "            else:\n",
    "                paths, errors = self.download_executor(arguments)\n",
    "                for i in paths:\n",
    "                    paths_agg[i] = paths[i]\n",
    "                if not arguments[\"silent_mode\"]:\n",
    "                    if arguments['print_paths']:\n",
    "                        print(paths.encode('raw_unicode_escape').decode('utf-8'))\n",
    "                return paths_agg, errors\n",
    "        # for input coming from CLI\n",
    "        else:\n",
    "            paths, errors = self.download_executor(arguments)\n",
    "            for i in paths:\n",
    "                paths_agg[i] = paths[i]\n",
    "            if not arguments[\"silent_mode\"]:\n",
    "                if arguments['print_paths']:\n",
    "                    print(paths.encode('raw_unicode_escape').decode('utf-8'))\n",
    "        return paths_agg, errors\n",
    "\n",
    "    def download_executor(self,arguments):\n",
    "        paths = {}\n",
    "        errorCount = None\n",
    "        for arg in args_list:\n",
    "            if arg not in arguments:\n",
    "                arguments[arg] = None\n",
    "        ######Initialization and Validation of user arguments\n",
    "        if arguments['keywords']:\n",
    "            search_keyword = [str(item) for item in arguments['keywords'].split(',')]\n",
    "\n",
    "        if arguments['keywords_from_file']:\n",
    "            search_keyword = self.keywords_from_file(arguments['keywords_from_file'])\n",
    "\n",
    "        # both time and time range should not be allowed in the same query\n",
    "        if arguments['time'] and arguments['time_range']:\n",
    "            raise ValueError('Either time or time range should be used in a query. Both cannot be used at the same time.')\n",
    "\n",
    "        # both time and time range should not be allowed in the same query\n",
    "        if arguments['size'] and arguments['exact_size']:\n",
    "            raise ValueError('Either \"size\" or \"exact_size\" should be used in a query. Both cannot be used at the same time.')\n",
    "\n",
    "        # both image directory and no image directory should not be allowed in the same query\n",
    "        if arguments['image_directory'] and arguments['no_directory']:\n",
    "            raise ValueError('You can either specify image directory or specify no image directory, not both!')\n",
    "\n",
    "        # Additional words added to keywords\n",
    "        if arguments['suffix_keywords']:\n",
    "            suffix_keywords = [\" \" + str(sk) for sk in arguments['suffix_keywords'].split(',')]\n",
    "        else:\n",
    "            suffix_keywords = ['']\n",
    "\n",
    "        # Additional words added to keywords\n",
    "        if arguments['prefix_keywords']:\n",
    "            prefix_keywords = [str(sk) + \" \" for sk in arguments['prefix_keywords'].split(',')]\n",
    "        else:\n",
    "            prefix_keywords = ['']\n",
    "\n",
    "        # Setting limit on number of images to be downloaded\n",
    "        if arguments['limit']:\n",
    "            limit = int(arguments['limit'])\n",
    "        else:\n",
    "            limit = 100\n",
    "\n",
    "        if arguments['url']:\n",
    "            current_time = str(datetime.datetime.now()).split('.')[0]\n",
    "            search_keyword = [current_time.replace(\":\", \"_\")]\n",
    "\n",
    "        if arguments['similar_images']:\n",
    "            current_time = str(datetime.datetime.now()).split('.')[0]\n",
    "            search_keyword = [current_time.replace(\":\", \"_\")]\n",
    "\n",
    "        # If single_image or url argument not present then keywords is mandatory argument\n",
    "        if arguments['single_image'] is None and arguments['url'] is None and arguments['similar_images'] is None and \\\n",
    "                        arguments['keywords'] is None and arguments['keywords_from_file'] is None:\n",
    "            print('-------------------------------\\n'\n",
    "                  'Uh oh! Keywords is a required argument \\n\\n'\n",
    "                  'Please refer to the documentation on guide to writing queries \\n'\n",
    "                  'https://github.com/hardikvasa/google-images-download#examples'\n",
    "                  '\\n\\nexiting!\\n'\n",
    "                  '-------------------------------')\n",
    "            sys.exit()\n",
    "\n",
    "        # If this argument is present, set the custom output directory\n",
    "        if arguments['output_directory']:\n",
    "            main_directory = arguments['output_directory']\n",
    "        else:\n",
    "            main_directory = \"downloads\"\n",
    "\n",
    "        # Proxy settings\n",
    "        if arguments['proxy']:\n",
    "            os.environ[\"http_proxy\"] = arguments['proxy']\n",
    "            os.environ[\"https_proxy\"] = arguments['proxy']\n",
    "            ######Initialization Complete\n",
    "        total_errors = 0\n",
    "        for pky in prefix_keywords:                 # 1.for every prefix keywords\n",
    "            for sky in suffix_keywords:             # 2.for every suffix keywords\n",
    "                i = 0\n",
    "                while i < len(search_keyword):      # 3.for every main keyword\n",
    "                    iteration = \"\\n\" + \"Item no.: \" + str(i + 1) + \" -->\" + \" Item name = \" + (pky) + (search_keyword[i]) + (sky)\n",
    "                    if not arguments[\"silent_mode\"]:\n",
    "                        print(iteration.encode('raw_unicode_escape').decode('utf-8'))\n",
    "                        print(\"Evaluating...\")\n",
    "                    else:\n",
    "                        print(\"Downloading images for: \" + (pky) + (search_keyword[i]) + (sky) + \" ...\")\n",
    "                    search_term = pky + search_keyword[i] + sky\n",
    "\n",
    "                    if arguments['image_directory']:\n",
    "                        dir_name = arguments['image_directory']\n",
    "                    elif arguments['no_directory']:\n",
    "                        dir_name = ''\n",
    "                    else:\n",
    "                        dir_name = search_term + ('-' + arguments['color'] if arguments['color'] else '')   #sub-directory\n",
    "\n",
    "                    if not arguments[\"no_download\"]:\n",
    "                        self.create_directories(main_directory,dir_name,arguments['thumbnail'],arguments['thumbnail_only'])     #create directories in OS\n",
    "\n",
    "                    params = self.build_url_parameters(arguments)     #building URL with params\n",
    "\n",
    "                    url = self.build_search_url(search_term,params,arguments['url'],arguments['similar_images'],arguments['specific_site'],arguments['safe_search'])      #building main search url\n",
    "\n",
    "                    if limit < 101:\n",
    "                        raw_html = self.download_page(url)  # download page\n",
    "                    else:\n",
    "                        raw_html = self.download_extended_page(url,arguments['chromedriver'])\n",
    "\n",
    "                    if not arguments[\"silent_mode\"]:\n",
    "                        if arguments['no_download']:\n",
    "                            print(\"Getting URLs without downloading images...\")\n",
    "                        else:\n",
    "                            print(\"Starting Download...\")\n",
    "                    items,errorCount,abs_path = self._get_all_items(raw_html,main_directory,dir_name,limit,arguments)    #get all image items and download images\n",
    "                    paths[pky + search_keyword[i] + sky] = abs_path\n",
    "\n",
    "                    #dumps into a json file\n",
    "                    if arguments['extract_metadata']:\n",
    "                        try:\n",
    "                            if not os.path.exists(\"logs\"):\n",
    "                                os.makedirs(\"logs\")\n",
    "                        except OSError as e:\n",
    "                            print(e)\n",
    "                        json_file = open(\"logs/\"+search_keyword[i]+\".json\", \"w\")\n",
    "                        json.dump(items, json_file, indent=4, sort_keys=True)\n",
    "                        json_file.close()\n",
    "\n",
    "                    #Related images\n",
    "                    if arguments['related_images']:\n",
    "                        print(\"\\nGetting list of related keywords...this may take a few moments\")\n",
    "                        tabs = self.get_all_tabs(raw_html)\n",
    "                        for key, value in tabs.items():\n",
    "                            final_search_term = (search_term + \" - \" + key)\n",
    "                            print(\"\\nNow Downloading - \" + final_search_term)\n",
    "                            if limit < 101:\n",
    "                                new_raw_html = self.download_page(value)  # download page\n",
    "                            else:\n",
    "                                new_raw_html = self.download_extended_page(value,arguments['chromedriver'])\n",
    "                            self.create_directories(main_directory, final_search_term,arguments['thumbnail'],arguments['thumbnail_only'])\n",
    "                            self._get_all_items(new_raw_html, main_directory, search_term + \" - \" + key, limit,arguments)\n",
    "\n",
    "                    i += 1\n",
    "                    total_errors = total_errors + errorCount\n",
    "                    if not arguments[\"silent_mode\"]:\n",
    "                        print(\"\\nErrors: \" + str(errorCount) + \"\\n\")\n",
    "        return paths, total_errors\n",
    "\n",
    "#------------- Main Program -------------#\n",
    "def main():\n",
    "    records = user_input()\n",
    "    total_errors = 0\n",
    "    t0 = time.time()  # start the timer\n",
    "    for arguments in records:\n",
    "\n",
    "        if arguments['single_image']:  # Download Single Image using a URL\n",
    "            response = googleimagesdownload()\n",
    "            response.single_image(arguments['single_image'])\n",
    "        else:  # or download multiple images based on keywords/keyphrase search\n",
    "            response = googleimagesdownload()\n",
    "            paths,errors = response.download(arguments)  #wrapping response in a variable just for consistency\n",
    "            total_errors = total_errors + errors\n",
    "\n",
    "        t1 = time.time()  # stop the timer\n",
    "        total_time = t1 - t0  # Calculating the total time required to crawl, find and download all the links of 60,000 images\n",
    "        if not arguments[\"silent_mode\"]:\n",
    "            print(\"\\nEverything downloaded!\")\n",
    "            print(\"Total errors: \" + str(total_errors))\n",
    "            print(\"Total time taken: \" + str(total_time) + \" Seconds\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = driver.find_element_by_xpath(\"img.rg_i.Q4LuWd\")##thumnails list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address = \"저장하고싶은 위치\"\n",
    "urllib.request.urlretrieve(url,address+\"/\"+str(keyword)+\".jpg\") # download images in address folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//*[@id=\"__next\"]/div[4]/div/div/div[1]/div/div[5]/div/div[1]/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//*[@id=\"__next\"]/div[4]/div/div/div[1]/div/div[5]/div/div[2]/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#__next > div.MuiContainer-root.jss73.MuiContainer-disableGutters > div > div > div.jss78 > div > div.jss133 > div > div.MuiGrid-root.jss136.MuiGrid-item.MuiGrid-grid-xs-true > div > div > div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "Driver [C:\\Users\\hongr\\.wdm\\drivers\\chromedriver\\win32\\94.0.4606.61\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "insert keyword for searching : 저작권 없는 데이터\n"
     ]
    },
    {
     "ename": "ElementNotInteractableException",
     "evalue": "Message: element not interactable\n  (Session info: chrome=94.0.4606.81)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementNotInteractableException\u001b[0m           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_45808/2327655594.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m##웹브라우저 창 화면 최대화\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"#__next > div.MuiContainer-root.jss73.MuiContainer-disableGutters > div > div > div.jss78 > div > div.jss133 > div > div.MuiGrid-root.jss136.MuiGrid-item.MuiGrid-grid-xs-true > div > div > div\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#send keyword\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_css_selector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"#__next > div.MuiContainer-root.jss73.MuiContainer-disableGutters > div > div > div.jss78 > div > div.jss133 > div > div.MuiGrid-root.jss136.MuiGrid-item.MuiGrid-grid-xs-true > div > div > div\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETURN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m##send Keys.RETURN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36msend_keys\u001b[1;34m(self, *value)\u001b[0m\n\u001b[0;32m    475\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_upload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m         self._execute(Command.SEND_KEYS_TO_ELEMENT,\n\u001b[0m\u001b[0;32m    478\u001b[0m                       {'text': \"\".join(keys_to_typing(value)),\n\u001b[0;32m    479\u001b[0m                        'value': keys_to_typing(value)})\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    631\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mElementNotInteractableException\u001b[0m: Message: element not interactable\n  (Session info: chrome=94.0.4606.81)\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import urllib.request\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())#chromedriver를 사용하기위한 webdriver함수 사용\n",
    "\n",
    "keyword = str(input(\"insert keyword for searching : \"))#get keyword to search\n",
    "driver.get(\"https://www.shutterstock.com/ko/search/%EC%9D%B8%EB%AC%BC+%EC%BA%90%EB%A6%AD%ED%84%B0?kw=%2Bshutterstock&c3apidt=p15857823525&gclsrc=aw.ds&gclid=Cj0KCQjw5JSLBhCxARIsAHgO2SfpE7YWg2Ox7bYU-o9lJe0blPspbEabrl8fQ44j1udEioa2kLv1BpUaAq8gEALw_wcB&sort=relevant&image_type=illustration\")##open google image search page\n",
    "driver.maximize_window()##웹브라우저 창 화면 최대화\n",
    "time.sleep(2)\n",
    "driver.find_element_by_css_selector(\"#__next > div.MuiContainer-root.jss73.MuiContainer-disableGutters > div > div > div.jss78 > div > div.jss133 > div > div.MuiGrid-root.jss136.MuiGrid-item.MuiGrid-grid-xs-true > div > div > div\").send_keys(keyword) #send keyword\n",
    "driver.find_element_by_css_selector(\"#__next > div.MuiContainer-root.jss73.MuiContainer-disableGutters > div > div > div.jss78 > div > div.jss133 > div > div.MuiGrid-root.jss136.MuiGrid-item.MuiGrid-grid-xs-true > div > div > div\").send_keys(Keys.RETURN)##send Keys.RETURN\n",
    "\n",
    "\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\") #initialize standard of height first\n",
    "while True: #break가 일어날 때 까지 계속 반복\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\") #페이지 스크롤 시키기\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\") ## update new_height\n",
    "    if new_height == last_height:#이전 스크롤 길이와 현재의 스크롤 길이를 비교\n",
    "        try:\n",
    "            driver.find_element_by_css_selector(\"#__next > div.MuiContainer-root.jss73.MuiContainer-disableGutters > div > div > div.jss78 > div > div.jss237 > div.jss238 > a\").click() ## click more button\n",
    "        except:\n",
    "            break # 더보기 버튼이 없을 경우는 더 이상 나올 정보가 없다는 의미이므로 반복문을 break\n",
    "    last_height = new_height ##last_height update\n",
    "\n",
    "i=0\n",
    "\n",
    "list = driver.find_elements_by_xpath(\"//*[@id=\\\"__next\\\"]/div[4]/div/div/div[1]/div/div[5]/div/\")##thumnails list\n",
    "print(len(list)) #print number of thumnails\n",
    "\n",
    "\n",
    "address = str(input(\"insert your address : \"))# 파일을 저장할 주소를 입력받기\n",
    "for img in list:\n",
    "    i += 1\n",
    "    try:\n",
    "\n",
    "        imgurl = img.get_attribute(\"src\") # get thumnails address list\n",
    "        time.sleep(1)\n",
    "        urllib.request.urlretrieve(imgurl,address+\"/\"+str(keyword)+str(i)+\".jpg\") # download images in address folder\n",
    "\n",
    "    except: #저장이 불가능할경우 그냥  pass\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mQOV4aFBULKb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다운로드 시도할 최대 이미지 수 : 100\n"
     ]
    }
   ],
   "source": [
    "maxImages = int(input('다운로드 시도할 최대 이미지 수 : '))\n",
    "image_name = \"캐릭터 : \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hongr'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'character'+number_image\n",
    "\n",
    "try:\n",
    "    # 중복되는 폴더 명이 없다면 생성\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    # 중복된다면 문구 출력 후 프로그램 종료\n",
    "    else:\n",
    "        print('이전에 같은 [검색어, 이미지 수]로 다운로드한 폴더가 존재합니다.')\n",
    "        sys.exit(0)\n",
    "except OSError:\n",
    "    print ('os error')\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = int((maxImages-1)/100)+1 #한 페이지당 표시되는 이미지 수(100)을 참고하여 확인할 페이지 수 계산\n",
    "imgCount = 0 # 추출 시도 이미지 수\n",
    "success = 0 # 추출 성공 이미지 수\n",
    "finish = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 94.0.4606\n",
      "Get LATEST driver version for 94.0.4606\n",
      "Driver [C:\\Users\\hongr\\.wdm\\drivers\\chromedriver\\win32\\94.0.4606.61\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('headless')\n",
    "chrome_options.add_argument('--disable-gpu')\n",
    "chrome_options.add_argument('lang=ko_KR')\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.82 Safari/537.36\")\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,int(pages)+1):\n",
    "    #웹 페이지 접근 후 1초동안 로드를 기다림\n",
    "    url = 'https://www.shutterstock.com/ko/search/%EC%BA%90%EB%A6%AD%ED%84%B0?pl=PPC_GOO_KR_IG-264131595792&cr=ec&kw=%EC%A0%80%EC%9E%91%EA%B6%8C%20%EC%97%86%EB%8A%94%20%EC%BA%90%EB%A6%AD%ED%84%B0&c3apidt=p19213837397&gclid=Cj0KCQjwwY-LBhD6ARIsACvT72Pqq67jZau_n_WGvLNYIddV-puPu2HtIGu6-Owqs5oJL9BB218T0N4aAjdgEALw_wcB&gclsrc=aw.ds&image_type=illustration&orientation=vertical&page=2'\n",
    "    driver.get(url)\n",
    "    driver.get('https://pixabay.com/images/search/'+keyword+'/?pagi='+str(i))\n",
    "    sleep(1)\n",
    "\n",
    "    #크롤링이 가능하도록 html코드 가공\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html,'html.parser')\n",
    "\n",
    "    imgs = soup.select('div.flex_grid.credits.search_results img') #요소 선택\n",
    "\n",
    "    #마지막 페이지 여부 결정\n",
    "    lastPage=False\n",
    "    if len(imgs)!=100:\n",
    "        lastPage=True\n",
    "\n",
    "    #5번 제목에서 설명함\n",
    "    for img in imgs:\n",
    "        srcset = \"\"\n",
    "        if img.get('srcset')==None:\n",
    "            srcset = img.get('data-lazy-srcset')\n",
    "        else: \n",
    "            srcset = img.get('srcset')\n",
    "\n",
    "\n",
    "        src = \"\"\n",
    "        if len(srcset):\n",
    "            src = str(srcset).split()[0] #가장 작은 사이즈의 이미지 경로 추출\n",
    "            print(src)\n",
    "            filename = src.split('/')[-1] #이미지 경로에서 날짜 부분뒤의 순 파일명만 추출\n",
    "            print(filename)\n",
    "            saveUrl = path+'/'+filename #저장 경로 결정\n",
    "            print(saveUrl)\n",
    "\n",
    "            #파일 저장\n",
    "            #user-agent 헤더를 가지고 있어야 접근 허용하는 사이트도 있을 수 있음(pixabay가 이에 해당)\n",
    "            req = urllib.request.Request(src, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            try:\n",
    "                imgUrl = urllib.request.urlopen(req).read() #웹 페이지 상의 이미지를 불러옴\n",
    "                with open(saveUrl,\"wb\") as f: #디렉토리 오픈\n",
    "                    f.write(imgUrl) #파일 저장\n",
    "                success+=1\n",
    "            except urllib.error.HTTPError:\n",
    "                print('에러')\n",
    "                sys.exit(0)\n",
    "\n",
    "        imgCount+=1\n",
    "\n",
    "        if imgCount==maxImages:\n",
    "            finish = True #입력한 이미지 수 만큼 모두 접근했음을 알림\n",
    "            break\n",
    "    \n",
    "    #finish가 참이거나 더 이상 접근할 이미지가 없을 경우 크롤링 종료\n",
    "    if finish or lastPage:\n",
    "        break\n",
    "\n",
    "print('성공 : '+str(success)+', 실패 : '+str(maxImages-success))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어 입력: 캐릭터\n",
      "크롤링할 갯수 입력(최대 50개): 10\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 500: Internal Server Error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9788/2902375702.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbaseUrl\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mquote_plus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplusUrl\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 한글 검색 자동 변환\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mhtml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_img'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    212\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m200\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m             response = self.parent.error(\n\u001b[0m\u001b[0;32m    633\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36merror\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'http_error_default'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m \u001b[1;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\test\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    639\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 500: Internal Server Error"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import quote_plus\n",
    " \n",
    "baseUrl = 'https://www.shutterstock.com/ko/search/%EC%BA%90%EB%A6%AD%ED%84%B0?pl=PPC_GOO_KR_IG-264131595792&cr=ec&kw=%EC%A0%80%EC%9E%91%EA%B6%8C%20%EC%97%86%EB%8A%94%20%EC%BA%90%EB%A6%AD%ED%84%B0&c3apidt=p19213837397&gclid=Cj0KCQjwwY-LBhD6ARIsACvT72Pqq67jZau_n_WGvLNYIddV-puPu2HtIGu6-Owqs5oJL9BB218T0N4aAjdgEALw_wcB&gclsrc=aw.ds&image_type=illustration&orientation=vertical&page=2'\n",
    "plusUrl = input('검색어 입력: ') \n",
    "crawl_num = int(input('크롤링할 갯수 입력(최대 50개): '))\n",
    " \n",
    "url = baseUrl + quote_plus(plusUrl) # 한글 검색 자동 변환\n",
    "html = urlopen(url)\n",
    "soup = bs(html, \"html.parser\")\n",
    "img = soup.find_all(class_='_img')\n",
    " \n",
    "n = 1\n",
    "for i in img:\n",
    "    print(n)\n",
    "    imgUrl = i['data-source']\n",
    "    with urlopen(imgUrl) as f:\n",
    "        with open('./images/img' + str(n)+'.jpg','wb') as h: # w - write b - binary\n",
    "            img = f.read()\n",
    "            h.write(img)\n",
    "    n += 1\n",
    "    if n > crawl_num:\n",
    "        break\n",
    "    \n",
    "    \n",
    "print('Image Crawling is done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'area' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9788/1401859328.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbutton\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marea\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"arguments[0].click();\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbutton\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'area' is not defined"
     ]
    }
   ],
   "source": [
    " button = driver.find_element_by_xpath(area)\n",
    "driver.execute_script(\"arguments[0].click();\", button)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "저작권x캐릭터",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
