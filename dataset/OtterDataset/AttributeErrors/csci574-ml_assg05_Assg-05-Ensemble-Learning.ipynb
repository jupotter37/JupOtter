{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "486f56c1-94fb-4e7c-8b7f-4d4d23056354",
   "metadata": {},
   "source": [
    "# Assignment 05: Ensemble Learning and Random Forests\n",
    "\n",
    "**Due Date:** Friday 11/22/2024 (by midnight)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e06f813-8a2d-4163-a2c5-0516e6ddb7a4",
   "metadata": {},
   "source": [
    "**Please fill these in before submitting, just in case I accidentally mix up file names while grading**:\n",
    "\n",
    "Name: Jane Hacker\n",
    "\n",
    "CWID-5: 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d87547-0713-4ffd-aa54-0941163acd08",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "In this assignment you will use a dataset from the OpenML repository named\n",
    "[MagicTelescope](https://openml.org/search?type=data&status=active&id=1120)\n",
    "You will load this data set and use it to to create some ensemble classifiers, both using voting, and then\n",
    "also some bagging and stacking type ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa33294a-b165-46d2-b16b-5adb6df22f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following ipython magic will reload changed file/modules.\n",
    "# So when editing function in source code modules, you should\n",
    "# be able to just rerun the cell, not restart the whole kernel.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "617c2b24-f42e-4c32-85e8-80dbcc1b354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "# By convention, we often just import the specific classes/functions\n",
    "# from scikit-learn we will need to train a model and perform prediction.\n",
    "# Here we include all of the classes and functions you should need for this\n",
    "# assignment from the sklearn library, but there could be other methods you might\n",
    "# want to try or would be useful to the way you approach the problem, so feel free\n",
    "# to import others you might need or want to try\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe758c69-c8f7-48ed-a0b1-388941664a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions/moduls from this project.  We manually set the\n",
    "# PYTHONPATH to append the location to search for this assignments\n",
    "# functions to just ensure the imports are found\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "# assignment function imports for doctests and github autograding\n",
    "# these are required for assignment autograding\n",
    "from assg_utils import run_unittests, run_doctests\n",
    "from assg_tasks import task_1_load_data, train_val_test_split, task_3_voting_ensemble, task_4_bag_of_trees_ensemble, create_stacked_data, task_6_stacked_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41c7e04-c559-444c-b6ac-f512797eb133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook wide settings to make plots more readable and visually better to understand\n",
    "np.set_printoptions(suppress=True)\n",
    "plt.rc('axes', labelsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "plt.rc('figure', titlesize=18)\n",
    "plt.rc('legend', fontsize=14)\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0) # default figure size if not specified in plot\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68b9b76-677a-4e39-9e22-7b5b165b8cf1",
   "metadata": {},
   "source": [
    "## Task 1: Load and Setup MagicTelescope data\n",
    "\n",
    "The [MagicTelescope](https://openml.org/search?type=data&status=active&id=1120) data set from the OpenML repository\n",
    "consists of 19020 instances.  There are 10 numeric features in this data set with no missing data.  The\n",
    "data set consists of various astronomical observations, and is a binary classification task where we want\n",
    "to classify the observations as either 'g' gamma signal detected or 'h' a hadron or no background signal.\n",
    "The data set is a bit skewed with 12332 instances of the positive 'g' class and 6688 instances of the\n",
    "negative 'h' class, so just always guessing positive of 'g' gives a $\\frac{12332}{19020} = 0.65$ or\n",
    "about 65% accuracy.\n",
    "\n",
    "In the first task, as usual, you need to complete the function to load the data set and clean it up a\n",
    "bit to be used for this assignment.  You are required to use the `fetch_openml()` method from\n",
    "`scikit-learn` to load this dataset from the OpenML repository.  There have been examples of using this\n",
    "to load the 'MNIST' dataset, you can do the same, but use the data set name 'MagicTelescope'\n",
    "\n",
    "There are a few other things you need to do.  As usual your `task1_load_data()` function is found in\n",
    "the `src/assg_tasks.py` file.  The function needs to return the `X` set of 19020 instances consisting\n",
    "of 10 numeric features, and the `y` target labels.  The targets as read from the OpenML function\n",
    "will be strings. Make sure that you encode the `g` as the positive class 1 and the `h` as the negative class 0,\n",
    "and you shape the targets as expected to pass the tests for this task to load the data we will\n",
    "use.  You should probably use an `OrdinalEncoder` so that you can correctly map the original labels as\n",
    "required ('g' is 1 and 'h' is 0).  The tests expect that you return a NumPy array with shape `(19020,)`, so a vector,\n",
    "and that you have encoded the targets correctly as described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c7975ae-1d70-406e-85dc-f8c2470cf487",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_X_properties (test_assg_tasks.test_task_1_load_data.test_X_properties)\n",
      "test_X_properties ... FAIL\n",
      "test_loaded_types (test_assg_tasks.test_task_1_load_data.test_loaded_types)\n",
      "test_loaded_types ... ok\n",
      "test_y_properties (test_assg_tasks.test_task_1_load_data.test_y_properties)\n",
      "test_y_properties ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_X_properties (test_assg_tasks.test_task_1_load_data.test_X_properties)\n",
      "test_X_properties\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg05/src/test_assg_tasks.py\", line 18, in test_X_properties\n",
      "    self.assertEqual(self.X.shape, (19020, 10))\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 444, in assertEqual\n",
      "    super().assertEqual(first, second, msg)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 885, in assertEqual\n",
      "    assertion_func(first, second, msg=msg)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 1102, in assertTupleEqual\n",
      "    self.assertSequenceEqual(tuple1, tuple2, msg, seq_type=tuple)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 1073, in assertSequenceEqual\n",
      "    self.fail(msg)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 381, in fail\n",
      "    raise self.failureException(msg)\n",
      "twisted.trial.unittest.FailTest: Tuples differ: (10, 5) != (19020, 10)\n",
      "\n",
      "First differing element 0:\n",
      "10\n",
      "19020\n",
      "\n",
      "- (10, 5)\n",
      "+ (19020, 10)\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_y_properties (test_assg_tasks.test_task_1_load_data.test_y_properties)\n",
      "test_y_properties\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg05/src/test_assg_tasks.py\", line 22, in test_y_properties\n",
      "    self.assertEqual(self.y.shape, (19020,))\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 444, in assertEqual\n",
      "    super().assertEqual(first, second, msg)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 885, in assertEqual\n",
      "    assertion_func(first, second, msg=msg)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 1102, in assertTupleEqual\n",
      "    self.assertSequenceEqual(tuple1, tuple2, msg, seq_type=tuple)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 1073, in assertSequenceEqual\n",
      "    self.fail(msg)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 381, in fail\n",
      "    raise self.failureException(msg)\n",
      "twisted.trial.unittest.FailTest: Tuples differ: (5,) != (19020,)\n",
      "\n",
      "First differing element 0:\n",
      "5\n",
      "19020\n",
      "\n",
      "- (5,)\n",
      "+ (19020,)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.169s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=3 errors=0 failures=2>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not remove or modify the code in this cell\n",
    "X, y = task_1_load_data()\n",
    "run_unittests(['test_task_1_load_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ac4c1c-3dc9-418d-b7bd-7fa651a1e196",
   "metadata": {},
   "source": [
    "In addition to loading the data, perform some exploration of this data set so that you better understand it.  \n",
    "Do the following tasks in the cell(s) below\n",
    "\n",
    "1. Verify that all of the features are numeric and that there is no missing data in this data set.\n",
    "2. We won't do any further data cleaning, but look at the feature ranges.  Does it look like features have\n",
    "  different scales and thus maybe we should try scaling it?\n",
    "3. Determine the correlation between each feature and the binary target label\n",
    "4. Plot the two most correated features.  In the plot also indicate the target of each point using\n",
    "  marker type and/or color, so we can visualize if there is any pattern among most correlated\n",
    "  features and the target we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15481602-9860-4841-b3b2-b2ae745cd60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. verify all features are numeric and that there is no missing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da896f60-ceb7-4d96-8e56-c4c041ccc701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. The mean and the min/max have different ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a411fd8-09a8-4262-b942-9157e9181d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Determine the correlation between each feature and the binary target label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "452c2365-68a7-492e-b032-52b6bf603bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. plot the two most correlated features and visualize the signal on the plot using marker type/color\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bd82a0-e878-4981-b8e1-51296d05a330",
   "metadata": {},
   "source": [
    "## Task 2: Utility Function for Train/Validation/Test Split\n",
    "\n",
    "In this section you are going to write a small utility function, for some more practice with\n",
    "using Python functions and the `sklearn` preprocessing library.\n",
    "\n",
    "There is a method in `sklearn` named `train_test_split()` that we have seen before and that can be used\n",
    "to split some data `X` and its targets `y` into training and testing data\n",
    "sets.  This function, by default, shuffles the data and performs the split as\n",
    "asked, using an absolute number of samples or a ratio to determine\n",
    "how much to split into the test set and how much into the training set.\n",
    "\n",
    "Create a function named `train_val_test_split()` that will split a set of data into\n",
    "3 sets, a training set, a validation set and a test set.  You are required to\n",
    "reuse the `train_test_split()` funciton in your implementation.  You should basically\n",
    "first split the data into the training data and the remaining data with one call of \n",
    "`train_test_split()` in your function, then call it a second time to split the\n",
    "remaining into a validation and final testing data set.\n",
    "\n",
    "The function is given in the `src/assg_tasks.py` file as usual.  The function expects\n",
    "the `X` input samples and the `y` labels as inputs to be split.  It also expects 2 parameters, the\n",
    "training set size and the validation set size (we won't support splitting by a ratio\n",
    "in this funciton, only by absolute number of samples to end up in each set).\n",
    "\n",
    "Implement the function so that it passes the tests given.  The function also has a\n",
    "`random_seed` with a default value of 42.  You should set the random state for both calls\n",
    "to `train_test_split()` when performing your 3-way split using this seed.  The random state is set to\n",
    "a different seed each time sklearn calls `train_test_split()` so if  you don't specify\n",
    "the seed everytime the function is called, the split from your implementation will\n",
    "not be reproducible as required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8db41318-c6d7-4716-9c80-a07113703859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_assg_data (test_assg_tasks.test_train_val_test_split.test_assg_data)\n",
      "test_assg_data ... FAIL\n",
      "test_generated_data (test_assg_tasks.test_train_val_test_split.test_generated_data)\n",
      "test_generated_data ... FAIL\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_assg_data (test_assg_tasks.test_train_val_test_split.test_assg_data)\n",
      "test_assg_data\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg05/src/test_assg_tasks.py\", line 69, in test_assg_data\n",
      "    self.assertEqual(X_train.shape, (10000, 10))\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 444, in assertEqual\n",
      "    super().assertEqual(first, second, msg)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 885, in assertEqual\n",
      "    assertion_func(first, second, msg=msg)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 1102, in assertTupleEqual\n",
      "    self.assertSequenceEqual(tuple1, tuple2, msg, seq_type=tuple)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 1073, in assertSequenceEqual\n",
      "    self.fail(msg)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 381, in fail\n",
      "    raise self.failureException(msg)\n",
      "twisted.trial.unittest.FailTest: Tuples differ: (10, 5) != (10000, 10)\n",
      "\n",
      "First differing element 0:\n",
      "10\n",
      "10000\n",
      "\n",
      "- (10, 5)\n",
      "+ (10000, 10)\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_generated_data (test_assg_tasks.test_train_val_test_split.test_generated_data)\n",
      "test_generated_data\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg05/src/test_assg_tasks.py\", line 37, in test_generated_data\n",
      "    self.assertIsInstance(X_train, np.ndarray)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 666, in assertIsInstance\n",
      "    self.fail(f\"{instance!r} is not an instance of {classOrTuple}{suffix}\")\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 381, in fail\n",
      "    raise self.failureException(msg)\n",
      "twisted.trial.unittest.FailTest:           0         1         2         3         4\n",
      "0  0.518748  0.051166  0.232859  0.492002  0.310235\n",
      "1  0.181764  0.504133  0.322810  0.258108  0.463985\n",
      "2  0.133284  0.927746  0.867702  0.707621  0.106214\n",
      "3  0.775877  0.807957  0.767765  0.113966  0.643908\n",
      "4  0.834325  0.577353  0.646407  0.458363  0.528707\n",
      "5  0.034377  0.638963  0.081447  0.435015  0.292655\n",
      "6  0.545428  0.133416  0.691643  0.795012  0.163354\n",
      "7  0.104313  0.145515  0.877128  0.528189  0.467261\n",
      "8  0.106712  0.649556  0.868000  0.828186  0.626055\n",
      "9  0.075279  0.112397  0.049309  0.257479  0.135661 is not an instance of <class 'numpy.ndarray'>\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.010s\n",
      "\n",
      "FAILED (failures=2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=2>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not remove or modify the code in this cell\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(X, y, train_size=10000, val_size=4510)\n",
    "run_unittests(['test_train_val_test_split'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd89f1c-7c0c-4aa5-9ffb-7ca8ad582661",
   "metadata": {},
   "source": [
    "## Task 3: Voting Ensemble Classifier\n",
    "\n",
    "In this task you will be creating a voting classifier as we have seen in our materials this week and\n",
    "train it on the `MagicTelescope` data we are using for this assignment.\n",
    "\n",
    "Implement the function named `task_3_voting_classifier()` in the `src/assg_tasks.py` module.  In this task we are going to create\n",
    "5 separate classifiers that will be added and trained with the voting classifier.  The function for this task should create\n",
    "the following 5 classifiers:\n",
    "\n",
    "1. 'knn': A k-nearest neighbors classifier\n",
    "2. 'dt': A basic decision tree classifier\n",
    "3. 'lr': A logistic regression classifier\n",
    "4. 'svc': A support vector classifier\n",
    "5. 'mlp': A multi-layer perceptron classifier (basically a neural network).\n",
    "\n",
    "In most all cases, just use the default classifier, do not specify any additional meta parameters for the object when you create it.  With the exception of\n",
    "the following cases:\n",
    "\n",
    "- For the logistic regression classifier, specify: `solver='sag'` and `max_iter=10000`, so that the model will converge when trained on the data.\n",
    "- For the support vector classifier use: `probability=True` so that we can use it in a soft voting ensemble.\n",
    "\n",
    "We will not be discussing neural network or multi-layer perceptrons in this class and have not used them before.  The `scikit-learn` object name for that type of classifer is simply `MLPClassifier` and it should just use the default parameters for that type of classifier.\n",
    "\n",
    "Make sure that you use the names shown above in the numbered list for each classifier instance when creating the voting classifier.  The tests of this\n",
    "task/function assume that they can access the classifiers in the returned voting ensemble by the names shown in the list.\n",
    "\n",
    "### Hard Voting Ensemble \n",
    "\n",
    "The data to train the voting ensemble is passed in to the function you are creating for this tasks.  Besides the data and labels, whether to use hard or soft\n",
    "voting is passed in as the third parameter.  Make sure you correctly use this parameter when creating  your voting ensemble so that we can test performance\n",
    "with either hard or soft voting.  And finally the tests expect that the returned voting ensemble is fit on the training data given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02d511c1-d37e-4187-8bc4-30df3862a05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_dt_estimator (test_assg_tasks.test_task_3_hard_voting_ensemble.test_dt_estimator)\n",
      "test_dt_estimator ... ERROR\n",
      "test_knn_estimator (test_assg_tasks.test_task_3_hard_voting_ensemble.test_knn_estimator)\n",
      "test_knn_estimator ... ERROR\n",
      "test_lr_estimator (test_assg_tasks.test_task_3_hard_voting_ensemble.test_lr_estimator)\n",
      "test_lr_estimator ... ERROR\n",
      "test_mlp_estimator (test_assg_tasks.test_task_3_hard_voting_ensemble.test_mlp_estimator)\n",
      "test_mlp_estimator ... ERROR\n",
      "test_svc_estimator (test_assg_tasks.test_task_3_hard_voting_ensemble.test_svc_estimator)\n",
      "test_svc_estimator ... ERROR\n",
      "test_voting_ensemble (test_assg_tasks.test_task_3_hard_voting_ensemble.test_voting_ensemble)\n",
      "test_voting_ensemble ... ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_dt_estimator (test_assg_tasks.test_task_3_hard_voting_ensemble.test_dt_estimator)\n",
      "test_dt_estimator\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg05/src/test_assg_tasks.py\", line 107, in test_dt_estimator\n",
      "    estimator_names = list(self.vc.named_estimators_.keys())\n",
      "AttributeError: 'NoneType' object has no attribute 'named_estimators_'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_knn_estimator (test_assg_tasks.test_task_3_hard_voting_ensemble.test_knn_estimator)\n",
      "test_knn_estimator\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg05/src/test_assg_tasks.py\", line 100, in test_knn_estimator\n",
      "    estimator_names = list(self.vc.named_estimators_.keys())\n",
      "AttributeError: 'NoneType' object has no attribute 'named_estimators_'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_lr_estimator (test_assg_tasks.test_task_3_hard_voting_ensemble.test_lr_estimator)\n",
      "test_lr_estimator\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg05/src/test_assg_tasks.py\", line 114, in test_lr_estimator\n",
      "    estimator_names = list(self.vc.named_estimators_.keys())\n",
      "AttributeError: 'NoneType' object has no attribute 'named_estimators_'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_mlp_estimator (test_assg_tasks.test_task_3_hard_voting_ensemble.test_mlp_estimator)\n",
      "test_mlp_estimator\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg05/src/test_assg_tasks.py\", line 128, in test_mlp_estimator\n",
      "    estimator_names = list(self.vc.named_estimators_.keys())\n",
      "AttributeError: 'NoneType' object has no attribute 'named_estimators_'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_svc_estimator (test_assg_tasks.test_task_3_hard_voting_ensemble.test_svc_estimator)\n",
      "test_svc_estimator\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg05/src/test_assg_tasks.py\", line 121, in test_svc_estimator\n",
      "    estimator_names = list(self.vc.named_estimators_.keys())\n",
      "AttributeError: 'NoneType' object has no attribute 'named_estimators_'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_voting_ensemble (test_assg_tasks.test_task_3_hard_voting_ensemble.test_voting_ensemble)\n",
      "test_voting_ensemble\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg05/src/test_assg_tasks.py\", line 135, in test_voting_ensemble\n",
      "    self.assertIsInstance(self.vc, sklearn.ensemble._voting.VotingClassifier)\n",
      "AttributeError: module 'sklearn' has no attribute 'ensemble'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.020s\n",
      "\n",
      "FAILED (errors=6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=6 errors=6 failures=0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not remove or modify the code in this cell\n",
    "vc = task_3_voting_ensemble(X_train, y_train, voting='hard')\n",
    "run_unittests(['test_task_3_hard_voting_ensemble'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1fb7fe-e153-490e-a6b2-e409681fee68",
   "metadata": {},
   "source": [
    "The voting classifier ensemble is returned from your task 3 function if you implemented it correctly.\n",
    "In the following cell(s) access the individual trained classifiers and report the performance of\n",
    "each individual classifier on the data it was trained with and on the validation data set that\n",
    "you should have available.  Do you notice any surprises?  Are the individual classifiers\n",
    "performing ok on the validation data, e.g. how does it compare to always guessing 1 (gamma signal)?\n",
    "Which classifier performs the best? Which is the worst?\n",
    "\n",
    "**HINT**: be careful, there are ways to access both the original estimators and the resulting fitted\n",
    "estimators.  You should be accessing the fitted estimators and reporting the accuracy performance\n",
    "on each individual estimator.  Also it would be best to access the estimators by name since this is alwo how\n",
    "we test your work in this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "543f8636-8bc5-4489-bf38-7c6b1ecd8a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# access the individual named classifiers in the ensemble and report accoracy on both the training data and the validation data here\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8cd59d-75af-4911-a616-2c80fa187784",
   "metadata": {},
   "source": [
    "If you did not modify the cell above then the classifier that you returned should be using\n",
    "hard voting.  Report the accuracy of the overall hard voting model in the next cell(s).\n",
    "\n",
    "Usually in my testing the performance on the unseen validation data will be at least as good as the\n",
    "best individual model, and usually shows some slight (though perhaps not significant) improvement\n",
    "in performance when using hard voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88a092ae-05cf-413b-b3b2-a1b513b1e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report the hard voting ensemble accuracy on both training and validation data here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0081bea9-536e-4307-be96-82e90abb399d",
   "metadata": {},
   "source": [
    "### Soft Voting Ensemble\n",
    "\n",
    "Now create another model (and run the tests), this time using soft voting.  The fitted individual models should not have changed\n",
    "here, they are all still being fit on the same training data.  But rerun your report of the performance of the\n",
    "voting ensemble using soft voting.  You should usually find a small but probably significant (1% or so) improvement\n",
    "over the hard voting ensemble results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66013dfa-5ef7-4880-bb31-259a048d6892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_voting_ensemble (test_assg_tasks.test_task_3_soft_voting_ensemble.test_voting_ensemble)\n",
      "test_voting_ensemble ... ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_voting_ensemble (test_assg_tasks.test_task_3_soft_voting_ensemble.test_voting_ensemble)\n",
      "test_voting_ensemble\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg05/src/test_assg_tasks.py\", line 148, in test_voting_ensemble\n",
      "    self.assertIsInstance(self.vc, sklearn.ensemble._voting.VotingClassifier)\n",
      "AttributeError: module 'sklearn' has no attribute 'ensemble'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.004s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=1 failures=0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not remove or modify the code in this cell\n",
    "vc = task_3_voting_ensemble(X_train, y_train, voting='soft')\n",
    "run_unittests(['test_task_3_soft_voting_ensemble'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64eb56b6-0323-4a93-a098-8f33c601960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# report the soft voting ensemble accuracy on both the training and alidation data here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00345cbf-aa1f-4872-a490-9728bb344d40",
   "metadata": {},
   "source": [
    "## Task 4: Bagging Classifier (Random Forest or Extra Trees)\n",
    "\n",
    "So far you have created a voting ensemble using a collection of very different types of\n",
    "machine learning algorithms.  We have not yet asked you to try and optimize the performance\n",
    "of the individual estimators nor the ensemble.\n",
    "\n",
    "As you should have learned from this week, we can create an ensemble in a different way,\n",
    "by ensembling a large number of the same type of estimator, but trying to differentiate\n",
    "them by having them sample only a subset of the inputs or the features of the\n",
    "data we want to model.  These are known as **Bagging** and **Pasting** types of ensembles.\n",
    "In fact random forests are sometimes refered to as a **Bag of Trees**.  Bagging ensembles\n",
    "are a much more commonly used ensemble than voting ensembles, and thus `scikit-learn` has\n",
    "random forest and extra trees classifiers as basic types in the library to create and use.\n",
    "\n",
    "This task is a bit more open ended than the previous one.  For this task complete the\n",
    "`task_4_bagging_ensemble()` function to create and fit a bagging type classifier on our\n",
    "`MagicTelescope` dataset.  For this task you can use either a Random Forest or\n",
    "an Extra (random) Trees classifier from `scikit-learn`.  Your goal in this section is\n",
    "to explore the parameters for these and try and find a bagging classifier that will beat\n",
    "the voting ensemble performance you achieved in the previous task (should not be that difficult).\n",
    "We did not optimize the previous ensemble, so you should be able to find a bagging ensemble that will do\n",
    "better than the voting ensemble from the previous task.  Don't forget to try\n",
    "different values of the `n_estimators`, this will have the most effect on a\n",
    "bag of classifiers, as well as exploring some of the other tree regularization\n",
    "parameters.\n",
    "\n",
    "As usual complete the `task_4_bagging_ensemble()` function in the `src/assg_tasks.py` \n",
    "module file.  The tests for this task only check that you use a random forest or an\n",
    "extra tree, and that you are getting a reasonably improved accuracy on the ensemble\n",
    "you create and fit for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d94c7d3-cd5e-4fb9-b202-72285592b7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_bag_of_trees_ensemble (test_assg_tasks.test_task_4_bag_of_trees_ensemble.test_bag_of_trees_ensemble)\n",
      "test_bag_of_trees_ensemble ... ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_bag_of_trees_ensemble (test_assg_tasks.test_task_4_bag_of_trees_ensemble.test_bag_of_trees_ensemble)\n",
      "test_bag_of_trees_ensemble\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg05/src/test_assg_tasks.py\", line 159, in test_bag_of_trees_ensemble\n",
      "    self.assertTrue(isinstance(self.bag, sklearn.ensemble._forest.RandomForestClassifier) or\n",
      "AttributeError: module 'sklearn' has no attribute 'ensemble'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.063s\n",
      "\n",
      "FAILED (errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=1 failures=0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not remove or modify the code in this cell\n",
    "bag = task_4_bag_of_trees_ensemble(X_train, y_train)\n",
    "run_unittests(['test_task_4_bag_of_trees_ensemble'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5181ad81-4286-4092-99f5-31e1b10923cf",
   "metadata": {},
   "source": [
    "If we were attempting to compete in a competition to get the best performing\n",
    "classifier for the MagicTelescope data, we would probably want to pay close\n",
    "attention to the ROC area under the curve characteristics of the models\n",
    "we were creating and testing.  In the following cell(s) \n",
    "\n",
    "1. Calculate the accuracy on the training data and the validation data for the\n",
    "   ensemble you created and returned in the task 4 function.\n",
    "2. Display the confusion matrix of your bag of trees classifier on the validation\n",
    "   data.\n",
    "3. Generate the ROC area under the curve performance for your ensemble classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a81c9ddf-0d60-4756-bb3a-8eb8c35ee7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. show accuracy on training and validation data of your bag of trees here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e13a87c9-2c48-4347-b407-73d7b08e9d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. display confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51779c9c-1250-4981-b72a-18e3549d85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. plot ROC AOC curve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140cbbbc-8dff-4607-9ed3-5b1487524a57",
   "metadata": {},
   "source": [
    "## Task 5: Utility Function for Training Data Stacking\n",
    "\n",
    "For your final two tasks we are going to be stacking the output of the set of 5 diverse estimators\n",
    "you created for the voting ensemble, and using this to train a new estimator to make the final prediciton (rather than simply\n",
    "taking a vote).  This is called a stacking ensemble by our textbook.\n",
    "\n",
    "It will be useful to have a utility function that will do some of the work we will need\n",
    "to create the stacked ensemble.  In this task you need to write a function\n",
    "named `create_stacked_data()`.  This function expects a `VotingClassifier`\n",
    "that has been fit and trained, and a set of `X` input data.\n",
    "You will be reusing the voting ensemble created in task 3, and will \n",
    "be using the estimators in the voting ensemble as the base estimators for the stacked\n",
    "ensemble you will create for the task 6.\n",
    "\n",
    "So for this function, you need to do the following:\n",
    "\n",
    "1. Iterate and access each estimator in the voting ensemble you are given as the first parameter\n",
    "   - Each estimator is already trained, so ask it to make probability\n",
    "     predictions on the input data `X` given.\n",
    "   - Gather all of the outputs into a regular python list.\n",
    "2. The list of probability outputs then needs to be stacked\n",
    "   horizontally.  For example, for our training data we have 5000 samples,\n",
    "   meaning that each estimator should generate a `(5000, 2)` shaped array\n",
    "   giving the probability of class 0 'h' and class 1 'g' respectively.  Stacking\n",
    "   these outputs for the 5 estimators should result in a `(5000, 10)`\n",
    "   shaped array that can be used as the input for a blending estimator.\n",
    "\n",
    "So in the following cell(s), complete the `create_stacked_data()` utility function\n",
    "so that it passes the tests for this task.  This function expects a voting\n",
    "ensemble that has already been fit and trained.  You will reuse the\n",
    "estimators of this ensemble as base estimators for the stacking task.  You \n",
    "are also given the inputs `X` that we need to generate probability estimates\n",
    "from the base estimators for.  This function returns the stacked\n",
    "outputs from all of the base estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13dc28eb-6459-4ae8-b70c-ce1d2947624c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_stack_random_data (test_assg_tasks.test_create_stacked_data.test_stack_random_data)\n",
      "test_stack_random_data ... ERROR\n",
      "test_stack_validation_data (test_assg_tasks.test_create_stacked_data.test_stack_validation_data)\n",
      "test_stack_validation_data ... FAIL\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_stack_random_data (test_assg_tasks.test_create_stacked_data.test_stack_random_data)\n",
      "test_stack_random_data\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg05/src/test_assg_tasks.py\", line 187, in test_stack_random_data\n",
      "    X = pd.DataFrame(data, columns=self.X_train.columns)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py\", line 827, in __init__\n",
      "    mgr = ndarray_to_mgr(\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/pandas/core/internals/construction.py\", line 336, in ndarray_to_mgr\n",
      "    _check_values_indices_shape_match(values, index, columns)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/pandas/core/internals/construction.py\", line 420, in _check_values_indices_shape_match\n",
      "    raise ValueError(f\"Shape of passed values is {passed}, indices imply {implied}\")\n",
      "ValueError: Shape of passed values is (500, 10), indices imply (500, 5)\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_stack_validation_data (test_assg_tasks.test_create_stacked_data.test_stack_validation_data)\n",
      "test_stack_validation_data\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg05/src/test_assg_tasks.py\", line 174, in test_stack_validation_data\n",
      "    self.assertEqual(X_stacked.shape, (4510, 10))\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 444, in assertEqual\n",
      "    super().assertEqual(first, second, msg)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 885, in assertEqual\n",
      "    assertion_func(first, second, msg=msg)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 1102, in assertTupleEqual\n",
      "    self.assertSequenceEqual(tuple1, tuple2, msg, seq_type=tuple)\n",
      "  File \"/opt/conda/lib/python3.12/unittest/case.py\", line 1073, in assertSequenceEqual\n",
      "    self.fail(msg)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/trial/_synctest.py\", line 381, in fail\n",
      "    raise self.failureException(msg)\n",
      "twisted.trial.unittest.FailTest: Tuples differ: (10, 5) != (4510, 10)\n",
      "\n",
      "First differing element 0:\n",
      "10\n",
      "4510\n",
      "\n",
      "- (10, 5)\n",
      "+ (4510, 10)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.013s\n",
      "\n",
      "FAILED (failures=1, errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=1 failures=1>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not remove or modify the code in this cell\n",
    "X_stacked = create_stacked_data(vc, X_train)\n",
    "run_unittests(['test_create_stacked_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d209aa03-84e5-438f-9395-bad7c10ea7b1",
   "metadata": {},
   "source": [
    "## Task 6: Create a Stacking Classifier by Hand\n",
    "\n",
    "As we implied in the previous task, you will be creating a stacked ensemble classifier by hand for this\n",
    "final task of the assignment.  You will be reusing your task 3 voting ensemble method, so that\n",
    "you don't have to recreate the work in training individual estimators to be stacked.\n",
    "So when implementing your `task_6_stacked_ensemble()` you should first simply call your\n",
    "`task_3_voting_ensemble()` method to train and fit the same 5 estimators again on the\n",
    "training data that is passed into this function.\n",
    "\n",
    "But you will not be using the voting ensemble in this method, you will simply want to\n",
    "access the trained estimators so you can create a stacked ensemble from them.  So after\n",
    "training the individual estimators using your previous method, perform the following:\n",
    "\n",
    "1. Reuse your task 3 function to train and fit a voting ensemble on the given training\n",
    "   data.  The estimators in this ensemble will be used as the base estimators of the stack.\n",
    "2. Reuse your `create_stacked_data()` function to stack the probability predictions of each of the\n",
    "   named estimators into a new resulting array.  Make sure that the stacked data is\n",
    "   created using the validation data set passed in to this function.\n",
    "3. Create a new classifier to train on this new input.  For this task use\n",
    "   a `SVC` classifier to train for the final blending.  Make sure that you correctly train\n",
    "   it using your stacked data from the validation inputs, and the `y` validation labels.\n",
    "4. This function should then return the `blending_estimator` and the `voting_ensemble` that\n",
    "   were trained and fit by your function on the training and validation data.\n",
    "\n",
    "The tests again are relatively simple for this function, they just check that you are\n",
    "creating and returning a `SVC` for the blending estimator and that it gets expected performance\n",
    "on the training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fe65648-c17d-4aaa-8253-4395c83557f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_blending_estimator (test_assg_tasks.test_task_6_stacked_ensemble.test_blending_estimator)\n",
      "test_blending_estimator ... ERROR\n",
      "test_voting_ensemble (test_assg_tasks.test_task_6_stacked_ensemble.test_voting_ensemble)\n",
      "test_voting_ensemble ... ERROR\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_blending_estimator (test_assg_tasks.test_task_6_stacked_ensemble.test_blending_estimator)\n",
      "test_blending_estimator\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg05/src/test_assg_tasks.py\", line 215, in test_blending_estimator\n",
      "    self.assertIsInstance(self.blending_estimator, sklearn.svm._classes.SVC)\n",
      "AttributeError: module 'sklearn' has no attribute 'svm'\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_voting_ensemble (test_assg_tasks.test_task_6_stacked_ensemble.test_voting_ensemble)\n",
      "test_voting_ensemble\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/defer.py\", line 209, in maybeDeferred\n",
      "    result = f(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 227, in runWithWarningsSuppressed\n",
      "    raise exc_info[1].with_traceback(exc_info[2])\n",
      "  File \"/opt/conda/lib/python3.12/site-packages/twisted/internet/utils.py\", line 223, in runWithWarningsSuppressed\n",
      "    result = f(*a, **kw)\n",
      "  File \"/workspaces/assg05/src/test_assg_tasks.py\", line 209, in test_voting_ensemble\n",
      "    self.assertIsInstance(self.voting_ensemble, sklearn.ensemble._voting.VotingClassifier)\n",
      "AttributeError: module 'sklearn' has no attribute 'ensemble'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.007s\n",
      "\n",
      "FAILED (errors=2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=2 failures=0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do not remove or modify the code in this cell\n",
    "blending_estimator, voting_ensemble = task_6_stacked_ensemble(X_train, y_train, X_val, y_val)\n",
    "run_unittests(['test_task_6_stacked_ensemble'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246c65f9-8191-42b1-a0d4-818ce541e9c8",
   "metadata": {},
   "source": [
    "Lets evaluate the performance a bit of this stacked classifier.  First of all, calculate the overall accuracy using both the training data as input to the\n",
    "stack, and the validation data as input to the stack.  To do this, you have to recreate some of the work you just did in your function.  You will need to generate\n",
    "the stacked output for the train and validation sets, and use that to ask for the accuracy scores from the final `blending_estimator` that was returned.\n",
    "You should reuse your `create_stacked_data()` function to do this.\n",
    "Report the accuracy on the training data and validation data in the next cell(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc51f6fb-a838-4305-aab8-501dd2a51354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first report accuracy score on training data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e09571d7-8772-44bf-8ed4-a18b7a2ba038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now report accuracy score on validation data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddc5425-1e10-41dd-a775-c0a14bfb550f",
   "metadata": {},
   "source": [
    "You should compare your accuracy score to the result you had for the soft voting classifier, as this is\n",
    "the most similar model.  We have simply replaced the soft vote with a new blending estimator to \n",
    "decide on the final answer.\n",
    "\n",
    "However, if you created the model correctly, then you used the training data set to train the base\n",
    "models in the voting ensemble, and you used the validation data set to generate training data to train\n",
    "the blender estimator.  So it is unfair to use either of these to evaluate the performance of the\n",
    "stacked model here, both were seen in the training of various estimators in the stack.\n",
    "\n",
    "So instead in the next cell(s) evaluate the stacked model on the unseen test data set, which we have\n",
    "not used at all in this assignment up to the point.  Show the accuracy again on the held back test data.\n",
    "But also show the confusion matrix and the ROC curve for the stacked model results here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0ebd6d1-0705-48b8-b38d-48a000caa915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy on unseen test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7bb28e2c-cda6-4ee2-8fa1-830921b6c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc27d325-7c5d-4ed7-ad4e-e815923a40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC area under curve for the stacked ensemble\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b25f62d-f40c-45c3-a1c4-70072b1ffaf9",
   "metadata": {},
   "source": [
    "If you performed the stacking ensemble correctly, you should usually find that it will give\n",
    "about the same performance as the soft voting classifier.  Usually it will be a bit above,\n",
    "but not obviously significantly so. \n",
    "\n",
    "And comparing this to the bag of trees classifer you created for task 4, usually the\n",
    "soft votining and stacking classifiers will not be quite as good as easily discovered\n",
    "bag of trees.  Though we have not had you try and tune any of the base estimators\n",
    "yet, so probably it would be easy to match the bag of trees with the base estimators\n",
    "we have been using here, with a bit of tuning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
