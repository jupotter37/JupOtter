{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-22T12:37:44.932740Z",
     "start_time": "2023-06-22T12:37:44.793740700Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatetime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m datetime, timedelta\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tt\\lib\\site-packages\\pandas\\__init__.py:22\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# numpy compat\u001B[39;00m\n\u001B[1;32m---> 22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m is_numpy_dev \u001B[38;5;28;01mas\u001B[39;00m _is_numpy_dev  \u001B[38;5;66;03m# pyright: ignore # noqa:F401\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_libs\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m hashtable \u001B[38;5;28;01mas\u001B[39;00m _hashtable, lib \u001B[38;5;28;01mas\u001B[39;00m _lib, tslib \u001B[38;5;28;01mas\u001B[39;00m _tslib\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tt\\lib\\site-packages\\pandas\\compat\\__init__.py:17\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TYPE_CHECKING\n\u001B[1;32m---> 17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_typing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m F\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     19\u001B[0m     is_numpy_dev,\n\u001B[0;32m     20\u001B[0m     np_version_under1p21,\n\u001B[0;32m     21\u001B[0m )\n\u001B[0;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyarrow\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     23\u001B[0m     pa_version_under1p01,\n\u001B[0;32m     24\u001B[0m     pa_version_under2p0,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     31\u001B[0m     pa_version_under9p0,\n\u001B[0;32m     32\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\tt\\lib\\site-packages\\pandas\\_typing.py:89\u001B[0m\n\u001B[0;32m     85\u001B[0m HashableT \u001B[38;5;241m=\u001B[39m TypeVar(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHashableT\u001B[39m\u001B[38;5;124m\"\u001B[39m, bound\u001B[38;5;241m=\u001B[39mHashable)\n\u001B[0;32m     87\u001B[0m \u001B[38;5;66;03m# array-like\u001B[39;00m\n\u001B[1;32m---> 89\u001B[0m ArrayLike \u001B[38;5;241m=\u001B[39m Union[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExtensionArray\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mndarray\u001B[49m]\n\u001B[0;32m     90\u001B[0m AnyArrayLike \u001B[38;5;241m=\u001B[39m Union[ArrayLike, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIndex\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSeries\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m     92\u001B[0m \u001B[38;5;66;03m# scalars\u001B[39;00m\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'numpy' has no attribute 'ndarray'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"completeDataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1021221"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alexandre\\anaconda3\\envs\\tr10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/roberta-hate-speech-dynabench-r1-target\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"facebook/roberta-hate-speech-dynabench-r1-target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "\n",
    "for a in df['Tweet Treated']: \n",
    "    tokens.append(tokenizer(a, padding=True, max_length=512, truncation=True, return_tensors=\"pt\").to(device))\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferences = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tk in tokens:\n",
    "        md = model(**tk)\n",
    "        logits = md.logits\n",
    "        scores = logits.softmax(dim=1).tolist()[0]\n",
    "        predicted_class_id = logits.argmax().item()\n",
    "        scores.insert(0 ,model.config.id2label[predicted_class_id])\n",
    "        inferences.append(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_inference</th>\n",
       "      <th>normal_score</th>\n",
       "      <th>hate_speech_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nothate</td>\n",
       "      <td>0.999554</td>\n",
       "      <td>0.000447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nothate</td>\n",
       "      <td>0.999679</td>\n",
       "      <td>0.000321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nothate</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>0.000289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nothate</td>\n",
       "      <td>0.998655</td>\n",
       "      <td>0.001345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nothate</td>\n",
       "      <td>0.999884</td>\n",
       "      <td>0.000116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_inference  normal_score  hate_speech_score\n",
       "0         nothate      0.999554           0.000447\n",
       "1         nothate      0.999679           0.000321\n",
       "2         nothate      0.999711           0.000289\n",
       "3         nothate      0.998655           0.001345\n",
       "4         nothate      0.999884           0.000116"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_outpus =  ['model_inference', 'normal_score', 'hate_speech_score']\n",
    "output_df  = pd.DataFrame(inferences,columns = col_outpus)\n",
    "output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.hate_speech_score = output_df.hate_speech_score.round(4)\n",
    "output_df.normal_score = output_df.normal_score.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = output_df.reset_index()\n",
    "\n",
    "completeDataset = pd.concat([df, output_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "completeDataset.to_csv(\"completeDataset_inference.csv\", index=False, quoting=csv.QUOTE_NONNUMERIC)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
