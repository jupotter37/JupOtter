{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5075c11e-e98b-4a90-8734-156391d770fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "134e411c-2c2a-403c-961b-9149efcb850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from enum import Enum\n",
    "from typing import Tuple, List\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, Subset, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import *\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "IMG_EXTENSIONS = [\n",
    "    \".jpg\", \".JPG\", \".jpeg\", \".JPEG\", \".png\",\n",
    "    \".PNG\", \".ppm\", \".PPM\", \".bmp\", \".BMP\",\n",
    "]\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9104aa1d-a640-4eae-bfab-7f576b6ae4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Configurations\n",
    "data_dir = '../input/data/train'\n",
    "img_dir = f'{data_dir}/images'\n",
    "img1_dir =f'{data_dir}/image_blend'\n",
    "df_path = f'{data_dir}/train.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bd1ee5-1bd4-4292-820b-ea2a42199094",
   "metadata": {},
   "source": [
    "# Dataset 구성 / DataLoad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669bea18-c70a-4900-97ba-429015a7db49",
   "metadata": {},
   "source": [
    "## Dataset 구성 함수\n",
    "  \n",
    "###   <span style ='color:red'> 변경한 부분 </span>\n",
    "1. 나이 구분 [1,28,56,60] 이걸 조금 변경해도 다르게 나올수도 있을거 같아요!\n",
    "2. 학습 부분 mask 3, mask4, incorrect_mask, normal 만 사용했습니다.\n",
    "3. 가우시안 노이즈 확률을 조금 낮췄어요! 그냥 개인적 취향으로 노이즈 덜 넣고 싶어서 아무이유 없이 했습니다.\n",
    "4. image blend를 dataset으로 만들수 있는 함수 maskmorebasedataset 인데 학습은 본 데이터 셋만 되도록 해놨습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6433ad7-3c0c-4286-b19d-f6c3116a0d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ext(img_dir, img_id):\n",
    "    filename = os.listdir(os.path.join(img_dir, img_id))[0]\n",
    "    ext = os.path.splitext(filename)[-1].lower()\n",
    "    return ext\n",
    "\n",
    "def get_img_stats(img_dir, img_ids):\n",
    "    img_info = dict(heights=[], widths=[], means=[], stds=[])\n",
    "    for img_id in tqdm(img_ids):\n",
    "        for path in glob(os.path.join(img_dir, img_id, '*')):\n",
    "            img = np.array(Image.open(path))\n",
    "            h, w, _ = img.shape\n",
    "            img_info['heights'].append(h)\n",
    "            img_info['widths'].append(w)\n",
    "            img_info['means'].append(img.mean(axis=(0,1)))\n",
    "            img_info['stds'].append(img.std(axis=(0,1)))\n",
    "    return img_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6028749d-a834-42ce-8612-a76d9c55e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 마스크 여부, 성별, 나이를 mapping할 클래스를 생성합니다.\n",
    "\n",
    "class MaskLabels(int, Enum):\n",
    "    MASK = 0\n",
    "    INCORRECT = 1\n",
    "    NORMAL = 2\n",
    "\n",
    "    \n",
    "\n",
    "class GenderLabels(int, Enum):\n",
    "    MALE = 0\n",
    "    FEMALE = 1\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(cls, value: str) -> int:\n",
    "        value = value.lower()\n",
    "        if value == \"male\":\n",
    "            return cls.MALE\n",
    "        elif value == \"female\":\n",
    "            return cls.FEMALE\n",
    "        else:\n",
    "            raise ValueError(f\"Gender value should be either 'male' or 'female', {value}\")\n",
    "\n",
    "\n",
    "class AgeLabels(int, Enum):\n",
    "    YOUNG = 0\n",
    "    MIDDLE = 1\n",
    "    OLD = 2\n",
    "\n",
    "    @classmethod\n",
    "    def from_number(cls, value: str) -> int:\n",
    "        try:\n",
    "            value = int(value)\n",
    "        except Exception:\n",
    "            raise ValueError(f\"Age value should be numeric, {value}\")\n",
    "\n",
    "        if value < 29 :\n",
    "            return cls.YOUNG\n",
    "        elif value < 57 :\n",
    "            return cls.MIDDLE\n",
    "        else:\n",
    "            return cls.OLD\n",
    "        \n",
    "class AgeLabels2(int, Enum):\n",
    "    YOUNG = 0\n",
    "    MIDDLE = 1\n",
    "    OLD = 2\n",
    "\n",
    "    @classmethod\n",
    "    def from_str(cls, value: str) -> int:\n",
    "        value = value.lower()\n",
    "        if value == \"middle\":\n",
    "            return cls.MIDDLE\n",
    "        elif value == \"elder\":\n",
    "            return cls.OLD\n",
    "        else:\n",
    "            raise ValueError(f\"Age value should be character, {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef160c35-aae5-4dd5-9fce-c3da25a9b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "def get_transforms(need=('train', 'val'), img_size=(512, 384), mean=(0.548, 0.504, 0.479), std=(0.237, 0.247, 0.246)):\n",
    "    \"\"\"\n",
    "    train 혹은 validation의 augmentation 함수를 정의합니다. train은 데이터에 많은 변형을 주어야하지만, validation에는 최소한의 전처리만 주어져야합니다.\n",
    "    \n",
    "    Args:\n",
    "        need: 'train', 혹은 'val' 혹은 둘 다에 대한 augmentation 함수를 얻을 건지에 대한 옵션입니다.\n",
    "        img_size: Augmentation 이후 얻을 이미지 사이즈입니다.\n",
    "        mean: 이미지를 Normalize할 때 사용될 RGB 평균값입니다.\n",
    "        std: 이미지를 Normalize할 때 사용될 RGB 표준편차입니다.\n",
    "\n",
    "    Returns:\n",
    "        transformations: Augmentation 함수들이 저장된 dictionary 입니다. transformations['train']은 train 데이터에 대한 augmentation 함수가 있습니다.\n",
    "    \"\"\"\n",
    "    transformations = {}\n",
    "    if 'train' in need:\n",
    "        transformations['train'] = Compose([\n",
    "            Resize(img_size[0], img_size[1], p=1.0),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.5),\n",
    "            HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.5),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), p=0.5),\n",
    "            GaussNoise(p=0.3),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "    if 'val' in need:\n",
    "        transformations['val'] = Compose([\n",
    "            Resize(img_size[0], img_size[1]),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], p=1.0)\n",
    "    return transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "088bebc7-ecce-4023-b7a9-ab8a168d6588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "class MaskBaseDataset(data.Dataset):\n",
    "    num_classes = 3 * 2 * 3\n",
    "\n",
    "    _file_names = {\n",
    "        #\"mask1\": MaskLabels.MASK,\n",
    "        #\"mask2\": MaskLabels.MASK,\n",
    "        \"mask3\": MaskLabels.MASK,\n",
    "        \"mask4\": MaskLabels.MASK,\n",
    "        #\"mask5\": MaskLabels.MASK,\n",
    "        \"incorrect_mask\": MaskLabels.INCORRECT,\n",
    "        \"normal\": MaskLabels.NORMAL\n",
    "    }\n",
    "\n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "\n",
    "    def __init__(self, img_dir, mean, std, transform=None):\n",
    "        \"\"\"\n",
    "        MaskBaseDataset을 initialize 합니다.\n",
    "\n",
    "        Args:\n",
    "            img_dir: 학습 이미지 폴더의 root directory 입니다.\n",
    "            transform: Augmentation을 하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.img_dir = img_dir\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.transform = transform\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        \"\"\"\n",
    "        transform 함수를 설정하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        \n",
    "    def setup(self):\n",
    "        \"\"\"\n",
    "        image의 경로와 각 이미지들의 label을 계산하여 저장해두는 함수입니다.\n",
    "        \"\"\"\n",
    "        profiles = os.listdir(self.img_dir)\n",
    "        for profile in profiles:\n",
    "            if profile.startswith(\".\"):  # \".\" 로 시작하는 파일은 무시합니다\n",
    "                continue\n",
    "\n",
    "            img_folder = os.path.join(self.img_dir, profile)\n",
    "            for file_name in os.listdir(img_folder):\n",
    "                _file_name, ext = os.path.splitext(file_name)\n",
    "                if _file_name not in self._file_names:  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "                    continue\n",
    "\n",
    "                img_path = os.path.join(self.img_dir, profile, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "                mask_label = self._file_names[_file_name]\n",
    "\n",
    "                id, gender, race, age = profile.split(\"_\")\n",
    "                gender_label = GenderLabels.from_str(gender)\n",
    "                age_label = AgeLabels.from_number(age)\n",
    "\n",
    "                self.image_paths.append(img_path)\n",
    "                self.mask_labels.append(mask_label)\n",
    "                self.gender_labels.append(gender_label)\n",
    "                self.age_labels.append(age_label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        데이터를 불러오는 함수입니다. \n",
    "        데이터셋 class에 데이터 정보가 저장되어 있고, index를 통해 해당 위치에 있는 데이터 정보를 불러옵니다.\n",
    "        \n",
    "        Args:\n",
    "            index: 불러올 데이터의 인덱스값입니다.\n",
    "        \"\"\"\n",
    "        # 이미지를 불러옵니다.\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # 레이블을 불러옵니다.\n",
    "        mask_label = self.mask_labels[index]\n",
    "        gender_label = self.gender_labels[index]\n",
    "        age_label = self.age_labels[index]\n",
    "        multi_class_label = mask_label * 6 + gender_label * 3 + age_label\n",
    "        \n",
    "        # 이미지를 Augmentation 시킵니다.\n",
    "        image_transform = self.transform(image=np.array(image))['image']\n",
    "        return image_transform, multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "\n",
    "\n",
    "img1_dir =f'{data_dir}/image_blend/'\n",
    "class MaskMoreBaseDataset(data.Dataset):\n",
    "    num_classes = 3 * 2 * 3\n",
    "    \n",
    "    _file_names = {\n",
    "        \"incorrect\": MaskLabels.INCORRECT,\n",
    "        \"normal\": MaskLabels.NORMAL\n",
    "    }\n",
    "        \n",
    "    image_paths = []\n",
    "    mask_labels = []\n",
    "    gender_labels = []\n",
    "    age_labels = []\n",
    "\n",
    "    def __init__(self, img_dir, mean, std, transform=None):\n",
    "        \"\"\"\n",
    "        MaskBaseDataset을 initialize 합니다.\n",
    "\n",
    "        Args:\n",
    "            img_dir: 학습 이미지 폴더의 root directory 입니다.\n",
    "            transform: Augmentation을 하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.img_dir = img1_dir\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.transform = transform\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def set_transform(self, transform):\n",
    "        \"\"\"\n",
    "        transform 함수를 설정하는 함수입니다.\n",
    "        \"\"\"\n",
    "        self.transform = transform\n",
    "        \n",
    "    def setup(self):\n",
    "        \"\"\"\n",
    "        image의 경로와 각 이미지들의 label을 계산하여 저장해두는 함수입니다.\n",
    "        \n",
    "        img_dir = f'{data_dir}/image_blend/\n",
    "        profiles =elder_male, middle_male\n",
    "        profile = incorrect, normal\n",
    "        \"\"\"\n",
    "        profiles = os.listdir(self.img_dir)\n",
    "        #print(profiles)\n",
    "        for profile in profiles: # eldermale, middle male\n",
    "            if profile.startswith(\".\"):  # \".\" 로 시작하는 파일은 무시합니다\n",
    "                continue\n",
    "            age, gender = profile.split(\"_\")\n",
    "            #print(age,gender)\n",
    "            gender_label = GenderLabels.from_str(gender)\n",
    "            age_label = AgeLabels2.from_str(age)\n",
    "            age_gender_forder = os.path.join(self.img_dir, profile)\n",
    "           # print(age_gender_forder)\n",
    "            for forders in os.listdir(age_gender_forder): # incorrect, normal\n",
    "                #print(forders)\n",
    "                if forders.startswith(\".\") :\n",
    "                    continue\n",
    "                image_forder = os.path.join(self.img_dir, profile, forders)                         \n",
    "                for file_name in os.listdir(image_forder):\n",
    "                    _file_name, ext = file_name.split('_')\n",
    "                    if _file_name not in self._file_names:  # \".\" 로 시작하는 파일 및 invalid 한 파일들은 무시합니다\n",
    "                        continue\n",
    "\n",
    "                    img_path = os.path.join(self.img_dir, profile,forders, file_name)  # (resized_data, 000004_male_Asian_54, mask1.jpg)\n",
    "   \n",
    "                    mask_label = self._file_names[_file_name]\n",
    "                   \n",
    "\n",
    "                   \n",
    "                    #print(img_path, mask_label)\n",
    "                    self.image_paths.append(img_path)\n",
    "                    self.mask_labels.append(mask_label)\n",
    "                    self.gender_labels.append(gender_label)\n",
    "                    self.age_labels.append(age_label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        데이터를 불러오는 함수입니다. \n",
    "        데이터셋 class에 데이터 정보가 저장되어 있고, index를 통해 해당 위치에 있는 데이터 정보를 불러옵니다.\n",
    "        \n",
    "        Args:\n",
    "            index: 불러올 데이터의 인덱스값입니다.\n",
    "        \"\"\"\n",
    "        # 이미지를 불러옵니다.\n",
    "        image_path = self.image_paths[index]\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # 레이블을 불러옵니다.\n",
    "        mask_label = self.mask_labels[index]\n",
    "        gender_label = self.gender_labels[index]\n",
    "        age_label = self.age_labels[index]\n",
    "        multi_class_label = mask_label * 6 + gender_label * 3 + age_label\n",
    "        \n",
    "        # 이미지를 Augmentation 시킵니다.\n",
    "        image_transform = self.transform(image=np.array(image))['image']\n",
    "        return image_transform, multi_class_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87474459-62e6-450f-a243-b9382cf0a7f8",
   "metadata": {},
   "source": [
    "## Dataset 선언 / Train & Validation 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9af5e648-bfd4-4a2f-9701-8d3703c90fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정의한 Augmentation 함수와 Dataset 클래스 객체를 생성합니다.\n",
    "mean, std = (0.56019358, 0.52410121,0.501457), (0.23318603, 0.24300033, 0.24567522)\n",
    "transform = get_transforms(mean=mean, std=std)\n",
    "\n",
    "dataset = MaskBaseDataset(\n",
    "    img_dir=img_dir,\n",
    "    mean=mean,\n",
    "    std=std\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90b4419a-47aa-4f61-a9f5-b2d43a97a735",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ConcatDataset' object has no attribute 'set_transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-713c3f9467f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 각 dataset에 augmentation 함수를 설정합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ConcatDataset' object has no attribute 'set_transform'"
     ]
    }
   ],
   "source": [
    "# train dataset과 validation dataset을 8:2 비율로 나눕니다.\n",
    "n_val = int(len(dataset) * 0.2)\n",
    "n_train = len(dataset) - n_val\n",
    "train_dataset, val_dataset = data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "# 각 dataset에 augmentation 함수를 설정합니다.\n",
    "train_dataset.dataset.set_transform(transform['train'])\n",
    "val_dataset.dataset.set_transform(transform['val'])\n",
    "\n",
    "\n",
    "# training dataloader은 데이터를 섞어주어야 합니다. (shuffle=True)\n",
    "train_loader = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=12,\n",
    "    num_workers=4,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=12,\n",
    "    num_workers=4,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e329ce-b190-4939-935a-69e9549e1dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader dict 만들기\n",
    "dloaders = {'train':train_loader, 'valid':val_loader}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bc2e7c-6baa-4273-a363-6426ca852dd2",
   "metadata": {},
   "source": [
    "# Train Model / Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa17e024-07e0-4c9e-b32d-19a82521e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dataloders, model, criterion, optimizer, scheduler, num_epochs):\n",
    "    since = time.time()\n",
    "    use_gpu = torch.cuda.is_available()\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    dataset_sizes = {'train': len(dataloders['train'].dataset), \n",
    "                     'valid': len(dataloders['valid'].dataset)}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train(True)\n",
    "            else:\n",
    "                model.train(False)\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for inputs, labels in dataloders[phase]:\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "               # running_loss += loss.data[0]\n",
    "                running_loss += loss.data\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                train_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                train_epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "            else:\n",
    "                valid_epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                valid_epoch_acc = running_corrects / dataset_sizes[phase]\n",
    "                \n",
    "            if phase == 'valid' and valid_epoch_acc > best_acc:\n",
    "                best_acc = valid_epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "        print('Epoch [{}/{}] train loss: {:.4f} acc: {:.4f} ' \n",
    "              'valid loss: {:.4f} acc: {:.4f}'.format(\n",
    "                epoch, num_epochs - 1,\n",
    "                train_epoch_loss, train_epoch_acc, \n",
    "                valid_epoch_loss, valid_epoch_acc))\n",
    "            \n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4180c41-5bf5-411e-ba2a-97fb17bd03a8",
   "metadata": {},
   "source": [
    "## 모델 불러오기 / Optim 구성\n",
    "1. adam을 사용해 봤는데 parameter 설정을 잘못한건지 SGD보다 덜한 성능을 보였습니다.\n",
    "2. ExpotentialLR도 사용해봤는데 multistepLR 보다 덜한 성능을 보였습니다.\n",
    "<br>어떤 기준으로 optim을 사용해야 하는지는 잘 모르겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b3446e-2f32-4141-923e-59c3e1234e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "model = torchvision.models.wide_resnet50_2(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.required_grad = False\n",
    "\n",
    "\n",
    "num_ftrt = model.fc.in_features\n",
    "\n",
    "model.fc = nn.Linear(num_ftrt,18)\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cc33534-83ea-44da-8456-85b792b29152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.5)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[4,6], gamma=0.06)\n",
    "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma= 0.45)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2dae65a9-58f0-48d0-b6e5-bd1328360251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/4] train loss: 0.3383 acc: 0.1708 valid loss: 0.3319 acc: 0.2750\n",
      "Epoch [1/4] train loss: 0.3379 acc: 0.1708 valid loss: 0.3447 acc: 0.2417\n",
      "Epoch [2/4] train loss: 0.3416 acc: 0.1792 valid loss: 0.3879 acc: 0.1750\n",
      "Epoch [3/4] train loss: 0.3441 acc: 0.1917 valid loss: 0.3786 acc: 0.2083\n",
      "Epoch [4/4] train loss: 0.3410 acc: 0.1792 valid loss: 0.3527 acc: 0.2583\n",
      "Best val Acc: 0.275000\n",
      "Training time:   1.040423 minutes\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "start_time = time.time()\n",
    "model = train_model(dloaders, model, criterion, optimizer, scheduler, num_epochs=5)\n",
    "print('Training time: {:10f} minutes'.format((time.time()-start_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5cd96c3-ac69-46ff-b8b8-0724dbff1a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model, '../models/Res50_wide.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
