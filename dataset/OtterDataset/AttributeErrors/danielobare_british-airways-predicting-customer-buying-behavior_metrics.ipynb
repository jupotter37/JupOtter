{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb55247d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "df = pd.read_csv(\"creditcard.csv\")[:80_000]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8f7a2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shapes of X=(80000, 28) y=(80000,), #Fraud Cases=196'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['Time', 'Amount', 'Class']).values\n",
    "y = df['Class'].values\n",
    "f\"Shapes of X={X.shape} y={y.shape}, #Fraud Cases={y.sum()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c199a45f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mod = LogisticRegression(class_weight={0: 1, 1: 2}, max_iter=1000)\n",
    "mod.fit(X, y).predict(X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb4051fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LogisticRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[43mLogisticRegression\u001b[49m()\n\u001b[0;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpinfo2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr.score\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LogisticRegression' is not defined"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "??lr.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3590121",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m     precision \u001b[38;5;241m=\u001b[39m precision_score(y_true, y_pred)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(recall, precision)\n\u001b[0;32m      9\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m---> 10\u001b[0m     estimator \u001b[38;5;241m=\u001b[39m \u001b[43mlr\u001b[49m(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m),\n\u001b[0;32m     11\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass_weight\u001b[39m\u001b[38;5;124m'\u001b[39m: [{\u001b[38;5;241m0\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m: v} \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinspace (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m)]},\n\u001b[0;32m     12\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(precision_score),\n\u001b[0;32m     13\u001b[0m              \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecall_score\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(recall_score),\n\u001b[0;32m     14\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_both\u001b[39m\u001b[38;5;124m'\u001b[39m: make_scorer(min_recall_precision)}, \n\u001b[0;32m     15\u001b[0m     refit \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_both\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     16\u001b[0m     return_train_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     17\u001b[0m     cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m,\n\u001b[0;32m     18\u001b[0m     n_jobs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m grid\u001b[38;5;241m.\u001b[39mfit(X, y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lr' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "\n",
    "def min_recall_precision(est, X, y_true, sample_weight=None):\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    return min(recall, precision)\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator = LogisticRegression(max_iter=1000),\n",
    "    param_grid={'class_weight': [{0: 1, 1: v} for v in np.linspace (1, 20, 30)]},\n",
    "    scoring={'precision': make_scorer(precision_score),\n",
    "             'recall_score': make_scorer(recall_score),\n",
    "            'min_both': make_scorer(min_recall_precision)}, \n",
    "    refit = 'min_both',\n",
    "    return_train_score=True,\n",
    "    cv = 10,\n",
    "    n_jobs = -1\n",
    ")\n",
    "grid.fit(X, y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444cdf4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2.2509551 , 2.13090239, 2.02991667, 2.05384459, 1.91615381,\n",
       "        2.39396856, 2.51818612, 2.30205808, 2.23471434, 2.44651997,\n",
       "        2.0881434 , 2.14116218, 2.15684147, 2.05831149, 2.03057036,\n",
       "        2.17027678, 2.20340989, 2.23579936, 2.2048517 , 2.23020065,\n",
       "        2.21089098, 2.2002589 , 2.25495956, 2.09738388, 2.46190627,\n",
       "        2.1337214 , 2.33243468, 2.28127205, 2.2076432 , 2.20122211]),\n",
       " 'std_fit_time': array([0.29632971, 0.31384326, 0.16447891, 0.22362577, 0.39035763,\n",
       "        0.42023479, 0.28844357, 0.19119305, 0.24419057, 0.3928654 ,\n",
       "        0.24386733, 0.32669651, 0.22455438, 0.32583377, 0.24288495,\n",
       "        0.28427783, 0.27710791, 0.24810661, 0.18098827, 0.26596157,\n",
       "        0.26918482, 0.29888167, 0.26833705, 0.27962972, 0.20766256,\n",
       "        0.275314  , 0.39206144, 0.26263153, 0.32479318, 0.26383677]),\n",
       " 'mean_score_time': array([0.05183172, 0.06094878, 0.05532076, 0.04879453, 0.04882162,\n",
       "        0.06356938, 0.07332768, 0.06165643, 0.04335508, 0.05641258,\n",
       "        0.06883721, 0.0535749 , 0.05289528, 0.04764724, 0.06555746,\n",
       "        0.05904226, 0.05348594, 0.0556746 , 0.04754431, 0.0879168 ,\n",
       "        0.05146613, 0.0491008 , 0.05203998, 0.06793559, 0.05727077,\n",
       "        0.05456486, 0.05198133, 0.05662267, 0.06464472, 0.05068033]),\n",
       " 'std_score_time': array([0.00805834, 0.01821661, 0.01719366, 0.01018984, 0.00733968,\n",
       "        0.01669032, 0.02412464, 0.01843158, 0.00722456, 0.01176174,\n",
       "        0.02133713, 0.01541055, 0.01003288, 0.01083154, 0.02886654,\n",
       "        0.01421649, 0.01027057, 0.01286096, 0.01304696, 0.07332536,\n",
       "        0.01360008, 0.00937816, 0.01154451, 0.02312491, 0.01835846,\n",
       "        0.01594551, 0.01097481, 0.01952089, 0.02147157, 0.01026132]),\n",
       " 'param_class_weight': masked_array(data=[{0: 1, 1: 1.0}, {0: 1, 1: 1.6551724137931034},\n",
       "                    {0: 1, 1: 2.310344827586207},\n",
       "                    {0: 1, 1: 2.9655172413793105},\n",
       "                    {0: 1, 1: 3.6206896551724137},\n",
       "                    {0: 1, 1: 4.275862068965517},\n",
       "                    {0: 1, 1: 4.931034482758621},\n",
       "                    {0: 1, 1: 5.586206896551724},\n",
       "                    {0: 1, 1: 6.241379310344827},\n",
       "                    {0: 1, 1: 6.896551724137931},\n",
       "                    {0: 1, 1: 7.551724137931034},\n",
       "                    {0: 1, 1: 8.206896551724139},\n",
       "                    {0: 1, 1: 8.862068965517242},\n",
       "                    {0: 1, 1: 9.517241379310345},\n",
       "                    {0: 1, 1: 10.172413793103448},\n",
       "                    {0: 1, 1: 10.827586206896552},\n",
       "                    {0: 1, 1: 11.482758620689655},\n",
       "                    {0: 1, 1: 12.137931034482758},\n",
       "                    {0: 1, 1: 12.793103448275861},\n",
       "                    {0: 1, 1: 13.448275862068964},\n",
       "                    {0: 1, 1: 14.103448275862068},\n",
       "                    {0: 1, 1: 14.758620689655173},\n",
       "                    {0: 1, 1: 15.413793103448276},\n",
       "                    {0: 1, 1: 16.06896551724138},\n",
       "                    {0: 1, 1: 16.724137931034484},\n",
       "                    {0: 1, 1: 17.379310344827587},\n",
       "                    {0: 1, 1: 18.03448275862069},\n",
       "                    {0: 1, 1: 18.689655172413794},\n",
       "                    {0: 1, 1: 19.344827586206897}, {0: 1, 1: 20.0}],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'class_weight': {0: 1, 1: 1.0}},\n",
       "  {'class_weight': {0: 1, 1: 1.6551724137931034}},\n",
       "  {'class_weight': {0: 1, 1: 2.310344827586207}},\n",
       "  {'class_weight': {0: 1, 1: 2.9655172413793105}},\n",
       "  {'class_weight': {0: 1, 1: 3.6206896551724137}},\n",
       "  {'class_weight': {0: 1, 1: 4.275862068965517}},\n",
       "  {'class_weight': {0: 1, 1: 4.931034482758621}},\n",
       "  {'class_weight': {0: 1, 1: 5.586206896551724}},\n",
       "  {'class_weight': {0: 1, 1: 6.241379310344827}},\n",
       "  {'class_weight': {0: 1, 1: 6.896551724137931}},\n",
       "  {'class_weight': {0: 1, 1: 7.551724137931034}},\n",
       "  {'class_weight': {0: 1, 1: 8.206896551724139}},\n",
       "  {'class_weight': {0: 1, 1: 8.862068965517242}},\n",
       "  {'class_weight': {0: 1, 1: 9.517241379310345}},\n",
       "  {'class_weight': {0: 1, 1: 10.172413793103448}},\n",
       "  {'class_weight': {0: 1, 1: 10.827586206896552}},\n",
       "  {'class_weight': {0: 1, 1: 11.482758620689655}},\n",
       "  {'class_weight': {0: 1, 1: 12.137931034482758}},\n",
       "  {'class_weight': {0: 1, 1: 12.793103448275861}},\n",
       "  {'class_weight': {0: 1, 1: 13.448275862068964}},\n",
       "  {'class_weight': {0: 1, 1: 14.103448275862068}},\n",
       "  {'class_weight': {0: 1, 1: 14.758620689655173}},\n",
       "  {'class_weight': {0: 1, 1: 15.413793103448276}},\n",
       "  {'class_weight': {0: 1, 1: 16.06896551724138}},\n",
       "  {'class_weight': {0: 1, 1: 16.724137931034484}},\n",
       "  {'class_weight': {0: 1, 1: 17.379310344827587}},\n",
       "  {'class_weight': {0: 1, 1: 18.03448275862069}},\n",
       "  {'class_weight': {0: 1, 1: 18.689655172413794}},\n",
       "  {'class_weight': {0: 1, 1: 19.344827586206897}},\n",
       "  {'class_weight': {0: 1, 1: 20.0}}],\n",
       " 'split0_test_precision': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.94444444, 0.89473684, 0.85      ,\n",
       "        0.85      , 0.85714286, 0.85714286, 0.85714286, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.7826087 , 0.7826087 ,\n",
       "        0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 ]),\n",
       " 'split1_test_precision': array([0.46341463, 0.46341463, 0.46341463, 0.45238095, 0.45238095,\n",
       "        0.45238095, 0.45238095, 0.45238095, 0.45238095, 0.45238095,\n",
       "        0.45238095, 0.45238095, 0.44186047, 0.43181818, 0.43181818,\n",
       "        0.43181818, 0.43181818, 0.43181818, 0.41304348, 0.41304348,\n",
       "        0.41304348, 0.40425532, 0.3877551 , 0.38      , 0.38      ,\n",
       "        0.38      , 0.36538462, 0.34545455, 0.34545455, 0.33928571]),\n",
       " 'split2_test_precision': array([0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.58333333,\n",
       "        0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.58333333,\n",
       "        0.58333333, 0.58333333, 0.58333333, 0.56      , 0.56      ,\n",
       "        0.56      , 0.56      , 0.57692308, 0.57692308, 0.57692308,\n",
       "        0.57692308, 0.57692308, 0.57692308, 0.57692308, 0.55555556,\n",
       "        0.55555556, 0.53571429, 0.53571429, 0.53571429, 0.53571429]),\n",
       " 'split3_test_precision': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842]),\n",
       " 'split4_test_precision': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.92307692,\n",
       "        0.92307692, 0.92307692, 0.86666667, 0.86666667, 0.86666667]),\n",
       " 'split5_test_precision': array([0.94444444, 0.94444444, 0.94444444, 0.94444444, 0.94444444,\n",
       "        0.94444444, 0.94444444, 0.89473684, 0.89473684, 0.85      ,\n",
       "        0.85      , 0.85      , 0.85      , 0.85      , 0.85      ,\n",
       "        0.85      , 0.85      , 0.85714286, 0.85714286, 0.85714286,\n",
       "        0.85714286, 0.85714286, 0.85714286, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.81818182]),\n",
       " 'split6_test_precision': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split7_test_precision': array([0.81818182, 0.83333333, 0.83333333, 0.83333333, 0.83333333,\n",
       "        0.83333333, 0.84615385, 0.85714286, 0.875     , 0.875     ,\n",
       "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ,\n",
       "        0.875     , 0.88235294, 0.88235294, 0.88235294, 0.88235294,\n",
       "        0.88235294, 0.88235294, 0.88235294, 0.88235294, 0.83333333,\n",
       "        0.78947368, 0.78947368, 0.78947368, 0.75      , 0.71428571]),\n",
       " 'split8_test_precision': array([0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split9_test_precision': array([1.        , 1.        , 1.        , 1.        , 0.92857143,\n",
       "        0.93333333, 0.94117647, 0.94117647, 0.94117647, 0.94117647,\n",
       "        0.94117647, 0.94117647, 0.94117647, 0.94117647, 0.94117647,\n",
       "        0.94117647, 0.94117647, 0.94117647, 0.88888889, 0.88888889,\n",
       "        0.88888889, 0.84210526, 0.84210526, 0.84210526, 0.8       ,\n",
       "        0.8       , 0.8       , 0.8       , 0.8       , 0.8       ]),\n",
       " 'mean_test_precision': array([0.78093742, 0.88245257, 0.88245257, 0.88134921, 0.87420635,\n",
       "        0.87468254, 0.8767489 , 0.87287705, 0.86384405, 0.85937036,\n",
       "        0.85937036, 0.85937036, 0.85831831, 0.85000999, 0.84553631,\n",
       "        0.84553631, 0.84698589, 0.84939248, 0.84228625, 0.83839015,\n",
       "        0.83839015, 0.83283297, 0.83118295, 0.82295402, 0.80401247,\n",
       "        0.79962651, 0.79618084, 0.78854681, 0.78459944, 0.78041113]),\n",
       " 'std_test_precision': array([0.31902901, 0.18820871, 0.18820871, 0.19067822, 0.18740959,\n",
       "        0.18755312, 0.18756457, 0.18623748, 0.18003759, 0.17976999,\n",
       "        0.17976999, 0.17976999, 0.18216354, 0.18625149, 0.18565978,\n",
       "        0.18565978, 0.18581622, 0.18327189, 0.18562023, 0.18567639,\n",
       "        0.18567639, 0.18693992, 0.19074947, 0.19282111, 0.18830869,\n",
       "        0.18808533, 0.19395897, 0.19546163, 0.19580135, 0.19809322]),\n",
       " 'rank_test_precision': array([29,  1,  1,  3,  6,  5,  4,  7,  8,  9,  9,  9, 12, 13, 16, 16, 15,\n",
       "        14, 18, 19, 19, 21, 22, 23, 24, 25, 26, 27, 28, 30]),\n",
       " 'split0_train_precision': array([0.80434783, 0.76821192, 0.77848101, 0.77639752, 0.79041916,\n",
       "        0.79411765, 0.80225989, 0.80446927, 0.81111111, 0.80978261,\n",
       "        0.80978261, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
       "        0.80645161, 0.80748663, 0.80319149, 0.80319149, 0.80319149,\n",
       "        0.80319149, 0.79581152, 0.79581152, 0.79166667, 0.79166667,\n",
       "        0.79166667, 0.79166667, 0.79166667, 0.78350515, 0.78571429]),\n",
       " 'split1_train_precision': array([0.91724138, 0.92307692, 0.91975309, 0.91975309, 0.92073171,\n",
       "        0.92073171, 0.92073171, 0.91071429, 0.90532544, 0.89473684,\n",
       "        0.89473684, 0.88953488, 0.88953488, 0.87931034, 0.87931034,\n",
       "        0.87931034, 0.87428571, 0.875     , 0.8700565 , 0.86516854,\n",
       "        0.8603352 , 0.85555556, 0.84615385, 0.84615385, 0.82795699,\n",
       "        0.82795699, 0.81914894, 0.81052632, 0.79381443, 0.78571429]),\n",
       " 'split2_train_precision': array([0.84090909, 0.82876712, 0.83974359, 0.84756098, 0.84883721,\n",
       "        0.84659091, 0.84745763, 0.84745763, 0.83798883, 0.83888889,\n",
       "        0.83977901, 0.83977901, 0.84153005, 0.83695652, 0.83243243,\n",
       "        0.83243243, 0.82795699, 0.82887701, 0.82539683, 0.82539683,\n",
       "        0.81675393, 0.80829016, 0.80412371, 0.79187817, 0.7839196 ,\n",
       "        0.77227723, 0.76470588, 0.76097561, 0.75728155, 0.75728155]),\n",
       " 'split3_train_precision': array([0.7578125 , 0.76551724, 0.77564103, 0.78125   , 0.78915663,\n",
       "        0.79532164, 0.80225989, 0.80446927, 0.80662983, 0.80769231,\n",
       "        0.80978261, 0.80978261, 0.80978261, 0.80540541, 0.80107527,\n",
       "        0.79679144, 0.79679144, 0.79473684, 0.79473684, 0.79581152,\n",
       "        0.79581152, 0.79166667, 0.78756477, 0.78756477, 0.78756477,\n",
       "        0.78461538, 0.77272727, 0.77272727, 0.76884422, 0.76884422]),\n",
       " 'split4_train_precision': array([0.7593985 , 0.77631579, 0.78616352, 0.79393939, 0.79166667,\n",
       "        0.79651163, 0.79885057, 0.8021978 , 0.80540541, 0.80540541,\n",
       "        0.80645161, 0.80748663, 0.80748663, 0.80748663, 0.80748663,\n",
       "        0.80319149, 0.8042328 , 0.80104712, 0.80104712, 0.80104712,\n",
       "        0.79792746, 0.79792746, 0.79792746, 0.78974359, 0.78974359,\n",
       "        0.78974359, 0.77777778, 0.76237624, 0.75490196, 0.75121951]),\n",
       " 'split5_train_precision': array([0.74814815, 0.77027027, 0.78343949, 0.79141104, 0.79393939,\n",
       "        0.80346821, 0.81355932, 0.81111111, 0.8121547 , 0.8121547 ,\n",
       "        0.81318681, 0.81420765, 0.81420765, 0.80978261, 0.81081081,\n",
       "        0.80645161, 0.80213904, 0.80213904, 0.80213904, 0.7989418 ,\n",
       "        0.7989418 , 0.79473684, 0.79166667, 0.79166667, 0.79166667,\n",
       "        0.79166667, 0.79166667, 0.79381443, 0.79381443, 0.78974359]),\n",
       " 'split6_train_precision': array([0.73880597, 0.76027397, 0.77564103, 0.7826087 , 0.78527607,\n",
       "        0.79532164, 0.80113636, 0.79888268, 0.80110497, 0.8021978 ,\n",
       "        0.80327869, 0.80327869, 0.79459459, 0.79459459, 0.79459459,\n",
       "        0.79459459, 0.79144385, 0.78723404, 0.78835979, 0.78947368,\n",
       "        0.78534031, 0.78125   , 0.78125   , 0.78125   , 0.77319588,\n",
       "        0.76923077, 0.76530612, 0.76262626, 0.74752475, 0.74384236]),\n",
       " 'split7_train_precision': array([0.76595745, 0.78571429, 0.79245283, 0.80120482, 0.80588235,\n",
       "        0.80813953, 0.81034483, 0.81142857, 0.81111111, 0.8121547 ,\n",
       "        0.8121547 , 0.80540541, 0.80645161, 0.8       , 0.79581152,\n",
       "        0.79581152, 0.79581152, 0.796875  , 0.79274611, 0.78865979,\n",
       "        0.78865979, 0.78461538, 0.78461538, 0.78461538, 0.78461538,\n",
       "        0.78061224, 0.77664975, 0.77272727, 0.75742574, 0.75742574]),\n",
       " 'split8_train_precision': array([0.76190476, 0.77848101, 0.78915663, 0.79532164, 0.79768786,\n",
       "        0.8       , 0.80446927, 0.80769231, 0.80748663, 0.80851064,\n",
       "        0.8042328 , 0.80104712, 0.80104712, 0.80104712, 0.796875  ,\n",
       "        0.79792746, 0.79896907, 0.79487179, 0.79591837, 0.78787879,\n",
       "        0.78787879, 0.78787879, 0.7839196 , 0.7839196 , 0.7839196 ,\n",
       "        0.7839196 , 0.785     , 0.78217822, 0.78217822, 0.78217822]),\n",
       " 'split9_train_precision': array([0.75352113, 0.77564103, 0.78527607, 0.78787879, 0.79289941,\n",
       "        0.79532164, 0.79885057, 0.80446927, 0.80662983, 0.80978261,\n",
       "        0.80978261, 0.80213904, 0.80319149, 0.80319149, 0.80319149,\n",
       "        0.7989418 , 0.79581152, 0.79581152, 0.79581152, 0.79581152,\n",
       "        0.79581152, 0.79581152, 0.79581152, 0.796875  , 0.79274611,\n",
       "        0.78974359, 0.78571429, 0.78172589, 0.78172589, 0.78172589]),\n",
       " 'mean_train_precision': array([0.78480467, 0.79322696, 0.80257483, 0.8077326 , 0.81164965,\n",
       "        0.81555245, 0.819992  , 0.82028922, 0.82049479, 0.82013065,\n",
       "        0.82031683, 0.81791126, 0.81742783, 0.81442263, 0.81280397,\n",
       "        0.81119043, 0.80949286, 0.80797839, 0.80694036, 0.80513811,\n",
       "        0.80306518, 0.79935439, 0.79688445, 0.79453337, 0.79069953,\n",
       "        0.78814327, 0.78303634, 0.77913442, 0.77210164, 0.77036897]),\n",
       " 'std_train_precision': array([0.05268875, 0.04690388, 0.04284959, 0.04182915, 0.04028248,\n",
       "        0.03810352, 0.03627198, 0.03282163, 0.02984173, 0.02662237,\n",
       "        0.02666218, 0.02613733, 0.02679795, 0.02416378, 0.02446424,\n",
       "        0.02499128, 0.023658  , 0.02466267, 0.02310217, 0.02249834,\n",
       "        0.02090023, 0.02005662, 0.01777753, 0.0177556 , 0.01356557,\n",
       "        0.01520361, 0.01513009, 0.01529442, 0.01616346, 0.01589423]),\n",
       " 'split0_test_recall_score': array([0.36842105, 0.42105263, 0.42105263, 0.63157895, 0.78947368,\n",
       "        0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842]),\n",
       " 'split1_test_recall_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'split2_test_recall_score': array([0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
       "        0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
       "        0.73684211, 0.73684211, 0.73684211, 0.73684211, 0.73684211,\n",
       "        0.73684211, 0.73684211, 0.78947368, 0.78947368, 0.78947368,\n",
       "        0.78947368, 0.78947368, 0.78947368, 0.78947368, 0.78947368,\n",
       "        0.78947368, 0.78947368, 0.78947368, 0.78947368, 0.78947368]),\n",
       " 'split3_test_recall_score': array([0.47368421, 0.78947368, 0.84210526, 0.84210526, 0.89473684,\n",
       "        0.89473684, 0.89473684, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842]),\n",
       " 'split4_test_recall_score': array([0.35, 0.35, 0.4 , 0.4 , 0.45, 0.45, 0.45, 0.45, 0.5 , 0.5 , 0.5 ,\n",
       "        0.5 , 0.5 , 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.6 , 0.6 , 0.6 ,\n",
       "        0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.65, 0.65, 0.65]),\n",
       " 'split5_test_recall_score': array([0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85,\n",
       "        0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.9 , 0.9 , 0.9 , 0.9 , 0.9 ,\n",
       "        0.9 , 0.9 , 0.9 , 0.9 , 0.9 , 0.9 , 0.9 , 0.9 ]),\n",
       " 'split6_test_recall_score': array([0.9 , 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 1.  , 1.  , 1.  , 1.  ,\n",
       "        1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  ,\n",
       "        1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  ]),\n",
       " 'split7_test_recall_score': array([0.45, 0.5 , 0.5 , 0.5 , 0.5 , 0.5 , 0.55, 0.6 , 0.7 , 0.7 , 0.7 ,\n",
       "        0.7 , 0.7 , 0.7 , 0.7 , 0.7 , 0.75, 0.75, 0.75, 0.75, 0.75, 0.75,\n",
       "        0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75, 0.75]),\n",
       " 'split8_test_recall_score': array([0.  , 0.25, 0.25, 0.25, 0.3 , 0.35, 0.35, 0.35, 0.4 , 0.5 , 0.5 ,\n",
       "        0.55, 0.6 , 0.6 , 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65,\n",
       "        0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65]),\n",
       " 'split9_test_recall_score': array([0.4 , 0.5 , 0.55, 0.65, 0.65, 0.7 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 ,\n",
       "        0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 ,\n",
       "        0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 ]),\n",
       " 'mean_test_recall_score': array([0.55289474, 0.63473684, 0.65      , 0.68105263, 0.71210526,\n",
       "        0.73263158, 0.74763158, 0.76289474, 0.78289474, 0.79289474,\n",
       "        0.79289474, 0.79789474, 0.80289474, 0.80789474, 0.81289474,\n",
       "        0.81289474, 0.82315789, 0.83342105, 0.83342105, 0.83842105,\n",
       "        0.83842105, 0.83842105, 0.83842105, 0.83842105, 0.83842105,\n",
       "        0.83842105, 0.83842105, 0.84342105, 0.84342105, 0.84342105]),\n",
       " 'std_test_recall_score': array([0.29387433, 0.24991633, 0.24583793, 0.23079052, 0.22041324,\n",
       "        0.21599861, 0.21142718, 0.21642861, 0.19345685, 0.17512184,\n",
       "        0.17512184, 0.16722354, 0.16034265, 0.15134668, 0.14509262,\n",
       "        0.14509262, 0.14562312, 0.14487099, 0.14487099, 0.13556693,\n",
       "        0.13556693, 0.13556693, 0.13556693, 0.13556693, 0.13556693,\n",
       "        0.13556693, 0.13556693, 0.12735456, 0.12735456, 0.12735456]),\n",
       " 'rank_test_recall_score': array([30, 29, 28, 27, 26, 25, 24, 23, 22, 20, 20, 19, 18, 17, 15, 15, 14,\n",
       "        12, 12,  4,  4,  4,  4,  4,  4,  4,  4,  1,  1,  1]),\n",
       " 'split0_train_recall_score': array([0.62711864, 0.65536723, 0.69491525, 0.70621469, 0.74576271,\n",
       "        0.76271186, 0.80225989, 0.81355932, 0.82485876, 0.84180791,\n",
       "        0.84180791, 0.84745763, 0.84745763, 0.84745763, 0.84745763,\n",
       "        0.84745763, 0.85310734, 0.85310734, 0.85310734, 0.85310734,\n",
       "        0.85310734, 0.85875706, 0.85875706, 0.85875706, 0.85875706,\n",
       "        0.85875706, 0.85875706, 0.85875706, 0.85875706, 0.8700565 ]),\n",
       " 'split1_train_recall_score': array([0.75141243, 0.81355932, 0.84180791, 0.84180791, 0.85310734,\n",
       "        0.85310734, 0.85310734, 0.86440678, 0.86440678, 0.86440678,\n",
       "        0.86440678, 0.86440678, 0.86440678, 0.86440678, 0.86440678,\n",
       "        0.86440678, 0.86440678, 0.8700565 , 0.8700565 , 0.8700565 ,\n",
       "        0.8700565 , 0.8700565 , 0.8700565 , 0.8700565 , 0.8700565 ,\n",
       "        0.8700565 , 0.8700565 , 0.8700565 , 0.8700565 , 0.8700565 ]),\n",
       " 'split2_train_recall_score': array([0.62711864, 0.68361582, 0.74011299, 0.78531073, 0.82485876,\n",
       "        0.84180791, 0.84745763, 0.84745763, 0.84745763, 0.85310734,\n",
       "        0.85875706, 0.85875706, 0.8700565 , 0.8700565 , 0.8700565 ,\n",
       "        0.8700565 , 0.8700565 , 0.87570621, 0.88135593, 0.88135593,\n",
       "        0.88135593, 0.88135593, 0.88135593, 0.88135593, 0.88135593,\n",
       "        0.88135593, 0.88135593, 0.88135593, 0.88135593, 0.88135593]),\n",
       " 'split3_train_recall_score': array([0.5480226 , 0.62711864, 0.68361582, 0.70621469, 0.74011299,\n",
       "        0.76836158, 0.80225989, 0.81355932, 0.82485876, 0.83050847,\n",
       "        0.84180791, 0.84180791, 0.84180791, 0.84180791, 0.84180791,\n",
       "        0.84180791, 0.84180791, 0.85310734, 0.85310734, 0.85875706,\n",
       "        0.85875706, 0.85875706, 0.85875706, 0.85875706, 0.85875706,\n",
       "        0.86440678, 0.86440678, 0.86440678, 0.86440678, 0.86440678]),\n",
       " 'split4_train_recall_score': array([0.57386364, 0.67045455, 0.71022727, 0.74431818, 0.75568182,\n",
       "        0.77840909, 0.78977273, 0.82954545, 0.84659091, 0.84659091,\n",
       "        0.85227273, 0.85795455, 0.85795455, 0.85795455, 0.85795455,\n",
       "        0.85795455, 0.86363636, 0.86931818, 0.86931818, 0.86931818,\n",
       "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ,\n",
       "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ]),\n",
       " 'split5_train_recall_score': array([0.57386364, 0.64772727, 0.69886364, 0.73295455, 0.74431818,\n",
       "        0.78977273, 0.81818182, 0.82954545, 0.83522727, 0.83522727,\n",
       "        0.84090909, 0.84659091, 0.84659091, 0.84659091, 0.85227273,\n",
       "        0.85227273, 0.85227273, 0.85227273, 0.85227273, 0.85795455,\n",
       "        0.85795455, 0.85795455, 0.86363636, 0.86363636, 0.86363636,\n",
       "        0.86363636, 0.86363636, 0.875     , 0.875     , 0.875     ]),\n",
       " 'split6_train_recall_score': array([0.5625    , 0.63068182, 0.6875    , 0.71590909, 0.72727273,\n",
       "        0.77272727, 0.80113636, 0.8125    , 0.82386364, 0.82954545,\n",
       "        0.83522727, 0.83522727, 0.83522727, 0.83522727, 0.83522727,\n",
       "        0.83522727, 0.84090909, 0.84090909, 0.84659091, 0.85227273,\n",
       "        0.85227273, 0.85227273, 0.85227273, 0.85227273, 0.85227273,\n",
       "        0.85227273, 0.85227273, 0.85795455, 0.85795455, 0.85795455]),\n",
       " 'split7_train_recall_score': array([0.61363636, 0.6875    , 0.71590909, 0.75568182, 0.77840909,\n",
       "        0.78977273, 0.80113636, 0.80681818, 0.82954545, 0.83522727,\n",
       "        0.83522727, 0.84659091, 0.85227273, 0.86363636, 0.86363636,\n",
       "        0.86363636, 0.86363636, 0.86931818, 0.86931818, 0.86931818,\n",
       "        0.86931818, 0.86931818, 0.86931818, 0.86931818, 0.86931818,\n",
       "        0.86931818, 0.86931818, 0.86931818, 0.86931818, 0.86931818]),\n",
       " 'split8_train_recall_score': array([0.63636364, 0.69886364, 0.74431818, 0.77272727, 0.78409091,\n",
       "        0.79545455, 0.81818182, 0.83522727, 0.85795455, 0.86363636,\n",
       "        0.86363636, 0.86931818, 0.86931818, 0.86931818, 0.86931818,\n",
       "        0.875     , 0.88068182, 0.88068182, 0.88636364, 0.88636364,\n",
       "        0.88636364, 0.88636364, 0.88636364, 0.88636364, 0.88636364,\n",
       "        0.88636364, 0.89204545, 0.89772727, 0.89772727, 0.89772727]),\n",
       " 'split9_train_recall_score': array([0.60795455, 0.6875    , 0.72727273, 0.73863636, 0.76136364,\n",
       "        0.77272727, 0.78977273, 0.81818182, 0.82954545, 0.84659091,\n",
       "        0.84659091, 0.85227273, 0.85795455, 0.85795455, 0.85795455,\n",
       "        0.85795455, 0.86363636, 0.86363636, 0.86363636, 0.86363636,\n",
       "        0.86363636, 0.86363636, 0.86363636, 0.86931818, 0.86931818,\n",
       "        0.875     , 0.875     , 0.875     , 0.875     , 0.875     ]),\n",
       " 'mean_train_recall_score': array([0.61218541, 0.68023883, 0.72445429, 0.74997753, 0.77149782,\n",
       "        0.79248523, 0.81232666, 0.82708012, 0.83843092, 0.84466487,\n",
       "        0.84806433, 0.85203839, 0.8543047 , 0.85544106, 0.85600924,\n",
       "        0.85657743, 0.85941513, 0.86281138, 0.86451271, 0.86621405,\n",
       "        0.86678223, 0.8673472 , 0.86791538, 0.86848356, 0.86848356,\n",
       "        0.86961672, 0.8701849 , 0.87245763, 0.87245763, 0.87358757]),\n",
       " 'std_train_recall_score': array([0.05473334, 0.05028625, 0.04388149, 0.0395889 , 0.03795866,\n",
       "        0.02928924, 0.02106253, 0.01719007, 0.01397413, 0.01201522,\n",
       "        0.01050163, 0.00999687, 0.01110338, 0.01141441, 0.01109672,\n",
       "        0.01188135, 0.01177783, 0.01184309, 0.01253003, 0.01079785,\n",
       "        0.01109173, 0.01050939, 0.01013308, 0.01003605, 0.01003605,\n",
       "        0.00978859, 0.01085138, 0.01102546, 0.01102546, 0.01010396]),\n",
       " 'split0_test_min_both': array([0.36842105, 0.42105263, 0.42105263, 0.63157895, 0.78947368,\n",
       "        0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.89473684,\n",
       "        0.89473684, 0.89473684, 0.89473684, 0.89473684, 0.85      ,\n",
       "        0.85      , 0.85714286, 0.85714286, 0.85714286, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.7826087 , 0.7826087 ,\n",
       "        0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 ]),\n",
       " 'split1_test_min_both': array([0.46341463, 0.46341463, 0.46341463, 0.45238095, 0.45238095,\n",
       "        0.45238095, 0.45238095, 0.45238095, 0.45238095, 0.45238095,\n",
       "        0.45238095, 0.45238095, 0.44186047, 0.43181818, 0.43181818,\n",
       "        0.43181818, 0.43181818, 0.43181818, 0.41304348, 0.41304348,\n",
       "        0.41304348, 0.40425532, 0.3877551 , 0.38      , 0.38      ,\n",
       "        0.38      , 0.36538462, 0.34545455, 0.34545455, 0.33928571]),\n",
       " 'split2_test_min_both': array([0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.58333333,\n",
       "        0.58333333, 0.58333333, 0.58333333, 0.58333333, 0.58333333,\n",
       "        0.58333333, 0.58333333, 0.58333333, 0.56      , 0.56      ,\n",
       "        0.56      , 0.56      , 0.57692308, 0.57692308, 0.57692308,\n",
       "        0.57692308, 0.57692308, 0.57692308, 0.57692308, 0.55555556,\n",
       "        0.55555556, 0.53571429, 0.53571429, 0.53571429, 0.53571429]),\n",
       " 'split3_test_min_both': array([0.47368421, 0.78947368, 0.84210526, 0.84210526, 0.89473684,\n",
       "        0.89473684, 0.89473684, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842,\n",
       "        0.94736842, 0.94736842, 0.94736842, 0.94736842, 0.94736842]),\n",
       " 'split4_test_min_both': array([0.35, 0.35, 0.4 , 0.4 , 0.45, 0.45, 0.45, 0.45, 0.5 , 0.5 , 0.5 ,\n",
       "        0.5 , 0.5 , 0.55, 0.55, 0.55, 0.55, 0.55, 0.55, 0.6 , 0.6 , 0.6 ,\n",
       "        0.6 , 0.6 , 0.6 , 0.6 , 0.6 , 0.65, 0.65, 0.65]),\n",
       " 'split5_test_min_both': array([0.85      , 0.85      , 0.85      , 0.85      , 0.85      ,\n",
       "        0.85      , 0.85      , 0.85      , 0.85      , 0.85      ,\n",
       "        0.85      , 0.85      , 0.85      , 0.85      , 0.85      ,\n",
       "        0.85      , 0.85      , 0.85714286, 0.85714286, 0.85714286,\n",
       "        0.85714286, 0.85714286, 0.85714286, 0.81818182, 0.81818182,\n",
       "        0.81818182, 0.81818182, 0.81818182, 0.81818182, 0.81818182]),\n",
       " 'split6_test_min_both': array([0.9 , 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 1.  , 1.  , 1.  , 1.  ,\n",
       "        1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  ,\n",
       "        1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  , 1.  ]),\n",
       " 'split7_test_min_both': array([0.45      , 0.5       , 0.5       , 0.5       , 0.5       ,\n",
       "        0.5       , 0.55      , 0.6       , 0.7       , 0.7       ,\n",
       "        0.7       , 0.7       , 0.7       , 0.7       , 0.7       ,\n",
       "        0.7       , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
       "        0.75      , 0.75      , 0.75      , 0.75      , 0.75      ,\n",
       "        0.75      , 0.75      , 0.75      , 0.75      , 0.71428571]),\n",
       " 'split8_test_min_both': array([0.  , 0.25, 0.25, 0.25, 0.3 , 0.35, 0.35, 0.35, 0.4 , 0.5 , 0.5 ,\n",
       "        0.55, 0.6 , 0.6 , 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65,\n",
       "        0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65, 0.65]),\n",
       " 'split9_test_min_both': array([0.4 , 0.5 , 0.55, 0.65, 0.65, 0.7 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 ,\n",
       "        0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 ,\n",
       "        0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 ]),\n",
       " 'mean_test_min_both': array([0.48388532, 0.56572743, 0.58099059, 0.61093985, 0.64199248,\n",
       "        0.6625188 , 0.6775188 , 0.69278195, 0.71278195, 0.72278195,\n",
       "        0.72278195, 0.72778195, 0.73172991, 0.73339234, 0.73391866,\n",
       "        0.73391866, 0.73963295, 0.74203954, 0.74016207, 0.74126597,\n",
       "        0.74126597, 0.74038715, 0.73873713, 0.7305082 , 0.72837145,\n",
       "        0.72837145, 0.72492578, 0.72793278, 0.72793278, 0.72374446]),\n",
       " 'std_test_min_both': array([0.24314433, 0.21566402, 0.21586034, 0.20987724, 0.20909461,\n",
       "        0.21135817, 0.21171139, 0.22158946, 0.2061325 , 0.19270436,\n",
       "        0.19270436, 0.18743572, 0.1848764 , 0.18288919, 0.17641085,\n",
       "        0.17641085, 0.17654994, 0.17534967, 0.17872911, 0.17184735,\n",
       "        0.17184735, 0.17353777, 0.17677418, 0.17470624, 0.176691  ,\n",
       "        0.176691  , 0.18158375, 0.18285846, 0.18285846, 0.18402526]),\n",
       " 'rank_test_min_both': array([30, 29, 28, 27, 26, 25, 24, 23, 22, 20, 20, 17, 11, 10,  8,  8,  6,\n",
       "         1,  5,  2,  2,  4,  7, 12, 13, 13, 18, 15, 15, 19]),\n",
       " 'split0_train_min_both': array([0.62711864, 0.65536723, 0.69491525, 0.70621469, 0.74576271,\n",
       "        0.76271186, 0.80225989, 0.80446927, 0.81111111, 0.80978261,\n",
       "        0.80978261, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
       "        0.80645161, 0.80748663, 0.80319149, 0.80319149, 0.80319149,\n",
       "        0.80319149, 0.79581152, 0.79581152, 0.79166667, 0.79166667,\n",
       "        0.79166667, 0.79166667, 0.79166667, 0.78350515, 0.78571429]),\n",
       " 'split1_train_min_both': array([0.75141243, 0.81355932, 0.84180791, 0.84180791, 0.85310734,\n",
       "        0.85310734, 0.85310734, 0.86440678, 0.86440678, 0.86440678,\n",
       "        0.86440678, 0.86440678, 0.86440678, 0.86440678, 0.86440678,\n",
       "        0.86440678, 0.86440678, 0.8700565 , 0.8700565 , 0.86516854,\n",
       "        0.8603352 , 0.85555556, 0.84615385, 0.84615385, 0.82795699,\n",
       "        0.82795699, 0.81914894, 0.81052632, 0.79381443, 0.78571429]),\n",
       " 'split2_train_min_both': array([0.62711864, 0.68361582, 0.74011299, 0.78531073, 0.82485876,\n",
       "        0.84180791, 0.84745763, 0.84745763, 0.83798883, 0.83888889,\n",
       "        0.83977901, 0.83977901, 0.84153005, 0.83695652, 0.83243243,\n",
       "        0.83243243, 0.82795699, 0.82887701, 0.82539683, 0.82539683,\n",
       "        0.81675393, 0.80829016, 0.80412371, 0.79187817, 0.7839196 ,\n",
       "        0.77227723, 0.76470588, 0.76097561, 0.75728155, 0.75728155]),\n",
       " 'split3_train_min_both': array([0.5480226 , 0.62711864, 0.68361582, 0.70621469, 0.74011299,\n",
       "        0.76836158, 0.80225989, 0.80446927, 0.80662983, 0.80769231,\n",
       "        0.80978261, 0.80978261, 0.80978261, 0.80540541, 0.80107527,\n",
       "        0.79679144, 0.79679144, 0.79473684, 0.79473684, 0.79581152,\n",
       "        0.79581152, 0.79166667, 0.78756477, 0.78756477, 0.78756477,\n",
       "        0.78461538, 0.77272727, 0.77272727, 0.76884422, 0.76884422]),\n",
       " 'split4_train_min_both': array([0.57386364, 0.67045455, 0.71022727, 0.74431818, 0.75568182,\n",
       "        0.77840909, 0.78977273, 0.8021978 , 0.80540541, 0.80540541,\n",
       "        0.80645161, 0.80748663, 0.80748663, 0.80748663, 0.80748663,\n",
       "        0.80319149, 0.8042328 , 0.80104712, 0.80104712, 0.80104712,\n",
       "        0.79792746, 0.79792746, 0.79792746, 0.78974359, 0.78974359,\n",
       "        0.78974359, 0.77777778, 0.76237624, 0.75490196, 0.75121951]),\n",
       " 'split5_train_min_both': array([0.57386364, 0.64772727, 0.69886364, 0.73295455, 0.74431818,\n",
       "        0.78977273, 0.81355932, 0.81111111, 0.8121547 , 0.8121547 ,\n",
       "        0.81318681, 0.81420765, 0.81420765, 0.80978261, 0.81081081,\n",
       "        0.80645161, 0.80213904, 0.80213904, 0.80213904, 0.7989418 ,\n",
       "        0.7989418 , 0.79473684, 0.79166667, 0.79166667, 0.79166667,\n",
       "        0.79166667, 0.79166667, 0.79381443, 0.79381443, 0.78974359]),\n",
       " 'split6_train_min_both': array([0.5625    , 0.63068182, 0.6875    , 0.71590909, 0.72727273,\n",
       "        0.77272727, 0.80113636, 0.79888268, 0.80110497, 0.8021978 ,\n",
       "        0.80327869, 0.80327869, 0.79459459, 0.79459459, 0.79459459,\n",
       "        0.79459459, 0.79144385, 0.78723404, 0.78835979, 0.78947368,\n",
       "        0.78534031, 0.78125   , 0.78125   , 0.78125   , 0.77319588,\n",
       "        0.76923077, 0.76530612, 0.76262626, 0.74752475, 0.74384236]),\n",
       " 'split7_train_min_both': array([0.61363636, 0.6875    , 0.71590909, 0.75568182, 0.77840909,\n",
       "        0.78977273, 0.80113636, 0.80681818, 0.81111111, 0.8121547 ,\n",
       "        0.8121547 , 0.80540541, 0.80645161, 0.8       , 0.79581152,\n",
       "        0.79581152, 0.79581152, 0.796875  , 0.79274611, 0.78865979,\n",
       "        0.78865979, 0.78461538, 0.78461538, 0.78461538, 0.78461538,\n",
       "        0.78061224, 0.77664975, 0.77272727, 0.75742574, 0.75742574]),\n",
       " 'split8_train_min_both': array([0.63636364, 0.69886364, 0.74431818, 0.77272727, 0.78409091,\n",
       "        0.79545455, 0.80446927, 0.80769231, 0.80748663, 0.80851064,\n",
       "        0.8042328 , 0.80104712, 0.80104712, 0.80104712, 0.796875  ,\n",
       "        0.79792746, 0.79896907, 0.79487179, 0.79591837, 0.78787879,\n",
       "        0.78787879, 0.78787879, 0.7839196 , 0.7839196 , 0.7839196 ,\n",
       "        0.7839196 , 0.785     , 0.78217822, 0.78217822, 0.78217822]),\n",
       " 'split9_train_min_both': array([0.60795455, 0.6875    , 0.72727273, 0.73863636, 0.76136364,\n",
       "        0.77272727, 0.78977273, 0.80446927, 0.80662983, 0.80978261,\n",
       "        0.80978261, 0.80213904, 0.80319149, 0.80319149, 0.80319149,\n",
       "        0.7989418 , 0.79581152, 0.79581152, 0.79581152, 0.79581152,\n",
       "        0.79581152, 0.79581152, 0.79581152, 0.796875  , 0.79274611,\n",
       "        0.78974359, 0.78571429, 0.78172589, 0.78172589, 0.78172589]),\n",
       " 'mean_train_min_both': array([0.61218541, 0.68023883, 0.72445429, 0.74997753, 0.77149782,\n",
       "        0.79248523, 0.81049315, 0.81519743, 0.81640292, 0.81709764,\n",
       "        0.81728382, 0.81539845, 0.81491502, 0.81293228, 0.81131361,\n",
       "        0.80970007, 0.80850496, 0.80748403, 0.80694036, 0.80513811,\n",
       "        0.80306518, 0.79935439, 0.79688445, 0.79453337, 0.79069953,\n",
       "        0.78814327, 0.78303634, 0.77913442, 0.77210164, 0.77036897]),\n",
       " 'std_train_min_both': array([0.05473334, 0.05028625, 0.04388149, 0.0395889 , 0.03795866,\n",
       "        0.02928924, 0.02096992, 0.02094268, 0.0186276 , 0.01841143,\n",
       "        0.0184995 , 0.01949448, 0.02031196, 0.02025999, 0.02050008,\n",
       "        0.0210121 , 0.02098732, 0.02332771, 0.02310217, 0.02249834,\n",
       "        0.02090023, 0.02005662, 0.01777753, 0.0177556 , 0.01356557,\n",
       "        0.01520361, 0.01513009, 0.01529442, 0.01616346, 0.01589423])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27008196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8115942028985508"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y, grid.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16856142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>split3_test_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_min_both</th>\n",
       "      <th>split3_train_min_both</th>\n",
       "      <th>split4_train_min_both</th>\n",
       "      <th>split5_train_min_both</th>\n",
       "      <th>split6_train_min_both</th>\n",
       "      <th>split7_train_min_both</th>\n",
       "      <th>split8_train_min_both</th>\n",
       "      <th>split9_train_min_both</th>\n",
       "      <th>mean_train_min_both</th>\n",
       "      <th>std_train_min_both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.250955</td>\n",
       "      <td>0.296330</td>\n",
       "      <td>0.051832</td>\n",
       "      <td>0.008058</td>\n",
       "      <td>{0: 1, 1: 1.0}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1.0}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.548023</td>\n",
       "      <td>0.573864</td>\n",
       "      <td>0.573864</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.612185</td>\n",
       "      <td>0.054733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.130902</td>\n",
       "      <td>0.313843</td>\n",
       "      <td>0.060949</td>\n",
       "      <td>0.018217</td>\n",
       "      <td>{0: 1, 1: 1.6551724137931034}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1.6551724137931034}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.683616</td>\n",
       "      <td>0.627119</td>\n",
       "      <td>0.670455</td>\n",
       "      <td>0.647727</td>\n",
       "      <td>0.630682</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.698864</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.680239</td>\n",
       "      <td>0.050286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.029917</td>\n",
       "      <td>0.164479</td>\n",
       "      <td>0.055321</td>\n",
       "      <td>0.017194</td>\n",
       "      <td>{0: 1, 1: 2.310344827586207}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.310344827586207}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.683616</td>\n",
       "      <td>0.710227</td>\n",
       "      <td>0.698864</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.724454</td>\n",
       "      <td>0.043881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.053845</td>\n",
       "      <td>0.223626</td>\n",
       "      <td>0.048795</td>\n",
       "      <td>0.010190</td>\n",
       "      <td>{0: 1, 1: 2.9655172413793105}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.9655172413793105}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785311</td>\n",
       "      <td>0.706215</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.732955</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.755682</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.738636</td>\n",
       "      <td>0.749978</td>\n",
       "      <td>0.039589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.916154</td>\n",
       "      <td>0.390358</td>\n",
       "      <td>0.048822</td>\n",
       "      <td>0.007340</td>\n",
       "      <td>{0: 1, 1: 3.6206896551724137}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 3.6206896551724137}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824859</td>\n",
       "      <td>0.740113</td>\n",
       "      <td>0.755682</td>\n",
       "      <td>0.744318</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.761364</td>\n",
       "      <td>0.771498</td>\n",
       "      <td>0.037959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.393969</td>\n",
       "      <td>0.420235</td>\n",
       "      <td>0.063569</td>\n",
       "      <td>0.016690</td>\n",
       "      <td>{0: 1, 1: 4.275862068965517}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.275862068965517}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.768362</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.792485</td>\n",
       "      <td>0.029289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.518186</td>\n",
       "      <td>0.288444</td>\n",
       "      <td>0.073328</td>\n",
       "      <td>0.024125</td>\n",
       "      <td>{0: 1, 1: 4.931034482758621}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.931034482758621}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.802260</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.801136</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.810493</td>\n",
       "      <td>0.020970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.302058</td>\n",
       "      <td>0.191193</td>\n",
       "      <td>0.061656</td>\n",
       "      <td>0.018432</td>\n",
       "      <td>{0: 1, 1: 5.586206896551724}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 5.586206896551724}}</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847458</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.806818</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.815197</td>\n",
       "      <td>0.020943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.234714</td>\n",
       "      <td>0.244191</td>\n",
       "      <td>0.043355</td>\n",
       "      <td>0.007225</td>\n",
       "      <td>{0: 1, 1: 6.241379310344827}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.241379310344827}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>0.805405</td>\n",
       "      <td>0.812155</td>\n",
       "      <td>0.801105</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.807487</td>\n",
       "      <td>0.806630</td>\n",
       "      <td>0.816403</td>\n",
       "      <td>0.018628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.446520</td>\n",
       "      <td>0.392865</td>\n",
       "      <td>0.056413</td>\n",
       "      <td>0.011762</td>\n",
       "      <td>{0: 1, 1: 6.896551724137931}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.896551724137931}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.805405</td>\n",
       "      <td>0.812155</td>\n",
       "      <td>0.802198</td>\n",
       "      <td>0.812155</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.809783</td>\n",
       "      <td>0.817098</td>\n",
       "      <td>0.018411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.088143</td>\n",
       "      <td>0.243867</td>\n",
       "      <td>0.068837</td>\n",
       "      <td>0.021337</td>\n",
       "      <td>{0: 1, 1: 7.551724137931034}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 7.551724137931034}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.839779</td>\n",
       "      <td>0.809783</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.812155</td>\n",
       "      <td>0.804233</td>\n",
       "      <td>0.809783</td>\n",
       "      <td>0.817284</td>\n",
       "      <td>0.018499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.141162</td>\n",
       "      <td>0.326697</td>\n",
       "      <td>0.053575</td>\n",
       "      <td>0.015411</td>\n",
       "      <td>{0: 1, 1: 8.206896551724139}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 8.206896551724139}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.839779</td>\n",
       "      <td>0.809783</td>\n",
       "      <td>0.807487</td>\n",
       "      <td>0.814208</td>\n",
       "      <td>0.803279</td>\n",
       "      <td>0.805405</td>\n",
       "      <td>0.801047</td>\n",
       "      <td>0.802139</td>\n",
       "      <td>0.815398</td>\n",
       "      <td>0.019494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.156841</td>\n",
       "      <td>0.224554</td>\n",
       "      <td>0.052895</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>{0: 1, 1: 8.862068965517242}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 8.862068965517242}}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.441860</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841530</td>\n",
       "      <td>0.809783</td>\n",
       "      <td>0.807487</td>\n",
       "      <td>0.814208</td>\n",
       "      <td>0.794595</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.801047</td>\n",
       "      <td>0.803191</td>\n",
       "      <td>0.814915</td>\n",
       "      <td>0.020312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.058311</td>\n",
       "      <td>0.325834</td>\n",
       "      <td>0.047647</td>\n",
       "      <td>0.010832</td>\n",
       "      <td>{0: 1, 1: 9.517241379310345}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 9.517241379310345}}</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.805405</td>\n",
       "      <td>0.807487</td>\n",
       "      <td>0.809783</td>\n",
       "      <td>0.794595</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.801047</td>\n",
       "      <td>0.803191</td>\n",
       "      <td>0.812932</td>\n",
       "      <td>0.020260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.030570</td>\n",
       "      <td>0.242885</td>\n",
       "      <td>0.065557</td>\n",
       "      <td>0.028867</td>\n",
       "      <td>{0: 1, 1: 10.172413793103448}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 10.172413793103448}}</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832432</td>\n",
       "      <td>0.801075</td>\n",
       "      <td>0.807487</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.794595</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.803191</td>\n",
       "      <td>0.811314</td>\n",
       "      <td>0.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.170277</td>\n",
       "      <td>0.284278</td>\n",
       "      <td>0.059042</td>\n",
       "      <td>0.014216</td>\n",
       "      <td>{0: 1, 1: 10.827586206896552}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 10.827586206896552}}</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832432</td>\n",
       "      <td>0.796791</td>\n",
       "      <td>0.803191</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.794595</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.797927</td>\n",
       "      <td>0.798942</td>\n",
       "      <td>0.809700</td>\n",
       "      <td>0.021012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.203410</td>\n",
       "      <td>0.277108</td>\n",
       "      <td>0.053486</td>\n",
       "      <td>0.010271</td>\n",
       "      <td>{0: 1, 1: 11.482758620689655}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 11.482758620689655}}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.796791</td>\n",
       "      <td>0.804233</td>\n",
       "      <td>0.802139</td>\n",
       "      <td>0.791444</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.798969</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.808505</td>\n",
       "      <td>0.020987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.235799</td>\n",
       "      <td>0.248107</td>\n",
       "      <td>0.055675</td>\n",
       "      <td>0.012861</td>\n",
       "      <td>{0: 1, 1: 12.137931034482758}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 12.137931034482758}}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.431818</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828877</td>\n",
       "      <td>0.794737</td>\n",
       "      <td>0.801047</td>\n",
       "      <td>0.802139</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.807484</td>\n",
       "      <td>0.023328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.204852</td>\n",
       "      <td>0.180988</td>\n",
       "      <td>0.047544</td>\n",
       "      <td>0.013047</td>\n",
       "      <td>{0: 1, 1: 12.793103448275861}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 12.793103448275861}}</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.794737</td>\n",
       "      <td>0.801047</td>\n",
       "      <td>0.802139</td>\n",
       "      <td>0.788360</td>\n",
       "      <td>0.792746</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.806940</td>\n",
       "      <td>0.023102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.230201</td>\n",
       "      <td>0.265962</td>\n",
       "      <td>0.087917</td>\n",
       "      <td>0.073325</td>\n",
       "      <td>{0: 1, 1: 13.448275862068964}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 13.448275862068964}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.801047</td>\n",
       "      <td>0.798942</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.788660</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.805138</td>\n",
       "      <td>0.022498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.210891</td>\n",
       "      <td>0.269185</td>\n",
       "      <td>0.051466</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>{0: 1, 1: 14.103448275862068}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 14.103448275862068}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.413043</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.816754</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.797927</td>\n",
       "      <td>0.798942</td>\n",
       "      <td>0.785340</td>\n",
       "      <td>0.788660</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.803065</td>\n",
       "      <td>0.020900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.200259</td>\n",
       "      <td>0.298882</td>\n",
       "      <td>0.049101</td>\n",
       "      <td>0.009378</td>\n",
       "      <td>{0: 1, 1: 14.758620689655173}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 14.758620689655173}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.404255</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808290</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.797927</td>\n",
       "      <td>0.794737</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.799354</td>\n",
       "      <td>0.020057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.254960</td>\n",
       "      <td>0.268337</td>\n",
       "      <td>0.052040</td>\n",
       "      <td>0.011545</td>\n",
       "      <td>{0: 1, 1: 15.413793103448276}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 15.413793103448276}}</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.804124</td>\n",
       "      <td>0.787565</td>\n",
       "      <td>0.797927</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.783920</td>\n",
       "      <td>0.795812</td>\n",
       "      <td>0.796884</td>\n",
       "      <td>0.017778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.097384</td>\n",
       "      <td>0.279630</td>\n",
       "      <td>0.067936</td>\n",
       "      <td>0.023125</td>\n",
       "      <td>{0: 1, 1: 16.06896551724138}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 16.06896551724138}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791878</td>\n",
       "      <td>0.787565</td>\n",
       "      <td>0.789744</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.783920</td>\n",
       "      <td>0.796875</td>\n",
       "      <td>0.794533</td>\n",
       "      <td>0.017756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.461906</td>\n",
       "      <td>0.207663</td>\n",
       "      <td>0.057271</td>\n",
       "      <td>0.018358</td>\n",
       "      <td>{0: 1, 1: 16.724137931034484}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 16.724137931034484}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783920</td>\n",
       "      <td>0.787565</td>\n",
       "      <td>0.789744</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.783920</td>\n",
       "      <td>0.792746</td>\n",
       "      <td>0.790700</td>\n",
       "      <td>0.013566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.133721</td>\n",
       "      <td>0.275314</td>\n",
       "      <td>0.054565</td>\n",
       "      <td>0.015946</td>\n",
       "      <td>{0: 1, 1: 17.379310344827587}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 17.379310344827587}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.789744</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.780612</td>\n",
       "      <td>0.783920</td>\n",
       "      <td>0.789744</td>\n",
       "      <td>0.788143</td>\n",
       "      <td>0.015204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.332435</td>\n",
       "      <td>0.392061</td>\n",
       "      <td>0.051981</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>{0: 1, 1: 18.03448275862069}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 18.03448275862069}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.776650</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.783036</td>\n",
       "      <td>0.015130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.281272</td>\n",
       "      <td>0.262632</td>\n",
       "      <td>0.056623</td>\n",
       "      <td>0.019521</td>\n",
       "      <td>{0: 1, 1: 18.689655172413794}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 18.689655172413794}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.760976</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.762376</td>\n",
       "      <td>0.793814</td>\n",
       "      <td>0.762626</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.781726</td>\n",
       "      <td>0.779134</td>\n",
       "      <td>0.015294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.207643</td>\n",
       "      <td>0.324793</td>\n",
       "      <td>0.064645</td>\n",
       "      <td>0.021472</td>\n",
       "      <td>{0: 1, 1: 19.344827586206897}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 19.344827586206897}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.345455</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.768844</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.793814</td>\n",
       "      <td>0.747525</td>\n",
       "      <td>0.757426</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.781726</td>\n",
       "      <td>0.772102</td>\n",
       "      <td>0.016163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2.201222</td>\n",
       "      <td>0.263837</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.010261</td>\n",
       "      <td>{0: 1, 1: 20.0}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 20.0}}</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.339286</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.768844</td>\n",
       "      <td>0.751220</td>\n",
       "      <td>0.789744</td>\n",
       "      <td>0.743842</td>\n",
       "      <td>0.757426</td>\n",
       "      <td>0.782178</td>\n",
       "      <td>0.781726</td>\n",
       "      <td>0.770369</td>\n",
       "      <td>0.015894</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        2.250955      0.296330         0.051832        0.008058   \n",
       "1        2.130902      0.313843         0.060949        0.018217   \n",
       "2        2.029917      0.164479         0.055321        0.017194   \n",
       "3        2.053845      0.223626         0.048795        0.010190   \n",
       "4        1.916154      0.390358         0.048822        0.007340   \n",
       "5        2.393969      0.420235         0.063569        0.016690   \n",
       "6        2.518186      0.288444         0.073328        0.024125   \n",
       "7        2.302058      0.191193         0.061656        0.018432   \n",
       "8        2.234714      0.244191         0.043355        0.007225   \n",
       "9        2.446520      0.392865         0.056413        0.011762   \n",
       "10       2.088143      0.243867         0.068837        0.021337   \n",
       "11       2.141162      0.326697         0.053575        0.015411   \n",
       "12       2.156841      0.224554         0.052895        0.010033   \n",
       "13       2.058311      0.325834         0.047647        0.010832   \n",
       "14       2.030570      0.242885         0.065557        0.028867   \n",
       "15       2.170277      0.284278         0.059042        0.014216   \n",
       "16       2.203410      0.277108         0.053486        0.010271   \n",
       "17       2.235799      0.248107         0.055675        0.012861   \n",
       "18       2.204852      0.180988         0.047544        0.013047   \n",
       "19       2.230201      0.265962         0.087917        0.073325   \n",
       "20       2.210891      0.269185         0.051466        0.013600   \n",
       "21       2.200259      0.298882         0.049101        0.009378   \n",
       "22       2.254960      0.268337         0.052040        0.011545   \n",
       "23       2.097384      0.279630         0.067936        0.023125   \n",
       "24       2.461906      0.207663         0.057271        0.018358   \n",
       "25       2.133721      0.275314         0.054565        0.015946   \n",
       "26       2.332435      0.392061         0.051981        0.010975   \n",
       "27       2.281272      0.262632         0.056623        0.019521   \n",
       "28       2.207643      0.324793         0.064645        0.021472   \n",
       "29       2.201222      0.263837         0.050680        0.010261   \n",
       "\n",
       "               param_class_weight  \\\n",
       "0                  {0: 1, 1: 1.0}   \n",
       "1   {0: 1, 1: 1.6551724137931034}   \n",
       "2    {0: 1, 1: 2.310344827586207}   \n",
       "3   {0: 1, 1: 2.9655172413793105}   \n",
       "4   {0: 1, 1: 3.6206896551724137}   \n",
       "5    {0: 1, 1: 4.275862068965517}   \n",
       "6    {0: 1, 1: 4.931034482758621}   \n",
       "7    {0: 1, 1: 5.586206896551724}   \n",
       "8    {0: 1, 1: 6.241379310344827}   \n",
       "9    {0: 1, 1: 6.896551724137931}   \n",
       "10   {0: 1, 1: 7.551724137931034}   \n",
       "11   {0: 1, 1: 8.206896551724139}   \n",
       "12   {0: 1, 1: 8.862068965517242}   \n",
       "13   {0: 1, 1: 9.517241379310345}   \n",
       "14  {0: 1, 1: 10.172413793103448}   \n",
       "15  {0: 1, 1: 10.827586206896552}   \n",
       "16  {0: 1, 1: 11.482758620689655}   \n",
       "17  {0: 1, 1: 12.137931034482758}   \n",
       "18  {0: 1, 1: 12.793103448275861}   \n",
       "19  {0: 1, 1: 13.448275862068964}   \n",
       "20  {0: 1, 1: 14.103448275862068}   \n",
       "21  {0: 1, 1: 14.758620689655173}   \n",
       "22  {0: 1, 1: 15.413793103448276}   \n",
       "23   {0: 1, 1: 16.06896551724138}   \n",
       "24  {0: 1, 1: 16.724137931034484}   \n",
       "25  {0: 1, 1: 17.379310344827587}   \n",
       "26   {0: 1, 1: 18.03448275862069}   \n",
       "27  {0: 1, 1: 18.689655172413794}   \n",
       "28  {0: 1, 1: 19.344827586206897}   \n",
       "29                {0: 1, 1: 20.0}   \n",
       "\n",
       "                                             params  split0_test_precision  \\\n",
       "0                  {'class_weight': {0: 1, 1: 1.0}}               1.000000   \n",
       "1   {'class_weight': {0: 1, 1: 1.6551724137931034}}               1.000000   \n",
       "2    {'class_weight': {0: 1, 1: 2.310344827586207}}               1.000000   \n",
       "3   {'class_weight': {0: 1, 1: 2.9655172413793105}}               1.000000   \n",
       "4   {'class_weight': {0: 1, 1: 3.6206896551724137}}               1.000000   \n",
       "5    {'class_weight': {0: 1, 1: 4.275862068965517}}               1.000000   \n",
       "6    {'class_weight': {0: 1, 1: 4.931034482758621}}               1.000000   \n",
       "7    {'class_weight': {0: 1, 1: 5.586206896551724}}               1.000000   \n",
       "8    {'class_weight': {0: 1, 1: 6.241379310344827}}               0.944444   \n",
       "9    {'class_weight': {0: 1, 1: 6.896551724137931}}               0.944444   \n",
       "10   {'class_weight': {0: 1, 1: 7.551724137931034}}               0.944444   \n",
       "11   {'class_weight': {0: 1, 1: 8.206896551724139}}               0.944444   \n",
       "12   {'class_weight': {0: 1, 1: 8.862068965517242}}               0.944444   \n",
       "13   {'class_weight': {0: 1, 1: 9.517241379310345}}               0.894737   \n",
       "14  {'class_weight': {0: 1, 1: 10.172413793103448}}               0.850000   \n",
       "15  {'class_weight': {0: 1, 1: 10.827586206896552}}               0.850000   \n",
       "16  {'class_weight': {0: 1, 1: 11.482758620689655}}               0.857143   \n",
       "17  {'class_weight': {0: 1, 1: 12.137931034482758}}               0.857143   \n",
       "18  {'class_weight': {0: 1, 1: 12.793103448275861}}               0.857143   \n",
       "19  {'class_weight': {0: 1, 1: 13.448275862068964}}               0.818182   \n",
       "20  {'class_weight': {0: 1, 1: 14.103448275862068}}               0.818182   \n",
       "21  {'class_weight': {0: 1, 1: 14.758620689655173}}               0.818182   \n",
       "22  {'class_weight': {0: 1, 1: 15.413793103448276}}               0.818182   \n",
       "23   {'class_weight': {0: 1, 1: 16.06896551724138}}               0.782609   \n",
       "24  {'class_weight': {0: 1, 1: 16.724137931034484}}               0.782609   \n",
       "25  {'class_weight': {0: 1, 1: 17.379310344827587}}               0.782609   \n",
       "26   {'class_weight': {0: 1, 1: 18.03448275862069}}               0.782609   \n",
       "27  {'class_weight': {0: 1, 1: 18.689655172413794}}               0.782609   \n",
       "28  {'class_weight': {0: 1, 1: 19.344827586206897}}               0.782609   \n",
       "29                {'class_weight': {0: 1, 1: 20.0}}               0.782609   \n",
       "\n",
       "    split1_test_precision  split2_test_precision  split3_test_precision  ...  \\\n",
       "0                0.463415               0.583333               1.000000  ...   \n",
       "1                0.463415               0.583333               1.000000  ...   \n",
       "2                0.463415               0.583333               1.000000  ...   \n",
       "3                0.452381               0.583333               1.000000  ...   \n",
       "4                0.452381               0.583333               1.000000  ...   \n",
       "5                0.452381               0.583333               1.000000  ...   \n",
       "6                0.452381               0.583333               1.000000  ...   \n",
       "7                0.452381               0.583333               1.000000  ...   \n",
       "8                0.452381               0.583333               0.947368  ...   \n",
       "9                0.452381               0.583333               0.947368  ...   \n",
       "10               0.452381               0.583333               0.947368  ...   \n",
       "11               0.452381               0.583333               0.947368  ...   \n",
       "12               0.441860               0.583333               0.947368  ...   \n",
       "13               0.431818               0.560000               0.947368  ...   \n",
       "14               0.431818               0.560000               0.947368  ...   \n",
       "15               0.431818               0.560000               0.947368  ...   \n",
       "16               0.431818               0.560000               0.947368  ...   \n",
       "17               0.431818               0.576923               0.947368  ...   \n",
       "18               0.413043               0.576923               0.947368  ...   \n",
       "19               0.413043               0.576923               0.947368  ...   \n",
       "20               0.413043               0.576923               0.947368  ...   \n",
       "21               0.404255               0.576923               0.947368  ...   \n",
       "22               0.387755               0.576923               0.947368  ...   \n",
       "23               0.380000               0.576923               0.947368  ...   \n",
       "24               0.380000               0.555556               0.947368  ...   \n",
       "25               0.380000               0.555556               0.947368  ...   \n",
       "26               0.365385               0.535714               0.947368  ...   \n",
       "27               0.345455               0.535714               0.947368  ...   \n",
       "28               0.345455               0.535714               0.947368  ...   \n",
       "29               0.339286               0.535714               0.947368  ...   \n",
       "\n",
       "    split2_train_min_both  split3_train_min_both  split4_train_min_both  \\\n",
       "0                0.627119               0.548023               0.573864   \n",
       "1                0.683616               0.627119               0.670455   \n",
       "2                0.740113               0.683616               0.710227   \n",
       "3                0.785311               0.706215               0.744318   \n",
       "4                0.824859               0.740113               0.755682   \n",
       "5                0.841808               0.768362               0.778409   \n",
       "6                0.847458               0.802260               0.789773   \n",
       "7                0.847458               0.804469               0.802198   \n",
       "8                0.837989               0.806630               0.805405   \n",
       "9                0.838889               0.807692               0.805405   \n",
       "10               0.839779               0.809783               0.806452   \n",
       "11               0.839779               0.809783               0.807487   \n",
       "12               0.841530               0.809783               0.807487   \n",
       "13               0.836957               0.805405               0.807487   \n",
       "14               0.832432               0.801075               0.807487   \n",
       "15               0.832432               0.796791               0.803191   \n",
       "16               0.827957               0.796791               0.804233   \n",
       "17               0.828877               0.794737               0.801047   \n",
       "18               0.825397               0.794737               0.801047   \n",
       "19               0.825397               0.795812               0.801047   \n",
       "20               0.816754               0.795812               0.797927   \n",
       "21               0.808290               0.791667               0.797927   \n",
       "22               0.804124               0.787565               0.797927   \n",
       "23               0.791878               0.787565               0.789744   \n",
       "24               0.783920               0.787565               0.789744   \n",
       "25               0.772277               0.784615               0.789744   \n",
       "26               0.764706               0.772727               0.777778   \n",
       "27               0.760976               0.772727               0.762376   \n",
       "28               0.757282               0.768844               0.754902   \n",
       "29               0.757282               0.768844               0.751220   \n",
       "\n",
       "    split5_train_min_both  split6_train_min_both  split7_train_min_both  \\\n",
       "0                0.573864               0.562500               0.613636   \n",
       "1                0.647727               0.630682               0.687500   \n",
       "2                0.698864               0.687500               0.715909   \n",
       "3                0.732955               0.715909               0.755682   \n",
       "4                0.744318               0.727273               0.778409   \n",
       "5                0.789773               0.772727               0.789773   \n",
       "6                0.813559               0.801136               0.801136   \n",
       "7                0.811111               0.798883               0.806818   \n",
       "8                0.812155               0.801105               0.811111   \n",
       "9                0.812155               0.802198               0.812155   \n",
       "10               0.813187               0.803279               0.812155   \n",
       "11               0.814208               0.803279               0.805405   \n",
       "12               0.814208               0.794595               0.806452   \n",
       "13               0.809783               0.794595               0.800000   \n",
       "14               0.810811               0.794595               0.795812   \n",
       "15               0.806452               0.794595               0.795812   \n",
       "16               0.802139               0.791444               0.795812   \n",
       "17               0.802139               0.787234               0.796875   \n",
       "18               0.802139               0.788360               0.792746   \n",
       "19               0.798942               0.789474               0.788660   \n",
       "20               0.798942               0.785340               0.788660   \n",
       "21               0.794737               0.781250               0.784615   \n",
       "22               0.791667               0.781250               0.784615   \n",
       "23               0.791667               0.781250               0.784615   \n",
       "24               0.791667               0.773196               0.784615   \n",
       "25               0.791667               0.769231               0.780612   \n",
       "26               0.791667               0.765306               0.776650   \n",
       "27               0.793814               0.762626               0.772727   \n",
       "28               0.793814               0.747525               0.757426   \n",
       "29               0.789744               0.743842               0.757426   \n",
       "\n",
       "    split8_train_min_both  split9_train_min_both  mean_train_min_both  \\\n",
       "0                0.636364               0.607955             0.612185   \n",
       "1                0.698864               0.687500             0.680239   \n",
       "2                0.744318               0.727273             0.724454   \n",
       "3                0.772727               0.738636             0.749978   \n",
       "4                0.784091               0.761364             0.771498   \n",
       "5                0.795455               0.772727             0.792485   \n",
       "6                0.804469               0.789773             0.810493   \n",
       "7                0.807692               0.804469             0.815197   \n",
       "8                0.807487               0.806630             0.816403   \n",
       "9                0.808511               0.809783             0.817098   \n",
       "10               0.804233               0.809783             0.817284   \n",
       "11               0.801047               0.802139             0.815398   \n",
       "12               0.801047               0.803191             0.814915   \n",
       "13               0.801047               0.803191             0.812932   \n",
       "14               0.796875               0.803191             0.811314   \n",
       "15               0.797927               0.798942             0.809700   \n",
       "16               0.798969               0.795812             0.808505   \n",
       "17               0.794872               0.795812             0.807484   \n",
       "18               0.795918               0.795812             0.806940   \n",
       "19               0.787879               0.795812             0.805138   \n",
       "20               0.787879               0.795812             0.803065   \n",
       "21               0.787879               0.795812             0.799354   \n",
       "22               0.783920               0.795812             0.796884   \n",
       "23               0.783920               0.796875             0.794533   \n",
       "24               0.783920               0.792746             0.790700   \n",
       "25               0.783920               0.789744             0.788143   \n",
       "26               0.785000               0.785714             0.783036   \n",
       "27               0.782178               0.781726             0.779134   \n",
       "28               0.782178               0.781726             0.772102   \n",
       "29               0.782178               0.781726             0.770369   \n",
       "\n",
       "    std_train_min_both  \n",
       "0             0.054733  \n",
       "1             0.050286  \n",
       "2             0.043881  \n",
       "3             0.039589  \n",
       "4             0.037959  \n",
       "5             0.029289  \n",
       "6             0.020970  \n",
       "7             0.020943  \n",
       "8             0.018628  \n",
       "9             0.018411  \n",
       "10            0.018499  \n",
       "11            0.019494  \n",
       "12            0.020312  \n",
       "13            0.020260  \n",
       "14            0.020500  \n",
       "15            0.021012  \n",
       "16            0.020987  \n",
       "17            0.023328  \n",
       "18            0.023102  \n",
       "19            0.022498  \n",
       "20            0.020900  \n",
       "21            0.020057  \n",
       "22            0.017778  \n",
       "23            0.017756  \n",
       "24            0.013566  \n",
       "25            0.015204  \n",
       "26            0.015130  \n",
       "27            0.015294  \n",
       "28            0.016163  \n",
       "29            0.015894  \n",
       "\n",
       "[30 rows x 81 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23fe3b1e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_results_\u001b[49m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m score \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_recall_score\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_precision\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_test_min_both\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      4\u001b[0m     plt\u001b[38;5;241m.\u001b[39mplot([_[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparam_class_weight\u001b[39m\u001b[38;5;124m'\u001b[39m]], \n\u001b[0;32m      5\u001b[0m              df[score], \n\u001b[0;32m      6\u001b[0m              label\u001b[38;5;241m=\u001b[39mscore)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "for score in ['mean_test_recall_score', 'mean_test_precision', 'mean_test_min_both']:\n",
    "    plt.plot([_[1] for _ in df['param_class_weight']], \n",
    "             df[score], \n",
    "             label=score)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ab81a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below code was used to find whether there was even a mean_test_recall column. I found that it was not even there in the first case which was giving a key error message.\n",
    "#fixed it by just using the mean_test_recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24ecdd94",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'cv_results_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcv_results_\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Print the column names to check for correctness\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'cv_results_'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x400 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "# Print the column names to check for correctness\n",
    "print(df.columns)\n",
    "\n",
    "for score in ['mean_test_recall', 'mean_test_precision']:\n",
    "    plt.plot([_[1] for _ in df['param_class_weight']], \n",
    "             df[score], \n",
    "             label=score)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a534f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_recall_precision(y_true, y_pred):\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    return min(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6d157a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e98c64e7d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "for score in ['mean_train_recall_score', 'mean_train_precision']:\n",
    "    plt.scatter(x=[_[1] for _ in df['param_class_weight']],\n",
    "               y=df[score.replace('test', 'train')],\n",
    "               label=score)\n",
    "    \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adea2bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = make_scorer(min_recall_precision)\n",
    "??s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "860465de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==0.23.0Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached scikit-learn-0.23.0.tar.gz (7.2 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: still running...\n",
      "  Installing build dependencies: finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade scikit-learn==0.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd2ba8b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to expression here. Maybe you meant '==' instead of '='? (3936940341.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    --NotebookApp.iopub_data_rate_limit=1.0e10\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to expression here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "--NotebookApp.iopub_data_rate_limit=1.0e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83f75eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: the following arguments are required: filename\n"
     ]
    }
   ],
   "source": [
    "notebook --NotebookApp.iopub_data_rate_limit=1.0e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "870355d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1387249117.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    jupyter notebook --generate-config\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "jupyter notebook --generate-config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7017e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
