{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic feature engineering and feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook some basic methods for adding new, useful features to a dataset is introduced:\n",
    "\n",
    "- Creating dummy variables\n",
    "- Binning of numerical features\n",
    "- Creating interacting features\n",
    "- Scaling of numerical features\n",
    "\n",
    "Furthermore, we show how we can automatically select the most useful features in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading a few packages we know we will need. More will be loaded along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a toy dataset, consisting of fruits with different colors and diameters. In the dataset there are approximately:\n",
    "- 500 grapes with a mean diameter of 1.5cm and a color which is a random assignment of either green or red.\n",
    "- 400 ripe apples with a mean diameter of 7cm and a color which is a random assignment of green, red or yellow.\n",
    "- 100 unripe apples with a mean diameter of 3cm, which are all green.\n",
    "\n",
    "See the notebook \"Appendix - generating fruits-data.ipynb\" to see how the data is generated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the dataset is loaded, and values in the column \"Diameter\" are converted to floats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Color</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Red</td>\n",
       "      <td>1.883633</td>\n",
       "      <td>Grape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Green</td>\n",
       "      <td>0.912832</td>\n",
       "      <td>Grape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>12.021957</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Green</td>\n",
       "      <td>6.097648</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Red</td>\n",
       "      <td>1.786855</td>\n",
       "      <td>Grape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>7.593902</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Red</td>\n",
       "      <td>1.534767</td>\n",
       "      <td>Grape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Green</td>\n",
       "      <td>2.128611</td>\n",
       "      <td>Grape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Red</td>\n",
       "      <td>2.526992</td>\n",
       "      <td>Grape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Red</td>\n",
       "      <td>4.442242</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0   Color   Diameter  Label\n",
       "0           0     Red   1.883633  Grape\n",
       "1           1   Green   0.912832  Grape\n",
       "2           2  Yellow  12.021957  Apple\n",
       "3           3   Green   6.097648  Apple\n",
       "4           4     Red   1.786855  Grape\n",
       "5           5  Yellow   7.593902  Apple\n",
       "6           6     Red   1.534767  Grape\n",
       "7           7   Green   2.128611  Grape\n",
       "8           8     Red   2.526992  Grape\n",
       "9           9     Red   4.442242  Apple"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('fruits-data.csv')\n",
    "data['Diameter'] = data['Diameter'].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Failed attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to train a decision tree on this data! We pull out the features and the labels and try training a tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = data.loc[:, 'Color':'Diameter']\n",
    "# y = data.loc[:,'Label']\n",
    "# tree = DecisionTreeClassifier()\n",
    "# tree.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code fails! Because even though the algorithm behind the decision tree is capable of handling categorical (i.e. non-numeric) features, the specific *implementation* in sklearn cannot do that! So we need to represent the color in a different way - e.g. by using socalled **dummy variables**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy variables (one-hot-encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first pull out the labels and then use the pandas-function \"get dummies\" to create a new dataset in which all categorical variables are converted to dummy variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Diameter', 'Color_Green', 'Color_Red', 'Color_Yellow']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Color_Green</th>\n",
       "      <th>Color_Red</th>\n",
       "      <th>Color_Yellow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.883633</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912832</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.021957</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.097648</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.786855</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.593902</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.534767</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.128611</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.526992</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.442242</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Diameter  Color_Green  Color_Red  Color_Yellow\n",
       "0   1.883633        False       True         False\n",
       "1   0.912832         True      False         False\n",
       "2  12.021957        False      False          True\n",
       "3   6.097648         True      False         False\n",
       "4   1.786855        False       True         False\n",
       "5   7.593902        False      False          True\n",
       "6   1.534767        False       True         False\n",
       "7   2.128611         True      False         False\n",
       "8   2.526992        False       True         False\n",
       "9   4.442242        False       True         False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data.loc[:,'Label']\n",
    "features = data.loc[:,'Color':'Diameter']\n",
    "features = pd.get_dummies(features)\n",
    "print(list(features.columns))\n",
    "features[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create train and test sets for subsequent training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: **In all of the following examples, we will depart from the features and labels defined in the previous cell** - i.e. \"features\" will point back to the array of features with dummy variables created for the colors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, we train a decision tree and print the obtained accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 1.0\n",
      "Accuracy on testing data = 0.8947368421052632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier() \n",
    "tree.fit(X_train,y_train)\n",
    "print(\"Accuracy on training data = {}\".format(tree.score(X_train, y_train)))\n",
    "print(\"Accuracy on testing data = {}\\n\".format(tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the overfitting we saw in the previous tree might be due to the fact that the tree is able to perfectly predict each fruit in the training set based on its diameter alone. One way to avoid this is to bin the diameters. In order to do this, we first create the bins we want to use using the linspace-function from numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  4.,  6.,  8., 10., 12., 14., 16., 18.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We choose the upper limit as some number strictly larger than the largest diameter IN THE TRAIN DATA!\n",
    "bins = np.linspace(0, 18, 10) \n",
    "bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then use the \"digitize\"-function to determine which bin each sample belongs to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [7],\n",
       "       [4],\n",
       "       [1],\n",
       "       [4],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [3]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which_bin = np.digitize(features.loc[:,\"Diameter\"], bins=bins).reshape(-1,1)\n",
    "which_bin[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then drop the \"Diameter\"-feature and append the corresponding bins instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color_Green</th>\n",
       "      <th>Color_Red</th>\n",
       "      <th>Color_Yellow</th>\n",
       "      <th>Bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Color_Green  Color_Red  Color_Yellow  Bin\n",
       "0        False       True         False    1\n",
       "1         True      False         False    1\n",
       "2        False      False          True    7\n",
       "3         True      False         False    4\n",
       "4        False       True         False    1\n",
       "5        False      False          True    4\n",
       "6        False       True         False    1\n",
       "7         True      False         False    2\n",
       "8        False       True         False    2\n",
       "9        False       True         False    3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which_bin_df = pd.DataFrame(which_bin, columns=['Bin'])\n",
    "features_binned = features.drop(['Diameter'], axis=1).join(which_bin_df)\n",
    "features_binned[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to split the data into train and test sets again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_binned = features_binned.values\n",
    "X_train_binned, X_test_binned, y_train, y_test = train_test_split(X_binned, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, we train the same model as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 0.9109311740890689\n",
      "Accuracy on testing data = 0.9109311740890689\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier() \n",
    "tree.fit(X_train_binned,y_train)\n",
    "print(\"Accuracy on training data = {}\".format(tree.score(X_train_binned, y_train)))\n",
    "print(\"Accuracy on testing data = {}\\n\".format(tree.score(X_test_binned, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that in this case, binning reduced the amount of overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Could it be that for red or yellow fruits the diameter has a great importance, whereas it means nothing for green fruits? \n",
    "If this is the case, we might gain something by adding one or more of the **interaction features**   \n",
    "- $\\text{Color\\_Green} \\times \\text{Diameter}$,\n",
    "- $\\text{Color\\_Red} \\times \\text{Diameter}\\text{      }$ or\n",
    "- $\\text{Color\\_Yellow} \\times \\text{Diameter}$.\n",
    "\n",
    "This is a way to allow the algorithm (in this case the decision tree) to take into account how these features interact with each other - lets try! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define each of the interacting features we are interested in and append them to the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Color_Green</th>\n",
       "      <th>Color_Red</th>\n",
       "      <th>Color_Yellow</th>\n",
       "      <th>Green_Times_Diameter</th>\n",
       "      <th>Red_Times_Diameter</th>\n",
       "      <th>Yellow_Times_Diameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.883633</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.883633</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.912832</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0.912832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.021957</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.021957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.097648</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.097648</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.786855</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.786855</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.593902</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.593902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.534767</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.534767</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.128611</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.128611</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.526992</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.526992</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.442242</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.442242</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Diameter  Color_Green  Color_Red  Color_Yellow  Green_Times_Diameter  \\\n",
       "0   1.883633        False       True         False              0.000000   \n",
       "1   0.912832         True      False         False              0.912832   \n",
       "2  12.021957        False      False          True              0.000000   \n",
       "3   6.097648         True      False         False              6.097648   \n",
       "4   1.786855        False       True         False              0.000000   \n",
       "5   7.593902        False      False          True              0.000000   \n",
       "6   1.534767        False       True         False              0.000000   \n",
       "7   2.128611         True      False         False              2.128611   \n",
       "8   2.526992        False       True         False              0.000000   \n",
       "9   4.442242        False       True         False              0.000000   \n",
       "\n",
       "   Red_Times_Diameter  Yellow_Times_Diameter  \n",
       "0            1.883633               0.000000  \n",
       "1            0.000000               0.000000  \n",
       "2            0.000000              12.021957  \n",
       "3            0.000000               0.000000  \n",
       "4            1.786855               0.000000  \n",
       "5            0.000000               7.593902  \n",
       "6            1.534767               0.000000  \n",
       "7            0.000000               0.000000  \n",
       "8            2.526992               0.000000  \n",
       "9            4.442242               0.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "green_times_diameter = pd.DataFrame(features['Color_Green']*features['Diameter'],columns=['Green_Times_Diameter'],dtype=float)\n",
    "red_times_diameter = pd.DataFrame(features['Color_Red']*features['Diameter'],columns=['Red_Times_Diameter'],dtype=float)\n",
    "yellow_times_diameter = pd.DataFrame(features['Color_Yellow']*features['Diameter'],columns=['Yellow_Times_Diameter'],dtype=float)\n",
    "\n",
    "features_interact = features.join(green_times_diameter).join(red_times_diameter).join(yellow_times_diameter)\n",
    "features_interact[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then pull out the feature values, split in traning and testing, fit a decision tree, and compute and compare the accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 1.0\n",
      "Accuracy on testing data = 0.8421052631578947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_interact = features_interact.values\n",
    "X_train_interact, X_test_interact, y_train, y_test = train_test_split(X_interact, y)\n",
    "\n",
    "tree = DecisionTreeClassifier() \n",
    "tree.fit(X_train_interact,y_train)\n",
    "print(\"Accuracy on training data = {}\".format(tree.score(X_train_interact, y_train)))\n",
    "print(\"Accuracy on testing data = {}\\n\".format(tree.score(X_test_interact, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatically adding interactions: PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can actually ask sklearn to compute **all** interactions up to a specified degree automatically. We do this using the function \"PolynomialFeatures\", which add all possible multiplications of features up to a certain degree (which is controlled by the \"degree\"-argument as seen below):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PolynomialFeatures' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\repos\\MAL\\session 2\\Data prep and feature eng 1 - Dummy, binning, feat sel.ipynb Cell 41\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/repos/MAL/session%202/Data%20prep%20and%20feature%20eng%201%20-%20Dummy%2C%20binning%2C%20feat%20sel.ipynb#X55sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m poly\u001b[39m.\u001b[39mfit(X)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/repos/MAL/session%202/Data%20prep%20and%20feature%20eng%201%20-%20Dummy%2C%20binning%2C%20feat%20sel.ipynb#X55sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_poly \u001b[39m=\u001b[39m poly\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/repos/MAL/session%202/Data%20prep%20and%20feature%20eng%201%20-%20Dummy%2C%20binning%2C%20feat%20sel.ipynb#X55sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPolynomial feature names:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(poly\u001b[39m.\u001b[39;49mget_feature_names()))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'PolynomialFeatures' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X = features.values\n",
    "poly.fit(X)\n",
    "X_poly = poly.transform(X)\n",
    "print(\"Polynomial feature names:\\n{}\".format(poly.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the list above, 'x0' correspond to the first feature in the dataset (i.e. 'Diameter'), 'x1' to the second feature (Color\\_Green)  and so on. The feature 'x0 x1' corresponds to the feature $\\text{Diameter}\\times\\text{Color\\_Green}$ which we manually added before.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already pulled out the feature values above, so all we need to do is to split the data in train and test and fit the decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 1.0\n",
      "Accuracy on testing data = 0.8785425101214575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_poly, X_test_poly, y_train, y_test = train_test_split(X_poly, y)\n",
    "\n",
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train_poly, y_train)\n",
    "\n",
    "print(\"Accuracy on training data = {}\".format(tree.score(X_train_poly, y_train)))\n",
    "print(\"Accuracy on testing data = {}\\n\".format(tree.score(X_test_poly, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding polynomial interactions can be extremely useful - especially for algorithms like the decision tree which cannot by itself consider combinations of features. However, when we do this, we create a much larger feature space - and this makes it more difficult for the algorithms to identify a good set of questions! Luckily, we can also make sklearn automatically select the most important features for us, and then leave out everything else:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Feature selection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decision tree seems to be overfitting quite a bit after we have added all the interaction features. Adding too many useless features increases the risk of overfitting, and makes it more difficult for the algorithms to identify the relevant parameters.\n",
    "\n",
    "Luckily, sklearn have methods for identifying the most useful features. They are all part of the module \"sklearn.feature_selection\":\n",
    "- SelectPercentile: Select e.g. the 50% of features which have the largest correlation with the target\n",
    "- SelectFromModel: Fits some model, and only keeps the features that this model finds to be the most important.\n",
    "- RFE (\"recursive feature elimination\"): fits a model and discards the least useful feature. This is repeated until only the wanted number of features is left.\n",
    "\n",
    "We will only demonstrate the first of these - you can look up the syntax for the other two in the documentation (or the book)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train with all interaction features: (741, 15)\n",
      "The shape of X_train after selected 50% of features: (741, 7)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "select = SelectPercentile(percentile=50) # 50% of the features will be chosen\n",
    "select.fit(X_train_poly, y_train)\n",
    "\n",
    "X_train_selected = select.transform(X_train_poly)\n",
    "X_test_selected = select.transform(X_test_poly)\n",
    "\n",
    "print(\"The shape of X_train with all interaction features: {}\".format(X_train_poly.shape))\n",
    "print(\"The shape of X_train after selected 50% of features: {}\".format(X_train_selected.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see which features were selected by using the \"get_support\"-method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected features are:\n",
      "\n",
      "x0\n",
      "x3\n",
      "x0^2\n",
      "x0 x1\n",
      "x0 x2\n",
      "x0 x3\n",
      "x3^2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['1', 'x0', '1', '1', 'x0', 'x0', 'x0', 'x0', 'x0', '1', '1', '1',\n",
       "       '1', '1', 'x0'], dtype='<U5')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = select.get_support()\n",
    "print(\"The selected features are:\\n\")\n",
    "[print(name) for m, name in zip(mask, poly.get_feature_names()) if m]\n",
    "np.array(poly.get_feature_names())[mask.astype(int)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last, we fit the tree and calculate the accuracies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data = 1.0\n",
      "Accuracy on testing data = 0.8947368421052632\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree.fit(X_train_selected, y_train)\n",
    "print(\"Accuracy on training data = {}\".format(tree.score(X_train_selected, y_train)))\n",
    "print(\"Accuracy on testing data = {}\\n\".format(tree.score(X_test_selected, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
