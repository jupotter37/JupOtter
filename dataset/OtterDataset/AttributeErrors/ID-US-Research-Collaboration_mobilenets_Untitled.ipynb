{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c1eae2-feb4-4901-a98e-94961bf54071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import onnx\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caeadd80-ffca-4378-966a-ad15f8336609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.ReLU6(inplace=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e6b9c3c-6326-49dc-a695-ec3db3e13d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = int(round(inp * expand_ratio))\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        layers = []\n",
    "        if expand_ratio != 1:\n",
    "            layers.append(nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False))\n",
    "            layers.append(nn.BatchNorm2d(hidden_dim))\n",
    "            layers.append(nn.ReLU6(inplace=True))\n",
    "        layers.extend([\n",
    "            nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU6(inplace=True),\n",
    "            nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(oup),\n",
    "        ])\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad7fe5c-6033-434c-886e-722d94f4ea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, num_classes=10, width_mult=1.):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        input_channel = 32\n",
    "        last_channel = 1280\n",
    "        inverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = int(input_channel * width_mult)\n",
    "        self.last_channel = int(last_channel * max(1.0, width_mult))\n",
    "        features = [conv_bn(1, input_channel, 2)]  # Changed input channels to 1 for MNIST\n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in inverted_residual_setting:\n",
    "            output_channel = int(c * width_mult)\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                features.append(block(input_channel, output_channel, stride, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "        # building last several layers\n",
    "        features.append(conv_bn(input_channel, self.last_channel, 1))\n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*features)\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.last_channel, num_classes),\n",
    "        )\n",
    "\n",
    "        # weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.mean([2, 3])\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0726586a-fa0a-411a-9cf4-e6178bfd5ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(device, batch_size=64):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "    \n",
    "    train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d601b41-db99-4c63-8f4f-f0476a7ab1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, data_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in data_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26b46a5c-35c6-452b-aead-eede66baf07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, device, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 100 == 99:  # print every 100 mini-batches\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}')\n",
    "                running_loss = 0.0\n",
    "        \n",
    "        # Calculate and print training accuracy at the end of each epoch\n",
    "        train_accuracy = calculate_accuracy(model, train_loader, device)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Accuracy: {train_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8144696-d719-4361-86e2-84b3b6a3d8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy on test set: {accuracy:.2f}%')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20c3da89-b8a9-4c7e-93a2-7af1a4551534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path='mobilenet_mnist.pth'):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80e3acdb-a71b-464f-823d-4da78009dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, path='mobilenet_mnist.pth', device='cpu'):\n",
    "    if os.path.exists(path):\n",
    "        model.load_state_dict(torch.load(path))\n",
    "        print(f\"Model loaded from {path}\")\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e12d883b-ed5a-4be2-83ec-ff0ae88d92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_onnx(model, sample_input, onnx_path='mobilenet_mnist.onnx'):\n",
    "    torch.onnx.export(model, sample_input, onnx_path, export_params=True, opset_version=10, do_constant_folding=True, input_names=['input'], output_names=['output'], dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}})\n",
    "    print(f\"Model exported to ONNX format at {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0216498-861d-4084-aac4-68c718586e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_onnx(onnx_path='mobilenet_mnist.onnx'):\n",
    "    onnx_model = onnx.load(onnx_path)\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "    print(\"ONNX model is valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6d735d6-dc05-4dcc-bda5-43a336e13ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_onnx(onnx_path, test_loader, device):\n",
    "    session = onnxruntime.InferenceSession(onnx_path, providers=['CPUExecutionProvider'] if device == 'cpu' else ['CUDAExecutionProvider'])\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data, targets in test_loader:\n",
    "        data = data.numpy()  # Convert to numpy array\n",
    "        outputs = session.run(None, {'input': data})\n",
    "        predicted = outputs[0].argmax(axis=1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets.numpy()).sum()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'ONNX model accuracy on test set: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48113f6e-937e-4a31-857c-aa22b2dc2068",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    train_loader, test_loader = preprocess_data(device)\n",
    "    \n",
    "    model = MobileNetV2().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    num_epochs = 10\n",
    "    model_path = 'mobilenetv2_mnist.pth'\n",
    "    onnx_path = 'mobilenetv2_mnist.onnx'\n",
    "    \n",
    "    if not load_model(model, model_path, device):\n",
    "        print(\"Training new model...\")\n",
    "        train(model, train_loader, criterion, optimizer, device, num_epochs)\n",
    "        save_model(model, model_path)\n",
    "    else:\n",
    "        print(\"Using pre-trained model.\")\n",
    "    \n",
    "    test(model, test_loader, device)\n",
    "    \n",
    "    # Export to ONNX\n",
    "    sample_input = torch.randn(1, 1, 28, 28).to(device)\n",
    "    export_to_onnx(model, sample_input, onnx_path)\n",
    "    verify_onnx(onnx_path)\n",
    "    test_onnx(onnx_path, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1adf3c5-1d2a-4be8-a3a8-1cde2480c61f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Training new model...\n",
      "Epoch [1/10], Step [100/938], Loss: 1.5688\n",
      "Epoch [1/10], Step [200/938], Loss: 0.7146\n",
      "Epoch [1/10], Step [300/938], Loss: 0.4681\n",
      "Epoch [1/10], Step [400/938], Loss: 0.3754\n",
      "Epoch [1/10], Step [500/938], Loss: 0.2884\n",
      "Epoch [1/10], Step [600/938], Loss: 0.2495\n",
      "Epoch [1/10], Step [700/938], Loss: 0.2287\n",
      "Epoch [1/10], Step [800/938], Loss: 0.2115\n",
      "Epoch [1/10], Step [900/938], Loss: 0.1865\n",
      "Epoch [1/10], Train Accuracy: 96.07%\n",
      "Epoch [2/10], Step [100/938], Loss: 0.1748\n",
      "Epoch [2/10], Step [200/938], Loss: 0.1594\n",
      "Epoch [2/10], Step [300/938], Loss: 0.1525\n",
      "Epoch [2/10], Step [400/938], Loss: 0.1353\n",
      "Epoch [2/10], Step [500/938], Loss: 0.1457\n",
      "Epoch [2/10], Step [600/938], Loss: 0.1323\n",
      "Epoch [2/10], Step [700/938], Loss: 0.1369\n",
      "Epoch [2/10], Step [800/938], Loss: 0.1265\n",
      "Epoch [2/10], Step [900/938], Loss: 0.1172\n",
      "Epoch [2/10], Train Accuracy: 97.65%\n",
      "Epoch [3/10], Step [100/938], Loss: 0.1014\n",
      "Epoch [3/10], Step [200/938], Loss: 0.0910\n",
      "Epoch [3/10], Step [300/938], Loss: 0.1097\n",
      "Epoch [3/10], Step [400/938], Loss: 0.1139\n",
      "Epoch [3/10], Step [500/938], Loss: 0.0986\n",
      "Epoch [3/10], Step [600/938], Loss: 0.1149\n",
      "Epoch [3/10], Step [700/938], Loss: 0.1070\n",
      "Epoch [3/10], Step [800/938], Loss: 0.1076\n",
      "Epoch [3/10], Step [900/938], Loss: 0.0956\n",
      "Epoch [3/10], Train Accuracy: 97.79%\n",
      "Epoch [4/10], Step [100/938], Loss: 0.0856\n",
      "Epoch [4/10], Step [200/938], Loss: 0.0887\n",
      "Epoch [4/10], Step [300/938], Loss: 0.0936\n",
      "Epoch [4/10], Step [400/938], Loss: 0.0978\n",
      "Epoch [4/10], Step [500/938], Loss: 0.0967\n",
      "Epoch [4/10], Step [600/938], Loss: 0.0951\n",
      "Epoch [4/10], Step [700/938], Loss: 0.0966\n",
      "Epoch [4/10], Step [800/938], Loss: 0.0775\n",
      "Epoch [4/10], Step [900/938], Loss: 0.0871\n",
      "Epoch [4/10], Train Accuracy: 98.35%\n",
      "Epoch [5/10], Step [100/938], Loss: 0.0660\n",
      "Epoch [5/10], Step [200/938], Loss: 0.0738\n",
      "Epoch [5/10], Step [300/938], Loss: 0.0731\n",
      "Epoch [5/10], Step [400/938], Loss: 0.0902\n",
      "Epoch [5/10], Step [500/938], Loss: 0.0891\n",
      "Epoch [5/10], Step [600/938], Loss: 0.0816\n",
      "Epoch [5/10], Step [700/938], Loss: 0.0835\n",
      "Epoch [5/10], Step [800/938], Loss: 0.0790\n",
      "Epoch [5/10], Step [900/938], Loss: 0.0775\n",
      "Epoch [5/10], Train Accuracy: 98.96%\n",
      "Epoch [6/10], Step [100/938], Loss: 0.0606\n",
      "Epoch [6/10], Step [200/938], Loss: 0.0544\n",
      "Epoch [6/10], Step [300/938], Loss: 0.0658\n",
      "Epoch [6/10], Step [400/938], Loss: 0.0623\n",
      "Epoch [6/10], Step [500/938], Loss: 0.0639\n",
      "Epoch [6/10], Step [600/938], Loss: 0.0662\n",
      "Epoch [6/10], Step [700/938], Loss: 0.0781\n",
      "Epoch [6/10], Step [800/938], Loss: 0.0732\n",
      "Epoch [6/10], Step [900/938], Loss: 0.0832\n",
      "Epoch [6/10], Train Accuracy: 98.87%\n",
      "Epoch [7/10], Step [100/938], Loss: 0.0638\n",
      "Epoch [7/10], Step [200/938], Loss: 0.0700\n",
      "Epoch [7/10], Step [300/938], Loss: 0.0673\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0462\n",
      "Epoch [7/10], Step [500/938], Loss: 0.0556\n",
      "Epoch [7/10], Step [600/938], Loss: 0.0675\n",
      "Epoch [7/10], Step [700/938], Loss: 0.0672\n",
      "Epoch [7/10], Step [800/938], Loss: 0.0652\n",
      "Epoch [7/10], Step [900/938], Loss: 0.0624\n",
      "Epoch [7/10], Train Accuracy: 98.68%\n",
      "Epoch [8/10], Step [100/938], Loss: 0.0513\n",
      "Epoch [8/10], Step [200/938], Loss: 0.0486\n",
      "Epoch [8/10], Step [300/938], Loss: 0.0679\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0531\n",
      "Epoch [8/10], Step [500/938], Loss: 0.0541\n",
      "Epoch [8/10], Step [600/938], Loss: 0.0646\n",
      "Epoch [8/10], Step [700/938], Loss: 0.0699\n",
      "Epoch [8/10], Step [800/938], Loss: 0.0572\n",
      "Epoch [8/10], Step [900/938], Loss: 0.0581\n",
      "Epoch [8/10], Train Accuracy: 99.23%\n",
      "Epoch [9/10], Step [100/938], Loss: 0.0441\n",
      "Epoch [9/10], Step [200/938], Loss: 0.0477\n",
      "Epoch [9/10], Step [300/938], Loss: 0.0581\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0709\n",
      "Epoch [9/10], Step [500/938], Loss: 0.0527\n",
      "Epoch [9/10], Step [600/938], Loss: 0.0536\n",
      "Epoch [9/10], Step [700/938], Loss: 0.0496\n",
      "Epoch [9/10], Step [800/938], Loss: 0.0439\n",
      "Epoch [9/10], Step [900/938], Loss: 0.0382\n",
      "Epoch [9/10], Train Accuracy: 99.32%\n",
      "Epoch [10/10], Step [100/938], Loss: 0.0396\n",
      "Epoch [10/10], Step [200/938], Loss: 0.0417\n",
      "Epoch [10/10], Step [300/938], Loss: 0.0440\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0352\n",
      "Epoch [10/10], Step [500/938], Loss: 0.0515\n",
      "Epoch [10/10], Step [600/938], Loss: 0.0409\n",
      "Epoch [10/10], Step [700/938], Loss: 0.0399\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0430\n",
      "Epoch [10/10], Step [900/938], Loss: 0.0456\n",
      "Epoch [10/10], Train Accuracy: 98.90%\n",
      "Model saved to mobilenetv2_mnist.pth\n",
      "Accuracy on test set: 98.71%\n",
      "Model exported to ONNX format at mobilenetv2_mnist.onnx\n",
      "ONNX model is valid\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'onnxruntime' has no attribute 'InferenceSession'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 28\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m export_to_onnx(model, sample_input, onnx_path)\n\u001b[1;32m     27\u001b[0m verify_onnx(onnx_path)\n\u001b[0;32m---> 28\u001b[0m \u001b[43mtest_onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[43monnx_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m, in \u001b[0;36mtest_onnx\u001b[0;34m(onnx_path, test_loader, device)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_onnx\u001b[39m(onnx_path, test_loader, device):\n\u001b[0;32m----> 2\u001b[0m     session \u001b[38;5;241m=\u001b[39m \u001b[43monnxruntime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInferenceSession\u001b[49m(onnx_path, providers\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCPUExecutionProvider\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCUDAExecutionProvider\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m     correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      5\u001b[0m     total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'onnxruntime' has no attribute 'InferenceSession'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d0ce20-a483-4f55-a0ad-216c0886ea02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
