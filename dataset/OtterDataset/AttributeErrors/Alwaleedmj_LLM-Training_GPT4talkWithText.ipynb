{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import time\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4-1106-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 1 document\n",
      "You have 4458520 characters in that document\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader('90coffe in hittan.txt')\n",
    "doc = loader.load()\n",
    "print (f\"You have {len(doc)} document\")\n",
    "print (f\"You have {len(doc[0].page_content)} characters in that document\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)\n",
    "docs = text_splitter.split_documents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now you have 1746 documents that have an average of 2,929 characters (smaller pieces)\n"
     ]
    }
   ],
   "source": [
    "num_total_characters = sum([len(x.page_content) for x in docs])\n",
    "\n",
    "print (f\"Now you have {len(docs)} documents that have an average of {num_total_characters / len(docs):,.0f} characters (smaller pieces)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500  # Adjust this based on your needs and token sizes\n",
    "batches = [docs[i:i + batch_size] for i in range(0, len(docs), batch_size)]\n",
    "\n",
    "for batch in batches:\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    docsearch = FAISS.from_documents(batch, embeddings)\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'OpenAIEmbeddings' object has no attribute 'embed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming 'docs' is a list of your document chunks\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Generate embeddings for each document\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m doc_embeddings \u001b[38;5;241m=\u001b[39m [embeddings\u001b[38;5;241m.\u001b[39membed(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create a FAISS index with these embeddings\u001b[39;00m\n\u001b[1;32m      8\u001b[0m docsearch \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(doc_embeddings)\n",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m OpenAIEmbeddings()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming 'docs' is a list of your document chunks\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Generate embeddings for each document\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m doc_embeddings \u001b[38;5;241m=\u001b[39m [\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed\u001b[49m(doc) \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create a FAISS index with these embeddings\u001b[39;00m\n\u001b[1;32m      8\u001b[0m docsearch \u001b[38;5;241m=\u001b[39m FAISS\u001b[38;5;241m.\u001b[39mfrom_documents(doc_embeddings)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'OpenAIEmbeddings' object has no attribute 'embed'"
     ]
    }
   ],
   "source": [
    "# embeddings = OpenAIEmbeddings()\n",
    "# docsearch = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(question):\n",
    "    prompt = f\"Analyze restaurant data for Hittan Alriyadh. Focus: {question}. Limit the response to key insights.\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_question = \"Identify key features of the restaurants in 2022 based on customer reviews.\"\n",
    "prompt = create_prompt(specific_question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the customer reviews provided for the restaurant in Riyadh, the following key features and insights can be identified for the year 2022:\n",
      "\n",
      "1. **Quality of Coffee and Desserts**: Multiple reviews praise the quality of the coffee and desserts offered at the restaurant. Customers have mentioned \"excellent coffee,\" \"delicious sweets,\" and specific mentions of a \"red cake\" being very tasty.\n",
      "\n",
      "2. **Ambiance and Comfort**: The ambiance of the restaurant is frequently described as nice, beautiful, and comfortable. One reviewer specifically appreciated the attention to small details by the owner, and the seating is described as very comfortable.\n",
      "\n",
      "3. **Customer Service**: There are mixed reviews regarding customer service. While some customers experienced great service and mentioned staff by name, thanking them for their service, others had negative experiences, describing the service as poor or the staff as rude.\n",
      "\n",
      "4. **Variety**: The restaurant seems to offer a wide variety of coffee beans, which is appreciated by customers who are coffee enthusiasts.\n",
      "\n",
      "5. **Pricing**: The cost of items at the restaurant is a point of contention among customers. Some find the prices to be high or overpriced, while others believe the prices are reasonable for the quality provided.\n",
      "\n",
      "6. **Atmosphere**: The general atmosphere of the place is described as pleasant, with a nice vibe, which contributes positively to the customer experience.\n",
      "\n",
      "7. **Recommendations**: Despite some negative feedback, there are strong recommendations from several customers who suggest trying the restaurant, indicating that the positive aspects outweigh the negatives for these individuals.\n",
      "\n",
      "These insights reflect the key features of the restaurant in Riyadh as perceived by customers in 2022, based on the reviews provided.\n"
     ]
    }
   ],
   "source": [
    "response = qa.run(prompt)  # Adjust max_tokens as needed\n",
    "\n",
    "# Print the response\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specific_question = \"Identify key features of the restaurants in 2022 based on customer reviews.\"\n",
    "prompt = create_prompt(specific_question)\n",
    "response = qa.run(prompt)  # Adjust max_tokens as needed\n",
    "print(response)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
