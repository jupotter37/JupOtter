{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.en import STOP_WORDS as sw\n",
    "from string import punctuation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['myself',\n",
       " 'whereby',\n",
       " 'most',\n",
       " 'whatever',\n",
       " 'which',\n",
       " 'cannot',\n",
       " 'done',\n",
       " 'someone',\n",
       " 'hereupon',\n",
       " 'without',\n",
       " 'above',\n",
       " 'but',\n",
       " 'doing',\n",
       " 'at',\n",
       " 'these',\n",
       " 'too',\n",
       " 'already',\n",
       " 'how',\n",
       " '‘m',\n",
       " 'move',\n",
       " 'wherever',\n",
       " 'whose',\n",
       " 'anywhere',\n",
       " 'except',\n",
       " 'six',\n",
       " 'have',\n",
       " 'up',\n",
       " 'so',\n",
       " 'nevertheless',\n",
       " 'thus',\n",
       " 'that',\n",
       " 'him',\n",
       " '‘ve',\n",
       " 'your',\n",
       " 'did',\n",
       " 'onto',\n",
       " 'i',\n",
       " 'every',\n",
       " 'upon',\n",
       " 'a',\n",
       " \"'m\",\n",
       " 'its',\n",
       " '’ll',\n",
       " 'were',\n",
       " 'meanwhile',\n",
       " 'rather',\n",
       " 'has',\n",
       " 'am',\n",
       " 'again',\n",
       " 'sixty',\n",
       " 'with',\n",
       " 'former',\n",
       " 'in',\n",
       " 'off',\n",
       " 'just',\n",
       " 'one',\n",
       " 'however',\n",
       " 'three',\n",
       " 'noone',\n",
       " 'beyond',\n",
       " '’re',\n",
       " '‘re',\n",
       " 'now',\n",
       " 'see',\n",
       " 'several',\n",
       " 'down',\n",
       " 'top',\n",
       " 'anyway',\n",
       " 'eleven',\n",
       " 'show',\n",
       " 'moreover',\n",
       " 'been',\n",
       " '’d',\n",
       " 'mostly',\n",
       " 'anyhow',\n",
       " 'below',\n",
       " 'or',\n",
       " 'forty',\n",
       " 'anything',\n",
       " 'our',\n",
       " 'really',\n",
       " 'n’t',\n",
       " 'from',\n",
       " 'while',\n",
       " 'would',\n",
       " 'back',\n",
       " 'ca',\n",
       " 'was',\n",
       " 'bottom',\n",
       " 'must',\n",
       " 'into',\n",
       " 'many',\n",
       " 'front',\n",
       " 'across',\n",
       " 'behind',\n",
       " 'neither',\n",
       " 'along',\n",
       " 'whom',\n",
       " 'seeming',\n",
       " 'whereafter',\n",
       " 'amount',\n",
       " 'elsewhere',\n",
       " 'does',\n",
       " 'only',\n",
       " 'might',\n",
       " 'latterly',\n",
       " 'the',\n",
       " 'during',\n",
       " 'also',\n",
       " 'enough',\n",
       " 'five',\n",
       " 'both',\n",
       " 'first',\n",
       " 'some',\n",
       " 'thereby',\n",
       " 'whenever',\n",
       " 'between',\n",
       " 'well',\n",
       " 'about',\n",
       " 'under',\n",
       " 'everywhere',\n",
       " 'namely',\n",
       " 'being',\n",
       " 'all',\n",
       " 're',\n",
       " '’s',\n",
       " 'because',\n",
       " 'twenty',\n",
       " 'what',\n",
       " 'my',\n",
       " 'should',\n",
       " \"'s\",\n",
       " 'such',\n",
       " 'via',\n",
       " 'further',\n",
       " 'anyone',\n",
       " 'name',\n",
       " 'each',\n",
       " 'besides',\n",
       " \"'ll\",\n",
       " 'herself',\n",
       " 'since',\n",
       " 'then',\n",
       " 'whither',\n",
       " 'do',\n",
       " 'take',\n",
       " 'another',\n",
       " 'alone',\n",
       " 'who',\n",
       " 'whereas',\n",
       " 'where',\n",
       " 'last',\n",
       " 'nothing',\n",
       " 'others',\n",
       " 'it',\n",
       " 'often',\n",
       " 'few',\n",
       " 'full',\n",
       " 'her',\n",
       " 'sometime',\n",
       " 'here',\n",
       " 'unless',\n",
       " 'afterwards',\n",
       " 'yourself',\n",
       " 'twelve',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'never',\n",
       " 'none',\n",
       " 'call',\n",
       " 'there',\n",
       " 'therefore',\n",
       " 'own',\n",
       " '’m',\n",
       " \"'d\",\n",
       " 'nowhere',\n",
       " 'beforehand',\n",
       " 'whether',\n",
       " 'nor',\n",
       " 'until',\n",
       " 'indeed',\n",
       " 'more',\n",
       " '‘s',\n",
       " 'itself',\n",
       " 'still',\n",
       " 'due',\n",
       " 'ours',\n",
       " 'fifty',\n",
       " 'though',\n",
       " 'otherwise',\n",
       " 'beside',\n",
       " 'whence',\n",
       " 'to',\n",
       " 'may',\n",
       " 'whoever',\n",
       " 'me',\n",
       " 'thereupon',\n",
       " 'eight',\n",
       " 'himself',\n",
       " 'even',\n",
       " 'through',\n",
       " 'latter',\n",
       " 'out',\n",
       " 'least',\n",
       " 'therein',\n",
       " 'hundred',\n",
       " 'hence',\n",
       " 'can',\n",
       " 'please',\n",
       " 'toward',\n",
       " 'those',\n",
       " 'everyone',\n",
       " '‘d',\n",
       " 'before',\n",
       " 'ourselves',\n",
       " 'sometimes',\n",
       " 'than',\n",
       " 'we',\n",
       " 'always',\n",
       " 'any',\n",
       " \"'re\",\n",
       " 'empty',\n",
       " 'make',\n",
       " 'you',\n",
       " 'somewhere',\n",
       " 'hers',\n",
       " 'thereafter',\n",
       " 'yours',\n",
       " 'against',\n",
       " 'hereby',\n",
       " 'somehow',\n",
       " 'as',\n",
       " 'much',\n",
       " 'thence',\n",
       " 'when',\n",
       " 'this',\n",
       " 'not',\n",
       " 'become',\n",
       " 'throughout',\n",
       " 'made',\n",
       " '‘ll',\n",
       " 'either',\n",
       " 'four',\n",
       " 'less',\n",
       " 'of',\n",
       " 'why',\n",
       " 'wherein',\n",
       " 'and',\n",
       " 'something',\n",
       " 'them',\n",
       " 'get',\n",
       " 'say',\n",
       " 'became',\n",
       " 'perhaps',\n",
       " 'be',\n",
       " 'seem',\n",
       " 'give',\n",
       " 'almost',\n",
       " 'per',\n",
       " 'by',\n",
       " 'hereafter',\n",
       " 'regarding',\n",
       " 'he',\n",
       " 'she',\n",
       " 'seems',\n",
       " 'thru',\n",
       " 'same',\n",
       " 'although',\n",
       " 'whole',\n",
       " 'their',\n",
       " 'no',\n",
       " \"n't\",\n",
       " 'together',\n",
       " 'among',\n",
       " \"'ve\",\n",
       " 'ever',\n",
       " 'everything',\n",
       " 'keep',\n",
       " 'side',\n",
       " 'two',\n",
       " 'us',\n",
       " 'had',\n",
       " 'part',\n",
       " 'is',\n",
       " 'mine',\n",
       " 'amongst',\n",
       " 'his',\n",
       " 'if',\n",
       " 'an',\n",
       " 'themselves',\n",
       " 'next',\n",
       " 'yet',\n",
       " 'for',\n",
       " 'towards',\n",
       " 'fifteen',\n",
       " 'ten',\n",
       " 'serious',\n",
       " 'using',\n",
       " 'various',\n",
       " 'yourselves',\n",
       " 'around',\n",
       " 'nobody',\n",
       " 'else',\n",
       " 'herein',\n",
       " 'they',\n",
       " 'used',\n",
       " 'formerly',\n",
       " 'on',\n",
       " 'other',\n",
       " '’ve',\n",
       " 'quite',\n",
       " 'over',\n",
       " 'are',\n",
       " 'third',\n",
       " 'will',\n",
       " 'n‘t',\n",
       " 'seemed',\n",
       " 'whereupon',\n",
       " 'put',\n",
       " 'could',\n",
       " 'very',\n",
       " 'after',\n",
       " 'within',\n",
       " 'once',\n",
       " 'nine',\n",
       " 'go']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stopwords consists of all the words\n",
    "stopwords = list(sw) #converting into list for easier use\n",
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" In computer science, a sorting algorithm is an algorithm that puts elements of a list into an order. The most frequently used orders are numerical order and lexicographical order, and either ascending or descending. Efficient sorting is important for optimizing the efficiency of other algorithms (such as search and merge algorithms) that require input data to be in sorted lists. Sorting is also often useful for canonicalizing data and for producing human-readable output.\n",
    "Formally, the output of any sorting algorithm must satisfy two conditions:\n",
    "The output is in monotonic order (each element is no smaller/larger than the previous element, according to the required order).\n",
    "The output is a permutation (a reordering, yet retaining all of the original elements) of the input.\n",
    "For optimum efficiency, the input data should be stored in a data structure which allows random access rather than one that allows only sequential access.\n",
    "History and concepts\n",
    "From the beginning of computing, the sorting problem has attracted a great deal of research, perhaps due to the complexity of solving it efficiently despite its simple, familiar statement. Among the authors of early sorting algorithms around 1951 was Betty Holberton, who worked on ENIAC and UNIVAC.[1][2] Bubble sort was analyzed as early as 1956.[3] Asymptotically optimal algorithms have been known since the mid-20th century – new algorithms are still being invented, with the widely used Timsort dating to 2002, and the library sort being first published in 2006.\n",
    "Comparison sorting algorithms have a fundamental requirement of Ω(n log n) comparisons (some input sequences will require a multiple of n log n comparisons, where n is the number of elements in the array to be sorted). Algorithms not based on comparisons, such as counting sort, can have better performance.\n",
    "Sorting algorithms are prevalent in introductory computer science classes, where the abundance of algorithms for the problem provides a gentle introduction to a variety of core algorithm concepts, such as big O notation, divide-and-conquer algorithms, data structures such as heaps and binary trees, randomized algorithms, best, worst and average case analysis, time–space tradeoffs, and upper and lower bounds.\n",
    "Sorting small arrays optimally (in fewest comparisons and swaps) or fast (i.e. taking into account machine specific details) is still an open research problem, with solutions only known for very small arrays (<20 elements). Similarly optimal (by various definitions) sorting on a parallel machine is an open research topic.\n",
    "Classification\n",
    "Sorting algorithms can be classified by:\n",
    "Computational complexity\n",
    "Best, worst and average case behavior in terms of the size of the list. For typical serial sorting algorithms, good behavior is O(n log n), with parallel sort in O(log2 n), and bad behavior is O(n2). Ideal behavior for a serial sort is O(n), but this is not possible in the average case. Optimal parallel sorting is O(log n).\n",
    "Swaps for \"in-place\" algorithms.\n",
    "Memory usage (and use of other computer resources). In particular, some sorting algorithms are \"in-place\". Strictly, an in-place sort needs only O(1) memory beyond the items being sorted; sometimes O(log n) additional memory is considered \"in-place\".\n",
    "Recursion: Some algorithms are either recursive or non-recursive, while others may be both (e.g., merge sort).\n",
    "Stability: stable sorting algorithms maintain the relative order of records with equal keys (i.e., values).\n",
    "Whether or not they are a comparison sort. A comparison sort examines the data only by comparing two elements with a comparison operator.\n",
    "General method: insertion, exchange, selection, merging, etc. Exchange sorts include bubble sort and quicksort. Selection sorts include cycle sort and heapsort.\n",
    "Whether the algorithm is serial or parallel. The remainder of this discussion almost exclusively concentrates upon serial algorithms and assumes serial operation.\n",
    "Adaptability: Whether or not the presortedness of the input affects the running time. Algorithms that take this into account are known to be adaptive.\n",
    "Online: An algorithm such as Insertion Sort that is online can sort a constant stream of input.\n",
    "Stability\n",
    "An example of stable sort on playing cards. When the cards are sorted by rank with a stable sort, the two 5s must remain in the same order in the sorted output that they were originally in. When they are sorted with a non-stable sort, the 5s may end up in the opposite order in the sorted output.\n",
    "Stable sort algorithms sort equal elements in the same order that they appear in the input. For example, in the card sorting example to the right, the cards are being sorted by their rank, and their suit is being ignored. This allows the possibility of multiple different correctly sorted versions of the original list. Stable sorting algorithms choose one of these, according to the following rule: if two items compare as equal (like the two 5 cards), then their relative order will be preserved, i.e. if one comes before the other in the input, it will come before the other in the output.\n",
    "Stability is important to preserve order over multiple sorts on the same data set. For example, say that student records consisting of name and class section are sorted dynamically, first by name, then by class section. If a stable sorting algorithm is used in both cases, the sort-by-class-section operation will not change the name order; with an unstable sort, it could be that sorting by section shuffles the name order, resulting in a nonalphabetical list of students.\n",
    "More formally, the data being sorted can be represented as a record or tuple of values, and the part of the data that is used for sorting is called the key. In the card example, cards are represented as a record (rank, suit), and the key is the rank. A sorting algorithm is stable if whenever there are two records R and S with the same key, and R appears before S in the original list, then R will always appear before S in the sorted list.\n",
    "When equal elements are indistinguishable, such as with integers, or more generally, any data where the entire element is the key, stability is not an issue. Stability is also not an issue if all keys are different.\n",
    "Unstable sorting algorithms can be specially implemented to be stable. One way of doing this is to artificially extend the key comparison, so that comparisons between two objects with otherwise equal keys are decided using the order of the entries in the original input list as a tie-breaker. Remembering this order, however, may require additional time and space.\n",
    "One application for stable sorting algorithms is sorting a list using a primary and secondary key. For example, suppose we wish to sort a hand of cards such that the suits are in the order clubs (♣), diamonds (♦), hearts (♥), spades (♠), and within each suit, the cards are sorted by rank. This can be done by first sorting the cards by rank (using any sort), and then doing a stable sort by suit:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39men_core_web_sm\u001b[39;49m\u001b[39m'\u001b[39;49m)  \u001b[39m#nlp - object of spacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m doc \u001b[39m=\u001b[39m nlp(text)\n",
      "File \u001b[1;32mc:\\Users\\Ansari\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     38\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[0;32m     39\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m     55\u001b[0m         name,\n\u001b[0;32m     56\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m     57\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m     58\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m     59\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m     60\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m     61\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Ansari\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\spacy\\util.py:449\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "\n",
    "nlp = spacy.load('en_core_web_sm')  #nlp - object of spacy\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokens \u001b[39m=\u001b[39m [token\u001b[39m.\u001b[39mtext \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc] \u001b[39m#creating tokens from doc\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(tokens)\n\u001b[0;32m      3\u001b[0m \u001b[39m#but this contains stop words and punctuations\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "tokens = [token.text for token in doc] #creating tokens from doc\n",
    "print(tokens)\n",
    "#but this contains stop words and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation\n",
    "punctuation = punctuation + '\\n' #inbuillt punctuation string, but it doesnt contain nextLine, so we add it\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#here we we find word frequnecy of the words in doc, if they are not stopWords and not punctuations, and keep adding them to a dictionary\u001b[39;00m\n\u001b[0;32m      2\u001b[0m word_freq \u001b[39m=\u001b[39m {}\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m doc:\n\u001b[0;32m      4\u001b[0m     \u001b[39mif\u001b[39;00m word\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mlower() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stopwords:\n\u001b[0;32m      5\u001b[0m          \u001b[39mif\u001b[39;00m word\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mlower() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m punctuation:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "#here we we find word frequnecy of the words in doc, if they are not stopWords and not punctuations, and keep adding them to a dictionary\n",
    "word_freq = {}\n",
    "for word in doc:\n",
    "    if word.text.lower() not in stopwords:\n",
    "         if word.text.lower() not in punctuation:\n",
    "            if word.text not in word_freq.keys():\n",
    "                word_freq[word.text] = 1\n",
    "            else :\n",
    "                word_freq[word.text] +=1\n",
    "\n",
    "word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m max_freq \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39;49m(word_freq\u001b[39m.\u001b[39;49mvalues()) \u001b[39m#finding the maximum frequency\u001b[39;00m\n\u001b[0;32m      2\u001b[0m max_freq\n",
      "\u001b[1;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "max_freq = max(word_freq.values()) #finding the maximum frequency\n",
    "max_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalization where max_freq = 1\n",
    "n_word_freq = word_freq\n",
    "for word in n_word_freq.keys():\n",
    "    n_word_freq[word] = n_word_freq[word] / max_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalised frequencies\n",
    "n_word_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sentence_tokens \u001b[39m=\u001b[39m [sent \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m doc\u001b[39m.\u001b[39msents] \u001b[39m#create sentences using sents (sentencizer)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(sentence_tokens)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc' is not defined"
     ]
    }
   ],
   "source": [
    "sentence_tokens = [sent for sent in doc.sents] #create sentences using sents (sentencizer)\n",
    "print(sentence_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sentence_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m sentence_score \u001b[39m=\u001b[39m {}\n\u001b[0;32m      2\u001b[0m \u001b[39m#calculate score for each sentence by adding the normalised frequecny of words in each sentence\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentence_tokens:\n\u001b[0;32m      4\u001b[0m     \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m sent:\n\u001b[0;32m      5\u001b[0m         \u001b[39mif\u001b[39;00m word\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mlower() \u001b[39min\u001b[39;00m n_word_freq\u001b[39m.\u001b[39mkeys():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sentence_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "sentence_score = {}\n",
    "#calculate score for each sentence by adding the normalised frequecny of words in each sentence\n",
    "for sent in sentence_tokens:\n",
    "    for word in sent:\n",
    "        if word.text.lower() in n_word_freq.keys():\n",
    "            if sent not in sentence_score.keys():\n",
    "                sentence_score[sent] = n_word_freq[word.text.lower()]\n",
    "            else:\n",
    "                sentence_score[sent] += n_word_freq[word.text.lower()]\n",
    "\n",
    "sentence_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from heapq import nlargest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking 30% of the entire text as summary\n",
    "select_length = int(len(sentence_tokens)*0.3)\n",
    "select_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sentences\n",
    "summary = nlargest(select_length, sentence_score, key = sentence_score.get)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#senetcnes are in list format, we join them using spaces\n",
    "final_summary = [word.text for word in summary]\n",
    "temp_summary = ' '.join(final_summary)\n",
    "\n",
    "print(temp_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6985"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3025"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temp_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
