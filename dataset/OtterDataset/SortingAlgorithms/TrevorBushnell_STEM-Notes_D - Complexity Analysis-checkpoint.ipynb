{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e135d04-d62a-474f-8230-31ec187c50b8",
   "metadata": {},
   "source": [
    "# D: Complexity Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedb8032-ddae-452f-986e-b46dbb8fb48b",
   "metadata": {},
   "source": [
    "## About Complexity Analysis\n",
    "\n",
    "* When doing complexity analysis, we care about this input size $n$\n",
    "    * We analyze algorithms in terms of the size of their input (e.g. Sequence has $n$ elements)\n",
    "    * Reason for this is because most algorithms take longer to run as $n \\to \\infty$\n",
    "    \n",
    "* \"Worst/Best case analysis:\" Certain input patterns for any $n$ that take the most/least amount of time\n",
    "    * Usually Big-O notation talks about the worst case (but not always)\n",
    "    \n",
    "* \"Average case analysis:\" The average amount of time over all cases for all $n$\n",
    "    * Usually you have to figure out the distribution of cases to better understand your average case analysis\n",
    "    * We won't generally do this in this class\n",
    "    \n",
    "* \"Count primitive operations:\" instead of timing something, we look at the underlying assembly operations that make the algorithm happen and assume how long these assembly operations take\n",
    "    * What are the primitive operations?\n",
    "    * How many times do these operations happen?\n",
    "    * Gives a Normalized distribution which helps with analysis\n",
    "    * Count up the primitives $\\to$ create a formula $\\to$ mathematically analyze this formula"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd4ac79-71ba-4393-97a5-2fc032c30847",
   "metadata": {},
   "source": [
    "## Detailed Analysis\n",
    "\n",
    "> GOAL: Define a function $T(n)$ (typically piecewise) giving the number of steps/operations as a function on $n$\n",
    "\n",
    "Detailed analysis is the complete backbone of Big-O notation and algorithm analysis, so we will use this method for the rest of the class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cb6049-3771-4cba-b00a-c7de2fce2e56",
   "metadata": {},
   "source": [
    "## Example #1\n",
    "\n",
    "\n",
    "Here's an example of an algorithm that we can analyze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7fef8c4-fefa-49a5-8bc6-d9c09af2383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Function to see if the value target is in the array A\n",
    "bool member(const int A[], int size, int target)\n",
    "{\n",
    "    bool found = false; // flag variable\n",
    "    \n",
    "    for (int i = 0; i < size and !found; ++i)\n",
    "    {\n",
    "        if (A[i] == target)\n",
    "        {\n",
    "            found = true;\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return found;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c31869-b2a5-45da-93f6-d48cff3bdc8f",
   "metadata": {},
   "source": [
    "For this algorithm, assume primitive operations:\n",
    "* assign/initialize = 1 operation\n",
    "* comparison = 1 operation\n",
    "* increment = 1 operation\n",
    "* array acces = 1 operation\n",
    "\n",
    "\n",
    "> Q: Is there a \"best\" and a \"worst\" case?\n",
    "\n",
    "* BEST CASE: `A[0] == target` so $T(n) \\ge c$ where $c$ is some constant\n",
    "    * $T(n) \\ge 10$\n",
    "* WORST CASE: `target` is not in `A`\n",
    "    * $T(n) \\le 5n+4$\n",
    "        * `found = true` +1\n",
    "        * `i = 0` +1\n",
    "        * REPEAT $n$ times\n",
    "            * `i < n` +1\n",
    "            * `!found` +1\n",
    "            * `A[i]==target` +2\n",
    "            * `++i` +1\n",
    "        * `found = true` +1\n",
    "        * `i < n` +1\n",
    "    * Since this algorithm's worst case is in the form oof linear $y=mx+b$, then `member` is a **linear time worst case algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ecf89-8afb-4b2f-87e3-bce35fe545d4",
   "metadata": {},
   "source": [
    "## Example #2\n",
    "\n",
    "Here is another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "461af4ce-8408-482f-a6c4-0a4f8da27e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool common(int A[], int B[], int n)\n",
    "{\n",
    "    for (int i = 0; i < n; ++i)\n",
    "    {\n",
    "        for (int j = 0; j < n; ++j)\n",
    "        {\n",
    "            if (A[i] == B[j])\n",
    "            {\n",
    "                return true;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c29c64-40d5-436f-88dc-5772ddc3ab64",
   "metadata": {},
   "source": [
    "> Q: Is there a best and worst case?\n",
    "\n",
    "* BEST CASE: When the first element of each array is the same (has something in common)\n",
    "    * $T(n) \\ge 7$\n",
    "* WORST CASE: When the neither array shares a common value\n",
    "    * $T(n) \\le 5n^2 + 4n + 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f302e26-c1bd-471c-b3a3-4eabb7af3211",
   "metadata": {},
   "source": [
    "## Example #3\n",
    "\n",
    "Here is yet another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd897fd9-fcea-4e0f-84c8-7e38c4dff904",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool duplicates(const int A[], int n)\n",
    "{\n",
    "    for (int i = 0; i < n; ++i) // loops n times\n",
    "    {\n",
    "        for (int j = i + 1; j < n; ++j)\n",
    "        {\n",
    "            if (A[i] == A[j])\n",
    "            {\n",
    "                return true;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2ce0a1-7e77-4ae0-b390-1e94f9cf4e3a",
   "metadata": {},
   "source": [
    "> Q: Only counting *array comparisons* what is the WORST CASE $T(n)$?\n",
    "* This is a bit harder because the number of inner loops you do decreases as `i` increases\n",
    "* $\\sum_{i=0}^{n-1} n-(i+1) = \\sum_{i=0}^{n-1} i = \\frac{(n-1)(n)}{2} = \\frac{n^2-n}{2} = \\frac{1}{2}n^2 - \\frac{1}{2}n$\n",
    "\n",
    "So now we have two ways to do detailed analysis:\n",
    "\n",
    "1. Count up the number of operations\n",
    "2. Find some sort of mathematical relationship and compute $T(n)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e816fd-a114-44da-9b06-2125daf92d44",
   "metadata": {},
   "source": [
    "## Asymptotic Notation\n",
    "\n",
    "* Two algorithms with the same \"growth rate\" treated as having the same \"complexity\"\n",
    "* supress constant factors and lower order terms\n",
    "    * constant factors = too system dependent\n",
    "    * lower order terms don't matter for large inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded3278-42da-4460-88f8-4b694da311be",
   "metadata": {},
   "source": [
    "# Three Main Notions/Tools for Comparing Growth Rates\n",
    "\n",
    "1. \"Big-O Notation\" (O-notation) $\\implies$ \"not slower than\" $\\implies$ upper bound\n",
    "2. \"Big-$\\Omega$ Notation\" ($\\Omega$-notation) $\\implies$ \"not faster than\" $\\implies$ lower bound\n",
    "3. \"Big-$\\Theta$ Notation\" ($\\Theta$-notation) $\\implies$ \"exactly\" $\\implies$ tight bound\n",
    "\n",
    "> **BIG-O NOTATION:** $T(n)$ is $O(f(n))$ if and only if there exists some positive constants $k$ and $n_0$ such that:\n",
    "> $$T(n) \\le k \\cdot f(n)\\:\\:\\:\\:\\:n \\ge n_0$$\n",
    "\n",
    "Showing that a $T(n)$ is $O(f(n))$ simply involves finding a $k$ and a $n_0$. \n",
    "\n",
    "> **Exercise:** Let $T(n) \\le 3n+2$ and $f(n)=n$. What is a $k$ and $n_0$ to show that $T(n)$ is $O(n)$?\n",
    ">\n",
    "> If $k=4$ and $n_0=2$, then $T(n) \\le k \\cdot f(n) \\implies 3n + 2 \\le 4 \\cdot n$. This relationship is true when $n_0=2$ because $T(2) = f(2) = 8$.\n",
    "\n",
    "> **BIG-$\\Omega$ NOTATION:** $T(n)$ is $\\Omega(f(n))$ if and only if there exists some positive constants $k$ and $n_0$ such that:\n",
    "> $$T(n) \\ge k \\cdot f(n)\\:\\:\\:\\:\\:n \\ge n_0$$\n",
    "\n",
    "Showing that a $T(n)$ is $\\Omega(f(n))$ simply involves finding a $k$ and a $n_0$. \n",
    "\n",
    "> **Exercise:** Let $T(n) \\ge 4n+3$ and $f(n)=n$. Show that $T(n)$ is $\\Omega(f(n))$.\n",
    ">\n",
    "> If $k=1$ and $n_0=1$, then $T(n)$ is $\\Omega(f(n))$\n",
    "\n",
    "> **BIG-$\\Theta$ NOTATION:** $T(n)$ is $\\Theta(f(n))$ if and only if there exists some positive constants $k_1$, $k_2$ and $n_0$ such that:\n",
    "> $$k_1 \\cdot f(n) \\le T(n) \\le k \\cdot f(n)\\:\\:\\:\\:\\:n \\ge n_0$$\n",
    "\n",
    "> **Exercise:** Let $4n+3 \\le T(n) \\le 5n+3$ and $f(n)=n$. Show that $T(n)$ is $\\Theta(f(n))$.\n",
    ">\n",
    "> If $k_1 = 4$, $k_2 = 8$, $n_0 = 1$, then $T(n) = \\Theta(f(n))$.\n",
    "\n",
    "**THE BEST WAY TO SOLVE THESE PROBLEMS (not the only way!)** is to fix $n_0$ at 1 and then solve for your corresponding constants. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24753266-ca55-4d79-9fe7-28656d626ad7",
   "metadata": {},
   "source": [
    "## The Different Types of Big-O's\n",
    "\n",
    "There are different types of Big-O functions that are common in the algorithm space:\n",
    "\n",
    "* $O(1)$: constant time - \"free\"\n",
    "* $O(\\log(n))$: logarithmic time - \"for free\"\n",
    "* $O(n)$: linear time - \"for free\"\n",
    "* $O(n \\log(n))$: linear-logarithmic time - \"for free\"\n",
    "* $O(n^2)$: quadratic time\n",
    "* $O(n^3)$: cubic time\n",
    "* $O(2^n)$: exponential time\n",
    "* $O(n!)$: factorial time\n",
    "* $O(n^n)$: really bad exponential time lol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d2e7ef-754b-437a-ad24-772b56b0497d",
   "metadata": {},
   "source": [
    "## Properties of Big-O\n",
    "\n",
    "* **SUM OF TWO FUNCTIONS:** $O(f(n))$ + $O(g(n)) = O(\\max[f(n),g(n)])$\n",
    "* **PRODUCT OF TWO FUNCTIONS:** $O(f(n)) \\cdot O(g(n)) = O(f(g) \\cdot g(f))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1984d8f-4d16-4421-bce9-2eddf091bc96",
   "metadata": {},
   "source": [
    "## Gotchas in Big-O Notation\n",
    "\n",
    "1. Algorithm VS Problem\n",
    "    * comparison sorting has a theoretical limit of $O(n \\log(n))$\n",
    "2. Tight Upper & Tight Lower Bound\n",
    "    * an algorithm that is $O(n)$ is also $O(n^2)$\n",
    "    * an algorithm that is $\\Omega(n)$ is also $\\Omega(n^2)$\n",
    "    * An algorithm that is $O(1)$ is also $\\Theta(1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c30783-38a3-4e94-a8d1-78b08cc202ff",
   "metadata": {},
   "source": [
    "## Sorting Algorithm Analysis\n",
    "\n",
    "### Selection Sort\n",
    "\n",
    "* Selection sort has $\\Theta(n)$ for the *number of moves*\n",
    "\n",
    "\n",
    "### Merge Sort - Hand-Wavy\n",
    "\n",
    "* Let's informally argue what the cost is\n",
    "\n",
    "> Q: What is the cost of the merge step?\n",
    "\n",
    "* For moves AND comparisons individually, it is $\\Theta(n) + \\Theta(n) = \\Theta(n)$\n",
    "* The first step in the merge sort algorithm is $\\Theta(1)$ (free)\n",
    "* The recursive steps start to get a bit trickier...\n",
    "    * The number of times that we have to halve the lists is on the order of $\\Theta(\\log n)$\n",
    "* This means that the total cost of this entire algorithm is $\\Theta(n) \\cdot \\Theta (\\log n) = \\Theta(n \\log n)$\n",
    "\n",
    "\n",
    "### Merge Sort - Recurrence Relations\n",
    "\n",
    "* Since merge-sort calls itself, we can write a relationship defining merge sort:\n",
    "\n",
    "$$\n",
    "T(n) = \\begin{cases}\n",
    "c_1 & n=0 \\text{ or } n=1\\\\ \n",
    "c_1 + c_2 + T(\\frac{n}{2})+ T(\\frac{n}{2}) + c_3n & n>1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "This can be simplified as follows:\n",
    "\n",
    "$$\n",
    "T(n) = \\begin{cases}\n",
    "\\Theta(1) & n=0 \\text{ or } n=1\\\\\n",
    "2 T(\\frac{n}{2}) + \\Theta(n) & n>1\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "* A \"standard recurrence\" has the following form:\n",
    "    * $T(n) = O(1)$ for small values of $n$\n",
    "    * $T(n) \\le a \\cdot T(\\frac{n}{b}) + O(n^d)$\n",
    "    \n",
    "* We can solve recurrence relations using the master method but THIS RELIES ON THERE BEING A STANDARD RECURRENCE RELATION TO WORK\n",
    "* If it is, then we get the following definition for $T(n)$:\n",
    "$$\n",
    "T(n) = \\begin{cases}\n",
    "O(n^d \\log n) & a = b^d\\\\\n",
    "O(n^d) & a < b^d\\\\\n",
    "O(n^{\\log_b a}) & a > b^d\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "* This means that for merge sort, we get the following for $T(n)$:\n",
    "\n",
    "$$\n",
    "T(n) \\le O(n^1 \\log n) = O(n \\log n)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4861c60-0b7e-4e37-a215-5f957bcef8cf",
   "metadata": {},
   "source": [
    "## Amortized Analysis\n",
    "\n",
    "Inserting into the end of our `ArraySeq` costs $\\Theta(1)$ unless we resize, in which case it costs $\\Theta(n)$. However, we can use just say that the cost of inserting at the end is just $\\Theta(1)$ despite the occasional resize. We can prove this using **amortized analysis**.\n",
    "\n",
    "> **Amortized Analysis:** Every once in awhile we have a big cost, so we will spread that cost out across all the calls\n",
    "\n",
    "This means that instead of looking at one insert-end, we average the cost of a sequence of calls. This would be the amortized cost. This means that for $m$ insert-end calls, $a$ the amortized cost, and $t_i$ the actual cost, we have:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^m a \\ge \\sum_{i=1}^m t_i\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C++14",
   "language": "C++14",
   "name": "xcpp14"
  },
  "language_info": {
   "codemirror_mode": "text/x-c++src",
   "file_extension": ".cpp",
   "mimetype": "text/x-c++src",
   "name": "c++",
   "version": "14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
