{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avinashyadav16/Custom-NER-Model/blob/main/CustomNER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbgguMXuNXIy"
      },
      "source": [
        "# Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C2OIvq5MapN",
        "outputId": "a8519510-44e2-4435-ee06-490b3c759d0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL5Mm-y5Pa0i"
      },
      "source": [
        "# Python Script for PDF Text Extraction and Consolidation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2vKKJDTT1fY"
      },
      "source": [
        "The TXT file is required for use with the Annotator web application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKx774KmPnlj",
        "outputId": "fbc80d68-ff19-44eb-9ada-08cbf2657cfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "# Installing the required dependencies using pip.\n",
        "\n",
        "%pip install PyPDF2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUPRWHxCT5XK"
      },
      "source": [
        "This Python script extracts text from multiple PDF files in a specified folder, combines the extracted text into a single string, and saves it to a .txt file. **The TXT file is required for use with the Annotator web application.**\n",
        "\n",
        "It uses the PyPDF2 library for PDF text extraction and is a useful utility for text-based tasks, especially relevant for AI and ML applications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "F6GFenN2Pr7L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PyPDF2\n",
        "\n",
        "source_folder = '/content/drive/MyDrive/Custom_NER_Model/resume_dataset'\n",
        "combined_txt_path = '/content/drive/MyDrive/Custom_NER_Model/resume_dataset/combined_resumes.txt'\n",
        "\n",
        "# Create a list to store text from all PDF files\n",
        "all_pdf_text = []\n",
        "\n",
        "# Loop through PDF files in the source folder\n",
        "for filename in os.listdir(source_folder):\n",
        "    if filename.endswith('.pdf'):\n",
        "        pdf_path = os.path.join(source_folder, filename)\n",
        "\n",
        "        # Extract text from PDF\n",
        "        with open(pdf_path, 'rb') as pdf_file:\n",
        "            pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "            pdf_text = ' '.join(page.extract_text() for page in pdf_reader.pages)\n",
        "            all_pdf_text.append(pdf_text)\n",
        "\n",
        "# Combine all PDF text into a single string\n",
        "combined_text = '\\n\\n'.join(all_pdf_text)  # Adding double newline separator\n",
        "\n",
        "# Save combined text to a single TXT file\n",
        "with open(combined_txt_path, 'w', encoding='utf-8') as combined_txt_file:\n",
        "    combined_txt_file.write(combined_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N2LbPLl7Rxwi"
      },
      "source": [
        "# Let’s start with the code. We’ll break it down into sections and explain each part."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7jBYVFsR9tH"
      },
      "source": [
        "## *1. Setting Up the Environment*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mV39eR0rTur2"
      },
      "source": [
        "In this section, we prepare the environment by mounting Google Drive, importing necessary libraries (like spaCy), and checking the GPU status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk-NbC_3SG9C",
        "outputId": "30789ba8-209f-4f10-9f86-917d5ff66e77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (6.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
            "Requirement already satisfied: spacy_transformers in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: spacy<4.1.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from spacy_transformers) (3.7.5)\n",
            "Requirement already satisfied: transformers<4.37.0,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy_transformers) (4.36.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from spacy_transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy_transformers) (2.4.8)\n",
            "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from spacy_transformers) (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy_transformers) (1.25.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (1.1.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (0.3.4)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (0.9.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (2.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy_transformers) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy_transformers) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->spacy_transformers) (12.5.40)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy_transformers) (0.23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy_transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy_transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy_transformers) (0.4.3)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy_transformers) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy_transformers) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.1.0,>=3.5.0->spacy_transformers) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.1.0,>=3.5.0->spacy_transformers) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (0.16.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (6.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4.1.0,>=3.5.0->spacy_transformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->spacy_transformers) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy_transformers) (1.1.1)\n"
          ]
        }
      ],
      "source": [
        "# install any necessary packages\n",
        "%pip install -U spacy\n",
        "%pip install spacy_transformers\n",
        "\n",
        "# Install below packages if error occurs while installing above packages\n",
        "#!pip install -U pip setuptools\n",
        "# !pip install typing-extensions==4.6.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvaUOBjGShNZ",
        "outputId": "46b78211-7586-4d9c-8ad9-85c586766fa4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/Custom_NER_Model\n",
            "Wed Jun 12 07:42:49 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Import the necessary libraries and mount Google Drive to access project files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Change the working directory to the project folder\n",
        "%cd \"/content/drive/MyDrive/Custom_NER_Model\"\n",
        "\n",
        "# Import required libraries and install any necessary packages\n",
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "\n",
        "# Check the installed version of spaCy\n",
        "spacy.__version__\n",
        "\n",
        "# Check GPU information\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fESHcCZRTSTQ"
      },
      "source": [
        "## *2. Loading Annotated Data*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ura4N-wTdbH"
      },
      "source": [
        "We load the annotated data from a JSON file, displaying the number of items in the dataset and showing the structure of the first item in the dataset for visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47MAsO07Tfbp",
        "outputId": "c9cd3bd6-6e06-44e5-aa81-9705f6fe6d61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['HARSHA REDDY PUNURU Computer Science Graduate My Contact punuruharsha999@gmail.com 8367746619 Gudivada, Andhra Pradesh https://www.linkedin.com/in/harsha reddy-30b4a224b/ About Me A diligent and enthusiastic computer science undergraduate with a passion for technology and a drive to excel in the field and looking to develop new skills and grow knowledge. Enthusiastic at using educational knowledge and eager to apply knowledge to achieve goals. Dedicated to working hard to make positive contributions. Internships Company: APSSDC Period: Jun-2023 to Aug-2023 Domain: Web Development Using Django Tools: Jupyter Notebook Company: Code Clause Period: Aug-2023 To Sep-2023 Domain: Artificial Intelligence Tools: Google Colab Hard Skill C Python Data Structures Soft Skill Adaptability Team Work Multi Tasking Education Background SRM University AP Branch: Computer Science(CSE) CGPA:8.13/10 Period:2021-ongoing Sri Chaitanya Junior College Subjects: Maths, Physics, Chemistry Marks:957/1000 Period-2019-2021 Gowtham English Medium School Board: SSC Grade:9.8/10 Period-2018-2019 Projects ATM Transaction using C Language: An ATM (Automated Teller Machine) In C is based on a concept of managing an account personally. From this ATM System Project, the user can check total balance, Deposit Amount and Withdraw Amounts easily. This application is helpful to users for checking their balance amount and for managing the account details. Digital Clock: In this Project we will see how to create a digital clock displaying hour, minute and seconds live. This is a simple task to get started with the turtle library in Python, which is a built-in package that comes with Python. Turtle has some cool features that can be used to build simple apps',\n",
              " {'entities': [[0, 19, 'NAME'],\n",
              "   [20, 45, 'JOB_TITLE'],\n",
              "   [57, 82, 'EMAIL_ID'],\n",
              "   [83, 93, 'PHONE_NO'],\n",
              "   [94, 118, 'ADDRESS'],\n",
              "   [119, 170, 'LINKEDIN_ACCOUNT'],\n",
              "   [180, 355, 'SUMMARY'],\n",
              "   [357, 504, 'SUMMARY'],\n",
              "   [527, 533, 'COMPANY'],\n",
              "   [542, 550, 'START_DATE_OF_JOB'],\n",
              "   [554, 562, 'END_DATE_OF_JOB'],\n",
              "   [571, 599, 'JOB_TITLE'],\n",
              "   [607, 623, 'TECHNOLOGIES_USED_IN_PROJECT'],\n",
              "   [633, 644, 'COMPANY'],\n",
              "   [653, 661, 'START_DATE_OF_JOB'],\n",
              "   [665, 673, 'END_DATE_OF_JOB'],\n",
              "   [682, 705, 'JOB_TITLE'],\n",
              "   [713, 725, 'TECHNOLOGIES_USED_IN_PROJECT'],\n",
              "   [737, 738, 'TECHNICAL_SKILLS'],\n",
              "   [739, 745, 'TECHNICAL_SKILLS'],\n",
              "   [746, 761, 'SKILLS'],\n",
              "   [773, 785, 'SOFT_SKILLS'],\n",
              "   [786, 795, 'SOFT_SKILLS'],\n",
              "   [796, 809, 'SOFT_SKILLS'],\n",
              "   [831, 849, 'INSTITUTE/UNIVERSITY'],\n",
              "   [857, 878, 'DEGREE'],\n",
              "   [884, 888, 'GPA'],\n",
              "   [899, 903, 'START_DATE_OF_UNIVERSITY'],\n",
              "   [912, 940, 'INSTITUTE/UNIVERSITY'],\n",
              "   [983, 991, 'PERCENTAGE'],\n",
              "   [999, 1003, 'START_DATE_OF_UNIVERSITY'],\n",
              "   [1004, 1008, 'END_DATE_OF_UNIVERSITY'],\n",
              "   [1009, 1038, 'INSTITUTE/UNIVERSITY'],\n",
              "   [1056, 1059, 'GPA'],\n",
              "   [1070, 1074, 'START_DATE_OF_UNIVERSITY'],\n",
              "   [1075, 1079, 'END_DATE_OF_UNIVERSITY'],\n",
              "   [1089, 1104, 'PROJECT_NAME'],\n",
              "   [1111, 1112, 'TECHNOLOGIES_USED_IN_PROJECT'],\n",
              "   [1123, 1217, 'DESCRIPTION_OF_PROJECT'],\n",
              "   [1219, 1325, 'DESCRIPTION_OF_PROJECT'],\n",
              "   [1328, 1435, 'DESCRIPTION_OF_PROJECT'],\n",
              "   [1436, 1449, 'PROJECT_NAME'],\n",
              "   [1451, 1549, 'DESCRIPTION_OF_PROJECT'],\n",
              "   [1551, 1673, 'DESCRIPTION_OF_PROJECT'],\n",
              "   [1675, 1681, 'TECHNOLOGIES_USED_IN_PROJECT']]}]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the annotated data from a JSON file\n",
        "cv_data = json.load(open('/content/drive/MyDrive/Custom_NER_Model/annotations_dataset/annotations.json','r'))\n",
        "\n",
        "# Display the number of items in the dataset\n",
        "len(cv_data)\n",
        "\n",
        "# Display the first item in the dataset\n",
        "cv_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn_38J6gUGj2"
      },
      "source": [
        "## *3. Configuring SpaCy*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zp6Z1SnjUSA7"
      },
      "source": [
        "This step involves configuring SpaCy for your custom NER model involves initializing configuration files, and you can use a base configuration file as a template. To download the `base_config.cfg` file from the documentation, you can visit the official spaCy documentation website:\n",
        "\n",
        "[spaCy base_config.cfg](https://spacy.io/usage/training#config)\n",
        "\n",
        "Download the file by clicking on the bottom-right download button present the command shell itself.\n",
        "\n",
        "**Select: Language** - *English*\n",
        "        **Components** - *ner*\n",
        "        **Hardware** - *GPU (transformer)*\n",
        "        **Optimize for** - *accuracy*\n",
        "\n",
        "This file serves as a starting point for creating your custom configuration tailored to your specific NER model training. We use the `base_config.cfg` as a template to create our custom `config.cfg`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shywZEaeWW0L",
        "outputId": "ffcc4c02-df90-419f-cf4a-91051090ffd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting spacy-transformers\n",
            "  Downloading spacy_transformers-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (197 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.8/197.8 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<4.1.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (3.7.4)\n",
            "Collecting transformers<4.37.0,>=3.4.0 (from spacy-transformers)\n",
            "  Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (2.3.0+cu121)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (2.4.8)\n",
            "Collecting spacy-alignments<1.0.0,>=0.7.2 (from spacy-transformers)\n",
            "  Downloading spacy_alignments-0.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.0/314.0 kB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy-transformers) (1.25.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (1.1.3)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (2.7.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.1.0,>=3.5.0->spacy-transformers) (3.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->spacy-transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->spacy-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers) (0.23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers) (2024.5.15)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers<4.37.0,>=3.4.0->spacy-transformers)\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m98.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers) (0.4.3)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (2024.6.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.1.5)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4.1.0,>=3.5.0->spacy-transformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->spacy-transformers) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.1.0,>=3.5.0->spacy-transformers) (1.1.1)\n",
            "Installing collected packages: spacy-alignments, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers, spacy-transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.41.2\n",
            "    Uninstalling transformers-4.41.2:\n",
            "      Successfully uninstalled transformers-4.41.2\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 spacy-alignments-0.9.1 spacy-transformers-1.3.5 tokenizers-0.15.2 transformers-4.36.2\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrY9gKcbWeuC",
        "outputId": "323ad6fb-5111-4948-cb3f-efea26a73a32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'spacy_version': '3.7.5',\n",
              " 'location': '/usr/local/lib/python3.10/dist-packages/spacy',\n",
              " 'platform': 'Linux-6.1.85+-x86_64-with-glibc2.35',\n",
              " 'python_version': '3.10.12',\n",
              " 'pipelines': {'en_core_web_sm': '3.7.1'}}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.cli import info\n",
        "\n",
        "info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPP9VW0KVyjq",
        "outputId": "3ac4bb4d-d6bd-4010-c5c0-da5493884493"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "/content/drive/MyDrive/Custom_NER_Model/config/config.cfgyth\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfgyth --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ],
      "source": [
        "# Initialize spaCy configuration files by copying from base_config to config.cfg\n",
        "# !python -m spacy init fill-config /\"your_file_path\"/base_config.cfg /\"your_file_path\"/config/config.cfg\n",
        "!python -m spacy init fill-config /content/drive/MyDrive/Custom_NER_Model/config/base_config.cfg /content/drive/MyDrive/Custom_NER_Model/config/config.cfgyth"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsNVV0OPXWD8"
      },
      "source": [
        "## *4. Defining the Data Processing Function*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH3kfooSXbTK"
      },
      "source": [
        "The provided code defines a function that is used to create spaCy DocBin objects from annotated data. This function plays a crucial role in the process of preparing data for training custom Named Entity Recognition (NER) models. Let’s break down the importance and functionality of this code:\n",
        "\n",
        "Why it is needed:\n",
        "\n",
        "1. **Data Preparation**: In NER tasks, having properly formatted training data is essential. This data typically consists of text documents with labeled entities, where each entity is defined by its start and end positions in the text and its associated label (e.g., person, organization, date).\n",
        "2. **SpaCy Integration**: spaCy is a popular NLP library that offers robust capabilities for NER model training. To leverage spaCy for training, you need to convert your annotated data into a format that spaCy understands."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HHdn5M6XeaJ"
      },
      "source": [
        "**Importance:**\n",
        "\n",
        "1. **Conversion to spaCy Format**: It transforms annotated data into a *format compatible with spaCy v3*, creating `Doc` objects with character spans linked to entities.\n",
        "2. **Entity Alignment**: Prevents entity overlaps or conflicts within documents, avoiding training issues.\n",
        "3. **Error Logging**: Captures and logs data issues, aiding debugging and data quality assessment.\n",
        "4. **Efficient Data Loading**: Utilizes spaCy’s `DocBin` for efficient storage and loading of processed documents, crucial for managing large datasets during model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CJfA6yjJXgvi"
      },
      "outputs": [],
      "source": [
        "# Define a function to create spaCy DocBin objects from the annotated data\n",
        "def get_spacy_doc(file, data):\n",
        "  # Create a blank spaCy pipeline\n",
        "  nlp = spacy.blank('en')\n",
        "  db = DocBin()\n",
        "\n",
        "  # Iterate through the data\n",
        "  for text, annot in tqdm(data):\n",
        "    doc = nlp.make_doc(text)\n",
        "    annot = annot['entities']\n",
        "\n",
        "    ents = []\n",
        "    entity_indices = []\n",
        "\n",
        "    # Extract entities from the annotations\n",
        "    for start, end, label in annot:\n",
        "      skip_entity = False\n",
        "      for idx in range(start, end):\n",
        "        if idx in entity_indices:\n",
        "          skip_entity = True\n",
        "          break\n",
        "      if skip_entity:\n",
        "        continue\n",
        "\n",
        "      entity_indices = entity_indices + list(range(start, end))\n",
        "      try:\n",
        "        span = doc.char_span(start, end, label=label, alignment_mode='strict')\n",
        "      except:\n",
        "        continue\n",
        "\n",
        "      if span is None:\n",
        "        # Log errors for annotations that couldn't be processed\n",
        "        err_data = str([start, end]) + \"    \" + str(text) + \"\\n\"\n",
        "        file.write(err_data)\n",
        "      else:\n",
        "        ents.append(span)\n",
        "\n",
        "    try:\n",
        "      doc.ents = ents\n",
        "      db.add(doc)\n",
        "    except:\n",
        "      pass\n",
        "\n",
        "  return db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0jXPj9kXm5p"
      },
      "source": [
        "## *5. Data Splitting and DocBin Creation*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25LOPIIHXrBs"
      },
      "source": [
        "In this section, we split the annotated data into training and testing sets display their sizes, and create spaCy DocBin objects for both sets. Additionally, we log errors during the annotation processing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34x7Bl46dyDV"
      },
      "source": [
        "`**Giving Error**`\n",
        "\n",
        "> Run Below Code\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awabbBnYXw2B"
      },
      "outputs": [],
      "source": [
        "# Split the annotated data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(cv_data, test_size=0.2)\n",
        "\n",
        "# Display the number of items in the training and testing sets\n",
        "len(train), len(test)\n",
        "\n",
        "# Open a file to log errors during annotation processing\n",
        "file = open('/content/drive/MyDrive/Custom_NER_Model/trained_models/train_file.txt','w')\n",
        "\n",
        "# Create spaCy DocBin objects for training and testing data\n",
        "db = get_spacy_doc(file, train)\n",
        "db.to_disk('/content/drive/MyDrive/Custom_NER_Model/trained_models/train_data.spacy')\n",
        "\n",
        "db = get_spacy_doc(file, test)\n",
        "db.to_disk('/content/drive/MyDrive/Custom_NER/trained_models/test_data.spacy')\n",
        "\n",
        "# Close the error log file\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGOLl-sFcY4j",
        "outputId": "09272494-e688-4636-dc21-c9133bf589d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/spacy/util.py:1740: UserWarning: [W111] Jupyter notebook detected: if using `prefer_gpu()` or `require_gpu()`, include it in the same cell right before `spacy.load()` to ensure that the model is loaded on the correct device. More information: http://spacy.io/usage/v3#jupyter-notebook-gpu\n",
            "  warnings.warn(Warnings.W111)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set size: 6, Testing set size: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/6 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity: LINKEDIN_ACCOUNT 99 151 https://www.linkedin.com/in/hujefa-shaik-9798b6183/ \n",
            "Skipping entity: SUMMARY 251 426  Eager to apply my educational background and passion for automation, continuous integration, and cloud technologies to contribute to the success of an innovative organization\n",
            "Skipping entity: SUMMARY 429 550  am a fast learner, enthusiastic about acquiring new skills, and ready to make a positive impact on development processes\n",
            "Skipping entity: DEVELOPER_TOOLS 1215 1223  Jenkins\n",
            "Skipping entity: DESCRIPTION_OF_PROJECT 1949 2122 mplemented the various stages in the pipeline as Build, Unit testing, Static code analysis, Artifactory, creation of Docker images, and Deployment on the Kubernetes platform\n",
            "Skipping entity: LOCATION_OF_WORK 712 817 Sadei Digital Pvt. Ltd. ABC Business Club, 16-Tagore villa, Chakrata Road, Dehradun, Uttarakhand, 248001 \n",
            "Skipping entity: SOFT_SKILLS 897 914  Highly dedicated\n",
            "Skipping entity: START_DATE_OF_UNIVERSITY 187 192 2020 \n",
            "Skipping entity: GPA 205 209 8.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 6/6 [00:00<00:00, 91.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity: LINKEDIN_ACCOUNT 88 108 Hrishikesh Choraghe \n",
            "Skipping entity: INSTITUTE/UNIVERSITY 501 543 Hemvati Nandan Bahuguna Garhwal University\n",
            "Skipping entity: START_DATE_OF_UNIVERSITY 544 548 2019\n",
            "Skipping entity: INSTITUTE/UNIVERSITY 666 704 ST. Theresa’s School, Srinagar Garhwal\n",
            "Skipping entity: GRADUATION_YEAR 705 709 2017\n",
            "Skipping entity: INSTITUTE/UNIVERSITY 831 849 SRM University AP \n",
            "Skipping entity: GPA 884 888 8.13\n",
            "Skipping entity: START_DATE_OF_UNIVERSITY 899 903 2021\n",
            "Skipping entity: PERCENTAGE 983 991 957/1000\n",
            "Skipping entity: START_DATE_OF_UNIVERSITY 999 1003 2019\n",
            "Skipping entity: GPA 1056 1059 9.8\n",
            "Skipping entity: START_DATE_OF_UNIVERSITY 1070 1074 2018\n",
            "Skipping entity: DESCRIPTION_OF_PROJECT 1328 1435 his application is helpful to users for checking their balance amount and for managing the account details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 125.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipping entity: SUMMARY 127 310 seeking an innovative career that would expand my knowledge utilize my personal skills and would provide ample opportunities to grow With the organisation personally and professionall\n",
            "Skipping entity: INSTITUTE/UNIVERSITY 369 397  Gehu. Dehradun, Uttarakhand\n",
            "Skipping entity: START_DATE_OF_JOB 371 377 July22\n",
            "Skipping entity: WORK_EXPERIENCE 397 438 6-Months of work experience in E-TRAVELI \n",
            "Skipping entity: START_DATE_OF_JOB 499 511 January 2022\n",
            "Skipping entity: END_DATE_OF_JOB 511 520 April2022\n",
            "Skipping entity: START_DATE_OF_JOB 571 575 2019\n",
            "Skipping entity: END_DATE_OF_JOB 575 579 2021\n",
            "Skipping entity: WORK_EXPERIENCE 582 773 ave done dissertation on RRB’S performance in Uttarakhand for the time period of (2019-2021) pre covid to post covid era ,by taking secondary data into consideration September2021-January2022\n",
            "Skipping entity: WORK_EXPERIENCE 801 852 Research work internship project on the as an river\n",
            "Skipping entity: START_DATE_OF_JOB 889 898 June 2021\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ensure the trained_models directory exists\n",
        "os.makedirs('/content/drive/MyDrive/Custom_NER_Model/trained_models', exist_ok=True)\n",
        "\n",
        "# Split the annotated data into training and testing sets\n",
        "train, test = train_test_split(cv_data, test_size=0.2)\n",
        "\n",
        "# Display the number of items in the training and testing sets\n",
        "print(f\"Training set size: {len(train)}, Testing set size: {len(test)}\")\n",
        "\n",
        "# Open a file to log errors during annotation processing\n",
        "file = open('/content/drive/MyDrive/Custom_NER_Model/trained_models/train_file.txt', 'w')\n",
        "\n",
        "# Function to create spaCy DocBin objects from data\n",
        "def get_spacy_doc(file, data):\n",
        "    nlp = spacy.blank(\"en\")  # create blank English model\n",
        "    db = DocBin()\n",
        "    for text, annotations in tqdm(data):\n",
        "        try:\n",
        "            doc = nlp.make_doc(text)\n",
        "            ents = []\n",
        "            for start, end, label in annotations[\"entities\"]:\n",
        "                span = doc.char_span(start, end, label=label)\n",
        "                if span is None:\n",
        "                    print(\"Skipping entity:\", label, start, end, text[start:end])\n",
        "                    continue\n",
        "                ents.append(span)\n",
        "            doc.ents = ents\n",
        "            db.add(doc)\n",
        "        except Exception as e:\n",
        "            file.write(str(e) + \"\\n\")\n",
        "    return db\n",
        "\n",
        "# Create spaCy DocBin objects for training and testing data\n",
        "db_train = get_spacy_doc(file, train)\n",
        "db_train.to_disk('/content/drive/MyDrive/Custom_NER_Model/trained_models/train_data.spacy')\n",
        "\n",
        "db_test = get_spacy_doc(file, test)\n",
        "db_test.to_disk('/content/drive/MyDrive/Custom_NER_Model/trained_models/test_data.spacy')\n",
        "\n",
        "# Close the error log file\n",
        "file.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZudEXjPaclrn"
      },
      "source": [
        "## *6. Model Training*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuG3AGHpcpHN",
        "outputId": "5ecd1075-af86-4343-a88a-dd5616142996"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Created output directory:\n",
            "/content/drive/MyDrive/Custom_NER_Model/trained_models/output\u001b[0m\n",
            "\u001b[38;5;4mℹ Saving to output directory:\n",
            "/content/drive/MyDrive/Custom_NER_Model/trained_models/output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "tokenizer_config.json: 100% 25.0/25.0 [00:00<00:00, 182kB/s]\n",
            "config.json: 100% 481/481 [00:00<00:00, 4.01MB/s]\n",
            "vocab.json: 100% 899k/899k [00:00<00:00, 6.84MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 6.93MB/s]\n",
            "tokenizer.json: 100% 1.36M/1.36M [00:00<00:00, 7.49MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "model.safetensors: 100% 499M/499M [00:02<00:00, 232MB/s]\n",
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "  0       0         294.69    547.59    0.00    0.00    0.00    0.00\n",
            "100     200      328393.32  76027.86    8.82   15.00    6.25    0.09\n",
            "200     400       66425.82  14888.79   29.21   31.71   27.08    0.29\n",
            "300     600          15.65    323.82   31.91   32.61   31.25    0.32\n",
            "400     800          14.72    311.94   35.16   37.21   33.33    0.35\n",
            "500    1000           0.00    308.92   32.97   34.88   31.25    0.33\n",
            "600    1200          37.30    330.84   24.00   33.33   18.75    0.24\n",
            "700    1400          42.13    317.57   34.15   41.18   29.17    0.34\n",
            "800    1600          30.30    326.02   35.44   45.16   29.17    0.35\n",
            "900    1800         340.54    422.12   35.62   52.00   27.08    0.36\n",
            "1000    2000           0.07    303.72   38.10   44.44   33.33    0.38\n",
            "1100    2200           0.00    305.21   35.96   39.02   33.33    0.36\n",
            "1200    2400          66.63    338.52   31.33   37.14   27.08    0.31\n",
            "1300    2600       28556.43   3531.64   34.88   39.47   31.25    0.35\n",
            "1400    2800        5455.26   1312.68   35.29   40.54   31.25    0.35\n",
            "1500    3000          10.25    313.58   34.48   38.46   31.25    0.34\n",
            "1600    3200           0.04    303.37   34.15   41.18   29.17    0.34\n",
            "1700    3400           0.01    301.85   30.23   34.21   27.08    0.30\n",
            "1800    3600          33.17    312.97   32.94   37.84   29.17    0.33\n",
            "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
            "/content/drive/MyDrive/Custom_NER_Model/trained_models/output/model-last\n"
          ]
        }
      ],
      "source": [
        "# Train a spaCy NER model using the provided configuration and data\n",
        "!python -m spacy train /content/drive/MyDrive/Custom_NER_Model/config/config.cfgyth  --output /content/drive/MyDrive/Custom_NER_Model/trained_models/output  --paths.train /content/drive/MyDrive/Custom_NER_Model/trained_models/train_data.spacy  --paths.dev /content/drive/MyDrive/Custom_NER_Model/trained_models/test_data.spacy --gpu-id 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJ03hNSJfjJw"
      },
      "source": [
        "Here's what each component of the log means:\n",
        "\n",
        "`E:` Epoch number. An epoch is one complete pass through the entire training dataset. In your log, this is the 0th epoch, indicating the very beginning of the training process.\n",
        "\n",
        "`#:` Step or batch number within the epoch. This is the 0th step, meaning this log entry is from the very start of the first epoch.\n",
        "\n",
        "`LOSS TRANS...`: The loss value for the transformer component. This value indicates how well the transformer model (e.g., RoBERTa) is performing during training. A high initial value is expected and should decrease as training progresses.\n",
        "\n",
        "`LOSS NER`: The loss value for the Named Entity Recognition (NER) component. This is a measure of how well the NER component is learning to recognize named entities. Like the transformer loss, it should decrease over time.\n",
        "\n",
        "`ENTS_F`: F1 score for named entities. The F1 score is a harmonic mean of precision and recall, giving a single measure of model performance. A score of 0.00 at this point is normal, as the model has just started training and hasn't learned anything yet.\n",
        "\n",
        "`ENTS_P`: Precision for named entities. Precision is the ratio of correctly predicted positive observations to the total predicted positives. A score of 0.00 indicates that the model is not yet making correct predictions.\n",
        "\n",
        "`ENTS_R`: Recall for named entities. Recall is the ratio of correctly predicted positive observations to all observations in the actual class. A score of 0.00 indicates that the model is not yet able to find the correct entities.\n",
        "\n",
        "`SCORE`: Overall score for the model, which is typically a combination of the F1 score and other metrics. A score of 0.00 at this initial stage is expected."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39mv1CH9d_Ty"
      },
      "source": [
        "## *7. Model Testing*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2ubHgPkeDSA"
      },
      "source": [
        "### *7.1 Extracting Information from a Test Resume with SpaCy*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiqjHzVHeJZR"
      },
      "source": [
        "In this section, we’re using spaCy to extract resume information. We begin by importing spaCy and loading a pre-trained NER model. For PDF handling, we import necessary libraries and specify the resume’s path. We open the PDF, extract its text, and consolidate it for further processing. This streamlined process enables us to efficiently extract data from resumes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z16wcMeIeNsF",
        "outputId": "fcba778f-d176-45c5-9aa2-e511bcd77e6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fitz\n",
            "  Downloading fitz-0.0.1.dev2-py2.py3-none-any.whl (20 kB)\n",
            "Collecting configobj (from fitz)\n",
            "  Downloading configobj-5.0.8-py2.py3-none-any.whl (36 kB)\n",
            "Collecting configparser (from fitz)\n",
            "  Downloading configparser-7.0.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: httplib2 in /usr/local/lib/python3.10/dist-packages (from fitz) (0.22.0)\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.10/dist-packages (from fitz) (4.0.2)\n",
            "Collecting nipype (from fitz)\n",
            "  Downloading nipype-1.8.6-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fitz) (2.0.3)\n",
            "Collecting pyxnat (from fitz)\n",
            "  Downloading pyxnat-1.6.2-py3-none-any.whl (95 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.6/95.6 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fitz) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from configobj->fitz) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2->fitz) (3.1.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (24.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nibabel->fitz) (67.7.2)\n",
            "Requirement already satisfied: click>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (8.1.7)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.3)\n",
            "Collecting prov>=1.5.2 (from nipype->fitz)\n",
            "  Downloading prov-2.0.1-py3-none-any.whl (421 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.5/421.5 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydot>=1.2.3 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (2.8.2)\n",
            "Collecting rdflib>=5.0.0 (from nipype->fitz)\n",
            "  Downloading rdflib-7.0.0-py3-none-any.whl (531 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m531.9/531.9 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting simplejson>=3.8.0 (from nipype->fitz)\n",
            "  Downloading simplejson-3.19.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting traits!=5.0,<6.4,>=4.6 (from nipype->fitz)\n",
            "  Downloading traits-6.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from nipype->fitz) (3.14.0)\n",
            "Collecting etelemetry>=0.2.0 (from nipype->fitz)\n",
            "  Downloading etelemetry-0.3.1-py3-none-any.whl (6.4 kB)\n",
            "Collecting looseversion (from nipype->fitz)\n",
            "  Downloading looseversion-1.3.0-py2.py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fitz) (2024.1)\n",
            "Requirement already satisfied: lxml>=4.3 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (4.9.4)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (2.31.0)\n",
            "Requirement already satisfied: pathlib>=1.0 in /usr/local/lib/python3.10/dist-packages (from pyxnat->fitz) (1.0.1)\n",
            "Collecting ci-info>=0.2 (from etelemetry>=0.2.0->nipype->fitz)\n",
            "  Downloading ci_info-0.3.0-py3-none-any.whl (7.8 kB)\n",
            "Collecting rdflib>=5.0.0 (from nipype->fitz)\n",
            "  Downloading rdflib-6.3.2-py3-none-any.whl (528 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m528.1/528.1 kB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting isodate<0.7.0,>=0.6.0 (from rdflib>=5.0.0->nipype->fitz)\n",
            "  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->pyxnat->fitz) (2024.6.2)\n",
            "Installing collected packages: looseversion, traits, simplejson, isodate, configparser, configobj, ci-info, rdflib, pyxnat, etelemetry, prov, nipype, fitz\n",
            "Successfully installed ci-info-0.3.0 configobj-5.0.8 configparser-7.0.0 etelemetry-0.3.1 fitz-0.0.1.dev2 isodate-0.6.1 looseversion-1.3.0 nipype-1.8.6 prov-2.0.1 pyxnat-1.6.2 rdflib-6.3.2 simplejson-3.19.2 traits-6.3.2\n",
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.5-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.24.3 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.5 PyMuPDFb-1.24.3\n"
          ]
        }
      ],
      "source": [
        "# install any necessary packages\n",
        "!pip install fitz\n",
        "!pip install PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxD8iLlkeP8R",
        "outputId": "368da067-40ef-4d22-857e-74a708e7ac4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Avinash Yadav\n",
            "SRM University, Neerukonda, Andhra Pradesh, India 522502\n",
            "+91 9317171704 | avinashurmilayadav@gmail.com | linkedin.com/in/avinash-yadav-16hgnisgar\n",
            "github.com/avinashyadav16 | Leetcode | CodeChef | GFG | Codeforces | Hackerrank | CodingNinjas\n",
            "PROFESSIONAL SUMMARY\n",
            "Versatile full stack developer and apprentice in ML with a keen attention to details and a knack for problem-solving.\n",
            "Currently pursuing a Bachelor’s in Computer Science, adept at collaborating and communicating new ideas\n",
            "effectively. Possesses excellent verbal communication skills, enabling seamless interaction within teams and clients\n",
            "alike.\n",
            "AWARDS AND CERTIfiCATIONS\n",
            "\"The Joy of Computing using Python\", top 1% Elite (out of 16,145) | NPTEL Oct 2023\n",
            "Microsoft Certified Azure AI Fundamentals | Microsoft Apr 2023\n",
            "Artificial Intelligence With Python | Languify | Coincent Feb 2023\n",
            "TECHNICAL SKILLS\n",
            "Languages : C, CPP, Python, SQL (PostgreSQL, MySQL), PHP, JavaScript, TypeScript, HTML, XML, JSON, CSS\n",
            "Frameworks/Libraries : jQuery, React, Node.js, ExpressJS, web3.js, Bootstrap5, Tailwind CSS, NumPy, Matplotlib\n",
            "DevOps and API Tools : Git, GitHub, Docker, Postman\n",
            "EXPERIENCE\n",
            "Software Testing Automation Virtual Intern | SmartBridge\n",
            "Dec 2023 – Feb2024\n",
            "– Proficient in Katalon Studio for automating software testing processes, integrating with Git and Jenkins for\n",
            "streamlined workflows.\n",
            "– Integral role in automating Amazon’s UI testing, ensuring efficient validation of different features and seamless\n",
            "navigation.\n",
            "– Strong grasp of software testing fundamentals, including manual testing and automation concepts.\n",
            "Defy24 Hackathon | VIT Chennai\n",
            "Jan 2024 | Chennai\n",
            "– Top 30 Finalist In 700+ Team\n",
            "– A national level web3 business oriented Hackathon conducted by VIT- Chennai, where I worked upon building a\n",
            "full stack website integrating blockchain to it.\n",
            "Geekathon 1.0 | VIT - Andhra Pradesh\n",
            "Nov 2023 | Guntur\n",
            "– Great accomplishment in national level hackathon conducted by GEEKS FOR GEEKS CHAPTER of VIT-AP Andhra\n",
            "Pradesh, where I aligned myself into building a travel-planner website.\n",
            "EDUCATION\n",
            "SRM University, Andhra Pradesh\n",
            "B.Tech. in CSE AI&ML | GPA : 9.46 (Till 3rd Sem)\n",
            "Oct 2022 – Present\n",
            "VidyaGyan School, Sitapur\n",
            "Grade 6 to 12 |\n",
            "July 2015 – May 2022\n",
            "PROJECTS\n",
            "Flask-Blog | Python, Flask, Bootstrap5\n",
            "Apr 2024\n",
            "– Created a full-fledged blog application using Flask, Python’s micro web framework and its dynamic libraries.\n",
            "Sorting Algorithm Visualiser | C++, SDL2\n",
            "Jan 2024\n",
            "– A mesmerizing visual representation of different sorting algorithm and their approach toward sorting.\n",
            "– Shows the time complexity of different popular sorting algorithms.\n",
            "Web Development Mini Projects | HTML, CSS, Bootstrap, JS, JQuery, Nodejs, express js, react, MongoDB\n",
            "Feb 2024\n",
            "– Portfolio / Google Drive Clone / Street Dog Adoption Site\n",
            "– Dice Playing Game / Drum Kits / Simon Game/ Currency Converter / Theme Switcher / ToDo App\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Import the spaCy library\n",
        "import spacy\n",
        "\n",
        "# Load the trained spaCy NER model from the specified path\n",
        "nlp = spacy.load('/content/drive/MyDrive/Custom_NER_Model/trained_models/output/model-best')\n",
        "\n",
        "# Import necessary libraries for PDF processing\n",
        "import sys\n",
        "import fitz\n",
        "\n",
        "# Specify the path to the PDF file containing the resume\n",
        "fname = '/content/drive/MyDrive/Custom_NER_Model/test_dataset/resume-1.pdf'\n",
        "\n",
        "# Open the PDF document using PyMuPDF (fitz)\n",
        "doc = fitz.open(fname)\n",
        "\n",
        "# Initialize an empty string to store the extracted text from the PDF\n",
        "text = \" \"\n",
        "\n",
        "# Iterate through each page in the PDF and concatenate the text\n",
        "for page in doc:\n",
        "  text = text + str(page.get_text())\n",
        "\n",
        "# Display the extracted text\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNIukkgVefau"
      },
      "source": [
        "### *7.2 NER Processing on the Test Resume*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WQqLSiGejC0"
      },
      "source": [
        "In this part of the code, we utilize the loaded, trained spaCy NER model to process the above text. The model identifies and categorizes named entities. We iterate through these recognized entities and print both the text and their respective labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZmGnZuUelkk"
      },
      "source": [
        "Now, let’s proceed with processing the extracted text using the loaded spaCy NER model and printing the recognized named entities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXXHnhmyempk",
        "outputId": "17c87642-5612-4c2c-acc4-312fb7971601"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avinash Yadav   ->>>>   NAME\n",
            "SRM University, Neerukonda   ->>>>   INSTITUTE/UNIVERSITY\n",
            "522502   ->>>>   PHONE_NO\n",
            "+91 9317171704   ->>>>   PHONE_NO\n",
            "avinashurmilayadav@gmail.com   ->>>>   EMAIL_ID\n",
            "linkedin.com/in/avinash-yadav-16hgnisgar   ->>>>   GITHUB_ACCOUNT\n",
            "github.com/avinashyadav16   ->>>>   GITHUB_ACCOUNT\n",
            "Leetcode |   ->>>>   DEVELOPER_TOOLS\n",
            "CodeChef   ->>>>   TECHNICAL_SKILLS\n",
            "GFG   ->>>>   TECHNICAL_SKILLS\n",
            "Codeforces   ->>>>   TECHNICAL_SKILLS\n",
            "Hackerrank   ->>>>   TECHNICAL_SKILLS\n",
            "CodingNinjas   ->>>>   TECHNICAL_SKILLS\n",
            "Versatile full stack developer and apprentice in ML with a keen attention to details and a knack for problem-solving.\n",
            "Currently pursuing a Bachelor’s in Computer Science, adept at collaborating and communicating new ideas\n",
            "effectively. Possesses excellent verbal communication skills, enabling seamless interaction within teams and clients\n",
            "alike.\n",
            "AWARDS AND CERTIfiCATIONS\n",
            "\"The Joy of Computing using Python\", top 1% Elite (out of 16,145) | NPTEL Oct 2023\n",
            "Microsoft Certified Azure AI Fundamentals | Microsoft Apr   ->>>>   SUMMARY\n",
            "Artificial Intelligence   ->>>>   JOB_TITLE\n",
            "Languify   ->>>>   DEVELOPER_TOOLS\n",
            "Coincent   ->>>>   DEVELOPER_TOOLS\n",
            "C   ->>>>   TECHNICAL_SKILLS\n",
            "CPP   ->>>>   TECHNICAL_SKILLS\n",
            "Python   ->>>>   TECHNICAL_SKILLS\n",
            "SQL   ->>>>   TECHNICAL_SKILLS\n",
            "PostgreSQL   ->>>>   TECHNICAL_SKILLS\n",
            "MySQL   ->>>>   TECHNICAL_SKILLS\n",
            "PHP   ->>>>   TECHNICAL_SKILLS\n",
            "JavaScript   ->>>>   TECHNICAL_SKILLS\n",
            "TypeScript   ->>>>   TECHNICAL_SKILLS\n",
            "HTML   ->>>>   TECHNICAL_SKILLS\n",
            "XML   ->>>>   TECHNICAL_SKILLS\n",
            "JSON   ->>>>   TECHNICAL_SKILLS\n",
            "CSS   ->>>>   TECHNICAL_SKILLS\n",
            "jQuery   ->>>>   TECHNICAL_SKILLS\n",
            "React   ->>>>   TECHNICAL_SKILLS\n",
            "Node.js   ->>>>   TECHNICAL_SKILLS\n",
            "ExpressJS   ->>>>   TECHNICAL_SKILLS\n",
            "web3.js   ->>>>   TECHNICAL_SKILLS\n",
            "Bootstrap5   ->>>>   TECHNICAL_SKILLS\n",
            "Tailwind   ->>>>   TECHNICAL_SKILLS\n",
            "CSS   ->>>>   TECHNICAL_SKILLS\n",
            "NumPy   ->>>>   TECHNICAL_SKILLS\n",
            "Matplotlib   ->>>>   TECHNICAL_SKILLS\n",
            "Git   ->>>>   TECHNICAL_SKILLS\n",
            "GitHub   ->>>>   TECHNICAL_SKILLS\n",
            "Docker   ->>>>   TECHNICAL_SKILLS\n",
            "Postman   ->>>>   TECHNICAL_SKILLS\n",
            "Software Testing Automation   ->>>>   JOB_TITLE\n",
            "SmartBridge   ->>>>   TECHNICAL_SKILLS\n",
            "Dec 2023   ->>>>   START_DATE_OF_JOB\n",
            "Feb2024   ->>>>   END_DATE_OF_UNIVERSITY\n",
            "Proficient in Katalon Studio for automating software testing processes, integrating with Git and Jenkins for\n",
            "streamlined workflows.\n",
            "– Integral role in automating Amazon’s UI testing, ensuring efficient validation of different features and seamless\n",
            "navigation.\n",
            "– Strong grasp of software testing fundamentals, including manual testing and automation concepts   ->>>>   SUMMARY\n",
            "Defy24   ->>>>   COMPANY\n",
            "VIT Chennai   ->>>>   INSTITUTE/UNIVERSITY\n",
            "Jan 2024   ->>>>   END_DATE_OF_JOB\n",
            "Chennai\n",
            "–   ->>>>   ADDRESS\n",
            "Top 30 Finalist In 700+   ->>>>   ACHIEVEMENTS\n",
            "A national level web3 business oriented Hackathon conducted by VIT- Chennai, where I worked upon building a\n",
            "full stack website integrating blockchain to it.   ->>>>   DESCRIPTION_OF_PROJECT\n",
            "Nov 2023   ->>>>   END_DATE_OF_JOB\n",
            "Guntur\n",
            "– Great   ->>>>   ADDRESS\n",
            "SRM University, Andhra Pradesh   ->>>>   INSTITUTE/UNIVERSITY\n",
            "B.Tech. in CSE AI&ML | GPA : 9.46 (Till 3rd Sem)   ->>>>   DEGREE\n",
            "Oct 2022   ->>>>   START_DATE_OF_JOB\n",
            "VidyaGyan School, Sitapur   ->>>>   INSTITUTE/UNIVERSITY\n",
            "12   ->>>>   DEGREE\n",
            "May 2022   ->>>>   END_DATE_OF_JOB\n",
            "Flask-Blog   ->>>>   PROJECT_NAME\n",
            "Python   ->>>>   TECHNICAL_SKILLS\n",
            "Flask   ->>>>   TECHNOLOGIES_USED_IN_PROJECT\n",
            "Bootstrap5   ->>>>   TECHNICAL_SKILLS\n",
            "Apr 2024   ->>>>   END_DATE_OF_JOB\n",
            "Created a full-fledged blog application using Flask, Python’s micro web framework and its dynamic libraries   ->>>>   DESCRIPTION_OF_PROJECT\n",
            "Sorting Algorithm Visualiser   ->>>>   PROJECT_NAME\n",
            "C++   ->>>>   TECHNICAL_SKILLS\n",
            "SDL2   ->>>>   TECHNICAL_SKILLS\n",
            "Jan 2024   ->>>>   END_DATE_OF_JOB\n",
            "A mesmerizing visual representation of different sorting algorithm and their approach toward sorting   ->>>>   DESCRIPTION_OF_PROJECT\n",
            "Shows the time complexity of different popular sorting algorithms   ->>>>   DESCRIPTION_OF_PROJECT\n",
            "Web Development Mini   ->>>>   JOB_TITLE\n",
            "HTML   ->>>>   TECHNICAL_SKILLS\n",
            "CSS   ->>>>   TECHNICAL_SKILLS\n",
            "Bootstrap   ->>>>   TECHNICAL_SKILLS\n",
            "JS   ->>>>   TECHNICAL_SKILLS\n",
            "JQuery   ->>>>   TECHNICAL_SKILLS\n",
            "Nodejs   ->>>>   TECHNICAL_SKILLS\n",
            "express js   ->>>>   TECHNICAL_SKILLS\n",
            "react   ->>>>   TECHNICAL_SKILLS\n",
            "MongoDB   ->>>>   TECHNICAL_SKILLS\n",
            "Feb 2024   ->>>>   END_DATE_OF_JOB\n",
            "Portfolio   ->>>>   DEVELOPER_TOOLS\n",
            "Google Drive Clone /   ->>>>   FRAMEWORKS_AND_LIBRARIES\n",
            "Street Dog Adoption Site\n",
            "– Dice Playing Game /   ->>>>   FRAMEWORKS_AND_LIBRARIES\n",
            "Simon Game/ Currency Converter   ->>>>   CERTIFICATES\n",
            "ToDo App\n",
            "   ->>>>   CERTIFICATES\n"
          ]
        }
      ],
      "source": [
        "# Process the extracted text using the loaded spaCy NER model\n",
        "doc = nlp(text)\n",
        "\n",
        "# Iterate through the named entities (entities) recognized by the model\n",
        "for ent in doc.ents:\n",
        "  # Print the recognized text and its corresponding label\n",
        "  print(ent.text, \"  ->>>>  \", ent.label_)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNK+xLYlg4katqwIkMITtjI",
      "gpuType": "T4",
      "include_colab_link": true,
      "mount_file_id": "16r6eJBNmdENemj8FqV-eo7-XvWhel5DE",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
