{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Course:** Randomized Algorithms by Dr. Zarei\n",
        "\n",
        "**Homework:** HW4\n",
        "\n",
        "**Name:** Mohammad Mohammadi\n",
        "\n",
        "**Student ID:** 402208592"
      ],
      "metadata": {
        "id": "9JbKLJNkfqlH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2.4 [RA_Mot]\n",
        "\n",
        "Determine the value $V_R$ of the following 2 x 2 matrix game and give optimal\n",
        "mixed strategies for the two players.\n",
        "\n",
        "$$\n",
        "\\begin{bmatrix}\n",
        "    5 & 6 \\\\\n",
        "    7 & 4 \\\\\n",
        "\\end{bmatrix}\n",
        "$$"
      ],
      "metadata": {
        "id": "TNS-hA4yyNoU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "\n",
        "Let $ p $ be the probability that Player 1 plays the first row and $ 1-p $ be the probability that Player 1 plays the second row. Similarly, let $ q $ be the probability that Player 2 plays the first column and $ 1-q $ be the probability that Player 2 plays the second column.\n",
        "\n",
        "The expected payoff for Player 1 when Player 2 plays the first column ($ q $) is:\n",
        "\n",
        "$$\n",
        "E_1(1) = 5p + 7(1-p)\n",
        "$$\n",
        "\n",
        "The expected payoff for Player 1 when Player 2 plays the second column ($ 1-q $) is:\n",
        "\n",
        "$$\n",
        "E_1(2) = 6p + 4(1-p)\n",
        "$$\n",
        "\n",
        "For Player 1 to be indifferent between the two columns (maximize the minimum payoff), we set the expected payoffs equal:\n",
        "\n",
        "$$\n",
        "5p + 7(1-p) = 6p + 4(1-p)\n",
        "$$\n",
        "\n",
        "Solving for $ p $:\n",
        "\n",
        "$$\n",
        "5p + 7 - 7p = 6p + 4 - 4p\n",
        "$$\n",
        "\n",
        "$$\n",
        "7 - 2p = 4 + 2p\n",
        "$$\n",
        "\n",
        "$$\n",
        "3 = 4p\n",
        "$$\n",
        "\n",
        "$$\n",
        "p = \\frac{3}{4}\n",
        "$$\n",
        "\n",
        "So, Player 1’s optimal mixed strategy is p=3/4 for the first row and p=1/4 for the second row.\n",
        "\n",
        "Similarly, the expected payoff for Player 2 when Player 1 plays the first row is:\n",
        "\n",
        "$$\n",
        "E_2(1) = 5q + 6(1-q)\n",
        "$$\n",
        "\n",
        "The expected payoff for Player 2 when Player 1 plays the second row is:\n",
        "\n",
        "$$\n",
        "E_2(2) = 7q + 4(1-q)\n",
        "$$\n",
        "\n",
        "Setting these equal for indifference:\n",
        "\n",
        "$$\n",
        "5q + 6(1-q) = 7q + 4(1-q)\n",
        "$$\n",
        "\n",
        "Solving for $ q $:\n",
        "\n",
        "$$\n",
        "5q + 6 - 6q = 7q + 4 - 4q\n",
        "$$\n",
        "\n",
        "$$\n",
        "6 - q = 4 + 3q\n",
        "$$\n",
        "\n",
        "$$\n",
        "2 = 4q\n",
        "$$\n",
        "\n",
        "$$\n",
        "q = \\frac{1}{2}\n",
        "$$\n",
        "\n",
        "So, Player 2’s optimal mixed strategy is q=1/2 for the first column and 1-q=1/2 for the second column.\n",
        "\n",
        "The value $ V_R $ of the game is the expected payoff when both players use their optimal mixed strategies:\n",
        "\n",
        "$$\n",
        "V_R = 5 \\cdot \\frac{3}{4} \\cdot \\frac{1}{2} + 6 \\cdot \\frac{3}{4} \\cdot \\frac{1}{2} + 7 \\cdot \\frac{1}{4} \\cdot \\frac{1}{2} + 4 \\cdot \\frac{1}{4} \\cdot \\frac{1}{2}\n",
        "$$\n",
        "\n",
        "$$\n",
        "V_R = \\frac{15}{8} + \\frac{18}{8} + \\frac{7}{8} + \\frac{4}{8}\n",
        "$$\n",
        "\n",
        "$$\n",
        "V_R = \\frac{44}{8} = 5.5\n",
        "$$"
      ],
      "metadata": {
        "id": "TgoxtYepSzTo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2.5 [RA_Mot]\n",
        "\n",
        "(Due to A.M. Karp.) Let ($a_{ij}$) be a $m * n$ matrix, let the vector ($P_1, P_2, ...,P_m$) consist of reals in $[0,1]$ such that $∑_{i=1,m}P_i=1$,  and let ($q_1, q_2, ...,q_m$) consist of reals in $[0,1]$ such that $∑_{i=1,m}q_i=1$. Prove algebraically that $max_q min_j ∑_{j=1,n}a_{ij}q_j ≤ min_q max_j ∑_{j=1,m}a_{ij}q_j$."
      ],
      "metadata": {
        "id": "3KKX2GmGWVTM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "\n",
        "To prove that\n",
        "$$\n",
        "\\max_{\\mathbf{q}} \\min_j \\sum_{i=1}^m a_{ij} q_i \\leq \\min_{\\mathbf{p}} \\max_j \\sum_{i=1}^m a_{ij} p_i,\n",
        "$$\n",
        "we need to use some fundamental results from game theory, particularly related to mixed strategies and the concept of the minimax theorem. Here, $\\mathbf{p} = (p_1, p_2, \\ldots, p_m)$ and $\\mathbf{q} = (q_1, q_2, \\ldots, q_m)$ are probability distributions over the rows and columns of the matrix $(a_{ij})$ respectively.\n",
        "\n",
        "\n",
        "1. Formulate the Problem in Game Theoretic Terms:\n",
        "   \n",
        "    Consider a zero-sum game where the matrix $(a_{ij})$ represents the payoff matrix.\n",
        "    \n",
        "    Player 1 selects a row $i$ with probability $p_i$.\n",
        "    \n",
        "    Player 2 selects a column $j$ with probability $q_j$.\n",
        "   \n",
        "\n",
        "2. Expected Payoffs:\n",
        "\n",
        "    The expected payoff for Player 1 if Player 2 plays according to the strategy $\\mathbf{q}$ is:\n",
        "    $$\n",
        "    E(\\mathbf{q}) = \\sum_{i=1}^m p_i \\left(\\sum_{j=1}^n a_{ij} q_j \\right)\n",
        "    $$\n",
        "    The expected payoff for Player 2 if Player 1 plays according to the strategy $\\mathbf{p}$ is:\n",
        "    $$\n",
        "    E(\\mathbf{p}) = \\sum_{j=1}^n q_j \\left(\\sum_{i=1}^m a_{ij} p_i \\right)\n",
        "    $$\n",
        "   \n",
        "\n",
        "3. Minimax Theorem Application:\n",
        "\n",
        "    By the minimax theorem, for any finite two-person zero-sum game with matrix $(a_{ij})$, the following holds:\n",
        "    $$\n",
        "    \\max_{\\mathbf{q}} \\min_{\\mathbf{p}} \\sum_{i=1}^m p_i \\left(\\sum_{j=1}^n a_{ij} q_j \\right) = \\min_{\\mathbf{p}} \\max_{\\mathbf{q}} \\sum_{j=1}^n q_j \\left(\\sum_{i=1}^m a_{ij} p_i \\right)\n",
        "    $$\n",
        "   \n",
        "\n",
        "4. Rewriting the Objective:\n",
        "   \n",
        "    *   The left-hand side of our inequality $\\max_{\\mathbf{q}} \\min_j \\sum_{i=1}^m a_{ij} q_i$ can be interpreted as finding the best mixed strategy for Player 2 that maximizes their worst-case payoff.\n",
        "    *   The right-hand side $\\min_{\\mathbf{p}} \\max_j \\sum_{i=1}^m a_{ij} p_i$ can be interpreted as finding the best mixed strategy for Player 1 that minimizes the best response of Player 2.\n",
        "   \n",
        "\n",
        "5. Prove the Inequality:\n",
        "   \n",
        "    By the minimax theorem, we know:\n",
        "    $$\n",
        "    \\max_{\\mathbf{q}} \\min_{\\mathbf{p}} \\sum_{i=1}^m p_i \\left(\\sum_{j=1}^n a_{ij} q_j \\right) \\leq \\min_{\\mathbf{p}} \\max_{\\mathbf{q}} \\sum_{j=1}^n q_j \\left(\\sum_{i=1}^m a_{ij} p_i \\right)\n",
        "    $$\n",
        "    Translating back to our specific terms, we get:\n",
        "    $$\n",
        "    \\max_{\\mathbf{q}} \\min_j \\sum_{i=1}^m a_{ij} q_i \\leq \\min_{\\mathbf{p}} \\max_j \\sum_{i=1}^m a_{ij} p_i\n",
        "    $$\n",
        "   "
      ],
      "metadata": {
        "id": "bDCb0sKUZALp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2.6 [RA_Mot]\n",
        "\n",
        "Use Yao's Minimax Principle to prove a lower bound on the expected running\n",
        "time of any Las Vegas algorithm for sorting n numbers."
      ],
      "metadata": {
        "id": "n3iYHy3BatLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use Yao's Minimax Principle to establish a lower bound on the expected running time of any Las Vegas algorithm for sorting $ n $ numbers. A Las Vegas algorithm is a randomized algorithm that always produces the correct result, but its running time is a random variable.\n",
        "\n",
        "Yao's Minimax Principle states that the expected running time of the best randomized algorithm on the worst-case input is at least the expected running time of the best deterministic algorithm on the average-case input distribution.\n",
        "\n",
        "Let $ \\mathcal{A} $ be a Las Vegas algorithm for sorting $ n $ numbers, and let $ T(\\mathcal{A}, x) $ denote the running time of $ \\mathcal{A} $ on input $ x $.\n",
        "\n",
        "FOr the lower bound we prove as:\n",
        "\n",
        "1. **Define the Input Distribution:**\n",
        "\n",
        "    Consider the uniform distribution over all $ n! $ permutations of $ n $ distinct numbers. Let $ \\mathcal{D} $ denote this distribution.\n",
        "\n",
        "2. **Expected Time for Deterministic Algorithms:**\n",
        "\n",
        "    Let $ \\mathcal{A_D} $ be any deterministic algorithm for sorting. The expected running time of $ \\mathcal{A_D} $ under the distribution $ \\mathcal{D} $ is:\n",
        "    $$\n",
        "    {\\mathbb{E_x} \\sim \\mathcal{D}}[T(\\mathcal{A_D}, x)] = \\frac{1}{n!} \\sum_{x \\in S_n} T(\\mathcal{A_D}, x)\n",
        "    $$\n",
        "    where $ S_n $ is the set of all $ n! $ permutations of $ n $ numbers.\n",
        "\n",
        "3. **Comparison-based Sorting Lower Bound:**\n",
        "\n",
        "    Any comparison-based deterministic sorting algorithm must perform at least $ \\log_2(n!) $ comparisons in the worst case. By Stirling's approximation, we have:\n",
        "    $$\n",
        "    \\log_2(n!) \\approx n \\log_2 n - n \\log_2 e\n",
        "    $$\n",
        "\n",
        "    Therefore, the expected number of comparisons for any deterministic algorithm under the uniform distribution is at least:\n",
        "    $$\n",
        "    \\mathbb{E}_{x \\sim \\mathcal{D}}[T(\\mathcal{A}_D, x)] \\geq \\log_2(n!)\n",
        "    $$\n",
        "\n",
        "4. **Application of Yao's Minimax Principle:**\n",
        "\n",
        "    By Yao's Minimax Principle, the expected running time of the best Las Vegas algorithm on the worst-case input is at least the expected running time of the best deterministic algorithm on the average-case input distribution. Hence,\n",
        "    $$\n",
        "    \\min_{\\mathcal{A}} \\max_{x} \\mathbb{E} [T(\\mathcal{A}, x)] \\geq \\min_{\\mathcal{A_D}} {\\mathbb{E_x} \\sim \\mathcal{D}} [T(\\mathcal{A_D}, x)]\n",
        "    $$\n",
        "    Given the lower bound for deterministic algorithms:\n",
        "    $$\n",
        "    \\min_{\\mathcal{A}} \\max_{x} \\mathbb{E}[T(\\mathcal{A}, x)] \\geq \\log_2(n!)\n",
        "    $$\n",
        "\n",
        "5. **Conclusion:**\n",
        "\n",
        "    Using Stirling's approximation again, we conclude that:\n",
        "    $$\n",
        "    \\log_2(n!) \\approx n \\log_2 n - n \\log_2 e\n",
        "    $$\n",
        "    Therefore, the expected running time of any Las Vegas algorithm for sorting $ n $ numbers is at least $ \\Omega(n \\log n) $.\n",
        "\n",
        "\n",
        "So using Yao's Minimax Principle, we have shown that the expected running time of any Las Vegas algorithm for sorting $ n $ numbers is at least $ \\Omega(n \\log n) $.\n"
      ],
      "metadata": {
        "id": "v_No1V8La0SV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 2.7 [RA_Mot]\n",
        "\n",
        "(Due to A.M. Karp.) You are given an array A containing n numbers in sorted\n",
        "order. In one step, an algorithm may specify an integer $i ϵ [1, n]$, and is given\n",
        "the value of $A[i]$ in return. Determine lower and upper bounds on the expected\n",
        "number of steps taken by a Las Vegas randomized algorithm to determine\n",
        "whether or not a given key k is present in the array."
      ],
      "metadata": {
        "id": "WdTfrxh0dKNB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "\n",
        "Given an array $ A $ containing $ n $ numbers in sorted order, determine lower and upper bounds on the expected number of steps taken by a Las Vegas randomized algorithm to determine whether a given key $ k $ is present in the array.\n",
        "\n",
        "**For Upper Bound**\n",
        "\n",
        "A Las Vegas randomized algorithm must always produce the correct result, but its running time is a random variable. One approach is to use randomized binary search:\n",
        "\n",
        "1.  Randomly select an index $ i $ from the array.\n",
        "2.  Compare $ A[i] $ with the key $ k $:\n",
        "    \n",
        "    *   If $ A[i] = k $, return the result.\n",
        "    *   If $ A[i] < k $, discard the left half and repeat on the right half.\n",
        "    *   If $ A[i] > k $, discard the right half and repeat on the left half.\n",
        "\n",
        "\n",
        "The expected number of steps $E(n)$ to find the key can be derived as follows:\n",
        "*   Initially, the search interval is of size n.\n",
        "*   At each step, the interval size reduces by half (on average), and this reduction continues until the interval size becomes 1.\n",
        "\n",
        "The number of steps required for the interval to reduce to 1 is $log_2n$ (base 2 logarithm).\n",
        "\n",
        "Since we randomly select the midpoint at each step, the expected number of steps is given by the harmonic series sum for binary search:\n",
        "\n",
        "$$\n",
        "E(n) = 1 + \\frac{1}{2} E(n/2) + \\frac{1}{2} E(n/2)\n",
        "$$\n",
        "\n",
        "Simplifying the recurrence relation:\n",
        "\n",
        "$$\n",
        "E(n) = 1 + E(n/2)\n",
        "$$\n",
        "\n",
        "Solving this, we get:\n",
        "\n",
        "$$\n",
        "E(n) = O(\\log n)\n",
        "$$\n",
        "\n",
        "Thus, the upper bound on the expected number of steps is $ O(\\log n) $.\n",
        "\n",
        "**For Lower Bound**\n",
        "\n",
        "Considering the information-theoretic limit, any comparison-based algorithm must make $ \\log_2 n $ comparisons in the worst case to determine whether a key is present.\n",
        "\n",
        "Therefore, the lower bound on the expected number of steps for any comparison-based algorithm, including Las Vegas algorithms, is:\n",
        "\n",
        "$$\n",
        "\\Omega(\\log n)\n",
        "$$\n",
        "\n",
        "\n",
        "So, in conclusion the expected number of steps taken by a Las Vegas randomized algorithm to determine whether a given key $ k $ is present in a sorted array $ A $ of $ n $ numbers is $\\Theta(\\log n)$.\n"
      ],
      "metadata": {
        "id": "GC90IxCUeflm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3.3 [RA_Mot]\n",
        "\n",
        "A parallel computer consists of n processors and n memory modules. During a\n",
        "step, each processor sends a memory request to one of the memory modules.\n",
        "A memory module that receives either one or two requests can satisfy its\n",
        "request(s): modules that receive more than two requests will satisfy two requests and discard the rest.\n",
        "\n",
        "(a) Assuming that each processor chooses a memory module independently and uniformly at random, what is the expected number of processors whose requests are satisfied? Use the approximation $(1 - 1/n)^n ≃ 1/e$ if necessary.\n",
        "(b) Repeat the computation for the case where each memory module can satisfy only one request during a step.  "
      ],
      "metadata": {
        "id": "mKdb_udQkcGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "\n",
        "### Part (a)\n",
        "\n",
        "Assume that each processor chooses a memory module independently and uniformly at random. We want to find the expected number of processors whose requests are satisfied.\n",
        "\n",
        "Let $ X_i $ be the number of processors that request memory module $ i $. Then $ X_i \\sim \\text{Binomial}(n, 1/n) $.\n",
        "\n",
        "Let $ Y_i $ be the indicator random variable that is 1 if memory module $ i $ satisfies one or two requests, and 0 otherwise. Then,\n",
        "$$\n",
        "Y_i =\n",
        "\\begin{cases}\n",
        "1 & \\text{if } X_i = 1 \\text{ or } X_i = 2 \\\\\n",
        "0 & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "The expected number of satisfied processors is:\n",
        "$$\n",
        "\\mathbb{E}\\left[ \\sum_{i=1}^n Y_i \\right] = \\sum_{i=1}^n \\mathbb{E}[Y_i]\n",
        "$$\n",
        "\n",
        "To compute $ \\mathbb{E}[Y_i] $:\n",
        "$$\n",
        "\\mathbb{E}[Y_i] = \\Pr(X_i = 1) + \\Pr(X_i = 2)\n",
        "$$\n",
        "\n",
        "Using the binomial probability formula:\n",
        "$$\n",
        "\\Pr(X_i = 1) = \\binom{n}{1} \\left( \\frac{1}{n} \\right)^1 \\left( 1 - \\frac{1}{n} \\right)^{n-1} = n \\cdot \\frac{1}{n} \\cdot \\left( 1 - \\frac{1}{n} \\right)^{n-1} = \\left( 1 - \\frac{1}{n} \\right)^{n-1}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\Pr(X_i = 2) = \\binom{n}{2} \\left( \\frac{1}{n} \\right)^2 \\left( 1 - \\frac{1}{n} \\right)^{n-2} = \\frac{n(n-1)}{2} \\cdot \\frac{1}{n^2} \\cdot \\left( 1 - \\frac{1}{n} \\right)^{n-2} = \\frac{(n-1)}{2n} \\cdot \\left( 1 - \\frac{1}{n} \\right)^{n-2}\n",
        "$$\n",
        "\n",
        "Using the approximation $(1 - \\frac{1}{n})^n \\approx \\frac{1}{e}$:\n",
        "$$\n",
        "\\Pr(X_i = 1) \\approx \\frac{1}{e}\n",
        "$$\n",
        "$$\n",
        "\\Pr(X_i = 2) \\approx \\frac{(n-1)}{2n} \\cdot \\frac{1}{e} \\approx \\frac{1}{2e}\n",
        "$$\n",
        "\n",
        "Thus,\n",
        "$$\n",
        "\\mathbb{E}[Y_i] \\approx \\frac{1}{e} + \\frac{1}{2e} = \\frac{3}{2e}\n",
        "$$\n",
        "\n",
        "The expected total number of processors whose requests are satisfied is:\n",
        "$$\n",
        "\\mathbb{E}\\left[ \\sum_{i=1}^n Y_i \\right] = n \\cdot \\mathbb{E}[Y_i] \\approx n \\cdot \\frac{3}{2e} = \\frac{3n}{2e}\n",
        "$$\n",
        "\n",
        "### Part (b)\n",
        "\n",
        "Now, assume each memory module can satisfy only one request during a step.\n",
        "\n",
        "Let $ X_i $ be the number of processors that request memory module $ i $, and let $ Z_i $ be the indicator random variable that is 1 if memory module $ i $ satisfies exactly one request and 0 otherwise. Then,\n",
        "$$\n",
        "Z_i =\n",
        "\\begin{cases}\n",
        "1 & \\text{if } X_i = 1 \\\\\n",
        "0 & \\text{otherwise}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "The expected number of satisfied processors is:\n",
        "$$\n",
        "\\mathbb{E}\\left[ \\sum_{i=1}^n Z_i \\right] = \\sum_{i=1}^n \\mathbb{E}[Z_i]\n",
        "$$\n",
        "\n",
        "To compute $ \\mathbb{E}[Z_i] $:\n",
        "$$\n",
        "\\mathbb{E}[Z_i] = \\Pr(X_i = 1)\n",
        "$$\n",
        "\n",
        "From above, we have:\n",
        "$$\n",
        "\\Pr(X_i = 1) \\approx \\frac{1}{e}\n",
        "$$\n",
        "\n",
        "Therefore,\n",
        "$$\n",
        "\\mathbb{E}[Z_i] = \\frac{1}{e}\n",
        "$$\n",
        "\n",
        "The expected total number of processors whose requests are satisfied is:\n",
        "$$\n",
        "\\mathbb{E}\\left[ \\sum_{i=1}^n Z_i \\right] = n \\cdot \\mathbb{E}[Z_i] \\approx n \\cdot \\frac{1}{e} = \\frac{n}{e}\n",
        "$$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WOOLBCUooBJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3.4 [RA_Mot]\n",
        "\n",
        "Consider the following experiment, which proceeds in a sequence of rounds.\n",
        "For the first round, we have n balls, which are thrown independently and\n",
        "uniformly at random into n bins. After round $i$, for $i \\geq 1$, we discard every ball\n",
        "that fell into a bin by itself in round $i$. The remaining balls are retained for\n",
        "round $i + 1$, in which they are thrown independently and uniformly at random into the n bins. Show that there is a constant c such that with probability\n",
        "$1- O(1)$, the number of rounds is at most $c log log n$"
      ],
      "metadata": {
        "id": "9_1N1X9lo_9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "\n",
        "We consider an experiment with $ n $ balls and $ n $ bins. In each round, balls are thrown independently and uniformly at random into the bins. Balls that fall alone in a bin are discarded, and the remaining balls proceed to the next round. Let's see if with high probability, the number of rounds is at most $ c \\log \\log n $ for some constant $ c $!\n",
        "\n",
        "**Expected Number of Balls After Each Round**\n",
        "\n",
        "Let $ B_i $ denote the number of balls remaining after round $ i $.\n",
        "\n",
        "\n",
        "The probability that a specific bin contains exactly one ball is:\n",
        "$$\n",
        "\\Pr(\\text{bin } i \\text{ has exactly one ball}) = B \\left( \\frac{1}{n} \\right) \\left( 1 - \\frac{1}{n} \\right)^{B-1} \\approx \\frac{B}{n} e^{-\\frac{B}{n}}\n",
        "$$\n",
        "\n",
        "The expected number of balls that are not alone in a bin is:\n",
        "$$\n",
        "\\mathbb{E}[B_{i+1}] \\approx B_i \\left( 1 - \\frac{B_i}{n} e^{-\\frac{B_i}{n}} \\right)\n",
        "$$\n",
        "\n",
        "For large $ B_i $, we approximate:\n",
        "$$\n",
        "B_{i+1} \\approx B_i \\left( 1 - \\frac{B_i}{n} \\right)\n",
        "$$\n",
        "\n",
        "Using the exponential decay:\n",
        "$$\n",
        "B_i \\approx n \\left( \\frac{1}{e} \\right)^i\n",
        "$$\n",
        "\n",
        "To have $ B_i \\leq 1 $:\n",
        "$$\n",
        "n \\left( \\frac{1}{e} \\right)^i \\leq 1\n",
        "$$\n",
        "\n",
        "Taking the logarithm:\n",
        "$$\n",
        "\\log n - i \\log e \\leq 0,\n",
        "$$\n",
        "\n",
        "$$\n",
        "i \\geq \\log n.\n",
        "$$\n",
        "\n",
        "Thus, $ i \\approx \\log n $. Considering the exponential decay, the number of rounds $ R $ is:\n",
        "$$\n",
        "R = O(\\log \\log n).\n",
        "$$\n",
        "\n",
        "Conclusion\n",
        "\n",
        "There exists a constant $ c $ such that with probability $ 1 - O(1) $, the number of rounds is at most $ c \\log \\log n $.\n",
        "\n"
      ],
      "metadata": {
        "id": "r31HrN1brBJI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3.10 [RA_Mot]\n",
        "\n",
        "The sharp threshold result in the coupon collector's problem does not imply that the probability of needing more than $c n log n$ trials goes to zero at a\n",
        "doubly exponential rate if c were not a constant, but were allowed to grow with $n$. Let the probability of requiring more than $c n log n$ trials be $p(c)$.\n",
        "For constant $c$, show that $1/p(c)$ can be bounded from above and below by\n",
        "polynomials in $n$."
      ],
      "metadata": {
        "id": "60iig882p1o4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "\n",
        "\n",
        "\n",
        "We analyze the probability $ p(c) $ of requiring more than $ cn \\log n $ trials in the coupon collector's problem and show that $ \\frac{1}{p(c)} $ can be bounded by polynomials in $ n $.\n",
        "\n",
        "\n",
        "\n",
        "Let $ X $ be the random variable representing the number of trials needed to collect all $ n $ coupons. Using the Central Limit Theorem:\n",
        "\n",
        "$$\n",
        "X \\sim \\mathcal{N}(n \\log n, n (\\log n)^2)\n",
        "$$\n",
        "\n",
        "We standardize to find $ p(c) $:\n",
        "\n",
        "$$\n",
        "p(c) = \\Pr\\left( \\frac{X - n \\log n}{\\sqrt{n} \\log n} > \\frac{cn \\log n - n \\log n}{\\sqrt{n} \\log n} \\right) = \\Pr\\left( Z > \\sqrt{n} (c - 1) \\right),\n",
        "$$\n",
        "\n",
        "where $ Z $ is a standard normal variable.\n",
        "\n",
        "Using the normal tail bound for $ z > 0 $:\n",
        "\n",
        "$$\n",
        "\\Pr(Z > z) \\approx \\frac{1}{\\sqrt{2 \\pi} z} e^{-z^2 / 2}\n",
        "$$\n",
        "\n",
        "Thus, for large $ n $:\n",
        "\n",
        "$$\n",
        "p(c) \\approx \\frac{1}{\\sqrt{2 \\pi \\sqrt{n} (c - 1)}} e^{-n (c - 1)^2 / 2}\n",
        "$$\n",
        "\n",
        "Taking the reciprocal of $ p(c) $:\n",
        "\n",
        "$$\n",
        "\\frac{1}{p(c)} \\approx \\sqrt{2 \\pi \\sqrt{n} (c - 1)} e^{n (c - 1)^2 / 2}\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "To show $ \\frac{1}{p(c)} $ can be bounded by polynomials in $ n $:\n",
        "\n",
        "\n",
        "\\textbf{Lower Bound}: For large $ n $, $ \\frac{1}{p(c)} \\geq n^{(c-1)^2/2} $.\n",
        "\\textbf{Upper Bound}: Similarly, $ \\frac{1}{p(c)} \\leq n^{(c-1)^2/2 + \\epsilon} $ for a small positive $\\epsilon$.\n",
        "\n",
        "\n",
        "Thus, there exist constants $ k_1 $ and $ k_2 $ such that:\n",
        "\n",
        "$$\n",
        "n^{k_1} \\leq \\frac{1}{p(c)} \\leq n^{k_2},\n",
        "$$\n",
        "\n",
        "where $ k_1 $ and $ k_2 $ are related to $ (c-1)^2 / 2 $.\n",
        "\n",
        "\n",
        "\n",
        "We have shown that $ \\frac{1}{p(c)} $ can be bounded from above and below by polynomials in $ n $.\n"
      ],
      "metadata": {
        "id": "_dAlFcUosQS8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem 3.15 [RA_Mot]\n",
        "\n",
        "(Due to D. Angluin and L.G. Valiant [28].) Let B denote a random bipartite\n",
        "graph with n vertices in each of the vertex sets U and V. Each possible\n",
        "edge, independently, is present with probability p(n). Consider the following\n",
        "algorithm for constructing a perfect matching (see Section 7.3) in such a\n",
        "random graph. Modify the Proposal Algorithm of Section 3.5 as follows. Each\n",
        "$u ϵ U$ can propose only to adjacent $v ϵ V$. A vertex $v ϵ V$ always accepts a\n",
        "proposal, and if a proposal causes a \"divorce,\" then the newly divorced $u ϵ U$\n",
        "is the next to propose. The sampling procedure outlined in Problem 3.14 helps\n",
        "implement the Principle of Deferred Decisions. How small can you make the\n",
        "value of $p(n)$ and still have the algorithm succeed with high probability? The\n",
        "following fact concerning the degree $d(v)$ of a vertex $v$ in $B$ proves useful:\n",
        "\n",
        "$$\\Pr[d(v) \\leq (1 - \\beta)np] = O \\left( e^{-\\beta^2 np / 2} \\right)$$\n",
        "\n",
        "Bs: The Proposal Algorithm is the algorithm in Stable Marriage problem and it is summarized as \"man proposes, woman disposes\"."
      ],
      "metadata": {
        "id": "N7yU1LwMs69y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer\n",
        "\n",
        "Let $ B $ denote a random bipartite graph with $ n $ vertices in each of the vertex sets $ U $ and $ V $. Each possible edge, independently, is present with probability $ p(n) $. We analyze the performance of a modified Proposal Algorithm to find a perfect matching in $ B $ and determine the smallest $ p(n) $ such that the algorithm succeeds with high probability.\n",
        "\n",
        "\n",
        "Each $ u \\in U $ proposes only to adjacent $ v \\in V $. A vertex $ v \\in V $ always accepts a proposal, and if a proposal causes a \"divorce,\" the newly divorced $ u $ is the next to propose.\n",
        "\n",
        "\n",
        "The following inequality proves useful in our analysis:\n",
        "$$\n",
        "\\Pr[d(v) \\leq (1 - \\beta)np] = O \\left( e^{-\\beta^2 np / 2} \\right)\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "The expected degree of a vertex $ v \\in V $ is $ np $.\n",
        "\n",
        "\n",
        "We want the probability of $ d(v) $ being too small to be $ o(1/n) $. Using the given inequality:\n",
        "$$\n",
        "\\Pr[d(v) \\leq (1 - \\beta)np] = O \\left( e^{-\\beta^2 np / 2} \\right)\n",
        "$$\n",
        "we need:\n",
        "$$\n",
        "O \\left( e^{-\\beta^2 np / 2} \\right) \\leq \\frac{1}{n}\n",
        "$$\n",
        "Taking the natural logarithm of both sides:\n",
        "$$\n",
        "-\\frac{\\beta^2 np}{2} \\leq -\\log n\n",
        "$$\n",
        "$$\n",
        "\\frac{\\beta^2 np}{2} \\geq \\log n\n",
        "$$\n",
        "$$\n",
        "np \\geq \\frac{2 \\log n}{\\beta^2}\n",
        "$$\n",
        "Choosing $\\beta = 1$, we get:\n",
        "$$\n",
        "p(n) \\geq \\frac{2 \\log n}{n}\n",
        "$$\n"
      ],
      "metadata": {
        "id": "J2fgbDL6v3cA"
      }
    }
  ]
}