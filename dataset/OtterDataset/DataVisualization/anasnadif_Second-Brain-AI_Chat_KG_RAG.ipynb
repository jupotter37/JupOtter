{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gOJp_QfYajVk"
   },
   "source": [
    "## Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T09:09:54.979882Z",
     "iopub.status.busy": "2024-02-29T09:09:54.979646Z",
     "iopub.status.idle": "2024-02-29T09:10:10.770528Z",
     "shell.execute_reply": "2024-02-29T09:10:10.769582Z",
     "shell.execute_reply.started": "2024-02-29T09:09:54.979859Z"
    },
    "id": "RKlVejzhyjgC"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T22:29:11.374066Z",
     "iopub.status.busy": "2024-02-28T22:29:11.373760Z",
     "iopub.status.idle": "2024-02-28T22:29:13.524655Z",
     "shell.execute_reply": "2024-02-28T22:29:13.523528Z",
     "shell.execute_reply.started": "2024-02-28T22:29:11.374035Z"
    },
    "id": "XArQuSWwyjgF"
   },
   "outputs": [],
   "source": [
    "pip install --index-url https://download.pytorch.org/whl/nightly/cu118 --pre 'torch==2.1.0.dev20230703'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T22:29:13.526335Z",
     "iopub.status.busy": "2024-02-28T22:29:13.526015Z",
     "iopub.status.idle": "2024-02-28T22:29:25.527810Z",
     "shell.execute_reply": "2024-02-28T22:29:25.526753Z",
     "shell.execute_reply.started": "2024-02-28T22:29:13.526295Z"
    },
    "id": "1tUYeEpxdk_R"
   },
   "outputs": [],
   "source": [
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T22:29:25.531621Z",
     "iopub.status.busy": "2024-02-28T22:29:25.530962Z",
     "iopub.status.idle": "2024-02-28T22:29:37.571667Z",
     "shell.execute_reply": "2024-02-28T22:29:37.570550Z",
     "shell.execute_reply.started": "2024-02-28T22:29:25.531587Z"
    },
    "id": "L13CC9--ZbmA"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T22:29:37.573614Z",
     "iopub.status.busy": "2024-02-28T22:29:37.573299Z",
     "iopub.status.idle": "2024-02-28T22:29:55.425994Z",
     "shell.execute_reply": "2024-02-28T22:29:55.425031Z",
     "shell.execute_reply.started": "2024-02-28T22:29:37.573584Z"
    },
    "id": "I5GKw-rb-s88"
   },
   "outputs": [],
   "source": [
    "!pip install pickle5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T22:29:55.428378Z",
     "iopub.status.busy": "2024-02-28T22:29:55.427589Z",
     "iopub.status.idle": "2024-02-28T22:29:56.138941Z",
     "shell.execute_reply": "2024-02-28T22:29:56.138216Z",
     "shell.execute_reply.started": "2024-02-28T22:29:55.428335Z"
    },
    "id": "huw4xXHvZj9b"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-02-28T22:29:56.140537Z",
     "iopub.status.busy": "2024-02-28T22:29:56.140194Z",
     "iopub.status.idle": "2024-02-28T22:29:58.221466Z",
     "shell.execute_reply": "2024-02-28T22:29:58.220507Z",
     "shell.execute_reply.started": "2024-02-28T22:29:56.140513Z"
    },
    "executionInfo": {
     "elapsed": 1279,
     "status": "ok",
     "timestamp": 1708884842330,
     "user": {
      "displayName": "gestion rattrapages",
      "userId": "05033612024752985563"
     },
     "user_tz": -60
    },
    "id": "M8uzA8o4xj-7",
    "outputId": "65cce7c1-e8cf-4848-aca0-828a3acd7f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T22:29:58.223476Z",
     "iopub.status.busy": "2024-02-28T22:29:58.222935Z",
     "iopub.status.idle": "2024-02-28T22:29:58.227925Z",
     "shell.execute_reply": "2024-02-28T22:29:58.227099Z",
     "shell.execute_reply.started": "2024-02-28T22:29:58.223439Z"
    },
    "id": "cT6Ca30w9z8f"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T22:29:58.229694Z",
     "iopub.status.busy": "2024-02-28T22:29:58.229377Z",
     "iopub.status.idle": "2024-02-28T22:30:05.032906Z",
     "shell.execute_reply": "2024-02-28T22:30:05.032140Z",
     "shell.execute_reply.started": "2024-02-28T22:29:58.229661Z"
    },
    "id": "dcOkEhdVyjgN"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer,AutoModel, pipeline\n",
    "# import math\n",
    "import torch\n",
    "import re\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T22:30:05.036629Z",
     "iopub.status.busy": "2024-02-28T22:30:05.036227Z",
     "iopub.status.idle": "2024-02-28T22:30:05.043744Z",
     "shell.execute_reply": "2024-02-28T22:30:05.042866Z",
     "shell.execute_reply.started": "2024-02-28T22:30:05.036604Z"
    },
    "id": "Ir8DzZkI-mXv"
   },
   "outputs": [],
   "source": [
    "import pickle5 as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T22:30:05.045163Z",
     "iopub.status.busy": "2024-02-28T22:30:05.044857Z",
     "iopub.status.idle": "2024-02-28T22:30:05.067942Z",
     "shell.execute_reply": "2024-02-28T22:30:05.067297Z",
     "shell.execute_reply.started": "2024-02-28T22:30:05.045132Z"
    },
    "id": "Y4a8ElmnyjgP"
   },
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"Your_open_ai_key\"\n",
    "client = OpenAI(api_key = OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTG4_dZt9nHZ"
   },
   "source": [
    "\n",
    "\n",
    "# KG embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.628162Z",
     "iopub.status.idle": "2024-02-28T22:30:27.628522Z",
     "shell.execute_reply": "2024-02-28T22:30:27.628366Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.628351Z"
    },
    "id": "X_aZov4D9rih"
   },
   "outputs": [],
   "source": [
    "# load graph object from file\n",
    "\n",
    "G_ex = pickle.load(open(\"KG.pickle\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.630327Z",
     "iopub.status.idle": "2024-02-28T22:30:27.630661Z",
     "shell.execute_reply": "2024-02-28T22:30:27.630513Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.630499Z"
    },
    "id": "0Z1Ej0jK_IyT"
   },
   "outputs": [],
   "source": [
    "# Load model from HuggingFace Hub\n",
    "\n",
    "tokenizer_e = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "model_e = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.632227Z",
     "iopub.status.idle": "2024-02-28T22:30:27.632527Z",
     "shell.execute_reply": "2024-02-28T22:30:27.632391Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.632378Z"
    },
    "id": "j8783k7c_KcE"
   },
   "outputs": [],
   "source": [
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.635444Z",
     "iopub.status.idle": "2024-02-28T22:30:27.635748Z",
     "shell.execute_reply": "2024-02-28T22:30:27.635605Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.635592Z"
    },
    "id": "Dn43KKnX-b1-"
   },
   "outputs": [],
   "source": [
    "def get_embedding_nodes(G_ex):\n",
    "\n",
    "    nodes = list(G_ex.nodes)\n",
    "    node_embeddings = {}\n",
    "    for node in nodes:\n",
    "\n",
    "        encoded_input = tokenizer_e(node, padding=True, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "\n",
    "            model_output = model_e(**encoded_input)\n",
    "        # Calculate mean pooling\n",
    "        sentence_embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        node_embeddings[node] = sentence_embedding\n",
    "\n",
    "    return node_embeddings\n",
    "\n",
    "def get_embedding_query(query_entities):\n",
    "\n",
    "    query_entities_embeddings = {}\n",
    "    for entity in query_entities:\n",
    "\n",
    "        encoded_input = tokenizer_e(entity, padding=True, return_tensors='pt')\n",
    "        with torch.no_grad():\n",
    "            model_output = model_e(**encoded_input)\n",
    "        # Calculate mean pooling\n",
    "        sentence_embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "        query_entities_embeddings[entity] = sentence_embedding\n",
    "\n",
    "    return query_entities_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.646167Z",
     "iopub.status.idle": "2024-02-28T22:30:27.646623Z",
     "shell.execute_reply": "2024-02-28T22:30:27.646407Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.646387Z"
    },
    "id": "vlrNQOusEpyn"
   },
   "outputs": [],
   "source": [
    "def calculate_similarity(query_entities_embeddings, node_embeddings):\n",
    "    similarities = {}\n",
    "    query_entities = query_entities_embeddings.keys()\n",
    "    for entity in query_entities:\n",
    "        query_embedding = query_entities_embeddings[entity]\n",
    "        for node in node_embeddings:\n",
    "            node_embedding = node_embeddings[node]\n",
    "            similarity = cosine_similarity(query_embedding.reshape(1, -1), node_embedding.reshape(1, -1))[0][0]\n",
    "            similarities[(entity, node)] = similarity\n",
    "    return similarities\n",
    "\n",
    "def retrieve_most_similar_nodes(query_entities_embeddings, node_embeddings, top_k=5):\n",
    "\n",
    "    similarities = calculate_similarity(query_entities_embeddings, node_embeddings)\n",
    "    sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "    unique_nodes = set()\n",
    "    for (entity, node), similarity in sorted_similarities:\n",
    "        unique_nodes.add(node)\n",
    "        if len(unique_nodes) >= top_k:\n",
    "            break\n",
    "\n",
    "    most_similar_nodes = list(unique_nodes)\n",
    "    # most_similar_nodes = [node for (entity, node), similarity in sorted_similarities[:top_k]]\n",
    "    return most_similar_nodes\n",
    "\n",
    "def traverse_graph(G_ex, node, depth=2):\n",
    "    triplets = []\n",
    "    if depth == 0:\n",
    "        return []\n",
    "    neighbors = list(G_ex.neighbors(node))\n",
    "    for neighbor in neighbors:\n",
    "        edge_data = G_ex.get_edge_data(node, neighbor)\n",
    "        triplet = (node, neighbor, edge_data)\n",
    "        triplets.append(triplet)\n",
    "        triplets.extend(traverse_graph(G_ex, neighbor, depth-1))\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.647594Z",
     "iopub.status.idle": "2024-02-28T22:30:27.648059Z",
     "shell.execute_reply": "2024-02-28T22:30:27.647824Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.647805Z"
    },
    "id": "Xy6lHKnSOTVg"
   },
   "outputs": [],
   "source": [
    "def organize_context_triplets(context_triplets):\n",
    "    organized_triplets = {}\n",
    "    for triplet in context_triplets:\n",
    "        entity1, entity2, edge_data = triplet\n",
    "        edge_title = list(edge_data.values())[0][\"title\"]\n",
    "        if entity1 not in organized_triplets:\n",
    "            organized_triplets[entity1] = []\n",
    "        organized_triplets[entity1].append((entity2, edge_title))\n",
    "    return organized_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.649701Z",
     "iopub.status.idle": "2024-02-28T22:30:27.650160Z",
     "shell.execute_reply": "2024-02-28T22:30:27.649935Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.649917Z"
    },
    "id": "SpONCJiCP9kn"
   },
   "outputs": [],
   "source": [
    "def organize_context_triplets(context_triplets):\n",
    "    organized_triplets = []\n",
    "    for triplet in context_triplets:\n",
    "        entity1, entity2, edge_data = triplet\n",
    "        edge_title = list(edge_data.values())[0][\"title\"]\n",
    "        organized_triplets.append((entity1, entity2, edge_title))\n",
    "    return organized_triplets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.639851Z",
     "iopub.status.idle": "2024-02-28T22:30:27.640181Z",
     "shell.execute_reply": "2024-02-28T22:30:27.640035Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.640021Z"
    },
    "id": "KAbQxfH8Du-a"
   },
   "outputs": [],
   "source": [
    "node_embeddings = get_embedding_nodes(G_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.656654Z",
     "iopub.status.idle": "2024-02-28T22:30:27.657120Z",
     "shell.execute_reply": "2024-02-28T22:30:27.656891Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.656872Z"
    },
    "id": "rbmuZZsgF9Di"
   },
   "outputs": [],
   "source": [
    "query_entities = extract_entities_from_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.659091Z",
     "iopub.status.idle": "2024-02-28T22:30:27.659520Z",
     "shell.execute_reply": "2024-02-28T22:30:27.659315Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.659296Z"
    },
    "id": "elmN1BJSE2_6"
   },
   "outputs": [],
   "source": [
    "query_entities_embeddings = get_embedding_query(query_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.660626Z"
    },
    "id": "pD7pg7EvKH0T"
   },
   "outputs": [],
   "source": [
    "query_entities_embeddings['Einstein die'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.idle": "2024-02-28T22:30:27.664933Z",
     "shell.execute_reply": "2024-02-28T22:30:27.664796Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.664783Z"
    },
    "id": "OChDXsVcJ0Mc"
   },
   "outputs": [],
   "source": [
    "# Step 3: Retrieve most similar nodes\n",
    "most_similar_nodes = retrieve_most_similar_nodes(query_entities_embeddings, node_embeddings, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.668068Z",
     "iopub.status.idle": "2024-02-28T22:30:27.668502Z",
     "shell.execute_reply": "2024-02-28T22:30:27.668298Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.668280Z"
    },
    "id": "vjnn_aLHKpjF"
   },
   "outputs": [],
   "source": [
    "context_triplets = []\n",
    "for node in most_similar_nodes:\n",
    "    context_triplets.extend(traverse_graph(G_ex, node, depth=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.669605Z",
     "iopub.status.idle": "2024-02-28T22:30:27.670072Z",
     "shell.execute_reply": "2024-02-28T22:30:27.669844Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.669825Z"
    },
    "id": "BBY-uE5YNZGm"
   },
   "outputs": [],
   "source": [
    "# Organize context triplets\n",
    "organized_triplets = organize_context_triplets(context_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.673265Z",
     "iopub.status.idle": "2024-02-28T22:30:27.674984Z",
     "shell.execute_reply": "2024-02-28T22:30:27.674825Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.674810Z"
    },
    "id": "iIOXGxN_QCIB"
   },
   "outputs": [],
   "source": [
    "len(organized_triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dau8dVFyyjhj"
   },
   "source": [
    "# Prompt preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T17:30:05.766128Z",
     "iopub.status.busy": "2024-02-28T17:30:05.765360Z",
     "iopub.status.idle": "2024-02-28T17:30:05.773861Z",
     "shell.execute_reply": "2024-02-28T17:30:05.772832Z",
     "shell.execute_reply.started": "2024-02-28T17:30:05.766094Z"
    },
    "id": "OHu2K4wTyjhk",
    "outputId": "a1f9d3b8-d33e-440f-a532-fa4f0c3c7873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def divide_into_chunks(lst, chunk_size):\n",
    "\n",
    "    return [lst[i:i+chunk_size] for i in range(0, len(lst), chunk_size)]\n",
    "\n",
    "\n",
    "chunk_size = 100\n",
    "result = divide_into_chunks(organized_triplets, chunk_size)\n",
    "len(result)\n",
    "\n",
    "def strings_response(text):\n",
    "    index = text.find(\"<|assistant|>\")\n",
    "    if index != -1:\n",
    "        return text[index + len(\"<|assistant|>\"):]\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "result = strings_response(text)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T17:30:05.775536Z",
     "iopub.status.busy": "2024-02-28T17:30:05.775155Z",
     "iopub.status.idle": "2024-02-28T17:30:05.806520Z",
     "shell.execute_reply": "2024-02-28T17:30:05.805552Z",
     "shell.execute_reply.started": "2024-02-28T17:30:05.775500Z"
    },
    "id": "zNLSbSZ3yjhl"
   },
   "outputs": [],
   "source": [
    "def triplets_to_sentences(organized_triplets):\n",
    "    sentences = []\n",
    "    for triplet in organized_triplets:\n",
    "        sentence = f\"{triplet[0]} {triplet[2]} {triplet[1]}\"\n",
    "        sentences.append(sentence)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T17:30:05.808254Z",
     "iopub.status.busy": "2024-02-28T17:30:05.807976Z",
     "iopub.status.idle": "2024-02-28T17:30:06.329052Z",
     "shell.execute_reply": "2024-02-28T17:30:06.327788Z",
     "shell.execute_reply.started": "2024-02-28T17:30:05.808231Z"
    },
    "id": "gJALKvZEyjhm"
   },
   "outputs": [],
   "source": [
    "sentence_embedder(query).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T17:51:13.207302Z",
     "iopub.status.busy": "2024-02-28T17:51:13.206337Z",
     "iopub.status.idle": "2024-02-28T17:51:13.215984Z",
     "shell.execute_reply": "2024-02-28T17:51:13.214966Z",
     "shell.execute_reply.started": "2024-02-28T17:51:13.207263Z"
    },
    "id": "YrOJzXu8yjhn"
   },
   "outputs": [],
   "source": [
    "def sentence_embedder(sentence) :\n",
    "    encoded_input = tokenizer_e(sentence, padding=True, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "\n",
    "        model_output = model_e(**encoded_input)\n",
    "        # Calculate mean pooling\n",
    "        sentence_embedding = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "    return sentence_embedding\n",
    "\n",
    "\n",
    "def sentences_embeddings(sentences):\n",
    "    sentence_embeddings = {}\n",
    "    for sentence in sentences :\n",
    "        sentence_embedding = sentence_embedder(sentence)\n",
    "        sentence_embeddings[sentence] = sentence_embedding\n",
    "\n",
    "    return sentence_embeddings\n",
    "\n",
    "def most_similar_sentences(sentences, query, top_k = 50):\n",
    "    query_embedding = sentence_embedder(query)\n",
    "    sentence_embeddings = sentences_embeddings(sentences)\n",
    "\n",
    "    similarities = {}\n",
    "    for sentence, embedding in sentence_embeddings.items():\n",
    "        similarity = cosine_similarity(embedding.numpy(), query_embedding.numpy())\n",
    "        similarities[sentence] = similarity\n",
    "\n",
    "    sorted_sentences = sorted(similarities.items(), key=lambda x: x[1], reverse=True)\n",
    "    sorted_sentences =  [u for u,v in sorted_sentences]\n",
    "    return sorted_sentences[:top_k ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T17:33:09.661785Z",
     "iopub.status.busy": "2024-02-28T17:33:09.661381Z",
     "iopub.status.idle": "2024-02-28T17:33:09.665926Z",
     "shell.execute_reply": "2024-02-28T17:33:09.665051Z",
     "shell.execute_reply.started": "2024-02-28T17:33:09.661739Z"
    },
    "id": "UzpZZi96yjho"
   },
   "outputs": [],
   "source": [
    "query = \"tell something about data science and albert einstein\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T17:39:54.598766Z",
     "iopub.status.busy": "2024-02-28T17:39:54.598007Z",
     "iopub.status.idle": "2024-02-28T17:39:54.606365Z",
     "shell.execute_reply": "2024-02-28T17:39:54.605486Z",
     "shell.execute_reply.started": "2024-02-28T17:39:54.598733Z"
    },
    "id": "FbqsH5hVyjhp"
   },
   "outputs": [],
   "source": [
    "def get_entity_from_query(query) :\n",
    "    prompt_content = \"Given a text, extract entities that one can use to search for node entities in an already existing knowledge graph, your only return should be a list of entities contained in the query, formatted as a string representation of a list like: entity1|entity2|... \"\n",
    "\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt_content,\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "    SYS_PROMPT = prompt_content\n",
    "    response = client.chat.completions.create(\n",
    "                  model=\"gpt-4-0125-preview\",\n",
    "                  messages = [\n",
    "                          {\n",
    "                              \"role\": \"system\",\n",
    "                              \"content\": SYS_PROMPT,\n",
    "                          },\n",
    "                          {\n",
    "                              \"role\": \"user\",\n",
    "                              \"content\": query\n",
    "                          }\n",
    "                      ]\n",
    "                )\n",
    "    result = response.choices[0].message.content\n",
    "    entities = result.split('|')\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T17:36:43.989955Z",
     "iopub.status.busy": "2024-02-28T17:36:43.989218Z",
     "iopub.status.idle": "2024-02-28T17:36:43.995465Z",
     "shell.execute_reply": "2024-02-28T17:36:43.994570Z",
     "shell.execute_reply.started": "2024-02-28T17:36:43.989922Z"
    },
    "id": "CKRDN9i5yjhr",
    "outputId": "92ca2730-4b2f-4003-c0a7-e9839f91dc2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data science', 'Albert Einstein']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = get_entity_from_query(query)\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-29T00:36:41.642486Z",
     "iopub.status.busy": "2024-02-29T00:36:41.642089Z",
     "iopub.status.idle": "2024-02-29T00:36:41.647008Z",
     "shell.execute_reply": "2024-02-29T00:36:41.646025Z",
     "shell.execute_reply.started": "2024-02-29T00:36:41.642459Z"
    },
    "id": "yH4figJ8yjhw"
   },
   "outputs": [],
   "source": [
    "prompt_content = \"respond to the queries of the user\"\n",
    "content = \"Give me a list containing visually appealing colors names in python \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T18:11:40.094595Z",
     "iopub.status.busy": "2024-02-28T18:11:40.094171Z",
     "iopub.status.idle": "2024-02-28T18:11:40.107763Z",
     "shell.execute_reply": "2024-02-28T18:11:40.106755Z",
     "shell.execute_reply.started": "2024-02-28T18:11:40.094562Z"
    },
    "id": "5XoTfXBpyjhz"
   },
   "outputs": [],
   "source": [
    "def answer_client(query):\n",
    "\n",
    "    query_entities = get_entity_from_query(query)\n",
    "\n",
    "    query_entities_embeddings = get_embedding_query(query_entities)\n",
    "\n",
    "    # Step 3: Retrieve most similar nodes\n",
    "    most_similar_nodes = retrieve_most_similar_nodes(query_entities_embeddings, node_embeddings, top_k=3)\n",
    "\n",
    "    context_triplets = []\n",
    "    for node in most_similar_nodes:\n",
    "        context_triplets.extend(traverse_graph(G_ex, node, depth=2))\n",
    "\n",
    "    # Organize context triplets\n",
    "    organized_triplets = organize_context_triplets(context_triplets)\n",
    "\n",
    "    sentences = triplets_to_sentences(organized_triplets)\n",
    "    sentences = most_similar_sentences(sentences, query, top_k = 50)\n",
    "\n",
    "    # FINAL PROMPT\n",
    "\n",
    "    prompt_content = (\n",
    "    \"Welcome! You are an AI chatbot designed to provide answers based on the provided context. \"\n",
    "    \"The context consists of sentences generated from a knowledge graph that came from notes of the user. \"\n",
    "    \"Think of this context as your second brain, a repository of information to draw from when answering questions. \"\n",
    "    \"Your task is to answer user queries based on this context if they are needed in the answer.\\n\\n\"\n",
    "    \"Here is your second brain, containing the accumulated knowledge:\\n\\n\"\n",
    "    f\"{sentences}\\n\\n\"\n",
    "    \"Feel free to start answering user queries.\"\n",
    "    )\n",
    "\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": prompt_content,\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "    ]\n",
    "    SYS_PROMPT = prompt_content\n",
    "    response = client.chat.completions.create(\n",
    "                  model=\"gpt-4-0125-preview\",\n",
    "                  messages = [\n",
    "                          {\n",
    "                              \"role\": \"system\",\n",
    "                              \"content\": SYS_PROMPT,\n",
    "                          },\n",
    "                          {\n",
    "                              \"role\": \"user\",\n",
    "                              \"content\": query\n",
    "                          }\n",
    "                      ]\n",
    "                )\n",
    "    result = response.choices[0].message.content\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbDfDwjpyjh1"
   },
   "outputs": [],
   "source": [
    "#example0\n",
    "st = time.time()\n",
    "query = \"Who are you ?\"\n",
    "response = answer_client(query)\n",
    "et = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T18:11:50.784017Z",
     "iopub.status.busy": "2024-02-28T18:11:50.783375Z",
     "iopub.status.idle": "2024-02-28T18:11:50.789796Z",
     "shell.execute_reply": "2024-02-28T18:11:50.788820Z",
     "shell.execute_reply.started": "2024-02-28T18:11:50.783978Z"
    },
    "id": "dCqiIr_Byjh2",
    "outputId": "e4c790a7-6ca8-47b5-e027-e0b5838f175f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am an AI chatbot designed to assist you by providing answers based on a specific set of information given to me, which I refer to as my \"second brain\". This includes various facts and connections across different topics, such as foundations of data science, measures of central tendency, Einstein\\'s mass-energy equivalence formula, and more. I\\'m here to help answer your questions using this information.'"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T18:13:51.153426Z",
     "iopub.status.busy": "2024-02-28T18:13:51.152560Z",
     "iopub.status.idle": "2024-02-28T18:14:03.805321Z",
     "shell.execute_reply": "2024-02-28T18:14:03.804513Z",
     "shell.execute_reply.started": "2024-02-28T18:13:51.153385Z"
    },
    "id": "kTOToTrjyjh3"
   },
   "outputs": [],
   "source": [
    "#example1\n",
    "st = time.time()\n",
    "query = \"When did Albert Einstein die ?\"\n",
    "response = answer_client(query)\n",
    "et = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T18:15:00.833628Z",
     "iopub.status.busy": "2024-02-28T18:15:00.832834Z",
     "iopub.status.idle": "2024-02-28T18:15:00.838652Z",
     "shell.execute_reply": "2024-02-28T18:15:00.837556Z",
     "shell.execute_reply.started": "2024-02-28T18:15:00.833595Z"
    },
    "id": "-kVEet1Pyjh4",
    "outputId": "ea948977-e5d6-4f3a-f188-267b1a4d8098"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed 12.647762537002563\n",
      "Response : \n",
      " Albert Einstein died on 1955-04-18.\n"
     ]
    }
   ],
   "source": [
    "print(\"Time elapsed\",et - st)\n",
    "print(\"Response : \\n\",response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eExwtIqAyjh5"
   },
   "outputs": [],
   "source": [
    "# example2\n",
    "st = time.time()\n",
    "query = \"Who wrote the cosmological paper\"\n",
    "response = answer_client(query)\n",
    "et = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T18:17:11.746544Z",
     "iopub.status.busy": "2024-02-28T18:17:11.745658Z",
     "iopub.status.idle": "2024-02-28T18:17:11.751189Z",
     "shell.execute_reply": "2024-02-28T18:17:11.750305Z",
     "shell.execute_reply.started": "2024-02-28T18:17:11.746506Z"
    },
    "id": "hxtw8vniyjh6",
    "outputId": "3a9c4ccc-3c29-469d-e3d5-a7ff67086228"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed 5.546705722808838\n",
      "Response : \n",
      " Albert Einstein wrote the cosmological paper. This is indicated by the multiple references to Einstein's contributions to the field, particularly his work on the general theory of relativity and its implications for the modeling of the structure and evolution of the universe. His influential work in 1905, often referred to as his \"annus mirabilis\" or miracle year, laid significant groundwork for modern cosmological theories and papers.\n"
     ]
    }
   ],
   "source": [
    "print(\"Time elapsed\",et - st)\n",
    "print(\"Response : \\n\",response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oXP2WOatyjh9"
   },
   "outputs": [],
   "source": [
    "# example3\n",
    "st = time.time()\n",
    "query = \"What open source libraries have i seen \"\n",
    "response = answer_client(query)\n",
    "et = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T18:18:18.218238Z",
     "iopub.status.busy": "2024-02-28T18:18:18.217739Z",
     "iopub.status.idle": "2024-02-28T18:18:18.226895Z",
     "shell.execute_reply": "2024-02-28T18:18:18.225929Z",
     "shell.execute_reply.started": "2024-02-28T18:18:18.218205Z"
    },
    "id": "doljFIenyjh8",
    "outputId": "305ac65a-c99e-4e48-97bf-916a62292a24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed 8.505751848220825\n",
      "Response : \n",
      " Based on your notes, you've mentioned several open-source libraries, particularly in the context of data visualization. You have referenced the following open-source libraries:\n",
      "\n",
      "- Matplotlib\n",
      "- Seaborn\n",
      "- Plotly\n",
      "- ggplot\n",
      "\n",
      "These libraries are related to open-source and open-source software libraries, and they provide rich functionalities for data visualization in Python.\n"
     ]
    }
   ],
   "source": [
    "print(\"Time elapsed\",et - st)\n",
    "print(\"Response : \\n\",response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-6GzDCa7fns"
   },
   "source": [
    "# Extract_entities_without_openAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T22:30:05.069326Z",
     "iopub.status.busy": "2024-02-28T22:30:05.069075Z",
     "iopub.status.idle": "2024-02-28T22:30:27.610394Z",
     "shell.execute_reply": "2024-02-28T22:30:27.607221Z",
     "shell.execute_reply.started": "2024-02-28T22:30:05.069303Z"
    },
    "id": "w-E86e2dZlmz"
   },
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.611129Z",
     "iopub.status.idle": "2024-02-28T22:30:27.611468Z",
     "shell.execute_reply": "2024-02-28T22:30:27.611321Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.611306Z"
    },
    "id": "1uf9Qaw4Zm6v"
   },
   "outputs": [],
   "source": [
    "# from https://huggingface.co/Babelscape/rebel-large\n",
    "def extract_relations_from_model_output(text):\n",
    "    relations = []\n",
    "    relation, subject, relation, object_ = '', '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    text_replaced = text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\")\n",
    "    for token in text_replaced.split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                relations.append({\n",
    "                    'head': subject.strip(),\n",
    "                    'type': relation.strip(),\n",
    "                    'tail': object_.strip()\n",
    "                })\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                relations.append({\n",
    "                    'head': subject.strip(),\n",
    "                    'type': relation.strip(),\n",
    "                    'tail': object_.strip()\n",
    "                })\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        relations.append({\n",
    "            'head': subject.strip(),\n",
    "            'type': relation.strip(),\n",
    "            'tail': object_.strip()\n",
    "        })\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.613167Z",
     "iopub.status.idle": "2024-02-28T22:30:27.613529Z",
     "shell.execute_reply": "2024-02-28T22:30:27.613362Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.613349Z"
    },
    "id": "5GRAsz6BZvfH"
   },
   "outputs": [],
   "source": [
    "# knowledge base class\n",
    "class KB():\n",
    "    def __init__(self):\n",
    "        self.relations = []\n",
    "\n",
    "    def are_relations_equal(self, r1, r2):\n",
    "        return all(r1[attr] == r2[attr] for attr in [\"head\", \"type\", \"tail\"])\n",
    "\n",
    "    def exists_relation(self, r1):\n",
    "        return any(self.are_relations_equal(r1, r2) for r2 in self.relations)\n",
    "\n",
    "    def add_relation(self, r):\n",
    "        if not self.exists_relation(r):\n",
    "            self.relations.append(r)\n",
    "\n",
    "    def print(self):\n",
    "        print(\"Relations:\")\n",
    "        for r in self.relations:\n",
    "            print(f\"  {r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.615050Z",
     "iopub.status.idle": "2024-02-28T22:30:27.615423Z",
     "shell.execute_reply": "2024-02-28T22:30:27.615263Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.615249Z"
    },
    "id": "7WZ4OhTQZwgP"
   },
   "outputs": [],
   "source": [
    "# build a knowledge base from text\n",
    "def from_small_text_to_kb(text, verbose=False):\n",
    "    kb = KB()\n",
    "\n",
    "    # Tokenizer text\n",
    "    model_inputs = tokenizer(text, max_length=512, padding=True, truncation=True,\n",
    "                            return_tensors='pt')\n",
    "    if verbose:\n",
    "        print(f\"Num tokens: {len(model_inputs['input_ids'][0])}\")\n",
    "\n",
    "    # Generate\n",
    "    gen_kwargs = {\n",
    "        \"max_length\": 216,\n",
    "        \"length_penalty\": 0,\n",
    "        \"num_beams\": 3,\n",
    "        \"num_return_sequences\": 3\n",
    "    }\n",
    "    generated_tokens = model.generate(\n",
    "        **model_inputs,\n",
    "        **gen_kwargs,\n",
    "    )\n",
    "    decoded_preds = tokenizer.batch_decode(generated_tokens, skip_special_tokens=False)\n",
    "\n",
    "    # create kb\n",
    "    for sentence_pred in decoded_preds:\n",
    "        relations = extract_relations_from_model_output(sentence_pred)\n",
    "        for r in relations:\n",
    "            kb.add_relation(r)\n",
    "\n",
    "    return kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.618002Z",
     "iopub.status.idle": "2024-02-28T22:30:27.618340Z",
     "shell.execute_reply": "2024-02-28T22:30:27.618184Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.618170Z"
    },
    "id": "4h-9JbZKxmUD"
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(text)\n",
    "    filtered_text = [word for word in word_tokens if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_text)\n",
    "\n",
    "text = \"When did Albert Einstein die?\"\n",
    "filtered_text = remove_stopwords(text)\n",
    "print(filtered_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.619906Z",
     "iopub.status.idle": "2024-02-28T22:30:27.620343Z",
     "shell.execute_reply": "2024-02-28T22:30:27.620154Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.620139Z"
    },
    "id": "9QmePyMG0fIX"
   },
   "outputs": [],
   "source": [
    "def extract_entities_from_query(query):\n",
    "  filtered_text = remove_stopwords(text)\n",
    "  kb = from_small_text_to_kb(filtered_text, verbose=True)\n",
    "  entities = []\n",
    "  for relation in kb.relations:\n",
    "      entities.extend(relation['head'].split())  # Split the head entity into individual words\n",
    "      entities.extend(relation['tail'].split())  # Split the tail entity into individual words\n",
    "\n",
    "  entities = set(filter(lambda x: x.strip(), entities))\n",
    "\n",
    "  return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.621523Z",
     "iopub.status.idle": "2024-02-28T22:30:27.621858Z",
     "shell.execute_reply": "2024-02-28T22:30:27.621709Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.621694Z"
    },
    "id": "tWgMmu85GYQB"
   },
   "outputs": [],
   "source": [
    "extract_entities_from_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.623499Z",
     "iopub.status.idle": "2024-02-28T22:30:27.623836Z",
     "shell.execute_reply": "2024-02-28T22:30:27.623680Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.623666Z"
    },
    "id": "-VczAMRDI4Qu"
   },
   "outputs": [],
   "source": [
    "def extract_entities_from_query(query):\n",
    "  entities = []\n",
    "  entity_set = set()\n",
    "  filtered_text = remove_stopwords(query)\n",
    "  kb = from_small_text_to_kb(filtered_text, verbose=True)\n",
    "\n",
    "  for relation in kb.relations:\n",
    "      head = relation['head']\n",
    "      tail = relation['tail']\n",
    "      # Split the entities into individual words\n",
    "      head_words = set(head.split())\n",
    "      tail_words = set(tail.split())\n",
    "\n",
    "      # Calculate intersection and union of words\n",
    "      intersection = head_words.intersection(tail_words)\n",
    "      union = head_words.union(tail_words)\n",
    "\n",
    "      # Calculate IOU score\n",
    "      iou_score = len(intersection) / len(union)\n",
    "\n",
    "      # Add entity to the set if IOU score is below a certain threshold (e.g., 0.5)\n",
    "      if iou_score < 0.5:\n",
    "          entity_set.add(head)\n",
    "          entity_set.add(tail)\n",
    "\n",
    "  # Convert set to list\n",
    "  entities = list(entity_set)\n",
    "\n",
    "  return entities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-28T22:30:27.626166Z",
     "iopub.status.idle": "2024-02-28T22:30:27.626505Z",
     "shell.execute_reply": "2024-02-28T22:30:27.626359Z",
     "shell.execute_reply.started": "2024-02-28T22:30:27.626344Z"
    },
    "id": "-91vzDSQJZo3"
   },
   "outputs": [],
   "source": [
    "extract_entities_from_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AyeftWGRp8S"
   },
   "source": [
    "# Prompt with zephyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T22:16:29.104040Z",
     "iopub.status.busy": "2024-02-26T22:16:29.103136Z",
     "iopub.status.idle": "2024-02-26T22:16:29.108701Z",
     "shell.execute_reply": "2024-02-26T22:16:29.107628Z",
     "shell.execute_reply.started": "2024-02-26T22:16:29.104004Z"
    },
    "id": "KdcI81CGyjhd"
   },
   "outputs": [],
   "source": [
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T07:46:37.423817Z",
     "iopub.status.busy": "2024-02-26T07:46:37.422916Z",
     "iopub.status.idle": "2024-02-26T07:46:37.431598Z",
     "shell.execute_reply": "2024-02-26T07:46:37.430389Z",
     "shell.execute_reply.started": "2024-02-26T07:46:37.423769Z"
    },
    "id": "JmHNjTi_yjhh"
   },
   "outputs": [],
   "source": [
    "# Prepare the prompt content with introduction and context\n",
    "prompt_content = (\n",
    "    \"Introduction:\\n\\n\"\n",
    "    \"You are a chatbot designed to generate responses based on context from a knowledge graph. \"\n",
    "    \"The context is provided in the form of triplets (entity1, entity2, relation), representing \"\n",
    "    \"relationships between entities in the knowledge graph.\\n\\n\"\n",
    "    \"Context:\\n\\n\"\n",
    ")\n",
    "for idx, triplet in enumerate(organized_triplets, start=1):\n",
    "    entity1, entity2, edge = triplet\n",
    "    prompt_content += f\"{idx}. ({entity1}, {entity2}, {edge})\\n\"\n",
    "prompt_content += \"\\nGiven this context, respond to the following query:\\n\\n\"\n",
    "prompt_content += query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T18:28:23.238121Z",
     "iopub.status.busy": "2024-02-26T18:28:23.237814Z",
     "iopub.status.idle": "2024-02-26T18:28:23.476410Z",
     "shell.execute_reply": "2024-02-26T18:28:23.475550Z",
     "shell.execute_reply.started": "2024-02-26T18:28:23.238094Z"
    },
    "id": "2LGd4xptyjhe"
   },
   "outputs": [],
   "source": [
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-26T23:13:48.517193Z",
     "iopub.status.busy": "2024-02-26T23:13:48.516823Z",
     "iopub.status.idle": "2024-02-26T23:13:55.948343Z",
     "shell.execute_reply": "2024-02-26T23:13:55.947388Z",
     "shell.execute_reply.started": "2024-02-26T23:13:48.517165Z"
    },
    "id": "vg5Uw7ZoyjiE"
   },
   "outputs": [],
   "source": [
    "#zephyr\n",
    "# Generate response\n",
    "outputs = pipe(prompt, max_new_tokens=256, do_sample=True, temperature=0.7, top_k=50, top_p=0.95)\n",
    "print(strings_response(outputs[0][\"generated_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T15:29:42.598923Z",
     "iopub.status.busy": "2024-02-28T15:29:42.597936Z",
     "iopub.status.idle": "2024-02-28T15:29:42.604852Z",
     "shell.execute_reply": "2024-02-28T15:29:42.603864Z",
     "shell.execute_reply.started": "2024-02-28T15:29:42.598876Z"
    },
    "id": "-u2_eTgGyjiB",
    "outputId": "d439256b-f9a4-4f89-e186-f74a5a05443f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'With the help of your second brain, Albert Einstein died on 1955-04-18.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "gOJp_QfYajVk",
    "Dau8dVFyyjhj",
    "w-6GzDCa7fns",
    "7AyeftWGRp8S"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4496659,
     "sourceId": 7702838,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
