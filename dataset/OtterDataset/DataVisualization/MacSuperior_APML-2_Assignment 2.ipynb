{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Predictive Process Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Due: Friday, 15 December, 2023 at 14:00 CET*\n",
    "\n",
    "In this assignment, you will learn to use several regression models to predict the process remaining time. In addition, you will also show that you can evaluate their performance and discuss the results in a report. The learning objectives of this assignment are: \n",
    "\n",
    "- use the data aggregation, feature encoding, and data transformation techniques to preprocess event data\n",
    "- use the regression models to predict the remaining time of ongoing cases. \n",
    "- perform cross validation and fine-tune the model parameters of each algorithm\n",
    "- calculate model performance (e.g., MAE, MSE, RMSE, R^2, etc.)\n",
    "- design experiments to compare the performance of algorithms\n",
    "- reflect on the difference between different models\n",
    "\n",
    "\n",
    "This assignment includes two algorithms: Regression Tree (or Random Forest Regression) and kNN regressor. Following a similar structure as the first assignment, your first task is to perform data exploration and data cleaning. \n",
    "In Task 2, you will perform two trace encoding techniques (covered during Lecture 07). \n",
    "In Task 3-4, you will use the two algorithms to learn regression models to forecast the remaining time of each case after each event. \n",
    "In Task 5, you will compare the algorithms and evaluate their results. \n",
    "\n",
    "Please note that Task 3 and 4 have the following structure:\n",
    "1. First, find the library (e.g., sklearn examples) and try out the algorithm by simply training the model on the training data (do not consider any parameters or cross validation just yet); \n",
    "2. Train the model with the training data by using cross validation and find the best parameter setting for the parameters of interest;\n",
    "3. Report the average MAE, MSE, RMSE, and R^2 of all validation sets;\n",
    "4. Finally, test the optimal model that has the best fitting parameters on your held-out test data, and report its MAE, MSE, RMSE, and R^2. \n",
    "\n",
    "Note that, in Task 5, you will need all the calculated MAE, MSE, RMSE, and R^2 on both encoded data from previous tasks. Make sure you save these to a list or dictionary so you can easily evaluate and compare the results. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Exploring the data set\n",
    "\n",
    "\n",
    "\n",
    "### Data set: Sepsis\n",
    "\n",
    "Import the file *sepsis.csv* to load the Sepsis data set. This real-life event log contains events of sepsis cases from a hospital. Sepsis is a life threatening condition typically caused by an infection. One case represents a patient's pathway through the treatment process. The events were recorded by the ERP (Enterprise Resource Planning) system of the hospital. The original data set contains about 1000 cases with in total 15,000 events that were recorded for 16 different activities. Moreover, 39 data attributes are recorded, e.g., the group responsible for the activity, the results of tests and information from checklists. \n",
    "\n",
    "Additional information about the data can be found :\n",
    "- https://data.4tu.nl/articles/dataset/Sepsis_Cases_-_Event_Log/12707639\n",
    "- http://ceur-ws.org/Vol-1859/bpmds-08-paper.pdf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sepsis = pd.read_csv(\"./sepsis.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sepsis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sepsis.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sepsis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_sepsis['Case ID'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 Exploratory data analysis\n",
    "\n",
    "For the data set, create 2-3 figures and tables that help you understand the data \n",
    "\n",
    "**Use the column \"remtime\" (which indicates the remaining time of each case after each corresponding event) as the response variable for regression**\n",
    "\n",
    "Note that some of these variables are categorical variables. How would you preprocess these variables?\n",
    "\n",
    "\n",
    "#### Tips: ---------------\n",
    "\n",
    "During the data exploration, you, as a team, are trying to get an impression of the data. You will create figures and/or tables that help you to get to know the data. While exploring the data, you may also consider answering the following questions, which may help you understand the data better. For example, \n",
    "\n",
    "- How many variables are in the data? What are the data type and the distribution of each variable? \n",
    "- What is the discribution of the response variable?\n",
    "- Are the variables informative?\n",
    "- Are any pair of the potential predictor variables highly correlated?\n",
    "- (Should the variables be normalized or not?)\n",
    "- (Any relevant, useful preprocessing steps that may be taken?)\n",
    "\n",
    "\n",
    "\n",
    "Make sure to at least check the data type of each variable and to understand the distribution of each variable, especially the response variable. \n",
    "\n",
    "Try to find out what factors seem to determine whether an instance is an outlier or not. What do you conclude?\n",
    "\n",
    "*For creating data visualizations, you may consider using the matplot library and visit the [matplot gallery](https://matplotlib.org/stable/gallery/index.html) for inspiration (e.g., histograms for distribution, or heatmaps for feature correlation).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# TODO: plot figure(s)\n",
    "\n",
    "# Get mean remtime per activity\n",
    "remtime_per_activity = data_sepsis.groupby(\"Activity\", as_index = False)[\"remtime\"].mean()\n",
    "sorted_remtime_per_activity = remtime_per_activity.sort_values(\"remtime\", ascending = False)\n",
    "\n",
    "plt.figure(figsize = (10,5))\n",
    "plt.bar(sorted_remtime_per_activity[\"Activity\"], sorted_remtime_per_activity[\"remtime\"], align = \"center\", width = 0.6)\n",
    "plt.title(\"Average remtime per last activity\")\n",
    "plt.xlabel(\"Activity\")\n",
    "plt.ylabel(\"Remaining time\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fig(df, x, y, title, xlabel, ylabel):\n",
    "    plt.bar(df[x], df[y])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "for col in [\"Hypotensie\", \"Oligurie\", \"Hypoxie\", \"Infusion\", \"DisfuncOrg\"]:\n",
    "    data_without_missing = data_sepsis.drop(data_sepsis[data_sepsis[col] == \"missing\"].index)\n",
    "    \n",
    "    data_group = pd.DataFrame(data_without_missing.groupby(col, as_index = False)[\"remtime\"].mean())\n",
    "    title = f\"Remtime difference in {col}\"\n",
    "    xlabel = col\n",
    "    ylabel = \"remtime\"\n",
    "    plot_fig(df=data_group, x=col, y=\"remtime\", title=title, xlabel=xlabel, ylabel=ylabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Data cleaning\n",
    "\n",
    "You have now gathered some information about the data during the data exploration task. You also know from the assignment description that you will be using regression trees and kNN regression models to predict the remaining time.\n",
    "\n",
    "Based on the above information, decide on which cleaning steps you will need to perform and implement them accordingly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sepsis = pd.read_csv(\"./sepsis.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_to_bool(df_row: pd.Series):\n",
    "    df_row.replace({'True': 1, 'False': 0, 'missing': np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in data_sepsis:\n",
    "    object_to_bool(data_sepsis[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sepsis['Complete Timestamp'] = pd.to_datetime(data_sepsis['Complete Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = data_sepsis.sort_values(by=\"Complete Timestamp\")\n",
    "df_sorted.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.groupby(by=\"Case ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "encoder = OrdinalEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis = df_sorted.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded = pd.get_dummies(df_analysis[['Diagnose', 'org:group']], prefix=['Diagnose=', 'org:group='])\n",
    "for col in df_encoded.columns:\n",
    "    df_encoded[col].replace({True: 1, False: 0}, inplace=True)\n",
    "df_analysis = pd.concat([df_analysis, df_encoded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis['Complete Timestamp'] = encoder.fit_transform(df_analysis['Complete Timestamp'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_cols = ['CRP', 'LacticAcid', 'Leucocytes', 'duration', 'month', 'weekday', 'hour', 'remtime', 'elapsed', 'Complete Timestamp', \"Age\"]\n",
    "df_analysis[scale_cols] = scaler.fit_transform(df_analysis[scale_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.drop(columns=['Diagnose', 'org:group'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_analysis.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activity to be encoded in task 2\n",
    "# Case ID is not dropped so it can be used for visualizations and grouping. It is dropped before handing data to models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.3 Process Discovery and Visualization (Optional)\n",
    "\n",
    "This is an optional task to show you how process discovery and visualizaion can be deployed using the pm4py library. \n",
    "\n",
    "(*The following code requires the graphviz library to be installed. If you have issues with installing the graphviz, you may try to follow the instructions on Install GraphViz on the [pm4py](https://pm4py.fit.fraunhofer.de/install-page) install page*)\n",
    "\n",
    "The following code:\n",
    "- fill in the columns for case id, activity, and timestamps\n",
    "- convert the data set into an event log\n",
    "- discover a Directly-follows graph (DFG) and a process model for each event log. \n",
    "- you may use the discovered process model in your report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Preprocessing and Trace Encoding\n",
    "\n",
    "\n",
    "### 2.1 Trace Encoding\n",
    "\n",
    "\n",
    "- Implement the last-2-state encoding for the data set \n",
    "- Implement the aggregated encoding for the data set (for example, see [1], Table 6)\n",
    "\n",
    "\n",
    "<span style=\"color:gray\">[1] Ilya Verenich, Marlon Dumas, Marcello La Rosa, Fabrizio Maria Maggi, Irene Teinemaa:\n",
    "Survey and Cross-benchmark Comparison of Remaining Time Prediction Methods in Business Process Monitoring. ACM Trans. Intell. Syst. Technol. 10(4): 34:1-34:34 (2019) [Section 1, 2, 4.1, 4.3, 4.6, 5.2, 5.3, 5.4, and 6] </span>\n",
    "\n",
    "These two encodings are discussed during lecture 7.\n",
    "In case you find difficult to implement the algorithms, you may also consider use the pandas functions to help you:\n",
    "- for the last-2-state encoding, check the pandas groupby.DataFrameGroupBy.shift and see the [answer on the stake overflow](https://stackoverflow.com/questions/53335567/use-pandas-shift-within-a-group)\n",
    "- for the aggregated encoding check the pandas groupby.DataFrameGroupBy and cumsum function and read the [examples and answers on the stake overflow](https://stackoverflow.com/a/49578219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the function that returns the last-state encoding of a log\n",
    "def last_2_state_encoding(_data, columncase, columnactivity):\n",
    "    _data.groupby(by = columncase)\n",
    "    df_sorted = _data.copy()\n",
    "    df_sorted['prev_activity'] = np.where(df_sorted[columncase] == df_sorted[columncase].shift(1), df_sorted[columnactivity].shift(1), None)\n",
    "    df_sorted['prev_2_activity'] = np.where(df_sorted[columncase] == df_sorted[columncase].shift(2), df_sorted[columnactivity].shift(2), None)\n",
    "    df_sorted = df_sorted.drop(columns = [columnactivity])\n",
    "    return df_sorted\n",
    "\n",
    "def onehotencoder(data: pd.DataFrame, columns: list):\n",
    "    ohcdata = pd.get_dummies(data, columns = columns)\n",
    "    for col in ohcdata.columns:\n",
    "        ohcdata[col].replace({True: 1, False: 0}, inplace=True)\n",
    "    \n",
    "    return ohcdata\n",
    "    \n",
    "data_sepsis_ls = last_2_state_encoding(df_analysis, \"Case ID\", \"Activity\")\n",
    "data_sepsis_ls = onehotencoder(data = data_sepsis_ls, columns = [\"prev_activity\", \"prev_2_activity\"])\n",
    "data_sepsis_ls = data_sepsis_ls.drop(columns = [\"Case ID\"])\n",
    "data_sepsis_ls.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sepsis_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sepsis_ls.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the function that returns the aggregated state encoding of a log\n",
    "target_columns = ['act_CRP', 'act_ER Registration', 'act_ER Sepsis Triage', 'act_ER Triage', 'act_LacticAcid', 'act_Leucocytes']\n",
    "\n",
    "def agg_state_encoding(_data: pd.DataFrame, columncase, columnactivity):\n",
    "    df_aggstate = pd.get_dummies(_data, prefix='act', columns=[columnactivity])\n",
    "    df_aggstate[target_columns] = df_aggstate.groupby(by=columncase)[target_columns].cumsum()\n",
    "    return df_aggstate\n",
    "\n",
    "# TODO: for each of the two data sets, create a last_2_state encoding and an aggregated state encoding\n",
    "data_sepsis_ag = agg_state_encoding(df_analysis, \"Case ID\", \"Activity\")\n",
    "data_sepsis_ag = data_sepsis_ag.drop(columns = [\"Case ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sepsis_ag.dropna(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Create Training and Held-out test data sets\n",
    "\n",
    "\n",
    "Create a training and a held-out test data set. *Later in Task 3-4, the training data will be used to perform cross-validation. The held-out test data will be used to evaluate the performance of the selected models.*\n",
    "\n",
    "Choose the size of your test data. Furthermore, how did you split the data? Motivate your choice when you discuss the experiment setup in your report. \n",
    "\n",
    "\n",
    "\n",
    "Tips: *You may consider reuse some of your code from Assignment 1 Task 1.2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data and held-out test data for *data_sepsis_ls*\n",
    "X = data_sepsis_ls.drop(columns=['remtime'])\n",
    "y = data_sepsis_ls['remtime']\n",
    "\n",
    "X_lstrain, X_lstest, y_lstrain, y_lstest = train_test_split(X, y, test_size=0.30, random_state=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data and held-out test data for *data_sepsis_ag*\n",
    "X = data_sepsis_ag.drop(columns=['remtime'])\n",
    "y = data_sepsis_ag['remtime']\n",
    "\n",
    "X_agtrain, X_agtest, y_agtrain, y_agtest = train_test_split(X, y, test_size=0.30, random_state=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Predicting Case Remaining Time - Regression Trees\n",
    "\n",
    "\n",
    "In this task, you will use the regression tree (or random forest regression if you prefer) to learn a regression model to predict case remaining time. Very similar to how you have trained a classification model in Assignment 1, now perform the following steps to train a regression model. \n",
    "\n",
    "i) use the default values for the parameters to get a [Regression Tree](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor) (or a [Random Forest Regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)) running on the training data. (*Optional: visualize the tree, the feature importance, and compute the error measures to get an impression of the performance of the model*).\n",
    "\n",
    "ii) use 5-fold cross-validation to determine a possibly better choice for the two parameters *min_samples_leaf* and *max_depth*\n",
    "    \n",
    "iii) create 2D or 3D plot that shows how the selected parameters affect the performance. \n",
    "\n",
    "iv) select the best-performing regression tree (or forest), i.e., the one that achieved the lowest cross-validated errors, and report all the error measures (MAE, MSE, RMSE, R^2) of the fitted model on the held-out test data. \n",
    "\n",
    "    \n",
    "#### TIPS:\n",
    "You may consider reuse the some of your code of Assignment 1 or use the [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) class (see an [example](https://www.dezyre.com/recipes/find-optimal-parameters-using-gridsearchcv-for-regression), but be aware that GridSearchSV does not return MAE or the other error measures (e.g., MSE, RMSE, R^2), you will need to update the scoring function)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, make_scorer\n",
    "\n",
    "# define scorers\n",
    "mae_scorer = make_scorer(mean_absolute_error)\n",
    "mse_scorer = make_scorer(mean_squared_error)\n",
    "rmse_scorer = make_scorer(lambda y_true, y_pred: np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "r2_scorer = make_scorer(r2_score)\n",
    "\n",
    "# define dictionary of scorers\n",
    "scorers = {\n",
    "    'MAE': mae_scorer,\n",
    "    'MSE': mse_scorer,\n",
    "    'RMSE': rmse_scorer,\n",
    "    'R2': r2_scorer\n",
    "}\n",
    "\n",
    "# define variables for upcoming functions\n",
    "main_scorer = 'MAE'\n",
    "main_test = f'mean_test_{main_scorer}'\n",
    "\n",
    "# define function for score retrieval\n",
    "def measure_performance(y_test, y_pred):\n",
    "    return [mean_absolute_error(y_test, y_pred), mean_squared_error(y_test, y_pred), np.sqrt(mean_squared_error(y_test, y_pred)), r2_score(y_test, y_pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import packages\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set the search space of the parameters *min_samples_leaf* and *max_depth*\n",
    "dtr_params = {\n",
    "    'min_samples_leaf': [1, 2, 4, 8, 16, 32, 64],\n",
    "    'max_depth': [1, 2, 4, 8, 16, 32, 64, None]\n",
    "}\n",
    "\n",
    "# TODO: create 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# TODO: learn an optimal regression tree model (random forest regressor)\n",
    "dtr = DecisionTreeRegressor(random_state=0)\n",
    "dtr_ls_optimized = GridSearchCV(dtr, dtr_params, scoring=scorers, refit=main_scorer, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "dtr_ls_optimized.fit(X_lstrain, y_lstrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create 2D or 3D plot that shows how the selected parameter values affect the MAE (or RMSE). \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a dataframe from the grid search results\n",
    "dtr_ls_results = pd.DataFrame(dtr_ls_optimized.cv_results_)\n",
    "\n",
    "# Create a pivot table from the dataframe\n",
    "dtr_pivot_table = dtr_ls_results.pivot(index='param_max_depth', columns='param_min_samples_leaf', values=f'mean_test_{main_scorer}')\n",
    "\n",
    "# Create a heatmap from the pivot table\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(dtr_pivot_table, annot=True, fmt='.3f', cmap='Purples_r', ax=ax)\n",
    "ax.set_title(f\"\"\"DT Regression on ls-encoded dataset - Metric: {main_scorer}\"\"\")\n",
    "ax.set_xlabel('Min Samples Leaf')\n",
    "ax.set_ylabel('Max Depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the performance of the model on your held-out test data\n",
    "dtr_ls_optimized.fit(X_lstrain, y_lstrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the test data\n",
    "y_pred_dtr_ls_optimized = dtr_ls_optimized.predict(X_lstest)\n",
    "\n",
    "# Retrieve scores\n",
    "dtr_ls_results_test = measure_performance(y_lstest, y_pred_dtr_ls_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: repeat the above steps for *data_Sepsis_ag* and compare the results\n",
    "\n",
    "# learn an optimal regression tree model (random forest regressor)\n",
    "dtr = DecisionTreeRegressor(random_state=0)\n",
    "dtr_ag_optimized = GridSearchCV(dtr, dtr_params, scoring=scorers, refit=main_scorer, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "dtr_ag_optimized.fit(X_agtrain, y_agtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 2D or 3D plot that shows how the selected parameter values affect the MAE (or RMSE). \n",
    "# create a dataframe from the grid search results\n",
    "dtr_ag_results = pd.DataFrame(dtr_ag_optimized.cv_results_)\n",
    "\n",
    "# create a pivot table from the dataframe\n",
    "dtr_pivot_table = dtr_ag_results.pivot(index='param_max_depth', columns='param_min_samples_leaf', values='mean_test_MAE')\n",
    "\n",
    "# create a heatmap from the pivot table\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.heatmap(dtr_pivot_table, annot=True, fmt='.3f', cmap='Purples_r', ax=ax)\n",
    "ax.set_title(f\"\"\"DT Regression on ag-encoded dataset - Metric: {main_scorer}\"\"\")\n",
    "ax.set_xlabel('Min Samples Leaf')\n",
    "ax.set_ylabel('Max Depth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the performance of the model on your held-out test data\n",
    "dtr_ag_optimized.fit(X_agtrain, y_agtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the test data\n",
    "y_pred_dtr_ag_optimized = dtr_ag_optimized.predict(X_agtest)\n",
    "\n",
    "# Store all scores\n",
    "dtr_ag_results_test = measure_performance(y_agtest, y_pred_dtr_ag_optimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4. Predicting Case Remaining Time - kNN Regression\n",
    "\n",
    "\n",
    "In this task, you will use the kNN Regression to learn a regression model to predict case remaining time. The same as task 3, now perform the following steps to train a regression model. \n",
    "\n",
    "i) use the default values for the parameters to get a [kNN Regression](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html#sklearn.neighbors.KNeighborsRegressor) running on the training data. (*Optional: compute the error measures to get an impression of the performance of the model).\n",
    "\n",
    "ii) use 5-fold cross-validation to determine a possibly better choice for the two parameters *n_neighbors* and *weights* \n",
    "    \n",
    "iii) create 2D or 3D plot that shows how the selected parameters affect the performance. \n",
    "\n",
    "iv) select the best-performing kNN, i.e., the one that achieved the lowest cross-validated errors, and report all the error measures (MAE, MSE, RMSE, R^2) of the fitted model on the held-out test data. \n",
    "\n",
    "    \n",
    "#### TIPS:\n",
    "The same here, you may consider reuse the some of your code of Assignment 1 or use the [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) class (see an [example](https://www.dezyre.com/recipes/find-optimal-parameters-using-gridsearchcv-for-regression), but be aware that GridSearchSV does not return MAE or the other error measures (e.g., MSE, RMSE, R^2), you will need to update the scoring function)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: import packages\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import KFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: set the search space of the parameters *n_neighbors* and *weights* \n",
    "knr_params = {\n",
    "    'n_neighbors': [1, 2, 4, 5, 8, 16, 32, 64],\n",
    "    'weights': ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# TODO: create 5-fold cross-validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "# TODO: learn an optimal kNN regressor\n",
    "knr = KNeighborsRegressor()\n",
    "knr_ls_optimized = GridSearchCV(knr, knr_params, scoring=scorers, refit=main_scorer, cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "knr_ls_optimized.fit(X_lstrain, y_lstrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create 2D or 3D plot that shows how the selected parameter values affect the MAE (or RMSE). \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Create a dataframe from the grid search results\n",
    "knr_ls_results = pd.DataFrame(knr_ls_optimized.cv_results_)\n",
    "\n",
    "# Create a line chart from the dataframw showing mean_test_MAE for each value of n_neighbors for all values of weights\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.lineplot(data=knr_ls_results, x='param_n_neighbors', y=f'mean_test_{main_scorer}', hue='param_weights', ax=ax)\n",
    "ax.set_title(f\"\"\"KN Regression on ls-encoded dataset - Metric: {main_scorer}\"\"\")\n",
    "ax.set_xlabel('N Neighbors')\n",
    "ax.set_ylabel(f'{main_scorer}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the performance of the model on your held-out test data\n",
    "\n",
    "# predict the test data\n",
    "y_pred_knr_ls_optimized = knr_ls_optimized.predict(X_lstest)\n",
    "\n",
    "# Store all scores\n",
    "knr_ls_results_test = measure_performance(y_lstest, y_pred_knr_ls_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn an optimal kNN regressor\n",
    "knr = KNeighborsRegressor()\n",
    "knr_ag_optimized = GridSearchCV(knr, knr_params, scoring=scorers, refit=main_scorer, cv=kf)\n",
    "\n",
    "# fit the model\n",
    "knr_ag_optimized.fit(X_agtrain, y_agtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: create 2D or 3D plot that shows how the selected parameter values affect the MAE (or RMSE). \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Create a dataframe from the grid search results\n",
    "knr_ag_results = pd.DataFrame(knr_ag_optimized.cv_results_)\n",
    "\n",
    "# Create a line chart from the dataframw showing mean_test_MAE for each value of n_neighbors for all values of weights\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "sns.lineplot(data=knr_ag_results, x='param_n_neighbors', y='mean_test_MAE', hue='param_weights', ax=ax)\n",
    "ax.set_title(f\"\"\"KN Regression on ag-encoded dataset - Metric: {main_scorer}\"\"\")\n",
    "ax.set_xlabel('N Neighbors')\n",
    "ax.set_ylabel(f'{main_scorer}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the performance of the model on your held-out test data\n",
    "\n",
    "# predict the test data\n",
    "y_pred_knr_ag_optimized = knr_ag_optimized.predict(X_agtest)\n",
    "\n",
    "# Store all scores\n",
    "knr_ag_results_test = measure_performance(y_agtest, y_pred_knr_ag_optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Data for the bar plots\n",
    "scorer_list = ['MAE', 'MSE', 'RMSE', 'R2']\n",
    "\n",
    "result_list = [dtr_ls_results, dtr_ls_results_test, dtr_ag_results, dtr_ag_results_test, knr_ls_results, knr_ls_results_test, knr_ag_results, knr_ag_results_test]\n",
    "regressor_list = ['CV DT - LS', 'Test DT - LS', 'CV DT - AG', 'Test DT - AG', 'CV KN - LS', 'Test KN - LS', 'CV KN - AG', 'Test KN - AG']\n",
    "\n",
    "mae_values = []\n",
    "mse_values = []\n",
    "rmse_values = []\n",
    "r2_values = []\n",
    "i = 0\n",
    "\n",
    "for result in result_list:\n",
    "    if i == 1 or i == 3 or i == 5 or i == 7:\n",
    "        mae_values.append(result[0])\n",
    "        mse_values.append(result[1])\n",
    "        rmse_values.append(result[2])\n",
    "        r2_values.append(result[3])\n",
    "    else:\n",
    "        mae_values.append(result.loc[result[f'rank_test_{scorer_list[0]}'] == 1, f'mean_test_{scorer_list[0]}'].values[0])\n",
    "        mse_values.append(result.loc[result[f'rank_test_{scorer_list[1]}'] == 1, f'mean_test_{scorer_list[1]}'].values[0])\n",
    "        rmse_values.append(result.loc[result[f'rank_test_{scorer_list[2]}'] == 1, f'mean_test_{scorer_list[2]}'].values[0])\n",
    "        r2_values.append(result.loc[result[f'rank_test_{scorer_list[3]}'] == 1, f'mean_test_{scorer_list[3]}'].values[0])\n",
    "    i += 1\n",
    "\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(rows=2, cols=2, subplot_titles=['MAE', 'MSE', 'RMSE', 'R2'])\n",
    "\n",
    "# Add bar plots to subplots\n",
    "fig.add_trace(go.Bar(x=regressor_list, y=mae_values), row=1, col=1)\n",
    "fig.add_trace(go.Bar(x=regressor_list, y=mse_values), row=1, col=2)\n",
    "fig.add_trace(go.Bar(x=regressor_list, y=rmse_values), row=2, col=1)\n",
    "fig.add_trace(go.Bar(x=regressor_list, y=r2_values), row=2, col=2)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title='Performance of the models on train and test data using ls and ag encoding')\n",
    "\n",
    "# Update colors to blue purple yellow and green\n",
    "fig.update_traces(marker_color=['#003f5c', '#003f5c', '#58508d', '#58508d', '#bc5090', '#bc5090', '#ff6361', '#ff6361'])\n",
    "\n",
    "# Update legend trace 'trace 0' to 'train'\n",
    "fig.update_traces(name='')\n",
    "\n",
    "# Show the figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5.  Report your results and discuss your findings\n",
    "\n",
    "By now, you have applied two algorithms with different parameters on the two encodings of the data set. For each algorithm and each encoding, you have created tables or figures which you can add to your report. Discuss the results and their optimal performance. \n",
    "\n",
    "Create an overview table or figure that shows the optimal performance of each algorithm on the data set, for example, see the table here below. \n",
    "\n",
    "\n",
    "Discuss your findings and reflect on the following questions in your report:\n",
    "- According to the error measures, which one would you suggest as the optimal model? \n",
    "- Are there any discrepancies between the MAE, MSE, RMSE, and R^2 measures in terms of which model performs the best? If yes, how would you explain these discrepancies. \n",
    "- Which one of the MAE, MSE, RMSE, and R^2 would you use for selecting the model? Why?\n",
    "- Which one of the encoding would you suggest for this data set? Why?\n",
    "- Which features have a big influence on predicting the remaining time?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| Encoding | Model | CV MAE  | Test MAE |  CV MSE  |  Test MSE  | CV R^2 | Test R^2 |... |\n",
    "|------|------|------|------|------|------|------|------|-----|\n",
    "|  Last-2-state | Regression Tree        |  |  | | | | |\n",
    "|  Agg-state |  Regression Tree  |  |  | || | |\n",
    "|   Last-2-state |kNN       |  |  | || | |\n",
    "|   ... |...       |  |  | || | |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Tasks \n",
    "\n",
    "We would like to challenge you with the following bonus tasks. For each task that is successfully completed, you may obtain max. 1 extra point. \n",
    "\n",
    "1. Implement or use another regression algorithm (for example, [Random Forest Regression](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html), [LinearRegresion](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html), [SVM Regression](https://scikit-learn.org/stable/auto_examples/svm/plot_svm_regression.html#sphx-glr-auto-examples-svm-plot-svm-regression-py)) or design your own algorithm that achieves a better MAE measure. Explain this in your report.\n",
    "2. Implement techniques (e.g., preprocessing, feature engineering, feature selection, sampling) that help improve the MAE scores of existing models. For example, try out a feature selection for kNN or implement inter-case features. Explain this in your report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
