{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Toolkit"
      ],
      "metadata": {
        "id": "AzRrYqG5Hn0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. What is numpy, and why is it widely used in python."
      ],
      "metadata": {
        "id": "t14fb2lSHsRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ans:- NumPy (Numerical Python) is a library for working with arrays and mathematical operations in Python. It provides support for large, multi-dimensional arrays and matrices, and is the foundation of most scientific computing in Python.\n"
      ],
      "metadata": {
        "id": "vgH30Z7SIjhA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Efficient numerical computations: NumPy provides an efficient way to perform numerical computations, such as linear algebra operations, statistical calculations, and signal processing.\n",
        "2. Multi-dimensional arrays: NumPy's array data structure allows for efficient storage and manipulation of large datasets, making it ideal for scientific computing and data analysis.\n",
        "3. Vectorized operations: NumPy's vectorized operations enable fast and efficient computations on entire arrays at once, reducing the need for loops and improving performance.\n",
        "4. Interoperability with other libraries: NumPy is designed to work seamlessly with other popular Python libraries, such as Pandas, SciPy, and Matplotlib, making it a fundamental tool for data science and scientific computing.\n",
        "5. Easy to use: NumPy has a simple and intuitive API, making it easy to learn and use, even for those without extensive programming experience.\n",
        "\n",
        "Some of the key features of NumPy include:\n",
        "\n",
        "- Support for large, multi-dimensional arrays and matrices\n",
        "- Efficient numerical computations, including linear algebra operations and statistical calculations\n",
        "- Vectorized operations for fast and efficient computations\n",
        "- Support for various data types, including integers, floating-point numbers, and complex numbers\n",
        "- Interoperability with other popular Python libraries\n",
        "\n",
        "Overall, NumPy is a powerful and essential library for anyone working with numerical data in Python."
      ],
      "metadata": {
        "id": "H-3_pUpZImvo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. How does broadcasting work in Numpy?"
      ],
      "metadata": {
        "id": "zdJrrSC_Iqe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anss:- Broadcasting is a powerful feature in NumPy that allows you to perform operations on arrays with different shapes and sizes. Here's how it works:\n",
        "\n",
        "What is broadcasting?\n",
        "\n",
        "Broadcasting is the process of aligning arrays with different shapes and sizes so that they can be operated on element-wise.\n",
        "\n",
        "How does broadcasting work?\n",
        "\n",
        "When you perform an operation on two arrays with different shapes, NumPy checks if the arrays can be broadcasted to a common shape. Here are the rules that NumPy follows:\n",
        "\n",
        "1. Matching dimensions: If the arrays have the same number of dimensions, NumPy checks if the dimensions match. If they do, the arrays can be broadcasted.\n",
        "2. Singleton dimensions: If one array has a singleton dimension (i.e., a dimension of size 1), NumPy can broadcast that dimension to match the corresponding dimension in the other array.\n",
        "3. New axes: If one array has fewer dimensions than the other, NumPy adds new axes to the array with fewer dimensions to match the shape of the other array.\n",
        "\n"
      ],
      "metadata": {
        "id": "Jl4CA-VMI9OZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example 1: Matching dimensions\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([4, 5, 6])\n",
        "print(a + b)"
      ],
      "metadata": {
        "id": "M9rA2d0FJDOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2: Singleton dimensions\n",
        "a = np.array([[1, 2], [3, 4]])\n",
        "b = np.array([5, 6])  # Singleton dimension\n",
        "print(a + b)"
      ],
      "metadata": {
        "id": "_JwF9ntXJO4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 3: New axes\n",
        "a = np.array([1, 2, 3])\n",
        "b = np.array([[4], [5], [6]])  # New axis\n",
        "print(a + b)"
      ],
      "metadata": {
        "id": "AFrf1r4IJS2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. What is a pandas dataframe?"
      ],
      "metadata": {
        "id": "yMAEdOOyJU3n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- A Pandas DataFrame is a two-dimensional table of data with rows and columns, similar to an Excel spreadsheet or a table in a relational database. It is a fundamental data structure in the Pandas library, which is a popular data manipulation and analysis tool in Python.\n",
        "\n",
        "A DataFrame consists of:\n",
        "\n",
        "1. Rows: Each row represents a single observation or record.\n",
        "2. Columns: Each column represents a variable or field.\n",
        "3. Index: The index is a label or identifier for each row.\n",
        "4. Data: The data is the actual values stored in the DataFrame.\n",
        "\n",
        "DataFrames are similar to NumPy arrays, but with additional features such as:\n",
        "\n",
        "1. Column labels: DataFrames have column labels, which make it easier to select and manipulate data.\n",
        "2. Indexing: DataFrames support label-based indexing, which allows you to select data using the index labels.\n",
        "3. Missing data handling: DataFrames provide built-in support for handling missing data.\n",
        "4. Data merging and joining: DataFrames provide methods for merging and joining data from multiple sources.\n",
        "\n",
        "DataFrames are widely used in data analysis, machine learning, and scientific computing for tasks such as:\n",
        "\n",
        "1. Data cleaning and preprocessing\n",
        "2. Data visualization\n",
        "3. Data analysis and modeling\n",
        "4. Data merging and integration\n",
        "\n",
        "Some common operations you can perform on DataFrames include:\n",
        "\n",
        "1. Selecting data: Selecting specific rows or columns using label-based indexing.\n",
        "2. Filtering data: Filtering data based on conditions using the query() method.\n",
        "3. Grouping and aggregating data: Grouping data by one or more columns and applying aggregation functions using the groupby() method.\n",
        "4. Merging and joining data: Merging and joining data from multiple DataFrames using the merge() and join() methods."
      ],
      "metadata": {
        "id": "wuotT_qdJmpf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Explain the use of the groupby() method in pandas."
      ],
      "metadata": {
        "id": "q_8fCxdgJpcY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- The groupby() method in pandas is used to split a DataFrame into groups based on one or more columns. It allows you to perform various aggregation operations on each group, such as calculating the mean, sum, count, and more.\n",
        "\n",
        "Here's a general syntax for using the groupby() method:\n",
        "\n",
        "df.groupby(by=None, axis=0, level=None, as_index=True, sort=True, group_keys=True, squeeze=False, observed=False)\n",
        "\n",
        "Let's break down the parameters:\n",
        "\n",
        "- by: The column(s) to group by. Can be a single column name, a list of column names, or a pandas Series.\n",
        "- axis: The axis to group by. Default is 0 (rows).\n",
        "- level: The level of the index to group by. Default is None.\n",
        "- as_index: Whether to use the grouped column(s) as the index of the resulting DataFrame. Default is True.\n",
        "- sort: Whether to sort the grouped DataFrame. Default is True.\n",
        "- group_keys: Whether to include the group keys in the resulting DataFrame. Default is True.\n",
        "- squeeze: Whether to squeeze the resulting DataFrame to remove any redundant dimensions. Default is False.\n",
        "- observed: Whether to only consider observed values in the grouped DataFrame. Default is False.\n",
        "\n"
      ],
      "metadata": {
        "id": "JY66YxVUJ9X_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {'Category': ['A', 'A', 'B', 'B', 'C', 'C'],\n",
        "        'Value': [10, 20, 30, 40, 50, 60]}\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "69W9ChdNKCAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Category and calculate the mean Value\n",
        "grouped_df = df.groupby('Category')['Value'].mean()\n",
        "print(grouped_df)\n"
      ],
      "metadata": {
        "id": "H4lggQxEKHGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by Category and calculate the sum of Value\n",
        "grouped_df = df.groupby('Category')['Value'].sum()\n",
        "print(grouped_df)"
      ],
      "metadata": {
        "id": "Lco83GoJKKhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by multiple columns (Category and Value) and calculate the count\n",
        "grouped_df = df.groupby(['Category', 'Value']).size()\n",
        "print(grouped_df)"
      ],
      "metadata": {
        "id": "JoELROnMKOFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Why is seaborn preferred for statical visualizations?"
      ],
      "metadata": {
        "id": "CbcN9rTJKQ2o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Seaborn is a popular Python data visualization library that is built on top of matplotlib. It is preferred for statistical visualizations for several reasons:\n",
        "\n",
        "1. High-level abstractions: Seaborn provides high-level abstractions for creating informative and attractive statistical graphics. It allows users to focus on the data and the story they want to tell, rather than worrying about the details of the plot.\n",
        "2. Integration with pandas: Seaborn is designed to work seamlessly with pandas, which is a popular library for data manipulation and analysis. This integration makes it easy to create visualizations of pandas DataFrames.\n",
        "3. Statistical graphics: Seaborn provides a wide range of statistical graphics, including scatterplots, boxplots, violin plots, and more. These graphics are designed to help users understand and communicate complex statistical relationships.\n",
        "4. Customization: Seaborn allows users to customize the appearance of their visualizations using a variety of options, including colors, fonts, and layouts.\n",
        "5. Consistency: Seaborn's visualizations are designed to be consistent in terms of their appearance and behavior. This consistency makes it easier for users to create and interpret visualizations.\n",
        "6. Easy to use: Seaborn is designed to be easy to use, even for users who are new to data visualization. It provides a simple and intuitive API that makes it easy to create a wide range of visualizations.\n",
        "7. Large community: Seaborn has a large and active community of users and contributors. This community provides a wealth of resources, including documentation, tutorials, and examples.\n",
        "\n",
        "Some of the most commonly used Seaborn plots include:\n",
        "\n",
        "- lmplot(): A linear regression plot that shows the relationship between two variables.\n",
        "- boxplot(): A boxplot that shows the distribution of a variable.\n",
        "- violinplot(): A violin plot that shows the distribution of a variable.\n",
        "- barplot(): A bar plot that shows the relationship between two variables.\n",
        "- heatmap(): A heatmap that shows the relationship between two variables.\n",
        "\n",
        "Overall, Seaborn is a powerful and flexible library that makes it easy to create informative and attractive statistical visualizations."
      ],
      "metadata": {
        "id": "NThhCkpGKp-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. What are the diffrence between numpy arrays and python lists?"
      ],
      "metadata": {
        "id": "c9zy29piKsqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- NumPy arrays and Python lists are two different data structures that serve different purposes. Here are the main differences between them:\n",
        "\n",
        "1. Homogeneity: NumPy arrays are homogeneous, meaning all elements must be of the same data type. Python lists, on the other hand, are heterogeneous, meaning they can contain elements of different data types.\n",
        "2. Memory Layout: NumPy arrays store elements in a contiguous block of memory, which allows for efficient access and manipulation of elements. Python lists, by contrast, store elements as separate objects, which can lead to slower access and manipulation times.\n",
        "3. Indexing and Slicing: Both NumPy arrays and Python lists support indexing and slicing. However, NumPy arrays support more advanced indexing and slicing techniques, such as broadcasting and fancy indexing.\n",
        "4. Mathematical Operations: NumPy arrays support element-wise mathematical operations, such as addition, subtraction, multiplication, and division. Python lists do not support these operations directly.\n",
        "5. Size and Performance: NumPy arrays are generally more memory-efficient and faster than Python lists, especially for large datasets.\n",
        "6. Data Type: NumPy arrays have a specific data type, such as int, float, or complex, whereas Python lists can contain elements of any data type.\n",
        "7. Reshaping and Transposing: NumPy arrays support reshaping and transposing operations, which can be useful for data manipulation. Python lists do not support these operations directly.\n",
        "8. Vectorized Operations: NumPy arrays support vectorized operations, which allow you to perform operations on entire arrays at once. Python lists do not support vectorized operations directly.\n"
      ],
      "metadata": {
        "id": "VBbQsA1TK_eh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a NumPy array and a Python list\n",
        "array = np.array([1, 2, 3, 4, 5])\n",
        "list_ = [1, 2, 3, 4, 5]\n"
      ],
      "metadata": {
        "id": "aw0h3srMLGii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform element-wise addition\n",
        "array_result = array + 2\n",
        "list_result = [x + 2 for x in list_]\n"
      ],
      "metadata": {
        "id": "SXNkogbwLJXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform matrix multiplication\n",
        "array_result = np.dot(array, array)\n",
        "list_result = [sum(x * y for x, y in zip(list_, list_))]\n"
      ],
      "metadata": {
        "id": "cE1AcPRPLL4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(array_result)\n",
        "print(list_result)"
      ],
      "metadata": {
        "id": "UzJJrnlXLSWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. What is a heatmap, and when should it be used?"
      ],
      "metadata": {
        "id": "sFydL-zgLU8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:-A heatmap is a graphical representation of data where values are depicted by color. Heatmaps are often used to visualize complex data, such as relationships between variables, patterns, and trends.\n",
        "\n",
        "Heatmaps are typically used to:\n",
        "\n",
        "1. Visualize relationships between variables: Heatmaps can help identify correlations, patterns, and relationships between variables.\n",
        "2. Show density or frequency: Heatmaps can be used to display the density or frequency of data points in a two-dimensional space.\n",
        "3. Highlight patterns or trends: Heatmaps can help identify patterns or trends in data, such as clusters, outliers, or anomalies.\n",
        "4. Compare data: Heatmaps can be used to compare data across different categories, groups, or time periods.\n",
        "\n",
        "When to use heatmaps:\n",
        "\n",
        "1. When dealing with large datasets: Heatmaps can help visualize large datasets and identify patterns or trends that might be difficult to see in a table or spreadsheet.\n",
        "2. When looking for relationships between variables: Heatmaps can help identify correlations or relationships between variables, which can be useful in exploratory data analysis.\n",
        "3. When trying to identify patterns or trends: Heatmaps can help identify patterns or trends in data, which can be useful in data analysis and visualization.\n",
        "4. When comparing data: Heatmaps can be used to compare data across different categories, groups, or time periods.\n",
        "\n",
        "Some common types of heatmaps include:\n",
        "\n",
        "1. Correlation heatmap: A heatmap that displays the correlation between variables.\n",
        "2. Density heatmap: A heatmap that displays the density or frequency of data points in a two-dimensional space.\n",
        "3. Cluster heatmap: A heatmap that displays clusters or groups of data points.\n",
        "4. Time-series heatmap: A heatmap that displays data over time.\n",
        "\n",
        "Some popular tools for creating heatmaps include:\n",
        "\n",
        "1. Seaborn: A Python library for data visualization that includes tools for creating heatmaps.\n",
        "2. Matplotlib: A Python library for data visualization that includes tools for creating heatmaps.\n",
        "3. Plotly: A Python library for data visualization that includes tools for creating interactive heatmaps.\n",
        "4. Tableau: A data visualization tool that includes features for creating heatmaps."
      ],
      "metadata": {
        "id": "QbSrIGuSLtHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. What does the term \"vectorized operation\" mean in numpy?"
      ],
      "metadata": {
        "id": "Ssa35EQ2LwT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ans:- In NumPy, a vectorized operation is an operation that is applied element-wise to an entire array or matrix, rather than requiring a loop to iterate over each element individually.\n",
        "\n",
        "In other words, vectorized operations are operations that are performed on entire arrays or matrices at once, using optimized C code under the hood. This approach is much faster and more efficient than using loops to iterate over each element.\n",
        "\n",
        "Here are some examples of vectorized operations in NumPy:\n",
        "\n",
        "1. Element-wise arithmetic: a + b, a * b, a / b, etc.\n",
        "2. Array indexing: a[0:10], a[:, 0], etc.\n",
        "3. Array reshaping: a.reshape((3, 4)), etc.\n",
        "4. Array aggregation: np.sum(a), np.mean(a), etc.\n",
        "5. Array comparison: a > b, a == b, etc.\n",
        "\n",
        "Vectorized operations have several benefits, including:\n",
        "\n",
        "1. Speed: Vectorized operations are much faster than using loops to iterate over each element.\n",
        "2. Convenience: Vectorized operations are often more concise and easier to read than equivalent code using loops.\n",
        "3. Memory efficiency: Vectorized operations can reduce memory usage by avoiding the need to create intermediate arrays.\n",
        "\n",
        "Overall, vectorized operations are a key feature of NumPy that make it an efficient and convenient library for numerical computing."
      ],
      "metadata": {
        "id": "aQ0S6BiFMH0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9. How does matplotlib deffer from plotly?"
      ],
      "metadata": {
        "id": "WUYzRBJ6MKMP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ans:- Matplotlib and Plotly are two popular Python libraries used for creating static and interactive visualizations, respectively. Here are the main differences between them:\n",
        "\n",
        "1. Interactivity:\n",
        "* Matplotlib: Creates static plots, which cannot be interacted with.\n",
        "* Plotly: Creates interactive plots that can be zoomed, hovered, and clicked.\n",
        "\n",
        "2. Plotting Style:\n",
        "* Matplotlib: Focuses on creating publication-quality 2D plots, with a wide range of customization options.\n",
        "* Plotly: Offers a variety of plot types, including 3D plots, and is particularly well-suited for creating interactive, web-based visualizations.\n",
        "\n",
        "3. Data Size and Complexity:\n",
        "* Matplotlib: Can handle large datasets, but may become slow and unwieldy.\n",
        "* Plotly: Optimized for handling large, complex datasets, and can render them quickly and efficiently.\n",
        "\n",
        "4. Integration with Other Libraries:\n",
        "* Matplotlib: Integrates well with other Python libraries, such as NumPy, Pandas, and Scikit-learn.\n",
        "* Plotly: Also integrates well with other Python libraries, including NumPy, Pandas, and Scikit-learn, as well as with other Plotly libraries, such as Dash.\n",
        "\n",
        "5. Output Format:\n",
        "* Matplotlib: Outputs plots as images (e.g., PNG, PDF, EPS) or displays them in a GUI window.\n",
        "* Plotly: Outputs plots as interactive HTML files, which can be shared online or embedded in web applications.\n",
        "\n",
        "6. Learning Curve:\n",
        "* Matplotlib: Has a steeper learning curve due to its extensive customization options and complex syntax.\n",
        "* Plotly: Has a more intuitive API and a gentler learning curve, making it easier to create interactive plots quickly.\n",
        "\n",
        "In summary, Matplotlib is ideal for creating static, publication-quality plots, while Plotly is better suited for creating interactive, web-based visualizations. Ultimately, the choice between Matplotlib and Plotly depends on your specific use case and personal preference."
      ],
      "metadata": {
        "id": "LXkklWtzMhFf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10. What is the significance of hierarchical indexing in pandas?"
      ],
      "metadata": {
        "id": "1CKdWoSiMjT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ans:- Hierarchical indexing, also known as multi-indexing, is a powerful feature in pandas that allows you to index and manipulate data with multiple levels of labels. This feature is significant because it enables you to:\n",
        "\n",
        "1. Organize complex data: Hierarchical indexing allows you to structure your data in a way that reflects its natural hierarchy. For example, you can have a DataFrame with a multi-index that includes country, region, and city.\n",
        "2. Simplify data manipulation: With hierarchical indexing, you can perform operations on specific levels of the index, making it easier to manipulate and analyze your data.\n",
        "3. Improve data readability: Hierarchical indexing makes it easier to understand the structure of your data, especially when working with large and complex datasets.\n",
        "4. Enable advanced data analysis: Hierarchical indexing is essential for advanced data analysis techniques, such as data aggregation, filtering, and grouping.\n",
        "\n",
        "Some common use cases for hierarchical indexing in pandas include:\n",
        "\n",
        "1. Time series data: Hierarchical indexing can be used to represent time series data with multiple frequencies (e.g., daily, weekly, monthly).\n",
        "2. Geospatial data: Hierarchical indexing can be used to represent geospatial data with multiple levels of granularity (e.g., country, region, city).\n",
        "3. Financial data: Hierarchical indexing can be used to represent financial data with multiple levels of hierarchy (e.g., company, department, account).\n",
        "4. Scientific data: Hierarchical indexing can be used to represent scientific data with multiple levels of hierarchy (e.g., experiment, trial, measurement).\n",
        "\n"
      ],
      "metadata": {
        "id": "sdnVBy53M5E_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {'Country': ['USA', 'USA', 'Canada', 'Canada'],\n",
        "        'Region': ['North', 'South', 'East', 'West'],\n",
        "        'Sales': [100, 200, 300, 400]}\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "xD6VR4hDM9F6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a hierarchical index\n",
        "df.set_index(['Country', 'Region'], inplace=True)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "XXUrrHmzNBN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11. What is the role of seaborn's pairplot() function?"
      ],
      "metadata": {
        "id": "M3WwD1h9ND0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Seaborn's pairplot() function is a powerful tool for visualizing the relationships between multiple variables in a dataset. It creates a matrix of plots, where each row and column represents a different variable.\n",
        "\n",
        "The pairplot() function serves several purposes:\n",
        "\n",
        "1. Exploratory Data Analysis (EDA): It helps to quickly understand the distribution of each variable, as well as the relationships between them.\n",
        "2. Correlation analysis: By visualizing the relationships between variables, pairplot() can help identify correlations, both positive and negative.\n",
        "3. Multivariate analysis: It allows you to examine the relationships between multiple variables simultaneously, which can be useful for identifying patterns and trends.\n",
        "4. Data quality checks: pairplot() can help identify outliers, missing values, and other data quality issues.\n",
        "\n",
        "The pairplot() function creates a grid of plots, where each plot shows the relationship between two variables. The plots can be customized to display different types of relationships, such as:\n",
        "\n",
        "- Scatter plots: Show the relationship between two continuous variables.\n",
        "- Box plots: Show the distribution of a continuous variable.\n",
        "- Bar plots: Show the distribution of a categorical variable.\n",
        "- Histograms: Show the distribution of a continuous variable.\n"
      ],
      "metadata": {
        "id": "ZYmtOAlHNX7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "wKWUpEIMNcPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the iris dataset\n",
        "iris = sns.load_dataset(\"iris\")"
      ],
      "metadata": {
        "id": "resRkOEpNgEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRVBXmJoHiYm"
      },
      "outputs": [],
      "source": [
        "# Create a pairplot\n",
        "sns.pairplot(iris)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JxY9zFJSNjxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12. What is the purpose of the describe() function in pandas?"
      ],
      "metadata": {
        "id": "QJDxfD4wNqY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- The describe() function in pandas is used to generate descriptive statistics for a DataFrame or Series. It provides a summary of the central tendency, dispersion, and shape of the data.\n",
        "\n",
        "The describe() function returns a DataFrame that includes the following statistics:\n",
        "\n",
        "1. count: The number of non-missing values in the data.\n",
        "2. mean: The average value of the data.\n",
        "3. std: The standard deviation of the data.\n",
        "4. min: The minimum value in the data.\n",
        "5. 25%: The 25th percentile (Q1) of the data.\n",
        "6. 50%: The 50th percentile (Q2) of the data, also known as the median.\n",
        "7. 75%: The 75th percentile (Q3) of the data.\n",
        "8. max: The maximum value in the data.\n"
      ],
      "metadata": {
        "id": "FTh_j-lxN7PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {'A': [1, 2, 3, 4, 5],\n",
        "        'B': [2, 4, 6, 8, 10]}\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "mKOCNKuEN9yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Use the describe() function\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "R4jqOXlvNjYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13. Why is handiling missing data important in pandas?"
      ],
      "metadata": {
        "id": "ITVo_P-KOGa3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Handling missing data is important in pandas because it can significantly impact the accuracy and reliability of data analysis and modeling. Here are some reasons why handling missing data is crucial:\n",
        "\n",
        "1. Data quality: Missing data can compromise the quality of the data, leading to inaccurate or biased results.\n",
        "2. Analysis and modeling: Many statistical and machine learning algorithms are sensitive to missing data, and can produce incorrect or misleading results if missing values are not handled properly.\n",
        "3. Data visualization: Missing data can make it difficult to visualize data effectively, leading to misleading or incomplete insights.\n",
        "4. Data integrity: Missing data can indicate data entry errors, data corruption, or other data quality issues that need to be addressed.\n",
        "\n",
        "Common problems caused by missing data include:\n",
        "\n",
        "1. Bias: Missing data can introduce bias into the analysis, leading to incorrect conclusions.\n",
        "2. Variance: Missing data can increase the variance of the data, making it more difficult to detect patterns or relationships.\n",
        "3. Error propagation: Missing data can propagate errors throughout the analysis, leading to incorrect or misleading results.\n",
        "\n",
        "To handle missing data in pandas, you can use various techniques, such as:\n",
        "\n",
        "1. Dropping missing values: Using the dropna() function to remove rows or columns with missing values.\n",
        "2. Filling missing values: Using the fillna() function to replace missing values with a specific value, such as the mean or median.\n",
        "3. Imputing missing values: Using techniques such as mean imputation, median imputation, or regression imputation to estimate missing values.\n",
        "4. Using interpolation: Using interpolation techniques, such as linear interpolation or spline interpolation, to estimate missing values.\n",
        "\n",
        "By handling missing data effectively, you can ensure that your data analysis and modeling results are accurate, reliable, and meaningful."
      ],
      "metadata": {
        "id": "go84WmBWOXxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#14. What are the benifits of using plotly for data visualization?"
      ],
      "metadata": {
        "id": "e0ftavppObxP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Plotly is a popular data visualization library that offers several benefits, including:\n",
        "\n",
        "1. Interactive Visualizations: Plotly allows you to create interactive visualizations that can be zoomed, hovered, and clicked to reveal more information.\n",
        "2. Web-Based Visualizations: Plotly visualizations can be easily shared and embedded in web applications, making it easy to share insights with others.\n",
        "3. Customizable: Plotly offers a wide range of customization options, including colors, fonts, and layouts, allowing you to tailor your visualizations to your specific needs.\n",
        "4. Support for Multiple Data Types: Plotly supports a wide range of data types, including numerical, categorical, and datetime data.\n",
        "5. Integration with Other Libraries: Plotly integrates seamlessly with other popular data science libraries, including Pandas, NumPy, and Scikit-learn.\n",
        "6. 3D Visualizations: Plotly offers support for 3D visualizations, allowing you to create complex and interactive 3D plots.\n",
        "7. Real-Time Data Visualization: Plotly allows you to create real-time data visualizations, making it easy to monitor and analyze streaming data.\n",
        "8. Collaboration: Plotly offers a range of collaboration tools, including real-time commenting and sharing, making it easy to work with others on data visualization projects.\n",
        "9. Security: Plotly offers enterprise-grade security features, including encryption and access controls, to ensure that your data is protected.\n",
        "10. Community Support: Plotly has a large and active community of users and developers, which means there are many resources available to help you get started and stay up-to-date with the latest features and best practices.\n",
        "\n",
        "Some of the most popular Plotly features include:\n",
        "\n",
        "- Dash: A framework for building web applications with Plotly.\n",
        "- Plotly Express: A high-level interface for creating common plots and charts.\n",
        "- Plotly Graph Objects: A low-level interface for creating custom plots and charts.\n",
        "\n",
        "Overall, Plotly is a powerful and flexible data visualization library that offers a wide range of benefits and features for data scientists, analysts, and developers."
      ],
      "metadata": {
        "id": "87NQw1tbOuDO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#15. How does numpy handle multidimensional arreys?"
      ],
      "metadata": {
        "id": "7WcwZnFTOwZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ns:- NumPy is designed to handle multidimensional arrays efficiently and effectively. Here are some key aspects of how NumPy handles multidimensional arrays:\n",
        "\n",
        "1. Array Structure: NumPy arrays are stored in a contiguous block of memory, which allows for efficient access and manipulation of elements.\n",
        "2. Shape and Size: NumPy arrays have a shape and size attribute, which describe the number of dimensions and the number of elements in each dimension.\n",
        "3. Indexing and Slicing: NumPy arrays support indexing and slicing, which allow you to access and manipulate specific elements or subsets of elements.\n",
        "4. Broadcasting: NumPy arrays support broadcasting, which allows you to perform operations on arrays with different shapes and sizes.\n",
        "5. Array Operations: NumPy provides a wide range of array operations, including element-wise operations, matrix multiplication, and linear algebra operations.\n",
        "\n",
        "Some key concepts in NumPy for handling multidimensional arrays include:\n",
        "\n",
        "1. Axes: NumPy arrays have axes, which are used to index and manipulate elements.\n",
        "2. Dimensions: NumPy arrays have dimensions, which describe the number of axes.\n",
        "3. Shape: The shape of a NumPy array describes the number of elements in each dimension.\n",
        "4. Stride: The stride of a NumPy array describes the number of bytes between elements in each dimension.\n",
        "\n",
        "Some common operations on multidimensional arrays in NumPy include:\n",
        "\n",
        "1. Array creation: Creating arrays with specific shapes and sizes.\n",
        "2. Indexing and slicing: Accessing and manipulating specific elements or subsets of elements.\n",
        "3. Array operations: Performing element-wise operations, matrix multiplication, and linear algebra operations.\n",
        "4. Array reshaping: Changing the shape of an array without changing its data.\n",
        "5. Array transposition: Swapping the axes of an array.\n"
      ],
      "metadata": {
        "id": "JHfW4Rx7PH-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a 3D array with shape (2, 3, 4)\n",
        "arr = np.arange(24).reshape(2, 3, 4)"
      ],
      "metadata": {
        "id": "svrUSagwPL1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the array\n",
        "print(arr)"
      ],
      "metadata": {
        "id": "NJtW4CqoPO1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Access a specific element\n",
        "print(arr[1, 2, 3])"
      ],
      "metadata": {
        "id": "sNWc4FMGODhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Slice a subset of elements\n",
        "print(arr[:, 1, :])"
      ],
      "metadata": {
        "id": "lqZLNiKOPSra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform an element-wise operation\n",
        "arr += 1\n",
        "print(arr)"
      ],
      "metadata": {
        "id": "Gv1FosS1PYEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#16. What is the role of boken in data visualization?"
      ],
      "metadata": {
        "id": "lDjj0E_6PZgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Bokeh is a Python library that provides a high-level interface for creating interactive, web-based visualizations. The role of Bokeh in data visualization is to enable users to create beautiful, interactive plots and dashboards that can be easily shared with others.\n",
        "\n",
        "Some of the key features of Bokeh include:\n",
        "\n",
        "1. Interactive plots: Bokeh allows users to create interactive plots that can be zoomed, panned, and hovered to reveal more information.\n",
        "2. Web-based visualizations: Bokeh visualizations can be easily shared and embedded in web applications, making it easy to share insights with others.\n",
        "3. Customizable: Bokeh provides a wide range of customization options, including colors, fonts, and layouts, allowing users to tailor their visualizations to their specific needs.\n",
        "4. Support for large datasets: Bokeh is designed to handle large datasets, making it a great choice for big data visualization.\n",
        "5. Integration with other libraries: Bokeh integrates seamlessly with other popular data science libraries, including Pandas, NumPy, and Scikit-learn.\n",
        "\n",
        "Bokeh is commonly used for:\n",
        "\n",
        "1. Exploratory data analysis: Bokeh's interactive plots make it easy to explore and understand complex data.\n",
        "2. Data storytelling: Bokeh's customizable visualizations and interactive plots make it easy to tell compelling stories with data.\n",
        "3. Business intelligence: Bokeh's web-based visualizations and dashboards make it easy to share insights with stakeholders and decision-makers.\n",
        "4. Scientific visualization: Bokeh's support for large datasets and customizable visualizations make it a great choice for scientific visualization.\n",
        "\n",
        "Some of the benefits of using Bokeh include:\n",
        "\n",
        "1. Easy to use: Bokeh has a simple and intuitive API, making it easy to get started with.\n",
        "2. High-quality visualizations: Bokeh's customizable visualizations and interactive plots make it easy to create high-quality visualizations.\n",
        "3. Flexible: Bokeh can be used for a wide range of applications, from exploratory data analysis to business intelligence and scientific visualization.\n",
        "4. Community support: Bokeh has an active and supportive community, with many resources available for learning and troubleshooting."
      ],
      "metadata": {
        "id": "URcawXNdPs04"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#17. Explain the diffrence between apply() and map() in pandas."
      ],
      "metadata": {
        "id": "SontPORGPvf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- In pandas, apply() and map() are two popular functions used to perform operations on DataFrames and Series. While they share some similarities, they have distinct differences in their usage, behavior, and performance.\n",
        "\n",
        "Apply()\n",
        "\n",
        "apply() is a more general-purpose function that applies a function to each row or column of a DataFrame or Series. It can handle more complex operations, such as applying a custom function to each row or column.\n",
        "\n"
      ],
      "metadata": {
        "id": "cjRsStttQFmn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})"
      ],
      "metadata": {
        "id": "v5O29lRZQJVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom function\n",
        "def custom_func(row):\n",
        "    return row['A'] + row['B']\n"
      ],
      "metadata": {
        "id": "71uYYwv3QMSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the custom function to each row\n",
        "result = df.apply(custom_func, axis=1)\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "474ytgMJQO-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Map()\n",
        "\n",
        "map() is a function that applies a function to each element of a Series or DataFrame. It's primarily used for simple, element-wise operations, such as replacing values or performing arithmetic operations.\n",
        "\n"
      ],
      "metadata": {
        "id": "xohEroZ8QS6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a sample Series\n",
        "s = pd.Series([1, 2, 3, 4, 5])\n"
      ],
      "metadata": {
        "id": "5iuEg1a5QWGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple function\n",
        "def square(x):\n",
        "    return x ** 2\n"
      ],
      "metadata": {
        "id": "LCwVv90eQZF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map the function to each element\n",
        "result = s.map(square)\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "U5ZZoFawPVXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#18. What are same advanced features of numpy?"
      ],
      "metadata": {
        "id": "egyfBIxUQeR2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- NumPy is a powerful library for numerical computing in Python, and it has many advanced features that can be useful for various applications. Here are some advanced features of NumPy:\n",
        "\n",
        "1. Broadcasting: NumPy's broadcasting feature allows you to perform operations on arrays with different shapes and sizes. This feature is useful when you need to perform element-wise operations on arrays with different dimensions.\n",
        "\n",
        "2. Vectorized operations: NumPy provides a wide range of vectorized operations that can be applied to entire arrays at once. This feature is useful when you need to perform operations on large datasets.\n",
        "\n",
        "3. Matrix operations: NumPy provides a wide range of matrix operations, including matrix multiplication, matrix transpose, and matrix inverse. These operations are useful when you need to perform linear algebra operations.\n",
        "\n",
        "4. Linear algebra functions: NumPy provides a wide range of linear algebra functions, including functions for solving systems of linear equations, finding eigenvalues and eigenvectors, and performing singular value decomposition.\n",
        "\n",
        "5. Random number generation: NumPy provides a wide range of random number generators that can be used to generate random numbers with different distributions.\n",
        "\n",
        "6. Data type support: NumPy supports a wide range of data types, including integers, floating-point numbers, complex numbers, and strings.\n",
        "\n",
        "7. Memory management: NumPy provides a wide range of memory management functions that can be used to manage memory allocation and deallocation.\n",
        "\n",
        "8. Array indexing and slicing: NumPy provides a wide range of array indexing and slicing functions that can be used to access and manipulate array elements.\n",
        "\n",
        "9. Array reshaping and transposition: NumPy provides a wide range of array reshaping and transposition functions that can be used to change the shape and orientation of arrays.\n",
        "\n",
        "10. Integration with other libraries: NumPy integrates well with other popular Python libraries, including Pandas, SciPy, and Matplotlib.\n",
        "\n",
        "Some examples of advanced NumPy features include:\n",
        "\n",
        "- Using broadcasting to perform element-wise operations on arrays with different shapes and sizes.\n",
        "- Using vectorized operations to perform operations on entire arrays at once.\n",
        "- Using matrix operations to perform linear algebra operations.\n",
        "- Using linear algebra functions to solve systems of linear equations and find eigenvalues and eigenvectors.\n",
        "- Using random number generators to generate random numbers with different distributions.\n",
        "- Using data type support to work with different data types, including integers, floating-point numbers, complex numbers, and strings.\n",
        "- Using memory management functions to manage memory allocation and deallocation.\n",
        "- Using array indexing and slicing functions to access and manipulate array elements.\n",
        "- Using array reshaping and transposition functions to change the shape and orientation of arrays.\n"
      ],
      "metadata": {
        "id": "e064235kQxMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create two arrays with different shapes and sizes\n",
        "arr1 = np.array([1, 2, 3])\n",
        "arr2 = np.array([[4, 5, 6], [7, 8, 9]])\n"
      ],
      "metadata": {
        "id": "ZXlR8kh2Q05w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use broadcasting to perform element-wise operations\n",
        "result = arr1 + arr2\n",
        "\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "lGLIghSjQ3qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#19. How does pandas simplify time series analysis?"
      ],
      "metadata": {
        "id": "0a2PwCbHQ48g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Pandas simplifies time series analysis by providing a wide range of features and functions that make it easy to work with time-stamped data. Here are some ways pandas simplifies time series analysis:\n",
        "\n",
        "1. Automatic Date Parsing: Pandas can automatically parse dates from various formats, making it easy to work with time-stamped data.\n",
        "\n",
        "2. Time Series Indexing: Pandas provides a time series index that allows you to easily select and manipulate data based on time periods.\n",
        "\n",
        "3. Resampling and Aggregation: Pandas provides a range of resampling and aggregation functions that make it easy to perform common time series operations, such as calculating daily or monthly means.\n",
        "\n",
        "4. Time Series Plotting: Pandas integrates well with matplotlib and seaborn, making it easy to create high-quality time series plots.\n",
        "\n",
        "5. Time Zone Handling: Pandas provides built-in support for time zones, making it easy to work with data from different regions.\n",
        "\n",
        "6. Holiday and Weekend Handling: Pandas provides built-in support for holidays and weekends, making it easy to exclude these periods from your analysis.\n",
        "\n",
        "7. Rolling and Expanding Window Calculations: Pandas provides a range of rolling and expanding window calculation functions that make it easy to perform calculations over time periods.\n",
        "\n",
        "8. Data Alignment and Merging: Pandas provides a range of data alignment and merging functions that make it easy to combine time series data from different sources.\n",
        "\n",
        "Some examples of how pandas simplifies time series analysis include:\n",
        "\n",
        "- Creating a time series index and using it to select and manipulate data\n",
        "- Resampling and aggregating data to calculate daily or monthly means\n",
        "- Plotting time series data using matplotlib or seaborn\n",
        "- Handling time zones and holidays/weekends\n",
        "- Performing rolling and expanding window calculations\n",
        "\n"
      ],
      "metadata": {
        "id": "CanfFnMNRM6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Create a sample time series dataset\n",
        "np.random.seed(0)\n",
        "dates = pd.date_range('2022-01-01', periods=12)\n",
        "values = np.random.randint(0, 100, size=12)\n",
        "df = pd.DataFrame({'values': values}, index=dates)\n"
      ],
      "metadata": {
        "id": "JM0XCowMRSLY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resample and aggregate the data to calculate monthly means\n",
        "monthly_means = df.resample('M').mean()\n",
        "print(monthly_means)"
      ],
      "metadata": {
        "id": "Dzkbh8aJRVNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#20. What is the role of a pivot table in pandas?"
      ],
      "metadata": {
        "id": "YrhdeEDQRbHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- In pandas, a pivot table is a powerful data summarization tool that allows you to transform and summarize data from a DataFrame. The role of a pivot table is to:\n",
        "\n",
        "1. Aggregate data: Pivot tables allow you to aggregate data by grouping it based on specific columns and performing calculations such as sum, mean, count, etc.\n",
        "2. Transform data: Pivot tables enable you to transform data from a long format to a wide format, making it easier to analyze and visualize.\n",
        "3. Summarize data: Pivot tables provide a concise summary of the data, making it easier to understand and analyze.\n",
        "\n",
        "The main benefits of using pivot tables in pandas are:\n",
        "\n",
        "1. Improved data analysis: Pivot tables enable you to analyze data from different angles, making it easier to identify trends, patterns, and correlations.\n",
        "2. Enhanced data visualization: Pivot tables provide a concise summary of the data, making it easier to create informative and interactive visualizations.\n",
        "3. Increased productivity: Pivot tables automate many data summarization tasks, freeing up time for more complex analysis and decision-making.\n",
        "\n",
        "Some common use cases for pivot tables in pandas include:\n",
        "\n",
        "1. Data summarization: Summarizing sales data by region, product, and time period.\n",
        "2. Data analysis: Analyzing customer behavior by demographic, purchase history, and marketing campaigns.\n",
        "3. Data visualization: Creating interactive dashboards to visualize sales trends, customer behavior, and market insights.\n"
      ],
      "metadata": {
        "id": "68JAMUpjRtNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {'Region': ['North', 'South', 'East', 'West'],\n",
        "        'Product': ['A', 'B', 'A', 'B'],\n",
        "        'Sales': [100, 200, 300, 400]}\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "pLCzfJ5LRx9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pivot table\n",
        "pivot_table = pd.pivot_table(df, values='Sales', index='Region', columns='Product')\n",
        "\n",
        "print(pivot_table)\n"
      ],
      "metadata": {
        "id": "nyNKYvMTR1FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#21. Why is numpy's role of a pivot table in pandas?"
      ],
      "metadata": {
        "id": "Km59xmBQR3c3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- NumPy doesn't have a direct role in pivot tables in pandas. However, NumPy is a fundamental library for numerical computing in Python, and pandas relies heavily on NumPy for its core data structures and operations.\n",
        "\n",
        "In the context of pivot tables, NumPy's role is indirect, but crucial. Here are a few ways NumPy contributes to pivot tables in pandas:\n",
        "\n",
        "1. Data storage: Pandas uses NumPy arrays to store data in DataFrames and Series. When creating a pivot table, pandas relies on NumPy arrays to store the aggregated data.\n",
        "2. Numerical computations: Pivot tables involve numerical computations, such as summing, averaging, or counting values. NumPy provides the underlying numerical computations for these operations.\n",
        "3. Data alignment: When creating a pivot table, pandas needs to align data from different columns and rows. NumPy's broadcasting and indexing capabilities help pandas perform these alignments efficiently.\n",
        "\n",
        "In summary, while NumPy doesn't have a direct role in pivot tables, its underlying numerical computing capabilities and data storage structures are essential for pandas to create and manipulate pivot tables efficiently."
      ],
      "metadata": {
        "id": "2UmRTpLISKFo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#22.What are some common use cases for seaborn?"
      ],
      "metadata": {
        "id": "cW-lKW9bSMNf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Seaborn is a popular Python data visualization library that provides a high-level interface for creating informative and attractive statistical graphics. Here are some common use cases for seaborn:\n",
        "\n",
        "1. Exploratory Data Analysis (EDA): Seaborn provides a range of visualization tools for EDA, such as scatterplots, boxplots, and violin plots, to help understand the distribution of variables and relationships between them.\n",
        "\n",
        "2. Statistical Graphics: Seaborn offers a range of statistical graphics, such as regression plots, residual plots, and Q-Q plots, to visualize and analyze statistical models.\n",
        "\n",
        "3. Data Visualization for Machine Learning: Seaborn provides visualization tools for machine learning, such as confusion matrices, ROC curves, and precision-recall curves, to help evaluate and compare the performance of different models.\n",
        "\n",
        "4. Time Series Analysis: Seaborn offers visualization tools for time series analysis, such as time series plots, autocorrelation plots, and partial autocorrelation plots, to help understand and analyze time series data.\n",
        "\n",
        "5. Categorical Data Analysis: Seaborn provides visualization tools for categorical data analysis, such as bar plots, count plots, and box plots, to help understand and compare categorical variables.\n",
        "\n",
        "6. Heatmap Visualization: Seaborn offers a range of heatmap visualization tools, such as clustermaps, heatmap plots, and correlation matrices, to help visualize and analyze high-dimensional data.\n",
        "\n",
        "7. Customizable Visualizations: Seaborn provides a range of customizable visualization options, such as colors, fonts, and layouts, to help create informative and attractive visualizations.\n",
        "\n",
        "Some examples of seaborn usage include:\n",
        "\n",
        "- Visualizing the distribution of a variable using a histogram or density plot.\n",
        "- Creating a scatterplot to visualize the relationship between two variables.\n",
        "- Using a boxplot or violin plot to compare the distribution of a variable across different groups.\n",
        "- Creating a heatmap to visualize the correlation between different variables.\n",
        "- Using a regression plot to visualize the relationship between a dependent variable and one or more independent variables.\n"
      ],
      "metadata": {
        "id": "5D5QpOzQScOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "9QFIeiSZSf6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the tips dataset\n",
        "tips = sns.load_dataset(\"tips\")\n"
      ],
      "metadata": {
        "id": "1VchkuzeSipe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a scatterplot\n",
        "sns.scatterplot(x=\"total_bill\", y=\"tip\", data=tips)\n"
      ],
      "metadata": {
        "id": "nXz4J7cRSlOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the plot\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ckUc1urLSn2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Practical"
      ],
      "metadata": {
        "id": "xRLNuo26Sqdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. How do you create a 2D Numpy array and calculate the sum of each row?"
      ],
      "metadata": {
        "id": "HVWuCf-YSumv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Here's an example of how to create a 2D NumPy array and calculate the sum of each row:"
      ],
      "metadata": {
        "id": "FMTX6BG0TCA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a 2D NumPy array\n",
        "arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n"
      ],
      "metadata": {
        "id": "F91jEDVFTGPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the array\n",
        "print(\"2D Array:\")\n",
        "print(arr)\n"
      ],
      "metadata": {
        "id": "l3j2iIOwTI3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the sum of each row\n",
        "row_sums = np.sum(arr, axis=1)\n"
      ],
      "metadata": {
        "id": "tcET87y7TNmU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the sum of each row\n",
        "print(\"\\nSum of each row:\")\n",
        "print(row_sums)\n"
      ],
      "metadata": {
        "id": "YzM_Sv53TQlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Write a pandas script to find the mean of a specific column in a Dataframe."
      ],
      "metadata": {
        "id": "eb_OR5i1TUeQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Here is a simple pandas script that calculates the mean of a specific column in a DataFrame:\n"
      ],
      "metadata": {
        "id": "W8JsbKgOTqhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {'Name': ['John', 'Anna', 'Peter', 'Linda'],\n",
        "        'Age': [28, 24, 35, 32],\n",
        "        'Score': [85, 90, 78, 92]}\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "IVI-ywEDTuKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the DataFrame\n",
        "print(\"DataFrame:\")\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "Yb1SC64fTwm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean of the 'Score' column\n",
        "mean_score = df['Score'].mean()\n"
      ],
      "metadata": {
        "id": "SDmYrH3ZTzg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the mean score\n",
        "print(\"\\nMean Score:\")\n",
        "print(mean_score)\n",
        "\n"
      ],
      "metadata": {
        "id": "OuLrq69sT2ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Create a scatter plot using matplotlib."
      ],
      "metadata": {
        "id": "EGJoAoVfT57Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Here's an example of creating a scatter plot using matplotlib:\n"
      ],
      "metadata": {
        "id": "Xm-RfcdtUMj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Create some sample data\n",
        "np.random.seed(0)\n",
        "x = np.random.rand(50)\n",
        "y = np.random.rand(50)\n"
      ],
      "metadata": {
        "id": "7mSO64FjURgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the scatter plot\n",
        "plt.scatter(x, y)\n"
      ],
      "metadata": {
        "id": "swG9kCn2UUk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Add title and labels\n",
        "plt.title('Scatter Plot Example')\n",
        "plt.xlabel('X-axis')\n",
        "plt.ylabel('Y-axis')\n"
      ],
      "metadata": {
        "id": "YGpepw8mUXbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qszL2jTzUaaO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. How do you calculate the correletion matrix using seaborn and visualize it with a heatmap?"
      ],
      "metadata": {
        "id": "nJGSyOCOUdMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Here's an example of how to calculate the correlation matrix using seaborn and visualize it with a heatmap:\n",
        "\n"
      ],
      "metadata": {
        "id": "0eGMCCQNU2am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "np.random.seed(0)\n",
        "data = np.random.rand(100, 5)\n",
        "df = pd.DataFrame(data, columns=['A', 'B', 'C', 'D', 'E'])\n"
      ],
      "metadata": {
        "id": "Z15_jRIBU-Vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the correlation matrix\n",
        "corr_matrix = df.corr()\n"
      ],
      "metadata": {
        "id": "jaGFZDUXVBB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', square=True)\n"
      ],
      "metadata": {
        "id": "OzSgNFCrVD9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add title and labels\n",
        "plt.title('Correlation Matrix')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Features')\n",
        "\n"
      ],
      "metadata": {
        "id": "lxnzt1E9VGzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display the plot\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Itp6TQjLVJsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Generate a bar plot using plotly."
      ],
      "metadata": {
        "id": "4hop6TpbVLA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Here's an example of how to generate a bar plot using plotly:\n"
      ],
      "metadata": {
        "id": "9o2pjiUFVafv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Define the data\n",
        "categories = ['A', 'B', 'C', 'D', 'E']\n",
        "values = [10, 15, 7, 12, 20]\n"
      ],
      "metadata": {
        "id": "-4T8nDzWVenA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a bar plot\n",
        "fig = go.Figure(data=[go.Bar(x=categories, y=values)])"
      ],
      "metadata": {
        "id": "ETmhkSUpVhtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Customize the plot\n",
        "fig.update_layout(\n",
        "    title='Bar Plot Example',\n",
        "    xaxis_title='Categories',\n",
        "    yaxis_title='Values'\n",
        ")\n"
      ],
      "metadata": {
        "id": "Yae9wQoBVmPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "c4rg6TB4VqIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Create a Dataframe and add a new colum based on an existing column."
      ],
      "metadata": {
        "id": "zHvynWUFVsHI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Here's an example of how to create a DataFrame and add a new column based on an existing column:\n"
      ],
      "metadata": {
        "id": "P-3pYkmZWAGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {'Name': ['John', 'Anna', 'Peter', 'Linda'],\n",
        "        'Age': [28, 24, 35, 32]}\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "zGqNJRgQWDzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print the original DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "UcwzfNQsWGcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new column 'Adult' based on the 'Age' column\n",
        "df['Adult'] = df['Age'].apply(lambda x: 'Yes' if x >= 18 else 'No')"
      ],
      "metadata": {
        "id": "d1HepK_2WI8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the updated DataFrame\n",
        "print(\"\\nUpdated DataFrame:\")\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "xVsgknzXWMDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7. Write a program to perform element-wise multiplication of two numpy arrays."
      ],
      "metadata": {
        "id": "AR08btydWNVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Here's a simple program that performs element-wise multiplication of two numpy arrays:\n"
      ],
      "metadata": {
        "id": "fCscE5QjWlC4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create two numpy arrays\n",
        "array1 = np.array([1, 2, 3, 4, 5])\n",
        "array2 = np.array([6, 7, 8, 9, 10])\n"
      ],
      "metadata": {
        "id": "fDl2ZnvEWuDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the original arrays\n",
        "print(\"Array 1:\")\n",
        "print(array1)\n",
        "print(\"\\nArray 2:\")\n",
        "print(array2)\n"
      ],
      "metadata": {
        "id": "KS-5Kwg6Wxcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform element-wise multiplication\n",
        "result = array1 * array2\n"
      ],
      "metadata": {
        "id": "ZTAgFwboW0Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the result\n",
        "print(\"\\nResult of element-wise multiplication:\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "oKF8puFIW3Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8. Create a line plot with multipale lines using matplotlib."
      ],
      "metadata": {
        "id": "HXsha5xcW5aJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Here's an example of how to create a line plot with multiple lines using matplotlib:\n"
      ],
      "metadata": {
        "id": "fgaSZacLXO24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Create some sample data\n",
        "x = np.linspace(0, 10, 100)\n",
        "y1 = np.sin(x)\n",
        "y2 = np.cos(x)\n",
        "y3 = np.sin(2*x)\n"
      ],
      "metadata": {
        "id": "H_PwSJLDXSpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the line plot\n",
        "plt.plot(x, y1, label='sin(x)')\n",
        "plt.plot(x, y2, label='cos(x)')\n",
        "plt.plot(x, y3, label='sin(2x)')\n"
      ],
      "metadata": {
        "id": "xr6kOXrKXVjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Customize the plot\n",
        "plt.title('Line Plot with Multiple Lines')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend()\n",
        "plt.grid(True)\n"
      ],
      "metadata": {
        "id": "BzFfB__eXYtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "zSCa7xMrXb0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9. Generate a pandas Dataframe and filter rows where a column value is greater than a threshold."
      ],
      "metadata": {
        "id": "xU4Ary72XdP4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Here's an example of how to generate a pandas DataFrame and filter rows where a column value is greater than a threshold:\n"
      ],
      "metadata": {
        "id": "ehyj5k5lX3NY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Generate a sample DataFrame\n",
        "np.random.seed(0)\n",
        "data = {'Name': ['John', 'Anna', 'Peter', 'Linda', 'Tom'],\n",
        "        'Age': [28, 24, 35, 32, 40],\n",
        "        'Score': np.random.randint(0, 100, 5)}\n",
        "df = pd.DataFrame(data)\n"
      ],
      "metadata": {
        "id": "1o934DaYX6zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the original DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n"
      ],
      "metadata": {
        "id": "dEkuD6xyX9eP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the threshold\n",
        "threshold = 30\n"
      ],
      "metadata": {
        "id": "VlRapPyHYAsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter rows where 'Age' is greater than the threshold\n",
        "filtered_df = df[df['Age'] > threshold]\n"
      ],
      "metadata": {
        "id": "v5ZI9pRHYDs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print the filtered DataFrame\n",
        "print(\"\\nFiltered DataFrame:\")\n",
        "print(filtered_df)\n"
      ],
      "metadata": {
        "id": "tl6EdM_yYGP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10. Create a histogram using seaborn to visualize a distribution."
      ],
      "metadata": {
        "id": "c3_lW9NiYH_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Here's an example of how to create a histogram using seaborn to visualize a distribution:\n"
      ],
      "metadata": {
        "id": "f5ElCPbWYedf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Generate some sample data\n",
        "np.random.seed(0)\n",
        "data = np.random.randn(1000)\n"
      ],
      "metadata": {
        "id": "c_KqUwwrYiCH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a histogram\n",
        "sns.histplot(data, bins=30, kde=True)\n"
      ],
      "metadata": {
        "id": "BvkYO6kSYk93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Customize the plot\n",
        "plt.title('Histogram of a Normal Distribution')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Frequency')\n"
      ],
      "metadata": {
        "id": "uBk8YhfiYnnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vaSb_qAsYqDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11. Perform matrix multiplication using numpy."
      ],
      "metadata": {
        "id": "fApcDWK8YraH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Here's an example of how to perform matrix multiplication using numpy:\n"
      ],
      "metadata": {
        "id": "gUAK2xbsY5dv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define two matrices\n",
        "matrix_a = np.array([[1, 2], [3, 4]])\n",
        "matrix_b = np.array([[5, 6], [7, 8]])\n"
      ],
      "metadata": {
        "id": "TcPpywi0Y81w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the original matrices\n",
        "print(\"Matrix A:\")\n",
        "print(matrix_a)\n",
        "print(\"\\nMatrix B:\")\n",
        "print(matrix_b)\n",
        "\n"
      ],
      "metadata": {
        "id": "z5hl9e1NY_vP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform matrix multiplication\n",
        "result = np.matmul(matrix_a, matrix_b)\n"
      ],
      "metadata": {
        "id": "e_t2jnoSZC5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the result\n",
        "print(\"\\nResult of Matrix Multiplication:\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "RY2xLzSJZF3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12. Use pandas to load a CSV file and display its first 5 rows."
      ],
      "metadata": {
        "id": "TQjxUPadZIV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Here's an example of how to use pandas to load a CSV file and display its first 5 rows:\n"
      ],
      "metadata": {
        "id": "vWxxO-0GZabu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display the first 5 rows\n",
        "print(df.head(5))\n",
        "\n"
      ],
      "metadata": {
        "id": "A64xCUGzZ38f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this example, we first import the pandas library. Then, we use the read_csv() function to load the CSV file into a DataFrame df. Finally, we use the head() function to display the first 5 rows of the DataFrame.\n",
        "\n",
        "Note that you should replace 'data.csv' with the actual path to your CSV file.\n"
      ],
      "metadata": {
        "id": "AKZrcoYJaCWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define the path to the CSV file\n",
        "file_path = 'data.csv'\n",
        "\n",
        "try:\n",
        "    # Load the CSV file\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Display the first 5 rows\n",
        "    print(df.head(5))\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{file_path}' was not found.\")\n",
        "except pd.errors.EmptyDataError:\n",
        "    print(f\"Error: The file '{file_path}' is empty.\")\n",
        "except pd.errors.ParserError:\n",
        "    print(f\"Error: An error occurred while parsing the file '{file_path}'.\")\n"
      ],
      "metadata": {
        "id": "2XZhxkTSb-5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13. Create a 3D scatter plot using plotly."
      ],
      "metadata": {
        "id": "oBKgTJbEcMYw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ans:- Here's an example of how to create a 3D scatter plot using plotly:\n"
      ],
      "metadata": {
        "id": "_jNnG8FMce_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "import numpy as np\n",
        "\n",
        "# Generate some sample data\n",
        "np.random.seed(0)\n",
        "x = np.random.randn(100)\n",
        "y = np.random.randn(100)\n",
        "z = np.random.randn(100)\n",
        "\n"
      ],
      "metadata": {
        "id": "UNZCv65_citn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a 3D scatter plot\n",
        "fig = go.Figure(data=[go.Scatter3d(x=x, y=y, z=z, mode='markers')])\n"
      ],
      "metadata": {
        "id": "U3gbPn6IctKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Customize the plot\n",
        "fig.update_layout(\n",
        "    title='3D Scatter Plot',\n",
        "    scene=dict(\n",
        "        xaxis_title='X',\n",
        "        yaxis_title='Y',\n",
        "        zaxis_title='Z'\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "-l5HuOG4cws3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Display the plot\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "Z7UCcgQfc0Jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b2v61oXcbUf_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}