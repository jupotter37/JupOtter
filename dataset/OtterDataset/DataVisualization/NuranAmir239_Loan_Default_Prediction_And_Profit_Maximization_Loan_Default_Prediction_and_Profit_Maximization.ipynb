{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x10sqsjrxRFC"
      },
      "source": [
        "#### Import necessary python modules (libraries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kagglehub in /home/nuran/miniconda3/lib/python3.12/site-packages (0.3.4)\n",
            "Requirement already satisfied: seaborn in /home/nuran/miniconda3/lib/python3.12/site-packages (0.13.2)\n",
            "Requirement already satisfied: imblearn in /home/nuran/miniconda3/lib/python3.12/site-packages (0.0)\n",
            "Requirement already satisfied: xgboost in /home/nuran/miniconda3/lib/python3.12/site-packages (2.1.3)\n",
            "Requirement already satisfied: catboost in /home/nuran/miniconda3/lib/python3.12/site-packages (1.2.7)\n",
            "Requirement already satisfied: scikit-optimize in /home/nuran/miniconda3/lib/python3.12/site-packages (0.10.2)\n",
            "Requirement already satisfied: numpy in /home/nuran/miniconda3/lib/python3.12/site-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /home/nuran/miniconda3/lib/python3.12/site-packages (2.2.1)\n",
            "Requirement already satisfied: matplotlib in /home/nuran/miniconda3/lib/python3.12/site-packages (3.9.2)\n",
            "Requirement already satisfied: scikit-learn in /home/nuran/miniconda3/lib/python3.12/site-packages (1.5.2)\n",
            "Requirement already satisfied: scipy in /home/nuran/miniconda3/lib/python3.12/site-packages (1.13.1)\n",
            "Requirement already satisfied: ydata-profiling in /home/nuran/miniconda3/lib/python3.12/site-packages (4.12.0)\n",
            "Requirement already satisfied: packaging in /home/nuran/miniconda3/lib/python3.12/site-packages (from kagglehub) (23.2)\n",
            "Requirement already satisfied: requests in /home/nuran/miniconda3/lib/python3.12/site-packages (from kagglehub) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /home/nuran/miniconda3/lib/python3.12/site-packages (from kagglehub) (4.65.0)\n",
            "Requirement already satisfied: imbalanced-learn in /home/nuran/miniconda3/lib/python3.12/site-packages (from imblearn) (0.12.4)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /home/nuran/miniconda3/lib/python3.12/site-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: graphviz in /home/nuran/miniconda3/lib/python3.12/site-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: plotly in /home/nuran/miniconda3/lib/python3.12/site-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /home/nuran/miniconda3/lib/python3.12/site-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/nuran/miniconda3/lib/python3.12/site-packages (from scikit-optimize) (1.4.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /home/nuran/miniconda3/lib/python3.12/site-packages (from scikit-optimize) (24.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/nuran/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/nuran/miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/nuran/miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/nuran/miniconda3/lib/python3.12/site-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/nuran/miniconda3/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/nuran/miniconda3/lib/python3.12/site-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /home/nuran/miniconda3/lib/python3.12/site-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=8 in /home/nuran/miniconda3/lib/python3.12/site-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /home/nuran/miniconda3/lib/python3.12/site-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/nuran/miniconda3/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pydantic>=2 in /home/nuran/miniconda3/lib/python3.12/site-packages (from ydata-profiling) (2.9.2)\n",
            "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in /home/nuran/miniconda3/lib/python3.12/site-packages (from ydata-profiling) (6.0.2)\n",
            "Requirement already satisfied: jinja2<3.2,>=2.11.1 in /home/nuran/miniconda3/lib/python3.12/site-packages (from ydata-profiling) (3.1.4)\n",
            "Requirement already satisfied: visions<0.7.7,>=0.7.5 in /home/nuran/miniconda3/lib/python3.12/site-packages (from visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (0.7.6)\n",
            "Requirement already satisfied: htmlmin==0.1.12 in /home/nuran/miniconda3/lib/python3.12/site-packages (from ydata-profiling) (0.1.12)\n",
            "Requirement already satisfied: phik<0.13,>=0.11.1 in /home/nuran/miniconda3/lib/python3.12/site-packages (from ydata-profiling) (0.12.4)\n",
            "Requirement already satisfied: multimethod<2,>=1.4 in /home/nuran/miniconda3/lib/python3.12/site-packages (from ydata-profiling) (1.12)\n",
            "Requirement already satisfied: statsmodels<1,>=0.13.2 in /home/nuran/miniconda3/lib/python3.12/site-packages (from ydata-profiling) (0.14.4)\n",
            "Requirement already satisfied: typeguard<5,>=3 in /home/nuran/miniconda3/lib/python3.12/site-packages (from ydata-profiling) (4.4.1)\n",
            "Requirement already satisfied: imagehash==4.3.1 in /home/nuran/miniconda3/lib/python3.12/site-packages (from ydata-profiling) (4.3.1)\n",
            "Requirement already satisfied: wordcloud>=1.9.3 in /home/nuran/miniconda3/lib/python3.12/site-packages (from ydata-profiling) (1.9.4)\n",
            "Requirement already satisfied: dacite>=1.8 in /home/nuran/miniconda3/lib/python3.12/site-packages (from ydata-profiling) (1.8.1)\n",
            "Requirement already satisfied: numba<1,>=0.56.0 in /home/nuran/miniconda3/lib/python3.12/site-packages (from ydata-profiling) (0.60.0)\n",
            "Requirement already satisfied: PyWavelets in /home/nuran/miniconda3/lib/python3.12/site-packages (from imagehash==4.3.1->ydata-profiling) (1.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/nuran/miniconda3/lib/python3.12/site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling) (3.0.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/nuran/miniconda3/lib/python3.12/site-packages (from numba<1,>=0.56.0->ydata-profiling) (0.43.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/nuran/miniconda3/lib/python3.12/site-packages (from pydantic>=2->ydata-profiling) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /home/nuran/miniconda3/lib/python3.12/site-packages (from pydantic>=2->ydata-profiling) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /home/nuran/miniconda3/lib/python3.12/site-packages (from pydantic>=2->ydata-profiling) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/nuran/miniconda3/lib/python3.12/site-packages (from requests->kagglehub) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/nuran/miniconda3/lib/python3.12/site-packages (from requests->kagglehub) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/nuran/miniconda3/lib/python3.12/site-packages (from requests->kagglehub) (2.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/nuran/miniconda3/lib/python3.12/site-packages (from requests->kagglehub) (2024.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /home/nuran/miniconda3/lib/python3.12/site-packages (from statsmodels<1,>=0.13.2->ydata-profiling) (1.0.1)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /home/nuran/miniconda3/lib/python3.12/site-packages (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (24.2.0)\n",
            "Requirement already satisfied: networkx>=2.4 in /home/nuran/miniconda3/lib/python3.12/site-packages (from visions<0.7.7,>=0.7.5->visions[type_image_path]<0.7.7,>=0.7.5->ydata-profiling) (3.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /home/nuran/miniconda3/lib/python3.12/site-packages (from plotly->catboost) (9.0.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install kagglehub seaborn imblearn xgboost catboost scikit-optimize numpy pandas matplotlib seaborn scikit-learn scipy ydata-profiling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pprint import pprint  # Pretty-print for better visualization of data structures\n",
        "import numpy as np  # Numerical computing library for arrays and mathematical operations\n",
        "import pandas as pd  # Data manipulation and analysis\n",
        "import matplotlib.pyplot as plt  # Data visualization\n",
        "import seaborn as sns  # Advanced data visualization (built on matplotlib)\n",
        "\n",
        "# Preprocessing and splitting data\n",
        "from sklearn.preprocessing import LabelEncoder  # Encoding categorical variables\n",
        "from sklearn.model_selection import train_test_split  # Splitting dataset into train and test sets\n",
        "\n",
        "# Machine learning models\n",
        "from sklearn.linear_model import LogisticRegression  # Logistic Regression model\n",
        "from sklearn.neighbors import KNeighborsClassifier  # k-Nearest Neighbors classifier\n",
        "from sklearn.naive_bayes import GaussianNB  # Naive Bayes classifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier  # Ensemble models\n",
        "from xgboost import XGBClassifier  # Extreme Gradient Boosting model\n",
        "from catboost import CatBoostClassifier  # CatBoost gradient boosting mode\n",
        "\n",
        "# Metrics for model evaluation\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,  # Accuracy metric\n",
        "    precision_score,  # Precision metric\n",
        "    recall_score,  # Recall metric\n",
        "    f1_score,  # F1 score metric\n",
        "    confusion_matrix,  # Confusion matrix for evaluation\n",
        "    roc_auc_score,  # ROC-AUC score\n",
        "    classification_report  # Detailed classification report\n",
        ")\n",
        "\n",
        "# Optimization\n",
        "from scipy.optimize import minimize  # Optimization library for model optimization\n",
        "\n",
        "# Handling imbalanced datasets\n",
        "from imblearn.over_sampling import SMOTE  # Synthetic Minority Oversampling Technique\n",
        "from imblearn.under_sampling import RandomUnderSampler  # Random undersampling for imbalanced data\n",
        "\n",
        "from datetime import datetime  # Date and time operations\n",
        "import kagglehub  # Kaggle API for downloading datasets\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFeGcBhfxMYQ"
      },
      "source": [
        "### Call upon the data from Kaggle and print the path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAgwOWvny8Hq",
        "outputId": "28dbab04-c81b-4547-b067-855a32bf85fd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LoanID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Income</th>\n",
              "      <th>LoanAmount</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>MonthsEmployed</th>\n",
              "      <th>NumCreditLines</th>\n",
              "      <th>InterestRate</th>\n",
              "      <th>LoanTerm</th>\n",
              "      <th>DTIRatio</th>\n",
              "      <th>Education</th>\n",
              "      <th>EmploymentType</th>\n",
              "      <th>MaritalStatus</th>\n",
              "      <th>HasMortgage</th>\n",
              "      <th>HasDependents</th>\n",
              "      <th>LoanPurpose</th>\n",
              "      <th>HasCoSigner</th>\n",
              "      <th>Default</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I38PQUQS96</td>\n",
              "      <td>56</td>\n",
              "      <td>85994</td>\n",
              "      <td>50587</td>\n",
              "      <td>520</td>\n",
              "      <td>80</td>\n",
              "      <td>4</td>\n",
              "      <td>15.23</td>\n",
              "      <td>36</td>\n",
              "      <td>0.44</td>\n",
              "      <td>Bachelor's</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Other</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>HPSK72WA7R</td>\n",
              "      <td>69</td>\n",
              "      <td>50432</td>\n",
              "      <td>124440</td>\n",
              "      <td>458</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>4.81</td>\n",
              "      <td>60</td>\n",
              "      <td>0.68</td>\n",
              "      <td>Master's</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Married</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Other</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C1OZ6DPJ8Y</td>\n",
              "      <td>46</td>\n",
              "      <td>84208</td>\n",
              "      <td>129188</td>\n",
              "      <td>451</td>\n",
              "      <td>26</td>\n",
              "      <td>3</td>\n",
              "      <td>21.17</td>\n",
              "      <td>24</td>\n",
              "      <td>0.31</td>\n",
              "      <td>Master's</td>\n",
              "      <td>Unemployed</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Auto</td>\n",
              "      <td>No</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>V2KKSFM3UN</td>\n",
              "      <td>32</td>\n",
              "      <td>31713</td>\n",
              "      <td>44799</td>\n",
              "      <td>743</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7.07</td>\n",
              "      <td>24</td>\n",
              "      <td>0.23</td>\n",
              "      <td>High School</td>\n",
              "      <td>Full-time</td>\n",
              "      <td>Married</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>Business</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>EY08JDHTZP</td>\n",
              "      <td>60</td>\n",
              "      <td>20437</td>\n",
              "      <td>9139</td>\n",
              "      <td>633</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>6.51</td>\n",
              "      <td>48</td>\n",
              "      <td>0.73</td>\n",
              "      <td>Bachelor's</td>\n",
              "      <td>Unemployed</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>No</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Auto</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       LoanID  Age  Income  LoanAmount  CreditScore  MonthsEmployed  \\\n",
              "0  I38PQUQS96   56   85994       50587          520              80   \n",
              "1  HPSK72WA7R   69   50432      124440          458              15   \n",
              "2  C1OZ6DPJ8Y   46   84208      129188          451              26   \n",
              "3  V2KKSFM3UN   32   31713       44799          743               0   \n",
              "4  EY08JDHTZP   60   20437        9139          633               8   \n",
              "\n",
              "   NumCreditLines  InterestRate  LoanTerm  DTIRatio    Education  \\\n",
              "0               4         15.23        36      0.44   Bachelor's   \n",
              "1               1          4.81        60      0.68     Master's   \n",
              "2               3         21.17        24      0.31     Master's   \n",
              "3               3          7.07        24      0.23  High School   \n",
              "4               4          6.51        48      0.73   Bachelor's   \n",
              "\n",
              "  EmploymentType MaritalStatus HasMortgage HasDependents LoanPurpose  \\\n",
              "0      Full-time      Divorced         Yes           Yes       Other   \n",
              "1      Full-time       Married          No            No       Other   \n",
              "2     Unemployed      Divorced         Yes           Yes        Auto   \n",
              "3      Full-time       Married          No            No    Business   \n",
              "4     Unemployed      Divorced          No           Yes        Auto   \n",
              "\n",
              "  HasCoSigner  Default  \n",
              "0         Yes        0  \n",
              "1         Yes        0  \n",
              "2          No        1  \n",
              "3          No        0  \n",
              "4          No        0  "
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"nikhil1e9/loan-default\") #dataset from kaggle\n",
        "data = pd.read_csv(str(path) + '/Loan_default.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9p2CK_E0V8j"
      },
      "source": [
        "#### Drop Unnecessary Column LoanID as its a set of random symbols that resemble an ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = data.drop(['LoanID'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Drop Unnecessary columns (deduced from the EDA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [],
      "source": [
        "columns_to_drop = ['LoanTerm', 'NumCreditLines']\n",
        "data = data.drop(columns=columns_to_drop, errors='ignore')  # errors='ignore' ensures no errors if a column is missing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Encode the categorical features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "encoder = LabelEncoder()\n",
        "obj_col = ['HasCoSigner','LoanPurpose','HasDependents', 'HasMortgage','MaritalStatus', 'EmploymentType', 'Education'] # these are all categorical columns\n",
        "for col in obj_col:\n",
        "    data[col] = encoder.fit_transform(data[col])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Making sure its encoded properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Age                 int64\n",
              "Income              int64\n",
              "LoanAmount          int64\n",
              "CreditScore         int64\n",
              "MonthsEmployed      int64\n",
              "InterestRate      float64\n",
              "DTIRatio          float64\n",
              "Education           int64\n",
              "EmploymentType      int64\n",
              "MaritalStatus       int64\n",
              "HasMortgage         int64\n",
              "HasDependents       int64\n",
              "LoanPurpose         int64\n",
              "HasCoSigner         int64\n",
              "Default             int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Splitting the data into a training dataset (75% of the data is going towards training+validation and 25% is going towards testing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [],
      "source": [
        "X = data.drop(columns=['Default'])\n",
        "y = data['Default']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y) # Stratification ensures that the proportion of Default is similar in both train and test datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Experimenting witrh different techniques to deal withe imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# Create different training datasets\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_downsampled, y_downsampled = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_upsampled, y_upsampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Use original training data for one model\n",
        "X_original, y_original = X_train, y_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Training Data Shape: (191510, 14) (191510,)\n",
            "Downsampled Training Data Shape: (44480, 14) (44480,)\n",
            "Upsampled Training Data Shape: (338540, 14) (338540,)\n"
          ]
        }
      ],
      "source": [
        "print(\"Original Training Data Shape:\", X_original.shape, y_original.shape)\n",
        "print(\"Downsampled Training Data Shape:\", X_downsampled.shape, y_downsampled.shape)\n",
        "print(\"Upsampled Training Data Shape:\", X_upsampled.shape, y_upsampled.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Experimenting with traditional Machine Learning Techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define models\n",
        "models = [\n",
        "    # CatBoostClassifier(verbose=False),\n",
        "    XGBClassifier(),\n",
        "    # RandomForestClassifier(),\n",
        "    # KNeighborsClassifier(),\n",
        "    # LogisticRegression(),\n",
        "    # GaussianNB()\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List to store all experiment results\n",
        "experiment_results = []\n",
        "\n",
        "# Function to adjust threshold for optimizing TN and minimizing FN\n",
        "def optimize_threshold(y_true, y_probs, metric=\"tn_fn\"):\n",
        "    \"\"\"\n",
        "    Finds the best threshold for a given model by optimizing a custom metric.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_true : array-like\n",
        "        True labels\n",
        "    y_probs : array-like\n",
        "        Predicted probabilities\n",
        "    metric : str, optional\n",
        "        Metric to optimize, by default \"tn_fn\". Can be \"accuracy\", \"tn_fn\", or a custom metric.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    best_threshold : float\n",
        "        Best threshold for optimizing the chosen metric\n",
        "    best_score : float\n",
        "        Best score for the chosen metric\n",
        "    \"\"\"\n",
        "    best_threshold = 0.5\n",
        "    best_score = -np.inf\n",
        "\n",
        "    for threshold in np.arange(0.0, 1.05, 0.05):  # Search thresholds from 0.0 to 1.0 in steps of 0.05\n",
        "        y_pred = (y_probs >= threshold).astype(int)\n",
        "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "        \n",
        "        # Custom metric to balance TN and FN\n",
        "        if metric == \"tn_fn\":\n",
        "            score = tn - fn \n",
        "        else:\n",
        "            score = accuracy_score(y_true, y_pred)\n",
        "\n",
        "        if score > best_score: #if score is better is better than teh current best , rename the best to the new score and do teh same for the threshold\n",
        "            best_score = score\n",
        "            best_threshold = threshold\n",
        "\n",
        "    return best_threshold\n",
        "\n",
        "# Function to run experiments with threshold optimization\n",
        "def run_experiment_with_cv(models, X_resampled, y_resampled, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Runs a series of experiments on a given set of models with cross-validation\n",
        "    and threshold optimization.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    models : list\n",
        "        List of models to experiment with\n",
        "    X_resampled : array-like\n",
        "        Resampled training features\n",
        "    y_resampled : array-like\n",
        "        Resampled training labels\n",
        "    X_test : array-like\n",
        "        Test features\n",
        "    y_test : array-like\n",
        "        Test labels\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    results : list\n",
        "        List of results for each model, including the model name, threshold, TN, FN, accuracy, precision, recall, F1 score, and AUC-ROC score\n",
        "    \"\"\"\n",
        "\n",
        "    experiment_name = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    results = []\n",
        "\n",
        "    for model in models:\n",
        "        # Train the model on the resampled training set\n",
        "        model.fit(X_resampled, y_resampled)\n",
        "\n",
        "        # Predict probabilities on the test set\n",
        "        y_test_probs = model.predict_proba(X_test)[:, 1]  # Get probabilities for the positive class\n",
        "\n",
        "        # Optimize the threshold\n",
        "        best_threshold = optimize_threshold(y_test, y_test_probs)\n",
        "\n",
        "        # Make predictions with the best threshold\n",
        "        y_test_pred = (y_test_probs >= best_threshold).astype(int)\n",
        "\n",
        "        # Calculate metrics\n",
        "        tn, fp, fn, tp = confusion_matrix(y_test, y_test_pred).ravel()\n",
        "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "        test_precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
        "        test_recall = recall_score(y_test, y_test_pred)\n",
        "        test_f1 = f1_score(y_test, y_test_pred)\n",
        "        test_auc = roc_auc_score(y_test, y_test_probs)\n",
        "\n",
        "        results.append({\n",
        "            \"Experiment\": experiment_name,\n",
        "            \"Model\": model.__class__.__name__,\n",
        "            \"Threshold\": best_threshold,\n",
        "            \"True Negatives\": tn,\n",
        "            \"False Positives\": fp,\n",
        "            \"False Negatives\": fn,\n",
        "            \"True Positives\": tp,\n",
        "            \"Test Accuracy\": test_accuracy,\n",
        "            \"Test Precision\": test_precision,\n",
        "            \"Test Recall\": test_recall,\n",
        "            \"Test F1 Score\": test_f1,\n",
        "            \"Test AUC\": test_auc\n",
        "        })\n",
        "    \n",
        "    # Convert results to DataFrame\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Save the results for this experiment\n",
        "    experiment_results.append(results_df)\n",
        "    results_df.to_csv(f\"{experiment_name}_threshold_optimized_results.csv\", index=False)\n",
        "    print(f\"Results saved for experiment: {experiment_name}\")\n",
        "\n",
        "    return y_test_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare the datasets\n",
        "# Original dataset\n",
        "X_original, y_original = X_train.copy(), y_train.copy()\n",
        "\n",
        "# Downsampled dataset\n",
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_downsampled, y_downsampled = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "# Upsampled dataset\n",
        "smote = SMOTE(random_state=42)\n",
        "X_upsampled, y_upsampled = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running models on Original Dataset\n",
            "Results saved for experiment: 2024-12-01_04-42-23\n",
            "\n",
            "Running models on Downsampled Dataset\n",
            "Results saved for experiment: 2024-12-01_04-42-23\n",
            "\n",
            "Running models on Upsampled Dataset\n",
            "Results saved for experiment: 2024-12-01_04-42-24\n"
          ]
        }
      ],
      "source": [
        "# Function to collect predictions from multiple runs\n",
        "def collect_predictions():\n",
        "    \"\"\"\n",
        "    Collect predictions from multiple runs on the original, downsampled, and upsampled datasets.\n",
        "\n",
        "    Returns a dictionary with the following structure:\n",
        "    {\n",
        "        \"Original\": {},\n",
        "        \"Downsampled\": {},\n",
        "        \"Upsampled\": {}\n",
        "    }\n",
        "    \"\"\"\n",
        "    predictions = {}\n",
        "\n",
        "    # Original dataset\n",
        "    print(\"\\nRunning models on Original Dataset\")\n",
        "    predictions[\"Original\"] = run_experiment_with_cv(models, X_original, y_original, X_test, y_test)\n",
        "\n",
        "    # Downsampled dataset\n",
        "    print(\"\\nRunning models on Downsampled Dataset\")\n",
        "    predictions[\"Downsampled\"] = run_experiment_with_cv(models, X_downsampled, y_downsampled, X_test, y_test)\n",
        "\n",
        "    # Upsampled dataset\n",
        "    print(\"\\nRunning models on Upsampled Dataset\")\n",
        "    predictions[\"Upsampled\"] = run_experiment_with_cv(models, X_upsampled, y_upsampled, X_test, y_test)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "# Run the experiments and collect predictions\n",
        "all_predictions = collect_predictions()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Optimized Ensemble Evaluation:\n",
            "Optimized Weights: [0.33333333 0.33333333 0.33333333]\n",
            "\n",
            "Confusion Matrix:\n",
            "[[55879   545]\n",
            " [ 6748   665]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.99      0.94     56424\n",
            "           1       0.55      0.09      0.15      7413\n",
            "\n",
            "    accuracy                           0.89     63837\n",
            "   macro avg       0.72      0.54      0.55     63837\n",
            "weighted avg       0.85      0.89      0.85     63837\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Negatives (TN): 55879\n",
            "False Negatives (FN): 6748\n"
          ]
        }
      ],
      "source": [
        "# Function to calculate True Negatives and False Negatives from the ensemble\n",
        "# Optimize the weights for the ensemble\n",
        "def optimize_weights(all_predictions, y_test):\n",
        "    def objective(weights):\n",
        "        # Calculate weighted probabilities\n",
        "        weighted_probs = np.dot(weights, all_predictions)\n",
        "\n",
        "        # Optimize threshold\n",
        "        best_threshold = optimize_threshold(y_test, weighted_probs)\n",
        "        y_pred = (weighted_probs >= best_threshold).astype(int)\n",
        "\n",
        "        # Calculate confusion matrix\n",
        "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "        # Define custom metric: maximize TN and minimize FN\n",
        "        return -(tn - fn)  # Negative to maximize\n",
        "\n",
        "    # Initial weights (equal weights for all models)\n",
        "    n_models = all_predictions.shape[0]\n",
        "    initial_weights = np.ones(n_models) / n_models\n",
        "\n",
        "    # Bounds and constraints for weights\n",
        "    bounds = [(0, 1) for _ in range(n_models)]\n",
        "    constraints = {\"type\": \"eq\", \"fun\": lambda w: np.sum(w) - 1}\n",
        "\n",
        "    # Perform optimization\n",
        "    result = minimize(objective, initial_weights, bounds=bounds, constraints=constraints)\n",
        "    return result.x  # Return optimized weights\n",
        "    \n",
        "def calculate_tn_fn(y_test, ensemble_pred):\n",
        "    \"\"\"\n",
        "    Calculate True Negatives and False Negatives from the ensemble predictions.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    y_test : array-like\n",
        "        Test labels\n",
        "    ensemble_pred : array-like\n",
        "        Ensemble predictions\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    tn : int\n",
        "        True Negatives\n",
        "    fn : int\n",
        "        False Negatives\n",
        "    \"\"\"\n",
        "    # Generate confusion matrix\n",
        "    cm = confusion_matrix(y_test, ensemble_pred)\n",
        "    \n",
        "    # Extract True Negatives (TN) and False Negatives (FN)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    return tn, fn\n",
        "\n",
        "# Ensemble predictions with optimized weights and threshold\n",
        "def ensemble_predictions(all_predictions, y_test):\n",
        "    \"\"\"\n",
        "    Generate ensemble predictions with optimized weights and threshold.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    all_predictions : dict\n",
        "        Dictionary of predictions from different models\n",
        "    y_test : array-like\n",
        "        Test labels\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ensemble_pred : array-like\n",
        "        Ensemble predictions\n",
        "    optimized_weights : array-like\n",
        "        Optimized weights for the ensemble\n",
        "    best_threshold : float\n",
        "        Best threshold for the ensemble\n",
        "    tn : int\n",
        "        True Negatives\n",
        "    fn : int\n",
        "        False Negatives\n",
        "    \"\"\"\n",
        "    # Convert all_predictions dictionary to a stacked array\n",
        "    prediction_array = np.array(list(all_predictions.values()))  # Shape: (n_models, n_samples)\n",
        "\n",
        "    # Optimize weights for the ensemble\n",
        "    optimized_weights = optimize_weights(prediction_array, y_test)\n",
        "\n",
        "    # Calculate weighted probabilities\n",
        "    weighted_probs = np.dot(optimized_weights, prediction_array)\n",
        "\n",
        "    # Optimize threshold\n",
        "    best_threshold = optimize_threshold(y_test, weighted_probs)\n",
        "\n",
        "    # Generate ensemble predictions\n",
        "    ensemble_pred = (weighted_probs >= best_threshold).astype(int)\n",
        "\n",
        "    # Evaluate the ensemble\n",
        "    print(\"\\nOptimized Ensemble Evaluation:\")\n",
        "    print(\"Optimized Weights:\", optimized_weights)\n",
        "\n",
        "    # Calculate TN and FN\n",
        "    tn, fn = calculate_tn_fn(y_test, ensemble_pred)\n",
        "\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    cm = confusion_matrix(y_test, ensemble_pred)\n",
        "    print(cm)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, ensemble_pred))\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='coolwarm', cbar=False,\n",
        "                xticklabels=np.unique(y_test), yticklabels=np.unique(y_test))\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return ensemble_pred, optimized_weights, best_threshold, tn, fn\n",
        "\n",
        "\n",
        "ensemble_pred, optimized_weights, best_threshold, tn, fn = ensemble_predictions(all_predictions, y_test)\n",
        "\n",
        "# Print the TN and FN values\n",
        "print(f\"True Negatives (TN): {tn}\")\n",
        "print(f\"False Negatives (FN): {fn}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True Negatives (approved loans): 55879\n",
            "False Negatives (defaults): 6748\n",
            "Income from approved loans: 1676370.00 OMR\n",
            "Total loss from defaults: 1359860.58 OMR\n",
            "\n",
            "##########################################################################################\n",
            "                Net profit: 316509.42 OMR\n",
            "##########################################################################################\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def calculate_net_profit(tn_count, fn_count, mu=5, sigma=1.0):\n",
        "    \"\"\"\n",
        "    Calculate the net profit.\n",
        "\n",
        "    Parameters:\n",
        "    - tn_count: Number of true negatives (approved loans that are fine).\n",
        "    - fn_count: Number of false negatives (approved loans that defaulted).\n",
        "    - mu: Mean of the log-normal distribution.\n",
        "    - sigma: Standard deviation of the log-normal distribution.\n",
        "\n",
        "    Returns:\n",
        "    - net_profit: The total net profit.\n",
        "    \"\"\"\n",
        "    np.random.seed(42)\n",
        "    # Income from approved loans (True Negatives)\n",
        "    income = tn_count * 30\n",
        "\n",
        "    # Loss from defaults (False Negatives)\n",
        "    losses = np.random.lognormal(mean=mu, sigma=sigma, size=fn_count)\n",
        "\n",
        "    # Ensure losses are between 50 and 1000 OMR\n",
        "    losses_clipped = np.clip(losses, 50, 1000)\n",
        "    total_loss = losses_clipped.sum()\n",
        "\n",
        "    # Net profit\n",
        "    net_profit = income - total_loss\n",
        "\n",
        "    # Print details\n",
        "    print(f\"True Negatives (approved loans): {tn_count}\")\n",
        "    print(f\"False Negatives (defaults): {fn_count}\")\n",
        "    print(f\"Income from approved loans: {income:.2f} OMR\")\n",
        "    print(f\"Total loss from defaults: {total_loss:.2f} OMR\")\n",
        "    print(\"\")\n",
        "    print(\"###\"*30)\n",
        "    print(\" \"*15, f\"Net profit: {net_profit:.2f} OMR\")\n",
        "    print(\"###\"*30)\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "    return net_profit\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "net_profit = calculate_net_profit(tn, fn, mu=5, sigma=0.8)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
