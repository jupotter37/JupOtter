{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(pageNumber):\n",
    "    template = 'https://www.seek.com.au/Data-Analyst-jobs?page={}'\n",
    "    #url = template.format(position,location)\n",
    "    return template\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = get_url(1)\n",
    "response = requests.get(url)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = soup.find_all('div','_1wkzzau0 a1msqi7e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Analyst\n",
      "https://seek.com.au/job/68883164?type=promoted\n",
      "Australian Automobile Association\n",
      "Canberra ACT\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "job = links[0]\n",
    "t = job.div.div.article\n",
    "jobTitle = t.get('aria-label')\n",
    "print(jobTitle)\n",
    "\n",
    "t = job.div.div.article.a\n",
    "jobLink = 'https://seek.com.au' + t.get('href')\n",
    "print(jobLink)\n",
    "\n",
    "jobCompany = job.find('a',{'data-automation': 'jobCompany'}).text\n",
    "#jobCompany = jobCompany.get('title')[8:]\n",
    "print(jobCompany)\n",
    "\n",
    "jobLocation = job.find('a',{'data-automation': 'jobLocation'}).text\n",
    "print(jobLocation)\n",
    "\n",
    "jobSalary = job.find('span', '_1wkzzau0 _16v7pfz1 a1msqi4y a1msqi0 a1msqir _16v7pfz3')\n",
    "print(jobSalary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills found in the text:\n",
      "['Android', 'iOS', 'Unity']\n"
     ]
    }
   ],
   "source": [
    "j = requests.get(jobLink)\n",
    "j\n",
    "jj = BeautifulSoup(j.text,'html.parser')\n",
    "webText = jj.text\n",
    "# List of well-known programming languages and skills\n",
    "skillList = [\n",
    "    \"Python\",\n",
    "    \"JavaScript\",\n",
    "    \"Java\",\n",
    "    \"C++\",\n",
    "    \"C#\",\n",
    "    \"HTML\",\n",
    "    \"CSS\",\n",
    "    \"SQL\",\n",
    "    \"React\",\n",
    "    \"Angular\",\n",
    "    \"Node.js\",\n",
    "    \"Ruby\",\n",
    "    \"PHP\",\n",
    "    \"Swift\",\n",
    "    \"TypeScript\",\n",
    "    \"Machine Learning\",\n",
    "    \"Artificial Intelligence\",\n",
    "    \"Data Science\",\n",
    "    \"Blockchain\",\n",
    "    \"Android\",\n",
    "    \"iOS\",\n",
    "    \"Unity\",\n",
    "    \"Game Development\",\n",
    "    \"DevOps\",\n",
    "    \"Git\",\n",
    "    \"Docker\",\n",
    "    \"Kubernetes\",\n",
    "    \"Cloud Computing\",\n",
    "    \"AWS\",\n",
    "    \"Azure\",\n",
    "]\n",
    "\n",
    "# Find skills in the list that are present in the text\n",
    "found_skills = [skill for skill in skillList if skill.lower() in jj.text.lower()]\n",
    "\n",
    "# Display the found skills\n",
    "print(\"Skills found in the text:\")\n",
    "print(found_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def getSkills(url):\n",
    "    j = requests.get(url)\n",
    "    jj = BeautifulSoup(j.text,'html.parser')\n",
    "    webText = jj.text\n",
    "    # List of well-known programming languages and skills\n",
    "    skillList = [\n",
    "    \"Python\",\n",
    "    \"R \",\n",
    "    \"SQL\",\n",
    "    \"Pandas\",\n",
    "    \"NumPy\",\n",
    "    \"Matplotlib\",\n",
    "    \"Seaborn\",\n",
    "    \"Plotly\",\n",
    "    \"Scikit-learn\",\n",
    "    \"TensorFlow\",\n",
    "    \"Keras\",\n",
    "    \"Machine Learning\",\n",
    "    \"Data Visualization\",\n",
    "    \"Statistical Analysis\",\n",
    "    \"Data Cleaning\",\n",
    "    \"Data Wrangling\",\n",
    "    \"Excel\",\n",
    "    \"Tableau\",\n",
    "    \"Power BI\",\n",
    "    \"Data Mining\",\n",
    "    \"ETL (Extract, Transform, Load)\",\n",
    "    \"Data Modeling\",\n",
    "    \"Business Intelligence\",\n",
    "    \"Predictive Analytics\",\n",
    "    \"Time Series Analysis\",\n",
    "    \"Data Manipulation\",\n",
    "    \"Data Interpretation\",\n",
    "    \"Data Reporting\",\n",
    "    \"Data Storytelling\",\n",
    "    \"Big Data\",\n",
    "    \"Hadoop\",\n",
    "    \"Spark\",\n",
    "    \"SQL Server\",\n",
    "    \"PostgreSQL\",\n",
    "    \"MongoDB\",\n",
    "    \"Data Warehousing\",\n",
    "    \"BI Tools (Business Intelligence)\",\n",
    "    ]\n",
    "\n",
    "    # Find skills in the list that are present in the text\n",
    "    found_skills = [skill for skill in skillList if skill.lower() in jj.text.lower()]\n",
    "    found_skills = [skill for skill in skillList if re.search(r'\\b' + re.escape(skill) + r'\\b', webText, re.IGNORECASE)]\n",
    "\n",
    "    return found_skills\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getInfo(job):\n",
    "    t = job.div.div.article\n",
    "    jobTitle = t.get('aria-label')\n",
    "\n",
    "    t = job.div.div.article.a\n",
    "    jobLink = 'https://seek.com.au' + t.get('href')\n",
    "\n",
    "    #jobCompany = job.find('a',{'title':'Jobs at Australian Automobile Association'})\n",
    "    jobCompany = job.find('a',{'data-automation': 'jobCompany'}).text\n",
    "    #jobCompany = jobCompany.get('title')[8:]\n",
    "\n",
    "    jobLocation = job.find('a',{'data-automation': 'jobLocation'}).text\n",
    "    \n",
    "    jobSalary = job.find('span', '_1wkzzau0 _16v7pfz1 a1msqi4y a1msqi0 a1msqir _16v7pfz3')\n",
    "    if jobSalary != None:\n",
    "        jobSalary = jobSalary.text.strip()\n",
    "    \n",
    "    jobSkills = getSkills(jobLink)\n",
    "\n",
    "    return (jobTitle, jobCompany, jobLocation, jobLink, jobSalary, jobSkills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "while i < 26:\n",
    "    url = get_url(i)\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    links = soup.find_all('div','_1wkzzau0 a1msqi7e')\n",
    "    \n",
    "    for job in links: \n",
    "        records.append(getInfo(job))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['Job Title', 'Job Company', 'Job Location', 'Job Link', 'Job Salary', 'Job Skills'])\n",
    "    writer.writerows(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
