{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas - Merging, grouping, aggregation and complex relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necesssary import evil\n",
    "\n",
    "import jupy_helpers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML, IFrame\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "# This will enable us to see plots embedded in the noteboo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the cells wide\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = 'sqlite:///./workshop_data.sqlite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data that we stored in the previous examples\n",
    "imdb_titles = pd.read_sql('imdb_titles', con)\n",
    "imdb_ratings = pd.read_sql('imdb_ratings', con)\n",
    "boxoffice = pd.read_sql('boxoffice', con)\n",
    "rotten_tomatoes = pd.read_sql(\"rotten_tomatoes\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative for Binder\n",
    "\n",
    "# imdb_titles = pd.read_csv('../data/title.basics.tsv.gz', sep='\\t', na_values=\"\\\\N\"),\n",
    "# imdb_ratings = pd.read_csv('../data/title.ratings.tsv.gz', sep='\\t', na_values=\"\\\\N\"),\n",
    "# boxoffice = pd.read_csv('../data/boxoffice_march_2019.csv.gz'),\n",
    "# rotten_tomatoes = pd.read_csv(\"../data/rotten_tomatoes_top_movies_2019-01-15.csv\"),\n",
    "# awards = pd.read_sql(\"awards\", con='sqlite:///../data/awards.sqlite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the operations from the previous notebook for a clean start\n",
    "imdb_titles[\"title_type\"] = imdb_titles.titleType.astype(\"category\")\n",
    "imdb_titles.loc[imdb_titles.isAdult > 1, 'isAdult'] = 0\n",
    "imdb_titles = imdb_titles.dropna(subset=[\"startYear\"])\n",
    "imdb_titles[\"runtimeMinutes\"] = pd.to_numeric(imdb_titles.runtimeMinutes, errors=\"coerce\").astype(\"Int64\")\n",
    "movie_titles = imdb_titles[imdb_titles.titleType.isin([\"movie\", \"tvMovie\"])]\n",
    "movie_titles = movie_titles.drop(columns=[\"titleType\", \"endYear\"]).dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging data\n",
    "\n",
    "We would like to attach ratings to the movies data set. \n",
    "Let's merge (join) the two two IMDB data sets. That's quite simple becase they share the `tconst` columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple merging - IMDB ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imdb_ratings.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, the datasets have a common column (tconst) and can be merged easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_rated = movie_titles.merge(imdb_ratings, on='tconst', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_rated.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative (based on automatic index matching)\n",
    "movie_titles.set_index(\"tconst\").join(imdb_ratings.set_index(\"tconst\")).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have two more data sets to merge: `rotten_tomatoes` and `boxoffice`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_tomatoes.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxoffice.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations :(\n",
    "1. No `tconst` \n",
    "2. (year) in titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**: \n",
    "1. Create `year` column with year simply parsed from `Title` by slicins and convert to `int` type.\n",
    "2. Create `correctedTitle` column with ` (year)` removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%exercise\n",
    "\n",
    "rotten_tomatoes[\"year\"] = rotten_tomatoes.Title.str.slice(___, ___)\n",
    "rotten_tomatoes[\"Title\"] = rotten_tomatoes.Title.str.slice_replace(___, ___, ___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%validate\n",
    "\n",
    "assert (rotten_tomatoes.year[:5] == [2018, 2015, 2017, 1927, 2017]).all()\n",
    "assert rotten_tomatoes.iloc[2].correctedTitle == 'Wonder Woman'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So no title `endswith` `\")\"` any more, right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_tomatoes[rotten_tomatoes.correctedTitle.str.endswith(')')].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have you heard of regural expressions? Get yourselves trained at https://regex101.com/ :)\n",
    "\n",
    "Shortcut for now. To match strings like `\"(Shichinin no Samurai)\"` at the end of a string, we can use this regex: `\\(.*\\)$`.\n",
    "\n",
    "The second ingredient to use is the `.str` accessor (see https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html), which can help us to `extract` and `replace` the year from the titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_tomatoes.correctedTitle.str.extract(r'\\((.*)\\)$').dropna().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have just extracted the original titles. Let's construct `primaryTitle` by replacing the original titles in the `Title` column by empty strings. We also need to delete any trailing white space characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_tomatoes[\"primaryTitle\"] = rotten_tomatoes.correctedTitle.str.replace(r'(\\s*\\(.*\\))$', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how we succeeded ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten_tomatoes[rotten_tomatoes.correctedTitle.str.contains(\"\\\\(\")][[\"Title\", \"correctedTitle\", \"primaryTitle\", \"year\"]].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feeling like a regex expert already? Try to write a RFC email address validator ... or just use an existing one: http://www.ex-parrot.com/~pdw/Mail-RFC822-Address.html ðŸ˜ˆ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about duplicated titles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the duplicated method\n",
    "rotten_tomatoes[rotten_tomatoes.primaryTitle.duplicated(keep=False)].sort_values(\"primaryTitle\").head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the differences are in genres and **years**. Let's make it easy and \n",
    "\n",
    "**Exercise:** Create an `honest_tomatoes` data set from `rotten_tamatoes`\n",
    "1. with no duplicates (use `duplicated` by `primaryTitle` and `year` columns with a different `keep` option for indexing),\n",
    "2. without `Title` and `correctedTitle` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%exercise\n",
    "\n",
    "honest_tomatoes = rotten_tomatoes.loc[___].drop(___)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%validate\n",
    "\n",
    "assert honest_tomatoes[honest_tomatoes.primaryTitle == \"Hairspray\"].year.tolist() == [1988, 2007]\n",
    "assert sorted(honest_tomatoes.columns) == ['Genres', 'No. of Reviews', 'Rank', 'RatingTomatometer', 'primaryTitle', 'year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what are the honestly duplicated titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "honest_tomatoes[honest_tomatoes.primaryTitle.duplicated(keep=False)].sort_values(\"primaryTitle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, the boxoffice data are somewhat easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxoffice[\"primaryTitle\"] = boxoffice.title.str.rstrip().str.replace(r'\\s*\\(.*\\)$', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let's do the big big merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.merge(\n",
    "    movies_rated,\n",
    "    pd.merge(honest_tomatoes, boxoffice, on=[\"primaryTitle\", \"year\"], how=\"left\"),\n",
    "    left_on=[\"primaryTitle\", \"startYear\"],\n",
    "    right_on=[\"primaryTitle\", \"year\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_movies = movies.loc[~movies.duplicated(subset=[\"primaryTitle\", \"year\"], keep='first')]\n",
    "\n",
    "# And just to make sure\n",
    "unique_movies = unique_movies.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_movies.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_movies.shape[0], movies_rated.shape[0], boxoffice.shape[0], honest_tomatoes.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have much less titles compared to IMDB or even boxoffice data :-| We could probably improve the merge by sanitizing the titles, likely there are punctuation, white space, Roman vs. Arabic numerals nuances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the number of votes related to rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_rated.plot(kind=\"scatter\", x=\"numVotes\", y=\"averageRating\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `scatter_matrix` to scatter-plot all variables against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pd.plotting.scatter_matrix(unique_movies, figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, maybe not every column is useful.\n",
    "\n",
    "**Exercise:** Use only some columns for scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%exercise\n",
    "\n",
    "fig = pd.plotting.scatter_matrix(___, figsize=(10, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seaborn\n",
    "\n",
    "[Seaborn](https://seaborn.pydata.org/) is a Python data visualization library based on matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are convenient functions to set plot styles and colout palettes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"notebook\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"hls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A powerful tool to visualize pairwise relationships is `pairplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(unique_movies[[\"startYear\", \"averageRating\", \"numVotes\", \"RatingTomatometer\", \"lifetime_gross\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Adapt the example from https://seaborn.pydata.org/examples/pair_grid_with_kde.html to match this figure.\n",
    "\n",
    "![pairgrid_exercise.png](pairgrid_exercise.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%exercise\n",
    "\n",
    "df = sns.load_dataset(\"iris\")\n",
    "\n",
    "g = sns.PairGrid(df, diag_sharey=False)\n",
    "g.map_lower(sns.kdeplot)\n",
    "g.map_upper(sns.scatterplot)\n",
    "g.map_diag(sns.kdeplot, lw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see any interesting relationships?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding interactivity to plots\n",
    "\n",
    "Seaborn is great. But maybe we would like to add some interactivity: zooming, panning, ... you name it. \n",
    "Some of that we can get with just using a different [Matplotlib backend](https://matplotlib.org/3.1.0/tutorials/introductory/usage.html#backends).\n",
    "There are libraries for that. We'll show [Plotly Express](https://www.plotly.express/) here, which builds Seaborn-like interface on top of https://plot.ly/.\n",
    "\n",
    "There are more libraries you can explore when you have more time: https://bokeh.pydata.org/en/latest/, https://altair-viz.github.io/, http://holoviews.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly_express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(\n",
    "    movies.dropna(), \n",
    "    x=\"averageRating\", \n",
    "    y=\"RatingTomatometer\",\n",
    "    marginal_x=\"histogram\", \n",
    "    marginal_y=\"histogram\",\n",
    "    color=\"numVotes\", \n",
    "    size=\"lifetime_gross\",\n",
    "    hover_name=\"title\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping & aggregation\n",
    "\n",
    "A common pattern in data analysis is grouping (or binning) data based on some property and getting some aggredate statistics.\n",
    "\n",
    "*Example:* Group this workshop participants by nationality a get the cardinality (the size) of each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use all title types here\n",
    "# let's merge first\n",
    "imdb_data = imdb_titles.merge(imdb_ratings, on=\"tconst\")\n",
    "imdb_data.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_type = imdb_data.groupby('titleType')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did we get? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's this `DataFrameGroupBy` object? [Its use case is](http://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html):\n",
    "* Splitting the data into groups based on some criteria.\n",
    "* Applying a function to each group independently.\n",
    "* Combining the results into a data structure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a simple aggregate: mean of rating per type group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_type.averageRating.mean().sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Movies are worst rated, TV episodes and video games are much better rated. What does that mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GroupBy` objects have `agg` method which is quite versatile to describe what aggregations we need. As an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_type.agg({\"averageRating\": [\"mean\", \"median\", \"std\"], \"startYear\": [\"min\", \"max\", \"median\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grouping is also behind Seaborn's `FacetGrid` plots of categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(imdb_data, col=\"titleType\", col_wrap=4)\n",
    "# g.map(plt.hist, \"averageRating\", density=True)\n",
    "g.map(sns.distplot, \"averageRating\", norm_hist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we were to group by decade? We don't have a decade column but we can just calculate the decades and use it for `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_decade = movies_rated.groupby((np.floor_divide(movies_rated.startYear, 10) * 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Use `group_by_decade.agg` similarly to above to get the mean of average rating and the total number of votes in each decade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%exercise\n",
    "\n",
    "decade_statistics = group_by_decade.agg({___})\n",
    "\n",
    "# Display (do not edit)\n",
    "decade_statistics[\"averageRating\"].plot(kind=\"bar\")\n",
    "decade_statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%validate\n",
    "\n",
    "assert np.allclose(decade_statistics.iloc[-1].averageRating, 6.364, rtol=0.01)\n",
    "assert np.allclose(decade_statistics.iloc[-1].numVotes, 2.55e+08, rtol=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "70's, 80's, 90's are the dark ages of the film industry?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:**: Find the most profitable film for each studio. Use `groupby` and either `apply` with `pn.nlargest` or `sort_values` and `first`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%exercise\n",
    "\n",
    "# result = movies.groupby ...\n",
    "\n",
    "# display \n",
    "result.nlargest(10, columns=\"lifetime_gross\")[[\"title\", \"startYear\", \"lifetime_gross\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%validate\n",
    "\n",
    "assert result.loc[\"Sony\", \"lifetime_gross\"].values == 373585825"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivoting\n",
    "\n",
    "> pivot (third-person singular simple present pivots, present participle pivoting, simple past and past participle pivoted)\n",
    " **To turn on an exact spot.**\n",
    " \n",
    "> A pivot table is a table of statistics that summarizes the data of a more extensive table ...\n",
    "> Although pivot table is a generic term, Microsoft Corporation trademarked PivotTable in the United States in 1994."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pivoting task: Get a table with numbers of titles per year (as row) and type (as column).\n",
    "\n",
    "One approach is to use `groupby`, `count` aggregation and `unstack`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_by_year_and_type = imdb_data.groupby(['startYear', 'titleType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = (\n",
    "    grouped_by_year_and_type\n",
    "    .numVotes\n",
    "    .count()\n",
    "    .unstack()\n",
    ")\n",
    "pivoted.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a shortcut though, see if you we can use it.\n",
    "\n",
    "**Exercise:** Create the `pivoted` table using `pivot_table`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%exercise\n",
    "\n",
    "pivot_table = imdb_data.pivot_table(values=___, index=___, columns=___, aggfunc=___)\n",
    "\n",
    "# display - do not edit\n",
    "pivot_table.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%validate\n",
    "\n",
    "pd.testing.assert_frame_equal(pivoted, pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use this to plot a kind of a histogram with colour for title types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.color_palette(\"Paired\"):\n",
    "    fig, ax = plt.subplots(figsize=(16, 6))\n",
    "    pivoted.loc[1990:].plot.bar(stacked=True, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final mini-project - creative, unbounded, free-style\n",
    "\n",
    "Here are some ideas of what you can do with the data.\n",
    "\n",
    "* Create 5-star rating based on quantiles using `quantile` and `cut` or `qcut`.\n",
    "* Group by studio / decade / rating\n",
    "* Compare simple (arithmetic) mean `averageRating` in each group with `averageRating` average weighted by `numVotes` ($ \\frac{\\sum \\rm{averageRating} \\times \\rm{numVotes}} {\\sum \\rm{numVotes}} $). Use `apply` and the `wavg` function from https://pbpython.com/weighted-average.html. This function is quite time and memory consuming and thus not ideal for large data sets. You can try to implement weighted average using standard `mean`. Check the performance with the `%timeit` magic.\n",
    "* Use the 5-star rating for `hue` in an interesting seaborn plot (see https://seaborn.pydata.org/tutorial/relational.html)\n",
    "* Use `sns.catplot` to visualize the distrubution of incomes in each 5-star rating group. \n",
    "\n",
    "A couple more ideas can be found in https://github.com/brandon-rhodes/pycon-pandas-tutorial\n",
    "\n",
    "After you have solved all of those, come up with your own quests - we may still be around and help you :-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
