{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Communicate Data Findings\n",
    "## Table of Contents\n",
    "<ul>\n",
    "    <li><a href=\"#intro\">Introduction</a></li>\n",
    "    <li><a href=\"#questions\">Posing Questions</a></li>\n",
    "    <li><a href=\"#sources\">Data Sources</a></li>\n",
    "    <li><a href=\"#gathering\">Data Gathering & Wrangling</a></li>\n",
    "    <li><a href=\"#assessing\">Data Assessing</a></li>\n",
    "    <ul>\n",
    "    <li><a href=\"#assessingsum\">Assessing Summary</a></li>            \n",
    "    </ul>    \n",
    "    <li><a href=\"#cleaning\">Data Cleaning</a></li>\n",
    "    <li><a href=\"#analysis\">Data Visualization</a></li>\n",
    "    <ul>\n",
    "        <li><a href=\"#uni\">Univariate Exploration</a></li>\n",
    "        <li><a href=\"#bi\">Bivariate Exploration</a></li>\n",
    "        <li><a href=\"#multi\">Multivariate Exploration</a></li> \n",
    "    </ul> \n",
    "    <li><a href=\"#conclusion\">Summary and Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='questions'></a>\n",
    "## Posing Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In this project we are going to explore the data systematically, so there is no specific question we want to answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sources'></a>\n",
    "## Data Sources\n",
    "\n",
    ">1. **Name:** result.csv\n",
    "><ul>   \n",
    ">    <li><b>Definition:</b> Ford GoBike System - Data</li>\n",
    ">    <li><b>Source:</b> <a href =\"https://www.fordgobike.com/system-data\">https://www.fordgobike.com/system-data</a></li>    \n",
    ">    <li><b>Version:</b>Files from 01.2018 - 02.2019</li>\n",
    "></ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import of the needed libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3babae361da2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmissingno\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "#Import important libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as ms\n",
    "import zipfile\n",
    "import requests\n",
    "import geopy.distance\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gathering'></a>\n",
    "## Data Gathering & Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we need to gather the data. The code below will download, unzip and merge the data together to a final *.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define filenames to download\n",
    "year_data = [x for x in range(201801, 201813)] + [x for x in range(201901, 201903)]\n",
    "\n",
    "#loop over years\n",
    "for year in year_data[:3]:\n",
    "    \n",
    "    #url structure\n",
    "    url = f\"https://s3.amazonaws.com/fordgobike-data/{year}-fordgobike-tripdata.csv.zip\"\n",
    "    \n",
    "    #get response\n",
    "    response = requests.get(url)\n",
    "   \n",
    "    #save file\n",
    "    with open(f\"{year}-fordgobike-tripdata.csv.zip\", mode = \"wb\") as file:\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/3451111/unzipping-files-in-python/3451150\n",
    "#define file names\n",
    "files = [x for x in os.walk(\"./Data\")][0][2]\n",
    "\n",
    "#loop over file names\n",
    "for x in files:\n",
    "    if \".zip\" in x:\n",
    "        with zipfile.ZipFile(f\"./Data/{x}\",'r') as zip_ref:\n",
    "            zip_ref.extractall(\"./Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_range =  [int(x[:6]) for x in files if \".zip\" not in x] #can be exchanged with year_data .. \n",
    "\n",
    "#read in the first file\n",
    "result = pd.read_csv(f\"./Data/{month_range[0]}-fordgobike-tripdata.csv\")\n",
    "len_df = len(result)\n",
    "\n",
    "#loop over all files and append data one by one\n",
    "for i, month in enumerate(month_range):\n",
    "    \n",
    "    if i+2 > len(month_range):\n",
    "        break\n",
    "    \n",
    "    else:    \n",
    "        df_append  = pd.read_csv(f\"./Data/{month_range[i+1]}-fordgobike-tripdata.csv\")\n",
    "        len_df += len(df_append)\n",
    "        assert all(result.columns == df_append.columns)\n",
    "        result = result.append(df_append)\n",
    "        print(f\"{month_range[i+1]}\")\n",
    "        \n",
    "result.to_csv(\"result.csv\", index = False)\n",
    "print(\"Done\")           \n",
    "print(len_df == len(result))\n",
    "del len_df, df_append, result, files, month_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assessing'></a>\n",
    "## Data Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our final \"result.csv\" file, we have to make sure that the data is ready for an analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can already see, that the start_time and end_time column is not a datetime - object. Also the ID's and the member_birth_year should be object type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.matrix(df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we also have a problem with missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.start_station_id.isnull()].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.start_station_id.isnull()].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the rows with missing data have similar coordinates. Also these coordinates are less precise than the other entries with no missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.start_station_id.isnull()].start_station_latitude.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.start_station_id.isnull()].start_station_longitude.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most frequent coordinates are at 37.41 latitude and -121.94 longitude. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes, figure = plt.subplots(figsize = (10,5))\n",
    "sns.scatterplot(data = df[df.start_station_id.isnull()], x = \"start_station_longitude\", y = \"start_station_latitude\", alpha = 0.15, s = 200)\n",
    "sns.scatterplot(data = df.dropna(subset=[\"start_station_id\"]).sample(50000), x = \"start_station_longitude\", y = \"start_station_latitude\", alpha = 0.15, s = 200)\n",
    "plt.xlim(-121.8,-122)\n",
    "plt.ylim(37.3,37.45)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see, that these 'nan' stations are mostly out of the range of the other stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all ids are a start- and ending point\n",
    "start_station_id_list = list(df.start_station_id.drop_duplicates().dropna().astype(\"int\"))\n",
    "start_station_id_list.sort()\n",
    "\n",
    "end_station_id_list = list(df.end_station_id.drop_duplicates().dropna().astype(\"int\"))\n",
    "end_station_id_list.sort()\n",
    "\n",
    "start_station_id_list == end_station_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_names = df[[\"end_station_id\", \"end_station_name\", \"end_station_latitude\", \"end_station_longitude\"]].copy()\n",
    "\n",
    "df_station_names.rename(columns={\"end_station_id\": \"id\", \n",
    "                                 \"end_station_name\": \"station_name\", \n",
    "                                 \"end_station_latitude\": \"station_latitude\", \n",
    "                                 \"end_station_longitude\": \"station_longitude\"}, inplace = True)\n",
    "\n",
    "df_station_names.drop_duplicates(inplace = True)\n",
    "df_station_names.dropna(inplace = True)\n",
    "df_station_names.sort_values(\"id\", inplace = True)\n",
    "df_station_names.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "axes, figure = plt.subplots(figsize = (10,5))\n",
    "#sns.scatterplot(data = df[df.start_station_id.isnull()], x = \"start_station_longitude\", y = \"start_station_latitude\", alpha = 0.15, s = 200)\n",
    "sns.scatterplot(data = df_station_names, x = \"station_longitude\", y = \"station_latitude\", s = 200)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we can see, that there are three clear clusters in this dataset. The website of FordGoBike differs following zones: \"San Francisco, East Bay, San José\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_names.id.value_counts()[df_station_names.id.value_counts()>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see an interesting thing: One ID can refer to multiple different stations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_names[df_station_names.duplicated(\"id\", keep = False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible, that some these stations changed position over time and/or got a new name. This is a data consistency problem, because the ID's are not unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_names.drop_duplicates(subset = [\"id\", \"station_latitude\", \"station_longitude\"]).id.value_counts().head(25) #excludes 4 cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we filter the data by these stations, which didn't changed the position and just got a new name, we can exclude 4 cases. The rest of the cases are still relevant to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_consistency = df[[\"end_station_id\", \"end_station_name\", \"end_station_latitude\", \"end_station_longitude\"]].copy().merge(df_station_names, left_on = \"end_station_id\", right_on = \"id\", how = \"outer\")\n",
    "\n",
    "df_consistency_issues = df_consistency.drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stat_dist = df_consistency_issues[(df_consistency_issues.end_station_latitude != df_consistency_issues.station_latitude) & \\\n",
    "                                     (df_consistency_issues.end_station_longitude != df_consistency_issues.station_longitude)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/19412462/getting-distance-between-two-points-based-on-latitude-longitude/43211266#43211266\n",
    "\n",
    "def calculate_coord_dist(col):\n",
    "    coords_1 = (col[0], col[1])\n",
    "    coords_2 = (col[2], col[3])\n",
    "    \n",
    "    return geopy.distance.distance(coords_1, coords_2).m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stat_dist[\"dist_in_m\"] = df_stat_dist[[\"end_station_latitude\", \"end_station_longitude\", \"station_latitude\", \"station_longitude\"]].apply(calculate_coord_dist, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stat_dist_data = df_stat_dist.drop_duplicates(\"dist_in_m\").sort_values(\"dist_in_m\", ascending = False)\n",
    "df_stat_dist_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the range of distance between new stations lies between 0 to 364 meters (and nearly 4 km in the worst case). This needs to be a part of data cleaning. Now we will look at the overall number structure of this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing too obvious here. There seems to be an outlier at the maximum duration_sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"duration_sec == 86366\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe somebody forgot to unregister the bike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"duration_sec > 80000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or some users really rent these bikes for this duration. For the final part of this assessing we will look on the missing values in the birth_year column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.member_birth_year.isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible that the users don't have to write down their birth day information during registration. Or they decided to not share this information at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assessingsum'></a>\n",
    "### Assessing Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality\n",
    "##### df table\n",
    "- there are missing values in the station_id, station_name, member_birth_year and member_gender columns\n",
    "- the columns 'start_time' and 'end_time' are not datetime type\n",
    "- the columns 'start_station_id', 'end_station_id', 'member_birth_year' and 'bike_id' are not object type\n",
    "- some stations share the same ID while they changed the position over time (consistency problem)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidiness\n",
    "##### df table\n",
    "- None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleaning'></a>\n",
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #1\n",
    "> #### Define #1\n",
    ">- there are missing values in the station_id, station_name, member_birth_year and member_gender columns\n",
    "\n",
    "> #### Clean #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are multiple ways how to handle this - but since the coordinates are not precise we will just drop them\n",
    "df.dropna(subset = [\"start_station_id\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill up the missing values\n",
    "df.member_birth_year.fillna(0, inplace = True)\n",
    "df.member_gender.fillna(\"not defined\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Test #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #2\n",
    "> #### Define #2\n",
    ">- the columns 'start_time' and 'end_time' are not datetime type\n",
    ">- the columns 'start_station_id', 'end_station_id', 'member_birth_year' and 'bike_id' are not object type\n",
    "\n",
    "> #### Clean #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"start_time\", \"end_time\"]:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "for col in [\"start_station_id\", \"end_station_id\"]:\n",
    "    df[col] = df[col].astype(\"int\")\n",
    "\n",
    "for col in [\"start_station_id\", \"end_station_id\", \"member_birth_year\", \"bike_id\"]:\n",
    "    df[col] = df[col].astype(\"str\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Test #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issue #3\n",
    "> #### Define #3\n",
    ">- some stations share the same ID while they changed the position over time (consistency problem)\n",
    "\n",
    "> #### Clean #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the one hand we can ignore most of these cases, because the different stations are relatively close to each other. That raises the question: How close is close? Another approach is to give the ID's a new \"subindex\". So everytime the coordinates of a station ID differs from the occurrence of this station before, we will increase the subindex by 1, if the calcualted difference is > x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(\"start_time\", inplace = True)\n",
    "df.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id_data = {}\n",
    "\n",
    "def get_new_id(col):\n",
    "    \n",
    "    #when the row is not in id_data - append it\n",
    "    if col[0] not in id_data:\n",
    "        id_data[col[0]] = [col[1], col[2], col[3], f\"{col[0]}_0\"]\n",
    "        return id_data[col[0]][3]\n",
    "    \n",
    "    #if the row exists in id_data, then check if the coordinates change, if yes - calculate the distance and increase the id and replace the \\\n",
    "    #saved coordinates in id_data with the new ones, if not, then just return the saved id\n",
    "    elif col[0] in id_data:\n",
    "        if id_data[col[0]][1] != col[2] or id_data[col[0]][2] != col[3]:\n",
    "            coords_1 = (id_data[col[0]][1], id_data[col[0]][2])\n",
    "            coords_2 = (col[2], col[3])\n",
    "                \n",
    "            if geopy.distance.distance(coords_1, coords_2).m > 100:\n",
    "                new_ind = str(col[0]) + \"_\" + str(int(id_data[col[0]][3][-1])+1)\n",
    "                id_data[col[0]][3] = new_ind\n",
    "                id_data[col[0]][1] = col[2]\n",
    "                id_data[col[0]][2] = col[3]\n",
    "\n",
    "                return new_ind\n",
    "            else:\n",
    "                return id_data[col[0]][3]\n",
    "\n",
    "        else:\n",
    "            return id_data[col[0]][3]\n",
    "            \n",
    "    else:\n",
    "        return \"Error\"   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_data = {}\n",
    "df[\"start_station_id_new\"] = df[[\"start_station_id\", \"start_station_name\", \"start_station_latitude\", \"start_station_longitude\"]].apply(get_new_id, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_data = {}\n",
    "df[\"end_station_id_new\"] = df[[\"end_station_id\", \"end_station_name\", \"end_station_latitude\", \"end_station_longitude\"]].apply(get_new_id, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_names = df[[\"start_time\", \"start_station_id\", \"start_station_name\", \"start_station_latitude\", \"start_station_longitude\"]].copy()\n",
    "df_station_names.sort_values(\"start_time\", inplace = True)\n",
    "df_station_names.drop(\"start_time\", axis = 1, inplace = True)\n",
    "df_station_names.rename(columns={\"start_station_id\": \"id\", \n",
    "                                 \"start_station_name\": \"station_name\", \n",
    "                                 \"start_station_latitude\": \"station_latitude\", \n",
    "                                 \"start_station_longitude\": \"station_longitude\"}, inplace = True)\n",
    "\n",
    "df_station_names.drop_duplicates(inplace = True)\n",
    "df_station_names.dropna(inplace = True)\n",
    "id_data = {}\n",
    "df_station_names[\"new_id\"] = df_station_names[[\"id\", \"station_name\", \"station_latitude\", \"station_longitude\"]].apply(get_new_id, axis = 1)\n",
    "df_station_names.sort_values(\"id\", inplace = True)\n",
    "df_station_names.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### Test #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"start_station_id == '208'\").drop_duplicates(\"start_station_id_new\")[[\"start_station_id\", \"start_station_name\", \"start_station_latitude\", \"start_station_longitude\", \"start_station_id_new\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"end_station_id == '208'\").drop_duplicates(\"end_station_id_new\")[[\"end_station_id\", \"end_station_name\", \"end_station_latitude\", \"end_station_longitude\", \"end_station_id_new\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the station names to csv\n",
    "df_station_names.to_csv(\"df_station_names.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the cleaned csv \n",
    "df.to_csv(\"result_clean.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='analysis'></a>\n",
    "## Exploratory Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the cleaning part is done, we can start to visualize the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"result_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wrong datatypes again, maybe change the datatype to HDF5\n",
    "for col in [\"start_time\", \"end_time\"]:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "for col in [\"member_birth_year\"]:\n",
    "    df[col] = df[col].astype(\"int\")\n",
    "\n",
    "for col in [\"start_station_id\", \"end_station_id\", \"member_birth_year\", \"bike_id\"]:\n",
    "    df[col] = df[col].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_names = pd.read_csv(\"df_station_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start visualizing, we can extract some additional information out of the data to improve the insights. We saw, that these datapoints can be separated in three clusters. Since these clusters are really obvious, we can classify them really efficient using the K-Means Clustering algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://datatofish.com/k-means-clustering-python/\n",
    "\n",
    "kmeans = KMeans(n_clusters=3).fit(df_station_names[[\"station_longitude\", \"station_latitude\"]])\n",
    "\n",
    "df_station_names[\"label\"] = kmeans.labels_\n",
    "\n",
    "for x in set(list(df_station_names.label)):\n",
    "    \n",
    "    df_plot_cluster = df_station_names.query(f\"label == {x}\")\n",
    "\n",
    "    plt.scatter(df_plot_cluster['station_longitude'], df_plot_cluster[\"station_latitude\"], s=50, alpha=0.5, label = x);\n",
    "\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that this is done, we can visualize this data on a map. This can happen with Bokeh or Plotly, but we will use kepler.gl out of the visualization toolbox for map visualizations.\n",
    "\n",
    "**Source:** <a href = https://kepler.gl/>kepler.gl</a>\n",
    "\n",
    "![All Stations](Images/stations_kepler.png)\n",
    "![Upper Two Cluster](Images/stations_1.png)\n",
    "![Lower Cluster](Images/stations_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will map the labels with the original names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {0: \"San Francisco\", 1: \"San José\", 2: \"East Bay\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_names[\"label_name\"] = df_station_names[\"label\"].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_names.label_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_names[df_station_names.duplicated(\"new_id\", keep = False)] # duplicates for new coordinates which are not > 100 m away from the origin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_names.drop_duplicates(subset = [\"new_id\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_names.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated(subset = [\"start_time\", \"end_time\"], keep = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can merge the labels to the id's of the main dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_station_names[[\"new_id\", \"label\"]], left_on = \"start_station_id_new\", right_on = \"new_id\", how = \"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.label.isnull()].start_station_id_new.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"start_station_id == '205'\").drop_duplicates(\"start_station_id_new\")[[\"start_station_id\", \"start_station_name\", \"start_station_latitude\", \"start_station_longitude\", \"start_station_id_new\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label_name\"] = df[\"label\"].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in set(list(df.label)):\n",
    "    \n",
    "    df_plot_cluster = df.query(f\"label == {x}\")\n",
    "\n",
    "    plt.scatter(df_plot_cluster['start_station_longitude'], df_plot_cluster[\"start_station_latitude\"], s=50, alpha=0.5, label = x);\n",
    "\n",
    "plt.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will extract multiple other informations out of the birth year and the start_time - timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"] = df[\"member_birth_year\"].apply(lambda x: 2018 - int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['month_year'] = pd.to_datetime(df[\"start_time\"]).dt.to_period('M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['day_month_year'] = pd.to_datetime(df[\"start_time\"]).dt.to_period('D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"dayofweek\"] = df[\"start_time\"].apply(lambda x: x.dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"start_hr\"] = df[\"start_time\"].apply(lambda x: x.hour)\n",
    "df[\"end_hr\"] = df[\"end_time\"].apply(lambda x: x.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age = df.query(\"age != 2018 and age < 100\").copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age.age.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [x for x in range(10,101, 10)]\n",
    "df_age[\"age_bins\"] = pd.cut(df_age.age, bins = bins, precision = 0, include_lowest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age[[\"age\", \"age_bins\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are really ready for the exploratory visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='uni'></a>\n",
    "### Univariate Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are mutliple interesting variables in thsi dataset. Let's start with the stations first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://codeyarns.com/2015/06/29/how-to-hide-axis-of-plot-in-matplotlib/\n",
    "\n",
    "value_ct = df.start_station_id_new.value_counts().iloc[:25]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (22,5), dpi = 80)\n",
    "color = sns.color_palette(\"viridis\")[1]\n",
    "sns.countplot(x = \"start_station_id_new\", data = df, order=value_ct.index, color = color);\n",
    "\n",
    "plt.ylim(0,70000)\n",
    "\n",
    "cur_axes = plt.gca()\n",
    "#cur_axes.axes.get_xaxis().set_visible(False)\n",
    "cur_axes.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "sns.despine(fig, left = True)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.08, p.get_height()-4000), color = \"white\")\n",
    "\n",
    "plt.title(\"Top 25 Start Stations\");\n",
    "plt.xlabel(\"Start Station ID\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall we can see, that 67_0, 15_0 and 58_0 are the most \"used\" stations in this dataset. Let's take a look on each group separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in value_ct.index:\n",
    "    print(x + \" - \" + str(df.query(f\"start_station_id_new == '{x}'\").start_station_name.drop_duplicates().get_values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://codeyarns.com/2015/06/29/how-to-hide-axis-of-plot-in-matplotlib/\n",
    "\n",
    "df_new = df.query(\"label == 0\").copy()\n",
    "\n",
    "value_ct = df_new.start_station_id_new.value_counts().iloc[:25]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (22,5), dpi = 80)\n",
    "color = sns.color_palette(\"viridis\")[1]\n",
    "sns.countplot(x = \"start_station_id_new\", data = df_new, order=value_ct.index, color = color);\n",
    "\n",
    "plt.ylim(0,50000)\n",
    "\n",
    "cur_axes = plt.gca()\n",
    "#cur_axes.axes.get_xaxis().set_visible(False)\n",
    "cur_axes.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "sns.despine(fig, left = True)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.08, p.get_height()-2000), color = \"white\")\n",
    "\n",
    "plt.title(\"Top 25 Start Stations for San Francisco\");\n",
    "plt.xlabel(\"Start Station ID\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For San Francisco we can see that this City is leading the trip counter overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://codeyarns.com/2015/06/29/how-to-hide-axis-of-plot-in-matplotlib/\n",
    "\n",
    "df_new = df.query(\"label == 1\").copy()\n",
    "\n",
    "value_ct = df_new.start_station_id_new.value_counts().iloc[:25]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (22,5), dpi = 80)\n",
    "color = sns.color_palette(\"viridis\")[1]\n",
    "sns.countplot(x = \"start_station_id_new\", data = df_new, order=value_ct.index, color = color);\n",
    "\n",
    "plt.ylim(0,50000)\n",
    "\n",
    "cur_axes = plt.gca()\n",
    "#cur_axes.axes.get_xaxis().set_visible(False)\n",
    "cur_axes.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "sns.despine(fig, left = True)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.08, p.get_height()-2000), color = \"white\")\n",
    "\n",
    "plt.title(\"Top 25 Start Stations for San José\");\n",
    "plt.xlabel(\"Start Station ID\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://codeyarns.com/2015/06/29/how-to-hide-axis-of-plot-in-matplotlib/\n",
    "\n",
    "df_new = df.query(\"label == 2\").copy()\n",
    "\n",
    "value_ct = df_new.start_station_id_new.value_counts().iloc[:25]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (22,5), dpi = 80)\n",
    "color = sns.color_palette(\"viridis\")[1]\n",
    "sns.countplot(x = \"start_station_id_new\", data = df_new, order=value_ct.index, color = color);\n",
    "\n",
    "plt.ylim(0,50000)\n",
    "\n",
    "cur_axes = plt.gca()\n",
    "#cur_axes.axes.get_xaxis().set_visible(False)\n",
    "cur_axes.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "sns.despine(fig, left = True)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.08, p.get_height()-2000), color = \"white\")\n",
    "\n",
    "plt.title(\"Top 25 Start Stations for East Bay\");\n",
    "plt.xlabel(\"Start Station ID\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like the Ford GoBike Program is relatively new in East Bay and San José. These parts have lesser trips than San Francisco. In East Bay the stations 182_0, 243_0 and 176_0 are popular. For San José are the top three 310_0, 296_0 and 312_0. Now that we know, that San Francisco is the city in this project with the most active users, we will now take a look on the duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maybe a customer forgot to log off\n",
    "bin_size = 100\n",
    "bins = np.arange(0,df.duration_sec.max()+bin_size,bin_size)\n",
    "\n",
    "fig, axes = plt.subplots(figsize = (12,5), dpi = 110)\n",
    "\n",
    "plt.hist(df.duration_sec, bins = bins, color= color);\n",
    "plt.xticks(ticks = [x for x in range(0,7000,250)])\n",
    "plt.xlim(-100,6000);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph is limited to 6000 seconds to exclude the 'outliers'. The main takeaway here is that the most trips have a duration between 250 and 550 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"duration_sec < 6000\").duration_sec.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (12,5), dpi = 110)\n",
    "for x in mapping.values():\n",
    "    df_new = df.query(f\"label_name == '{x}'\")\n",
    "\n",
    "    bin_size = 100\n",
    "    bins = np.arange(0,df_new.duration_sec.max()+bin_size,bin_size)   \n",
    "\n",
    "    plt.hist(df_new.duration_sec, bins = bins, label = x, histtype='step');\n",
    "    \n",
    "plt.xticks(ticks = [x for x in range(0,7000,250)])\n",
    "plt.legend()\n",
    "plt.xlim(-100,6000);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these, trends are looking similar to each other (right skewed), although it seems like trips in East Bay are usually a little bit shorter in duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in mapping.values():\n",
    "    print(x, df.query(f\"label_name == '{x}' and duration_sec < 6000\").duration_sec.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean values also agree on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (12,5), dpi = 110)\n",
    "df_new = df.query(f\"label_name == 'San Francisco'\")\n",
    "\n",
    "bin_size = 100\n",
    "bins = np.arange(0,df_new.duration_sec.max()+bin_size,bin_size)   \n",
    "\n",
    "plt.hist(df_new.duration_sec, bins = bins, label = x, histtype='step', color = \"g\");\n",
    "    \n",
    "plt.xticks(ticks = [x for x in range(0,7000,250)])\n",
    "plt.legend()\n",
    "plt.xlim(-100,6000);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (12,5), dpi = 110)\n",
    "df_new = df.query(f\"label_name == 'East Bay'\")\n",
    "\n",
    "bin_size = 100\n",
    "bins = np.arange(0,df_new.duration_sec.max()+bin_size,bin_size)   \n",
    "\n",
    "plt.hist(df_new.duration_sec, bins = bins, label = x, histtype='step');\n",
    "    \n",
    "plt.xticks(ticks = [x for x in range(0,7000,250)])\n",
    "plt.legend()\n",
    "plt.xlim(-100,6000);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(figsize = (12,5), dpi = 110)\n",
    "df_new = df.query(f\"label_name == 'San José'\")\n",
    "\n",
    "bin_size = 100\n",
    "bins = np.arange(0,df_new.duration_sec.max()+bin_size,bin_size)   \n",
    "\n",
    "plt.hist(df_new.duration_sec, bins = bins, label = x, histtype='step', color = \"orange\");\n",
    "    \n",
    "plt.xticks(ticks = [x for x in range(0,7000,250)])\n",
    "plt.legend()\n",
    "plt.xlim(-100,6000);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will look at the user structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,5), dpi = 80)\n",
    "sns.countplot(x = \"member_gender\", data = df,  order=df.member_gender.value_counts().index, palette = \"viridis\");\n",
    "\n",
    "cur_axes = plt.gca()\n",
    "cur_axes.axes.get_yaxis().set_visible(False)\n",
    "sns.despine(fig, left = True)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.303, p.get_height()+50000))\n",
    "\n",
    "plt.title(\"Users By Gender\");\n",
    "plt.xlabel(\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there are a lot more men using this service than woman, \"not defined\" or other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (10,5), dpi = 80)\n",
    "sns.countplot(x = \"label_name\", data = df,  order=df.label_name.value_counts().index, palette = \"viridis\", hue = \"member_gender\");\n",
    "\n",
    "cur_axes = plt.gca()\n",
    "cur_axes.axes.get_yaxis().set_visible(False)\n",
    "sns.despine(fig, left = True)\n",
    "\n",
    "#for p in ax.patches:\n",
    " #   ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.01, p.get_height()+50000))\n",
    "\n",
    "plt.title(\"Users By Gender\");\n",
    "plt.xlabel(\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in mapping.values():\n",
    "    print(x, df.query(f\"label_name == '{x}'\").member_gender.value_counts() / df.query(f\"label_name == '{x}'\").member_gender.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the plot and the relative frequencies, the male percentage is > 50% for all three areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_ct = df.user_type.value_counts().iloc[:31]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,5), dpi = 80)\n",
    "sns.countplot(x = \"user_type\", data = df, order=value_ct.index, palette = \"viridis\");\n",
    "\n",
    "cur_axes = plt.gca()\n",
    "cur_axes.axes.get_yaxis().set_visible(False)\n",
    "sns.despine(fig, left = True)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.31, p.get_height()+40000))\n",
    "\n",
    "plt.title(\"Users By Type\");\n",
    "plt.xlabel(\"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_ct = df.label_name.value_counts().iloc[:31]\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (10,5), dpi = 80)\n",
    "sns.countplot(x = \"label_name\", data = df, order=value_ct.index, palette = \"viridis\", hue = \"user_type\");\n",
    "\n",
    "cur_axes = plt.gca()\n",
    "cur_axes.axes.get_yaxis().set_visible(False)\n",
    "sns.despine(fig, left = True)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate('{:.0f}'.format(p.get_height()), (p.get_x()+0.08, p.get_height()+40000))\n",
    "\n",
    "plt.title(\"Users By Type\");\n",
    "plt.xlabel(\"\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also there are a lot more users using the subscription service than the customer usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,5), dpi = 80)\n",
    "color = sns.color_palette(\"viridis\")[2]\n",
    "sns.countplot(x = \"age\", data = df.query(\"age != 2018 and age < 73\").sort_values(\"age\"), color = color);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query(\"age != 2018\").age.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the average user is between 24 and 35 years old, with no user being younger than 18 (and giving their birth year data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,5), dpi = 80)\n",
    "color = sns.color_palette(\"viridis\")[2]\n",
    "sns.countplot(x = \"age\", data = df.query(\"age != 2018 and age < 73 and label == 2\").sort_values(\"age\"), color = 'orange', label = \"San Francisco\");\n",
    "sns.countplot(x = \"age\", data = df.query(\"age != 2018 and age < 73 and label == 0\").sort_values(\"age\"), color = 'g', label = \"East Bay\");\n",
    "sns.countplot(x = \"age\", data = df.query(\"age != 2018 and age < 73 and label == 1\").sort_values(\"age\"), color = 'b', label = \"San José\");\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The East Bay age structure is broader than the one of San Francisco. San José has the youngest average group of users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in mapping.values():\n",
    "    print(x, df.query(f\"label_name == '{x}' and age != 2018\").age.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next plots we will focus on the time components of the data. At first we will explore on which days people like to go on trips. 0 refers to monday while 6 refers to sunday. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (16,5))\n",
    "sns.countplot(x = \"dayofweek\", data = df, palette = \"viridis\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this graph it looks like users use the bikes more during the week than during the weekend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (16,5))\n",
    "sns.countplot(x = \"label_name\", data = df, palette = \"viridis\", hue = \"dayofweek\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/43855474/changing-sort-in-value-counts\n",
    "\n",
    "for x in mapping.values():\n",
    "    print(f\"{x}\\n\", df.query(f\"label_name == '{x}'\").dayofweek.value_counts().sort_index() / df.query(f\"label_name == '{x}'\").dayofweek.count(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This applies for all three areas. Tuesday, Wednesday and Thursday are the most active days, followed by Monday and Friday and then Saturday and Sunday. Now let's look on the trips per month/year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (16,5))\n",
    "sns.countplot(x = \"month_year\", data = df, palette = \"viridis\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (16,5))\n",
    "sns.countplot(x = \"month_year\", data = df, palette = \"viridis\", hue = \"label_name\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all three areas we can see that Bikesharing got more and more popular from 2018-01 - 2018-10, followed by a drop for two months during November 18 and Dezember 18.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/4700614/how-to-put-the-legend-out-of-the-plot\n",
    "fig, ax = plt.subplots(figsize = (20,5))\n",
    "sns.countplot(x = \"label_name\", data = df, palette = \"viridis\", hue = \"month_year\");\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/4700614/how-to-put-the-legend-out-of-the-plot\n",
    "fig, ax = plt.subplots(figsize = (20,5))\n",
    "sns.countplot(x = \"month_year\", data = df.query(\"label_name == 'San José'\"), palette = \"viridis\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/4700614/how-to-put-the-legend-out-of-the-plot\n",
    "fig, ax = plt.subplots(figsize = (20,5))\n",
    "sns.countplot(x = \"month_year\", data = df.query(\"label_name == 'East Bay'\"), palette = \"viridis\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The drop for the \"San José\" area held on for on more month till February 19. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://seaborn.pydata.org/generated/seaborn.color_palette.html\n",
    "sns.palplot(sns.color_palette(\"viridis\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/35143672/seaborn-conditional-colors-based-on-value\n",
    "custom_palette = {}\n",
    "for q in set(df.day_month_year):\n",
    "    if q.dayofweek ==0:\n",
    "        custom_palette[q] =sns.color_palette(\"viridis\")[0]\n",
    "    elif q.dayofweek ==1:\n",
    "        custom_palette[q] = sns.color_palette(\"viridis\")[1]\n",
    "    elif q.dayofweek == 2:\n",
    "        custom_palette[q] =sns.color_palette(\"viridis\")[2]\n",
    "    elif q.dayofweek == 3:\n",
    "        custom_palette[q] =sns.color_palette(\"viridis\")[3]\n",
    "    elif q.dayofweek == 4:\n",
    "        custom_palette[q] = sns.color_palette(\"viridis\")[4]\n",
    "    elif q.dayofweek == 5:\n",
    "        custom_palette[q] =sns.color_palette(\"viridis\")[5]\n",
    "    elif q.dayofweek == 6:\n",
    "        custom_palette[q] =(224/255,228/255,65/255)\n",
    "    else:\n",
    "        custom_palette[q] = 'g'\n",
    "        \n",
    "legend_obj = []\n",
    "colors = [sns.color_palette(\"viridis\")[0],\n",
    "          sns.color_palette(\"viridis\")[1],\n",
    "          sns.color_palette(\"viridis\")[2],\n",
    "          sns.color_palette(\"viridis\")[3],\n",
    "          sns.color_palette(\"viridis\")[4],\n",
    "          sns.color_palette(\"viridis\")[5],\n",
    "          (224/255, 228/255, 65/255)]\n",
    "days=[\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
    "for i,s in enumerate(days):\n",
    "    legend_obj.append(plt.scatter([],[],color = colors[i]));  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/4700614/how-to-put-the-legend-out-of-the-plot\n",
    "def plot_data_time(start_date=\"12.31.17\", end_date=\"03.01.18\"):\n",
    "    fig, ax = plt.subplots(figsize =(30,5),dpi = 100)\n",
    "    sns.countplot(x = \"day_month_year\", data = df[(df[\"start_time\"] < pd.to_datetime(end_date)) & (df[\"start_time\"] > pd.to_datetime(start_date))], palette = custom_palette);\n",
    "    plt.xticks(rotation = 90);\n",
    "    plt.ylim(0,10000);\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0,box.y0, box.width*0.8, box.height])\n",
    "    # Put a legend to the right of the current axis\n",
    "    ax.legend(legend_obj, days, loc='center left',bbox_to_anchor=(1,0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_time(\"03.01.18\",\"05.01.18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_time(\"05.01.18\",\"07.01.18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_time(\"07.01.18\",\"09.01.18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_time(\"09.01.18\",\"11.01.18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_time(\"11.01.18\",\"01.01.19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_time(\"01.01.19\",\"03.01.19\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots also show the increasing count of trips per day and also the trend, that on the weekends are less trips than on weekdays. Also we can see drops in tripcount for example on the 23.11.18 or the 06.01.19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (16,5))\n",
    "\n",
    "sns.countplot(x = \"start_hr\", data = df, palette = \"viridis\", ax = ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most frequent starting hours are at 8 and at 17. Maybe people use it before and after work, which would make sense, because we have a lot of subscribers in working age in our dataset. You only subscribe to something, if you want to use it regulary. The integration into the working/study life would make sense here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (16,5))\n",
    "\n",
    "sns.countplot(x = \"start_hr\", data = df.query(\"label == 0\"), palette = \"viridis\", ax = ax);        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (16,5))\n",
    "\n",
    "sns.countplot(x = \"start_hr\", data = df.query(\"label == 1\"),palette = \"viridis\",ax =ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For San José the trend is going more torwards the hour 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (16,5))\n",
    "\n",
    "sns.countplot(x = \"start_hr\", data = df.query(\"label == 2\"),palette = \"viridis\", ax = ax);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw, the most frequent hours are 8 and 17. I want to see how this trend is changing over time, so for the next plot we will connect these two counts with a line to see the trend based on the slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(14,1,figsize = (16,50))\n",
    "\n",
    "dates = [pd.to_datetime(f\"2018-{x}\") for x in range(1,13)] + [pd.to_datetime(f\"2019-{x}\")for x in range(1,3)]\n",
    "\n",
    "for i, date in enumerate(dates):\n",
    "    try:\n",
    "        sns.countplot(x = \"start_hr\",data = df[(df['start_time'] < dates[i+1])&(df['start_time'] >= date)],palette =\"viridis\", ax = ax[i]);\n",
    "        ax[i].set_ylim(0,25000)\n",
    "        ax[i].set_xlim(-0.5,23.5)\n",
    "        ax[i].plot([8,17], [ax[i].patches[8].get_height(),ax[i].patches[17].get_height()], 'o-',color= \"#3a3a3a\")\n",
    "        ax[i].text(0, 22000, str(date.date()))\n",
    "        \n",
    "    except:        \n",
    "        sns.countplot(x = \"start_hr\",data = df[(df['start_time'] > dates[i])],palette = \"viridis\", ax=ax[i]);\n",
    "        ax[i].set_ylim(0,25000)\n",
    "        ax[i].set_xlim(-0.5,23.5)\n",
    "        ax[i].plot([8,17], [ax[i].patches[8].get_height(),ax[i].patches[17].get_height()], 'o-', color=\"#3a3a3a\")\n",
    "        ax[i].text(0, 22000, str(date.date()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that this is an ongoing trend. At 17 'o clock slightly more trips are starting in comparison to 8 'o clock (for most of the months). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, date in enumerate(dates):\n",
    "    try:\n",
    "        print(str(df[(df['start_time'] < dates[i+1])&(df['start_time'] >= date)].start_hr.value_counts().head(2)))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bi'></a>\n",
    "### Bivariate Exploration\n",
    "> Now we are going to dig deeper into the data searching for relationships and trends between variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join the trips together\n",
    "df[\"combi\"] = df[\"start_station_id_new\"]+ \" - \" + df[\"end_station_id_new\"]\n",
    "df.combi.value_counts().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One interesting insight are the most frequent trips. Based on the data in the upper cell we can see, that the station 6_0 appears often. A heatmap should make this visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi_list = df.combi.value_counts().head(15).keys()\n",
    "df_criteria =df[df[\"combi\"].isin(combi_list)]\n",
    "df_pivot =df_criteria.pivot_table(index=\"start_station_id_new\",columns=\"end_station_id_new\",values =\"start_time\",aggfunc=\"count\", fill_value = 0)\n",
    "fig,axes = plt.subplots(figsize =(15,10),dpi = 70)\n",
    "sns.heatmap(df_pivot,annot = True,cmap =\"viridis_r\", fmt='g',vmin = 1,vmax =6000, mask= df_pivot==0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see the top 15 routes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,x in enumerate(combi_list):\n",
    "    start, end= x.split(\" - \")\n",
    "    start_name= df.query(f\"start_station_id_new == '{start}'\").start_station_name.drop_duplicates().get_values()\n",
    "    end_name= df.query(f\"end_station_id_new == '{end}'\").end_station_name.drop_duplicates().get_values()\n",
    "    print(start,\" \",start_name[0],\" - \",end, \" \",end_name[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combi_list = df.combi.value_counts().sample(20).keys()\n",
    "df_criteria = df[df[\"combi\"].isin(combi_list)]\n",
    "df_pivot = df_criteria.pivot_table(index=\"start_station_id_new\", columns = \"end_station_id_new\", values=\"start_time\", aggfunc = \"count\", fill_value = 0)\n",
    "fig, axes = plt.subplots(figsize = (15,10), dpi = 80)\n",
    "sns.heatmap(df_pivot, annot = True, cmap = \"viridis_r\",fmt='g',vmin = 1, vmax = 6000, mask= df_pivot ==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the legend object for the next plot\n",
    "legend_obj = []\n",
    "colors = [sns.color_palette(\"viridis\")[0],\n",
    "          sns.color_palette(\"viridis\")[1],\n",
    "          sns.color_palette(\"viridis\")[2],\n",
    "          sns.color_palette(\"viridis\")[3],\n",
    "          sns.color_palette(\"viridis\")[4],\n",
    "          sns.color_palette(\"viridis\")[5],\n",
    "          (163/255, 199/255, 70/255)]\n",
    "\n",
    "days = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\n",
    "for i, s in enumerate(days):\n",
    "    legend_obj.append(plt.scatter([],[],color = colors[i]));  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another interesting combination would be the day of the week combined with the average duration. For this we will create a groupby - object (mean) over each month-year combination. A Box Plot should be  appropriate to visualize this relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/4700614/how-to-put-the-legend-out-of-the-plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (15,10), dpi = 80)\n",
    "sns.boxplot(x = \"dayofweek\", y = \"duration_sec\", data = df.groupby([\"dayofweek\", \"month_year\"], as_index = False).mean(), palette = \"viridis\")\n",
    "\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(legend_obj, days, loc='center left', bbox_to_anchor=(1, 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see, that under the week the users are going on shorter trips ~ 780 Seconds while the average duration on the weekend rises to ~ 1200 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(15,10),dpi=80)\n",
    "sns.boxplot(x=\"dayofweek\",y=\"duration_sec\",data=df.groupby([\"dayofweek\",\"month_year\",\"label_name\"],as_index=False).mean(),palette = \"viridis\", hue = \"label_name\")\n",
    "box=ax.get_position()\n",
    "ax.set_position([box.x0,box.y0,box.width*0.8, box.height])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This trend applies for all areas, while we can also see that the users of San Francisco have, on average, the longest duration of trips, followed by East Bay and then San José. But what about the average duration based on the age?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize = (15,10), dpi = 80)\n",
    "sns.boxplot(x = \"age_bins\", y = \"duration_sec\", data = df_age.groupby([\"age_bins\", \"month_year\"], as_index = False).mean(), palette = \"viridis\")\n",
    "plt.ylim(250,1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The longest duration can be found in the 10 to 20 years bins. After this bin the average duration drops, then it is slightly increasing until the 60, 70 bin. Now we should explore if the duration is also different based on the starting hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_age.to_csv(\"df_age.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(15,10),dpi=80)\n",
    "sns.boxplot(x=\"start_hr\",y=\"duration_sec\",data = df.groupby([\"start_hr\", \"month_year\"], as_index = False).mean(), palette = \"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the hours 0, 1, 2, 3 we maybe have to deal with outliers. On the other hand we saw earlier, that there are not much trips starting at that time, so longer trips have a stronger impact then at 8 o' cloc kfor example. From 5 - 9 trips are relatively short with ~ 600 seconds, then the average rises to ~950 from 10 - 15. From 16 - 20 it drops again to ~700 seconds to finally increase slightly around 22 and 23."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (20,10), dpi = 80)\n",
    "sns.boxplot(x = \"start_hr\", y = \"duration_sec\", data = df.groupby([\"start_hr\", \"month_year\", \"label_name\"], as_index = False).mean(), palette = \"viridis\", hue = \"label_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the hours 0 - 4 are getting more unclear. This graph confirms again, that San Francisco has, on average, the longest duration of trips, while users of East Bay and San José tend to have shorter trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,10),dpi=80)\n",
    "sns.boxplot(x = \"dayofweek\",y=\"start_hr\",data=df.groupby([\"dayofweek\",\"month_year\"], as_index = False).mean(), palette = \"viridis\")\n",
    "box = ax.get_position()\n",
    "ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "# Put a legend to the right of the current axis\n",
    "ax.legend(legend_obj, days,loc='center left', bbox_to_anchor=(1, 0.5)) #misleading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows, that people start their trips, on average, later on the weekend than during the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,10), dpi = 80)\n",
    "sns.boxplot(x = \"dayofweek\", y = \"start_hr\", data = df.groupby([\"dayofweek\", \"month_year\", \"label_name\"], as_index=False).mean(), palette = \"viridis\", hue = \"label_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at each area is interesting, because Users from East Bay and San José are not only have shorter trip durations on average, but also they start their trips later than San Francisco on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,10), dpi = 80)\n",
    "sns.boxplot(x = \"month_year\", y = \"start_hr\", data = df.groupby([\"month_year\",\"dayofweek\"], as_index =False).mean(), palette = \"viridis\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows, that on average the users start later in the middle of the year than at the beginning or the end of the year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize = (15,10), dpi = 80)\n",
    "sns.boxplot(x = \"month_year\", y = \"start_hr\", data = df.groupby([\"month_year\",\"dayofweek\", \"label_name\"], as_index = False).mean(), palette = \"viridis\", hue = \"label_name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multi'></a>\n",
    "### Multivariate Exploration\n",
    "> For the last explorative visualization we will take a look on a visualization on the trips with kepler.gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_station_names.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips = df[[\"start_station_latitude\", \"start_station_longitude\",  \"end_station_latitude\",\"end_station_longitude\",\"start_station_id_new\", \"end_station_id_new\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips[\"cnt\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_grp=df_trips.groupby([x for x in df_trips.columns[:-1]],as_index = False).sum().sort_values(\"cnt\",ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_grp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trips_grp.to_csv(\"grps.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first we will look at San Francisco. To get some insight, the visualization will only contain routes with more than 1000 trips:\n",
    "![San Francisco Trips with more than 1000 trips](Images/san_francisco_1000.png)\n",
    "\n",
    "We can see that most of the trips are close to the beach. Now for East Bay with routes with more than 500 trips:\n",
    "![East Bay Trips with more than 500 trips](Images/east_bay_500.png)\n",
    "\n",
    "Here the main routes are much more spread than in San Francisco. Also it looks like people use this service to quickly overcome smaller distances. For San José we will take a look on routes that have more than 200 trips.\n",
    "![San Jose Trips with more than 200 trips](Images/san_jose_200.png)\n",
    "\n",
    "For San José it looks spread over most of the stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "## Summary and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From our exploration we can note that:\n",
    "- This data covers three areas: San Francisco, East Bay and San José.\n",
    "- The highest count of trips can be found in San Francisco, followed by East Bay and San José.\n",
    "- The average trips is ~700 seconds long, the most trips were around ~500 seconds long.\n",
    "- San Francisco has the longest trips with ~717 seconds, followed by East Bay with ~631 seconds and San José with ~ 627seconds.\n",
    "- There are alot more male users than other users, for all areas there are always over 64% male.\n",
    "- There are a lot more subscribers than customer using this service.\n",
    "- The average user over all data is most likely between 24 and 35 years old.\n",
    "- San Francisco has the oldest average users, followed by East Bay and San José, which has the youngest users with an average of ~ 30 years\n",
    "- People use the bikes more/in higher counts during the week than during the weekend.\n",
    "- On the other hand the trips on the weekend are longer (~1100 seconds) than during the week (~780 seconds).\n",
    "- Also people start their trips later during the weekends than during the week (~ 14 'o clock instead of ~13:20 during the week).\n",
    "- Overall San Francisco has the longest average trips, followed by East Bay and San José.\n",
    "- Users starting in the morning and in the evening have shorter trips than people who start between 11 and 15.\n",
    "- In San Jose the trips start on average the latest, followed by East Bay and San Francisco.\n",
    "- There is an increasing trend of usage.\n",
    "- People start their trips most frequently at 8 and 17 'o clock.\n",
    "- the most popular trip so far is between stations 15_0 San Francisco Ferry Building (Harry Bridges Plaza) and 6_0 The Embarcadero at Sansome St."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
