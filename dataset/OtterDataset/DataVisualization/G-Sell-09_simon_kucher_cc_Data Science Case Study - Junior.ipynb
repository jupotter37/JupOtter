{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "27f14d9a-8893-449a-930e-f5d946957a2c",
   "metadata": {},
   "source": [
    "# Problem Description\n",
    "***alles um tier GmBH*** is a pet supplies company. They are currently auditing their promotional activities and the CEO, one of the main stakeholders, feels that the promotions they offer is too generic and not targeted. They have requested us to devise a customer segmentation model that they can use to run targeted promotional activities.\n",
    "\n",
    "The client is interested in seeing what kind of customers are buying at ***alles um tier GmbH***. They assume that, in addition to private individuals, there are also smaller companies that purchase from ***alles um tier GmBH***. The project scope is to build a segmentation model and analyze the resulting customer segments.\n",
    "\n",
    "# Data\n",
    "\n",
    "You are given a dataset at customer level for the past year with the following data points. Number of transactions in the past year (*num_transactions*), order amount the past year (*total_order_value*), days between transactions the past year (*days_between_trans*), re-order rate the past year (*repeat_share*), and % of dog products bought (*dog_share*).\n",
    "\n",
    "### Data Set\n",
    "The dataset consists of 100k rows and has the following columns:\n",
    "\n",
    "* CustomerID (int): UUID for the customer\n",
    "* num_transactions (int): number of transactions in a given year\n",
    "* total_order_value (float): total order value in € for the time period\n",
    "* days_between_trans (float): average days between transactions for a user\n",
    "* repeat_share (float): product share repeated every order\n",
    "* dog_share (float): percentage of products ordered that are dog food related\n",
    "    \n",
    "# Technical Environment\n",
    "* Python\n",
    "* numpy\n",
    "* pandas\n",
    "* scikit-learn\n",
    "* matplotlib / scipy / searborn / altair / plotly\n",
    "\n",
    "# Approach\n",
    "The solution is assessed on the following skills:\n",
    "* A thorough evaluation of the data set using statistical measures and visualization\n",
    "* Elegant Python coding skills\n",
    "* Machine learning modelling fundamentals\n",
    "* Model & result evaluation\n",
    "\n",
    "# Output\n",
    "Please provide your solution in a jupyter notebook with clear markdown comments.\n",
    "The final output should be in the form of a DataFrame with two columns, the CustomerId and the assigned cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4acb833",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "--------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22559e30",
   "metadata": {},
   "source": [
    "# Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b57f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import davies_bouldin_score\n",
    "import altair as alt\n",
    "import plotly.express as px\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f087c59",
   "metadata": {},
   "source": [
    "## Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed64ab0-ad74-42b4-a516-857d513a1f2e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# load the data and make sure to specify the correct delimiter\n",
    "df = pd.read_csv(\"DataSet_JuniorCodingChallenge.csv\", delimiter='|')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6727eda2",
   "metadata": {},
   "source": [
    "## Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acf5ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how often two values are missing in one row\n",
    "print(f\"Number of rows with two missing values: {len(df[df.isnull().sum(axis=1) == 2])}\")\n",
    "\n",
    "dropping = len(df[df.isnull().sum(axis=1) == 1])/len(df)\n",
    "print(f\"Percentage of rows with one missing value: {dropping:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5b8cbe",
   "metadata": {},
   "source": [
    "* Only 0.46% of all customer data have missing values, with just one entry missing at a time.\n",
    "\n",
    "* Given the low percentage of missing data, one approach could be to drop the incomplete rows. However, since the missing data occurs sparsely across the dataset, it’s preferable to fill these gaps rather than discard potentially valuable records.\n",
    "\n",
    "* To preserve the dataset’s integrity, we will apply K-Nearest Neighbors (KNN) Imputation to fill in the missing numerical values. This method ensures that the imputed values are aligned with the general structure of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad73c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy and drop the CustomerID column\n",
    "df_knn = df.drop(columns='CustomerID')\n",
    "\n",
    "# Initialize the KNN imputer, choosing k=3 for nearest neighbors\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# Apply the imputer to the dataset (on numeric columns)\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df_knn), columns=df_knn.columns)\n",
    "\n",
    "# After imputation, check if any missing values remain\n",
    "assert df_imputed.isnull().sum().sum() == 0, \"There are still missing values in the data.\"\n",
    "\n",
    "# The imputed data is now free of missing values and has been verified as consistent with expectations.\n",
    "print(\"Missing values handled using KNN imputation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e709b68",
   "metadata": {},
   "source": [
    "* After applying the KNN Imputer, all missing values were successfully filled. The imputed data was manually reviewed, and all values appeared reasonable and consistent with the rest of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0f447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set df to the imputed data and add the CustomerID column back to the first column\n",
    "df = pd.concat([df['CustomerID'], df_imputed], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18558a30",
   "metadata": {},
   "source": [
    "## Data Integrity Check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3431260",
   "metadata": {},
   "source": [
    "At first we want to make sure that the num_transaction has the correct integer values and that the other numerical features are saved as floats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740b4eca",
   "metadata": {},
   "source": [
    "We review all columns to ensure that each field had the correct data type (e.g., numerical, categorical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303900ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the current data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a228bca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_floats(df, column):\n",
    "    \"\"\"\n",
    "    Count the number of unique entries in the specified column of a DataFrame\n",
    "    that are floats with non-zero decimal parts.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data.\n",
    "    column (str): The name of the column to analyze.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of unique floats with non-zero decimal parts in the column.\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    for i in df[column].unique():\n",
    "        if isinstance(i, float) and i % 1 != 0:\n",
    "            count += 1\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73badef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State how many entries need to be rounded in the num_transactions column\n",
    "print(f\"There are {find_floats(df, 'num_transactions')} entries that are not .00 floats and need to be rounded.\")\n",
    "\n",
    "# Round all float values before converting them to integers\n",
    "df['num_transactions'] = df['num_transactions'].apply(lambda x: round(x))\n",
    "\n",
    "# Double Check if all values are rounded now with a print statement\n",
    "print(f\"There are {find_floats(df, 'num_transactions')} entries that are not .00 floats left.\")\n",
    "\n",
    "# Convert num_transactions to integers\n",
    "df['num_transactions'] = df['num_transactions'].astype(int)\n",
    "\n",
    "# Check the data types again\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e6072c",
   "metadata": {},
   "source": [
    "* Any necessary adjustments were made to align the data types with their intended use. \n",
    "\n",
    "* It was carefully considered that the float values will be rounded first before they are converted into integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f84040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of negative values for num_transactions, total_order_value and days_between_trans for negative values\n",
    "print(f\"Number of negative values for num_transactions: {len(df[df['num_transactions'] < 0])}\")\n",
    "print(f\"Number of negative values for total_order_value: {len(df[df['total_order_value'] < 0])}\")\n",
    "print(f\"Number of negative values for days_between_trans: {len(df[df['days_between_trans'] < 0])}\")\n",
    "\n",
    "# Check repeat_share and dog_share for values between 0 and 1. So count the number of values outside of this range\n",
    "print(f\"Number of values outside of the range [0, 1] for repeat_share: {len(df[(df['repeat_share'] < 0) | (df['repeat_share'] > 1)])}\")\n",
    "print(f\"Number of values outside of the range [0, 1] for dog_share: {len(df[(df['dog_share'] < 0) | (df['dog_share'] > 1)])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b596c3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the negative values in the 3 columns\n",
    "df = df[df['num_transactions'] >= 0]\n",
    "df = df[df['total_order_value'] >= 0]\n",
    "df = df[df['days_between_trans'] >= 0]\n",
    "\n",
    "# Drop the values outside of the range 0 and 1 for the last two columns\n",
    "df = df[(df['repeat_share'] >= 0) & (df['repeat_share'] <= 1)]\n",
    "df = df[(df['dog_share'] >= 0) & (df['dog_share'] <= 1)]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea5e905",
   "metadata": {},
   "source": [
    "* A comprehensive check was performed to ensure all numerical values were within logical and reasonable ranges. \n",
    "\n",
    "* Any data points falling outside acceptable ranges were identified and removed to maintain data accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43f1fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_inconsistent_duplicates(df, object_col):\n",
    "    \"\"\"\n",
    "    Identify indices of rows where duplicated values in the specified column\n",
    "    have inconsistent data.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data.\n",
    "    object_col (str): The name of the column to check for duplicates.\n",
    "\n",
    "    Returns:\n",
    "    list of int: Indices of rows with inconsistent data among duplicates.\n",
    "    \"\"\"\n",
    "    # Get the indices of duplicated entries in the object column\n",
    "    duplicated_indices = df[df.duplicated(subset=[object_col], keep=False)].index\n",
    "\n",
    "    # Dictionary to store the indices of inconsistent duplicates\n",
    "    inconsistent_indices = []\n",
    "\n",
    "    # Group by the object column and iterate over each group\n",
    "    for key, group in df.loc[duplicated_indices].groupby(object_col):\n",
    "        # Get the first row's data (excluding the object column)\n",
    "        reference_row = group.iloc[0, 1:].values\n",
    "        \n",
    "        # Check if all rows in the group match the first row\n",
    "        for idx, row in group.iterrows():\n",
    "            if not (row.iloc[1:].values == reference_row).all():\n",
    "                inconsistent_indices.append(idx)\n",
    "\n",
    "    return inconsistent_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc2607",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_with_inconsistencies = find_inconsistent_duplicates(df, 'CustomerID')\n",
    "\n",
    "# Print the number of inconsistent duplicates\n",
    "print(f\"Number of inconsistent duplicates: {len(indices_with_inconsistencies)}.\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0564692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State how many CustomerIDs are duplicated and that they will be dropped\n",
    "print(f\"There are {df['CustomerID'].duplicated().sum()} duplicated CustomerIDs. They will be dropped.\")\n",
    "\n",
    "# Drop the duplicated CustomerIDs\n",
    "df = df.drop_duplicates(subset='CustomerID')\n",
    "\n",
    "# Reset the index\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040bf329",
   "metadata": {},
   "source": [
    "* A duplicate check was conducted across the dataset.\n",
    "\n",
    "* All duplicate entries were found to be consistent with no conflicting values. These duplicates were safely dropped to avoid any skewing of the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1cdf69",
   "metadata": {},
   "source": [
    "Steps Taken:\n",
    "\n",
    "* Data was loaded and reviewed for missing entries.\n",
    "\n",
    "* Missing values were handled using K-Nearest Neighbors (KNN) Imputation to fill gaps efficiently.\n",
    "\n",
    "* The data types of each column were verified and corrected where necessary.\n",
    "\n",
    "* Numerical ranges were validated, and any values outside acceptable ranges were removed.\n",
    "\n",
    "* Duplicate entries were detected, verified for consistency, and dropped.\n",
    "\n",
    "Outcome:\n",
    "\n",
    "* The dataset now contains 99,105 unique customer records, with clean and verified data, ready for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d259363",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis **(EDA)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8c206e",
   "metadata": {},
   "source": [
    "## Statistical Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fe4cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary statistics for the data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a377d6d1",
   "metadata": {},
   "source": [
    "* Using the describe() function, we obtained a detailed overview of each variable, including key statistics such as mean, standard deviation, and quartiles. This provided an initial understanding of the distribution of the features and highlighted the presence of potential outliers, which were explored further in the subsequent visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c4298",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7eb26f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histogram for each column\n",
    "df.hist(figsize=(10, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4895a8e4",
   "metadata": {},
   "source": [
    "* The histograms of all numerical variables revealed varying distributions across features, with some exhibiting skewness. For example, num_transactions and total_order_value are skewed to the right, indicating the presence of a few customers with a high volume of transactions or large order values. This may support the CEO's hypothesis that there are also corporate customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f08d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.drop(columns='CustomerID')\n",
    "\n",
    "# Creating multiple boxplots, one for each column\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, col in enumerate(df_copy.columns):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    sns.boxplot(x=df_copy[col])\n",
    "    plt.title(col)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fcdab2",
   "metadata": {},
   "source": [
    "* The boxplots further reinforced the hypothesis by highlighting significant outliers, particularly in total_order_value and days_between_trans. These extreme values likely represent corporate customers, who order infrequently but in large volumes. Understanding the spread and identifying outliers is crucial for later feature engineering and clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a64c4f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(df):\n",
    "    \"\"\"\n",
    "    Create and visualize a correlation matrix for the DataFrame using a heatmap.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data to analyze.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays a heatmap plot of the correlation matrix.\n",
    "    \"\"\"\n",
    "    corr = df.corr()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1088943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_matrix(df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca1824a",
   "metadata": {},
   "source": [
    "The correlation matrix provided valuable insights into the relationships between features:\n",
    "\n",
    "* days_between_trans and repeat_share (-0.67): This negative linear correlation suggests that customers with higher reordering rates tend to have shorter intervals between purchases. These could be customers who place routine, frequent orders, possibly on a weekly or monthly basis.\n",
    "\n",
    "* days_between_trans and dog_share (0.41): The positive correlation indicates that customers who order less frequently tend to have a higher share of dog-related products in their purchases. However, this relationship requires further exploration as it could indicate differing customer types (e.g., occasional buyers focused on specific products like dog food)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454cff72",
   "metadata": {},
   "source": [
    "## Feature Relationships and Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pairplots for all numerical data\n",
    "sns.pairplot(df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb05525",
   "metadata": {},
   "source": [
    "The pairplot helped visualize the relationships between all features:\n",
    "\n",
    "* num_transactions vs. total_order_value: This relationship highlights two distinct customer behaviors. Frequent, smaller orders could suggest private customers who need regular household supplies, while infrequent but large orders could represent smaller companies making bulk purchases. This supports the hypothesis of different customer segments: private individuals versus corporate clients.\n",
    "\n",
    "* num_transactions & days_between_trans vs. repeat_share: The plots suggest three distinct customer segments. Two noticeable clusters of possibly private customers (those making regular, repeated purchases) are evident, as well as a group of outliers, likely representing corporate clients. The corporate clients typically have fewer transactions but higher order volumes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86424959",
   "metadata": {},
   "source": [
    "### Dropping some of the Outliers in a 1st Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0fe0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 10% outliers from the data in a new copy\n",
    "df_no_outliers = df.copy()\n",
    "\n",
    "# Define the columns to check for outliers\n",
    "columns = ['num_transactions', 'total_order_value', 'days_between_trans', 'repeat_share', 'dog_share']\n",
    "\n",
    "# Iterate over the columns and remove the outliers\n",
    "for col in columns:\n",
    "    # Calculate the z-scores for each value in the column\n",
    "    z_scores = np.abs(stats.zscore(df_no_outliers[col]))\n",
    "\n",
    "    # 99.9% confidence interval (2194 outliers)\n",
    "    outlier_indices = np.where(z_scores > 3.291)[0]\n",
    "\n",
    "    # 99.5% confidence interval (3523 outliers)\n",
    "    # outlier_indices = np.where(z_scores > 2.807)[0]\n",
    "\n",
    "    # 99% confidence interval (4532 outliers)\n",
    "    # outlier_indices = np.where(z_scores > 2.58)[0]\n",
    "\n",
    "    # 95% confidence interval (17560 outliers)\n",
    "    # outlier_indices = np.where(z_scores > 1.96)[0] \n",
    "\n",
    "    # 90% confidence interval (29567 outliers)\n",
    "    # outlier_indices = np.where(z_scores > 1.64)[0]\n",
    "\n",
    "    # Drop the outliers\n",
    "    df_no_outliers = df_no_outliers.drop(index=outlier_indices)\n",
    "\n",
    "    # Reset the index\n",
    "    df_no_outliers = df_no_outliers.reset_index(drop=True)\n",
    "\n",
    "# How many outliers were removed\n",
    "print(f\"{len(df) - len(df_no_outliers)} outliers were removed.\")\n",
    "\n",
    "# Visualize the pairplots for the data without outliers\n",
    "sns.pairplot(df_no_outliers)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36c583b",
   "metadata": {},
   "source": [
    "After removing outliers using a 99.9% confidence interval, we gained clearer insights into customer segments:\n",
    "\n",
    "* total_order_value vs. num_transactions: There is now a distinct relationship between higher total order values and increased transaction frequency. Customers who frequently place orders also tend to reorder the same products, suggesting a routine purchasing behavior.\n",
    "\n",
    "* Customer Segments: Two key customer segments are visible:\n",
    "    1. Low-frequency, low-volume buyers: These customers tend to have a high number of days between transactions and low repeat orders. They may represent trial users who were not fully convinced by the product offerings and could be targeted with win-back strategies (e.g., special offers or discounts).\n",
    "    2. High-frequency, high-volume buyers: These customers order frequently and tend to reorder the same products. They likely have a stable shopping pattern, making them ideal candidates for loyalty programs or early access to new products.\n",
    "\n",
    "* Repeat Share vs. Days Between Transactions: A clear segmentation emerges here. Customers with short intervals between transactions tend to have higher repeat share percentages, indicating they rely on certain staple products. On the other hand, less frequent buyers have lower repeat shares, suggesting they might experiment with different products. This insight could be useful for targeted promotions focusing on new or complementary products for loyal customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4dbdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_correlation_matrix(df_no_outliers.drop(columns='CustomerID'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e7e464",
   "metadata": {},
   "source": [
    "After removing the outliers, the correlation matrix further validated several key relationships:\n",
    "\n",
    "* num_transactions and total_order_value (0.98): This strong positive correlation highlights that frequent buyers naturally accumulate higher total order values over time. \n",
    "\n",
    "* days_between_trans and other features: The negative correlations between days_between_trans and both num_transactions (-0.84) and total_order_value (-0.79) emphasize that customers who order more frequently tend to have shorter gaps between transactions. This is expected and supports the segmentation of frequent buyers with routine purchasing behaviors.\n",
    "\n",
    "* repeat_share vs. days_between_trans (-0.8): The negative correlation between the repeat order rate and days between transactions further indicates that customers with shorter transaction intervals tend to reorder the same products. These insights could inform the development of targeted promotions that focus on encouraging product trials or cross-selling to customers who rely on routine purchases.\n",
    "\n",
    "* dog_share vs. num_transactions (-0.38): The inverse relationship here suggests that customers who place frequent orders tend to have a lower percentage of dog-related products. This is an important insight for product targeting, as infrequent buyers are more likely to be interested in dog-related products, whereas frequent buyers diversify their purchases beyond dog supplies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b9a1c2",
   "metadata": {},
   "source": [
    "### Creating a new Feature – avg_order_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9a1271",
   "metadata": {},
   "source": [
    "* Given the high correlation between total_order_value and num_transactions (0.98), we will derive a new feature, avg_order_value, to represent the average value of each order per customer. This transformation simplifies the analysis by consolidating these two highly correlated features into a more interpretable metric.\n",
    "\n",
    "* Calculating the average order value provides a clearer insight into how much a customer spends per transaction, removing the noise of transaction frequency. This newly engineered feature will help in better understanding the purchasing behavior of different customer segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a576ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate new feature avg_order_value\n",
    "df_no_outliers['avg_order_value'] = df_no_outliers['total_order_value'] / df_no_outliers['num_transactions']\n",
    "\n",
    "# Set the new column as the first column and drop the old columns\n",
    "df_no_outliers = df_no_outliers[['CustomerID', 'avg_order_value', 'days_between_trans', 'repeat_share', 'dog_share']]\n",
    "\n",
    "# Do the same for the original data\n",
    "df['avg_order_value'] = df['total_order_value'] / df['num_transactions']\n",
    "# df = df[['CustomerID', 'avg_order_value', 'days_between_trans', 'repeat_share', 'dog_share']]\n",
    "\n",
    "# Check the new data\n",
    "df_no_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba88adb5",
   "metadata": {},
   "source": [
    "### Visualizing the Dataset with new Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda8c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use .describe but only for the new feature\n",
    "df_no_outliers['avg_order_value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbca76f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pairplot that only shows the relationship of the new feature with the other features\n",
    "sns.pairplot(df_no_outliers, y_vars='avg_order_value', x_vars=['days_between_trans', 'repeat_share', 'dog_share'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f752a",
   "metadata": {},
   "source": [
    "* avg_order_value vs. days_between_trans: Customers who order more frequently (i.e., have lower days_between_trans) tend to have higher average order values. This relationship could indicate that frequent buyers are consistently purchasing higher quantities or more expensive products in each order.\n",
    "\n",
    "* avg_order_value vs. repeat_share: A clear linear relationship is visible here. The higher the average order value, the greater the percentage of repeat items in each order. This suggests that customers with larger average purchases are more likely to reorder the same products regularly, indicating loyalty to specific products.\n",
    "\n",
    "* avg_order_value vs. dog_share: The relationship between these two features is less pronounced. However, there is a slight tendency indicating that customers with lower average order values might have a higher percentage of dog-related products. This could hint at occasional or first-time buyers focused on specific pet-related needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12022b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the correlation only for the new feature with the other features\n",
    "corr_avg_order = df_no_outliers.drop(columns='CustomerID').corr()['avg_order_value']\n",
    "corr_avg_order = corr_avg_order.drop('avg_order_value')\n",
    "\n",
    "# Visualize these findings\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=corr_avg_order.values, y=corr_avg_order.index, palette='coolwarm', hue=corr_avg_order.values)\n",
    "plt.title('Correlation of Average Order Value with the other Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c2c72c",
   "metadata": {},
   "source": [
    "The correlations between the new feature avg_order_value and the remaining features provide further support for the patterns observed in the pairplot:\n",
    "\n",
    "* days_between_trans (-0.78): The negative correlation suggests that customers with shorter intervals between transactions tend to have higher average order values. This is consistent with the idea that frequent buyers make larger or more valuable purchases per transaction.\n",
    "\n",
    "* repeat_share (0.86): The strong positive correlation shows a clear and significant relationship between average order value and the percentage of repeat items in each order. Customers with higher average order values are more likely to reorder the same products regularly, which indicates loyalty and possibly a reliance on staple products. This also implies that high-value customers may be ideal targets for promotions involving new products, as they already exhibit strong purchasing habits.\n",
    "\n",
    "* dog_share (-0.40): The negative correlation between avg_order_value and dog_share suggests that customers with higher average order values tend to have a lower percentage of dog-related products in their orders. This supports the observation that occasional buyers, particularly those with smaller average order values, may be focusing more on dog-related items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the avg_order_value column in a boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x=df['avg_order_value'])\n",
    "plt.title('Original Data')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x=df_no_outliers['avg_order_value'])\n",
    "plt.title('Data without Outliers')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6c2e91",
   "metadata": {},
   "source": [
    "* Full Dataset: The left boxplot, which includes the entire dataset, clearly highlights the presence of corporate customers with significantly higher average order values. These outliers, representing large, less frequent purchases, are distinct from the general population of private customers. This visual representation reinforces the need to segment these corporate customers for more targeted analysis later on.\n",
    "\n",
    "* Outlier-Free Dataset: The right boxplot, after removing outliers, provides a more refined view of the average order value distribution among private customers. It shows a narrower range, giving a clearer sense of the central tendency and spread of average order values. Most regular customers have average order values clustered within a range of 14 to 25 euros, confirming that corporate customers were skewing the previous analysis.\n",
    "\n",
    "This refined understanding of avg_order_value sets the stage for the next analysis, where corporate customers will be more precisely identified and characterized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f9813f",
   "metadata": {},
   "source": [
    "### Identifying Corporate Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370c5630",
   "metadata": {},
   "source": [
    "#### Using avg_order_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b579210",
   "metadata": {},
   "source": [
    "Step 1: Detecting Outliers with Interquartile Range (IQR)\n",
    "\n",
    "* To precisely identify corporate customers, we begin by applying the Interquartile Range (IQR) method on the newly created feature, avg_order_value. This classic approach allows us to systematically identify outliers, particularly those with high average order values, which are indicative of corporate clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb811f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the IQR method to identify the outliers in the avg_order_value column\n",
    "Q1 = df['avg_order_value'].quantile(0.25)\n",
    "Q3 = df['avg_order_value'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate the number of outliers\n",
    "outliers = df[(df['avg_order_value'] < (Q1 - 1.5 * IQR)) | (df['avg_order_value'] > (Q3 + 1.5 * IQR))]\n",
    "print(f\"Number of outliers in the avg_order_value column: {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf55a07",
   "metadata": {},
   "source": [
    "* After computing the IQR, we identified 99 customers as potential outliers. However, a more detailed, manual inspection of the data will help to find a more refined boundary for accurate segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87599a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the original data and rank the dataset by the avg_order_value column in descending order\n",
    "df_ranked = df.sort_values(by='avg_order_value', ascending=False).reset_index(drop=True)\n",
    "df_ranked.head(len(outliers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf5366",
   "metadata": {},
   "source": [
    "Step 2: Refining the Boundary for Corporate Customers\n",
    "\n",
    "* Upon further analysis, we found a clear and significant boundary at index 95, where the average order value drops sharply from €2,370 to just €96.50 for the next customer (index 96). This strong difference suggests that the first 96 customers are very likely corporate clients, distinguished by their substantially higher average order values.\n",
    "\n",
    "* Interestingly, the customer at index 96 (ID: tvs855) has a much lower avg_order_value of €96.50 but shares a total order value similar to the lower range of corporate clients. This observation prompts us to investigate total_order_value more thoroughly to detect other potential corporate customers based on total spending rather than per-order averages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27150c51",
   "metadata": {},
   "source": [
    "#### Using total_order_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a810aea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the IQR method to identify the outliers in the avg_order_value column\n",
    "Q1 = df['total_order_value'].quantile(0.25)\n",
    "Q3 = df['total_order_value'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Calculate the number of outliers\n",
    "outliers = df[(df['total_order_value'] < (Q1 - 1.5 * IQR)) | (df['total_order_value'] > (Q3 + 1.5 * IQR))]\n",
    "print(f\"Number of outliers in the total_order_value column: {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae3882b",
   "metadata": {},
   "source": [
    "Step 1: Analyzing total_order_value for Further Outliers\n",
    "\n",
    "* In our next step, we applied the same IQR technique to the total_order_value column. This method revealed 1,587 customers with notably high total order values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7e021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank the df by the total order value\n",
    "df_ranked_total = df.sort_values(by='total_order_value', ascending=False).reset_index(drop=True)\n",
    "df_ranked_total.iloc[1580:1595]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3cf59d",
   "metadata": {},
   "source": [
    "* At the lower boundary, the total order value drops from €6,726 at index 1586 to just €658 for the next customer. This sharp decline indicates the presence of another distinct cluster of possibly corporate customers, maybe smaller businesses that place frequent but lower-value orders. These companies likely place orders on a near-daily basis, a behavior uncommon for private individuals, and thus represent another segment of corporate clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86803f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within df_ranked_total.iloc[97:1595] check for customers that have a days_between_trans value of above 3\n",
    "outliers = df_ranked_total.iloc[97:1587][df_ranked_total.iloc[97:1587]['days_between_trans'] > 3].index\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768ef2bc",
   "metadata": {},
   "source": [
    "* While analyzing days_between_trans, we found two extreme outliers that suggested data entry errors. Given that the dataset covers a one-year period, it is impossible for the number of days between transactions to exceed 365, yet two customers had significantly higher values, suggesting a potential typo or miscalculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd500044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the df_ranked_total from 96 to 1586 and plot the days_between_trans column in a boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df[df['num_transactions'] == 401]['days_between_trans'][df[df['num_transactions'] == 401 ]['days_between_trans'] < 1000])\n",
    "plt.title('Boxplot of the days_between_trans column for the first 1587 companies of total_order_value')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the mean of that column for that range\n",
    "print(f\"The mean of the days_between_trans column for the first 1587 companies of total_order_value is {df[df['num_transactions'] == 401]['days_between_trans'][df[df['num_transactions'] == 401]['days_between_trans'] < 1000].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff8f3ed",
   "metadata": {},
   "source": [
    "* After visualizing the corrected dataset using a boxplot (without these two outliers), we observed that the remaining customers have days_between_trans values ranging from 1.4 to 2.5 days, with an average of 1.90 days. This suggests that the two erroneous entries were inflated by three digits, potentially due to a data-entry issue where values should have been recorded as 2,346 and 2,349, respectively.\n",
    "\n",
    "* To address this issue, we will divide the problematic values by 1,000 to align them with the rest of the dataset. After correction, the data will reflect realistic transaction frequencies and no longer skews the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d43f08a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the wrong values\n",
    "df_ranked_total.loc[1231, 'days_between_trans'] = df_ranked_total.loc[1231, 'days_between_trans'] / 1000\n",
    "df_ranked_total.loc[957, 'days_between_trans'] = df_ranked_total.loc[957, 'days_between_trans'] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b1bf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is any outlier left\n",
    "print(f\"Number of companies with a days_between_trans value of above 3: {len(df_ranked_total.iloc[97:1587][df_ranked_total.iloc[97:1587]['days_between_trans'] > 3])}\")\n",
    "print(f\"Number of companies with a days_between_trans value of below 0.1: {len(df_ranked_total.iloc[97:1587][df_ranked_total.iloc[97:1587]['days_between_trans'] < 0.1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b31a52",
   "metadata": {},
   "source": [
    "Based on the analysis of both avg_order_value and total_order_value, along with the corrected days_between_trans values, we established three distinct segments:\n",
    "\n",
    "1. Corporate Customers (1st 96 customers): \n",
    "    * Identified based on a significant boundary in avg_order_value and supported by their high total order value.\n",
    "\n",
    "2. Frequent Corporate Customers (97th to 1588th customers): \n",
    "    * Identified by their high total order values and low days_between_trans values, representing companies that order frequently but with smaller individual transactions.\n",
    "\n",
    "3. Private Customers (Remaining customers): \n",
    "    * These customers exhibit lower values in both avg_order_value and total_order_value and likely represent individual buyers with more sporadic purchasing behavior.\n",
    "\n",
    "With this segmentation, we can now tailor future analyses and strategies to better understand and target each group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cf8544",
   "metadata": {},
   "source": [
    "### Dividing the Dataset into Corporate and Private Customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacdfe9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the corporate custome datarframe by using only the first 96 rows\n",
    "df_corporate1 = df_ranked.head(96)\n",
    "df_corporate1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e9a3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corporate2 = df_ranked_total.iloc[97:1587]\n",
    "df_corporate2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63cc954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the private customer dataframe by using the remaining rows\n",
    "df_private = df_ranked_total.iloc[1587:]\n",
    "df_private = df_private.reset_index(drop=True)\n",
    "df_private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9ebde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the 3 datasets have a common CustomerID with each other\n",
    "common_ids1 = df_corporate1['CustomerID'].isin(df_corporate2['CustomerID'])\n",
    "common_ids2 = df_corporate1['CustomerID'].isin(df_private['CustomerID'])\n",
    "common_ids3 = df_corporate2['CustomerID'].isin(df_private['CustomerID'])\n",
    "\n",
    "# Print the results\n",
    "print(f\"Number of common CustomerIDs between corporate1 and corporate2: {common_ids1.sum()}\")\n",
    "print(f\"Number of common CustomerIDs between corporate1 and private: {common_ids2.sum()}\")\n",
    "print(f\"Number of common CustomerIDs between corporate2 and private: {common_ids3.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b24140",
   "metadata": {},
   "source": [
    "The dataset is now divided into three segments:\n",
    "\n",
    "* Corporate Customers 1: The first 96 customers based on their high average order values.\n",
    "\n",
    "* Corporate Customers 2: Customers ranked 97 to 1586, distinguished by their frequent and high-volume transactions.\n",
    "\n",
    "* Private Customers: The remaining customers, presumed to be individual buyers with lower total and average order values.\n",
    "\n",
    "We then proceed by visualizing each dataset with boxplots and histograms, focusing on avg_order_value and total_order_value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4293d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now in 2x3 grid, plot the boxplots for the avg_order_value and total_order_value columns for the 3 datasets\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# First row: Boxplots\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.boxplot(x=df_corporate1['avg_order_value'])\n",
    "plt.title('Corporate Customers 1 - Average Order Value')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.boxplot(x=df_corporate2['avg_order_value'])\n",
    "plt.title('Corporate Customers 2 - Average Order Value')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.boxplot(x=df_private['avg_order_value'])\n",
    "plt.title('Private Customers - Average Order Value')\n",
    "\n",
    "# Second row: Boxplots\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.boxplot(x=df_corporate1['total_order_value'])\n",
    "plt.title('Corporate Customers 1 - Total Order Value')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.boxplot(x=df_corporate2['total_order_value'])\n",
    "plt.title('Corporate Customers 2 - Total Order Value')\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "sns.boxplot(x=df_private['total_order_value'])\n",
    "plt.title('Private Customers - Total Order Value')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876041aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2x3 grid of histograms for the three dataframes with avg_order_value and total_order_value\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# First row: Histograms\n",
    "plt.subplot(2, 3, 1)\n",
    "sns.histplot(df_corporate1['avg_order_value'], bins=20)\n",
    "plt.title('Corporate Customers 1 - Histogram')\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "sns.histplot(df_corporate2['avg_order_value'], bins=20)\n",
    "plt.title('Corporate Customers 2 - Histogram')\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "sns.histplot(df_private['avg_order_value'], bins=20)\n",
    "plt.title('Private Customers - Histogram')\n",
    "\n",
    "# Second row: Histograms\n",
    "plt.subplot(2, 3, 4)\n",
    "sns.histplot(df_corporate1['total_order_value'], bins=20)\n",
    "plt.title('Corporate Customers 1 - Histogram')\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "sns.histplot(df_corporate2['total_order_value'], bins=20)\n",
    "plt.title('Corporate Customers 2 - Histogram')\n",
    "\n",
    "plt.subplot(2, 3, 6)\n",
    "sns.histplot(df_private['total_order_value'], bins=20)\n",
    "plt.title('Private Customers - Histogram')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c9f023",
   "metadata": {},
   "source": [
    "The boxplots and histograms generated for each segment confirm the robustness of our segmentation. Each customer group demonstrates distinct value ranges, with only a few outliers in each dataset.\n",
    "\n",
    "* Corporate Customers 1: The range of avg_order_value and total_order_value aligns with our expectations for large, less frequent orders from corporate clients.\n",
    "\n",
    "* Corporate Customers 2: A high total order value but with lower average order values, characteristic of companies making frequent but smaller orders.\n",
    "\n",
    "* Private Customers: Interestingly, the histogram for private customers suggests at least two possible clusters, indicating varied spending behavior within this group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb2d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the correlation matrix for all customer datasets\n",
    "plt.figure(figsize=(18, 6))\n",
    "\n",
    "# First plot: Corporate Customers 1\n",
    "plt.subplot(1, 3, 1)\n",
    "corr_corporate1 = df_corporate1.drop(columns=['CustomerID','num_transactions','total_order_value']).corr()\n",
    "sns.heatmap(corr_corporate1, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix - Corporate Customers 1')\n",
    "\n",
    "# Second plot: Corporate Customers 2\n",
    "plt.subplot(1, 3, 2)\n",
    "corr_corporate2 = df_corporate2.drop(columns=['CustomerID','num_transactions','total_order_value']).corr()\n",
    "sns.heatmap(corr_corporate2, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix - Corporate Customers 2')\n",
    "\n",
    "# Third plot: Private Customers\n",
    "plt.subplot(1, 3, 3)\n",
    "corr_private = df_private.drop(columns=['CustomerID','num_transactions','total_order_value']).corr()\n",
    "sns.heatmap(corr_private, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix - Private Customers')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba766a3",
   "metadata": {},
   "source": [
    "After calculating the correlation matrix for each segment, we gained additional insights into the behavior of different customer groups.\n",
    "\n",
    "1. Corporate Customers 1\n",
    "\n",
    "    * Avg Order Value vs. Days Between Transactions (0.87): Customers who order less frequently tend to have higher average order values.\n",
    "\n",
    "    * Avg Order Value vs. Repeat Share (-0.65): Customers with a higher average order value tend to have a lower share of repeated orders.\n",
    "    \n",
    "    * Avg Order Value vs. Dog Share (0.20): There is a slight positive correlation suggesting that higher-spending corporate customers might also order more dog-related products.\n",
    "\n",
    "2. Corporate Customers 2\n",
    "\n",
    "    * All correlations are very weak, ranging between -0.034 and 0.035. This indicates that the behavior of these high-frequency, lower-average-order customers is relatively uniform and not strongly influenced by other factors.\n",
    "\n",
    "3. Private Customers\n",
    "\n",
    "    * Avg Order Value vs. Days Between Transactions (-0.69): Higher-spending customers tend to place orders more frequently, suggesting a division into high-spending frequent buyers and low-spending infrequent buyers.\n",
    "\n",
    "    * Avg Order Value vs. Repeat Share (0.86): Strong positive correlation, indicating that frequent buyers also have a higher proportion of repeated orders.\n",
    "    \n",
    "    * Avg Order Value vs. Dog Share (-0.40): Interestingly, higher-spending private customers purchase fewer dog-related products, unlike the corporate segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a77615ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_customers_3d(df):\n",
    "    \"\"\"\n",
    "    Visualize corporate customers in a 3D scatter plot using average order value,\n",
    "    days between transactions, and dog share, with points colored by repeat share.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing corporate customer data.\n",
    "    \n",
    "    Returns:\n",
    "    None: Displays a 3D scatter plot.\n",
    "    \"\"\"\n",
    "    # Create a 3D scatter plot\n",
    "    fig = px.scatter_3d(df, \n",
    "                        x='avg_order_value', \n",
    "                        y='days_between_trans', \n",
    "                        z='dog_share', \n",
    "                        color='repeat_share',\n",
    "                        title='Corporate Customers - 3D Scatter Plot')\n",
    "\n",
    "    # Set the size of the figure\n",
    "    fig.update_layout(width=1600, height=800)\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6eb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_customers_3d(df_corporate1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3282e57",
   "metadata": {},
   "source": [
    "We visualized corporate customer 1 in a 3D scatterplot, using the following axes: avg_order_value, days_between_trans, and dog_share, with color representing the repeat_share. The plot revealed:\n",
    "\n",
    "* A wide range of dog_share values, from 3% to 50%, for customers with lower average order values and more frequent orders.\n",
    "\n",
    "* Less frequent but higher-spending corporate customers showed more variability in their dog_share, with no distinct separation. One high-spending corporate customer had a dog share of 62%, while another had only 8%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb199e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_customers_3d(df_corporate2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fec0809",
   "metadata": {},
   "source": [
    "For the second corporate segment:\n",
    "\n",
    "* The plot reaffirmed their high repeat_share values and low days_between_trans, with only two outliers in terms of avg_order_value. These outliers could be looked at in closer inspection later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78246e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_customers_3d(df_private)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916b2604",
   "metadata": {},
   "source": [
    "* In this plot, we discovered some anomalous data points where days_between_trans exceeded 364 days. Given that the dataset covers a one-year period, these entries are likely errors and should be corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494e2130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the private customers that have a days_between_trans value of higher than 364 (the maximum)\n",
    "df_private_hd = df_private[df_private['days_between_trans'] > 364]\n",
    "\n",
    "plot_customers_3d(df_private_hd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5a1164",
   "metadata": {},
   "source": [
    "* After visualizing the data points with more than 364 days between transactions, we found that, except for their anomalous days between transactions, the rest of their data appeared reasonable. As such, we will correct these errors by setting their days_between_trans to a more realistic value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef601fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_customers_3d(df_private[df_private['days_between_trans'] <= 364])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d117115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_customers_by_days_between(df, thresholds):\n",
    "    \"\"\"\n",
    "    Print the number of customers with 'days_between_trans' exceeding specified thresholds.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing customer data.\n",
    "    thresholds (list of int): List of thresholds for 'days_between_trans'.\n",
    "\n",
    "    Returns:\n",
    "    None: Prints the counts for each threshold.\n",
    "    \"\"\"\n",
    "    for threshold in thresholds:\n",
    "        count = len(df[df['days_between_trans'] > threshold])\n",
    "        print(f\"Number of customers that have more than {threshold} days between transactions: {count}\")\n",
    "\n",
    "# Example usage\n",
    "thresholds = [364, 240, 236, 235, 234, 233, 1000]\n",
    "count_customers_by_days_between(df_private, thresholds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a52643",
   "metadata": {},
   "source": [
    "* We further visualized the days_between_trans for customers below 364 days and identified additional outliers. By analyzing the distribution of these values, we determined that a boundary of 235 days is appropriate. All values exceeding 235 days will be set to 235, providing a more consistent dataset for future analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8512b623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the number of days between transactions to 235 for the private customers that have more than 235 days\n",
    "df_private.loc[df_private['days_between_trans'] > 235, 'days_between_trans'] = 235\n",
    "\n",
    "plot_customers_3d(df_private)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d890ca",
   "metadata": {},
   "source": [
    "* After correcting the data, we visualized the private customer data once again. This final visualization offers valuable insights into the distribution of private customers, clearly indicating different clusters of spending behavior. These clusters will be the focus of further analysis in the next section.\n",
    "\n",
    "For now, we will save the segmented datasets—Corporate Customers 1, Corporate Customers 2, and Private Customers—into CSV files for future use and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "339d48c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframes to csv files\n",
    "df_corporate1.to_csv('corporate_customers1.csv', index=False)\n",
    "df_corporate2.to_csv('corporate_customers2.csv', index=False)\n",
    "df_private.to_csv('private_customers.csv', index=False)\n",
    "df.to_csv('cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad09f47",
   "metadata": {},
   "source": [
    "# Clustering and Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69af5111",
   "metadata": {},
   "source": [
    "What Has Been Done So Far:\n",
    "\n",
    "* Data Preparation and Feature Engineering: We created new features such as avg_order_value to better understand customer purchasing behavior.\n",
    "\n",
    "* Identification of Corporate Customers: Using statistical methods like the Interquartile Range (IQR), we segmented the dataset into Corporate Customers 1, Corporate Customers 2, and Private Customers.\n",
    "\n",
    "* Data Visualization and Correction: Through boxplots, histograms, and 3D scatter plots, we visualized the data, identified anomalies, and corrected data errors to ensure accuracy.\n",
    "\n",
    "What We Aim to Do Next:\n",
    "\n",
    "* Finalize Clusters for Corporate and Private Customers: Use clustering techniques to identify distinct groups within each customer segment.\n",
    "\n",
    "* Define Customer Characteristics: Analyze each cluster to understand their purchasing patterns and key characteristics.\n",
    "\n",
    "* Develop Targeted Marketing Strategies: Based on the clusters, devise customized marketing approaches to effectively engage each customer group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "707ef3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all dataframes again (can be used as a new starting point for the code - except the libraries at the beginning)\n",
    "df_corporate1 = pd.read_csv('corporate_customers1.csv')\n",
    "df_corporate2 = pd.read_csv('corporate_customers2.csv')\n",
    "df_private = pd.read_csv('private_customers.csv')\n",
    "df = pd.read_csv('cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8765b3d6",
   "metadata": {},
   "source": [
    "## Corporate Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b6eba7",
   "metadata": {},
   "source": [
    "### Corporate Customers 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55d696f",
   "metadata": {},
   "source": [
    "* Even though this customer segment is already quite small, it makes sense to break it down further due to its importance in terms of the level of expenditure over the time horizon under consideration, particularly because we have seen very broad behavior with no clear pattern in its distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d86c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a 3d scatter plot function\n",
    "def scatter_plot3d(df, columns):\n",
    "    # Visualize the corporate customers\n",
    "    fig = px.scatter_3d(df, x=columns[0], y=columns[1], z=columns[2], color=columns[3])\n",
    "\n",
    "    # Set the size of the figure\n",
    "    fig.update_layout(width=1600, height=800)\n",
    "\n",
    "    fig.update_layout(title='Corporate Customers - 3D Scatter Plot')\n",
    "    fig.show()\n",
    "\n",
    "scatter_plot3d(df_corporate1, ['avg_order_value', 'days_between_trans', 'dog_share', 'repeat_share'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3aa20ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot3d(df_corporate1, ['total_order_value', 'days_between_trans', 'dog_share', 'repeat_share'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7484b32d",
   "metadata": {},
   "source": [
    "* These visualizations revealed potential clusters within the dataset. To further explore these clusters, we apply the K-means clustering algorithm using the features mentioned above, experimenting with two and four clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e2e297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering(df, columns_to_use, columns_to_drop, n_clusters):\n",
    "    \"\"\"\n",
    "    Perform KMeans clustering on selected columns of a DataFrame and visualize the clusters in a 3D scatter plot.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The DataFrame containing the data to be clustered.\n",
    "    columns_to_use (list of str): List of column names to be used for clustering and visualization (x, y, z axes).\n",
    "    columns_to_drop (list of str): List of column names to be dropped before clustering (e.g., identifiers and irrelevant columns).\n",
    "    n_clusters (int): The number of clusters to form with KMeans.\n",
    "\n",
    "    Returns:\n",
    "    None: Displays a 3D scatter plot of the clusters.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validate inputs\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise ValueError(\"Input df must be a pandas DataFrame.\")\n",
    "    \n",
    "    if not all(col in df.columns for col in columns_to_use):\n",
    "        raise ValueError(\"Some columns_to_use are not present in the DataFrame.\")\n",
    "    \n",
    "    if not all(col in df.columns for col in columns_to_drop):\n",
    "        raise ValueError(\"Some columns_to_drop are not present in the DataFrame.\")\n",
    "    \n",
    "    if not isinstance(n_clusters, int) or n_clusters <= 0:\n",
    "        raise ValueError(\"n_clusters must be a positive integer.\")\n",
    "\n",
    "    # Create a copy of the DataFrame to avoid modifying the original data\n",
    "    df_cluster = df.copy()\n",
    "\n",
    "    # Drop specified columns\n",
    "    df_cluster = df_cluster.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "    # Validate columns_to_use after dropping irrelevant columns\n",
    "    if not all(col in df_cluster.columns for col in columns_to_use):\n",
    "        raise ValueError(\"Not all columns_to_use are present in the DataFrame after dropping irrelevant columns.\")\n",
    "\n",
    "    # Standardize the data\n",
    "    scaler = StandardScaler()\n",
    "    df_cluster_scaled = scaler.fit_transform(df_cluster[columns_to_use])\n",
    "\n",
    "    # Create and fit the KMeans model\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    df['cluster'] = kmeans.fit_predict(df_cluster_scaled)\n",
    "\n",
    "    # Create a 3D scatter plot to visualize the clusters\n",
    "    fig = px.scatter_3d(\n",
    "        df,\n",
    "        x=columns_to_use[0],\n",
    "        y=columns_to_use[1],\n",
    "        z=columns_to_use[2],\n",
    "        color='cluster',\n",
    "        title='3D Scatter Plot with KMeans Clusters'\n",
    "    )\n",
    "    fig.update_layout(width=1600, height=800)\n",
    "    fig.show()\n",
    "\n",
    "# Example usage\n",
    "kmeans_clustering(\n",
    "    df_corporate1, \n",
    "    ['avg_order_value', 'days_between_trans', 'dog_share'],  # Columns for visualization (x, y, z axes)\n",
    "    ['CustomerID', 'total_order_value', 'num_transactions'],  # Columns to drop (irrelevant for clustering)\n",
    "    2  # Number of clusters\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749b6fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with the corporate customers dataframe, the columns and the number of clusters\n",
    "kmeans_clustering(\n",
    "    df_corporate1, ['total_order_value', 'days_between_trans', 'dog_share'], \n",
    "    ['CustomerID', 'avg_order_value', 'num_transactions'], \n",
    "    2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5993b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use k-means clustering to cluster the corporate customers into four groups\n",
    "kmeans_clustering(\n",
    "    df_corporate1, ['avg_order_value', 'days_between_trans', 'dog_share'], \n",
    "    ['CustomerID', 'total_order_value', 'num_transactions'], \n",
    "    4\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e1870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the same but with total_order_value instead of avg_order_value\n",
    "kmeans_clustering(\n",
    "    df_corporate1, ['total_order_value', 'days_between_trans', 'dog_share'], \n",
    "    ['CustomerID', 'avg_order_value', 'num_transactions'],\n",
    "    4\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6301d0e",
   "metadata": {},
   "source": [
    "* While K-means provided initial insights, given the small size of this segment (96 customers), we opted for a more straightforward approach for segmentation. Instead of relying solely on clustering algorithms, we decided to segment customers based on key features that align closely with business objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fbdb15",
   "metadata": {},
   "source": [
    "* We divide Corporate Customers Segment 1 using total_order_value and num_transactions, categorizing each as \"High\" or \"Low\" based on their respective mean values. This method considers both the volume and frequency of purchases, providing a practical framework for marketing strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf9571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the corporate customers dataframe\n",
    "df_corporate_split = df_corporate1.copy()\n",
    "\n",
    "# Calculate the mean for total_order_value and num_transactions\n",
    "mean_total_order_value = df_corporate_split['total_order_value'].mean()\n",
    "mean_num_transactions = df_corporate_split['num_transactions'].mean()\n",
    "\n",
    "# Split based on whether the values are above or below the mean\n",
    "df_corporate_split['total_order_value_split'] = df_corporate_split['total_order_value'].apply(\n",
    "    lambda x: 'low' if x < mean_total_order_value else 'high'\n",
    ")\n",
    "\n",
    "df_corporate_split['num_transactions_split'] = df_corporate_split['num_transactions'].apply(\n",
    "    lambda x: 'low' if x < mean_num_transactions else 'high'\n",
    ")\n",
    "\n",
    "# Combine the two splits into a single group variable for four distinct categories\n",
    "df_corporate_split['group'] = (\n",
    "    df_corporate_split['total_order_value_split'].astype(str) + '_' +\n",
    "    df_corporate_split['num_transactions_split'].astype(str)\n",
    ")\n",
    "\n",
    "# Visualize the 2x2 grid in a 3D scatter plot with four different colors\n",
    "fig = px.scatter_3d(\n",
    "    df_corporate_split,\n",
    "    x='total_order_value',\n",
    "    y='days_between_trans',\n",
    "    z='dog_share',\n",
    "    color='group',  # Use the combined group variable for color\n",
    "    symbol='group',  # Optionally, use different symbols for clarity\n",
    "    labels={\n",
    "        'total_order_value': 'Total Order Value',\n",
    "        'days_between_trans': 'Days Between Transactions',\n",
    "        'dog_share': 'Dog Share',\n",
    "        'group': 'Group'\n",
    "    }\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=1600,\n",
    "    height=800,\n",
    "    title='Corporate Customers - 3D Scatter Plot with 2x2 Grid (Split by Mean)',\n",
    "    legend_title_text='Group (Total Order Value vs Num Transactions)'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Set the found clusters as df_corporate['cluster']\n",
    "df_corporate1['cluster'] = df_corporate_split['group']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b370990",
   "metadata": {},
   "source": [
    "### Model Valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc3ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot with color based on 'cluster'\n",
    "scatter_plot = alt.Chart(df_corporate1).mark_circle(size=60).encode(\n",
    "    x=alt.X('avg_order_value', title='Average Order Value'),\n",
    "    y=alt.Y('days_between_trans', title='Days Between Transactions'),\n",
    "    color=alt.Color('cluster:N', scale=alt.Scale(scheme='category10'), title='Customer Segment'),\n",
    "    tooltip=['CustomerID', 'avg_order_value', 'days_between_trans', 'repeat_share']\n",
    ").properties(\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    title=\"Customer Segments by Order Value and Days Between Transactions\"\n",
    ").interactive()\n",
    "\n",
    "scatter_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613d98d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corporate1['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1177a836",
   "metadata": {},
   "source": [
    "## 2x2 Matrix: Customer Segmentation Based on Total Order Value and Number of Transactions\n",
    "\n",
    "|                          | **Low Number of Transactions** <br> (Customers below Average Transactions Number) | **High Number of Transactions** <br> (Customers above Average Transactions Number) |\n",
    "|--------------------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------|\n",
    "| **Low Total Order Value** <br> (Customers below Average Order Value) | **Budget-Conscious Occasional Customers** <br> These customers make infrequent purchases and spend a low total amount. They may be cost-sensitive or not heavily engaged. | **Budget-Conscious Frequent Customers** <br> These customers make frequent purchases but still maintain a relatively low total order value, indicating smaller transaction sizes. |\n",
    "| **High Total Order Value** <br> (Customers above Average Order Value) | **High-Spending Occasional Customers** <br> These customers do not transact often, but when they do, they tend to spend a significant amount. They might be selective but valuable. | **High-Spending Frequent Customers** <br> These are highly valuable customers who make frequent purchases with high total order value, indicating strong engagement and consistent spending. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69826efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters in a boxplot for each feature\n",
    "def boxplot_clusters(df):\n",
    "    # Create a boxplot for each feature in the corporate customers dataframe, but split by the cluster\n",
    "    plt.figure(figsize=(18, 12))\n",
    "\n",
    "    # Iterate over the columns\n",
    "    for i, col in enumerate(df.columns[1:-1]):\n",
    "        plt.subplot(3, 3, i + 1)\n",
    "        sns.boxplot(x='cluster', y=col, data=df)\n",
    "        plt.title(col)\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with the corporate customers dataframe\n",
    "boxplot_clusters(df_corporate1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac911e0",
   "metadata": {},
   "source": [
    "### Marketing Strategy Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4dfaba",
   "metadata": {},
   "source": [
    "* Budget-Conscious Occasional Clients:\n",
    "    * Objective: Increase engagement and order frequency.\n",
    "    * Strategy: Offer incentives such as discounts on repeat purchases or loyalty programs to encourage more frequent ordering.\n",
    "\n",
    "* Budget-Conscious Frequent Clients:\n",
    "    * Objective: Upsell and increase average order value.\n",
    "    * Strategy: Promote bundled products or premium offerings to encourage larger purchases.\n",
    "\n",
    "* High-Spending Occasional Clients:\n",
    "    * Objective: Increase purchase frequency.\n",
    "    * Strategy: Provide personalized communication highlighting new products and exclusive deals to entice more regular engagement.\n",
    "\n",
    "* High-Spending Frequent Clients:\n",
    "    * Objective: Retain and reward loyalty.\n",
    "    * Strategy: Offer VIP programs, early access to new products, and personalized services to strengthen the relationship.\n",
    "\n",
    "Note: While dog_share did not show a clear pattern within these segments, it may still be beneficial to customize marketing content based on this feature by categorizing it into intervals (e.g., low, medium, high) and tailoring product recommendations accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9bd73888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the cluster strings into integers\n",
    "df_corporate1['cluster'] = df_corporate1['cluster'].apply(lambda x: 0 if x == 'low_low' else 1 if x == 'low_high' else 2 if x == 'high_low' else 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b985164",
   "metadata": {},
   "source": [
    "## Corporate Customers 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf1202",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot3d(df_corporate2, ['avg_order_value', 'days_between_trans', 'dog_share', 'repeat_share'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2fca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot3d(df_corporate2, ['total_order_value', 'days_between_trans', 'dog_share', 'repeat_share'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f60050f",
   "metadata": {},
   "source": [
    "We created 3D scatter plots for Corporate Customers 2 using the same features as before.\n",
    "\n",
    "Observations:\n",
    "\n",
    "* The dataset is highly homogeneous.\n",
    "\n",
    "* Three customers stand out with significantly higher total_order_value (> €15,000).\n",
    "\n",
    "* Wide range in dog_share values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17d18d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corporate2[df_corporate2['total_order_value']>15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cebd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save them in a dataframe of individual handled customers\n",
    "df_individual = df_corporate2[df_corporate2['total_order_value']>15000]\n",
    "\n",
    "# Drop them from the corporate customers 2\n",
    "df_corporate2 = df_corporate2[df_corporate2['total_order_value']<=15000]\n",
    "# Reindex the dataframe\n",
    "df_corporate2 = df_corporate2.reset_index(drop=True)\n",
    "\n",
    "# Visualize the corporate customers again with the 3d scatter plot\n",
    "scatter_plot3d(df_corporate2[df_corporate2['total_order_value']<=15000], ['avg_order_value', 'days_between_trans', 'dog_share', 'repeat_share'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a19ff15",
   "metadata": {},
   "source": [
    "* Isolating High-Value Customers: The three outliers were saved as individual clients for specialized attention (still they will be in the cluster as well)\n",
    "\n",
    "* The remaining customers show close similarity in avg_order_value, total_order_value, and days_between_trans.\n",
    "\n",
    "* The main differentiators are dog_share and repeat_share."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with the corporate customers dataframe, the columns and the number of clusters\n",
    "kmeans_clustering(df_corporate2, ['avg_order_value', 'days_between_trans', 'dog_share'], ['CustomerID', 'total_order_value', 'num_transactions'], 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0961d0c1",
   "metadata": {},
   "source": [
    "* We attempted K-Means clustering with different numbers of clusters.\n",
    "\n",
    "* No clear patterns emerged that would facilitate an effective marketing strategy.\n",
    "\n",
    "* Instead, we focused on segmenting based on dog_share and repeat_share, splitting the data manually using the mean values of these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cb3ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the corporate customers dataframe\n",
    "df_corporate_split = df_corporate2.copy()\n",
    "\n",
    "# Calculate the mean for total_order_value and num_transactions\n",
    "mean_total_order_value = df_corporate_split['dog_share'].mean()\n",
    "mean_num_transactions = df_corporate_split['repeat_share'].mean()\n",
    "\n",
    "# Split based on whether the values are above or below the mean\n",
    "df_corporate_split['dog_share_split'] = df_corporate_split['dog_share'].apply(\n",
    "    lambda x: 'low' if x < mean_total_order_value else 'high'\n",
    ")\n",
    "\n",
    "df_corporate_split['repeat_share_split'] = df_corporate_split['repeat_share'].apply(\n",
    "    lambda x: 'low' if x < mean_num_transactions else 'high'\n",
    ")\n",
    "\n",
    "# Combine the two splits into a single group variable for four distinct categories\n",
    "df_corporate_split['group'] = (\n",
    "    df_corporate_split['dog_share_split'].astype(str) + '_' +\n",
    "    df_corporate_split['repeat_share_split'].astype(str)\n",
    ")\n",
    "\n",
    "# Visualize the 2x2 grid in a 3D scatter plot with four different colors\n",
    "fig = px.scatter_3d(\n",
    "    df_corporate_split,\n",
    "    x='total_order_value',\n",
    "    y='num_transactions',\n",
    "    z='dog_share',\n",
    "    color='group',  # Use the combined group variable for color\n",
    "    symbol='group',  # Optionally, use different symbols for clarity\n",
    "    labels={\n",
    "        'total_order_value': 'Total Order Value',\n",
    "        'num_transactions': 'Num Transactions',\n",
    "        'dog_share': 'Dog Share',\n",
    "        'group': 'Group'\n",
    "    }\n",
    ")\n",
    "fig.update_layout(\n",
    "    width=1600,\n",
    "    height=800,\n",
    "    title='Corporate Customers - 3D Scatter Plot with 2x2 Grid (Split by Mean)',\n",
    "    legend_title_text='Group (Total Order Value vs Num Transactions)'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# Set the found clusters as df_corporate['cluster']\n",
    "df_corporate2['cluster'] = df_corporate_split['group']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce8334b",
   "metadata": {},
   "source": [
    "Segments:\n",
    "\n",
    "* Low Repeat Share & Low Dog Share (Low_Low)\n",
    "\n",
    "* Low Repeat Share & High Dog Share (Low_High)\n",
    "\n",
    "* High Repeat Share & Low Dog Share (High_Low)\n",
    "\n",
    "* High Repeat Share & High Dog Share (High_High)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcbacd1",
   "metadata": {},
   "source": [
    "### Model Valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425535bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse the found clusters\n",
    "df_corporate2['cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5bc9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters in a boxplot\n",
    "boxplot_clusters(df_corporate2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b262642",
   "metadata": {},
   "source": [
    "The boxplots confirmed that:\n",
    "\n",
    "* avg_order_value, total_order_value, days_between_trans, and num_transactions are similar across clusters.\n",
    "\n",
    "* The primary differences lie in repeat_share and dog_share."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8d5e0",
   "metadata": {},
   "source": [
    "## 2x2 Matrix: Customer Segmentation Based on Dog Share and Repeat Share\n",
    "\n",
    "|                                                  | **Low Dog Share**<br>(Below Average)                                     | **High Dog Share**<br>(Above Average)                                     |\n",
    "|--------------------------------------------------|-------------------------------------------------------------------------|---------------------------------------------------------------------------|\n",
    "| **Low Repeat Share**<br>(Below Average)          | **Variety-Seeking Customers**<br>Purchase a diverse range of products with fewer repeats and less focus on dog-related items. | **Dog Product Explorers**<br>Low repeat purchases but higher interest in dog-related products. Opportunity to promote new dog products. |\n",
    "| **High Repeat Share**<br>(Above Average)         | **Loyal Customers**<br>Frequently reorder the same products, not heavily focused on dog-related items. | **Dog Product Loyalists**<br>High repeat purchases and strong preference for dog-related products. Highly engaged in this category. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a553541",
   "metadata": {},
   "source": [
    "### Marketing Strategy Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0286b758",
   "metadata": {},
   "source": [
    "* Variety-Seeking Customers:\n",
    "    * Approach: Introduce loyalty programs to encourage repeat purchases. Highlight new and diverse product offerings.\n",
    "    * Content: Personalized recommendations based on past diverse purchases.\n",
    "\n",
    "* Dog Product Explorers:\n",
    "    * Approach: Promote new dog-related products and exclusive deals. Encourage trial of other product categories.\n",
    "    * Content: Tailored promotions on dog products, cross-selling opportunities.\n",
    "\n",
    "* Loyal Customers:\n",
    "    * Approach: Reward loyalty with special offers. Introduce them to complementary products to enhance their usual purchases.\n",
    "    * Content: Exclusive discounts on frequently purchased items, bundled offers.\n",
    "\n",
    "* Dog Product Loyalists:\n",
    "    * Approach: Offer premium dog-related products and services. Engage them with community events or content related to dog care.\n",
    "    * Content: Early access to new dog products, invitations to dog-related events, informative content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "db8e93da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the cluster names into integer values\n",
    "df_corporate2['cluster'] = df_corporate2['cluster'].apply(lambda x: 4 if x == 'low_low' else 5 if x == 'low_high' else 6 if x == 'high_low' else 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d0a67f",
   "metadata": {},
   "source": [
    "## Private Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5d237b",
   "metadata": {},
   "source": [
    "* To begin analyzing the private customers, we first plot two 3D scatter plots to gain a visual understanding of the dataset. These plots help us identify patterns and potential clusters within the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073b4bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot3d(df_private, ['avg_order_value', 'days_between_trans', 'dog_share', 'repeat_share'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433bd50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter_plot3d(df_private, ['total_order_value', 'days_between_trans', 'dog_share', 'repeat_share'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d883ad54",
   "metadata": {},
   "source": [
    "* Compared to the corporate customer segments, the private customer data appears more dispersed, making it less straightforward to segment. While we can visually detect the possibility of two or three clusters, this approach lacks precision.\n",
    "\n",
    "* To refine our understanding, we will employ the elbow method to determine the optimal number of clusters. After that, we will use the k-means algorithm to effectively cluster the customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dffd79c",
   "metadata": {},
   "source": [
    "The Elbow Method\n",
    "\n",
    "* The elbow method is a commonly used technique in cluster analysis to identify the optimal number of clusters in a dataset. \n",
    "\n",
    "* It works by running the k-means algorithm for a range of cluster numbers (k) and plotting the total within-cluster sum of squares (inertia) against the number of clusters. \n",
    "\n",
    "* The goal is to find the point where the inertia starts to decrease more slowly, forming an \"elbow\" shape in the graph. \n",
    "\n",
    "* This point typically indicates the optimal number of clusters, where adding more clusters does not significantly improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5530f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elbow_method(df, max_clusters=10):\n",
    "    \"\"\"\n",
    "    Runs the elbow method to determine the optimal number of clusters.\n",
    "    Args:\n",
    "        df: Input DataFrame with relevant features.\n",
    "        max_clusters: The maximum number of clusters to test.\n",
    "    Returns:\n",
    "        A plot showing the inertia values for each k.\n",
    "    \"\"\"\n",
    "    # Standardize the data to ensure each feature contributes equally\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "    inertia_values = []\n",
    "\n",
    "    # Iterate over possible cluster sizes (k) to calculate inertia for each\n",
    "    for k in range(1, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        kmeans.fit(df_scaled)\n",
    "        inertia_values.append(kmeans.inertia_)\n",
    "\n",
    "    # Plotting the inertia values to visualize the \"elbow\"\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(range(1, max_clusters + 1), inertia_values, marker='o', linestyle='-', color='b')\n",
    "    plt.xlabel('Number of Clusters (k)')\n",
    "    plt.ylabel('Inertia')\n",
    "    plt.title('Elbow Method: Optimal Number of Clusters')\n",
    "    plt.show()\n",
    "\n",
    "# Run the elbow method for the corporate customers\n",
    "elbow_method(df_private.drop(columns=['CustomerID', 'total_order_value', 'num_transactions']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7fbf74",
   "metadata": {},
   "source": [
    "* By using the elbow method, we can confidently proceed with k-means clustering, using 3 clusters as the most appropriate choice based on the data's distribution and the elbow graph results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5406289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans first\n",
    "kmeans_clustering(df_private, ['avg_order_value', 'days_between_trans', 'dog_share'], ['CustomerID', 'total_order_value', 'num_transactions'], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65898d5e",
   "metadata": {},
   "source": [
    "### Model Valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfec0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8aeb053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters in a boxplot\n",
    "boxplot_clusters(df_private)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41fc9ad",
   "metadata": {},
   "source": [
    "With corporate customers, we have always been able to use our own established logic to divide customers into different segments. This was not so easy with private customers. We will therefore use two common scores to further validate our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc4cc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copy of df_private without the custoemrID column\n",
    "df_private_cluster = df_private.drop(columns=['CustomerID', 'total_order_value', 'num_transactions'])\n",
    "\n",
    "# Calculate the silhouette score for the KMeans model\n",
    "silhouette_score(df_private_cluster, df_private_cluster['cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220d4ae7",
   "metadata": {},
   "source": [
    "Silhouette Score (0.61): \n",
    "\n",
    "* The silhouette score ranges from -1 to 1, with higher values indicating better-defined clusters. \n",
    "\n",
    "* A score of 0.61 suggests that the clusters are reasonably well-defined and separated, with most data points being close to the center of their assigned clusters. \n",
    "\n",
    "* This indicates that the clustering algorithm has effectively grouped customers based on similar behavioral patterns such as frequency of transactions, order value, and product preferences\n",
    "\n",
    "* While not perfect, this score implies that the segmentation is strong enough to identify meaningful patterns for targeted marketing strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adc1bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Davies Bouldin score for the KMeans model\n",
    "davies_bouldin_score(df_private_cluster, df_private_cluster['cluster'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee0e59e",
   "metadata": {},
   "source": [
    "Davies-Bouldin Score (0.54): \n",
    "\n",
    "* The Davies-Bouldin score measures the average similarity between clusters, with lower values indicating better clustering. \n",
    "\n",
    "* A score of 0.54 suggests that the clusters are relatively distinct, with minimal overlap. \n",
    "\n",
    "* This means that the differences between customer groups (such as high vs. low spenders or frequent vs. infrequent buyers) are clearly defined, allowing for more precise targeting in marketing efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831309aa",
   "metadata": {},
   "source": [
    "### Marketing Strategy Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51214ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_private filtered for cluster 0\n",
    "df_private[df_private['cluster'] == 0].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c50effb",
   "metadata": {},
   "source": [
    "Segment 0: Frequent High-Spending Customers (57.844 customers)\n",
    "\n",
    "* Transaction Frequency: Moderate, with an average of 14 transactions (max 24)\n",
    "\n",
    "* Total Order Value: Highest among all segments, with an average of €340 (standard deviation of 80)\n",
    "\n",
    "* Days Between Transactions: Lowest, averaging 36 days (mostly between 31 and 36 days)\n",
    "\n",
    "* Repeat Share: Highest, at 39%\n",
    "\n",
    "* Dog Share: Low, averaging 20%\n",
    "\n",
    "* Average Order Value: Highest, at €24 per order\n",
    "\n",
    "Marketing Strategy: This group is the most valuable segment, making frequent, high-value purchases. Their high repeat share suggests strong loyalty to certain products. A targeted strategy for this segment could focus on:\n",
    "\n",
    "* Exclusive Loyalty Programs: Offering personalized loyalty rewards to encourage repeat purchasing.\n",
    "\n",
    "* Upselling and Cross-selling: Suggest complementary products based on their high spending behavior.\n",
    "\n",
    "* Early Access to New Products: These customers are engaged and likely to appreciate early access or exclusive products.\n",
    "\n",
    "* Subscription Services: Given their frequent orders, offer them a convenient subscription model with recurring delivery options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c325cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_private filtered for cluster 1\n",
    "df_private[df_private['cluster'] == 1].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8f134c",
   "metadata": {},
   "source": [
    "Segment 1: Infrequent Dog-Centric Customers (10,326 customers)\n",
    "\n",
    "* Transaction Frequency: Low, with an average of only 4 transactions\n",
    "\n",
    "* Total Order Value: Lowest, at an average of €11\n",
    "\n",
    "* Days Between Transactions: Highest, averaging 230 days\n",
    "\n",
    "* Repeat Share: Lowest, at 10%\n",
    "\n",
    "* Dog Share: By far the highest, at 59%\n",
    "\n",
    "* Average Order Value: Lowest, at €11\n",
    "\n",
    "Marketing Strategy: These customers primarily buy dog-related products and do so infrequently. Their low repeat share and high dog share suggest they come for specific needs and then disengage. The marketing strategy here should focus on:\n",
    "\n",
    "* Targeted Promotions on Dog Products: Offer discounts and special offers on dog-related items to drive engagement and repeat purchases.\n",
    "\n",
    "* Educational Content: Provide personalized, informative content such as newsletters or blog posts about dog care, nutrition, or seasonal product recommendations.\n",
    "\n",
    "* Re-engagement Campaigns: Since they have a long gap between transactions, automated re-engagement emails with time-sensitive offers could help bring them back sooner.\n",
    "\n",
    "* Bundle Offers: Encourage them to purchase more items per transaction by offering bundle deals focused on dog care essentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f1ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_private filtered for cluster 2\n",
    "df_private[df_private['cluster'] == 2].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a5119a",
   "metadata": {},
   "source": [
    "Segment 2: Occasional Moderate-Spending Customers (29,348 customers)\n",
    "\n",
    "* Transaction Frequency: Medium, averaging 10 transactions (but some outliers up to 4000)\n",
    "\n",
    "* Total Order Value: Moderate, averaging €70 (standard deviation of 54)\n",
    "\n",
    "* Days Between Transactions: Medium, at an average of 102 days\n",
    "\n",
    "* Repeat Share: Medium, at 21%\n",
    "\n",
    "* Dog Share: Low, averaging 21%\n",
    "\n",
    "* Average Order Value: Moderate, at €15 per order\n",
    "\n",
    "Marketing Strategy: This segment represents a more balanced customer group that orders occasionally but shows moderate spending and engagement. To increase their frequency or spending:\n",
    "\n",
    "* Seasonal Campaigns: Offer seasonal promotions or limited-time deals to spur additional purchases throughout the year.\n",
    "\n",
    "* Loyalty Incentives: Introduce tiered loyalty programs to gradually increase engagement and reward customers based on purchase frequency or order value.\n",
    "\n",
    "* Personalized Recommendations: Leverage purchase data to provide personalized product recommendations that align with their past behavior.\n",
    "\n",
    "* Targeted Emails: Sending customized emails with product suggestions based on past transactions and browsing habits may increase engagement and total order value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9ac7b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the cluster values 0, 1, 2 to the values 8, 9, 10\n",
    "df_private['cluster'] = df_private['cluster'].apply(lambda x: 8 if x == 0 else 9 if x == 1 else 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d68fe12",
   "metadata": {},
   "source": [
    "Each customer segment presents unique behaviors and opportunities for targeted marketing. Frequent High-Spending Customers are loyal and valuable, requiring a focus on personalization and exclusivity. Infrequent Dog-Centric Customers should be re-engaged with targeted promotions and educational content on dog-related products, while Occasional Moderate-Spending Customers benefit from a balanced approach combining personalized offers, loyalty rewards, and seasonal campaigns.\n",
    "\n",
    "By tailoring the marketing strategies to these distinct segments, the company can optimize customer engagement, drive repeat business, and maximize revenue potential across the board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9332a94f",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63da1eb4",
   "metadata": {},
   "source": [
    "## Corporate Customers 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab715e74",
   "metadata": {},
   "source": [
    "### 2x2 Matrix: Customer Segmentation Based on Total Order Value and Number of Transactions\n",
    "\n",
    "|                          | **Low Number of Transactions** <br> (Customers below Average Transactions Number) | **High Number of Transactions** <br> (Customers above Average Transactions Number) |\n",
    "|--------------------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------|\n",
    "| **Low Total Order Value** <br> (Customers below Average Order Value) | **Budget-Conscious Occasional Customers** <br> These customers make infrequent purchases and spend a low total amount. They may be cost-sensitive or not heavily engaged. | **Budget-Conscious Frequent Customers** <br> These customers make frequent purchases but still maintain a relatively low total order value, indicating smaller transaction sizes. |\n",
    "| **High Total Order Value** <br> (Customers above Average Order Value) | **High-Spending Occasional Customers** <br> These customers do not transact often, but when they do, they tend to spend a significant amount. They might be selective but valuable. | **High-Spending Frequent Customers** <br> These are highly valuable customers who make frequent purchases with high total order value, indicating strong engagement and consistent spending. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1740dc72",
   "metadata": {},
   "source": [
    "### Key Marketing Strategies:\n",
    "\n",
    "* Budget-Conscious Occasional Customers: Incentivize repeat purchases through discounts and loyalty programs.\n",
    "\n",
    "* Budget-Conscious Frequent Customers: Upsell premium or bundled products to increase basket size.\n",
    "\n",
    "* High-Spending Occasional Customers: Personalized offers for exclusive products and services to increase purchase frequency.\n",
    "\n",
    "* High-Spending Frequent Customers: VIP treatment, early access to products, and personalized communication to retain loyalty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2cb141",
   "metadata": {},
   "source": [
    "## Corporate Customers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96d764c",
   "metadata": {},
   "source": [
    "### 2x2 Matrix: Customer Segmentation Based on Dog Share and Repeat Share\n",
    "\n",
    "|                                                  | **Low Dog Share**<br>(Below Average)                                     | **High Dog Share**<br>(Above Average)                                     |\n",
    "|--------------------------------------------------|-------------------------------------------------------------------------|---------------------------------------------------------------------------|\n",
    "| **Low Repeat Share**<br>(Below Average)          | **Variety-Seeking Customers**<br>Purchase a diverse range of products with fewer repeats and less focus on dog-related items. | **Dog Product Explorers**<br>Low repeat purchases but higher interest in dog-related products. Opportunity to promote new dog products. |\n",
    "| **High Repeat Share**<br>(Above Average)         | **Loyal Customers**<br>Frequently reorder the same products, not heavily focused on dog-related items. | **Dog Product Loyalists**<br>High repeat purchases and strong preference for dog-related products. Highly engaged in this category. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6b429b",
   "metadata": {},
   "source": [
    "### Key Marketing Strategies:\n",
    "\n",
    "* Variety-Seeking Customers: Highlight new and diverse product offerings, introduce loyalty programs.\n",
    "\n",
    "* Dog Product Explorers: Promote new dog-related products, encourage cross-category purchases.\n",
    "\n",
    "* Loyal Customers: Reward loyalty with special offers, cross-sell complementary products.\n",
    "\n",
    "* Dog Product Loyalists: Offer premium dog products and services, create engagement through exclusive dog-related content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a382bad",
   "metadata": {},
   "source": [
    "## Private Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d9e934",
   "metadata": {},
   "source": [
    "### Key Marketing Strategies:\n",
    "\n",
    "Frequent High-Spending Customers:\n",
    "\n",
    "* Exclusive loyalty programs to drive further engagement.\n",
    "\n",
    "* Upselling and cross-selling opportunities to maximize value.\n",
    "\n",
    "* Early access to new products to reward loyalty.\n",
    "\n",
    "* Subscription services to maintain consistent transactions.\n",
    "\n",
    "\n",
    "Infrequent Dog-Centric Customers:\n",
    "\n",
    "* Targeted promotions and discounts on dog-related products.\n",
    "\n",
    "* Educational content on dog care to build trust and engagement.\n",
    "\n",
    "* Re-engagement campaigns to reduce long transaction gaps.\n",
    "\n",
    "* Bundle offers for dog-related products to increase transaction size.\n",
    "\n",
    "\n",
    "Occasional Moderate-Spending Customers\n",
    "*  Seasonal campaigns to drive purchases during key times.\n",
    "\n",
    "* Loyalty programs to boost engagement and encourage repeat buying.\n",
    "\n",
    "* Personalized recommendations to drive higher average order values.\n",
    "\n",
    "* Targeted emails to increase relevance and customer interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c15adef",
   "metadata": {},
   "source": [
    "# Recommendations and Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc86d7a",
   "metadata": {},
   "source": [
    "Based on the insights gathered from the customer segmentation analysis, the following strategic recommendations and future initiatives are proposed to enhance customer engagement, optimize marketing efforts, and drive business growth.\n",
    "\n",
    "1. Implement an Automated Customer Segmentation Model\n",
    "\n",
    "    * Leverage the customer segments identified in this analysis to build an automated model that dynamically manages and targets different customer groups. This will enable the business to:\n",
    "\n",
    "        * Personalize marketing strategies according to the unique needs and behaviors of each segment.\n",
    "\n",
    "        * Streamline communications, promotions, and product recommendations for high-value and high-potential customer groups.\n",
    "\n",
    "        * Continuously update customer classifications as new data comes in, ensuring that the company can respond proactively to changing customer behaviors.\n",
    "\n",
    "2. Incorporate Additional Data for a Refined Analysis\n",
    "\n",
    "    * RFM Analysis: Use detailed order data, including purchase dates, to implement a Recency, Frequency, and Monetary (RFM) model. This model will allow for:\n",
    "        \n",
    "        * A deeper understanding of customer purchasing habits over time.\n",
    "        \n",
    "        * Identifying customers who are likely to engage with offers based on how recently and frequently they have made purchases.\n",
    "\n",
    "    * Customer Lifetime Value (CLV) Modeling: For businesses with historical data spanning at least 2-3 years, implementing a CLV model can provide critical insights into:\n",
    "        \n",
    "        * Which customer segments are likely to deliver the highest long-term value.\n",
    "        \n",
    "        * Which customers should be prioritized for loyalty programs, personalized offers, and retention strategies.\n",
    "        \n",
    "        * Tools such as the PyMC-Marketing library can be employed to develop a probabilistic CLV model that factors in future revenue potential, helping to optimize investment in customer retention and acquisition.\n",
    "\n",
    "3. Develop a Personalized Product Recommendation System\n",
    "\n",
    "    * Utilize customer transaction history to build a recommendation engine that suggests products based on individual purchasing behavior. This model could:\n",
    "        \n",
    "        * Predict customer preferences, improving upselling and cross-selling efforts by offering highly relevant product suggestions.\n",
    "        \n",
    "        * Increase average order value and customer satisfaction by offering tailored product bundles or promotions.\n",
    "        \n",
    "        * Improve customer retention by providing timely recommendations for repeat purchases based on prior buying patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0587ea1f",
   "metadata": {},
   "source": [
    "# Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99860fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all cluster labels are unique\n",
    "print(df_corporate1['cluster'].unique())\n",
    "print(df_corporate2['cluster'].unique())\n",
    "print(df_private['cluster'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ff5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now combine all three dataframes by only using the CustomerID and the cluster column\n",
    "df_final = pd.concat([df_corporate1[['CustomerID', 'cluster']], df_corporate2[['CustomerID', 'cluster']], df_private[['CustomerID', 'cluster']]])\n",
    "df_final = df_final.reset_index(drop=True)\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cb50a1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the clustered data to a CSV file\n",
    "df_final.to_csv('Clustered_Data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fcbd7240ee8f908d933dc7f71e8c42a1a91163b70ede8dcff5146d4087436c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
