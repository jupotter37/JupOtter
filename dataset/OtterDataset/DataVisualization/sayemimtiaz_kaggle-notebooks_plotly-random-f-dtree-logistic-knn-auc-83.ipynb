{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#'''Importing Data Manipulation Modules'''\nimport numpy as np                 # Linear Algebra\nimport pandas as pd                # Data Processing, CSV file I/O (e.g. pd.read_csv)\n\n#'''Seaborn and Matplotlib Visualization'''\nimport matplotlib                  # 2D Plotting Library\nimport matplotlib.pyplot as plt\nimport seaborn as sns              # Python Data Visualization Library based on matplotlib\nplt.style.use('fivethirtyeight')\n%matplotlib inline\n\n#'''Plotly Visualizations'''\nimport plotly as plotly                # Interactive Graphing Library for Python\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly.offline as py\ninit_notebook_mode(connected=True)\nimport os\n%pylab inline\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/health-insurance-cross-sell-prediction/train.csv\")\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop('id', axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"response_0 = df[df['Response'] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"response_1 = df[df['Response'] == 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Response Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = sorted(df.Response.unique())\nvalues = df.Response.value_counts().sort_index()\ncolors = ['DarkGrey', 'HotPink']\n\n\nfig = go.Figure(data=[go.Pie(labels=labels,\n                             values=values, pull=[0, 0.06])])\nfig.update_traces(hoverinfo='label+percent', textinfo='value',textfont_size=20,\n                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n\nfig.update_layout(title_text=\"Distribution of Response\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Gender Analysis "},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = sorted(df.Gender.unique())\nvalues = df.Gender.value_counts().sort_index()\ncolors = ['Aqua', 'Peru']\n\n\nfig = go.Figure(data=[go.Pie(labels=labels,\n                             values=values)])\nfig.update_traces(hoverinfo='label+percent', textinfo='value',textfont_size=20,\n                  marker=dict(colors=colors, line=dict(color='#000000', width=2)))\n\nfig.update_layout(title_text=\"Distribution of Gender\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Histogram(\n    x=response_0.Gender,\n    opacity=0.85,\n    name = \"No response\",\n    marker=dict(color='DarkGrey',line=dict(color='#000000', width=2)))\ntrace2 = go.Histogram(\n    x=response_1.Gender,\n    opacity=0.85,\n    name = \"Response\",\n    marker=dict(color='Crimson',line=dict(color='#000000', width=2)))\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   title='Gender - Response',\n                   xaxis=dict(title='Gender'),\n                   yaxis=dict( title='Count'),\n                   paper_bgcolor='beige',\n                   plot_bgcolor='beige'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> Males are more likely to response"},{"metadata":{},"cell_type":"markdown","source":"## Age Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Min age: ', df['Age'].max())\nprint('Max age: ', df['Age'].min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nfig.set_size_inches(20, 8)\nsns.countplot(x = 'Age', data = df)\nax.set_xlabel('Age', fontsize=15)\nax.set_ylabel('Count', fontsize=15)\nax.set_title('Age Count Distribution', fontsize=15)\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(nrows = 1, ncols = 2, figsize = (13, 5))\nsns.boxplot(x = 'Age', data = df, orient = 'v', ax = ax1)\nax1.set_xlabel('People Age', fontsize=15)\nax1.set_ylabel('Age', fontsize=15)\nax1.set_title('Age Distribution', fontsize=15)\nax1.tick_params(labelsize=15)\n\nsns.distplot(df['Age'], ax = ax2)\nsns.despine(ax = ax2)\nax2.set_xlabel('Age', fontsize=15)\nax2.set_ylabel('Occurence', fontsize=15)\nax2.set_title('Age x Ocucurence', fontsize=15)\nax2.tick_params(labelsize=15)\n\nplt.subplots_adjust(wspace=0.5)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('1ยบ Quartile: ', df['Age'].quantile(q = 0.25))\nprint('2ยบ Quartile: ', df['Age'].quantile(q = 0.50))\nprint('3ยบ Quartile: ', df['Age'].quantile(q = 0.75))\nprint('4ยบ Quartile: ', df['Age'].quantile(q = 1.00))\n#Calculate the outliers:\n  # Interquartile range, IQR = Q3 - Q1\n  # lower 1.5*IQR whisker = Q1 - 1.5 * IQR \n  # Upper 1.5*IQR whisker = Q3 + 1.5 * IQR\n    \nprint('Ages above: ', df['Age'].quantile(q = 0.75) + \n                      1.5*(df['Age'].quantile(q = 0.75) - df['Age'].quantile(q = 0.25)), 'are outliers')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Numerber of outliers: ', df[df['Age'] >= 85.0]['Age'].count())\nprint('Number of clients: ', len(df))\n#Outliers in %\nprint('Outliers are:', round(df[df['Age'] >= 85.0]['Age'].count()*100/len(df),10), '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('MEAN:', round(df['Age'].mean(), 1))\n\nprint('STD :', round(df['Age'].std(), 1))\n\n#coefficient variation: (STD/MEAN)*100\n#    cv < 15%, low dispersion\n#    cv > 30%, high dispersion\n\nprint('CV  :',round(df['Age'].std()*100/df['Age'].mean(), 1), ', High dispersion')\n\n#High dispersion means we have people with all ages and all of them are likely subscrib the service.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Histogram(\n    x=response_0.Age,\n    opacity=0.85,\n    name = \"No response\",\n    marker=dict(color='DarkGrey',line=dict(color='#000000', width=2)))\ntrace2 = go.Histogram(\n    x=response_1.Age,\n    opacity=0.85,\n    name = \"Response\",\n    marker=dict(color='Crimson',line=dict(color='#000000', width=2)))\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   title='Age - Response',\n                   xaxis=dict(title='Age'),\n                   yaxis=dict( title='Count'),\n                   paper_bgcolor='beige',\n                   plot_bgcolor='beige'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> From the graph beyond, we could easily see the age between 35 and 55, they are more likely to response"},{"metadata":{},"cell_type":"markdown","source":"## Driving License Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Histogram(\n    x=response_0.Driving_License,\n    opacity=0.85,\n    name = \"No response\",\n    marker=dict(color='DarkGrey',line=dict(color='#000000', width=2)))\ntrace2 = go.Histogram(\n    x=response_1.Driving_License,\n    opacity=0.85,\n    name = \"Response\",\n    marker=dict(color='Crimson',line=dict(color='#000000', width=2)))\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   title='Driving License - Response',\n                   xaxis=dict(title='Driving License'),\n                   yaxis=dict( title='Count'),\n                   paper_bgcolor='beige',\n                   plot_bgcolor='beige'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People who have driving license are more likely to response"},{"metadata":{},"cell_type":"markdown","source":"## Region Code Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Histogram(\n    x=response_0.Region_Code,\n    opacity=0.85,\n    name = \"No response\",\n    marker=dict(color='DarkGrey',line=dict(color='#000000', width=2)))\ntrace2 = go.Histogram(\n    x=response_1.Region_Code,\n    opacity=0.85,\n    name = \"Response\",\n    marker=dict(color='Crimson',line=dict(color='#000000', width=2)))\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   title='Region - Response',\n                   xaxis=dict(title='Region Code'),\n                   yaxis=dict( title='Count'),\n                   paper_bgcolor='beige',\n                   plot_bgcolor='beige'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"More positive response comming from the region 28 and region 8, the other regions are most likely ignore it"},{"metadata":{},"cell_type":"markdown","source":"## Previously Insured Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Histogram(\n    x=response_0.Previously_Insured,\n    opacity=0.85,\n    name = \"No response\",\n    marker=dict(color='DarkGrey',line=dict(color='#000000', width=2)))\ntrace2 = go.Histogram(\n    x=response_1.Previously_Insured,\n    opacity=0.85,\n    name = \"Response\",\n    marker=dict(color='Crimson',line=dict(color='#000000', width=2)))\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   title='Previously Insured - Response',\n                   xaxis=dict(title='Previously Insured'),\n                   yaxis=dict( title='Count'),\n                   paper_bgcolor='beige',\n                   plot_bgcolor='beige'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"People who have not been insured yet are more likely the potentials clients"},{"metadata":{},"cell_type":"markdown","source":"## Vehicle Age"},{"metadata":{"trusted":true},"cell_type":"code","source":"nodamage = df[df['Vehicle_Damage'] == 'No']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"yesdamage = df[df['Vehicle_Damage'] == 'Yes']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Histogram(\n    x=response_0.Vehicle_Age,\n    opacity=0.85,\n    name = \"No response\",\n    marker=dict(color='DarkGrey',line=dict(color='#000000', width=2)))\ntrace2 = go.Histogram(\n    x=response_1.Vehicle_Age,\n    opacity=0.85,\n    name = \"Response\",\n    marker=dict(color='Crimson',line=dict(color='#000000', width=2)))\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   title='Vehicle Age - Response',\n                   xaxis=dict(title='Vehicle Age'),\n                   yaxis=dict( title='Count'),\n                   paper_bgcolor='beige',\n                   plot_bgcolor='beige'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Histogram(\n    x=nodamage.Vehicle_Age,\n    opacity=0.85,\n    name = \"No Damage\",\n    marker=dict(color='LightCyan',line=dict(color='#000000', width=2)))\ntrace2 = go.Histogram(\n    x=yesdamage.Vehicle_Age,\n    opacity=0.85,\n    name = \"Damaged\",\n    marker=dict(color='OrangeRed',line=dict(color='#000000', width=2)))\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   title='Vehicle Damage - Vehicle Age',\n                   xaxis=dict(title='Vehicle Age'),\n                   yaxis=dict( title='Count'),\n                   paper_bgcolor='beige',\n                   plot_bgcolor='beige'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vehicle Age between 1-2 are most likely to have car accidents, and accroding to the graph beyond, we can conclude that  they tend to be more willing to subscribe our services"},{"metadata":{"trusted":true},"cell_type":"code","source":"trace1 = go.Histogram(\n    x=nodamage.Gender,\n    opacity=0.85,\n    name = \"No Damage\",\n    marker=dict(color='LightCyan',line=dict(color='#000000', width=2)))\ntrace2 = go.Histogram(\n    x=yesdamage.Gender,\n    opacity=0.85,\n    name = \"Damaged\",\n    marker=dict(color='DeepPink',line=dict(color='#000000', width=2)))\n\ndata = [trace1, trace2]\nlayout = go.Layout(barmode='stack',\n                   title='Vehicle Damage - Gender',\n                   xaxis=dict(title='Gender'),\n                   yaxis=dict( title='Count'),\n                   paper_bgcolor='beige',\n                   plot_bgcolor='beige'\n)\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Males are more likely to have car accidents than females."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x = 'Vehicle_Age', y = 'Annual_Premium', hue = 'Vehicle_Damage',data = df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Vehicle Age between 0 - 2 has a higher and stable Annual Premium, people tend to be more taking care of their cars, wherears when Age > 2, customers are more focosed on lower price services where can enoughly cover the basic requirments."},{"metadata":{},"cell_type":"markdown","source":"## To conclude: Males at the age between 35~55 who live in region 28 & 8, have not purchased inssurance for their 1-2 year(s) old car yet that had accidents before would be MORE interested in purchasing inssurance."},{"metadata":{},"cell_type":"markdown","source":"# Group Segmentation & Categorical Treatment"},{"metadata":{},"cell_type":"markdown","source":"## Gender Segmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to group gender into 0,1\ndef gender(dataframe):\n    dataframe.loc[dataframe['Gender'] == 'Male', 'Gender'] = 0\n    dataframe.loc[dataframe['Gender'] == 'Female', 'Gender'] = 1\n    \n    return dataframe\n\ngender(df);\n\ndf['Gender'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Age Segmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to devide Age into 4 groups.\ndef age(dataframe):\n    dataframe.loc[dataframe['Age'] <= 33, 'Age'] = 1\n    dataframe.loc[(dataframe['Age'] > 33) & (dataframe['Age'] <= 52), 'Age'] = 2\n    dataframe.loc[(dataframe['Age'] > 52) & (dataframe['Age'] <= 66), 'Age'] = 3\n    dataframe.loc[(dataframe['Age'] > 66) & (dataframe['Age'] <= 85), 'Age'] = 4\n           \n    return dataframe\n\nage(df)\n\ndf['Age'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Premium Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"rcParams['figure.figsize'] = 11.7,8.27\nsns.distplot(df['Annual_Premium'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('1ยบ Quartile: ', df['Annual_Premium'].quantile(q = 0.25))\nprint('2ยบ Quartile: ', df['Annual_Premium'].quantile(q = 0.50))\nprint('3ยบ Quartile: ', df['Annual_Premium'].quantile(q = 0.75))\nprint('4ยบ Quartile: ', df['Annual_Premium'].quantile(q = 1.00))\n#Calculate the outliers:\n  # Interquartile range, IQR = Q3 - Q1\n  # lower 1.5*IQR whisker = Q1 - 1.5 * IQR \n  # Upper 1.5*IQR whisker = Q3 + 1.5 * IQR\n    \nprint('Annual Premium above: ', df['Annual_Premium'].quantile(q = 0.75) + \n                      1.5*(df['Annual_Premium'].quantile(q = 0.75) - df['Annual_Premium'].quantile(q = 0.25)), 'are outliers')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Numerber of outliers: ', df[df['Annual_Premium'] >= 61892.5]['Annual_Premium'].count())\nprint('Number of clients: ', len(df))\n#Outliers in %\nprint('Outliers are:', round(df[df['Annual_Premium'] >= 61892.5]['Annual_Premium'].count()*100/len(df),2), '%')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to devide Annual Premium into 4 groups.\ndef Premium(dataframe):\n    dataframe.loc[dataframe['Annual_Premium'] <= 24405.0, 'Annual_Premium'] = 1\n    dataframe.loc[(dataframe['Annual_Premium'] > 24405.0) & (dataframe['Annual_Premium'] <= 39400.0), 'Annual_Premium'] = 2\n    dataframe.loc[(dataframe['Annual_Premium'] > 39400.0) & (dataframe['Annual_Premium'] <= 55000), 'Annual_Premium'] = 3\n    dataframe.loc[(dataframe['Annual_Premium'] > 55000) & (dataframe['Annual_Premium'] <= 540165.0), 'Annual_Premium'] = 4\n           \n    return dataframe\n\nPremium(df)\n\ndf['Annual_Premium'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vintage Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('1ยบ Quartile: ', df['Vintage'].quantile(q = 0.25))\nprint('2ยบ Quartile: ', df['Vintage'].quantile(q = 0.50))\nprint('3ยบ Quartile: ', df['Vintage'].quantile(q = 0.75))\nprint('4ยบ Quartile: ', df['Vintage'].quantile(q = 1.00))\n#Calculate the outliers:\n  # Interquartile range, IQR = Q3 - Q1\n  # lower 1.5*IQR whisker = Q1 - 1.5 * IQR \n  # Upper 1.5*IQR whisker = Q3 + 1.5 * IQR\n    \nprint('Vintage above: ', df['Vintage'].quantile(q = 0.75) + \n                      1.5*(df['Vintage'].quantile(q = 0.75) - df['Vintage'].quantile(q = 0.25)), 'are outliers')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#function to devide Annual Premium into 4 groups.\ndef Vintage(dataframe):\n    dataframe.loc[dataframe['Vintage'] <= 82.0, 'Vintage'] = 1\n    dataframe.loc[(dataframe['Vintage'] > 82.0) & (dataframe['Vintage'] <= 154.0), 'Vintage'] = 2\n    dataframe.loc[(dataframe['Vintage'] > 154.0) & (dataframe['Vintage'] <= 227.0), 'Vintage'] = 3\n    dataframe.loc[(dataframe['Vintage'] > 227.0) & (dataframe['Vintage'] <= 450), 'Vintage'] = 4\n           \n    return dataframe\n\nVintage(df)\n\ndf['Vintage'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Label Encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlabelencoder_X = LabelEncoder()\n\ndf['Vehicle_Age']  = labelencoder_X.fit_transform(df['Vehicle_Age']) \ndf['Vehicle_Damage']  = labelencoder_X.fit_transform(df['Vehicle_Damage']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Gender'] = pd.to_numeric(df['Gender'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Shrink our dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_no_response = df[df['Response'] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_response = df[df['Response'] == 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample\n\ndf_no_response_downsampled = resample(df_no_response,\n                                      replace = False,\n                                      n_samples=2500,\n                                      random_state = 42)\nlen(df_no_response_downsampled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_response_downsampled = resample(df_response,\n                                   replace = False,\n                                   n_samples=2500,\n                                   random_state = 42)\nlen(df_response_downsampled)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's merge these 2 downsampled datasets into a single Dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_downsample = pd.concat([df_no_response_downsampled,df_response_downsampled])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_downsample)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## We are off to go, Features & Target Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df_downsample.drop('Response', axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df_downsample['Response']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(x.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax, cmap='Purples')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score,confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import KFold\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)\naccuracies = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nx_train = sc_X.fit_transform(x_train)\nx_test = sc_X.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFECV\n\n# The \"accuracy\" scoring is proportional to the number of correct classifications\nclf_rf_1 = RandomForestClassifier(random_state = 42) \nrfecv = RFECV(estimator=clf_rf_1, step=1, cv=k_fold,scoring='accuracy')   #10-fold cross-validation\nrfecv = rfecv.fit(x_train, y_train)\n\nprint('Optimal number of features :', rfecv.n_features_)\nprint('Best features :', x.columns[rfecv.support_])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_1 = df_downsample[['Region_Code','Previously_Insured','Vehicle_Damage','Policy_Sales_Channel']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x_1,y, test_size=0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nx_train = sc_X.fit_transform(x_train)\nx_test = sc_X.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rf_2 = RandomForestClassifier(random_state=43)      \nclr_rf_2 = clf_rf_2.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ac = accuracy_score(y_test,clf_rf_2.predict(x_test))\naccuracies['Random_Forest'] = ac\n\nprint('Accuracy is: ',ac, '\\n')\ncm = confusion_matrix(y_test,clf_rf_2.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('RFC Reports\\n',classification_report(y_test, clf_rf_2.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score of number of selected features\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LogisticRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogmodel = LogisticRegression() \nlogmodel.fit(x_train,y_train)\n\nac = accuracy_score(y_test,logmodel.predict(x_test))\naccuracies['Logistic regression'] = ac\n\nprint('Accuracy is: ',ac, '\\n')\ncm = confusion_matrix(y_test,logmodel.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('Logistic regression Reports\\n',classification_report(y_test, logmodel.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#Neighbors\nneighbors = np.arange(0,25)\n\n#Create empty list that will hold cv scores\ncv_scores = []\n\n#Perform 10-fold cross validation on training set for odd values of k:\nfor k in neighbors:\n    k_value = k+1\n    knn = KNeighborsClassifier(n_neighbors = k_value, weights='uniform', p=2, metric='euclidean')\n    kfold = model_selection.KFold(n_splits=10, random_state=123)\n    scores = model_selection.cross_val_score(knn, x_train, y_train, cv=k_fold, scoring='accuracy')\n    cv_scores.append(scores.mean()*100)\n    print(\"k=%d %0.2f (+/- %0.2f)\" % (k_value, scores.mean()*100, scores.std()*100))\n\noptimal_k = neighbors[cv_scores.index(max(cv_scores))]\nprint (\"The optimal number of neighbors is %d with %0.1f%%\" % (optimal_k, cv_scores[optimal_k]))\n\nplt.plot(neighbors, cv_scores)\nplt.xlabel('Number of Neighbors K')\nplt.ylabel('Train Accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=24)\nknn.fit(x_train, y_train)\n\nac = accuracy_score(y_test,knn.predict(x_test))\naccuracies['KNN'] = ac\n\n\nprint('Accuracy is: ',ac, '\\n')\ncm = confusion_matrix(y_test,knn.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('KNN Reports\\n',classification_report(y_test, knn.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier(criterion='gini') #criterion = entopy, gini\ndtree.fit(x_train, y_train)\n\nac = accuracy_score(y_test,dtree.predict(x_test))\naccuracies['decisiontree'] = ac\n\nprint('Accuracy is: ',ac, '\\n')\ncm = confusion_matrix(y_test,dtree.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('DecisionTree Reports\\n',classification_report(y_test, dtree.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvc = SVC()\n\nsvc1= SVC(random_state = 42,kernel = 'rbf')\nsvc1.fit(x_train, y_train)\n\nac = accuracy_score(y_test,svc1.predict(x_test))\naccuracies['SVM'] = ac\n\n\nprint('Accuracy is: ',ac, '\\n')\ncm = confusion_matrix(y_test,svc1.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('SVM report\\n',classification_report(y_test, svc1.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GaussianNB"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngaussiannb= GaussianNB()\ngaussiannb.fit(x_train, y_train)\n\nac = accuracy_score(y_test,gaussiannb.predict(x_test))\naccuracies['GaussianNB'] = ac\n\n\nprint('Accuracy is: ',ac,'\\n')\ncm = confusion_matrix(y_test,gaussiannb.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('GaussianNB report\\n',classification_report(y_test, gaussiannb.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = [\"purple\", \"green\", \"orange\", \"magenta\",\"#CFC60E\",\"#0FBBAE\"]\n\nplt.rcParams['figure.figsize'] = (18,8)\n\nx=list(accuracies.keys())\ny=list(accuracies.values())\n\nbars = plt.bar(x, height=y, width=.4, color = colors)\n\nxlocs, xlabs = plt.xticks()\n\nxlocs=[i for i in x]\nxlabs=[i for i in x]\n\nplt.xlabel('Algorithms', size = 20)\nplt.ylabel('Accuracy %', size = 20)\nplt.xticks(xlocs, xlabs, size = 15)\n\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + .1, yval + .005, yval, size = 15)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig, ax_arr = plt.subplots(nrows = 2, ncols = 3, figsize = (20,15))\nfrom sklearn import metrics\n\n#RandomForest\nprobs = clf_rf_2.predict_proba(x_test)\npreds = probs[:,1]\nfprrfc, tprrfc, thresholdrfc = metrics.roc_curve(y_test, preds)\nroc_aucrfc = metrics.auc(fprrfc, tprrfc)\n\nax_arr[0,0].plot(fprrfc, tprrfc, 'b', label = 'AUC = %0.2f' % roc_aucrfc)\nax_arr[0,0].plot([0, 1], [0, 1],'r--')\nax_arr[0,0].set_title('ROC Random Forest ',fontsize=20)\nax_arr[0,0].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[0,0].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[0,0].legend(loc = 'lower right', prop={'size': 16})\n\n#LOGMODEL\nprobs = logmodel.predict_proba(x_test)\npreds = probs[:,1]\nfprlog, tprlog, thresholdlog = metrics.roc_curve(y_test, preds)\nroc_auclog = metrics.auc(fprlog, tprlog)\n\nax_arr[0,1].plot(fprlog, tprlog, 'b', label = 'AUC = %0.2f' % roc_auclog)\nax_arr[0,1].plot([0, 1], [0, 1],'r--')\nax_arr[0,1].set_title('ROC Logistic ',fontsize=20)\nax_arr[0,1].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[0,1].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[0,1].legend(loc = 'lower right', prop={'size': 16})\n\n#KNN\nprobs = knn.predict_proba(x_test)\npreds = probs[:,1]\nfprknn, tprknn, thresholdknn = metrics.roc_curve(y_test, preds)\nroc_aucknn = metrics.auc(fprknn, tprknn)\n\nax_arr[0,2].plot(fprknn, tprknn, 'b', label = 'AUC = %0.2f' % roc_aucknn)\nax_arr[0,2].plot([0, 1], [0, 1],'r--')\nax_arr[0,2].set_title('ROC KNN ',fontsize=20)\nax_arr[0,2].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[0,2].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[0,2].legend(loc = 'lower right', prop={'size': 16})\n\n#DECISION TREE\nprobs = dtree.predict_proba(x_test)\npreds = probs[:,1]\nfprdtree, tprdtree, thresholddtree = metrics.roc_curve(y_test, preds)\nroc_aucdtree = metrics.auc(fprdtree, tprdtree)\n\nax_arr[1,0].plot(fprdtree, tprdtree, 'b', label = 'AUC = %0.2f' % roc_aucdtree)\nax_arr[1,0].plot([0, 1], [0, 1],'r--')\nax_arr[1,0].set_title('ROC Decision Tree ',fontsize=20)\nax_arr[1,0].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[1,0].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[1,0].legend(loc = 'lower right', prop={'size': 16})\n\n\n#Gaussiannb\n\nprobs = gaussiannb.predict_proba(x_test)\npreds = probs[:,1]\nfprgau, tprgau, thresholdgau = metrics.roc_curve(y_test, preds)\nroc_aucgau = metrics.auc(fprgau, tprgau)\n\nax_arr[1,1].plot(fprgau, tprgau, 'b', label = 'AUC = %0.2f' % roc_aucgau)\nax_arr[1,1].plot([0, 1], [0, 1],'r--')\nax_arr[1,1].set_title('ROC Gaussian ',fontsize=20)\nax_arr[1,1].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[1,1].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[1,1].legend(loc = 'lower right', prop={'size': 16})\n\n#All plots\nax_arr[1,2].plot(fprrfc, tprrfc, 'b', label = 'rfc', color='black')\nax_arr[1,2].plot(fprlog, tprlog, 'b', label = 'Logistic', color='blue')\nax_arr[1,2].plot(fprknn, tprknn, 'b', label = 'Knn', color='brown')\nax_arr[1,2].plot(fprdtree, tprdtree, 'b', label = 'Decision Tree', color='green')\nax_arr[1,2].plot(fprgau, tprgau, 'b', label = 'Gaussiannb', color='grey')\nax_arr[1,2].set_title('Receiver Operating Comparison ',fontsize=20)\nax_arr[1,2].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[1,2].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[1,2].legend(loc = 'lower right', prop={'size': 16})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Our Final Model would be ใRandom Forestใ with Accuracy 79%, AUC: 0.83"},{"metadata":{},"cell_type":"markdown","source":"# Thanks for watching! please upvote Cheers!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}