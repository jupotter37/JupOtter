{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shirarozenthal/Documents/CS/Git/optiver-realized-volatility-prediction\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/shirarozenthal/Documents/CS/Git/optiver-realized-volatility-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import time\n",
    "import glob\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler, minmax_scale\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# Parallel processing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Set matplotlib to display inline and pandas option\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data\n",
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "# Load test data\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "# Initialize stock_id\n",
    "stock_id = 0\n",
    "\n",
    "# Load book data\n",
    "book_example = pd.read_parquet('book_train.parquet/stock_id=0')\n",
    "\n",
    "# Load trade data\n",
    "trade_example = pd.read_parquet('trade_train.parquet/stock_id=0')\n",
    "\n",
    "# Reassign book_example to only include stock_id 0\n",
    "book_example = book_example[book_example['time_id']==5]\n",
    "\n",
    "# Create stock_id column in book_example\n",
    "book_example.loc[:,'stock_id'] = stock_id\n",
    "\n",
    "# Reassign trade_example to only include stock_id 0\n",
    "trade_example = trade_example[trade_example['time_id']==5]\n",
    "\n",
    "# Create stock_id column in trade_example\n",
    "trade_example.loc[:,'stock_id'] = stock_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a WAP feature for example book df\n",
    "# WAP = (bid_price1 * ask_size1 + ask_price1 * bid_size1) / (bid_size1 + ask_size1)\n",
    "book_example['wap'] = (book_example['bid_price1'] * book_example['ask_size1'] +\n",
    "                                book_example['ask_price1'] * book_example['bid_size1']) / (\n",
    "                                       book_example['bid_size1']+ book_example['ask_size1'])\n",
    "\n",
    "# Define function for computing log returns\n",
    "# Log return = log(current price / previous price)\n",
    "def log_return(list_stock_prices):\n",
    "    return np.log(list_stock_prices).diff()\n",
    "\n",
    "# Generate a log return column for book_example df\n",
    "# Takes the log return of the current row and previous row\n",
    "# Row zero omitted because it cannot be compared to a previous time entry using ~ operator\n",
    "book_example.loc[:,'log_return'] = log_return(book_example['wap'])\n",
    "book_example = book_example[~book_example['log_return'].isnull()]\n",
    "\n",
    "# Define a function to compute realized volatility using the log returns in a time bucket\n",
    "# Computed by taking the square root of the sum of squared log returns\n",
    "# # Realized volatility = sqrt(sum(log returns^2))\n",
    "def realized_volatility(series_log_return):\n",
    "    return np.sqrt(np.sum(series_log_return**2))\n",
    "\n",
    "realized_vol = realized_volatility(book_example['log_return'])\n",
    "\n",
    "# Create a list of all file paths within book training parquet file\n",
    "list_order_book_file_train = glob.glob('book_train.parquet/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for computing the realitized volatiltiy for each time bucket for a specific stock\n",
    "def realized_volatility_per_time_id(file_path, prediction_column_name):\n",
    "    # Load the parquet file for a specific stock into a DataFrame\n",
    "    df_book_data = pd.read_parquet(file_path)\n",
    "\n",
    "    # Compute the Weighted Average Price (WAP) using bid and ask prices and sizes\n",
    "    df_book_data['wap'] =(df_book_data['bid_price1'] * df_book_data['ask_size1']+df_book_data['ask_price1'] * df_book_data['bid_size1'])  / (\n",
    "                                      df_book_data['bid_size1']+ df_book_data['ask_size1'])\n",
    "\n",
    "    # Calculate the log returns of WAP for each 'time_id'\n",
    "    df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
    "\n",
    "    # Remove rows with NaN values in the 'log_return' column\n",
    "    df_book_data = df_book_data[~df_book_data['log_return'].isnull()]\n",
    "\n",
    "    # Compute the realized volatility for each 'time_id' based on the log returns\n",
    "    df_realized_vol_per_stock =  pd.DataFrame(df_book_data.groupby(['time_id'])['log_return'].agg(realized_volatility)).reset_index()\n",
    "\n",
    "    # Rename the 'log_return' column to the provided prediction_column_name\n",
    "    df_realized_vol_per_stock = df_realized_vol_per_stock.rename(columns = {'log_return':prediction_column_name})\n",
    "\n",
    "    # Extract the stock_id from the file_path\n",
    "    stock_id = file_path.split('=')[1]\n",
    "\n",
    "    # Create a 'row_id' column combining the stock_id and time_id\n",
    "    df_realized_vol_per_stock['row_id'] = df_realized_vol_per_stock['time_id'].apply(lambda x:f'{stock_id}-{x}')\n",
    "\n",
    "    return df_realized_vol_per_stock[['row_id',prediction_column_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n",
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/2202599754.py:11: FutureWarning: Not prepending group keys to the result index of transform-like apply. In the future, the group keys will be included in the index, regardless of whether the applied function returns a like-indexed object.\n",
      "To preserve the previous behavior, use\n",
      "\n",
      "\t>>> .groupby(..., group_keys=False)\n",
      "\n",
      "To adopt the future behavior and silence this warning, use \n",
      "\n",
      "\t>>> .groupby(..., group_keys=True)\n",
      "  df_book_data['log_return'] = df_book_data.groupby(['time_id'])['wap'].apply(log_return)\n"
     ]
    }
   ],
   "source": [
    "def past_realized_volatility_per_stock(list_file,prediction_column_name):\n",
    "    # Initialize an empty DataFrame to store the results for all stocks\n",
    "    df_past_realized = pd.DataFrame()\n",
    "\n",
    "    # Loop through each file in the provided list (each file corresponds to a stock's data)\n",
    "    for file in list_file:\n",
    "        # Compute the realized volatility for the current stock using the function 'realized_volatility_per_time_id'\n",
    "        # This function returns the realized volatility for each 'time_id' of the current stock\n",
    "        df_single_stock_realized_vol = realized_volatility_per_time_id(file, prediction_column_name)\n",
    "\n",
    "        # Concatenate the results for the current stock with the aggregated results\n",
    "        df_past_realized = pd.concat([df_past_realized, df_single_stock_realized_vol])\n",
    "\n",
    "    # Return the aggregated results for all stocks\n",
    "    return df_past_realized\n",
    "\n",
    "# Calculate the realized volatility for all stocks in the training data\n",
    "# The list 'list_order_book_file_train' contains file paths for all stocks in the training set\n",
    "df_past_realized_train = past_realized_volatility_per_stock(list_file=list_order_book_file_train, prediction_column_name='pvol')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column 'row_id' in the 'train' dataframe. This column is a combination of the 'stock_id' and 'time_id' columns.\n",
    "# The two values are separated by a '-' and both are converted to string type to facilitate concatenation.\n",
    "train_mod = pd.read_csv('train.csv')\n",
    "\n",
    "train_mod['row_id'] = train['stock_id'].astype(str) + '-' + train_mod['time_id'].astype(str)\n",
    "\n",
    "# Update the 'train' dataframe to keep only the 'row_id' and 'target' columns.\n",
    "train_mod = train_mod[['row_id','target']]\n",
    "\n",
    "# Merge the 'train' dataframe with the 'df_past_realized_train' dataframe.\n",
    "# The merging is based on the 'row_id' column, which is common between the two dataframes.\n",
    "# This is a left merge, which means all the rows from the 'train' dataframe will be retained and corresponding\n",
    "# values from 'df_past_realized_train' will be added wherever there's a match based on 'row_id'.\n",
    "# If there's no match for a particular 'row_id' in 'df_past_realized_train', NaN values will be filled for 'pred' column.\n",
    "df_joined = train_mod.merge(df_past_realized_train[['row_id','pvol']], on = ['row_id'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse-Engineering TimeID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def timer(name):\n",
    "    s = time.time()\n",
    "    yield\n",
    "    e = time.time() - s\n",
    "    print(f\"[{name}] {e:.3f}sec\")\n",
    "\n",
    "\n",
    "def calc_price2(df):\n",
    "    tick = sorted(np.diff(sorted(np.unique(df.values.flatten()))))[0]\n",
    "    return 0.01 / tick\n",
    "\n",
    "def calc_prices(r):\n",
    "    df = pd.read_parquet(r.book_path, columns=['time_id', 'ask_price1', 'ask_price2', 'bid_price1', 'bid_price2'])\n",
    "    df = df.set_index('time_id')\n",
    "    df = df.groupby(level='time_id').apply(calc_price2).to_frame('price').reset_index()\n",
    "    df['stock_id'] = r.stock_id\n",
    "    return df\n",
    "\n",
    "def sort_manifold(df, clf):\n",
    "    df_ = df.set_index('time_id')\n",
    "    df_ = pd.DataFrame(minmax_scale(df_.fillna(df_.mean())))\n",
    "\n",
    "    X_compoents = clf.fit_transform(df_)\n",
    "\n",
    "    dft = df.reindex(np.argsort(X_compoents[:,0])).reset_index(drop=True)\n",
    "    return np.argsort(X_compoents[:, 0]), X_compoents\n",
    "\n",
    "def reconstruct_time_id_order():\n",
    "    with timer('load files'):\n",
    "        df_files = pd.DataFrame(\n",
    "            {'book_path': glob.glob('book_train.parquet/**/*.parquet')}) \\\n",
    "            .eval('stock_id = book_path.str.extract(\"stock_id=(\\d+)\").astype(\"int\")', engine='python')\n",
    "\n",
    "    with timer('calc prices'):\n",
    "        df_prices = pd.concat(Parallel(n_jobs=4, verbose=51)(delayed(calc_prices)(r) for _, r in df_files.iterrows()))\n",
    "        df_prices = df_prices.pivot('time_id', 'stock_id', 'price')\n",
    "        df_prices.columns = [f'stock_id={i}' for i in df_prices.columns]\n",
    "        df_prices = df_prices.reset_index(drop=False)\n",
    "\n",
    "    with timer('t-SNE(400) -> 50'):\n",
    "        clf = TSNE(n_components=1, perplexity=400, random_state=0, n_iter=2000)\n",
    "        order, X_compoents = sort_manifold(df_prices, clf)\n",
    "\n",
    "        clf = TSNE(n_components=1, perplexity=50, random_state=0, init=X_compoents, n_iter=2000, method='exact')\n",
    "        order, X_compoents = sort_manifold(df_prices, clf)\n",
    "\n",
    "        df_ordered = df_prices.reindex(order).reset_index(drop=True)\n",
    "        if df_ordered['stock_id=61'].iloc[0] > df_ordered['stock_id=61'].iloc[-1]:\n",
    "            df_ordered = df_ordered.reindex(df_ordered.index[::-1]).reset_index(drop=True)\n",
    "\n",
    "    # AMZN\n",
    "    plt.plot(df_ordered['stock_id=61'])\n",
    "\n",
    "    return df_ordered[['time_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load files] 0.017sec\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   1 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=4)]: Done   2 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done   3 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=4)]: Done   4 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=4)]: Done   5 tasks      | elapsed:    2.6s\n",
      "[Parallel(n_jobs=4)]: Done   6 tasks      | elapsed:    2.8s\n",
      "[Parallel(n_jobs=4)]: Done   7 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=4)]: Done   8 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=4)]: Done   9 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=4)]: Done  11 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=4)]: Done  12 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=4)]: Done  13 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=4)]: Done  14 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done  15 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=4)]: Done  16 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=4)]: Done  17 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=4)]: Done  18 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=4)]: Done  19 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=4)]: Done  20 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=4)]: Done  21 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=4)]: Done  22 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=4)]: Done  23 tasks      | elapsed:    6.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirarozenthal/Documents/CS/Git/CMPS-4020-Capstone/Cap/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  24 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=4)]: Done  25 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=4)]: Done  26 tasks      | elapsed:    6.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirarozenthal/Documents/CS/Git/CMPS-4020-Capstone/Cap/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  27 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=4)]: Done  28 tasks      | elapsed:    7.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirarozenthal/Documents/CS/Git/CMPS-4020-Capstone/Cap/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  29 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=4)]: Done  30 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=4)]: Done  31 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=4)]: Done  32 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=4)]: Done  33 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=4)]: Done  34 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=4)]: Done  35 tasks      | elapsed:    9.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirarozenthal/Documents/CS/Git/CMPS-4020-Capstone/Cap/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  36 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=4)]: Done  37 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=4)]: Done  38 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=4)]: Done  39 tasks      | elapsed:   10.4s\n",
      "[Parallel(n_jobs=4)]: Done  40 tasks      | elapsed:   10.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirarozenthal/Documents/CS/Git/CMPS-4020-Capstone/Cap/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  41 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=4)]: Done  43 tasks      | elapsed:   11.3s\n",
      "[Parallel(n_jobs=4)]: Done  44 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=4)]: Done  45 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=4)]: Done  46 tasks      | elapsed:   11.9s\n",
      "[Parallel(n_jobs=4)]: Done  47 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=4)]: Done  48 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=4)]: Done  49 tasks      | elapsed:   12.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirarozenthal/Documents/CS/Git/CMPS-4020-Capstone/Cap/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  50 tasks      | elapsed:   13.3s\n",
      "[Parallel(n_jobs=4)]: Done  51 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=4)]: Done  52 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=4)]: Done  53 tasks      | elapsed:   14.2s\n",
      "[Parallel(n_jobs=4)]: Done  54 tasks      | elapsed:   14.4s\n",
      "[Parallel(n_jobs=4)]: Done  55 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=4)]: Done  56 tasks      | elapsed:   14.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirarozenthal/Documents/CS/Git/CMPS-4020-Capstone/Cap/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  57 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=4)]: Done  58 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=4)]: Done  59 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=4)]: Done  60 tasks      | elapsed:   16.0s\n",
      "[Parallel(n_jobs=4)]: Done  61 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=4)]: Done  62 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=4)]: Done  63 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:   17.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirarozenthal/Documents/CS/Git/CMPS-4020-Capstone/Cap/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  65 tasks      | elapsed:   17.3s\n",
      "[Parallel(n_jobs=4)]: Done  66 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=4)]: Done  67 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=4)]: Done  68 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=4)]: Done  69 tasks      | elapsed:   18.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirarozenthal/Documents/CS/Git/CMPS-4020-Capstone/Cap/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  70 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=4)]: Done  71 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=4)]: Done  72 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=4)]: Done  73 tasks      | elapsed:   19.4s\n",
      "[Parallel(n_jobs=4)]: Done  74 tasks      | elapsed:   19.9s\n",
      "[Parallel(n_jobs=4)]: Done  75 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:   20.5s\n",
      "[Parallel(n_jobs=4)]: Done  77 tasks      | elapsed:   20.6s\n",
      "[Parallel(n_jobs=4)]: Done  78 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=4)]: Done  79 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=4)]: Done  80 tasks      | elapsed:   21.2s\n",
      "[Parallel(n_jobs=4)]: Done  81 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=4)]: Done  82 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=4)]: Done  83 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=4)]: Done  84 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=4)]: Done  85 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=4)]: Done  86 tasks      | elapsed:   22.4s\n",
      "[Parallel(n_jobs=4)]: Done  87 tasks      | elapsed:   22.7s\n",
      "[Parallel(n_jobs=4)]: Done  88 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=4)]: Done  89 tasks      | elapsed:   23.2s\n",
      "[Parallel(n_jobs=4)]: Done  90 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=4)]: Done  91 tasks      | elapsed:   23.7s\n",
      "[Parallel(n_jobs=4)]: Done  92 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=4)]: Done  93 tasks      | elapsed:   24.1s\n",
      "[Parallel(n_jobs=4)]: Done  94 tasks      | elapsed:   24.3s\n",
      "[Parallel(n_jobs=4)]: Done  95 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=4)]: Done  96 tasks      | elapsed:   24.7s\n",
      "[Parallel(n_jobs=4)]: Done  97 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=4)]: Done  98 tasks      | elapsed:   25.1s\n",
      "[Parallel(n_jobs=4)]: Done  99 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=4)]: Done 100 tasks      | elapsed:   25.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirarozenthal/Documents/CS/Git/CMPS-4020-Capstone/Cap/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 101 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=4)]: Done 102 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=4)]: Done 103 tasks      | elapsed:   26.1s\n",
      "[Parallel(n_jobs=4)]: Done 104 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=4)]: Done 105 tasks      | elapsed:   26.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirarozenthal/Documents/CS/Git/CMPS-4020-Capstone/Cap/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 108 out of 112 | elapsed:   27.6s remaining:    1.0s\n",
      "[Parallel(n_jobs=4)]: Done 112 out of 112 | elapsed:   28.7s finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vt/9fdy65x9687b115fpdn7jlpw0000gn/T/ipykernel_21719/3112154199.py:37: FutureWarning: In a future version of pandas all arguments of DataFrame.pivot will be keyword-only.\n",
      "  df_prices = df_prices.pivot('time_id', 'stock_id', 'price')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[calc prices] 28.928sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shirarozenthal/Documents/CS/Git/CMPS-4020-Capstone/Cap/lib/python3.9/site-packages/threadpoolctl.py:1195: RuntimeWarning: libc not found. The ctypes module in Python 3.9 is maybe too old for this OS.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE(400) -> 50] 495.710sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ordered = reconstruct_time_id_order()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattening Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all file paths within book training parquet file\n",
    "list_order_book_file_train = glob.glob('book_train.parquet/*')\n",
    "\n",
    "# Create a list of all file paths within trade training parquet file\n",
    "list_order_trade_file_train = glob.glob('trade_train.parquet/*')\n",
    "\n",
    "#\n",
    "master = df_joined\n",
    "\n",
    "#\n",
    "master = master.rename(columns={'pvol': 'realized_vol'})\n",
    "\n",
    "# Set the 'order' column of df_ordered to be its index values\n",
    "df_ordered['order'] = df_ordered.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'train' DataFrame with 'df_ordered' based on the 'time_id' column\n",
    "# This is a left join, which means all rows from 'train' will be kept,\n",
    "# along with matched rows from 'df_ordered'\n",
    "merged_df = pd.merge(train, df_ordered, on='time_id', how='left')\n",
    "\n",
    "# Sort the merged DataFrame first by 'stock_id' and then by 'order'\n",
    "merged_df.sort_values(by=['stock_id', 'order'], inplace=True)\n",
    "\n",
    "# Create a new 'row_id' column by concatenating 'stock_id' and 'time_id' as strings\n",
    "merged_df['row_id'] = merged_df['stock_id'].astype(str) + '-' + merged_df['time_id'].astype(str)\n",
    "\n",
    "# Reorder columns so that 'row_id' is the first column, and retain all other columns\n",
    "cols = ['row_id'] + [col for col in merged_df.columns if col != 'row_id']\n",
    "df_merged = merged_df[cols]\n",
    "\n",
    "# Drop 'stock_id' and 'time_id' columns from the DataFrame\n",
    "df_merged = df_merged.drop(['stock_id', 'time_id'], axis=1)\n",
    "\n",
    "# Swap the positions of the second and third columns in the DataFrame\n",
    "cols = df_merged.columns.tolist()\n",
    "cols[1], cols[2] = cols[2], cols[1]\n",
    "df_merged = df_merged[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge 'master' DataFrame with 'df_merged' on 'row_id', using a right join\n",
    "# This keeps all rows from 'df_merged' and the matched rows from 'master'\n",
    "master = master.merge(df_merged, on='row_id', how='right')\n",
    "\n",
    "# Rename the column 'target_x' to 'target' in the 'master' DataFrame\n",
    "master = master.rename(columns={'target_x': 'target'})\n",
    "\n",
    "# Drop the column 'target_y' from the 'master' DataFrame\n",
    "master = master.drop(['target_y'], axis=1)\n",
    "\n",
    "# Select and reorder specific columns in the 'master' DataFrame\n",
    "master = master[['row_id', 'order', 'target', 'realized_vol']]\n",
    "\n",
    "# Extract the stock identifier from 'row_id' and create a new column 'stock'\n",
    "master['stock'] = master['row_id'].str.split('-').str[0]\n",
    "\n",
    "# Finalize the DataFrame by selecting specific columns\n",
    "master = master[['stock', 'row_id', 'order', 'target', 'realized_vol']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>row_id</th>\n",
       "      <th>order</th>\n",
       "      <th>target</th>\n",
       "      <th>realized_vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0-4294</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>0.007026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0-24033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>0.004136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0-5666</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.002395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0-29740</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.001790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0-22178</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.002601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428927</th>\n",
       "      <td>126</td>\n",
       "      <td>126-24913</td>\n",
       "      <td>3825</td>\n",
       "      <td>0.006360</td>\n",
       "      <td>0.007303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428928</th>\n",
       "      <td>126</td>\n",
       "      <td>126-32195</td>\n",
       "      <td>3826</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>0.006109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428929</th>\n",
       "      <td>126</td>\n",
       "      <td>126-15365</td>\n",
       "      <td>3827</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>0.005740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428930</th>\n",
       "      <td>126</td>\n",
       "      <td>126-10890</td>\n",
       "      <td>3828</td>\n",
       "      <td>0.006899</td>\n",
       "      <td>0.004815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428931</th>\n",
       "      <td>126</td>\n",
       "      <td>126-29316</td>\n",
       "      <td>3829</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.004781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428932 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stock     row_id  order    target  realized_vol\n",
       "0          0     0-4294      0  0.003267      0.007026\n",
       "1          0    0-24033      1  0.002580      0.004136\n",
       "2          0     0-5666      2  0.002051      0.002395\n",
       "3          0    0-29740      3  0.002364      0.001790\n",
       "4          0    0-22178      4  0.001439      0.002601\n",
       "...      ...        ...    ...       ...           ...\n",
       "428927   126  126-24913   3825  0.006360      0.007303\n",
       "428928   126  126-32195   3826  0.005479      0.006109\n",
       "428929   126  126-15365   3827  0.004802      0.005740\n",
       "428930   126  126-10890   3828  0.006899      0.004815\n",
       "428931   126  126-29316   3829  0.003397      0.004781\n",
       "\n",
       "[428932 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_wap(df):\n",
    "    return ((df['bid_price1'] * df['ask_size1']) + (df['ask_price1'] * df['bid_size1'])) / (df['bid_size1'] + df['ask_size1'])\n",
    "\n",
    "def calculate_price_spread(df):\n",
    "    return (df['ask_price1'] - df['bid_price1']) / ((df['ask_price1'] + df['bid_price1']) / 2)\n",
    "\n",
    "def calculate_bid_ask_spread(df, bid_col, ask_col):\n",
    "    return df[ask_col] - df[bid_col]\n",
    "\n",
    "def calculate_total_volume(df):\n",
    "    return df[['ask_size1', 'ask_size2', 'bid_size1', 'bid_size2']].sum(axis=1)\n",
    "\n",
    "def calculate_volume_imbalance(df):\n",
    "    return abs((df['ask_size1'] + df['ask_size2']) - (df['bid_size1'] + df['bid_size2']))\n",
    "\n",
    "def book_aggregate_features_per_time_id(file_path, feature_aggregations):\n",
    "    df_book_data = pd.read_parquet(file_path)\n",
    "    stock_id = int(file_path.split('=')[1])\n",
    "\n",
    "    # Precompute complex features\n",
    "    df_book_data['wap'] = calculate_wap(df_book_data)\n",
    "    df_book_data['price_spread'] = calculate_price_spread(df_book_data)\n",
    "    df_book_data['bid_spread'] = calculate_bid_ask_spread(df_book_data, 'bid_price1', 'bid_price2')\n",
    "    df_book_data['ask_spread'] = calculate_bid_ask_spread(df_book_data, 'ask_price1', 'ask_price2')\n",
    "    df_book_data['total_volume'] = calculate_total_volume(df_book_data)\n",
    "    df_book_data['volume_imbalance'] = calculate_volume_imbalance(df_book_data)\n",
    "\n",
    "    # Prepare aggregation\n",
    "    aggregation_dict = {}\n",
    "    for new_name, (original, agg_func) in feature_aggregations.items():\n",
    "        aggregation_dict.setdefault(original, []).append((new_name, agg_func))\n",
    "\n",
    "    # Aggregate features\n",
    "    df_aggregated = df_book_data.groupby('time_id').agg(\n",
    "        {key: [func for _, func in value] for key, value in aggregation_dict.items()}\n",
    "    )\n",
    "\n",
    "    # Simplify MultiIndex in columns\n",
    "    df_aggregated.columns = [\n",
    "        f\"{original}_{agg_func.__name__ if callable(agg_func) else agg_func}\"\n",
    "        for original, funcs in aggregation_dict.items() for _, agg_func in funcs\n",
    "    ]\n",
    "\n",
    "    # Efficient row_id creation\n",
    "    df_aggregated['row_id'] = f\"{stock_id}-\" + df_aggregated.index.astype(str)\n",
    "    df_aggregated.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    cols = ['row_id'] + [col for col in df_aggregated.columns if col != 'row_id']\n",
    "    df_aggregated = df_aggregated[cols]\n",
    "\n",
    "    return df_aggregated\n",
    "\n",
    "def book_aggregate_features_for_all_stocks(list_file, feature_aggregations):\n",
    "    aggregated_data = [book_aggregate_features_per_time_id(file, feature_aggregations) for file in list_file]\n",
    "    return pd.concat(aggregated_data, ignore_index=True)\n",
    "\n",
    "def append_book_flattened_feature(list_file, flattened_feature, master):\n",
    "    df_aggregated_book = book_aggregate_features_for_all_stocks(list_file, flattened_feature)\n",
    "    master = pd.merge(master, df_aggregated_book, on='row_id', how='left')\n",
    "    return master\n",
    "\n",
    "def max_div_avg(series):\n",
    "    \"\"\"Returns the ratio of the maximum to the average of a series.\"\"\"\n",
    "    if series.mean() != 0:\n",
    "        return series.max() / series.mean()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def abs_price_change_first_last(series):\n",
    "    \"\"\"Returns the absolute difference between the first and last values of a series.\"\"\"\n",
    "    return abs(series.iloc[-1] - series.iloc[0])\n",
    "\n",
    "def price_spread(series_ask, series_bid):\n",
    "    \"\"\"Calculate price spread; requires preprocessing to apply.\"\"\"\n",
    "    return (series_ask - series_bid) / ((series_ask + series_bid) / 2)\n",
    "\n",
    "def bid_ask_spread(series_ask_price, series_bid_price):\n",
    "    \"\"\"Calculate bid and ask spread; requires preprocessing to apply.\"\"\"\n",
    "    return series_ask_price - series_bid_price\n",
    "\n",
    "def total_volume(series_ask_size, series_bid_size):\n",
    "    \"\"\"Calculate total volume; requires preprocessing to apply.\"\"\"\n",
    "    return series_ask_size.sum() + series_bid_size.sum()\n",
    "\n",
    "def volume_imbalance(series_ask_size, series_bid_size):\n",
    "    \"\"\"Calculate volume imbalance; requires preprocessing to apply.\"\"\"\n",
    "    return abs(series_ask_size.sum() - series_bid_size.sum())\n",
    "\n",
    "def calculate_wap(df):\n",
    "    wap = (df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']) / (df['bid_size1'] + df['ask_size1'])\n",
    "    return wap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade_aggregate_features_per_time_id(file_path, feature_aggregations):\n",
    "    df_trade_data = pd.read_parquet(file_path)\n",
    "    stock_id = int(file_path.split('=')[1])\n",
    "\n",
    "    # Prepare the aggregation dictionary\n",
    "    aggregation_dict = {}\n",
    "    for new_name, (original, agg_func) in feature_aggregations.items():\n",
    "        aggregation_dict.setdefault(original, []).append((new_name, agg_func))\n",
    "\n",
    "    # Aggregate features\n",
    "    df_aggregated = df_trade_data.groupby('time_id').agg(\n",
    "        {key: [func for _, func in value] for key, value in aggregation_dict.items()}\n",
    "    )\n",
    "\n",
    "    # Simplify MultiIndex in columns\n",
    "    df_aggregated.columns = [\n",
    "        f\"{original}_{agg_func.__name__ if callable(agg_func) else agg_func}\"\n",
    "        for original, funcs in aggregation_dict.items() for _, agg_func in funcs\n",
    "    ]\n",
    "\n",
    "    # Efficient row_id creation\n",
    "    df_aggregated['row_id'] = f\"{stock_id}-\" + df_aggregated.index.astype(str)\n",
    "    df_aggregated.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    cols = ['row_id'] + [col for col in df_aggregated.columns if col != 'row_id']\n",
    "    df_aggregated = df_aggregated[cols]\n",
    "\n",
    "    return df_aggregated\n",
    "\n",
    "def trade_aggregate_features_for_all_stocks(list_file, feature_aggregations):\n",
    "    aggregated_data = [trade_aggregate_features_per_time_id(file, feature_aggregations) for file in list_file]\n",
    "    return pd.concat(aggregated_data, ignore_index=True)\n",
    "\n",
    "def append_trade_flattened_feature(list_file, flattened_feature, master):\n",
    "    df_aggregated_trade = trade_aggregate_features_for_all_stocks(list_file, flattened_feature)\n",
    "    master = pd.merge(master, df_aggregated_trade, on='row_id', how='left')\n",
    "    return master\n",
    "\n",
    "def calculate_percent_change(series):\n",
    "    return (series.iloc[-1] - series.iloc[0]) / series.iloc[0] if series.iloc[0] != 0 else np.nan\n",
    "\n",
    "def calculate_percent_change_from_extremes(series):\n",
    "    return (series.max() - series.min()) / series.min() if series.min() != 0 else np.nan\n",
    "\n",
    "def abs_price_change(series):\n",
    "    \"\"\"Returns the absolute price change within the series.\"\"\"\n",
    "    return abs(series.iloc[-1] - series.iloc[0])\n",
    "\n",
    "def max_div_avg_size(series):\n",
    "    \"\"\"Returns the ratio of the max size to the average size.\"\"\"\n",
    "    if series.mean() != 0:\n",
    "        return series.max() / series.mean()\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def max_div_avg_order_count(series):\n",
    "    \"\"\"Returns the ratio of the max order count to the average order count.\"\"\"\n",
    "    if series.mean() != 0:\n",
    "        return series.max() / series.mean()\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_aggregations = {\n",
    "    'max_bid_size_div_avg_bid_size': ('bid_size1', max_div_avg),\n",
    "    'max_ask_size_div_avg_ask_size': ('ask_size1', max_div_avg),\n",
    "    'ask_price2_ptp': ('ask_price2', np.ptp),\n",
    "    'bid_price2_ptp': ('bid_price2', np.ptp),\n",
    "    'ask_price2_calculate_percent_change_from_extremes': ('ask_price2', calculate_percent_change_from_extremes),\n",
    "    'bid_price2_calculate_percent_change_froxm_extremes': ('bid_price2', calculate_percent_change_from_extremes),\n",
    "    'ask_price1_ptp': ('ask_price1', np.ptp),\n",
    "    'bid_price1_ptp': ('bid_price1', np.ptp),\n",
    "    'ask_price1_calculate_percent_change_from_extremes': ('ask_price1', calculate_percent_change_from_extremes),\n",
    "    'bid_price1_calculate_percent_change_from_extremes': ('bid_price1', calculate_percent_change_from_extremes),\n",
    "    'ask_price2_max': ('ask_price2', 'max'),\n",
    "    'ask_price1_max': ('ask_price1', 'max'),\n",
    "    'abs_bid_price_change': ('bid_price1', abs_price_change_first_last),\n",
    "    'abs_ask_price_change': ('ask_price1', abs_price_change_first_last),\n",
    "    'wap_mean': ('wap', 'mean'),\n",
    "    'price_spread_mean': ('price_spread', 'mean'),  # Assuming 'price_spread' is pre-calculated\n",
    "    'bid_spread_mean': ('bid_spread', 'mean'),  # Assuming 'bid_spread' is pre-calculated\n",
    "    'ask_spread_mean': ('ask_spread', 'mean'),  # Assuming 'ask_spread' is pre-calculated\n",
    "    'volume_imbalance_mean': ('volume_imbalance', 'mean'),\n",
    "    'total_volume_mean': ('total_volume', 'mean'),\n",
    "}\n",
    "\n",
    "\n",
    "trade_aggregations = {\n",
    "    'price_ptp': ('price', np.ptp),\n",
    "    'price_calculate_percent_change_from_extremes': ('price', calculate_percent_change_from_extremes),\n",
    "    'abs_price_last_first': ('price', abs_price_change),\n",
    "    'max_size_div_avg_size': ('size', max_div_avg_size),\n",
    "    'max_order_count_div_avg_order_count': ('order_count', max_div_avg_order_count),\n",
    "    'avg_size': ('size', 'mean'),\n",
    "    'avg_order_count': ('order_count', 'mean'),\n",
    "    'trade_seconds_in_bucket_count_unique': ('seconds_in_bucket', 'nunique'),\n",
    "    'trade_size_sum': ('size', 'sum'),\n",
    "    'trade_order_count_mean': ('order_count', 'mean'),\n",
    "    'price_ptp': ('price', np.ptp),\n",
    "    'price_calculate_percent_change_from_extremes': ('price', calculate_percent_change_from_extremes),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = append_book_flattened_feature(list_order_book_file_train, book_aggregations, master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = append_trade_flattened_feature(list_order_trade_file_train, trade_aggregations, master)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifted Volatilties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_shifted_volatilities(df, n_before, n_after):\n",
    "    # Ensure the DataFrame is sorted by 'stock' and then by 'order'\n",
    "    df = df.sort_values(by=['stock', 'order'])\n",
    "    \n",
    "    # Generate shifted columns for prior volatilities\n",
    "    for i in range(1, n_before + 1):\n",
    "        shifted_col_name = f'previous_vol_{i}'\n",
    "        df[shifted_col_name] = df.groupby('stock')['realized_vol'].shift(i)\n",
    "        # Fill NaN values for the first 'n_before' rows within each stock group with the first available 'realized_vol' in that group\n",
    "        df[shifted_col_name] = df.groupby('stock')[shifted_col_name].transform(lambda x: x.fillna(method='bfill'))\n",
    "    \n",
    "    # Generate shifted columns for following volatilities\n",
    "    for i in range(1, n_after + 1):\n",
    "        shifted_col_name = f'next_vol_{i}'\n",
    "        df[shifted_col_name] = df.groupby('stock')['realized_vol'].shift(-i)\n",
    "        # Fill NaN values for the last 'n_after' rows within each stock group with the last available 'realized_vol' in that group\n",
    "        df[shifted_col_name] = df.groupby('stock')[shifted_col_name].transform(lambda x: x.fillna(method='ffill'))\n",
    "\n",
    "    return df\n",
    "\n",
    "n_before = 3  # Number of previous volatilities to include\n",
    "n_after = 3   # Number of following volatilities to include\n",
    "master = add_shifted_volatilities(master, n_before, n_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-NN Market Conditions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'master' is your DataFrame\n",
    "\n",
    "# Step 1: Select features for KNN\n",
    "X = master.drop(['row_id', 'target', 'realized_vol'], axis=1)\n",
    "\n",
    "# Step 2: Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 3: Apply KNN to find the nearest 3 neighbors (excluding the row itself, so k=4)\n",
    "knn = NearestNeighbors(n_neighbors=4, algorithm='auto').fit(X_scaled)\n",
    "distances, indices = knn.kneighbors(X_scaled)\n",
    "\n",
    "# Step 4: Extract 'realized_vol' from the three nearest neighbors\n",
    "master.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Initialize columns for neighbor's realized_vol\n",
    "master['neighbor_vol_1'] = np.nan\n",
    "master['neighbor_vol_2'] = np.nan\n",
    "master['neighbor_vol_3'] = np.nan\n",
    "\n",
    "for i in range(len(indices)):\n",
    "    # Get the indices of the three nearest neighbors (excluding the row itself)\n",
    "    neighbors_indices = indices[i, 1:]  # Exclude the first index since it's the row itself\n",
    "    \n",
    "    # Use the DataFrame's index to correctly reference rows for 'realized_vol'\n",
    "    neighbor_vols = master.iloc[neighbors_indices]['realized_vol'].values\n",
    "    \n",
    "    # Assign 'realized_vol' values from neighbors\n",
    "    master.at[i, 'neighbor_vol_1'] = neighbor_vols[0]\n",
    "    master.at[i, 'neighbor_vol_2'] = neighbor_vols[1]\n",
    "    master.at[i, 'neighbor_vol_3'] = neighbor_vols[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running K-NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = master.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    mask = y_true != 0\n",
    "    rmspe = np.sqrt(np.mean(np.square((y_true[mask] - y_pred[mask]) / y_true[mask])))\n",
    "    return rmspe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Percentage Error: 0.29077510099811454\n"
     ]
    }
   ],
   "source": [
    "X_knn = master.drop(columns=['row_id', 'target'])\n",
    "y_knn = master['target'].values\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_knn_scaled = scaler.fit_transform(X_knn)\n",
    "\n",
    "X_train_knn, X_test_knn, y_train_knn, y_test_knn = train_test_split(X_knn_scaled, y_knn, test_size=0.3, random_state=42)\n",
    "\n",
    "knn_model = KNeighborsRegressor(n_neighbors=25)\n",
    "knn_model.fit(X_train_knn, y_train_knn)\n",
    "knn_predictions = knn_model.predict(X_test_knn)\n",
    "\n",
    "knn_rmspe = rmspe(y_test_knn, knn_predictions)\n",
    "print(f'Root Mean Squared Percentage Error: {knn_rmspe}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>row_id</th>\n",
       "      <th>order</th>\n",
       "      <th>target</th>\n",
       "      <th>realized_vol</th>\n",
       "      <th>bid_size1_max_div_avg</th>\n",
       "      <th>ask_size1_max_div_avg</th>\n",
       "      <th>ask_price2_ptp</th>\n",
       "      <th>ask_price2_calculate_percent_change_from_extremes</th>\n",
       "      <th>ask_price2_max</th>\n",
       "      <th>bid_price2_ptp</th>\n",
       "      <th>bid_price2_calculate_percent_change_from_extremes</th>\n",
       "      <th>ask_price1_ptp</th>\n",
       "      <th>ask_price1_calculate_percent_change_from_extremes</th>\n",
       "      <th>ask_price1_max</th>\n",
       "      <th>ask_price1_abs_price_change_first_last</th>\n",
       "      <th>bid_price1_ptp</th>\n",
       "      <th>bid_price1_calculate_percent_change_from_extremes</th>\n",
       "      <th>bid_price1_abs_price_change_first_last</th>\n",
       "      <th>wap_mean</th>\n",
       "      <th>price_spread_mean</th>\n",
       "      <th>bid_spread_mean</th>\n",
       "      <th>ask_spread_mean</th>\n",
       "      <th>volume_imbalance_mean</th>\n",
       "      <th>total_volume_mean</th>\n",
       "      <th>price_ptp</th>\n",
       "      <th>price_calculate_percent_change_from_extremes</th>\n",
       "      <th>price_abs_price_change</th>\n",
       "      <th>size_max_div_avg_size</th>\n",
       "      <th>size_mean</th>\n",
       "      <th>size_sum</th>\n",
       "      <th>order_count_max_div_avg_order_count</th>\n",
       "      <th>order_count_mean</th>\n",
       "      <th>order_count_mean</th>\n",
       "      <th>order_count_mean</th>\n",
       "      <th>order_count_mean</th>\n",
       "      <th>seconds_in_bucket_nunique</th>\n",
       "      <th>previous_vol_1</th>\n",
       "      <th>previous_vol_2</th>\n",
       "      <th>previous_vol_3</th>\n",
       "      <th>next_vol_1</th>\n",
       "      <th>next_vol_2</th>\n",
       "      <th>next_vol_3</th>\n",
       "      <th>neighbor_vol_1</th>\n",
       "      <th>neighbor_vol_2</th>\n",
       "      <th>neighbor_vol_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0-4294</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>2.806304</td>\n",
       "      <td>6.434691</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>1.007990</td>\n",
       "      <td>0.009381</td>\n",
       "      <td>0.009408</td>\n",
       "      <td>0.003505</td>\n",
       "      <td>0.003490</td>\n",
       "      <td>1.007732</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>0.004682</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>1.005457</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>-0.000231</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>205.157609</td>\n",
       "      <td>498.081522</td>\n",
       "      <td>0.003957</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>2.498525</td>\n",
       "      <td>145.285714</td>\n",
       "      <td>2034.0</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.004937</td>\n",
       "      <td>0.006266</td>\n",
       "      <td>0.005423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0-24033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>2.440895</td>\n",
       "      <td>3.456275</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>1.000128</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.002768</td>\n",
       "      <td>0.002503</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.002197</td>\n",
       "      <td>0.002810</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>0.002299</td>\n",
       "      <td>0.998583</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>116.313783</td>\n",
       "      <td>382.923754</td>\n",
       "      <td>0.001908</td>\n",
       "      <td>0.001913</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>3.214815</td>\n",
       "      <td>67.500000</td>\n",
       "      <td>1755.0</td>\n",
       "      <td>2.212766</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.004334</td>\n",
       "      <td>0.003503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0-5666</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>3.053678</td>\n",
       "      <td>4.802214</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.998998</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>-0.000095</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>115.274576</td>\n",
       "      <td>319.016949</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>4.770754</td>\n",
       "      <td>45.275862</td>\n",
       "      <td>1313.0</td>\n",
       "      <td>4.578947</td>\n",
       "      <td>1.965517</td>\n",
       "      <td>1.965517</td>\n",
       "      <td>1.965517</td>\n",
       "      <td>1.965517</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.003443</td>\n",
       "      <td>0.001790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0-29740</td>\n",
       "      <td>3</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>2.944738</td>\n",
       "      <td>4.280906</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>1.001563</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>0.001486</td>\n",
       "      <td>1.001461</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>1.000602</td>\n",
       "      <td>0.000576</td>\n",
       "      <td>-0.000101</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>174.898058</td>\n",
       "      <td>496.927184</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>4.967666</td>\n",
       "      <td>65.423077</td>\n",
       "      <td>1701.0</td>\n",
       "      <td>3.319149</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.003590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0-22178</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>3.586559</td>\n",
       "      <td>3.590304</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>1.000205</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>1.000051</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>0.998349</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>148.091667</td>\n",
       "      <td>482.441667</td>\n",
       "      <td>0.002411</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>7.735746</td>\n",
       "      <td>96.047619</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.150943</td>\n",
       "      <td>2.523810</td>\n",
       "      <td>2.523810</td>\n",
       "      <td>2.523810</td>\n",
       "      <td>2.523810</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.001196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428908</th>\n",
       "      <td>99</td>\n",
       "      <td>99-24913</td>\n",
       "      <td>3825</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>2.247635</td>\n",
       "      <td>2.343238</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>1.000982</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>1.000831</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>1.000192</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>357.053830</td>\n",
       "      <td>2268.246377</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>7.736945</td>\n",
       "      <td>352.852459</td>\n",
       "      <td>21524.0</td>\n",
       "      <td>5.613497</td>\n",
       "      <td>5.344262</td>\n",
       "      <td>5.344262</td>\n",
       "      <td>5.344262</td>\n",
       "      <td>5.344262</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.001394</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>0.001274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428909</th>\n",
       "      <td>99</td>\n",
       "      <td>99-32195</td>\n",
       "      <td>3826</td>\n",
       "      <td>0.001248</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>3.261741</td>\n",
       "      <td>6.643945</td>\n",
       "      <td>0.001509</td>\n",
       "      <td>0.001511</td>\n",
       "      <td>1.000226</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>1.000075</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.999309</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>631.287109</td>\n",
       "      <td>2172.791016</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>14.251719</td>\n",
       "      <td>264.740000</td>\n",
       "      <td>26474.0</td>\n",
       "      <td>11.666667</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.001905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428910</th>\n",
       "      <td>99</td>\n",
       "      <td>99-15365</td>\n",
       "      <td>3827</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>3.384056</td>\n",
       "      <td>10.750909</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>1.001584</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>1.001433</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>1.000229</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>386.595238</td>\n",
       "      <td>1867.503968</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.001056</td>\n",
       "      <td>3.794150</td>\n",
       "      <td>206.897436</td>\n",
       "      <td>16138.0</td>\n",
       "      <td>4.155738</td>\n",
       "      <td>3.128205</td>\n",
       "      <td>3.128205</td>\n",
       "      <td>3.128205</td>\n",
       "      <td>3.128205</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.001367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428911</th>\n",
       "      <td>99</td>\n",
       "      <td>99-10890</td>\n",
       "      <td>3828</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>3.441576</td>\n",
       "      <td>3.883602</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1.000678</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>1.000527</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.002259</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.999461</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>994.640777</td>\n",
       "      <td>3326.633010</td>\n",
       "      <td>0.002108</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>6.327757</td>\n",
       "      <td>539.843750</td>\n",
       "      <td>51825.0</td>\n",
       "      <td>5.197452</td>\n",
       "      <td>6.541667</td>\n",
       "      <td>6.541667</td>\n",
       "      <td>6.541667</td>\n",
       "      <td>6.541667</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001466</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.001246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428912</th>\n",
       "      <td>99</td>\n",
       "      <td>99-29316</td>\n",
       "      <td>3829</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>3.974785</td>\n",
       "      <td>5.009612</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>1.002338</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>1.002187</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>1.001094</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>-0.000151</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>445.455969</td>\n",
       "      <td>2089.162427</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>6.472060</td>\n",
       "      <td>299.750000</td>\n",
       "      <td>20383.0</td>\n",
       "      <td>5.003344</td>\n",
       "      <td>4.397059</td>\n",
       "      <td>4.397059</td>\n",
       "      <td>4.397059</td>\n",
       "      <td>4.397059</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001443</td>\n",
       "      <td>0.001784</td>\n",
       "      <td>0.001616</td>\n",
       "      <td>0.001367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428913 rows  46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stock    row_id  order    target  realized_vol  bid_size1_max_div_avg  \\\n",
       "0          0    0-4294      0  0.003267      0.007026               2.806304   \n",
       "1          0   0-24033      1  0.002580      0.004136               2.440895   \n",
       "2          0    0-5666      2  0.002051      0.002395               3.053678   \n",
       "3          0   0-29740      3  0.002364      0.001790               2.944738   \n",
       "4          0   0-22178      4  0.001439      0.002601               3.586559   \n",
       "...      ...       ...    ...       ...           ...                    ...   \n",
       "428908    99  99-24913   3825  0.001040      0.001153               2.247635   \n",
       "428909    99  99-32195   3826  0.001248      0.001502               3.261741   \n",
       "428910    99  99-15365   3827  0.001257      0.001379               3.384056   \n",
       "428911    99  99-10890   3828  0.002815      0.001468               3.441576   \n",
       "428912    99  99-29316   3829  0.001351      0.001443               3.974785   \n",
       "\n",
       "        ask_size1_max_div_avg  ask_price2_ptp  \\\n",
       "0                    6.434691        0.003196   \n",
       "1                    3.456275        0.002452   \n",
       "2                    4.802214        0.001332   \n",
       "3                    4.280906        0.001384   \n",
       "4                    3.590304        0.002514   \n",
       "...                       ...             ...   \n",
       "428908               2.343238        0.001208   \n",
       "428909               6.643945        0.001509   \n",
       "428910              10.750909        0.002262   \n",
       "428911               3.883602        0.002259   \n",
       "428912               5.009612        0.001961   \n",
       "\n",
       "        ask_price2_calculate_percent_change_from_extremes  ask_price2_max  \\\n",
       "0                                                0.003181        1.007990   \n",
       "1                                                0.002458        1.000128   \n",
       "2                                                0.001333        1.000000   \n",
       "3                                                0.001384        1.001563   \n",
       "4                                                0.002519        1.000205   \n",
       "...                                                   ...             ...   \n",
       "428908                                           0.001209        1.000982   \n",
       "428909                                           0.001511        1.000226   \n",
       "428910                                           0.002264        1.001584   \n",
       "428911                                           0.002262        1.000678   \n",
       "428912                                           0.001960        1.002338   \n",
       "\n",
       "        bid_price2_ptp  bid_price2_calculate_percent_change_from_extremes  \\\n",
       "0             0.009381                                           0.009408   \n",
       "1             0.002759                                           0.002768   \n",
       "2             0.002048                                           0.002054   \n",
       "3             0.001692                                           0.001693   \n",
       "4             0.002719                                           0.002728   \n",
       "...                ...                                                ...   \n",
       "428908        0.001208                                           0.001209   \n",
       "428909        0.001661                                           0.001664   \n",
       "428910        0.002262                                           0.002265   \n",
       "428911        0.002259                                           0.002263   \n",
       "428912        0.001810                                           0.001811   \n",
       "\n",
       "        ask_price1_ptp  ask_price1_calculate_percent_change_from_extremes  \\\n",
       "0             0.003505                                           0.003490   \n",
       "1             0.002503                                           0.002510   \n",
       "2             0.001280                                           0.001282   \n",
       "3             0.001486                                           0.001486   \n",
       "4             0.002616                                           0.002623   \n",
       "...                ...                                                ...   \n",
       "428908        0.001208                                           0.001209   \n",
       "428909        0.001510                                           0.001512   \n",
       "428910        0.002262                                           0.002264   \n",
       "428911        0.002259                                           0.002262   \n",
       "428912        0.001961                                           0.001961   \n",
       "\n",
       "        ask_price1_max  ask_price1_abs_price_change_first_last  \\\n",
       "0             1.007732                                0.001598   \n",
       "1             0.999923                                0.002197   \n",
       "2             0.999898                                0.001024   \n",
       "3             1.001461                                0.000410   \n",
       "4             1.000051                                0.001744   \n",
       "...                ...                                     ...   \n",
       "428908        1.000831                                0.000302   \n",
       "428909        1.000075                                0.000755   \n",
       "428910        1.001433                                0.001056   \n",
       "428911        1.000527                                0.000301   \n",
       "428912        1.002187                                0.000151   \n",
       "\n",
       "        bid_price1_ptp  bid_price1_calculate_percent_change_from_extremes  \\\n",
       "0             0.004691                                           0.004682   \n",
       "1             0.002810                                           0.002820   \n",
       "2             0.002048                                           0.002054   \n",
       "3             0.001281                                           0.001282   \n",
       "4             0.002719                                           0.002728   \n",
       "...                ...                                                ...   \n",
       "428908        0.001208                                           0.001209   \n",
       "428909        0.001661                                           0.001663   \n",
       "428910        0.002262                                           0.002265   \n",
       "428911        0.002259                                           0.002263   \n",
       "428912        0.001810                                           0.001810   \n",
       "\n",
       "        bid_price1_abs_price_change_first_last  wap_mean  price_spread_mean  \\\n",
       "0                                     0.003608  1.005457           0.002081   \n",
       "1                                     0.002299  0.998583           0.000786   \n",
       "2                                     0.000717  0.998998           0.000456   \n",
       "3                                     0.000308  1.000602           0.000576   \n",
       "4                                     0.001642  0.998349           0.000617   \n",
       "...                                        ...       ...                ...   \n",
       "428908                                0.000302  1.000192           0.000158   \n",
       "428909                                0.000906  0.999309           0.000164   \n",
       "428910                                0.001056  1.000229           0.000172   \n",
       "428911                                0.000301  0.999461           0.000154   \n",
       "428912                                0.000302  1.001094           0.000181   \n",
       "\n",
       "        bid_spread_mean  ask_spread_mean  volume_imbalance_mean  \\\n",
       "0             -0.000231         0.000423             205.157609   \n",
       "1             -0.000088         0.000199             116.313783   \n",
       "2             -0.000095         0.000176             115.274576   \n",
       "3             -0.000101         0.000185             174.898058   \n",
       "4             -0.000087         0.000165             148.091667   \n",
       "...                 ...              ...                    ...   \n",
       "428908        -0.000151         0.000151             357.053830   \n",
       "428909        -0.000151         0.000151             631.287109   \n",
       "428910        -0.000151         0.000151             386.595238   \n",
       "428911        -0.000151         0.000151             994.640777   \n",
       "428912        -0.000151         0.000151             445.455969   \n",
       "\n",
       "        total_volume_mean  price_ptp  \\\n",
       "0              498.081522   0.003957   \n",
       "1              382.923754   0.001908   \n",
       "2              319.016949   0.001078   \n",
       "3              496.927184   0.001076   \n",
       "4              482.441667   0.002411   \n",
       "...                   ...        ...   \n",
       "428908        2268.246377   0.001195   \n",
       "428909        2172.791016   0.001510   \n",
       "428910        1867.503968   0.002111   \n",
       "428911        3326.633010   0.002108   \n",
       "428912        2089.162427   0.001810   \n",
       "\n",
       "        price_calculate_percent_change_from_extremes  price_abs_price_change  \\\n",
       "0                                           0.003943                0.001756   \n",
       "1                                           0.001913                0.001890   \n",
       "2                                           0.001080                0.000559   \n",
       "3                                           0.001076                0.000308   \n",
       "4                                           0.002417                0.001949   \n",
       "...                                              ...                     ...   \n",
       "428908                                      0.001196                0.000151   \n",
       "428909                                      0.001512                0.000604   \n",
       "428910                                      0.002113                0.001056   \n",
       "428911                                      0.002112                0.000455   \n",
       "428912                                      0.001810                0.000151   \n",
       "\n",
       "        size_max_div_avg_size   size_mean  size_sum  \\\n",
       "0                    2.498525  145.285714    2034.0   \n",
       "1                    3.214815   67.500000    1755.0   \n",
       "2                    4.770754   45.275862    1313.0   \n",
       "3                    4.967666   65.423077    1701.0   \n",
       "4                    7.735746   96.047619    2017.0   \n",
       "...                       ...         ...       ...   \n",
       "428908               7.736945  352.852459   21524.0   \n",
       "428909              14.251719  264.740000   26474.0   \n",
       "428910               3.794150  206.897436   16138.0   \n",
       "428911               6.327757  539.843750   51825.0   \n",
       "428912               6.472060  299.750000   20383.0   \n",
       "\n",
       "        order_count_max_div_avg_order_count  order_count_mean  \\\n",
       "0                                  2.333333          3.857143   \n",
       "1                                  2.212766          1.807692   \n",
       "2                                  4.578947          1.965517   \n",
       "3                                  3.319149          1.807692   \n",
       "4                                  5.150943          2.523810   \n",
       "...                                     ...               ...   \n",
       "428908                             5.613497          5.344262   \n",
       "428909                            11.666667          3.600000   \n",
       "428910                             4.155738          3.128205   \n",
       "428911                             5.197452          6.541667   \n",
       "428912                             5.003344          4.397059   \n",
       "\n",
       "        order_count_mean  order_count_mean  order_count_mean  \\\n",
       "0               3.857143          3.857143          3.857143   \n",
       "1               1.807692          1.807692          1.807692   \n",
       "2               1.965517          1.965517          1.965517   \n",
       "3               1.807692          1.807692          1.807692   \n",
       "4               2.523810          2.523810          2.523810   \n",
       "...                  ...               ...               ...   \n",
       "428908          5.344262          5.344262          5.344262   \n",
       "428909          3.600000          3.600000          3.600000   \n",
       "428910          3.128205          3.128205          3.128205   \n",
       "428911          6.541667          6.541667          6.541667   \n",
       "428912          4.397059          4.397059          4.397059   \n",
       "\n",
       "        seconds_in_bucket_nunique  previous_vol_1  previous_vol_2  \\\n",
       "0                            14.0        0.007026        0.007026   \n",
       "1                            26.0        0.007026        0.007026   \n",
       "2                            29.0        0.004136        0.007026   \n",
       "3                            26.0        0.002395        0.004136   \n",
       "4                            21.0        0.001790        0.002395   \n",
       "...                           ...             ...             ...   \n",
       "428908                       61.0        0.001301        0.001368   \n",
       "428909                      100.0        0.001153        0.001301   \n",
       "428910                       78.0        0.001502        0.001153   \n",
       "428911                       96.0        0.001379        0.001502   \n",
       "428912                       68.0        0.001468        0.001379   \n",
       "\n",
       "        previous_vol_3  next_vol_1  next_vol_2  next_vol_3  neighbor_vol_1  \\\n",
       "0             0.007026    0.004136    0.002395    0.001790        0.004937   \n",
       "1             0.007026    0.002395    0.001790    0.002601        0.002395   \n",
       "2             0.007026    0.001790    0.002601    0.001474        0.003481   \n",
       "3             0.007026    0.002601    0.001474    0.001465        0.001958   \n",
       "4             0.004136    0.001474    0.001465    0.000891        0.001628   \n",
       "...                ...         ...         ...         ...             ...   \n",
       "428908        0.001394    0.001502    0.001379    0.001468        0.001007   \n",
       "428909        0.001368    0.001379    0.001468    0.001443        0.001670   \n",
       "428910        0.001301    0.001468    0.001443    0.001443        0.001569   \n",
       "428911        0.001153    0.001443    0.001443    0.001443        0.001466   \n",
       "428912        0.001502    0.001443    0.001443    0.001443        0.001784   \n",
       "\n",
       "        neighbor_vol_2  neighbor_vol_3  \n",
       "0             0.006266        0.005423  \n",
       "1             0.004334        0.003503  \n",
       "2             0.003443        0.001790  \n",
       "3             0.003481        0.003590  \n",
       "4             0.002264        0.001196  \n",
       "...                ...             ...  \n",
       "428908        0.000905        0.001274  \n",
       "428909        0.001790        0.001905  \n",
       "428910        0.001595        0.001367  \n",
       "428911        0.001355        0.001246  \n",
       "428912        0.001616        0.001367  \n",
       "\n",
       "[428913 rows x 46 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "master.sort_values(by=['order'], inplace=True)\n",
    "\n",
    "# Parameters\n",
    "sequence_length = 50  # This is an arbitrary choice; adjust based on your temporal analysis needs\n",
    "\n",
    "# Placeholder for transformed data\n",
    "sequences = []\n",
    "targets = []\n",
    "\n",
    "# Iterate through each stockID to create sequences\n",
    "for timeID, group in master.groupby('order'):\n",
    "    orders = group[['order']].values  # Assuming you want to use both timeID and target as features\n",
    "    targs = group[['target']].values\n",
    "    for i in range(len(orders) - sequence_length):\n",
    "        sequences.append(orders[i:i+sequence_length, :])\n",
    "        targets.append(targs[i+sequence_length, -1])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(sequences)\n",
    "y = np.array(targets)\n",
    "\n",
    "# Normalizing the features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_reshaped = X.reshape(-1, X.shape[2])  # Reshape to 2D for scaling\n",
    "X_scaled = scaler.fit_transform(X_reshaped)\n",
    "X_scaled = X_scaled.reshape(X.shape)  # Reshape back to 3D\n",
    "\n",
    "# Define split ratio\n",
    "split_ratio = 0.8\n",
    "\n",
    "# Calculate the split index\n",
    "split_index = int(X_scaled.shape[0] * split_ratio)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test = X_scaled[:split_index], X_scaled[split_index:]\n",
    "y_train, y_test = y[:split_index], y[split_index:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define LSTM model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m lstm_model \u001b[38;5;241m=\u001b[39m \u001b[43mSequential\u001b[49m()\n\u001b[1;32m      3\u001b[0m lstm_model\u001b[38;5;241m.\u001b[39madd(LSTM(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39m(X_scaled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], X_scaled\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])))\n\u001b[1;32m      4\u001b[0m lstm_model\u001b[38;5;241m.\u001b[39madd(LSTM(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# Define LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(units=50, return_sequences=True, input_shape=(X_scaled.shape[1], X_scaled.shape[2])))\n",
    "lstm_model.add(LSTM(units=50))\n",
    "lstm_model.add(Dense(1))\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train model\n",
    "# Train model\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13369/13369 [==============================] - 43s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "lstm_y_pred = lstm_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(428903, 10, 35)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmspe(y_test, lstm_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'master' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmaster\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'master' is not defined"
     ]
    }
   ],
   "source": [
    "master"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
