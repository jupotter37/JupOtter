{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "618bcba4-6aeb-45ab-8e68-e0fa68b872ea",
   "metadata": {},
   "source": [
    "<div align=\"left\">\n",
    "    <strong>RNA Seq Data Analysis Pipeline using Jupyter and Colab Notebook</strong>\n",
    "</div>\n",
    "\n",
    "![alt text](https://pydeseq2.readthedocs.io/en/latest/_static/pydeseq2_logo.svg)\n",
    "![alt text](https://jupyter.org/assets/logos/rectanglelogo-greytext-orangebody-greymoons.svg)\n",
    "![alt text](https://www.python.org/static/img/python-logo.png)\n",
    "![alt text](https://colab.google/static/images/icons/colab.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127717ff-2ee4-4b95-b631-4356895145ff",
   "metadata": {},
   "source": [
    "</p> <a class=\"btn\" href=\"#home\" style=\"display: inline-block; margin-top: 10px; text-decoration: none; color: #ffffff; background-color: #4CAF85; padding: 8px 15px; border-radius: 4px;\"> \n",
    "<b>Table of Contents</b>\n",
    "    \n",
    "- .........................................................................................................................................\n",
    "    \n",
    "### Part: 1\n",
    "- Import Libraries\n",
    "- Working Directory Info.\n",
    "- Sample information\n",
    "- Download Dataset From SRA\n",
    "- Converting Files: SRA to FASTQ\n",
    "- Initial Quality Check\n",
    "- Adaptor Trim and Trim Quality Check\n",
    "- Download Ref Genome Indexing and Read Alignment\n",
    "- SAM to BAM Conversion sorted and indexed\n",
    "- Deduplication: Use Picard to mark and remove duplicate reads\n",
    "- Final Quality Check:  Qualimap, Samtools Stats, and MultiQC\n",
    "- Reads Quantification using HTseq\n",
    "- Reads Metrics integration with metadata\n",
    "\n",
    "### Part: 2\n",
    "- Normalization:  Filter lowly expressed genes and Normalized Dataset Creation\n",
    "- Visualization: PCA, Volcano and Heatmap Plots\n",
    "- Result Interpretation: Upregulated and Downregulated Genes\n",
    "- Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d305261-8bad-4acc-b6b6-17f25f2c8c53",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"\n",
    "    background-image: url('https://i.postimg.cc/x18pG8B2/image.webp');\n",
    "    background-size: cover;\n",
    "    background-repeat: no-repeat;\n",
    "    font-family: 'Arial', sans-serif;\n",
    "    font-size: 24px;\n",
    "    color: white;\n",
    "    text-align: center;\n",
    "    border-radius: 15px 50px;\n",
    "    padding: 20px 40px;\n",
    "    margin: 20px 0;\n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\">\n",
    "    <b>Import Libraries</b>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c6bf1d-78dd-4e08-a90d-d4928c400b05",
   "metadata": {},
   "source": [
    "- Jupyter Working Directory Path: `/home/mahendra/Desktop/Python/Project/`\n",
    "- If You Want to Run This Jupyter Notebook on Google Colab You Can Set the Following Path: `/content/Python/Project/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b386a2e4-644d-40df-8bc5-dac7564c3f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/mahendra/anaconda3/lib/python3.12/site-packages (24.3.1)\n",
      "Reading package lists... Done\n",
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "Requirement already satisfied: pysradb in /home/mahendra/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: lxml>=4.6.3 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pysradb) (5.2.1)\n",
      "Requirement already satisfied: pandas>=1.3.2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pysradb) (2.2.2)\n",
      "Requirement already satisfied: requests-ftp>=0.3.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pysradb) (0.3.1)\n",
      "Requirement already satisfied: requests>=2.26.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pysradb) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pysradb) (4.66.4)\n",
      "Requirement already satisfied: xmltodict>=0.12.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pysradb) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas>=1.3.2->pysradb) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas>=1.3.2->pysradb) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas>=1.3.2->pysradb) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas>=1.3.2->pysradb) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->pysradb) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->pysradb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->pysradb) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from requests>=2.26.0->pysradb) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.3.2->pysradb) (1.16.0)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "Requirement already satisfied: multiqc in /home/mahendra/anaconda3/lib/python3.12/site-packages (1.25.1)\n",
      "Requirement already satisfied: click in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (8.1.7)\n",
      "Requirement already satisfied: humanize in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (4.11.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (7.0.1)\n",
      "Requirement already satisfied: jinja2>=3.0.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (3.1.4)\n",
      "Requirement already satisfied: kaleido in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (0.2.1)\n",
      "Requirement already satisfied: markdown in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (3.4.1)\n",
      "Requirement already satisfied: numpy in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (23.2)\n",
      "Requirement already satisfied: requests in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (2.32.2)\n",
      "Requirement already satisfied: Pillow>=10 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (10.3.0)\n",
      "Requirement already satisfied: plotly>=5.18 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (5.22.0)\n",
      "Requirement already satisfied: pyyaml>=4 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (6.0.1)\n",
      "Requirement already satisfied: rich>=10 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (13.3.5)\n",
      "Requirement already satisfied: rich-click in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (1.8.3)\n",
      "Requirement already satisfied: coloredlogs in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (15.0.1)\n",
      "Requirement already satisfied: spectra>=0.0.10 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (0.0.11)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (2.8.2)\n",
      "Requirement already satisfied: typeguard in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (4.2.1)\n",
      "Requirement already satisfied: tqdm in /home/mahendra/anaconda3/lib/python3.12/site-packages (from multiqc) (4.66.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jinja2>=3.0.0->multiqc) (2.1.3)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from plotly>=5.18->multiqc) (8.2.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pydantic>=2.7.0->multiqc) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pydantic>=2.7.0->multiqc) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pydantic>=2.7.0->multiqc) (4.11.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from rich>=10->multiqc) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from rich>=10->multiqc) (2.15.1)\n",
      "Requirement already satisfied: colormath>=3.0.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from spectra>=0.0.10->multiqc) (3.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from coloredlogs->multiqc) (10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from importlib-metadata->multiqc) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from requests->multiqc) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from requests->multiqc) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from requests->multiqc) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from requests->multiqc) (2024.8.30)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from colormath>=3.0.0->spectra>=0.0.10->multiqc) (3.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10->multiqc) (0.1.0)\n",
      "Reading package lists... Done\n",
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "Requirement already satisfied: cutadapt in /home/mahendra/anaconda3/lib/python3.12/site-packages (4.9)\n",
      "Requirement already satisfied: dnaio>=1.2.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from cutadapt) (1.2.2)\n",
      "Requirement already satisfied: xopen>=1.6.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from cutadapt) (2.0.2)\n",
      "Requirement already satisfied: isal>=1.6.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from xopen>=1.6.0->cutadapt) (1.7.1)\n",
      "Requirement already satisfied: zlib-ng>=0.4.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from xopen>=1.6.0->cutadapt) (0.5.1)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement samtools (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for samtools\u001b[0m\u001b[31m\n",
      "\u001b[0mCollecting picard\n",
      "  Using cached picard-2.12.3.tar.gz (5.9 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting discid~=1.0 (from picard)\n",
      "  Using cached discid-1.2.0-py3-none-any.whl\n",
      "Collecting fasteners~=0.14 (from picard)\n",
      "  Using cached fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: Markdown~=3.2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from picard) (3.4.1)\n",
      "Collecting mutagen~=1.37 (from picard)\n",
      "  Using cached mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: PyJWT~=2.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from picard) (2.8.0)\n",
      "Requirement already satisfied: PyQt5~=5.11 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from picard) (5.15.10)\n",
      "Requirement already satisfied: python-dateutil~=2.7 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from picard) (2.9.0.post0)\n",
      "Requirement already satisfied: PyYAML<7,>=5.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from picard) (6.0.1)\n",
      "Collecting charset-normalizer~=3.3.2 (from picard)\n",
      "  Using cached charset_normalizer-3.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.13 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from PyQt5~=5.11->picard) (12.13.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from python-dateutil~=2.7->picard) (1.16.0)\n",
      "Using cached charset_normalizer-3.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "Using cached fasteners-0.19-py3-none-any.whl (18 kB)\n",
      "Using cached mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
      "Building wheels for collected packages: picard\n",
      "  Building wheel for picard (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for picard \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[7 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m generating tagger.py from tagger.py.in\n",
      "  \u001b[31m   \u001b[0m generating scripts/picard from scripts/picard.in\n",
      "  \u001b[31m   \u001b[0m running build_appdata\n",
      "  \u001b[31m   \u001b[0m msgfmt --xml --template=org.musicbrainz.Picard.appdata.xml.in -d po/appstream -o /tmp/tmp9rmliv8porg.musicbrainz.Picard.appdata.xml\n",
      "  \u001b[31m   \u001b[0m error: command 'msgfmt' failed: No such file or directory\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for picard\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25hFailed to build picard\n",
      "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (picard)\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: biopython in /home/mahendra/anaconda3/lib/python3.12/site-packages (1.84)\n",
      "Requirement already satisfied: numpy in /home/mahendra/anaconda3/lib/python3.12/site-packages (from biopython) (1.26.4)\n",
      "Reading package lists... Done\n",
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n",
      "--2024-11-17 22:52:42--  https://github.com/broadinstitute/picard/releases/download/2.27.4/picard.jar\n",
      "Resolving github.com (github.com)... 20.207.73.82\n",
      "Connecting to github.com (github.com)|20.207.73.82|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/18225913/839cd9dd-e7dc-4c29-ab0d-6ab4bdcded4e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241117%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241117T172243Z&X-Amz-Expires=300&X-Amz-Signature=ab3d4636191488899feffb0d28ca5b19807376161f7ef0a54cd45e92827485da&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dpicard.jar&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-11-17 22:52:43--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/18225913/839cd9dd-e7dc-4c29-ab0d-6ab4bdcded4e?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20241117%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20241117T172243Z&X-Amz-Expires=300&X-Amz-Signature=ab3d4636191488899feffb0d28ca5b19807376161f7ef0a54cd45e92827485da&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dpicard.jar&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 17544754 (17M) [application/octet-stream]\n",
      "Saving to: ‘picard.jar.1’\n",
      "\n",
      "picard.jar.1        100%[===================>]  16.73M  5.27MB/s    in 3.4s    \n",
      "\n",
      "2024-11-17 22:52:48 (4.93 MB/s) - ‘picard.jar.1’ saved [17544754/17544754]\n",
      "\n",
      "Retrieving notices: ...working... done\n",
      "Channels:\n",
      " - conda-forge\n",
      " - bioconda\n",
      " - defaults\n",
      " - anaconda\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/mahendra/anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - openjdk=8\n",
      "    - picard\n",
      "\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            pkgs/main/linux-64::certifi-2024.8.30~ --> conda-forge/noarch::certifi-2024.8.30-pyhd8ed1ab_0 \n",
      "  conda              pkgs/main::conda-24.9.2-py312h06a4308~ --> conda-forge::conda-24.9.2-py312h7900ff3_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages:\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Requirement already satisfied: pandas in /home/mahendra/anaconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: numpy in /home/mahendra/anaconda3/lib/python3.12/site-packages (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /home/mahendra/anaconda3/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.21 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in /home/mahendra/anaconda3/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from seaborn) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Requirement already satisfied: scipy in /home/mahendra/anaconda3/lib/python3.12/site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from scipy) (1.26.4)\n",
      "Requirement already satisfied: pysam in /home/mahendra/anaconda3/lib/python3.12/site-packages (0.22.1)\n",
      "Requirement already satisfied: gffutils in /home/mahendra/anaconda3/lib/python3.12/site-packages (0.13)\n",
      "Requirement already satisfied: pyfaidx>=0.5.5.2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from gffutils) (0.8.1.3)\n",
      "Requirement already satisfied: argh>=0.26.2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from gffutils) (0.31.3)\n",
      "Requirement already satisfied: argcomplete>=1.9.4 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from gffutils) (3.5.1)\n",
      "Requirement already satisfied: simplejson in /home/mahendra/anaconda3/lib/python3.12/site-packages (from gffutils) (3.19.3)\n",
      "Requirement already satisfied: importlib-metadata in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pyfaidx>=0.5.5.2->gffutils) (7.0.1)\n",
      "Requirement already satisfied: packaging in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pyfaidx>=0.5.5.2->gffutils) (23.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from importlib-metadata->pyfaidx>=0.5.5.2->gffutils) (3.17.0)\n",
      "Collecting rpy2\n",
      "  Using cached rpy2-3.5.16.tar.gz (220 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.15.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from rpy2) (1.16.0)\n",
      "Requirement already satisfied: jinja2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from rpy2) (3.1.4)\n",
      "Collecting tzlocal (from rpy2)\n",
      "  Downloading tzlocal-5.2-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: pycparser in /home/mahendra/anaconda3/lib/python3.12/site-packages (from cffi>=1.15.1->rpy2) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jinja2->rpy2) (2.1.3)\n",
      "Downloading tzlocal-5.2-py3-none-any.whl (17 kB)\n",
      "Building wheels for collected packages: rpy2\n",
      "  Building wheel for rpy2 (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rpy2: filename=rpy2-3.5.16-cp312-cp312-linux_x86_64.whl size=261942 sha256=c6c2bb58a09f0445639dbd705013a6c548d685bbd6a95c6bcd066da0b4b987f5\n",
      "  Stored in directory: /home/mahendra/.cache/pip/wheels/1b/7a/26/1d103e01b538d35ccbc2247a5b0f55fcf98a973d032a1282e5\n",
      "Successfully built rpy2\n",
      "Installing collected packages: tzlocal, rpy2\n",
      "Successfully installed rpy2-3.5.16 tzlocal-5.2\n",
      "Requirement already satisfied: pydeseq2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (0.4.11)\n",
      "Requirement already satisfied: anndata>=0.8.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pydeseq2) (0.10.9)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pydeseq2) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.4.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pydeseq2) (2.2.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pydeseq2) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.11.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pydeseq2) (1.14.1)\n",
      "Requirement already satisfied: matplotlib>=3.6.2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pydeseq2) (3.8.4)\n",
      "Requirement already satisfied: array-api-compat!=1.5,>1.4 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from anndata>=0.8.0->pydeseq2) (1.8)\n",
      "Requirement already satisfied: h5py>=3.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from anndata>=0.8.0->pydeseq2) (3.11.0)\n",
      "Requirement already satisfied: natsort in /home/mahendra/anaconda3/lib/python3.12/site-packages (from anndata>=0.8.0->pydeseq2) (8.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from anndata>=0.8.0->pydeseq2) (23.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.6.2->pydeseq2) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.6.2->pydeseq2) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.6.2->pydeseq2) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.6.2->pydeseq2) (1.4.4)\n",
      "Requirement already satisfied: pillow>=8 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.6.2->pydeseq2) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.6.2->pydeseq2) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib>=3.6.2->pydeseq2) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->pydeseq2) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas>=1.4.0->pydeseq2) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from scikit-learn>=1.1.0->pydeseq2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from scikit-learn>=1.1.0->pydeseq2) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib>=3.6.2->pydeseq2) (1.16.0)\n",
      "Requirement already satisfied: bioinfokit in /home/mahendra/anaconda3/lib/python3.12/site-packages (2.1.4)\n",
      "Requirement already satisfied: pandas in /home/mahendra/anaconda3/lib/python3.12/site-packages (from bioinfokit) (2.2.2)\n",
      "Requirement already satisfied: numpy in /home/mahendra/anaconda3/lib/python3.12/site-packages (from bioinfokit) (1.26.4)\n",
      "Requirement already satisfied: matplotlib in /home/mahendra/anaconda3/lib/python3.12/site-packages (from bioinfokit) (3.8.4)\n",
      "Requirement already satisfied: scipy in /home/mahendra/anaconda3/lib/python3.12/site-packages (from bioinfokit) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn in /home/mahendra/anaconda3/lib/python3.12/site-packages (from bioinfokit) (1.4.2)\n",
      "Requirement already satisfied: seaborn in /home/mahendra/anaconda3/lib/python3.12/site-packages (from bioinfokit) (0.13.2)\n",
      "Requirement already satisfied: matplotlib-venn in /home/mahendra/anaconda3/lib/python3.12/site-packages (from bioinfokit) (1.1.1)\n",
      "Requirement already satisfied: tabulate in /home/mahendra/anaconda3/lib/python3.12/site-packages (from bioinfokit) (0.9.0)\n",
      "Requirement already satisfied: statsmodels in /home/mahendra/anaconda3/lib/python3.12/site-packages (from bioinfokit) (0.14.2)\n",
      "Requirement already satisfied: textwrap3 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from bioinfokit) (0.9.2)\n",
      "Requirement already satisfied: adjustText in /home/mahendra/anaconda3/lib/python3.12/site-packages (from bioinfokit) (1.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib->bioinfokit) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib->bioinfokit) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib->bioinfokit) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib->bioinfokit) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib->bioinfokit) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib->bioinfokit) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib->bioinfokit) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from matplotlib->bioinfokit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas->bioinfokit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas->bioinfokit) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from scikit-learn->bioinfokit) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from scikit-learn->bioinfokit) (2.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from statsmodels->bioinfokit) (0.5.6)\n",
      "Requirement already satisfied: six in /home/mahendra/anaconda3/lib/python3.12/site-packages (from patsy>=0.5.6->statsmodels->bioinfokit) (1.16.0)\n",
      "Requirement already satisfied: jupyterlab in /home/mahendra/anaconda3/lib/python3.12/site-packages (4.0.11)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: ipykernel in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyterlab) (6.28.0)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyterlab) (3.1.4)\n",
      "Requirement already satisfied: jupyter-core in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyterlab) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyterlab) (2.2.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyterlab) (2.14.1)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.19.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyterlab) (2.25.1)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyterlab) (0.2.3)\n",
      "Requirement already satisfied: packaging in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyterlab) (23.2)\n",
      "Requirement already satisfied: tornado>=6.2.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyterlab) (6.4.1)\n",
      "Requirement already satisfied: traitlets in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyterlab) (5.14.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jinja2>=3.0.3->jupyterlab) (2.1.3)\n",
      "Requirement already satisfied: anyio>=3.1.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (4.2.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (21.3.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (8.6.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.4.4)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.10.0)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (5.9.2)\n",
      "Requirement already satisfied: overrides>=5.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (7.4.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.14.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (25.1.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (0.17.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-server<3,>=2.4.0->jupyterlab) (1.8.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-core->jupyterlab) (3.10.0)\n",
      "Requirement already satisfied: babel>=2.10 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab) (2.11.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab) (0.9.6)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab) (4.19.2)\n",
      "Requirement already satisfied: requests>=2.31 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab) (2.32.2)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from ipykernel->jupyterlab) (0.2.1)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from ipykernel->jupyterlab) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from ipykernel->jupyterlab) (8.25.0)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from ipykernel->jupyterlab) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in /home/mahendra/anaconda3/lib/python3.12/site-packages (from ipykernel->jupyterlab) (1.6.0)\n",
      "Requirement already satisfied: psutil in /home/mahendra/anaconda3/lib/python3.12/site-packages (from ipykernel->jupyterlab) (5.9.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/mahendra/anaconda3/lib/python3.12/site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (21.2.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from babel>=2.10->jupyterlab-server<3,>=2.19.0->jupyterlab) (2024.1)\n",
      "Requirement already satisfied: decorator in /home/mahendra/anaconda3/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab) (0.18.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /home/mahendra/anaconda3/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from ipython>=7.23.1->ipykernel->jupyterlab) (4.8.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab) (0.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.9.0.post0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (6.0.1)\n",
      "Requirement already satisfied: rfc3339-validator in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /home/mahendra/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/mahendra/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.1.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in /home/mahendra/anaconda3/lib/python3.12/site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.19.0->jupyterlab) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.19.0->jupyterlab) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.19.0->jupyterlab) (2024.8.30)\n",
      "Requirement already satisfied: ptyprocess in /home/mahendra/anaconda3/lib/python3.12/site-packages (from terminado>=0.8.3->jupyter-server<3,>=2.4.0->jupyterlab) (0.7.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /home/mahendra/anaconda3/lib/python3.12/site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyterlab) (0.8.3)\n",
      "Requirement already satisfied: fqdn in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (2.1)\n",
      "Requirement already satisfied: uri-template in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (24.8.0)\n",
      "Requirement already satisfied: wcwidth in /home/mahendra/anaconda3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->jupyterlab) (0.2.5)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab) (2.5)\n",
      "Requirement already satisfied: executing in /home/mahendra/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyterlab) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /home/mahendra/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyterlab) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /home/mahendra/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyterlab) (0.2.2)\n",
      "Requirement already satisfied: pycparser in /home/mahendra/anaconda3/lib/python3.12/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab) (1.2.3)\n",
      "Requirement already satisfied: scikit-learn in /home/mahendra/anaconda3/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: statsmodels in /home/mahendra/anaconda3/lib/python3.12/site-packages (0.14.2)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from statsmodels) (1.26.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from statsmodels) (1.14.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from statsmodels) (2.2.2)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six in /home/mahendra/anaconda3/lib/python3.12/site-packages (from patsy>=0.5.6->statsmodels) (1.16.0)\n",
      "Requirement already satisfied: plotly in /home/mahendra/anaconda3/lib/python3.12/site-packages (5.22.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/mahendra/anaconda3/lib/python3.12/site-packages (from plotly) (8.2.2)\n",
      "Requirement already satisfied: packaging in /home/mahendra/anaconda3/lib/python3.12/site-packages (from plotly) (23.2)\n",
      "Requirement already satisfied: tqdm in /home/mahendra/anaconda3/lib/python3.12/site-packages (4.66.4)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: System Updates\n",
    "!pip install --upgrade pip\n",
    "!apt-get update && apt-get upgrade -y                                    # Update and upgrade package list\n",
    "\n",
    "# Step 2: Install Key Tools and Libraries\n",
    "!pip install pysradb --upgrade                                           # Install pysradb (for SRA database access)\n",
    "!apt-get install fastqc --upgrade -y                                     # Install FastQC (for quality control)\n",
    "!pip install multiqc                                                     # Install MultiQC (for quality control report generation)\n",
    "!apt-get update && apt-get install -y sra-toolkit                        # Install SRA Toolkit (for downloading data from SRA)\n",
    "!pip install cutadapt                                                    # Install cutadapt (for adapter trimming)\n",
    "!pip install samtools                                                    # Install samtools (for BAM/SAM file manipulation)\n",
    "!pip install picard                                                      # Install picard (for working with BAM files, deduplication)\n",
    "!pip install biopython                                                   # Install Biopython (for biological computations)\n",
    "!apt-get update && apt-get install -y bwa                                # Install BWA (for sequence alignment)\n",
    "!apt-get install -y default-jdk                                          # Install JDK (for running Java-based tools like Picard)\n",
    "\n",
    "# Step 3: Download Picard JAR File\n",
    "!wget https://github.com/broadinstitute/picard/releases/download/2.27.4/picard.jar  \n",
    "!chmod +x /home/mahendra/Desktop/Python/Project/picard.jar               # Make picard.jar executable\n",
    "# Optional: Install Picard via Bioconda # Install picard and qualimap using bioconda\n",
    "!conda install -c conda-forge -c bioconda openjdk=8 picard -y\n",
    "!conda install -c bioconda qualimap -y\n",
    "\n",
    "# Step 4: Install Additional Python Libraries for RNA-Seq Analysis\n",
    "!pip install pandas                                                      # Install pandas (for data manipulation)\n",
    "!pip install numpy                                                       # Install numpy (for numerical computations)\n",
    "!pip install matplotlib                                                  # Install matplotlib (for visualization)\n",
    "!pip install seaborn                                                     # Install seaborn (for advanced data visualization)\n",
    "!pip install scipy                                                       # Install scipy (for statistical analysis)\n",
    "!pip install pysam                                                       # Install pysam (for BAM/SAM file reading and writing)\n",
    "!pip install gffutils                                                    # Install gffutils (for working with GFF files)\n",
    "!pip install rpy2                                                        # Install rpy2 (for interfacing R with Python, useful for DESeq2 and edgeR)\n",
    "!pip install pydeseq2                                                    # Install pyDESeq2\n",
    "!pip install bioinfokit                                                  # Install bioinfokit (for statistical analysis)\n",
    "!pip install jupyterlab                                                  # Optional: Install JupyterLab (if running locally)\n",
    "!pip install scikit-learn                                                # Install scikit-learn (for machine learning algorithms)\n",
    "!pip install statsmodels                                                 # Install statsmodels (for statistical modeling)\n",
    "!pip install plotly                                                      # Install Plotly (for interactive plots)\n",
    "!pip install tqdm                                                        # Install tqdm (for progress bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63f94d7b-2505-4a82-810c-4f5fe47d6e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Python packages imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Importing installed libraries and Python packages\n",
    "try:\n",
    "  import pandas as pd                                                     # For data manipulation\n",
    "  import pysradb                                                          # For accessing and managing SRA data\n",
    "  import subprocess                                                       # For executing system commands from Python\n",
    "  import os                                                               # For file management\n",
    "  from tqdm import tqdm                                                   # For creating progress bars\n",
    "  import numpy as np                                                      # For numerical computations\n",
    "  import scipy.stats as stats                                             # For statistical analysis\n",
    "  import numpy as np                                                      # For numerical computations\n",
    "  import matplotlib.pyplot as plt                                         # For plotting\n",
    "  import seaborn as sns                                                   # For creating advanced visualizations\n",
    "  import pysam                                                            # For working with BAM and SAM files\n",
    "  import gffutils                                                         # For handling GFF files\n",
    "  import pydeseq2                                                         # For differential gene expression analysis\n",
    "  from sklearn.preprocessing import StandardScaler                        # For preprocessing the data\n",
    "  from pydeseq2.dds import DeseqDataSet                                   # For Read counts modeling with the DeseqDataSet class\n",
    "  from pydeseq2.ds import DeseqStats                                      # Statistical analysis with the DeseqStats class\n",
    "  from pydeseq2.default_inference import DefaultInference  \n",
    "  from IPython.display import IFrame                                      # For Reading the web frame\n",
    "  import warnings                                                         # For hiding the warning text\n",
    "  from sklearn.exceptions import ConvergenceWarning\n",
    "  warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "  print(\"All Python packages imported successfully.\")\n",
    "except ImportError as e:\n",
    "  print(f\"Import failed: {e}\")                                            # Print error message if import fails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1181cb71-e205-49a3-901c-1a3be6f37176",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"\n",
    "    background-image: url('https://i.postimg.cc/K87ByXmr/stage5.jpg');\n",
    "    background-size: cover;\n",
    "    background-repeat: no-repeat;\n",
    "    font-family: 'Arial', sans-serif;\n",
    "    font-size: 24px;\n",
    "    color: white;\n",
    "    text-align: center;\n",
    "    border-radius: 15px 50px;\n",
    "    padding: 20px 40px;\n",
    "    margin: 20px 0;\n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\">\n",
    "    <b>Sample information</b>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a234dc16-69a2-4253-8c6b-462e99405dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>SRR_ID</th>\n",
       "      <th>Spots</th>\n",
       "      <th>Bases</th>\n",
       "      <th>Size (Mb)</th>\n",
       "      <th>Published</th>\n",
       "      <th>Instrument</th>\n",
       "      <th>Strategy</th>\n",
       "      <th>Source</th>\n",
       "      <th>Layout</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alzheimer's whole brain</td>\n",
       "      <td>SRR087416</td>\n",
       "      <td>14720816</td>\n",
       "      <td>529.9M</td>\n",
       "      <td>362.1</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>Illumina Genome Analyzer II</td>\n",
       "      <td>WGS</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>SINGLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Normal brain, temporal lobe</td>\n",
       "      <td>SRR085471</td>\n",
       "      <td>15256752</td>\n",
       "      <td>549.2M</td>\n",
       "      <td>372.8</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>Illumina Genome Analyzer II</td>\n",
       "      <td>WGS</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>SINGLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alzheimer's brain, temporal lobe</td>\n",
       "      <td>SRR085473</td>\n",
       "      <td>14227702</td>\n",
       "      <td>498M</td>\n",
       "      <td>350.2</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>Illumina Genome Analyzer II</td>\n",
       "      <td>WGS</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>SINGLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Normal brain, frontal lobe</td>\n",
       "      <td>SRR085474</td>\n",
       "      <td>15772947</td>\n",
       "      <td>552.1M</td>\n",
       "      <td>391.0</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>Illumina Genome Analyzer II</td>\n",
       "      <td>WGS</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>SINGLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alzheimer's brain, frontal lobe</td>\n",
       "      <td>SRR085726</td>\n",
       "      <td>15228832</td>\n",
       "      <td>533M</td>\n",
       "      <td>377.3</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>Illumina Genome Analyzer II</td>\n",
       "      <td>WGS</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>SINGLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Normal whole brain</td>\n",
       "      <td>SRR085725</td>\n",
       "      <td>13442077</td>\n",
       "      <td>483.9M</td>\n",
       "      <td>324.0</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>Illumina Genome Analyzer II</td>\n",
       "      <td>WGS</td>\n",
       "      <td>TRANSCRIPTOMIC</td>\n",
       "      <td>SINGLE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Sample     SRR_ID     Spots   Bases  Size (Mb)  \\\n",
       "0           Alzheimer's whole brain  SRR087416  14720816  529.9M      362.1   \n",
       "1       Normal brain, temporal lobe  SRR085471  15256752  549.2M      372.8   \n",
       "2  Alzheimer's brain, temporal lobe  SRR085473  14227702    498M      350.2   \n",
       "3        Normal brain, frontal lobe  SRR085474  15772947  552.1M      391.0   \n",
       "4   Alzheimer's brain, frontal lobe  SRR085726  15228832    533M      377.3   \n",
       "5                Normal whole brain  SRR085725  13442077  483.9M      324.0   \n",
       "\n",
       "    Published                   Instrument Strategy          Source  Layout  \n",
       "0  2011-01-05  Illumina Genome Analyzer II      WGS  TRANSCRIPTOMIC  SINGLE  \n",
       "1  2011-01-05  Illumina Genome Analyzer II      WGS  TRANSCRIPTOMIC  SINGLE  \n",
       "2  2011-01-05  Illumina Genome Analyzer II      WGS  TRANSCRIPTOMIC  SINGLE  \n",
       "3  2011-01-05  Illumina Genome Analyzer II      WGS  TRANSCRIPTOMIC  SINGLE  \n",
       "4  2011-01-05  Illumina Genome Analyzer II      WGS  TRANSCRIPTOMIC  SINGLE  \n",
       "5  2011-01-05  Illumina Genome Analyzer II      WGS  TRANSCRIPTOMIC  SINGLE  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the data frame for sample information\n",
    "data = {\n",
    "    'Sample': [\n",
    "        \"Alzheimer's whole brain\",\n",
    "        \"Normal brain, temporal lobe\",\n",
    "        \"Alzheimer's brain, temporal lobe\",\n",
    "        \"Normal brain, frontal lobe\",\n",
    "        \"Alzheimer's brain, frontal lobe\",\n",
    "        \"Normal whole brain\"\n",
    "    ],\n",
    "    'SRR_ID': [\n",
    "        \"SRR087416\", \"SRR085471\", \"SRR085473\", \"SRR085474\", \"SRR085726\", \"SRR085725\"\n",
    "    ],\n",
    "    'Spots': [\n",
    "        14720816, 15256752, 14227702, 15772947, 15228832, 13442077\n",
    "    ],\n",
    "    'Bases': [\n",
    "        \"529.9M\", \"549.2M\", \"498M\", \"552.1M\", \"533M\", \"483.9M\"\n",
    "    ],\n",
    "    'Size (Mb)': [\n",
    "        362.1, 372.8, 350.2, 391.0, 377.3, 324.0\n",
    "    ],\n",
    "    'Published': [\n",
    "        \"2011-01-05\", \"2011-01-05\", \"2011-01-05\", \"2011-01-05\", \"2011-01-05\", \"2011-01-05\"\n",
    "    ],\n",
    "    'Instrument': [\n",
    "        \"Illumina Genome Analyzer II\",\n",
    "        \"Illumina Genome Analyzer II\",\n",
    "        \"Illumina Genome Analyzer II\",\n",
    "        \"Illumina Genome Analyzer II\",\n",
    "        \"Illumina Genome Analyzer II\",\n",
    "        \"Illumina Genome Analyzer II\"\n",
    "    ],\n",
    "    'Strategy': [\n",
    "        \"WGS\", \"WGS\", \"WGS\", \"WGS\", \"WGS\", \"WGS\"\n",
    "    ],\n",
    "    'Source': [\n",
    "        \"TRANSCRIPTOMIC\", \"TRANSCRIPTOMIC\", \"TRANSCRIPTOMIC\", \"TRANSCRIPTOMIC\", \"TRANSCRIPTOMIC\", \"TRANSCRIPTOMIC\"\n",
    "    ],\n",
    "    'Layout': [\n",
    "        \"SINGLE\", \"SINGLE\", \"SINGLE\", \"SINGLE\", \"SINGLE\", \"SINGLE\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "# Display the DataFrame\n",
    "df.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e939609c-1399-4bdf-b565-3ecf08c25f25",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"\n",
    "    background-image: url('https://i.postimg.cc/K87ByXmr/stage5.jpg');\n",
    "    background-size: cover;\n",
    "    background-repeat: no-repeat;\n",
    "    font-family: 'Arial', sans-serif;\n",
    "    font-size: 24px;\n",
    "    color: white;\n",
    "    text-align: center;\n",
    "    border-radius: 15px 50px;\n",
    "    padding: 20px 40px;\n",
    "    margin: 20px 0;\n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\">\n",
    "    <b>Download Dataset</b>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2323108-1495-4768-a4f8-61f04bfa667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Please Say \"Y\" to Download the Dataset or Run this code on Google Colab.........\n",
    "\n",
    "sra = pysradb.SRAweb()                                            # Initialize SRAweb object\n",
    "study_accession = \"SRA027308\"                                     # Define the study accession\n",
    "\n",
    "                                                                  # Get metadata for the study accession\n",
    "try:\n",
    "    metadata_df = sra.sra_metadata(study_accession)\n",
    "    run_accessions = metadata_df['run_accession'].tolist()        # Access run_accession column\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving metadata for {study_accession}: {e}\")\n",
    "    run_accessions = []\n",
    "\n",
    "                                                                  # Check if run_accessions is empty and handle it\n",
    "if not run_accessions:\n",
    "    print(\"No run accessions found for the study. Skipping download.\")\n",
    "else:\n",
    "                                                                  # Download the SRA files using run accessions\n",
    "    sra.download(run_accessions, out_dir='sra_downloads/')\n",
    "    print(f\"Downloaded SRA files for study {study_accession} to 'sra_downloads/' directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d35c140-9271-4116-ba84-5fd18d768f98",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"\n",
    "    background-image: url('https://i.postimg.cc/K87ByXmr/stage5.jpg');\n",
    "    background-size: cover;\n",
    "    background-repeat: no-repeat;\n",
    "    font-family: 'Arial', sans-serif;\n",
    "    font-size: 24px;\n",
    "    color: white;\n",
    "    text-align: center;\n",
    "    border-radius: 15px 50px;\n",
    "    padding: 20px 40px;\n",
    "    margin: 20px 0;\n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\">\n",
    "    <b>Converting the .SRA files into .fastq format</b>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2193c8d-88a8-4c41-af82-cff301b26129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spots read      : 13,442,077\n",
      "reads read      : 13,442,077\n",
      "reads written   : 13,442,077\n",
      "spots read      : 14,720,816\n",
      "reads read      : 14,720,816\n",
      "reads written   : 14,720,816\n",
      "spots read      : 15,256,752\n",
      "reads read      : 15,256,752\n",
      "reads written   : 15,256,752\n",
      "spots read      : 14,227,702\n",
      "reads read      : 14,227,702\n",
      "reads written   : 14,227,702\n",
      "spots read      : 15,772,947\n",
      "reads read      : 15,772,947\n",
      "reads written   : 15,772,947\n",
      "spots read      : 15,228,832\n",
      "reads read      : 15,228,832\n",
      "reads written   : 15,228,832\n"
     ]
    }
   ],
   "source": [
    "# Define a list of SRA files with path\n",
    "sra_files = [\n",
    "    \"/home/mahendra/Desktop/Python/Project/sra_downloads/SRP004879/SRX035170/SRR085725.sra\",\n",
    "    \"/home/mahendra/Desktop/Python/Project/sra_downloads/SRP004879/SRX035760/SRR087416.sra\",\n",
    "    \"/home/mahendra/Desktop/Python/Project/sra_downloads/SRP004879/SRX034874/SRR085471.sra\",\n",
    "    \"/home/mahendra/Desktop/Python/Project/sra_downloads/SRP004879/SRX035166/SRR085473.sra\",\n",
    "    \"/home/mahendra/Desktop/Python/Project/sra_downloads/SRP004879/SRX035167/SRR085474.sra\",\n",
    "    \"/home/mahendra/Desktop/Python/Project/sra_downloads/SRP004879/SRX035171/SRR085726.sra\"\n",
    "]\n",
    "\n",
    "# Create a FastQ folder if it doesn't exist\n",
    "output_dir = \"FastQ\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop through and run fasterq-dump for each file\n",
    "for sra_file in sra_files:\n",
    "  cmd = [\"fasterq-dump\", \"--split-files\", sra_file]\n",
    "  subprocess.run(cmd)\n",
    "# Move the output FASTQ files to the FastQ folder\n",
    "  fastq_files = [f for f in os.listdir('.') if f.endswith('.fastq')]\n",
    "  for fastq in fastq_files:\n",
    "    subprocess.run([\"mv\", fastq, os.path.join(output_dir, fastq)])\n",
    "# Compress the moved FASTQ files\n",
    "    subprocess.run([\"gzip\", os.path.join(output_dir, fastq)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a940147-9c14-412f-bd40-a8d87ddad4aa",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"\n",
    "    background-image: url('https://i.postimg.cc/K87ByXmr/stage5.jpg');\n",
    "    background-size: cover;\n",
    "    background-repeat: no-repeat;\n",
    "    font-family: 'Arial', sans-serif;\n",
    "    font-size: 24px;\n",
    "    color: white;\n",
    "    text-align: center;\n",
    "    border-radius: 15px 50px;\n",
    "    padding: 20px 40px;\n",
    "    margin: 20px 0;\n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\">\n",
    "    <b>Initial Quality Check</b>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a9df0c9-2d55-4915-830a-69b889b94391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application/gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR087416.fastq.gz\n",
      "Approx 5% complete for SRR087416.fastq.gz\n",
      "Approx 10% complete for SRR087416.fastq.gz\n",
      "Approx 15% complete for SRR087416.fastq.gz\n",
      "Approx 20% complete for SRR087416.fastq.gz\n",
      "Approx 25% complete for SRR087416.fastq.gz\n",
      "Approx 30% complete for SRR087416.fastq.gz\n",
      "Approx 35% complete for SRR087416.fastq.gz\n",
      "Approx 40% complete for SRR087416.fastq.gz\n",
      "Approx 45% complete for SRR087416.fastq.gz\n",
      "Approx 50% complete for SRR087416.fastq.gz\n",
      "Approx 55% complete for SRR087416.fastq.gz\n",
      "Approx 60% complete for SRR087416.fastq.gz\n",
      "Approx 65% complete for SRR087416.fastq.gz\n",
      "Approx 70% complete for SRR087416.fastq.gz\n",
      "Approx 75% complete for SRR087416.fastq.gz\n",
      "Approx 80% complete for SRR087416.fastq.gz\n",
      "Approx 85% complete for SRR087416.fastq.gz\n",
      "Approx 90% complete for SRR087416.fastq.gz\n",
      "Approx 95% complete for SRR087416.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR087416.fastq.gz\n",
      "application/gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR085725.fastq.gz\n",
      "Approx 5% complete for SRR085725.fastq.gz\n",
      "Approx 10% complete for SRR085725.fastq.gz\n",
      "Approx 15% complete for SRR085725.fastq.gz\n",
      "Approx 20% complete for SRR085725.fastq.gz\n",
      "Approx 25% complete for SRR085725.fastq.gz\n",
      "Approx 30% complete for SRR085725.fastq.gz\n",
      "Approx 35% complete for SRR085725.fastq.gz\n",
      "Approx 40% complete for SRR085725.fastq.gz\n",
      "Approx 45% complete for SRR085725.fastq.gz\n",
      "Approx 50% complete for SRR085725.fastq.gz\n",
      "Approx 55% complete for SRR085725.fastq.gz\n",
      "Approx 60% complete for SRR085725.fastq.gz\n",
      "Approx 65% complete for SRR085725.fastq.gz\n",
      "Approx 70% complete for SRR085725.fastq.gz\n",
      "Approx 75% complete for SRR085725.fastq.gz\n",
      "Approx 80% complete for SRR085725.fastq.gz\n",
      "Approx 85% complete for SRR085725.fastq.gz\n",
      "Approx 90% complete for SRR085725.fastq.gz\n",
      "Approx 95% complete for SRR085725.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR085725.fastq.gz\n",
      "application/gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR085471.fastq.gz\n",
      "Approx 5% complete for SRR085471.fastq.gz\n",
      "Approx 10% complete for SRR085471.fastq.gz\n",
      "Approx 15% complete for SRR085471.fastq.gz\n",
      "Approx 20% complete for SRR085471.fastq.gz\n",
      "Approx 25% complete for SRR085471.fastq.gz\n",
      "Approx 30% complete for SRR085471.fastq.gz\n",
      "Approx 35% complete for SRR085471.fastq.gz\n",
      "Approx 40% complete for SRR085471.fastq.gz\n",
      "Approx 45% complete for SRR085471.fastq.gz\n",
      "Approx 50% complete for SRR085471.fastq.gz\n",
      "Approx 55% complete for SRR085471.fastq.gz\n",
      "Approx 60% complete for SRR085471.fastq.gz\n",
      "Approx 65% complete for SRR085471.fastq.gz\n",
      "Approx 70% complete for SRR085471.fastq.gz\n",
      "Approx 75% complete for SRR085471.fastq.gz\n",
      "Approx 80% complete for SRR085471.fastq.gz\n",
      "Approx 85% complete for SRR085471.fastq.gz\n",
      "Approx 90% complete for SRR085471.fastq.gz\n",
      "Approx 95% complete for SRR085471.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR085471.fastq.gz\n",
      "application/gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR085473.fastq.gz\n",
      "Approx 5% complete for SRR085473.fastq.gz\n",
      "Approx 10% complete for SRR085473.fastq.gz\n",
      "Approx 15% complete for SRR085473.fastq.gz\n",
      "Approx 20% complete for SRR085473.fastq.gz\n",
      "Approx 25% complete for SRR085473.fastq.gz\n",
      "Approx 30% complete for SRR085473.fastq.gz\n",
      "Approx 35% complete for SRR085473.fastq.gz\n",
      "Approx 40% complete for SRR085473.fastq.gz\n",
      "Approx 45% complete for SRR085473.fastq.gz\n",
      "Approx 50% complete for SRR085473.fastq.gz\n",
      "Approx 55% complete for SRR085473.fastq.gz\n",
      "Approx 60% complete for SRR085473.fastq.gz\n",
      "Approx 65% complete for SRR085473.fastq.gz\n",
      "Approx 70% complete for SRR085473.fastq.gz\n",
      "Approx 75% complete for SRR085473.fastq.gz\n",
      "Approx 80% complete for SRR085473.fastq.gz\n",
      "Approx 85% complete for SRR085473.fastq.gz\n",
      "Approx 90% complete for SRR085473.fastq.gz\n",
      "Approx 95% complete for SRR085473.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR085473.fastq.gz\n",
      "application/gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR085474.fastq.gz\n",
      "Approx 5% complete for SRR085474.fastq.gz\n",
      "Approx 10% complete for SRR085474.fastq.gz\n",
      "Approx 15% complete for SRR085474.fastq.gz\n",
      "Approx 20% complete for SRR085474.fastq.gz\n",
      "Approx 25% complete for SRR085474.fastq.gz\n",
      "Approx 30% complete for SRR085474.fastq.gz\n",
      "Approx 35% complete for SRR085474.fastq.gz\n",
      "Approx 40% complete for SRR085474.fastq.gz\n",
      "Approx 45% complete for SRR085474.fastq.gz\n",
      "Approx 50% complete for SRR085474.fastq.gz\n",
      "Approx 55% complete for SRR085474.fastq.gz\n",
      "Approx 60% complete for SRR085474.fastq.gz\n",
      "Approx 65% complete for SRR085474.fastq.gz\n",
      "Approx 70% complete for SRR085474.fastq.gz\n",
      "Approx 75% complete for SRR085474.fastq.gz\n",
      "Approx 80% complete for SRR085474.fastq.gz\n",
      "Approx 85% complete for SRR085474.fastq.gz\n",
      "Approx 90% complete for SRR085474.fastq.gz\n",
      "Approx 95% complete for SRR085474.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR085474.fastq.gz\n",
      "application/gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR085726.fastq.gz\n",
      "Approx 5% complete for SRR085726.fastq.gz\n",
      "Approx 10% complete for SRR085726.fastq.gz\n",
      "Approx 15% complete for SRR085726.fastq.gz\n",
      "Approx 20% complete for SRR085726.fastq.gz\n",
      "Approx 25% complete for SRR085726.fastq.gz\n",
      "Approx 30% complete for SRR085726.fastq.gz\n",
      "Approx 35% complete for SRR085726.fastq.gz\n",
      "Approx 40% complete for SRR085726.fastq.gz\n",
      "Approx 45% complete for SRR085726.fastq.gz\n",
      "Approx 50% complete for SRR085726.fastq.gz\n",
      "Approx 55% complete for SRR085726.fastq.gz\n",
      "Approx 60% complete for SRR085726.fastq.gz\n",
      "Approx 65% complete for SRR085726.fastq.gz\n",
      "Approx 70% complete for SRR085726.fastq.gz\n",
      "Approx 75% complete for SRR085726.fastq.gz\n",
      "Approx 80% complete for SRR085726.fastq.gz\n",
      "Approx 85% complete for SRR085726.fastq.gz\n",
      "Approx 90% complete for SRR085726.fastq.gz\n",
      "Approx 95% complete for SRR085726.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR085726.fastq.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;208m///\u001b[0m \u001b]8;id=240177;https://multiqc.info\u001b\\\u001b[1mMultiQC\u001b[0m\u001b]8;;\u001b\\ 🔍 \u001b[2mv1.25.1\u001b[0m\n",
      "\n",
      "\u001b[34m       file_search\u001b[0m | Search path: /home/mahendra/Desktop/Python/Project/fastqc_output\n",
      "\u001b[2K         \u001b[34msearching\u001b[0m | \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m12/12\u001b[0m   \n",
      "\u001b[?25h\u001b[34m            fastqc\u001b[0m | Found 6 reports\n",
      "\u001b[34m     write_results\u001b[0m | Data        : multiqc_output/multiqc_data\n",
      "\u001b[34m     write_results\u001b[0m | Report      : multiqc_output/multiqc_report.html\n",
      "\u001b[34m           multiqc\u001b[0m | MultiQC complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['multiqc', 'fastqc_output', '-o', 'multiqc_output'], returncode=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of FastQ files (with path)\n",
    "fastq_files = [os.path.join('FastQ', f) for f in ['SRR087416.fastq.gz', 'SRR085725.fastq.gz','SRR085471.fastq.gz','SRR085473.fastq.gz','SRR085474.fastq.gz', 'SRR085726.fastq.gz']]\n",
    "\n",
    "# Directory to store FastQC results\n",
    "output_dir_fastqc = 'fastqc_output'\n",
    "os.makedirs(output_dir_fastqc, exist_ok=True)\n",
    "\n",
    "# Run FastQC on all files\n",
    "# Define parameters for threads and kmers\n",
    "threads = 4   # Set the number of threads, e.g., 4 (adjust as needed based on available memory)\n",
    "kmers = 10    # Set the kmer length, e.g., 7 (ensure it's between 2 and 10)\n",
    "\n",
    "# Run FastQC on all files with specified threads and kmer length\n",
    "for fastq_file in fastq_files:\n",
    "    subprocess.run(['fastqc', fastq_file, '-o', output_dir_fastqc, '-t', str(threads), '-k', str(kmers)])\n",
    "\n",
    "\n",
    "# After FastQC, run MultiQC to aggregate the results\n",
    "output_dir_multiqc = 'multiqc_output'\n",
    "os.makedirs(output_dir_multiqc, exist_ok=True)\n",
    "subprocess.run(['multiqc', output_dir_fastqc, '-o', output_dir_multiqc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72b4a37-ba48-48cf-ad56-fd12a250e030",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"\n",
    "    background-image: url('https://i.postimg.cc/K87ByXmr/stage5.jpg');\n",
    "    background-size: cover;\n",
    "    background-repeat: no-repeat;\n",
    "    font-family: 'Arial', sans-serif;\n",
    "    font-size: 24px;\n",
    "    color: white;\n",
    "    text-align: center;\n",
    "    border-radius: 15px 50px;\n",
    "    padding: 20px 40px;\n",
    "    margin: 20px 0;\n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\">\n",
    "    <b>Adapter Trimming using cutadapt</b>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b8beb28-8a75-4db9-bb67-93b058487d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is cutadapt 4.9 with Python 3.12.2\n",
      "Command line parameters: -a AGATCGGAAGAGC -q 30 -o trimmed_fastq/SRR087416_trimmed.fastq.gz FastQ/SRR087416.fastq.gz\n",
      "Processing single-end reads on 1 core ...\n",
      "Finished in 63.311 s (4.301 µs/read; 13.95 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:              14,720,816\n",
      "Reads with adapters:                   337,690 (2.3%)\n",
      "Reads written (passing filters):    14,720,816 (100.0%)\n",
      "\n",
      "Total basepairs processed:   529,949,376 bp\n",
      "Quality-trimmed:                       0 bp (0.0%)\n",
      "Total written (filtered):    528,821,475 bp (99.8%)\n",
      "\n",
      "=== Adapter 1 ===\n",
      "\n",
      "Sequence: AGATCGGAAGAGC; Type: regular 3'; Length: 13; Trimmed: 337690 times\n",
      "\n",
      "Minimum overlap: 3\n",
      "No. of allowed errors:\n",
      "1-9 bp: 0; 10-13 bp: 1\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 29.5%\n",
      "  C: 27.2%\n",
      "  G: 26.1%\n",
      "  T: 17.1%\n",
      "  none/other: 0.2%\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t269225\t230012.8\t0\t269225\n",
      "4\t54562\t57503.2\t0\t54562\n",
      "5\t9431\t14375.8\t0\t9431\n",
      "6\t1288\t3593.9\t0\t1288\n",
      "7\t616\t898.5\t0\t616\n",
      "8\t372\t224.6\t0\t372\n",
      "9\t495\t56.2\t0\t327 168\n",
      "10\t348\t14.0\t1\t152 196\n",
      "11\t208\t3.5\t1\t84 124\n",
      "12\t118\t0.9\t1\t57 61\n",
      "13\t55\t0.2\t1\t43 12\n",
      "14\t57\t0.2\t1\t51 6\n",
      "15\t41\t0.2\t1\t35 6\n",
      "16\t29\t0.2\t1\t18 11\n",
      "17\t130\t0.2\t1\t114 16\n",
      "18\t13\t0.2\t1\t7 6\n",
      "19\t10\t0.2\t1\t6 4\n",
      "20\t8\t0.2\t1\t7 1\n",
      "21\t12\t0.2\t1\t3 9\n",
      "22\t16\t0.2\t1\t8 8\n",
      "23\t9\t0.2\t1\t6 3\n",
      "24\t11\t0.2\t1\t8 3\n",
      "25\t14\t0.2\t1\t6 8\n",
      "26\t19\t0.2\t1\t12 7\n",
      "27\t18\t0.2\t1\t8 10\n",
      "28\t16\t0.2\t1\t5 11\n",
      "29\t20\t0.2\t1\t13 7\n",
      "30\t10\t0.2\t1\t9 1\n",
      "31\t23\t0.2\t1\t16 7\n",
      "32\t23\t0.2\t1\t17 6\n",
      "33\t27\t0.2\t1\t10 17\n",
      "34\t24\t0.2\t1\t21 3\n",
      "35\t19\t0.2\t1\t12 7\n",
      "36\t423\t0.2\t1\t3 420\n",
      "This is cutadapt 4.9 with Python 3.12.2\n",
      "Command line parameters: -a AGATCGGAAGAGC -q 30 -o trimmed_fastq/SRR085725_trimmed.fastq.gz FastQ/SRR085725.fastq.gz\n",
      "Processing single-end reads on 1 core ...\n",
      "Finished in 57.631 s (4.287 µs/read; 13.99 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:              13,442,077\n",
      "Reads with adapters:                   329,378 (2.5%)\n",
      "Reads written (passing filters):    13,442,077 (100.0%)\n",
      "\n",
      "Total basepairs processed:   483,914,772 bp\n",
      "Quality-trimmed:                       0 bp (0.0%)\n",
      "Total written (filtered):    482,801,243 bp (99.8%)\n",
      "\n",
      "=== Adapter 1 ===\n",
      "\n",
      "Sequence: AGATCGGAAGAGC; Type: regular 3'; Length: 13; Trimmed: 329378 times\n",
      "\n",
      "Minimum overlap: 3\n",
      "No. of allowed errors:\n",
      "1-9 bp: 0; 10-13 bp: 1\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 29.3%\n",
      "  C: 29.6%\n",
      "  G: 26.4%\n",
      "  T: 14.6%\n",
      "  none/other: 0.1%\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t256917\t210032.5\t0\t256917\n",
      "4\t54388\t52508.1\t0\t54388\n",
      "5\t11564\t13127.0\t0\t11564\n",
      "6\t1952\t3281.8\t0\t1952\n",
      "7\t943\t820.4\t0\t943\n",
      "8\t636\t205.1\t0\t636\n",
      "9\t770\t51.3\t0\t584 186\n",
      "10\t603\t12.8\t1\t328 275\n",
      "11\t311\t3.2\t1\t172 139\n",
      "12\t161\t0.8\t1\t91 70\n",
      "13\t104\t0.2\t1\t90 14\n",
      "14\t119\t0.2\t1\t105 14\n",
      "15\t63\t0.2\t1\t52 11\n",
      "16\t52\t0.2\t1\t33 19\n",
      "17\t180\t0.2\t1\t157 23\n",
      "18\t21\t0.2\t1\t13 8\n",
      "19\t29\t0.2\t1\t18 11\n",
      "20\t21\t0.2\t1\t12 9\n",
      "21\t19\t0.2\t1\t11 8\n",
      "22\t37\t0.2\t1\t23 14\n",
      "23\t18\t0.2\t1\t9 9\n",
      "24\t17\t0.2\t1\t12 5\n",
      "25\t32\t0.2\t1\t16 16\n",
      "26\t23\t0.2\t1\t15 8\n",
      "27\t46\t0.2\t1\t23 23\n",
      "28\t25\t0.2\t1\t16 9\n",
      "29\t16\t0.2\t1\t8 8\n",
      "30\t13\t0.2\t1\t8 5\n",
      "31\t25\t0.2\t1\t19 6\n",
      "32\t33\t0.2\t1\t20 13\n",
      "33\t34\t0.2\t1\t19 15\n",
      "34\t44\t0.2\t1\t33 11\n",
      "35\t22\t0.2\t1\t14 8\n",
      "36\t140\t0.2\t1\t3 137\n",
      "This is cutadapt 4.9 with Python 3.12.2\n",
      "Command line parameters: -a AGATCGGAAGAGC -q 30 -o trimmed_fastq/SRR085471_trimmed.fastq.gz FastQ/SRR085471.fastq.gz\n",
      "Processing single-end reads on 1 core ...\n",
      "Finished in 68.676 s (4.501 µs/read; 13.33 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:              15,256,752\n",
      "Reads with adapters:                   366,266 (2.4%)\n",
      "Reads written (passing filters):    15,256,752 (100.0%)\n",
      "\n",
      "Total basepairs processed:   549,243,072 bp\n",
      "Quality-trimmed:                       0 bp (0.0%)\n",
      "Total written (filtered):    548,010,222 bp (99.8%)\n",
      "\n",
      "=== Adapter 1 ===\n",
      "\n",
      "Sequence: AGATCGGAAGAGC; Type: regular 3'; Length: 13; Trimmed: 366266 times\n",
      "\n",
      "Minimum overlap: 3\n",
      "No. of allowed errors:\n",
      "1-9 bp: 0; 10-13 bp: 1\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 29.0%\n",
      "  C: 29.4%\n",
      "  G: 26.8%\n",
      "  T: 14.7%\n",
      "  none/other: 0.1%\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t285319\t238386.8\t0\t285319\n",
      "4\t61232\t59596.7\t0\t61232\n",
      "5\t12561\t14899.2\t0\t12561\n",
      "6\t2259\t3724.8\t0\t2259\n",
      "7\t1072\t931.2\t0\t1072\n",
      "8\t766\t232.8\t0\t766\n",
      "9\t835\t58.2\t0\t674 161\n",
      "10\t683\t14.5\t1\t373 310\n",
      "11\t341\t3.6\t1\t194 147\n",
      "12\t188\t0.9\t1\t123 65\n",
      "13\t97\t0.2\t1\t79 18\n",
      "14\t132\t0.2\t1\t110 22\n",
      "15\t60\t0.2\t1\t48 12\n",
      "16\t44\t0.2\t1\t29 15\n",
      "17\t212\t0.2\t1\t180 32\n",
      "18\t25\t0.2\t1\t17 8\n",
      "19\t14\t0.2\t1\t9 5\n",
      "20\t11\t0.2\t1\t6 5\n",
      "21\t25\t0.2\t1\t8 17\n",
      "22\t23\t0.2\t1\t10 13\n",
      "23\t14\t0.2\t1\t5 9\n",
      "24\t18\t0.2\t1\t7 11\n",
      "25\t18\t0.2\t1\t4 14\n",
      "26\t15\t0.2\t1\t11 4\n",
      "27\t35\t0.2\t1\t16 19\n",
      "28\t19\t0.2\t1\t9 10\n",
      "29\t21\t0.2\t1\t14 7\n",
      "30\t16\t0.2\t1\t9 7\n",
      "31\t24\t0.2\t1\t15 9\n",
      "32\t20\t0.2\t1\t13 7\n",
      "33\t44\t0.2\t1\t22 22\n",
      "34\t36\t0.2\t1\t24 12\n",
      "35\t14\t0.2\t1\t8 6\n",
      "36\t73\t0.2\t1\t5 68\n",
      "This is cutadapt 4.9 with Python 3.12.2\n",
      "Command line parameters: -a AGATCGGAAGAGC -q 30 -o trimmed_fastq/SRR085473_trimmed.fastq.gz FastQ/SRR085473.fastq.gz\n",
      "Processing single-end reads on 1 core ...\n",
      "Finished in 59.997 s (4.217 µs/read; 14.23 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:              14,227,702\n",
      "Reads with adapters:                   279,969 (2.0%)\n",
      "Reads written (passing filters):    14,227,702 (100.0%)\n",
      "\n",
      "Total basepairs processed:   497,969,570 bp\n",
      "Quality-trimmed:                       0 bp (0.0%)\n",
      "Total written (filtered):    496,863,554 bp (99.8%)\n",
      "\n",
      "=== Adapter 1 ===\n",
      "\n",
      "Sequence: AGATCGGAAGAGC; Type: regular 3'; Length: 13; Trimmed: 279969 times\n",
      "\n",
      "Minimum overlap: 3\n",
      "No. of allowed errors:\n",
      "1-9 bp: 0; 10-13 bp: 1\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 27.3%\n",
      "  C: 23.3%\n",
      "  G: 28.5%\n",
      "  T: 19.0%\n",
      "  none/other: 1.9%\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t215315\t222307.8\t0\t215315\n",
      "4\t45834\t55577.0\t0\t45834\n",
      "5\t8935\t13894.2\t0\t8935\n",
      "6\t1235\t3473.6\t0\t1235\n",
      "7\t608\t868.4\t0\t608\n",
      "8\t767\t217.1\t0\t767\n",
      "9\t351\t54.3\t0\t272 79\n",
      "10\t283\t13.6\t1\t147 136\n",
      "11\t174\t3.4\t1\t93 81\n",
      "12\t99\t0.8\t1\t73 26\n",
      "13\t92\t0.2\t1\t72 20\n",
      "14\t52\t0.2\t1\t42 10\n",
      "15\t49\t0.2\t1\t41 8\n",
      "16\t547\t0.2\t1\t491 56\n",
      "17\t24\t0.2\t1\t20 4\n",
      "18\t15\t0.2\t1\t10 5\n",
      "19\t17\t0.2\t1\t11 6\n",
      "20\t18\t0.2\t1\t10 8\n",
      "21\t36\t0.2\t1\t30 6\n",
      "22\t14\t0.2\t1\t9 5\n",
      "23\t11\t0.2\t1\t10 1\n",
      "24\t8\t0.2\t1\t7 1\n",
      "25\t21\t0.2\t1\t19 2\n",
      "26\t33\t0.2\t1\t27 6\n",
      "27\t15\t0.2\t1\t7 8\n",
      "28\t14\t0.2\t1\t14\n",
      "29\t17\t0.2\t1\t15 2\n",
      "30\t16\t0.2\t1\t16\n",
      "31\t12\t0.2\t1\t7 5\n",
      "32\t25\t0.2\t1\t20 5\n",
      "33\t23\t0.2\t1\t18 5\n",
      "34\t13\t0.2\t1\t9 4\n",
      "35\t5296\t0.2\t1\t7 5289\n",
      "This is cutadapt 4.9 with Python 3.12.2\n",
      "Command line parameters: -a AGATCGGAAGAGC -q 30 -o trimmed_fastq/SRR085474_trimmed.fastq.gz FastQ/SRR085474.fastq.gz\n",
      "Processing single-end reads on 1 core ...\n",
      "Finished in 69.690 s (4.418 µs/read; 13.58 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:              15,772,947\n",
      "Reads with adapters:                   375,937 (2.4%)\n",
      "Reads written (passing filters):    15,772,947 (100.0%)\n",
      "\n",
      "Total basepairs processed:   552,053,145 bp\n",
      "Quality-trimmed:                       0 bp (0.0%)\n",
      "Total written (filtered):    550,804,622 bp (99.8%)\n",
      "\n",
      "=== Adapter 1 ===\n",
      "\n",
      "Sequence: AGATCGGAAGAGC; Type: regular 3'; Length: 13; Trimmed: 375937 times\n",
      "\n",
      "Minimum overlap: 3\n",
      "No. of allowed errors:\n",
      "1-9 bp: 0; 10-13 bp: 1\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 28.7%\n",
      "  C: 29.5%\n",
      "  G: 28.1%\n",
      "  T: 13.7%\n",
      "  none/other: 0.1%\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t297181\t246452.3\t0\t297181\n",
      "4\t60526\t61613.1\t0\t60526\n",
      "5\t13284\t15403.3\t0\t13284\n",
      "6\t1986\t3850.8\t0\t1986\n",
      "7\t582\t962.7\t0\t582\n",
      "8\t380\t240.7\t0\t380\n",
      "9\t425\t60.2\t0\t187 238\n",
      "10\t401\t15.0\t1\t114 287\n",
      "11\t266\t3.8\t1\t52 214\n",
      "12\t93\t0.9\t1\t38 55\n",
      "13\t80\t0.2\t1\t52 28\n",
      "14\t37\t0.2\t1\t26 11\n",
      "15\t41\t0.2\t1\t18 23\n",
      "16\t165\t0.2\t1\t144 21\n",
      "17\t22\t0.2\t1\t13 9\n",
      "18\t34\t0.2\t1\t17 17\n",
      "19\t24\t0.2\t1\t7 17\n",
      "20\t32\t0.2\t1\t15 17\n",
      "21\t20\t0.2\t1\t11 9\n",
      "22\t19\t0.2\t1\t10 9\n",
      "23\t27\t0.2\t1\t20 7\n",
      "24\t25\t0.2\t1\t11 14\n",
      "25\t24\t0.2\t1\t14 10\n",
      "26\t40\t0.2\t1\t10 30\n",
      "27\t24\t0.2\t1\t10 14\n",
      "28\t25\t0.2\t1\t15 10\n",
      "29\t10\t0.2\t1\t9 1\n",
      "30\t27\t0.2\t1\t16 11\n",
      "31\t24\t0.2\t1\t15 9\n",
      "32\t41\t0.2\t1\t18 23\n",
      "33\t24\t0.2\t1\t17 7\n",
      "34\t21\t0.2\t1\t10 11\n",
      "35\t27\t0.2\t1\t4 23\n",
      "This is cutadapt 4.9 with Python 3.12.2\n",
      "Command line parameters: -a AGATCGGAAGAGC -q 30 -o trimmed_fastq/SRR085726_trimmed.fastq.gz FastQ/SRR085726.fastq.gz\n",
      "Processing single-end reads on 1 core ...\n",
      "Finished in 68.409 s (4.492 µs/read; 13.36 M reads/minute).\n",
      "\n",
      "=== Summary ===\n",
      "\n",
      "Total reads processed:              15,228,832\n",
      "Reads with adapters:                   345,751 (2.3%)\n",
      "Reads written (passing filters):    15,228,832 (100.0%)\n",
      "\n",
      "Total basepairs processed:   533,009,120 bp\n",
      "Quality-trimmed:                       0 bp (0.0%)\n",
      "Total written (filtered):    531,794,117 bp (99.8%)\n",
      "\n",
      "=== Adapter 1 ===\n",
      "\n",
      "Sequence: AGATCGGAAGAGC; Type: regular 3'; Length: 13; Trimmed: 345751 times\n",
      "\n",
      "Minimum overlap: 3\n",
      "No. of allowed errors:\n",
      "1-9 bp: 0; 10-13 bp: 1\n",
      "\n",
      "Bases preceding removed adapters:\n",
      "  A: 28.8%\n",
      "  C: 28.1%\n",
      "  G: 27.8%\n",
      "  T: 14.6%\n",
      "  none/other: 0.7%\n",
      "\n",
      "Overview of removed sequences\n",
      "length\tcount\texpect\tmax.err\terror counts\n",
      "3\t272530\t237950.5\t0\t272530\n",
      "4\t55583\t59487.6\t0\t55583\n",
      "5\t10973\t14871.9\t0\t10973\n",
      "6\t1656\t3718.0\t0\t1656\n",
      "7\t539\t929.5\t0\t539\n",
      "8\t437\t232.4\t0\t437\n",
      "9\t343\t58.1\t0\t176 167\n",
      "10\t316\t14.5\t1\t101 215\n",
      "11\t226\t3.6\t1\t66 160\n",
      "12\t100\t0.9\t1\t52 48\n",
      "13\t85\t0.2\t1\t60 25\n",
      "14\t54\t0.2\t1\t38 16\n",
      "15\t31\t0.2\t1\t27 4\n",
      "16\t285\t0.2\t1\t238 47\n",
      "17\t25\t0.2\t1\t17 8\n",
      "18\t35\t0.2\t1\t20 15\n",
      "19\t23\t0.2\t1\t14 9\n",
      "20\t29\t0.2\t1\t16 13\n",
      "21\t26\t0.2\t1\t18 8\n",
      "22\t27\t0.2\t1\t17 10\n",
      "23\t25\t0.2\t1\t16 9\n",
      "24\t27\t0.2\t1\t16 11\n",
      "25\t21\t0.2\t1\t14 7\n",
      "26\t39\t0.2\t1\t18 21\n",
      "27\t27\t0.2\t1\t12 15\n",
      "28\t21\t0.2\t1\t17 4\n",
      "29\t17\t0.2\t1\t13 4\n",
      "30\t21\t0.2\t1\t14 7\n",
      "31\t18\t0.2\t1\t15 3\n",
      "32\t42\t0.2\t1\t21 21\n",
      "33\t28\t0.2\t1\t20 8\n",
      "34\t18\t0.2\t1\t12 6\n",
      "35\t2124\t0.2\t1\t7 2117\n",
      "All FastQ files have been trimmed using cutadapt.\n"
     ]
    }
   ],
   "source": [
    "# List of FastQ files (with path)\n",
    "fastq_files = [os.path.join('FastQ', f) for f in ['SRR087416.fastq.gz', 'SRR085725.fastq.gz', 'SRR085471.fastq.gz', 'SRR085473.fastq.gz', 'SRR085474.fastq.gz', 'SRR085726.fastq.gz']]\n",
    "\n",
    "# Adapter sequence\n",
    "adapter_seq = 'AGATCGGAAGAGC'  # Example adapter for Illumina\n",
    "\n",
    "# Directory to store trimmed FastQ files\n",
    "trimmed_dir = 'trimmed_fastq'\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(trimmed_dir, exist_ok=True)\n",
    "\n",
    "# Run Cutadapt for each file\n",
    "for fastq_file in fastq_files:\n",
    "    output_file = os.path.join(trimmed_dir, os.path.basename(fastq_file).replace('.fastq.gz', '_trimmed.fastq.gz'))\n",
    "    subprocess.run(['cutadapt', '-a', adapter_seq, '-q', '30', '-o', output_file, fastq_file])\n",
    "\n",
    "print(\"All FastQ files have been trimmed using cutadapt.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd68ee0-a2e8-44d5-99e3-5748101288f3",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"\n",
    "    background-image: url('https://i.postimg.cc/K87ByXmr/stage5.jpg');\n",
    "    background-size: cover;\n",
    "    background-repeat: no-repeat;\n",
    "    font-family: 'Arial', sans-serif;\n",
    "    font-size: 24px;\n",
    "    color: white;\n",
    "    text-align: center;\n",
    "    border-radius: 15px 50px;\n",
    "    padding: 20px 40px;\n",
    "    margin: 20px 0;\n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\">\n",
    "    <b>Post-Trim Quality Check</b>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9823300-c99e-4c8c-b51f-af56f81b5705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application/gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR087416_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR087416_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR087416_trimmed.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR087416_trimmed.fastq.gz\n",
      "application/gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR085725_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR085725_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR085725_trimmed.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR085725_trimmed.fastq.gz\n",
      "application/gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR085471_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR085471_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR085471_trimmed.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR085471_trimmed.fastq.gz\n",
      "application/gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR085473_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR085473_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR085473_trimmed.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR085473_trimmed.fastq.gz\n",
      "application/gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR085474_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR085474_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR085474_trimmed.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR085474_trimmed.fastq.gz\n",
      "application/gzip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Started analysis of SRR085726_trimmed.fastq.gz\n",
      "Approx 5% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 10% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 15% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 20% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 25% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 30% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 35% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 40% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 45% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 50% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 55% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 60% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 65% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 70% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 75% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 80% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 85% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 90% complete for SRR085726_trimmed.fastq.gz\n",
      "Approx 95% complete for SRR085726_trimmed.fastq.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete for SRR085726_trimmed.fastq.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;208m///\u001b[0m \u001b]8;id=305485;https://multiqc.info\u001b\\\u001b[1mMultiQC\u001b[0m\u001b]8;;\u001b\\ 🔍 \u001b[2mv1.25.1\u001b[0m\n",
      "\n",
      "\u001b[34m       file_search\u001b[0m | Search path: /home/mahendra/Desktop/Python/Project/trim_fastqc\n",
      "\u001b[2K         \u001b[34msearching\u001b[0m | \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m12/12\u001b[0m   \n",
      "\u001b[?25h\u001b[34m            fastqc\u001b[0m | Found 6 reports\n",
      "\u001b[34m     write_results\u001b[0m | Data        : trim_mqc/multiqc_data\n",
      "\u001b[34m     write_results\u001b[0m | Report      : trim_mqc/multiqc_report.html\n",
      "\u001b[34m           multiqc\u001b[0m | MultiQC complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final quality control completed with FastQC and MultiQC.\n"
     ]
    }
   ],
   "source": [
    "# List of trimmed files\n",
    "trimmed_files = [os.path.join('trimmed_fastq', f) for f in ['SRR087416_trimmed.fastq.gz', 'SRR085725_trimmed.fastq.gz','SRR085471_trimmed.fastq.gz', 'SRR085473_trimmed.fastq.gz',\n",
    "                                                            'SRR085474_trimmed.fastq.gz', 'SRR085726_trimmed.fastq.gz']]\n",
    "\n",
    "# Directory to store FastQC results\n",
    "fastqc_trim_dir = 'trim_fastqc'\n",
    "os.makedirs(fastqc_trim_dir, exist_ok=True)\n",
    "\n",
    "# Run FastQC on deduplicated BAM files\n",
    "# Define parameters for threads and kmers\n",
    "threads = 4   # Set the number of threads, e.g., 4 (adjust as needed based on available memory)\n",
    "kmers = 10    # Set the kmer length, e.g., 7 (ensure it's between 2 and 10)\n",
    "for trim_file in trimmed_files:\n",
    "  subprocess.run(['fastqc', trim_file, '-o', fastqc_trim_dir, '-t', str(threads), '-k', str(kmers)])\n",
    "\n",
    "# Run MultiQC to aggregate FastQC results\n",
    "output_trim_multiqc = 'trim_mqc'\n",
    "os.makedirs(output_trim_multiqc, exist_ok=True)\n",
    "subprocess.run(['multiqc', fastqc_trim_dir, '-o', output_trim_multiqc])\n",
    "\n",
    "print(\"Final quality control completed with FastQC and MultiQC.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "07d7555a-89f3-481b-9690-2446e420877a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"800\"\n",
       "            src=\"trim_mqc/multiqc_report.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ed1cad6edb0>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the MultiQC report\n",
    "multiqc_report_path = os.path.join(output_trim_multiqc, \"multiqc_report.html\")\n",
    "\n",
    "# Display the report in the notebook\n",
    "IFrame(multiqc_report_path, width=1000, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc058bf7-e3ef-4fbe-abaa-a04026ca42d2",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"\n",
    "    background-image: url('https://i.postimg.cc/K87ByXmr/stage5.jpg');\n",
    "    background-size: cover;\n",
    "    background-repeat: no-repeat;\n",
    "    font-family: 'Arial', sans-serif;\n",
    "    font-size: 24px;\n",
    "    color: white;\n",
    "    text-align: center;\n",
    "    border-radius: 15px 50px;\n",
    "    padding: 20px 40px;\n",
    "    margin: 20px 0;\n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\">\n",
    "    <b>Download the human reference genome and Align FASTQ files with the Reference Genome using BWA</b>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f630cf1b-51fd-42d3-88d1-bf401886218c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference genome path\n",
    "reference_genome = '/home/mahendra/Desktop/Python/Project/Ref/GCF_000001405.40_GRCh38.p14_genomic.fna'\n",
    "if not os.path.exists(reference_genome):\n",
    "    subprocess.run(['wget', 'https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.40_GRCh38.p14/GCF_000001405.40_GRCh38.p14_genomic.fna.gz'])\n",
    "    subprocess.run(['gunzip', 'GCF_000001405.40_GRCh38.p14_genomic.fna.gz'])\n",
    "    RF = 'Ref'\n",
    "    os.makedirs(RF, exist_ok=True)\n",
    "    subprocess.run(['mv', 'GCF_000001405.40_GRCh38.p14_genomic.fna', '/home/mahendra/Desktop/Python/Project/Ref/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2595bf4b-2dac-4136-86cc-c894e0c2992e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference genome already downloaded.\n",
      "Reference genome is already indexed.\n",
      "Running BWA mem for each FASTQ file...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alignment Progress:   0%|\u001b[33m                                            \u001b[0m| 0/6 files\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 278392 sequences (10000040 bp)...\n",
      "[M::process] read 278374 sequences (10000032 bp)...\n",
      "[M::mem_process_seqs] Processed 278392 reads in 40.399 CPU sec, 100.554 real sec\n",
      "[M::process] read 278382 sequences (10000067 bp)...\n",
      "[M::mem_process_seqs] Processed 278374 reads in 33.895 CPU sec, 60.862 real sec\n",
      "[M::process] read 278366 sequences (10000060 bp)...\n",
      "[M::mem_process_seqs] Processed 278382 reads in 32.662 CPU sec, 54.507 real sec\n",
      "[M::process] read 278382 sequences (10000028 bp)...\n",
      "[M::mem_process_seqs] Processed 278366 reads in 34.366 CPU sec, 61.419 real sec\n",
      "[M::process] read 278378 sequences (10000034 bp)...\n",
      "[M::mem_process_seqs] Processed 278382 reads in 34.655 CPU sec, 61.958 real sec\n",
      "[M::process] read 278374 sequences (10000048 bp)...\n",
      "[M::mem_process_seqs] Processed 278378 reads in 33.773 CPU sec, 58.527 real sec\n",
      "[M::process] read 278392 sequences (10000028 bp)...\n",
      "[M::mem_process_seqs] Processed 278374 reads in 35.154 CPU sec, 64.840 real sec\n",
      "[M::process] read 278382 sequences (10000040 bp)...\n",
      "[M::mem_process_seqs] Processed 278392 reads in 31.873 CPU sec, 50.126 real sec\n",
      "[M::process] read 278374 sequences (10000016 bp)...\n",
      "[M::mem_process_seqs] Processed 278382 reads in 32.583 CPU sec, 52.426 real sec\n",
      "[M::process] read 278392 sequences (10000002 bp)...\n",
      "[M::mem_process_seqs] Processed 278374 reads in 33.211 CPU sec, 56.776 real sec\n",
      "[M::process] read 278378 sequences (10000057 bp)...\n",
      "[M::mem_process_seqs] Processed 278392 reads in 34.125 CPU sec, 59.941 real sec\n",
      "[M::process] read 278368 sequences (10000015 bp)...\n",
      "[M::mem_process_seqs] Processed 278378 reads in 35.422 CPU sec, 66.157 real sec\n",
      "[M::process] read 278360 sequences (10000066 bp)...\n",
      "[M::mem_process_seqs] Processed 278368 reads in 32.520 CPU sec, 52.906 real sec\n",
      "[M::process] read 278374 sequences (10000048 bp)...\n",
      "[M::mem_process_seqs] Processed 278360 reads in 34.022 CPU sec, 60.334 real sec\n",
      "[M::process] read 278384 sequences (10000042 bp)...\n",
      "[M::mem_process_seqs] Processed 278374 reads in 32.918 CPU sec, 54.126 real sec\n",
      "[M::process] read 278368 sequences (10000071 bp)...\n",
      "[M::mem_process_seqs] Processed 278384 reads in 37.683 CPU sec, 74.973 real sec\n",
      "[M::process] read 278376 sequences (10000033 bp)...\n",
      "[M::mem_process_seqs] Processed 278368 reads in 33.424 CPU sec, 57.101 real sec\n",
      "[M::process] read 278382 sequences (10000065 bp)...\n",
      "[M::mem_process_seqs] Processed 278376 reads in 34.813 CPU sec, 61.325 real sec\n",
      "[M::process] read 278362 sequences (10000019 bp)...\n",
      "[M::mem_process_seqs] Processed 278382 reads in 33.728 CPU sec, 58.492 real sec\n",
      "[M::process] read 278366 sequences (10000041 bp)...\n",
      "[M::mem_process_seqs] Processed 278362 reads in 33.214 CPU sec, 55.716 real sec\n",
      "[M::process] read 278372 sequences (10000041 bp)...\n",
      "[M::mem_process_seqs] Processed 278366 reads in 33.479 CPU sec, 56.134 real sec\n",
      "[M::process] read 278374 sequences (10000024 bp)...\n",
      "[M::mem_process_seqs] Processed 278372 reads in 34.037 CPU sec, 59.190 real sec\n",
      "[M::process] read 278370 sequences (10000004 bp)...\n",
      "[M::mem_process_seqs] Processed 278374 reads in 32.742 CPU sec, 53.436 real sec\n",
      "[M::process] read 278356 sequences (10000002 bp)...\n",
      "[M::mem_process_seqs] Processed 278370 reads in 34.228 CPU sec, 60.238 real sec\n",
      "[M::process] read 278368 sequences (10000006 bp)...\n",
      "[M::mem_process_seqs] Processed 278356 reads in 33.959 CPU sec, 58.592 real sec\n",
      "[M::process] read 278370 sequences (10000013 bp)...\n",
      "[M::mem_process_seqs] Processed 278368 reads in 33.299 CPU sec, 55.453 real sec\n",
      "[M::process] read 278374 sequences (10000037 bp)...\n",
      "[M::mem_process_seqs] Processed 278370 reads in 33.105 CPU sec, 54.189 real sec\n",
      "[M::process] read 278372 sequences (10000003 bp)...\n",
      "[M::mem_process_seqs] Processed 278374 reads in 34.554 CPU sec, 61.515 real sec\n",
      "[M::process] read 278368 sequences (10000020 bp)...\n",
      "[M::mem_process_seqs] Processed 278372 reads in 33.330 CPU sec, 55.721 real sec\n",
      "[M::process] read 278384 sequences (10000068 bp)...\n",
      "[M::mem_process_seqs] Processed 278368 reads in 35.827 CPU sec, 66.445 real sec\n",
      "[M::process] read 278376 sequences (10000007 bp)...\n",
      "[M::mem_process_seqs] Processed 278384 reads in 33.425 CPU sec, 56.301 real sec\n",
      "[M::process] read 278372 sequences (10000070 bp)...\n",
      "[M::mem_process_seqs] Processed 278376 reads in 33.416 CPU sec, 56.013 real sec\n",
      "[M::process] read 278362 sequences (10000010 bp)...\n",
      "[M::mem_process_seqs] Processed 278372 reads in 33.360 CPU sec, 56.687 real sec\n",
      "[M::process] read 278372 sequences (10000018 bp)...\n",
      "[M::mem_process_seqs] Processed 278362 reads in 34.509 CPU sec, 60.295 real sec\n",
      "[M::process] read 278364 sequences (10000024 bp)...\n",
      "[M::mem_process_seqs] Processed 278372 reads in 35.992 CPU sec, 66.838 real sec\n",
      "[M::process] read 278368 sequences (10000059 bp)...\n",
      "[M::mem_process_seqs] Processed 278364 reads in 35.363 CPU sec, 66.953 real sec\n",
      "[M::process] read 278356 sequences (10000064 bp)...\n",
      "[M::mem_process_seqs] Processed 278368 reads in 37.540 CPU sec, 74.114 real sec\n",
      "[M::process] read 278364 sequences (10000036 bp)...\n",
      "[M::mem_process_seqs] Processed 278356 reads in 38.607 CPU sec, 78.036 real sec\n",
      "[M::process] read 278362 sequences (10000000 bp)...\n",
      "[M::mem_process_seqs] Processed 278364 reads in 37.309 CPU sec, 73.611 real sec\n",
      "[M::process] read 278364 sequences (10000032 bp)...\n",
      "[M::mem_process_seqs] Processed 278362 reads in 33.655 CPU sec, 62.059 real sec\n",
      "[M::process] read 278370 sequences (10000047 bp)...\n",
      "[M::mem_process_seqs] Processed 278364 reads in 33.370 CPU sec, 58.424 real sec\n",
      "[M::process] read 278364 sequences (10000045 bp)...\n",
      "[M::mem_process_seqs] Processed 278370 reads in 33.119 CPU sec, 57.833 real sec\n",
      "[M::process] read 278386 sequences (10000022 bp)...\n",
      "[M::mem_process_seqs] Processed 278364 reads in 34.507 CPU sec, 66.070 real sec\n",
      "[M::process] read 278362 sequences (10000045 bp)...\n",
      "[M::mem_process_seqs] Processed 278386 reads in 32.540 CPU sec, 53.821 real sec\n",
      "[M::process] read 278368 sequences (10000002 bp)...\n",
      "[M::mem_process_seqs] Processed 278362 reads in 31.275 CPU sec, 48.972 real sec\n",
      "[M::process] read 278370 sequences (10000007 bp)...\n",
      "[M::mem_process_seqs] Processed 278368 reads in 32.304 CPU sec, 53.012 real sec\n",
      "[M::process] read 278358 sequences (10000038 bp)...\n",
      "[M::mem_process_seqs] Processed 278370 reads in 32.210 CPU sec, 54.408 real sec\n",
      "[M::process] read 278350 sequences (10000009 bp)...\n",
      "[M::mem_process_seqs] Processed 278358 reads in 31.705 CPU sec, 51.115 real sec\n",
      "[M::process] read 278376 sequences (10000064 bp)...\n",
      "[M::mem_process_seqs] Processed 278350 reads in 32.354 CPU sec, 54.136 real sec\n",
      "[M::process] read 278360 sequences (10000018 bp)...\n",
      "[M::mem_process_seqs] Processed 278376 reads in 32.493 CPU sec, 54.803 real sec\n",
      "[M::process] read 278362 sequences (10000029 bp)...\n",
      "[M::mem_process_seqs] Processed 278360 reads in 31.168 CPU sec, 48.218 real sec\n",
      "[M::process] read 245516 sequences (8819759 bp)...\n",
      "[M::mem_process_seqs] Processed 278362 reads in 31.596 CPU sec, 50.119 real sec\n",
      "[M::mem_process_seqs] Processed 245516 reads in 28.928 CPU sec, 51.011 real sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alignment Progress:  17%|\u001b[33m███████▎                                    \u001b[0m| 1/6 files\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem /home/mahendra/Desktop/Python/Project/Ref/GCF_000001405.40_GRCh38.p14_genomic.fna trimmed_fastq/SRR087416_trimmed.fastq.gz\n",
      "[main] Real time: 3171.090 sec; CPU: 1801.563 sec\n",
      "Alignment completed for trimmed_fastq/SRR087416_trimmed.fastq.gz, output saved to aligned_sam/SRR087416.sam\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 278420 sequences (10000040 bp)...\n",
      "[M::process] read 278418 sequences (10000056 bp)...\n",
      "[M::mem_process_seqs] Processed 278420 reads in 33.517 CPU sec, 74.458 real sec\n",
      "[M::process] read 278434 sequences (10000020 bp)...\n",
      "[M::mem_process_seqs] Processed 278418 reads in 29.795 CPU sec, 54.491 real sec\n",
      "[M::process] read 278424 sequences (10000042 bp)...\n",
      "[M::mem_process_seqs] Processed 278434 reads in 28.898 CPU sec, 48.654 real sec\n",
      "[M::process] read 278428 sequences (10000017 bp)...\n",
      "[M::mem_process_seqs] Processed 278424 reads in 29.362 CPU sec, 51.353 real sec\n",
      "[M::process] read 278444 sequences (10000052 bp)...\n",
      "[M::mem_process_seqs] Processed 278428 reads in 28.947 CPU sec, 48.987 real sec\n",
      "[M::process] read 278428 sequences (10000044 bp)...\n",
      "[M::mem_process_seqs] Processed 278444 reads in 28.457 CPU sec, 46.233 real sec\n",
      "[M::process] read 278424 sequences (10000051 bp)...\n",
      "[M::mem_process_seqs] Processed 278428 reads in 28.756 CPU sec, 47.303 real sec\n",
      "[M::process] read 278430 sequences (10000037 bp)...\n",
      "[M::mem_process_seqs] Processed 278424 reads in 29.359 CPU sec, 50.324 real sec\n",
      "[M::process] read 278414 sequences (10000008 bp)...\n",
      "[M::mem_process_seqs] Processed 278430 reads in 28.667 CPU sec, 46.956 real sec\n",
      "[M::process] read 278428 sequences (10000047 bp)...\n",
      "[M::mem_process_seqs] Processed 278414 reads in 28.000 CPU sec, 44.019 real sec\n",
      "[M::process] read 278414 sequences (10000057 bp)...\n",
      "[M::mem_process_seqs] Processed 278428 reads in 28.926 CPU sec, 48.654 real sec\n",
      "[M::process] read 278446 sequences (10000060 bp)...\n",
      "[M::mem_process_seqs] Processed 278414 reads in 28.475 CPU sec, 45.424 real sec\n",
      "[M::process] read 278432 sequences (10000004 bp)...\n",
      "[M::mem_process_seqs] Processed 278446 reads in 28.020 CPU sec, 43.770 real sec\n",
      "[M::process] read 278410 sequences (10000050 bp)...\n",
      "[M::mem_process_seqs] Processed 278432 reads in 29.357 CPU sec, 51.238 real sec\n",
      "[M::process] read 278416 sequences (10000039 bp)...\n",
      "[M::mem_process_seqs] Processed 278410 reads in 29.251 CPU sec, 49.904 real sec\n",
      "[M::process] read 278424 sequences (10000013 bp)...\n",
      "[M::mem_process_seqs] Processed 278416 reads in 28.163 CPU sec, 44.240 real sec\n",
      "[M::process] read 278416 sequences (10000067 bp)...\n",
      "[M::mem_process_seqs] Processed 278424 reads in 33.096 CPU sec, 64.448 real sec\n",
      "[M::process] read 278430 sequences (10000015 bp)...\n",
      "[M::mem_process_seqs] Processed 278416 reads in 30.120 CPU sec, 53.348 real sec\n",
      "[M::process] read 278418 sequences (10000066 bp)...\n",
      "[M::mem_process_seqs] Processed 278430 reads in 28.750 CPU sec, 45.620 real sec\n",
      "[M::process] read 278428 sequences (10000051 bp)...\n",
      "[M::mem_process_seqs] Processed 278418 reads in 29.895 CPU sec, 50.839 real sec\n",
      "[M::process] read 278418 sequences (10000014 bp)...\n",
      "[M::mem_process_seqs] Processed 278428 reads in 30.224 CPU sec, 52.905 real sec\n",
      "[M::process] read 278414 sequences (10000025 bp)...\n",
      "[M::mem_process_seqs] Processed 278418 reads in 28.883 CPU sec, 47.049 real sec\n",
      "[M::process] read 278416 sequences (10000001 bp)...\n",
      "[M::mem_process_seqs] Processed 278414 reads in 29.188 CPU sec, 48.554 real sec\n",
      "[M::process] read 278426 sequences (10000042 bp)...\n",
      "[M::mem_process_seqs] Processed 278416 reads in 29.183 CPU sec, 48.053 real sec\n",
      "[M::process] read 278410 sequences (10000059 bp)...\n",
      "[M::mem_process_seqs] Processed 278426 reads in 28.361 CPU sec, 44.508 real sec\n",
      "[M::process] read 278398 sequences (10000017 bp)...\n",
      "[M::mem_process_seqs] Processed 278410 reads in 29.251 CPU sec, 48.979 real sec\n",
      "[M::process] read 278414 sequences (10000043 bp)...\n",
      "[M::mem_process_seqs] Processed 278398 reads in 29.626 CPU sec, 50.993 real sec\n",
      "[M::process] read 278398 sequences (10000014 bp)...\n",
      "[M::mem_process_seqs] Processed 278414 reads in 30.639 CPU sec, 55.755 real sec\n",
      "[M::process] read 278416 sequences (10000011 bp)...\n",
      "[M::mem_process_seqs] Processed 278398 reads in 30.782 CPU sec, 55.585 real sec\n",
      "[M::process] read 278420 sequences (10000049 bp)...\n",
      "[M::mem_process_seqs] Processed 278416 reads in 29.454 CPU sec, 49.473 real sec\n",
      "[M::process] read 278422 sequences (10000022 bp)...\n",
      "[M::mem_process_seqs] Processed 278420 reads in 29.462 CPU sec, 49.003 real sec\n",
      "[M::process] read 278422 sequences (10000029 bp)...\n",
      "[M::mem_process_seqs] Processed 278422 reads in 29.631 CPU sec, 51.328 real sec\n",
      "[M::process] read 278414 sequences (10000004 bp)...\n",
      "[M::mem_process_seqs] Processed 278422 reads in 28.813 CPU sec, 47.249 real sec\n",
      "[M::process] read 278414 sequences (10000046 bp)...\n",
      "[M::mem_process_seqs] Processed 278414 reads in 29.277 CPU sec, 49.342 real sec\n",
      "[M::process] read 278400 sequences (10000018 bp)...\n",
      "[M::mem_process_seqs] Processed 278414 reads in 29.942 CPU sec, 51.932 real sec\n",
      "[M::process] read 278410 sequences (10000041 bp)...\n",
      "[M::mem_process_seqs] Processed 278400 reads in 29.067 CPU sec, 47.676 real sec\n",
      "[M::process] read 278420 sequences (10000060 bp)...\n",
      "[M::mem_process_seqs] Processed 278410 reads in 28.480 CPU sec, 45.886 real sec\n",
      "[M::process] read 278426 sequences (10000024 bp)...\n",
      "[M::mem_process_seqs] Processed 278420 reads in 29.510 CPU sec, 49.916 real sec\n",
      "[M::process] read 278426 sequences (10000027 bp)...\n",
      "[M::mem_process_seqs] Processed 278426 reads in 29.586 CPU sec, 52.153 real sec\n",
      "[M::process] read 278410 sequences (10000011 bp)...\n",
      "[M::mem_process_seqs] Processed 278426 reads in 28.905 CPU sec, 47.359 real sec\n",
      "[M::process] read 278414 sequences (10000040 bp)...\n",
      "[M::mem_process_seqs] Processed 278410 reads in 29.403 CPU sec, 48.674 real sec\n",
      "[M::process] read 278412 sequences (10000002 bp)...\n",
      "[M::mem_process_seqs] Processed 278414 reads in 28.716 CPU sec, 46.014 real sec\n",
      "[M::process] read 278424 sequences (10000035 bp)...\n",
      "[M::mem_process_seqs] Processed 278412 reads in 29.016 CPU sec, 47.272 real sec\n",
      "[M::process] read 278428 sequences (10000035 bp)...\n",
      "[M::mem_process_seqs] Processed 278424 reads in 30.666 CPU sec, 55.877 real sec\n",
      "[M::process] read 278400 sequences (10000007 bp)...\n",
      "[M::mem_process_seqs] Processed 278428 reads in 29.748 CPU sec, 51.914 real sec\n",
      "[M::process] read 278424 sequences (10000034 bp)...\n",
      "[M::mem_process_seqs] Processed 278400 reads in 28.456 CPU sec, 44.893 real sec\n",
      "[M::process] read 278404 sequences (10000011 bp)...\n",
      "[M::mem_process_seqs] Processed 278424 reads in 29.719 CPU sec, 49.999 real sec\n",
      "[M::process] read 77951 sequences (2799686 bp)...\n",
      "[M::mem_process_seqs] Processed 278404 reads in 29.310 CPU sec, 49.200 real sec\n",
      "[M::mem_process_seqs] Processed 77951 reads in 8.291 CPU sec, 13.982 real sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alignment Progress:  33%|\u001b[33m██████████████▋                             \u001b[0m| 2/6 files\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem /home/mahendra/Desktop/Python/Project/Ref/GCF_000001405.40_GRCh38.p14_genomic.fna trimmed_fastq/SRR085725_trimmed.fastq.gz\n",
      "[main] Real time: 2424.286 sec; CPU: 1426.885 sec\n",
      "Alignment completed for trimmed_fastq/SRR085725_trimmed.fastq.gz, output saved to aligned_sam/SRR085725.sam\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 278398 sequences (10000033 bp)...\n",
      "[M::process] read 278412 sequences (10000049 bp)...\n",
      "[M::mem_process_seqs] Processed 278398 reads in 33.164 CPU sec, 75.198 real sec\n",
      "[M::process] read 278428 sequences (10000042 bp)...\n",
      "[M::mem_process_seqs] Processed 278412 reads in 28.216 CPU sec, 44.986 real sec\n",
      "[M::process] read 278406 sequences (10000041 bp)...\n",
      "[M::mem_process_seqs] Processed 278428 reads in 27.578 CPU sec, 42.791 real sec\n",
      "[M::process] read 278394 sequences (10000009 bp)...\n",
      "[M::mem_process_seqs] Processed 278406 reads in 29.142 CPU sec, 48.717 real sec\n",
      "[M::process] read 278392 sequences (10000032 bp)...\n",
      "[M::mem_process_seqs] Processed 278394 reads in 28.559 CPU sec, 47.758 real sec\n",
      "[M::process] read 278410 sequences (10000002 bp)...\n",
      "[M::mem_process_seqs] Processed 278392 reads in 28.549 CPU sec, 47.737 real sec\n",
      "[M::process] read 278392 sequences (10000031 bp)...\n",
      "[M::mem_process_seqs] Processed 278410 reads in 29.849 CPU sec, 53.857 real sec\n",
      "[M::process] read 278412 sequences (10000063 bp)...\n",
      "[M::mem_process_seqs] Processed 278392 reads in 29.181 CPU sec, 49.395 real sec\n",
      "[M::process] read 278400 sequences (10000055 bp)...\n",
      "[M::mem_process_seqs] Processed 278412 reads in 27.667 CPU sec, 43.889 real sec\n",
      "[M::process] read 278414 sequences (10000047 bp)...\n",
      "[M::mem_process_seqs] Processed 278400 reads in 27.853 CPU sec, 44.214 real sec\n",
      "[M::process] read 278408 sequences (10000066 bp)...\n",
      "[M::mem_process_seqs] Processed 278414 reads in 28.911 CPU sec, 48.925 real sec\n",
      "[M::process] read 278414 sequences (10000071 bp)...\n",
      "[M::mem_process_seqs] Processed 278408 reads in 27.960 CPU sec, 44.159 real sec\n",
      "[M::process] read 278418 sequences (10000039 bp)...\n",
      "[M::mem_process_seqs] Processed 278414 reads in 27.070 CPU sec, 40.286 real sec\n",
      "[M::process] read 278406 sequences (10000063 bp)...\n",
      "[M::mem_process_seqs] Processed 278418 reads in 29.846 CPU sec, 53.604 real sec\n",
      "[M::process] read 278402 sequences (10000003 bp)...\n",
      "[M::mem_process_seqs] Processed 278406 reads in 28.858 CPU sec, 48.265 real sec\n",
      "[M::process] read 278398 sequences (10000018 bp)...\n",
      "[M::mem_process_seqs] Processed 278402 reads in 28.609 CPU sec, 46.793 real sec\n",
      "[M::process] read 278422 sequences (10000031 bp)...\n",
      "[M::mem_process_seqs] Processed 278398 reads in 28.213 CPU sec, 45.194 real sec\n",
      "[M::process] read 278394 sequences (10000054 bp)...\n",
      "[M::mem_process_seqs] Processed 278422 reads in 29.150 CPU sec, 50.726 real sec\n",
      "[M::process] read 278416 sequences (10000064 bp)...\n",
      "[M::mem_process_seqs] Processed 278394 reads in 29.426 CPU sec, 51.255 real sec\n",
      "[M::process] read 278410 sequences (10000034 bp)...\n",
      "[M::mem_process_seqs] Processed 278416 reads in 27.679 CPU sec, 43.646 real sec\n",
      "[M::process] read 278400 sequences (10000062 bp)...\n",
      "[M::mem_process_seqs] Processed 278410 reads in 28.193 CPU sec, 45.776 real sec\n",
      "[M::process] read 278400 sequences (10000056 bp)...\n",
      "[M::mem_process_seqs] Processed 278400 reads in 27.482 CPU sec, 42.179 real sec\n",
      "[M::process] read 278400 sequences (10000043 bp)...\n",
      "[M::mem_process_seqs] Processed 278400 reads in 28.059 CPU sec, 44.825 real sec\n",
      "[M::process] read 278398 sequences (10000018 bp)...\n",
      "[M::mem_process_seqs] Processed 278400 reads in 27.953 CPU sec, 44.837 real sec\n",
      "[M::process] read 278410 sequences (10000012 bp)...\n",
      "[M::mem_process_seqs] Processed 278398 reads in 29.237 CPU sec, 50.620 real sec\n",
      "[M::process] read 278400 sequences (10000067 bp)...\n",
      "[M::mem_process_seqs] Processed 278410 reads in 28.620 CPU sec, 49.147 real sec\n",
      "[M::process] read 278398 sequences (10000047 bp)...\n",
      "[M::mem_process_seqs] Processed 278400 reads in 28.236 CPU sec, 45.226 real sec\n",
      "[M::process] read 278404 sequences (10000040 bp)...\n",
      "[M::mem_process_seqs] Processed 278398 reads in 28.161 CPU sec, 47.483 real sec\n",
      "[M::process] read 278386 sequences (10000017 bp)...\n",
      "[M::mem_process_seqs] Processed 278404 reads in 28.807 CPU sec, 47.559 real sec\n",
      "[M::process] read 278398 sequences (10000027 bp)...\n",
      "[M::mem_process_seqs] Processed 278386 reads in 29.216 CPU sec, 50.416 real sec\n",
      "[M::process] read 278400 sequences (10000000 bp)...\n",
      "[M::mem_process_seqs] Processed 278398 reads in 28.303 CPU sec, 46.342 real sec\n",
      "[M::process] read 278412 sequences (10000058 bp)...\n",
      "[M::mem_process_seqs] Processed 278400 reads in 27.303 CPU sec, 41.558 real sec\n",
      "[M::process] read 278396 sequences (10000026 bp)...\n",
      "[M::mem_process_seqs] Processed 278412 reads in 27.861 CPU sec, 43.756 real sec\n",
      "[M::process] read 278394 sequences (10000052 bp)...\n",
      "[M::mem_process_seqs] Processed 278396 reads in 28.099 CPU sec, 45.601 real sec\n",
      "[M::process] read 278398 sequences (10000010 bp)...\n",
      "[M::mem_process_seqs] Processed 278394 reads in 28.735 CPU sec, 47.854 real sec\n",
      "[M::process] read 278404 sequences (10000040 bp)...\n",
      "[M::mem_process_seqs] Processed 278398 reads in 28.517 CPU sec, 46.565 real sec\n",
      "[M::process] read 278408 sequences (10000055 bp)...\n",
      "[M::mem_process_seqs] Processed 278404 reads in 29.339 CPU sec, 52.716 real sec\n",
      "[M::process] read 278406 sequences (10000031 bp)...\n",
      "[M::mem_process_seqs] Processed 278408 reads in 27.782 CPU sec, 44.189 real sec\n",
      "[M::process] read 278410 sequences (10000028 bp)...\n",
      "[M::mem_process_seqs] Processed 278406 reads in 27.984 CPU sec, 44.260 real sec\n",
      "[M::process] read 278402 sequences (10000059 bp)...\n",
      "[M::mem_process_seqs] Processed 278410 reads in 28.241 CPU sec, 45.969 real sec\n",
      "[M::process] read 278410 sequences (10000033 bp)...\n",
      "[M::mem_process_seqs] Processed 278402 reads in 29.053 CPU sec, 49.034 real sec\n",
      "[M::process] read 278404 sequences (10000035 bp)...\n",
      "[M::mem_process_seqs] Processed 278410 reads in 28.479 CPU sec, 46.859 real sec\n",
      "[M::process] read 278412 sequences (10000033 bp)...\n",
      "[M::mem_process_seqs] Processed 278404 reads in 28.324 CPU sec, 45.991 real sec\n",
      "[M::process] read 278396 sequences (10000052 bp)...\n",
      "[M::mem_process_seqs] Processed 278412 reads in 28.242 CPU sec, 44.396 real sec\n",
      "[M::process] read 278404 sequences (10000036 bp)...\n",
      "[M::mem_process_seqs] Processed 278396 reads in 28.534 CPU sec, 46.316 real sec\n",
      "[M::process] read 278388 sequences (10000028 bp)...\n",
      "[M::mem_process_seqs] Processed 278404 reads in 29.405 CPU sec, 51.176 real sec\n",
      "[M::process] read 278406 sequences (10000039 bp)...\n",
      "[M::mem_process_seqs] Processed 278388 reads in 28.703 CPU sec, 50.170 real sec\n",
      "[M::process] read 278406 sequences (10000057 bp)...\n",
      "[M::mem_process_seqs] Processed 278406 reads in 28.647 CPU sec, 48.719 real sec\n",
      "[M::process] read 278408 sequences (10000000 bp)...\n",
      "[M::mem_process_seqs] Processed 278406 reads in 28.877 CPU sec, 48.367 real sec\n",
      "[M::process] read 278400 sequences (10000002 bp)...\n",
      "[M::mem_process_seqs] Processed 278408 reads in 27.545 CPU sec, 42.446 real sec\n",
      "[M::process] read 278396 sequences (10000011 bp)...\n",
      "[M::mem_process_seqs] Processed 278400 reads in 28.950 CPU sec, 49.289 real sec\n",
      "[M::process] read 278406 sequences (10000007 bp)...\n",
      "[M::mem_process_seqs] Processed 278396 reads in 28.663 CPU sec, 47.444 real sec\n",
      "[M::process] read 278394 sequences (10000013 bp)...\n",
      "[M::mem_process_seqs] Processed 278406 reads in 29.141 CPU sec, 50.108 real sec\n",
      "[M::process] read 222952 sequences (8008281 bp)...\n",
      "[M::mem_process_seqs] Processed 278394 reads in 28.390 CPU sec, 46.600 real sec\n",
      "[M::mem_process_seqs] Processed 222952 reads in 22.549 CPU sec, 36.695 real sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alignment Progress:  50%|\u001b[33m██████████████████████                      \u001b[0m| 3/6 files\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem /home/mahendra/Desktop/Python/Project/Ref/GCF_000001405.40_GRCh38.p14_genomic.fna trimmed_fastq/SRR085471_trimmed.fastq.gz\n",
      "[main] Real time: 2613.812 sec; CPU: 1572.619 sec\n",
      "Alignment completed for trimmed_fastq/SRR085471_trimmed.fastq.gz, output saved to aligned_sam/SRR085471.sam\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 286376 sequences (10000022 bp)...\n",
      "[M::process] read 286374 sequences (10000056 bp)...\n",
      "[M::mem_process_seqs] Processed 286376 reads in 39.932 CPU sec, 89.680 real sec\n",
      "[M::process] read 286340 sequences (10000030 bp)...\n",
      "[M::mem_process_seqs] Processed 286374 reads in 33.506 CPU sec, 48.115 real sec\n",
      "[M::process] read 286342 sequences (10000023 bp)...\n",
      "[M::mem_process_seqs] Processed 286340 reads in 35.674 CPU sec, 59.341 real sec\n",
      "[M::process] read 286352 sequences (10000069 bp)...\n",
      "[M::mem_process_seqs] Processed 286342 reads in 35.117 CPU sec, 55.816 real sec\n",
      "[M::process] read 286336 sequences (10000055 bp)...\n",
      "[M::mem_process_seqs] Processed 286352 reads in 34.406 CPU sec, 52.754 real sec\n",
      "[M::process] read 286368 sequences (10000037 bp)...\n",
      "[M::mem_process_seqs] Processed 286336 reads in 34.231 CPU sec, 50.606 real sec\n",
      "[M::process] read 286342 sequences (10000061 bp)...\n",
      "[M::mem_process_seqs] Processed 286368 reads in 33.856 CPU sec, 49.245 real sec\n",
      "[M::process] read 286344 sequences (10000054 bp)...\n",
      "[M::mem_process_seqs] Processed 286342 reads in 35.164 CPU sec, 56.060 real sec\n",
      "[M::process] read 286378 sequences (10000035 bp)...\n",
      "[M::mem_process_seqs] Processed 286344 reads in 34.299 CPU sec, 52.662 real sec\n",
      "[M::process] read 286394 sequences (10000061 bp)...\n",
      "[M::mem_process_seqs] Processed 286378 reads in 33.465 CPU sec, 47.833 real sec\n",
      "[M::process] read 286372 sequences (10000067 bp)...\n",
      "[M::mem_process_seqs] Processed 286394 reads in 34.383 CPU sec, 51.830 real sec\n",
      "[M::process] read 286386 sequences (10000031 bp)...\n",
      "[M::mem_process_seqs] Processed 286372 reads in 33.192 CPU sec, 48.164 real sec\n",
      "[M::process] read 286370 sequences (10000048 bp)...\n",
      "[M::mem_process_seqs] Processed 286386 reads in 34.637 CPU sec, 52.456 real sec\n",
      "[M::process] read 286366 sequences (10000022 bp)...\n",
      "[M::mem_process_seqs] Processed 286370 reads in 34.255 CPU sec, 52.522 real sec\n",
      "[M::process] read 286360 sequences (10000028 bp)...\n",
      "[M::mem_process_seqs] Processed 286366 reads in 34.431 CPU sec, 52.985 real sec\n",
      "[M::process] read 286348 sequences (10000062 bp)...\n",
      "[M::mem_process_seqs] Processed 286360 reads in 34.098 CPU sec, 50.488 real sec\n",
      "[M::process] read 286378 sequences (10000003 bp)...\n",
      "[M::mem_process_seqs] Processed 286348 reads in 34.634 CPU sec, 51.706 real sec\n",
      "[M::process] read 286388 sequences (10000000 bp)...\n",
      "[M::mem_process_seqs] Processed 286378 reads in 33.881 CPU sec, 49.015 real sec\n",
      "[M::process] read 286400 sequences (10000059 bp)...\n",
      "[M::mem_process_seqs] Processed 286388 reads in 34.141 CPU sec, 49.984 real sec\n",
      "[M::process] read 286348 sequences (10000007 bp)...\n",
      "[M::mem_process_seqs] Processed 286400 reads in 36.803 CPU sec, 55.205 real sec\n",
      "[M::process] read 286344 sequences (10000021 bp)...\n",
      "[M::mem_process_seqs] Processed 286348 reads in 33.979 CPU sec, 49.417 real sec\n",
      "[M::process] read 286342 sequences (10000060 bp)...\n",
      "[M::mem_process_seqs] Processed 286344 reads in 34.314 CPU sec, 51.251 real sec\n",
      "[M::process] read 286330 sequences (10000017 bp)...\n",
      "[M::mem_process_seqs] Processed 286342 reads in 35.243 CPU sec, 55.470 real sec\n",
      "[M::process] read 286348 sequences (10000038 bp)...\n",
      "[M::mem_process_seqs] Processed 286330 reads in 34.392 CPU sec, 51.803 real sec\n",
      "[M::process] read 286298 sequences (10000011 bp)...\n",
      "[M::mem_process_seqs] Processed 286348 reads in 34.354 CPU sec, 51.783 real sec\n",
      "[M::process] read 286338 sequences (10000043 bp)...\n",
      "[M::mem_process_seqs] Processed 286298 reads in 33.606 CPU sec, 49.345 real sec\n",
      "[M::process] read 286316 sequences (10000022 bp)...\n",
      "[M::mem_process_seqs] Processed 286338 reads in 33.131 CPU sec, 47.166 real sec\n",
      "[M::process] read 286366 sequences (10000065 bp)...\n",
      "[M::mem_process_seqs] Processed 286316 reads in 33.854 CPU sec, 49.824 real sec\n",
      "[M::process] read 286338 sequences (10000068 bp)...\n",
      "[M::mem_process_seqs] Processed 286366 reads in 34.157 CPU sec, 52.926 real sec\n",
      "[M::process] read 286342 sequences (10000053 bp)...\n",
      "[M::mem_process_seqs] Processed 286338 reads in 33.743 CPU sec, 48.433 real sec\n",
      "[M::process] read 286362 sequences (10000031 bp)...\n",
      "[M::mem_process_seqs] Processed 286342 reads in 33.088 CPU sec, 46.000 real sec\n",
      "[M::process] read 286358 sequences (10000007 bp)...\n",
      "[M::mem_process_seqs] Processed 286362 reads in 33.693 CPU sec, 49.345 real sec\n",
      "[M::process] read 286322 sequences (10000040 bp)...\n",
      "[M::mem_process_seqs] Processed 286358 reads in 33.700 CPU sec, 49.249 real sec\n",
      "[M::process] read 286340 sequences (10000016 bp)...\n",
      "[M::mem_process_seqs] Processed 286322 reads in 33.868 CPU sec, 50.443 real sec\n",
      "[M::process] read 286334 sequences (10000012 bp)...\n",
      "[M::mem_process_seqs] Processed 286340 reads in 34.132 CPU sec, 51.263 real sec\n",
      "[M::process] read 286342 sequences (10000004 bp)...\n",
      "[M::mem_process_seqs] Processed 286334 reads in 33.904 CPU sec, 50.244 real sec\n",
      "[M::process] read 286344 sequences (10000060 bp)...\n",
      "[M::mem_process_seqs] Processed 286342 reads in 34.706 CPU sec, 54.475 real sec\n",
      "[M::process] read 286358 sequences (10000060 bp)...\n",
      "[M::mem_process_seqs] Processed 286344 reads in 33.822 CPU sec, 49.885 real sec\n",
      "[M::process] read 286348 sequences (10000044 bp)...\n",
      "[M::mem_process_seqs] Processed 286358 reads in 33.700 CPU sec, 52.425 real sec\n",
      "[M::process] read 286354 sequences (10000063 bp)...\n",
      "[M::mem_process_seqs] Processed 286348 reads in 33.541 CPU sec, 47.928 real sec\n",
      "[M::process] read 286336 sequences (10000034 bp)...\n",
      "[M::mem_process_seqs] Processed 286354 reads in 35.491 CPU sec, 57.503 real sec\n",
      "[M::process] read 286356 sequences (10000061 bp)...\n",
      "[M::mem_process_seqs] Processed 286336 reads in 33.326 CPU sec, 48.088 real sec\n",
      "[M::process] read 286340 sequences (10000024 bp)...\n",
      "[M::mem_process_seqs] Processed 286356 reads in 33.042 CPU sec, 46.503 real sec\n",
      "[M::process] read 286346 sequences (10000035 bp)...\n",
      "[M::mem_process_seqs] Processed 286340 reads in 34.540 CPU sec, 53.939 real sec\n",
      "[M::process] read 286340 sequences (10000067 bp)...\n",
      "[M::mem_process_seqs] Processed 286346 reads in 32.822 CPU sec, 45.969 real sec\n",
      "[M::process] read 286342 sequences (10000040 bp)...\n",
      "[M::mem_process_seqs] Processed 286340 reads in 34.345 CPU sec, 52.138 real sec\n",
      "[M::process] read 286330 sequences (10000023 bp)...\n",
      "[M::mem_process_seqs] Processed 286342 reads in 33.286 CPU sec, 49.276 real sec\n",
      "[M::process] read 286368 sequences (10000023 bp)...\n",
      "[M::mem_process_seqs] Processed 286330 reads in 33.465 CPU sec, 50.177 real sec\n",
      "[M::process] read 196458 sequences (6861682 bp)...\n",
      "[M::mem_process_seqs] Processed 286368 reads in 34.600 CPU sec, 55.937 real sec\n",
      "[M::mem_process_seqs] Processed 196458 reads in 22.869 CPU sec, 34.530 real sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alignment Progress:  67%|\u001b[33m█████████████████████████████▎              \u001b[0m| 4/6 files\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem /home/mahendra/Desktop/Python/Project/Ref/GCF_000001405.40_GRCh38.p14_genomic.fna trimmed_fastq/SRR085473_trimmed.fastq.gz\n",
      "[main] Real time: 2591.593 sec; CPU: 1708.399 sec\n",
      "Alignment completed for trimmed_fastq/SRR085473_trimmed.fastq.gz, output saved to aligned_sam/SRR085473.sam\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 286372 sequences (10000059 bp)...\n",
      "[M::process] read 286358 sequences (10000024 bp)...\n",
      "[M::mem_process_seqs] Processed 286372 reads in 34.433 CPU sec, 70.224 real sec\n",
      "[M::process] read 286350 sequences (10000028 bp)...\n",
      "[M::mem_process_seqs] Processed 286358 reads in 30.851 CPU sec, 48.177 real sec\n",
      "[M::process] read 286362 sequences (10000016 bp)...\n",
      "[M::mem_process_seqs] Processed 286350 reads in 30.761 CPU sec, 47.870 real sec\n",
      "[M::process] read 286340 sequences (10000030 bp)...\n",
      "[M::mem_process_seqs] Processed 286362 reads in 31.243 CPU sec, 49.331 real sec\n",
      "[M::process] read 286342 sequences (10000003 bp)...\n",
      "[M::mem_process_seqs] Processed 286340 reads in 32.311 CPU sec, 54.938 real sec\n",
      "[M::process] read 286354 sequences (10000011 bp)...\n",
      "[M::mem_process_seqs] Processed 286342 reads in 32.034 CPU sec, 55.429 real sec\n",
      "[M::process] read 286366 sequences (10000025 bp)...\n",
      "[M::mem_process_seqs] Processed 286354 reads in 31.639 CPU sec, 51.438 real sec\n",
      "[M::process] read 286368 sequences (10000047 bp)...\n",
      "[M::mem_process_seqs] Processed 286366 reads in 32.352 CPU sec, 55.688 real sec\n",
      "[M::process] read 286362 sequences (10000016 bp)...\n",
      "[M::mem_process_seqs] Processed 286368 reads in 31.016 CPU sec, 47.966 real sec\n",
      "[M::process] read 286368 sequences (10000026 bp)...\n",
      "[M::mem_process_seqs] Processed 286362 reads in 31.748 CPU sec, 51.265 real sec\n",
      "[M::process] read 286366 sequences (10000051 bp)...\n",
      "[M::mem_process_seqs] Processed 286368 reads in 31.147 CPU sec, 48.724 real sec\n",
      "[M::process] read 286362 sequences (10000051 bp)...\n",
      "[M::mem_process_seqs] Processed 286366 reads in 31.393 CPU sec, 50.540 real sec\n",
      "[M::process] read 286364 sequences (10000014 bp)...\n",
      "[M::mem_process_seqs] Processed 286362 reads in 31.605 CPU sec, 51.209 real sec\n",
      "[M::process] read 286362 sequences (10000021 bp)...\n",
      "[M::mem_process_seqs] Processed 286364 reads in 32.389 CPU sec, 53.595 real sec\n",
      "[M::process] read 286370 sequences (10000018 bp)...\n",
      "[M::mem_process_seqs] Processed 286362 reads in 31.307 CPU sec, 51.419 real sec\n",
      "[M::process] read 286372 sequences (10000032 bp)...\n",
      "[M::mem_process_seqs] Processed 286370 reads in 30.292 CPU sec, 45.524 real sec\n",
      "[M::process] read 286368 sequences (10000031 bp)...\n",
      "[M::mem_process_seqs] Processed 286372 reads in 31.219 CPU sec, 49.739 real sec\n",
      "[M::process] read 286350 sequences (10000011 bp)...\n",
      "[M::mem_process_seqs] Processed 286368 reads in 31.127 CPU sec, 49.177 real sec\n",
      "[M::process] read 286370 sequences (10000054 bp)...\n",
      "[M::mem_process_seqs] Processed 286350 reads in 30.648 CPU sec, 47.173 real sec\n",
      "[M::process] read 286364 sequences (10000043 bp)...\n",
      "[M::mem_process_seqs] Processed 286370 reads in 31.953 CPU sec, 52.655 real sec\n",
      "[M::process] read 286376 sequences (10000048 bp)...\n",
      "[M::mem_process_seqs] Processed 286364 reads in 32.088 CPU sec, 53.621 real sec\n",
      "[M::process] read 286360 sequences (10000056 bp)...\n",
      "[M::mem_process_seqs] Processed 286376 reads in 30.547 CPU sec, 46.452 real sec\n",
      "[M::process] read 286372 sequences (10000060 bp)...\n",
      "[M::mem_process_seqs] Processed 286360 reads in 31.228 CPU sec, 49.021 real sec\n",
      "[M::process] read 286362 sequences (10000058 bp)...\n",
      "[M::mem_process_seqs] Processed 286372 reads in 31.981 CPU sec, 54.045 real sec\n",
      "[M::process] read 286364 sequences (10000032 bp)...\n",
      "[M::mem_process_seqs] Processed 286362 reads in 31.070 CPU sec, 48.235 real sec\n",
      "[M::process] read 286366 sequences (10000034 bp)...\n",
      "[M::mem_process_seqs] Processed 286364 reads in 31.971 CPU sec, 52.296 real sec\n",
      "[M::process] read 286372 sequences (10000004 bp)...\n",
      "[M::mem_process_seqs] Processed 286366 reads in 31.819 CPU sec, 52.408 real sec\n",
      "[M::process] read 286364 sequences (10000028 bp)...\n",
      "[M::mem_process_seqs] Processed 286372 reads in 30.529 CPU sec, 46.163 real sec\n",
      "[M::process] read 286362 sequences (10000048 bp)...\n",
      "[M::mem_process_seqs] Processed 286364 reads in 33.091 CPU sec, 58.377 real sec\n",
      "[M::process] read 286360 sequences (10000041 bp)...\n",
      "[M::mem_process_seqs] Processed 286362 reads in 31.658 CPU sec, 52.838 real sec\n",
      "[M::process] read 286372 sequences (10000067 bp)...\n",
      "[M::mem_process_seqs] Processed 286360 reads in 31.529 CPU sec, 51.305 real sec\n",
      "[M::process] read 286360 sequences (10000031 bp)...\n",
      "[M::mem_process_seqs] Processed 286372 reads in 31.220 CPU sec, 49.556 real sec\n",
      "[M::process] read 286358 sequences (10000029 bp)...\n",
      "[M::mem_process_seqs] Processed 286360 reads in 31.075 CPU sec, 50.677 real sec\n",
      "[M::process] read 286368 sequences (10000045 bp)...\n",
      "[M::mem_process_seqs] Processed 286358 reads in 30.638 CPU sec, 47.017 real sec\n",
      "[M::process] read 286374 sequences (10000015 bp)...\n",
      "[M::mem_process_seqs] Processed 286368 reads in 31.428 CPU sec, 49.912 real sec\n",
      "[M::process] read 286374 sequences (10000044 bp)...\n",
      "[M::mem_process_seqs] Processed 286374 reads in 32.303 CPU sec, 54.164 real sec\n",
      "[M::process] read 286340 sequences (10000056 bp)...\n",
      "[M::mem_process_seqs] Processed 286374 reads in 31.746 CPU sec, 50.579 real sec\n",
      "[M::process] read 286348 sequences (10000002 bp)...\n",
      "[M::mem_process_seqs] Processed 286340 reads in 31.703 CPU sec, 50.859 real sec\n",
      "[M::process] read 286366 sequences (10000034 bp)...\n",
      "[M::mem_process_seqs] Processed 286348 reads in 32.171 CPU sec, 53.151 real sec\n",
      "[M::process] read 286354 sequences (10000040 bp)...\n",
      "[M::mem_process_seqs] Processed 286366 reads in 30.880 CPU sec, 47.582 real sec\n",
      "[M::process] read 286360 sequences (10000055 bp)...\n",
      "[M::mem_process_seqs] Processed 286354 reads in 31.423 CPU sec, 50.750 real sec\n",
      "[M::process] read 286372 sequences (10000020 bp)...\n",
      "[M::mem_process_seqs] Processed 286360 reads in 31.562 CPU sec, 53.806 real sec\n",
      "[M::process] read 286360 sequences (10000040 bp)...\n",
      "[M::mem_process_seqs] Processed 286372 reads in 31.583 CPU sec, 51.613 real sec\n",
      "[M::process] read 286362 sequences (10000064 bp)...\n",
      "[M::mem_process_seqs] Processed 286360 reads in 31.109 CPU sec, 49.211 real sec\n",
      "[M::process] read 286362 sequences (10000061 bp)...\n",
      "[M::mem_process_seqs] Processed 286362 reads in 31.506 CPU sec, 50.971 real sec\n",
      "[M::process] read 286370 sequences (10000012 bp)...\n",
      "[M::mem_process_seqs] Processed 286362 reads in 31.137 CPU sec, 49.830 real sec\n",
      "[M::process] read 286372 sequences (10000005 bp)...\n",
      "[M::mem_process_seqs] Processed 286370 reads in 31.311 CPU sec, 50.539 real sec\n",
      "[M::process] read 286358 sequences (10000009 bp)...\n",
      "[M::mem_process_seqs] Processed 286372 reads in 31.767 CPU sec, 53.786 real sec\n",
      "[M::process] read 286362 sequences (10000031 bp)...\n",
      "[M::mem_process_seqs] Processed 286358 reads in 31.119 CPU sec, 49.719 real sec\n",
      "[M::process] read 286368 sequences (10000009 bp)...\n",
      "[M::mem_process_seqs] Processed 286362 reads in 30.760 CPU sec, 48.938 real sec\n",
      "[M::process] read 286356 sequences (10000048 bp)...\n",
      "[M::mem_process_seqs] Processed 286368 reads in 30.916 CPU sec, 50.788 real sec\n",
      "[M::process] read 286366 sequences (10000002 bp)...\n",
      "[M::mem_process_seqs] Processed 286356 reads in 31.486 CPU sec, 50.776 real sec\n",
      "[M::process] read 286370 sequences (10000033 bp)...\n",
      "[M::mem_process_seqs] Processed 286366 reads in 31.312 CPU sec, 52.317 real sec\n",
      "[M::process] read 286362 sequences (10000058 bp)...\n",
      "[M::mem_process_seqs] Processed 286370 reads in 30.612 CPU sec, 46.987 real sec\n",
      "[M::process] read 22985 sequences (802792 bp)...\n",
      "[M::mem_process_seqs] Processed 286362 reads in 31.072 CPU sec, 49.621 real sec\n",
      "[M::mem_process_seqs] Processed 22985 reads in 2.747 CPU sec, 4.920 real sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alignment Progress:  83%|\u001b[33m████████████████████████████████████▋       \u001b[0m| 5/6 files\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem /home/mahendra/Desktop/Python/Project/Ref/GCF_000001405.40_GRCh38.p14_genomic.fna trimmed_fastq/SRR085474_trimmed.fastq.gz\n",
      "[main] Real time: 2826.703 sec; CPU: 1740.923 sec\n",
      "Alignment completed for trimmed_fastq/SRR085474_trimmed.fastq.gz, output saved to aligned_sam/SRR085474.sam\n",
      "[M::bwa_idx_load_from_disk] read 0 ALT contigs\n",
      "[M::process] read 286374 sequences (10000065 bp)...\n",
      "[M::process] read 286366 sequences (10000054 bp)...\n",
      "[M::mem_process_seqs] Processed 286374 reads in 37.640 CPU sec, 80.877 real sec\n",
      "[M::process] read 286354 sequences (10000023 bp)...\n",
      "[M::mem_process_seqs] Processed 286366 reads in 32.345 CPU sec, 50.570 real sec\n",
      "[M::process] read 286342 sequences (10000059 bp)...\n",
      "[M::mem_process_seqs] Processed 286354 reads in 32.487 CPU sec, 51.513 real sec\n",
      "[M::process] read 286358 sequences (10000047 bp)...\n",
      "[M::mem_process_seqs] Processed 286342 reads in 32.500 CPU sec, 51.517 real sec\n",
      "[M::process] read 286344 sequences (10000054 bp)...\n",
      "[M::mem_process_seqs] Processed 286358 reads in 33.347 CPU sec, 53.759 real sec\n",
      "[M::process] read 286382 sequences (10000054 bp)...\n",
      "[M::mem_process_seqs] Processed 286344 reads in 32.518 CPU sec, 50.610 real sec\n",
      "[M::process] read 286376 sequences (10000011 bp)...\n",
      "[M::mem_process_seqs] Processed 286382 reads in 32.341 CPU sec, 48.967 real sec\n",
      "[M::process] read 286370 sequences (10000005 bp)...\n",
      "[M::mem_process_seqs] Processed 286376 reads in 32.964 CPU sec, 51.074 real sec\n",
      "[M::process] read 286360 sequences (10000014 bp)...\n",
      "[M::mem_process_seqs] Processed 286370 reads in 32.508 CPU sec, 50.883 real sec\n",
      "[M::process] read 286364 sequences (10000038 bp)...\n",
      "[M::mem_process_seqs] Processed 286360 reads in 33.086 CPU sec, 51.759 real sec\n",
      "[M::process] read 286376 sequences (10000009 bp)...\n",
      "[M::mem_process_seqs] Processed 286364 reads in 34.104 CPU sec, 57.557 real sec\n",
      "[M::process] read 286366 sequences (10000063 bp)...\n",
      "[M::mem_process_seqs] Processed 286376 reads in 32.645 CPU sec, 53.329 real sec\n",
      "[M::process] read 286390 sequences (10000038 bp)...\n",
      "[M::mem_process_seqs] Processed 286366 reads in 33.079 CPU sec, 52.149 real sec\n",
      "[M::process] read 286380 sequences (10000069 bp)...\n",
      "[M::mem_process_seqs] Processed 286390 reads in 33.280 CPU sec, 53.678 real sec\n",
      "[M::process] read 286368 sequences (10000061 bp)...\n",
      "[M::mem_process_seqs] Processed 286380 reads in 33.002 CPU sec, 52.221 real sec\n",
      "[M::process] read 286388 sequences (10000060 bp)...\n",
      "[M::mem_process_seqs] Processed 286368 reads in 32.716 CPU sec, 50.421 real sec\n",
      "[M::process] read 286376 sequences (10000067 bp)...\n",
      "[M::mem_process_seqs] Processed 286388 reads in 32.893 CPU sec, 51.940 real sec\n",
      "[M::process] read 286356 sequences (10000032 bp)...\n",
      "[M::mem_process_seqs] Processed 286376 reads in 34.578 CPU sec, 59.857 real sec\n",
      "[M::process] read 286366 sequences (10000044 bp)...\n",
      "[M::mem_process_seqs] Processed 286356 reads in 32.475 CPU sec, 50.896 real sec\n",
      "[M::process] read 286366 sequences (10000061 bp)...\n",
      "[M::mem_process_seqs] Processed 286366 reads in 33.143 CPU sec, 54.493 real sec\n",
      "[M::process] read 286358 sequences (10000038 bp)...\n",
      "[M::mem_process_seqs] Processed 286366 reads in 32.264 CPU sec, 48.727 real sec\n",
      "[M::process] read 286376 sequences (10000011 bp)...\n",
      "[M::mem_process_seqs] Processed 286358 reads in 30.180 CPU sec, 47.111 real sec\n",
      "[M::process] read 286386 sequences (10000061 bp)...\n",
      "[M::mem_process_seqs] Processed 286376 reads in 32.386 CPU sec, 48.973 real sec\n",
      "[M::process] read 286362 sequences (10000052 bp)...\n",
      "[M::mem_process_seqs] Processed 286386 reads in 32.183 CPU sec, 48.710 real sec\n",
      "[M::process] read 286354 sequences (10000017 bp)...\n",
      "[M::mem_process_seqs] Processed 286362 reads in 32.231 CPU sec, 48.408 real sec\n",
      "[M::process] read 286380 sequences (10000003 bp)...\n",
      "[M::mem_process_seqs] Processed 286354 reads in 32.426 CPU sec, 49.717 real sec\n",
      "[M::process] read 286352 sequences (10000041 bp)...\n",
      "[M::mem_process_seqs] Processed 286380 reads in 32.823 CPU sec, 51.017 real sec\n",
      "[M::process] read 286348 sequences (10000063 bp)...\n",
      "[M::mem_process_seqs] Processed 286352 reads in 34.321 CPU sec, 59.390 real sec\n",
      "[M::process] read 286354 sequences (10000013 bp)...\n",
      "[M::mem_process_seqs] Processed 286348 reads in 33.312 CPU sec, 52.430 real sec\n",
      "[M::process] read 286362 sequences (10000068 bp)...\n",
      "[M::mem_process_seqs] Processed 286354 reads in 32.409 CPU sec, 53.642 real sec\n",
      "[M::process] read 286372 sequences (10000036 bp)...\n",
      "[M::mem_process_seqs] Processed 286362 reads in 32.243 CPU sec, 49.196 real sec\n",
      "[M::process] read 286394 sequences (10000060 bp)...\n",
      "[M::mem_process_seqs] Processed 286372 reads in 32.869 CPU sec, 51.886 real sec\n",
      "[M::process] read 286374 sequences (10000009 bp)...\n",
      "[M::mem_process_seqs] Processed 286394 reads in 32.491 CPU sec, 49.981 real sec\n",
      "[M::process] read 286372 sequences (10000013 bp)...\n",
      "[M::mem_process_seqs] Processed 286374 reads in 33.148 CPU sec, 52.269 real sec\n",
      "[M::process] read 286348 sequences (10000051 bp)...\n",
      "[M::mem_process_seqs] Processed 286372 reads in 32.419 CPU sec, 50.614 real sec\n",
      "[M::process] read 286370 sequences (10000008 bp)...\n",
      "[M::mem_process_seqs] Processed 286348 reads in 32.844 CPU sec, 51.896 real sec\n",
      "[M::process] read 286354 sequences (10000009 bp)...\n",
      "[M::mem_process_seqs] Processed 286370 reads in 33.405 CPU sec, 55.645 real sec\n",
      "[M::process] read 286374 sequences (10000049 bp)...\n",
      "[M::mem_process_seqs] Processed 286354 reads in 32.378 CPU sec, 49.245 real sec\n",
      "[M::process] read 286380 sequences (10000029 bp)...\n",
      "[M::mem_process_seqs] Processed 286374 reads in 33.247 CPU sec, 55.541 real sec\n",
      "[M::process] read 286372 sequences (10000033 bp)...\n",
      "[M::mem_process_seqs] Processed 286380 reads in 33.372 CPU sec, 54.360 real sec\n",
      "[M::process] read 286372 sequences (10000022 bp)...\n",
      "[M::mem_process_seqs] Processed 286372 reads in 32.687 CPU sec, 51.060 real sec\n",
      "[M::process] read 286380 sequences (10000067 bp)...\n",
      "[M::mem_process_seqs] Processed 286372 reads in 32.410 CPU sec, 50.031 real sec\n",
      "[M::process] read 286362 sequences (10000025 bp)...\n",
      "[M::mem_process_seqs] Processed 286380 reads in 33.484 CPU sec, 55.617 real sec\n",
      "[M::process] read 286376 sequences (10000004 bp)...\n",
      "[M::mem_process_seqs] Processed 286362 reads in 32.556 CPU sec, 51.738 real sec\n",
      "[M::process] read 286382 sequences (10000062 bp)...\n",
      "[M::mem_process_seqs] Processed 286376 reads in 33.605 CPU sec, 54.591 real sec\n",
      "[M::process] read 286382 sequences (10000032 bp)...\n",
      "[M::mem_process_seqs] Processed 286382 reads in 32.575 CPU sec, 50.616 real sec\n",
      "[M::process] read 286382 sequences (10000035 bp)...\n",
      "[M::mem_process_seqs] Processed 286382 reads in 32.352 CPU sec, 52.249 real sec\n",
      "[M::process] read 286384 sequences (10000006 bp)...\n",
      "[M::mem_process_seqs] Processed 286382 reads in 32.901 CPU sec, 51.835 real sec\n",
      "[M::process] read 286368 sequences (10000058 bp)...\n",
      "[M::mem_process_seqs] Processed 286384 reads in 37.933 CPU sec, 65.599 real sec\n",
      "[M::process] read 286354 sequences (10000019 bp)...\n",
      "[M::mem_process_seqs] Processed 286368 reads in 33.673 CPU sec, 57.245 real sec\n",
      "[M::process] read 286346 sequences (10000049 bp)...\n",
      "[M::mem_process_seqs] Processed 286354 reads in 33.977 CPU sec, 57.085 real sec\n",
      "[M::process] read 286360 sequences (10000032 bp)...\n",
      "[M::mem_process_seqs] Processed 286346 reads in 34.732 CPU sec, 61.384 real sec\n",
      "[M::process] read 51320 sequences (1792114 bp)...\n",
      "[M::mem_process_seqs] Processed 286360 reads in 33.264 CPU sec, 56.125 real sec\n",
      "[M::mem_process_seqs] Processed 51320 reads in 6.046 CPU sec, 10.261 real sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Alignment Progress: 100%|\u001b[33m████████████████████████████████████████████\u001b[0m| 6/6 files\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main] Version: 0.7.17-r1188\n",
      "[main] CMD: bwa mem /home/mahendra/Desktop/Python/Project/Ref/GCF_000001405.40_GRCh38.p14_genomic.fna trimmed_fastq/SRR085726_trimmed.fastq.gz\n",
      "[main] Real time: 2844.202 sec; CPU: 1766.266 sec\n",
      "Alignment completed for trimmed_fastq/SRR085726_trimmed.fastq.gz, output saved to aligned_sam/SRR085726.sam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check for the human reference genome\n",
    "reference_genome = '/home/mahendra/Desktop/Python/Project/Ref/GCF_000001405.40_GRCh38.p14_genomic.fna'\n",
    "if not os.path.exists(reference_genome):\n",
    "    print(\"Reference genome is not found. Please download it first.\")\n",
    "else:\n",
    "    print(\"Reference genome already downloaded.\")\n",
    "\n",
    "# Step 2: Ensure reference genome is indexed\n",
    "index_files = [reference_genome + ext for ext in ['.bwt', '.sa', '.ann', '.amb', '.pac']]\n",
    "if not all(os.path.exists(f) for f in index_files):\n",
    "    print(\"Indexing the reference genome...\")\n",
    "    subprocess.run(['bwa', 'index', reference_genome])\n",
    "else:\n",
    "    print(\"Reference genome is already indexed.\")\n",
    "\n",
    "# Step 3: Run BWA mem to align each FASTQ file and save output to SAM files\n",
    "fastq_files = [os.path.join('trimmed_fastq', f) for f in [\n",
    "    'SRR087416_trimmed.fastq.gz', 'SRR085725_trimmed.fastq.gz',\n",
    "    'SRR085471_trimmed.fastq.gz', 'SRR085473_trimmed.fastq.gz',\n",
    "    'SRR085474_trimmed.fastq.gz', 'SRR085726_trimmed.fastq.gz'\n",
    "]]\n",
    "sam_dir = 'aligned_sam'\n",
    "os.makedirs(sam_dir, exist_ok=True)\n",
    "\n",
    "print(\"Running BWA mem for each FASTQ file...\")\n",
    "for fastq_file in tqdm(fastq_files, desc=\"Alignment Progress\", unit=\"file\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} files', colour=\"yellow\"):\n",
    "    output_sam = os.path.join(sam_dir, os.path.basename(fastq_file).replace('_trimmed.fastq.gz', '.sam'))\n",
    "\n",
    "    # Run BWA mem with real-time output and error handling\n",
    "    with open(output_sam, 'w') as sam_output:\n",
    "        process = subprocess.Popen(['bwa', 'mem', reference_genome, fastq_file], stdout=sam_output, stderr=subprocess.PIPE, text=True)\n",
    "\n",
    "        # Capture stderr output and print any errors\n",
    "        for line in process.stderr:\n",
    "            print(line, end=\"\")  # Real-time error output\n",
    "\n",
    "        # Wait for the process to complete and check for errors\n",
    "        return_code = process.wait()\n",
    "        if return_code != 0:\n",
    "            print(f\"Error during alignment for {fastq_file}. Check the SAM file or stderr for details.\")\n",
    "        else:\n",
    "            print(f\"Alignment completed for {fastq_file}, output saved to {output_sam}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce11de7-ad81-471a-bb7b-5ffa6f75f8f9",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"\n",
    "    background-image: url('https://i.postimg.cc/K87ByXmr/stage5.jpg');\n",
    "    background-size: cover;\n",
    "    background-repeat: no-repeat;\n",
    "    font-family: 'Arial', sans-serif;\n",
    "    font-size: 24px;\n",
    "    color: white;\n",
    "    text-align: center;\n",
    "    border-radius: 15px 50px;\n",
    "    padding: 20px 40px;\n",
    "    margin: 20px 0;\n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\">\n",
    "    <b>SAM File converted, sorted, and indexed</b>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c9e8a68f-e181-4627-b4a6-0b88c7f3f360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing SAM files:   0%|                             | 0/6 [00:00<?, ?file/s][bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "Processing SAM files:  17%|███▌                 | 1/6 [00:55<04:37, 55.42s/file][bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "Processing SAM files:  33%|███████              | 2/6 [01:55<03:52, 58.20s/file][bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "Processing SAM files:  50%|██████████▌          | 3/6 [02:57<02:59, 59.98s/file][bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "Processing SAM files:  67%|██████████████       | 4/6 [03:53<01:56, 58.42s/file][bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "Processing SAM files:  83%|█████████████████▌   | 5/6 [04:56<00:59, 59.85s/file][bam_sort_core] merging from 3 files and 1 in-memory blocks...\n",
      "Processing SAM files: 100%|█████████████████████| 6/6 [06:01<00:00, 60.33s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All SAM files have been processed: converted, sorted, and indexed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Directories for output BAM files, and sorted BAM files\n",
    "bam_dir = 'aligned_bam'\n",
    "sorted_bam_dir = 'sorted_bam'\n",
    "os.makedirs(bam_dir, exist_ok=True)\n",
    "os.makedirs(sorted_bam_dir, exist_ok=True)\n",
    "\n",
    "# List SAM files to process\n",
    "sam_files = [os.path.join(sam_dir, f) for f in os.listdir(sam_dir) if f.endswith('.sam')]\n",
    "\n",
    "# Process each SAM file: Convert to BAM, sort, and index\n",
    "for sam_file in tqdm(sam_files, desc=\"Processing SAM files\", unit=\"file\"):\n",
    "    try:\n",
    "        # Step 1: Convert SAM to BAM\n",
    "        bam_file = os.path.join(bam_dir, os.path.basename(sam_file).replace('.sam', '.bam'))\n",
    "        subprocess.run(['samtools', 'view', '-b', '-o', bam_file, sam_file], check=True)\n",
    "\n",
    "        # Step 2: Sort BAM file\n",
    "        sorted_bam_file = os.path.join(sorted_bam_dir, os.path.basename(sam_file).replace('.sam', '_sorted.bam'))\n",
    "        subprocess.run(['samtools', 'sort', '-o', sorted_bam_file, bam_file], check=True)\n",
    "\n",
    "        # Step 3: Index sorted BAM file\n",
    "        subprocess.run(['samtools', 'index', sorted_bam_file], check=True)\n",
    "\n",
    "        # Optional: Delete intermediate BAM file to save space\n",
    "        os.remove(bam_file)\n",
    "\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error processing file {sam_file}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(\"All SAM files have been processed: converted, sorted, and indexed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53326ebf-6838-49b3-b0e6-fec6965cbda4",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"\n",
    "    background-image: url('https://i.postimg.cc/K87ByXmr/stage5.jpg');\n",
    "    background-size: cover;\n",
    "    background-repeat: no-repeat;\n",
    "    font-family: 'Arial', sans-serif;\n",
    "    font-size: 24px;\n",
    "    color: white;\n",
    "    text-align: center;\n",
    "    border-radius: 15px 50px;\n",
    "    padding: 20px 40px;\n",
    "    margin: 20px 0;\n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\">\n",
    "    <b>Deduplication: Use Picard to mark and remove duplicate reads</b>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "36579b36-ea24-4d42-b234-7ccac9a9e24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO\t2024-11-17 10:04:01\tMarkDuplicates\t\n",
      "\n",
      "********** NOTE: Picard's command line syntax is changing.\n",
      "**********\n",
      "********** For more information, please see:\n",
      "********** \n",
      "https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition)\n",
      "**********\n",
      "********** The command line looks like this in the new syntax:\n",
      "**********\n",
      "**********    MarkDuplicates -I sorted_bam/SRR087416_sorted.bam -O deduplicated_bam/SRR087416_dedup.bam -M deduplicated_bam/SRR087416_metrics.txt -REMOVE_DUPLICATES true -CREATE_INDEX true\n",
      "**********\n",
      "\n",
      "\n",
      "10:04:02.300 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/mahendra/Desktop/Python/Project/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Sun Nov 17 10:04:02 IST 2024] MarkDuplicates INPUT=[sorted_bam/SRR087416_sorted.bam] OUTPUT=deduplicated_bam/SRR087416_dedup.bam METRICS_FILE=deduplicated_bam/SRR087416_metrics.txt REMOVE_DUPLICATES=true CREATE_INDEX=true    MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP=50000 MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=8000 SORTING_COLLECTION_SIZE_RATIO=0.25 TAG_DUPLICATE_SET_MEMBERS=false REMOVE_SEQUENCING_DUPLICATES=false TAGGING_POLICY=DontTag CLEAR_DT=true DUPLEX_UMI=false FLOW_MODE=false FLOW_QUALITY_SUM_STRATEGY=false USE_END_IN_UNPAIRED_READS=false USE_UNPAIRED_CLIPPED_END=false UNPAIRED_END_UNCERTAINTY=0 FLOW_SKIP_FIRST_N_FLOWS=0 FLOW_Q_IS_KNOWN_END=false FLOW_EFFECTIVE_QUALITY_THRESHOLD=15 ADD_PG_TAG_TO_READS=true ASSUME_SORTED=false DUPLICATE_SCORING_STRATEGY=SUM_OF_BASE_QUALITIES PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates READ_NAME_REGEX=<optimized capture of last three ':' separated fields as numeric values> OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 MAX_OPTICAL_DUPLICATE_SET_SIZE=300000 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false\n",
      "[Sun Nov 17 10:04:02 IST 2024] Executing as mahendra@ms on Linux 6.8.0-47-generic amd64; OpenJDK 64-Bit Server VM 17.0.10+7; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.27.4-SNAPSHOT\n",
      "INFO\t2024-11-17 10:04:02\tMarkDuplicates\tStart of doWork freeMemory: 33955056; totalMemory: 41943040; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:04:02\tMarkDuplicates\tReading input file and constructing read end information.\n",
      "INFO\t2024-11-17 10:04:02\tMarkDuplicates\tWill retain up to 15561475 data points before spilling to disk.\n",
      "WARNING\t2024-11-17 10:04:02\tAbstractOpticalDuplicateFinderCommandLineProgram\tA field field parsed out of a read name was expected to contain an integer and did not. Read name: SRR087416.14632905. Cause: String 'SRR087416.14632905' did not start with a parsable number.\n",
      "INFO\t2024-11-17 10:04:05\tMarkDuplicates\tRead     1,000,000 records.  Elapsed time: 00:00:02s.  Time for last 1,000,000:    2s.  Last read position: NC_000001.11:153,779,716\n",
      "INFO\t2024-11-17 10:04:05\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:04:07\tMarkDuplicates\tRead     2,000,000 records.  Elapsed time: 00:00:04s.  Time for last 1,000,000:    2s.  Last read position: NC_000003.12:42,667,481\n",
      "INFO\t2024-11-17 10:04:07\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:04:09\tMarkDuplicates\tRead     3,000,000 records.  Elapsed time: 00:00:07s.  Time for last 1,000,000:    2s.  Last read position: NC_000005.10:134,927,047\n",
      "INFO\t2024-11-17 10:04:09\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:04:11\tMarkDuplicates\tRead     4,000,000 records.  Elapsed time: 00:00:09s.  Time for last 1,000,000:    2s.  Last read position: NC_000007.14:151,378,041\n",
      "INFO\t2024-11-17 10:04:11\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:04:13\tMarkDuplicates\tRead     5,000,000 records.  Elapsed time: 00:00:11s.  Time for last 1,000,000:    2s.  Last read position: NC_000010.11:119,828,230\n",
      "INFO\t2024-11-17 10:04:13\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:04:15\tMarkDuplicates\tRead     6,000,000 records.  Elapsed time: 00:00:13s.  Time for last 1,000,000:    2s.  Last read position: NC_000012.12:71,923,143\n",
      "INFO\t2024-11-17 10:04:15\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:04:17\tMarkDuplicates\tRead     7,000,000 records.  Elapsed time: 00:00:15s.  Time for last 1,000,000:    2s.  Last read position: NC_000016.10:2,645,934\n",
      "INFO\t2024-11-17 10:04:17\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:04:20\tMarkDuplicates\tRead     8,000,000 records.  Elapsed time: 00:00:17s.  Time for last 1,000,000:    2s.  Last read position: NC_000018.10:37,924,288\n",
      "INFO\t2024-11-17 10:04:20\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:04:22\tMarkDuplicates\tRead     9,000,000 records.  Elapsed time: 00:00:19s.  Time for last 1,000,000:    2s.  Last read position: NC_000020.11:54,028,411\n",
      "INFO\t2024-11-17 10:04:22\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:04:24\tMarkDuplicates\tRead    10,000,000 records.  Elapsed time: 00:00:21s.  Time for last 1,000,000:    2s.  Last read position: NT_167214.1:118,026\n",
      "INFO\t2024-11-17 10:04:24\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:04:26\tMarkDuplicates\tRead    11,000,000 records.  Elapsed time: 00:00:23s.  Time for last 1,000,000:    2s.  Last read position: NC_012920.1:2,346\n",
      "INFO\t2024-11-17 10:04:26\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:04:28\tMarkDuplicates\tRead    12,000,000 records.  Elapsed time: 00:00:25s.  Time for last 1,000,000:    1s.  Last read position: NC_012920.1:6,245\n",
      "INFO\t2024-11-17 10:04:28\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:04:30\tMarkDuplicates\tRead    13,000,000 records.  Elapsed time: 00:00:27s.  Time for last 1,000,000:    2s.  Last read position: NC_012920.1:10,369\n",
      "INFO\t2024-11-17 10:04:30\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:04:31\tMarkDuplicates\tRead 13795155 records. 0 pairs never matched.\n",
      "INFO\t2024-11-17 10:04:32\tMarkDuplicates\tAfter buildSortedReadEndLists freeMemory: 771511528; totalMemory: 1902116864; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:04:32\tMarkDuplicates\tWill retain up to 134217728 duplicate indices before spilling to disk.\n",
      "INFO\t2024-11-17 10:04:32\tMarkDuplicates\tTraversing read pair information and detecting duplicates.\n",
      "INFO\t2024-11-17 10:04:32\tMarkDuplicates\tTraversing fragment information and detecting duplicates.\n",
      "INFO\t2024-11-17 10:04:34\tMarkDuplicates\tSorting list of duplicate records.\n",
      "INFO\t2024-11-17 10:04:34\tMarkDuplicates\tAfter generateDuplicateIndexes freeMemory: 2369026040; totalMemory: 3454009344; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:04:34\tMarkDuplicates\tMarking 7078054 records as duplicates.\n",
      "INFO\t2024-11-17 10:04:34\tMarkDuplicates\tFound 0 optical duplicate clusters.\n",
      "INFO\t2024-11-17 10:04:34\tMarkDuplicates\tReads are assumed to be ordered by: coordinate\n",
      "INFO\t2024-11-17 10:05:05\tMarkDuplicates\tWriting complete. Closing input iterator.\n",
      "INFO\t2024-11-17 10:05:05\tMarkDuplicates\tDuplicate Index cleanup.\n",
      "INFO\t2024-11-17 10:05:05\tMarkDuplicates\tGetting Memory Stats.\n",
      "INFO\t2024-11-17 10:05:05\tMarkDuplicates\tBefore output close freeMemory: 61331136; totalMemory: 71303168; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:05:05\tMarkDuplicates\tClosed outputs. Getting more Memory Stats.\n",
      "INFO\t2024-11-17 10:05:05\tMarkDuplicates\tAfter output close freeMemory: 32306096; totalMemory: 41943040; maxMemory: 4294967296\n",
      "[Sun Nov 17 10:05:05 IST 2024] picard.sam.markduplicates.MarkDuplicates done. Elapsed time: 1.05 minutes.\n",
      "Runtime.totalMemory()=41943040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplication completed for sorted_bam/SRR087416_sorted.bam, output BAM: deduplicated_bam/SRR087416_dedup.bam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO\t2024-11-17 10:05:06\tMarkDuplicates\t\n",
      "\n",
      "********** NOTE: Picard's command line syntax is changing.\n",
      "**********\n",
      "********** For more information, please see:\n",
      "********** \n",
      "https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition)\n",
      "**********\n",
      "********** The command line looks like this in the new syntax:\n",
      "**********\n",
      "**********    MarkDuplicates -I sorted_bam/SRR085725_sorted.bam -O deduplicated_bam/SRR085725_dedup.bam -M deduplicated_bam/SRR085725_metrics.txt -REMOVE_DUPLICATES true -CREATE_INDEX true\n",
      "**********\n",
      "\n",
      "\n",
      "10:05:06.524 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/mahendra/Desktop/Python/Project/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Sun Nov 17 10:05:06 IST 2024] MarkDuplicates INPUT=[sorted_bam/SRR085725_sorted.bam] OUTPUT=deduplicated_bam/SRR085725_dedup.bam METRICS_FILE=deduplicated_bam/SRR085725_metrics.txt REMOVE_DUPLICATES=true CREATE_INDEX=true    MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP=50000 MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=8000 SORTING_COLLECTION_SIZE_RATIO=0.25 TAG_DUPLICATE_SET_MEMBERS=false REMOVE_SEQUENCING_DUPLICATES=false TAGGING_POLICY=DontTag CLEAR_DT=true DUPLEX_UMI=false FLOW_MODE=false FLOW_QUALITY_SUM_STRATEGY=false USE_END_IN_UNPAIRED_READS=false USE_UNPAIRED_CLIPPED_END=false UNPAIRED_END_UNCERTAINTY=0 FLOW_SKIP_FIRST_N_FLOWS=0 FLOW_Q_IS_KNOWN_END=false FLOW_EFFECTIVE_QUALITY_THRESHOLD=15 ADD_PG_TAG_TO_READS=true ASSUME_SORTED=false DUPLICATE_SCORING_STRATEGY=SUM_OF_BASE_QUALITIES PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates READ_NAME_REGEX=<optimized capture of last three ':' separated fields as numeric values> OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 MAX_OPTICAL_DUPLICATE_SET_SIZE=300000 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false\n",
      "[Sun Nov 17 10:05:06 IST 2024] Executing as mahendra@ms on Linux 6.8.0-47-generic amd64; OpenJDK 64-Bit Server VM 17.0.10+7; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.27.4-SNAPSHOT\n",
      "INFO\t2024-11-17 10:05:06\tMarkDuplicates\tStart of doWork freeMemory: 33624688; totalMemory: 41943040; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:05:06\tMarkDuplicates\tReading input file and constructing read end information.\n",
      "INFO\t2024-11-17 10:05:06\tMarkDuplicates\tWill retain up to 15561475 data points before spilling to disk.\n",
      "WARNING\t2024-11-17 10:05:06\tAbstractOpticalDuplicateFinderCommandLineProgram\tA field field parsed out of a read name was expected to contain an integer and did not. Read name: SRR085725.6066077. Cause: String 'SRR085725.6066077' did not start with a parsable number.\n",
      "INFO\t2024-11-17 10:05:09\tMarkDuplicates\tRead     1,000,000 records.  Elapsed time: 00:00:02s.  Time for last 1,000,000:    2s.  Last read position: NC_000001.11:184,693,475\n",
      "INFO\t2024-11-17 10:05:09\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:05:11\tMarkDuplicates\tRead     2,000,000 records.  Elapsed time: 00:00:04s.  Time for last 1,000,000:    2s.  Last read position: NC_000003.12:50,256,788\n",
      "INFO\t2024-11-17 10:05:11\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:05:13\tMarkDuplicates\tRead     3,000,000 records.  Elapsed time: 00:00:06s.  Time for last 1,000,000:    1s.  Last read position: NC_000005.10:137,752,572\n",
      "INFO\t2024-11-17 10:05:13\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:05:15\tMarkDuplicates\tRead     4,000,000 records.  Elapsed time: 00:00:08s.  Time for last 1,000,000:    2s.  Last read position: NC_000007.14:139,568,937\n",
      "INFO\t2024-11-17 10:05:15\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:05:17\tMarkDuplicates\tRead     5,000,000 records.  Elapsed time: 00:00:10s.  Time for last 1,000,000:    1s.  Last read position: NC_000010.11:75,181,573\n",
      "INFO\t2024-11-17 10:05:17\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:05:19\tMarkDuplicates\tRead     6,000,000 records.  Elapsed time: 00:00:12s.  Time for last 1,000,000:    1s.  Last read position: NC_000012.12:50,478,382\n",
      "INFO\t2024-11-17 10:05:19\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:05:21\tMarkDuplicates\tRead     7,000,000 records.  Elapsed time: 00:00:14s.  Time for last 1,000,000:    1s.  Last read position: NC_000015.10:64,528,979\n",
      "INFO\t2024-11-17 10:05:21\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:05:23\tMarkDuplicates\tRead     8,000,000 records.  Elapsed time: 00:00:16s.  Time for last 1,000,000:    1s.  Last read position: NC_000017.11:50,695,178\n",
      "INFO\t2024-11-17 10:05:23\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:05:25\tMarkDuplicates\tRead     9,000,000 records.  Elapsed time: 00:00:18s.  Time for last 1,000,000:    2s.  Last read position: NC_000019.10:53,978,194\n",
      "INFO\t2024-11-17 10:05:25\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:05:27\tMarkDuplicates\tRead    10,000,000 records.  Elapsed time: 00:00:20s.  Time for last 1,000,000:    2s.  Last read position: NC_000023.11:71,728,998\n",
      "INFO\t2024-11-17 10:05:27\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:05:29\tMarkDuplicates\tRead    11,000,000 records.  Elapsed time: 00:00:22s.  Time for last 1,000,000:    1s.  Last read position: NC_012920.1:3,173\n",
      "INFO\t2024-11-17 10:05:29\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:05:31\tMarkDuplicates\tRead    12,000,000 records.  Elapsed time: 00:00:24s.  Time for last 1,000,000:    1s.  Last read position: NC_012920.1:11,465\n",
      "INFO\t2024-11-17 10:05:31\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:05:31\tMarkDuplicates\tRead 12325923 records. 0 pairs never matched.\n",
      "INFO\t2024-11-17 10:05:32\tMarkDuplicates\tAfter buildSortedReadEndLists freeMemory: 1484215952; totalMemory: 2508193792; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:05:32\tMarkDuplicates\tWill retain up to 134217728 duplicate indices before spilling to disk.\n",
      "INFO\t2024-11-17 10:05:32\tMarkDuplicates\tTraversing read pair information and detecting duplicates.\n",
      "INFO\t2024-11-17 10:05:32\tMarkDuplicates\tTraversing fragment information and detecting duplicates.\n",
      "INFO\t2024-11-17 10:05:33\tMarkDuplicates\tSorting list of duplicate records.\n",
      "INFO\t2024-11-17 10:05:33\tMarkDuplicates\tAfter generateDuplicateIndexes freeMemory: 2496957608; totalMemory: 3581935616; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:05:33\tMarkDuplicates\tMarking 4829379 records as duplicates.\n",
      "INFO\t2024-11-17 10:05:33\tMarkDuplicates\tFound 0 optical duplicate clusters.\n",
      "INFO\t2024-11-17 10:05:33\tMarkDuplicates\tReads are assumed to be ordered by: coordinate\n",
      "INFO\t2024-11-17 10:06:05\tMarkDuplicates\tWriting complete. Closing input iterator.\n",
      "INFO\t2024-11-17 10:06:05\tMarkDuplicates\tDuplicate Index cleanup.\n",
      "INFO\t2024-11-17 10:06:05\tMarkDuplicates\tGetting Memory Stats.\n",
      "INFO\t2024-11-17 10:06:05\tMarkDuplicates\tBefore output close freeMemory: 67544128; totalMemory: 77594624; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:06:05\tMarkDuplicates\tClosed outputs. Getting more Memory Stats.\n",
      "INFO\t2024-11-17 10:06:05\tMarkDuplicates\tAfter output close freeMemory: 32311280; totalMemory: 41943040; maxMemory: 4294967296\n",
      "[Sun Nov 17 10:06:05 IST 2024] picard.sam.markduplicates.MarkDuplicates done. Elapsed time: 0.99 minutes.\n",
      "Runtime.totalMemory()=41943040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplication completed for sorted_bam/SRR085725_sorted.bam, output BAM: deduplicated_bam/SRR085725_dedup.bam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO\t2024-11-17 10:06:06\tMarkDuplicates\t\n",
      "\n",
      "********** NOTE: Picard's command line syntax is changing.\n",
      "**********\n",
      "********** For more information, please see:\n",
      "********** \n",
      "https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition)\n",
      "**********\n",
      "********** The command line looks like this in the new syntax:\n",
      "**********\n",
      "**********    MarkDuplicates -I sorted_bam/SRR085471_sorted.bam -O deduplicated_bam/SRR085471_dedup.bam -M deduplicated_bam/SRR085471_metrics.txt -REMOVE_DUPLICATES true -CREATE_INDEX true\n",
      "**********\n",
      "\n",
      "\n",
      "10:06:07.140 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/mahendra/Desktop/Python/Project/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Sun Nov 17 10:06:07 IST 2024] MarkDuplicates INPUT=[sorted_bam/SRR085471_sorted.bam] OUTPUT=deduplicated_bam/SRR085471_dedup.bam METRICS_FILE=deduplicated_bam/SRR085471_metrics.txt REMOVE_DUPLICATES=true CREATE_INDEX=true    MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP=50000 MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=8000 SORTING_COLLECTION_SIZE_RATIO=0.25 TAG_DUPLICATE_SET_MEMBERS=false REMOVE_SEQUENCING_DUPLICATES=false TAGGING_POLICY=DontTag CLEAR_DT=true DUPLEX_UMI=false FLOW_MODE=false FLOW_QUALITY_SUM_STRATEGY=false USE_END_IN_UNPAIRED_READS=false USE_UNPAIRED_CLIPPED_END=false UNPAIRED_END_UNCERTAINTY=0 FLOW_SKIP_FIRST_N_FLOWS=0 FLOW_Q_IS_KNOWN_END=false FLOW_EFFECTIVE_QUALITY_THRESHOLD=15 ADD_PG_TAG_TO_READS=true ASSUME_SORTED=false DUPLICATE_SCORING_STRATEGY=SUM_OF_BASE_QUALITIES PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates READ_NAME_REGEX=<optimized capture of last three ':' separated fields as numeric values> OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 MAX_OPTICAL_DUPLICATE_SET_SIZE=300000 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false\n",
      "[Sun Nov 17 10:06:07 IST 2024] Executing as mahendra@ms on Linux 6.8.0-47-generic amd64; OpenJDK 64-Bit Server VM 17.0.10+7; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.27.4-SNAPSHOT\n",
      "INFO\t2024-11-17 10:06:07\tMarkDuplicates\tStart of doWork freeMemory: 27709112; totalMemory: 35651584; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:06:07\tMarkDuplicates\tReading input file and constructing read end information.\n",
      "INFO\t2024-11-17 10:06:07\tMarkDuplicates\tWill retain up to 15561475 data points before spilling to disk.\n",
      "WARNING\t2024-11-17 10:06:07\tAbstractOpticalDuplicateFinderCommandLineProgram\tA field field parsed out of a read name was expected to contain an integer and did not. Read name: SRR085471.13791417. Cause: String 'SRR085471.13791417' did not start with a parsable number.\n",
      "INFO\t2024-11-17 10:06:09\tMarkDuplicates\tRead     1,000,000 records.  Elapsed time: 00:00:02s.  Time for last 1,000,000:    2s.  Last read position: NC_000001.11:153,930,076\n",
      "INFO\t2024-11-17 10:06:09\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:06:12\tMarkDuplicates\tRead     2,000,000 records.  Elapsed time: 00:00:04s.  Time for last 1,000,000:    2s.  Last read position: NC_000002.12:225,702,129\n",
      "INFO\t2024-11-17 10:06:12\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:06:14\tMarkDuplicates\tRead     3,000,000 records.  Elapsed time: 00:00:07s.  Time for last 1,000,000:    2s.  Last read position: NC_000004.12:185,143,375\n",
      "INFO\t2024-11-17 10:06:14\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:06:16\tMarkDuplicates\tRead     4,000,000 records.  Elapsed time: 00:00:09s.  Time for last 1,000,000:    2s.  Last read position: NC_000007.14:5,528,571\n",
      "INFO\t2024-11-17 10:06:16\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:06:18\tMarkDuplicates\tRead     5,000,000 records.  Elapsed time: 00:00:11s.  Time for last 1,000,000:    2s.  Last read position: NC_000009.12:97,625,875\n",
      "INFO\t2024-11-17 10:06:18\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:06:20\tMarkDuplicates\tRead     6,000,000 records.  Elapsed time: 00:00:13s.  Time for last 1,000,000:    2s.  Last read position: NC_000011.10:65,499,428\n",
      "INFO\t2024-11-17 10:06:20\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:06:22\tMarkDuplicates\tRead     7,000,000 records.  Elapsed time: 00:00:15s.  Time for last 1,000,000:    2s.  Last read position: NC_000013.11:35,773,479\n",
      "INFO\t2024-11-17 10:06:22\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:06:24\tMarkDuplicates\tRead     8,000,000 records.  Elapsed time: 00:00:17s.  Time for last 1,000,000:    2s.  Last read position: NC_000016.10:29,811,074\n",
      "INFO\t2024-11-17 10:06:24\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:06:26\tMarkDuplicates\tRead     9,000,000 records.  Elapsed time: 00:00:19s.  Time for last 1,000,000:    2s.  Last read position: NC_000018.10:46,086,215\n",
      "INFO\t2024-11-17 10:06:26\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:06:29\tMarkDuplicates\tRead    10,000,000 records.  Elapsed time: 00:00:21s.  Time for last 1,000,000:    2s.  Last read position: NC_000020.11:24,966,680\n",
      "INFO\t2024-11-17 10:06:29\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:06:31\tMarkDuplicates\tRead    11,000,000 records.  Elapsed time: 00:00:23s.  Time for last 1,000,000:    1s.  Last read position: NC_000023.11:53,086,048\n",
      "INFO\t2024-11-17 10:06:31\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:06:33\tMarkDuplicates\tRead    12,000,000 records.  Elapsed time: 00:00:25s.  Time for last 1,000,000:    1s.  Last read position: NC_012920.1:1,890\n",
      "INFO\t2024-11-17 10:06:33\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:06:35\tMarkDuplicates\tRead    13,000,000 records.  Elapsed time: 00:00:27s.  Time for last 1,000,000:    1s.  Last read position: NC_012920.1:7,753\n",
      "INFO\t2024-11-17 10:06:35\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:06:37\tMarkDuplicates\tRead    14,000,000 records.  Elapsed time: 00:00:29s.  Time for last 1,000,000:    1s.  Last read position: NC_012920.1:15,261\n",
      "INFO\t2024-11-17 10:06:37\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:06:37\tMarkDuplicates\tRead 14100316 records. 0 pairs never matched.\n",
      "INFO\t2024-11-17 10:06:37\tMarkDuplicates\tAfter buildSortedReadEndLists freeMemory: 1363255104; totalMemory: 2514485248; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:06:37\tMarkDuplicates\tWill retain up to 134217728 duplicate indices before spilling to disk.\n",
      "INFO\t2024-11-17 10:06:38\tMarkDuplicates\tTraversing read pair information and detecting duplicates.\n",
      "INFO\t2024-11-17 10:06:38\tMarkDuplicates\tTraversing fragment information and detecting duplicates.\n",
      "INFO\t2024-11-17 10:06:39\tMarkDuplicates\tSorting list of duplicate records.\n",
      "INFO\t2024-11-17 10:06:39\tMarkDuplicates\tAfter generateDuplicateIndexes freeMemory: 2503245440; totalMemory: 3588227072; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:06:39\tMarkDuplicates\tMarking 6561051 records as duplicates.\n",
      "INFO\t2024-11-17 10:06:39\tMarkDuplicates\tFound 0 optical duplicate clusters.\n",
      "INFO\t2024-11-17 10:06:39\tMarkDuplicates\tReads are assumed to be ordered by: coordinate\n",
      "INFO\t2024-11-17 10:07:13\tMarkDuplicates\tWriting complete. Closing input iterator.\n",
      "INFO\t2024-11-17 10:07:13\tMarkDuplicates\tDuplicate Index cleanup.\n",
      "INFO\t2024-11-17 10:07:13\tMarkDuplicates\tGetting Memory Stats.\n",
      "INFO\t2024-11-17 10:07:13\tMarkDuplicates\tBefore output close freeMemory: 53028360; totalMemory: 62914560; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:07:13\tMarkDuplicates\tClosed outputs. Getting more Memory Stats.\n",
      "INFO\t2024-11-17 10:07:13\tMarkDuplicates\tAfter output close freeMemory: 32308056; totalMemory: 41943040; maxMemory: 4294967296\n",
      "[Sun Nov 17 10:07:13 IST 2024] picard.sam.markduplicates.MarkDuplicates done. Elapsed time: 1.11 minutes.\n",
      "Runtime.totalMemory()=41943040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplication completed for sorted_bam/SRR085471_sorted.bam, output BAM: deduplicated_bam/SRR085471_dedup.bam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO\t2024-11-17 10:07:14\tMarkDuplicates\t\n",
      "\n",
      "********** NOTE: Picard's command line syntax is changing.\n",
      "**********\n",
      "********** For more information, please see:\n",
      "********** \n",
      "https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition)\n",
      "**********\n",
      "********** The command line looks like this in the new syntax:\n",
      "**********\n",
      "**********    MarkDuplicates -I sorted_bam/SRR085473_sorted.bam -O deduplicated_bam/SRR085473_dedup.bam -M deduplicated_bam/SRR085473_metrics.txt -REMOVE_DUPLICATES true -CREATE_INDEX true\n",
      "**********\n",
      "\n",
      "\n",
      "10:07:14.777 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/mahendra/Desktop/Python/Project/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Sun Nov 17 10:07:14 IST 2024] MarkDuplicates INPUT=[sorted_bam/SRR085473_sorted.bam] OUTPUT=deduplicated_bam/SRR085473_dedup.bam METRICS_FILE=deduplicated_bam/SRR085473_metrics.txt REMOVE_DUPLICATES=true CREATE_INDEX=true    MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP=50000 MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=8000 SORTING_COLLECTION_SIZE_RATIO=0.25 TAG_DUPLICATE_SET_MEMBERS=false REMOVE_SEQUENCING_DUPLICATES=false TAGGING_POLICY=DontTag CLEAR_DT=true DUPLEX_UMI=false FLOW_MODE=false FLOW_QUALITY_SUM_STRATEGY=false USE_END_IN_UNPAIRED_READS=false USE_UNPAIRED_CLIPPED_END=false UNPAIRED_END_UNCERTAINTY=0 FLOW_SKIP_FIRST_N_FLOWS=0 FLOW_Q_IS_KNOWN_END=false FLOW_EFFECTIVE_QUALITY_THRESHOLD=15 ADD_PG_TAG_TO_READS=true ASSUME_SORTED=false DUPLICATE_SCORING_STRATEGY=SUM_OF_BASE_QUALITIES PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates READ_NAME_REGEX=<optimized capture of last three ':' separated fields as numeric values> OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 MAX_OPTICAL_DUPLICATE_SET_SIZE=300000 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false\n",
      "[Sun Nov 17 10:07:14 IST 2024] Executing as mahendra@ms on Linux 6.8.0-47-generic amd64; OpenJDK 64-Bit Server VM 17.0.10+7; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.27.4-SNAPSHOT\n",
      "INFO\t2024-11-17 10:07:14\tMarkDuplicates\tStart of doWork freeMemory: 33624616; totalMemory: 41943040; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:07:14\tMarkDuplicates\tReading input file and constructing read end information.\n",
      "INFO\t2024-11-17 10:07:14\tMarkDuplicates\tWill retain up to 15561475 data points before spilling to disk.\n",
      "WARNING\t2024-11-17 10:07:14\tAbstractOpticalDuplicateFinderCommandLineProgram\tA field field parsed out of a read name was expected to contain an integer and did not. Read name: SRR085473.8892046. Cause: String 'SRR085473.8892046' did not start with a parsable number.\n",
      "INFO\t2024-11-17 10:07:17\tMarkDuplicates\tRead     1,000,000 records.  Elapsed time: 00:00:02s.  Time for last 1,000,000:    2s.  Last read position: NC_000001.11:634,550\n",
      "INFO\t2024-11-17 10:07:17\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:07:19\tMarkDuplicates\tRead     2,000,000 records.  Elapsed time: 00:00:04s.  Time for last 1,000,000:    2s.  Last read position: NC_000003.12:115,647,554\n",
      "INFO\t2024-11-17 10:07:19\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:07:21\tMarkDuplicates\tRead     3,000,000 records.  Elapsed time: 00:00:06s.  Time for last 1,000,000:    2s.  Last read position: NC_000007.14:142,667,513\n",
      "INFO\t2024-11-17 10:07:21\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:07:23\tMarkDuplicates\tRead     4,000,000 records.  Elapsed time: 00:00:08s.  Time for last 1,000,000:    2s.  Last read position: NC_000012.12:6,945,882\n",
      "INFO\t2024-11-17 10:07:23\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:07:26\tMarkDuplicates\tRead     5,000,000 records.  Elapsed time: 00:00:11s.  Time for last 1,000,000:    2s.  Last read position: NC_000017.11:44,906,601\n",
      "INFO\t2024-11-17 10:07:26\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:07:28\tMarkDuplicates\tRead     6,000,000 records.  Elapsed time: 00:00:13s.  Time for last 1,000,000:    2s.  Last read position: NC_000021.9:8,401,097\n",
      "INFO\t2024-11-17 10:07:28\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:07:30\tMarkDuplicates\tRead     7,000,000 records.  Elapsed time: 00:00:15s.  Time for last 1,000,000:    1s.  Last read position: NW_021160023.1:492,115\n",
      "INFO\t2024-11-17 10:07:30\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:07:32\tMarkDuplicates\tRead     8,000,000 records.  Elapsed time: 00:00:17s.  Time for last 1,000,000:    2s.  Last read position: NC_012920.1:2,939\n",
      "INFO\t2024-11-17 10:07:32\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:07:34\tMarkDuplicates\tRead     9,000,000 records.  Elapsed time: 00:00:19s.  Time for last 1,000,000:    2s.  Last read position: NC_012920.1:5,426\n",
      "INFO\t2024-11-17 10:07:34\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:07:36\tMarkDuplicates\tRead    10,000,000 records.  Elapsed time: 00:00:21s.  Time for last 1,000,000:    1s.  Last read position: NC_012920.1:7,250\n",
      "INFO\t2024-11-17 10:07:36\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:07:38\tMarkDuplicates\tRead    11,000,000 records.  Elapsed time: 00:00:23s.  Time for last 1,000,000:    2s.  Last read position: NC_012920.1:9,229\n",
      "INFO\t2024-11-17 10:07:38\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:07:40\tMarkDuplicates\tRead    12,000,000 records.  Elapsed time: 00:00:25s.  Time for last 1,000,000:    1s.  Last read position: NC_012920.1:11,679\n",
      "INFO\t2024-11-17 10:07:40\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:07:42\tMarkDuplicates\tRead    13,000,000 records.  Elapsed time: 00:00:27s.  Time for last 1,000,000:    1s.  Last read position: NC_012920.1:15,529\n",
      "INFO\t2024-11-17 10:07:42\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:07:42\tMarkDuplicates\tRead 13163111 records. 0 pairs never matched.\n",
      "INFO\t2024-11-17 10:07:42\tMarkDuplicates\tAfter buildSortedReadEndLists freeMemory: 1166538280; totalMemory: 2250244096; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:07:42\tMarkDuplicates\tWill retain up to 134217728 duplicate indices before spilling to disk.\n",
      "INFO\t2024-11-17 10:07:43\tMarkDuplicates\tTraversing read pair information and detecting duplicates.\n",
      "INFO\t2024-11-17 10:07:43\tMarkDuplicates\tTraversing fragment information and detecting duplicates.\n",
      "INFO\t2024-11-17 10:07:44\tMarkDuplicates\tSorting list of duplicate records.\n",
      "INFO\t2024-11-17 10:07:44\tMarkDuplicates\tAfter generateDuplicateIndexes freeMemory: 2239009024; totalMemory: 3323985920; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:07:44\tMarkDuplicates\tMarking 9415088 records as duplicates.\n",
      "INFO\t2024-11-17 10:07:44\tMarkDuplicates\tFound 0 optical duplicate clusters.\n",
      "INFO\t2024-11-17 10:07:44\tMarkDuplicates\tReads are assumed to be ordered by: coordinate\n",
      "INFO\t2024-11-17 10:08:07\tMarkDuplicates\tWriting complete. Closing input iterator.\n",
      "INFO\t2024-11-17 10:08:07\tMarkDuplicates\tDuplicate Index cleanup.\n",
      "INFO\t2024-11-17 10:08:07\tMarkDuplicates\tGetting Memory Stats.\n",
      "INFO\t2024-11-17 10:08:07\tMarkDuplicates\tBefore output close freeMemory: 67544448; totalMemory: 77594624; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:08:07\tMarkDuplicates\tClosed outputs. Getting more Memory Stats.\n",
      "INFO\t2024-11-17 10:08:07\tMarkDuplicates\tAfter output close freeMemory: 32311512; totalMemory: 41943040; maxMemory: 4294967296\n",
      "[Sun Nov 17 10:08:07 IST 2024] picard.sam.markduplicates.MarkDuplicates done. Elapsed time: 0.87 minutes.\n",
      "Runtime.totalMemory()=41943040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplication completed for sorted_bam/SRR085473_sorted.bam, output BAM: deduplicated_bam/SRR085473_dedup.bam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO\t2024-11-17 10:08:07\tMarkDuplicates\t\n",
      "\n",
      "********** NOTE: Picard's command line syntax is changing.\n",
      "**********\n",
      "********** For more information, please see:\n",
      "********** \n",
      "https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition)\n",
      "**********\n",
      "********** The command line looks like this in the new syntax:\n",
      "**********\n",
      "**********    MarkDuplicates -I sorted_bam/SRR085474_sorted.bam -O deduplicated_bam/SRR085474_dedup.bam -M deduplicated_bam/SRR085474_metrics.txt -REMOVE_DUPLICATES true -CREATE_INDEX true\n",
      "**********\n",
      "\n",
      "\n",
      "10:08:08.218 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/mahendra/Desktop/Python/Project/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Sun Nov 17 10:08:08 IST 2024] MarkDuplicates INPUT=[sorted_bam/SRR085474_sorted.bam] OUTPUT=deduplicated_bam/SRR085474_dedup.bam METRICS_FILE=deduplicated_bam/SRR085474_metrics.txt REMOVE_DUPLICATES=true CREATE_INDEX=true    MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP=50000 MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=8000 SORTING_COLLECTION_SIZE_RATIO=0.25 TAG_DUPLICATE_SET_MEMBERS=false REMOVE_SEQUENCING_DUPLICATES=false TAGGING_POLICY=DontTag CLEAR_DT=true DUPLEX_UMI=false FLOW_MODE=false FLOW_QUALITY_SUM_STRATEGY=false USE_END_IN_UNPAIRED_READS=false USE_UNPAIRED_CLIPPED_END=false UNPAIRED_END_UNCERTAINTY=0 FLOW_SKIP_FIRST_N_FLOWS=0 FLOW_Q_IS_KNOWN_END=false FLOW_EFFECTIVE_QUALITY_THRESHOLD=15 ADD_PG_TAG_TO_READS=true ASSUME_SORTED=false DUPLICATE_SCORING_STRATEGY=SUM_OF_BASE_QUALITIES PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates READ_NAME_REGEX=<optimized capture of last three ':' separated fields as numeric values> OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 MAX_OPTICAL_DUPLICATE_SET_SIZE=300000 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false\n",
      "[Sun Nov 17 10:08:08 IST 2024] Executing as mahendra@ms on Linux 6.8.0-47-generic amd64; OpenJDK 64-Bit Server VM 17.0.10+7; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.27.4-SNAPSHOT\n",
      "INFO\t2024-11-17 10:08:08\tMarkDuplicates\tStart of doWork freeMemory: 33960232; totalMemory: 41943040; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:08:08\tMarkDuplicates\tReading input file and constructing read end information.\n",
      "INFO\t2024-11-17 10:08:08\tMarkDuplicates\tWill retain up to 15561475 data points before spilling to disk.\n",
      "WARNING\t2024-11-17 10:08:08\tAbstractOpticalDuplicateFinderCommandLineProgram\tA field field parsed out of a read name was expected to contain an integer and did not. Read name: SRR085474.1772308. Cause: String 'SRR085474.1772308' did not start with a parsable number.\n",
      "INFO\t2024-11-17 10:08:11\tMarkDuplicates\tRead     1,000,000 records.  Elapsed time: 00:00:02s.  Time for last 1,000,000:    2s.  Last read position: NC_000001.11:154,550,330\n",
      "INFO\t2024-11-17 10:08:11\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:08:13\tMarkDuplicates\tRead     2,000,000 records.  Elapsed time: 00:00:04s.  Time for last 1,000,000:    2s.  Last read position: NC_000002.12:219,207,986\n",
      "INFO\t2024-11-17 10:08:13\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:08:15\tMarkDuplicates\tRead     3,000,000 records.  Elapsed time: 00:00:07s.  Time for last 1,000,000:    2s.  Last read position: NC_000004.12:128,081,728\n",
      "INFO\t2024-11-17 10:08:15\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:08:17\tMarkDuplicates\tRead     4,000,000 records.  Elapsed time: 00:00:09s.  Time for last 1,000,000:    2s.  Last read position: NC_000006.12:132,401,162\n",
      "INFO\t2024-11-17 10:08:17\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:08:19\tMarkDuplicates\tRead     5,000,000 records.  Elapsed time: 00:00:11s.  Time for last 1,000,000:    2s.  Last read position: NC_000008.11:143,991,955\n",
      "INFO\t2024-11-17 10:08:19\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:08:21\tMarkDuplicates\tRead     6,000,000 records.  Elapsed time: 00:00:13s.  Time for last 1,000,000:    2s.  Last read position: NC_000011.10:10,804,374\n",
      "INFO\t2024-11-17 10:08:21\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:08:23\tMarkDuplicates\tRead     7,000,000 records.  Elapsed time: 00:00:15s.  Time for last 1,000,000:    2s.  Last read position: NC_000012.12:57,620,282\n",
      "INFO\t2024-11-17 10:08:23\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:08:25\tMarkDuplicates\tRead     8,000,000 records.  Elapsed time: 00:00:17s.  Time for last 1,000,000:    2s.  Last read position: NC_000015.10:64,155,918\n",
      "INFO\t2024-11-17 10:08:25\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:08:28\tMarkDuplicates\tRead     9,000,000 records.  Elapsed time: 00:00:20s.  Time for last 1,000,000:    2s.  Last read position: NC_000017.11:41,913,746\n",
      "INFO\t2024-11-17 10:08:28\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:08:30\tMarkDuplicates\tRead    10,000,000 records.  Elapsed time: 00:00:22s.  Time for last 1,000,000:    2s.  Last read position: NC_000019.10:19,569,476\n",
      "INFO\t2024-11-17 10:08:30\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:08:32\tMarkDuplicates\tRead    11,000,000 records.  Elapsed time: 00:00:24s.  Time for last 1,000,000:    1s.  Last read position: NC_000021.9:43,744,172\n",
      "INFO\t2024-11-17 10:08:32\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:08:34\tMarkDuplicates\tRead    12,000,000 records.  Elapsed time: 00:00:26s.  Time for last 1,000,000:    2s.  Last read position: NW_025791778.1:243,330\n",
      "INFO\t2024-11-17 10:08:34\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:08:36\tMarkDuplicates\tRead    13,000,000 records.  Elapsed time: 00:00:28s.  Time for last 1,000,000:    2s.  Last read position: NC_012920.1:5,199\n",
      "INFO\t2024-11-17 10:08:36\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:08:38\tMarkDuplicates\tRead    14,000,000 records.  Elapsed time: 00:00:30s.  Time for last 1,000,000:    2s.  Last read position: NC_012920.1:11,778\n",
      "INFO\t2024-11-17 10:08:38\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:08:39\tMarkDuplicates\tRead 14317567 records. 0 pairs never matched.\n",
      "INFO\t2024-11-17 10:08:39\tMarkDuplicates\tAfter buildSortedReadEndLists freeMemory: 1246819904; totalMemory: 2413821952; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:08:39\tMarkDuplicates\tWill retain up to 134217728 duplicate indices before spilling to disk.\n",
      "INFO\t2024-11-17 10:08:40\tMarkDuplicates\tTraversing read pair information and detecting duplicates.\n",
      "INFO\t2024-11-17 10:08:40\tMarkDuplicates\tTraversing fragment information and detecting duplicates.\n",
      "INFO\t2024-11-17 10:08:41\tMarkDuplicates\tSorting list of duplicate records.\n",
      "INFO\t2024-11-17 10:08:42\tMarkDuplicates\tAfter generateDuplicateIndexes freeMemory: 2402585488; totalMemory: 3487563776; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:08:42\tMarkDuplicates\tMarking 6433685 records as duplicates.\n",
      "INFO\t2024-11-17 10:08:42\tMarkDuplicates\tFound 0 optical duplicate clusters.\n",
      "INFO\t2024-11-17 10:08:42\tMarkDuplicates\tReads are assumed to be ordered by: coordinate\n",
      "INFO\t2024-11-17 10:09:17\tMarkDuplicates\tWriting complete. Closing input iterator.\n",
      "INFO\t2024-11-17 10:09:17\tMarkDuplicates\tDuplicate Index cleanup.\n",
      "INFO\t2024-11-17 10:09:17\tMarkDuplicates\tGetting Memory Stats.\n",
      "INFO\t2024-11-17 10:09:17\tMarkDuplicates\tBefore output close freeMemory: 61336728; totalMemory: 71303168; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:09:17\tMarkDuplicates\tClosed outputs. Getting more Memory Stats.\n",
      "INFO\t2024-11-17 10:09:17\tMarkDuplicates\tAfter output close freeMemory: 32311456; totalMemory: 41943040; maxMemory: 4294967296\n",
      "[Sun Nov 17 10:09:17 IST 2024] picard.sam.markduplicates.MarkDuplicates done. Elapsed time: 1.16 minutes.\n",
      "Runtime.totalMemory()=41943040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplication completed for sorted_bam/SRR085474_sorted.bam, output BAM: deduplicated_bam/SRR085474_dedup.bam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO\t2024-11-17 10:09:18\tMarkDuplicates\t\n",
      "\n",
      "********** NOTE: Picard's command line syntax is changing.\n",
      "**********\n",
      "********** For more information, please see:\n",
      "********** \n",
      "https://github.com/broadinstitute/picard/wiki/Command-Line-Syntax-Transition-For-Users-(Pre-Transition)\n",
      "**********\n",
      "********** The command line looks like this in the new syntax:\n",
      "**********\n",
      "**********    MarkDuplicates -I sorted_bam/SRR085726_sorted.bam -O deduplicated_bam/SRR085726_dedup.bam -M deduplicated_bam/SRR085726_metrics.txt -REMOVE_DUPLICATES true -CREATE_INDEX true\n",
      "**********\n",
      "\n",
      "\n",
      "10:09:18.675 INFO  NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/mahendra/Desktop/Python/Project/picard.jar!/com/intel/gkl/native/libgkl_compression.so\n",
      "[Sun Nov 17 10:09:18 IST 2024] MarkDuplicates INPUT=[sorted_bam/SRR085726_sorted.bam] OUTPUT=deduplicated_bam/SRR085726_dedup.bam METRICS_FILE=deduplicated_bam/SRR085726_metrics.txt REMOVE_DUPLICATES=true CREATE_INDEX=true    MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP=50000 MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=8000 SORTING_COLLECTION_SIZE_RATIO=0.25 TAG_DUPLICATE_SET_MEMBERS=false REMOVE_SEQUENCING_DUPLICATES=false TAGGING_POLICY=DontTag CLEAR_DT=true DUPLEX_UMI=false FLOW_MODE=false FLOW_QUALITY_SUM_STRATEGY=false USE_END_IN_UNPAIRED_READS=false USE_UNPAIRED_CLIPPED_END=false UNPAIRED_END_UNCERTAINTY=0 FLOW_SKIP_FIRST_N_FLOWS=0 FLOW_Q_IS_KNOWN_END=false FLOW_EFFECTIVE_QUALITY_THRESHOLD=15 ADD_PG_TAG_TO_READS=true ASSUME_SORTED=false DUPLICATE_SCORING_STRATEGY=SUM_OF_BASE_QUALITIES PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates READ_NAME_REGEX=<optimized capture of last three ':' separated fields as numeric values> OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 MAX_OPTICAL_DUPLICATE_SET_SIZE=300000 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false\n",
      "[Sun Nov 17 10:09:18 IST 2024] Executing as mahendra@ms on Linux 6.8.0-47-generic amd64; OpenJDK 64-Bit Server VM 17.0.10+7; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.27.4-SNAPSHOT\n",
      "INFO\t2024-11-17 10:09:18\tMarkDuplicates\tStart of doWork freeMemory: 33619504; totalMemory: 41943040; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:09:18\tMarkDuplicates\tReading input file and constructing read end information.\n",
      "INFO\t2024-11-17 10:09:18\tMarkDuplicates\tWill retain up to 15561475 data points before spilling to disk.\n",
      "WARNING\t2024-11-17 10:09:18\tAbstractOpticalDuplicateFinderCommandLineProgram\tA field field parsed out of a read name was expected to contain an integer and did not. Read name: SRR085726.9169885. Cause: String 'SRR085726.9169885' did not start with a parsable number.\n",
      "INFO\t2024-11-17 10:09:21\tMarkDuplicates\tRead     1,000,000 records.  Elapsed time: 00:00:02s.  Time for last 1,000,000:    2s.  Last read position: NC_000001.11:159,919,305\n",
      "INFO\t2024-11-17 10:09:21\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:09:23\tMarkDuplicates\tRead     2,000,000 records.  Elapsed time: 00:00:04s.  Time for last 1,000,000:    2s.  Last read position: NC_000003.12:47,852,247\n",
      "INFO\t2024-11-17 10:09:23\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:09:25\tMarkDuplicates\tRead     3,000,000 records.  Elapsed time: 00:00:06s.  Time for last 1,000,000:    2s.  Last read position: NC_000005.10:138,446,692\n",
      "INFO\t2024-11-17 10:09:25\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:09:27\tMarkDuplicates\tRead     4,000,000 records.  Elapsed time: 00:00:08s.  Time for last 1,000,000:    2s.  Last read position: NC_000007.14:155,400,566\n",
      "INFO\t2024-11-17 10:09:27\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:09:29\tMarkDuplicates\tRead     5,000,000 records.  Elapsed time: 00:00:10s.  Time for last 1,000,000:    2s.  Last read position: NC_000010.11:107,143,456\n",
      "INFO\t2024-11-17 10:09:29\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:09:31\tMarkDuplicates\tRead     6,000,000 records.  Elapsed time: 00:00:12s.  Time for last 1,000,000:    2s.  Last read position: NC_000012.12:56,204,528\n",
      "INFO\t2024-11-17 10:09:31\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:09:33\tMarkDuplicates\tRead     7,000,000 records.  Elapsed time: 00:00:14s.  Time for last 1,000,000:    1s.  Last read position: NC_000015.10:99,130,031\n",
      "INFO\t2024-11-17 10:09:33\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:09:35\tMarkDuplicates\tRead     8,000,000 records.  Elapsed time: 00:00:17s.  Time for last 1,000,000:    2s.  Last read position: NC_000017.11:74,203,776\n",
      "INFO\t2024-11-17 10:09:35\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:09:37\tMarkDuplicates\tRead     9,000,000 records.  Elapsed time: 00:00:19s.  Time for last 1,000,000:    2s.  Last read position: NC_000019.10:49,856,047\n",
      "INFO\t2024-11-17 10:09:37\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:09:40\tMarkDuplicates\tRead    10,000,000 records.  Elapsed time: 00:00:21s.  Time for last 1,000,000:    2s.  Last read position: NT_187388.1:126,388\n",
      "INFO\t2024-11-17 10:09:40\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:09:42\tMarkDuplicates\tRead    11,000,000 records.  Elapsed time: 00:00:23s.  Time for last 1,000,000:    2s.  Last read position: NT_187607.1:2,009,464\n",
      "INFO\t2024-11-17 10:09:42\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:09:44\tMarkDuplicates\tRead    12,000,000 records.  Elapsed time: 00:00:25s.  Time for last 1,000,000:    1s.  Last read position: NC_012920.1:3,406\n",
      "INFO\t2024-11-17 10:09:44\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:09:46\tMarkDuplicates\tRead    13,000,000 records.  Elapsed time: 00:00:27s.  Time for last 1,000,000:    1s.  Last read position: NC_012920.1:9,028\n",
      "INFO\t2024-11-17 10:09:46\tMarkDuplicates\tTracking 0 as yet unmatched pairs. 0 records in RAM.\n",
      "INFO\t2024-11-17 10:09:48\tMarkDuplicates\tRead 13957464 records. 0 pairs never matched.\n",
      "INFO\t2024-11-17 10:09:48\tMarkDuplicates\tAfter buildSortedReadEndLists freeMemory: 1555489552; totalMemory: 2696937472; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:09:48\tMarkDuplicates\tWill retain up to 134217728 duplicate indices before spilling to disk.\n",
      "INFO\t2024-11-17 10:09:48\tMarkDuplicates\tTraversing read pair information and detecting duplicates.\n",
      "INFO\t2024-11-17 10:09:48\tMarkDuplicates\tTraversing fragment information and detecting duplicates.\n",
      "INFO\t2024-11-17 10:09:49\tMarkDuplicates\tSorting list of duplicate records.\n",
      "INFO\t2024-11-17 10:09:50\tMarkDuplicates\tAfter generateDuplicateIndexes freeMemory: 2572450304; totalMemory: 3657433088; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:09:50\tMarkDuplicates\tMarking 7226076 records as duplicates.\n",
      "INFO\t2024-11-17 10:09:50\tMarkDuplicates\tFound 0 optical duplicate clusters.\n",
      "INFO\t2024-11-17 10:09:50\tMarkDuplicates\tReads are assumed to be ordered by: coordinate\n",
      "INFO\t2024-11-17 10:10:22\tMarkDuplicates\tWriting complete. Closing input iterator.\n",
      "INFO\t2024-11-17 10:10:22\tMarkDuplicates\tDuplicate Index cleanup.\n",
      "INFO\t2024-11-17 10:10:22\tMarkDuplicates\tGetting Memory Stats.\n",
      "INFO\t2024-11-17 10:10:22\tMarkDuplicates\tBefore output close freeMemory: 53026432; totalMemory: 62914560; maxMemory: 4294967296\n",
      "INFO\t2024-11-17 10:10:22\tMarkDuplicates\tClosed outputs. Getting more Memory Stats.\n",
      "INFO\t2024-11-17 10:10:22\tMarkDuplicates\tAfter output close freeMemory: 32306192; totalMemory: 41943040; maxMemory: 4294967296\n",
      "[Sun Nov 17 10:10:22 IST 2024] picard.sam.markduplicates.MarkDuplicates done. Elapsed time: 1.06 minutes.\n",
      "Runtime.totalMemory()=41943040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduplication completed for sorted_bam/SRR085726_sorted.bam, output BAM: deduplicated_bam/SRR085726_dedup.bam\n"
     ]
    }
   ],
   "source": [
    "# Directory to store deduplicated BAM files\n",
    "dedup_bam_dir = 'deduplicated_bam'\n",
    "os.makedirs(dedup_bam_dir, exist_ok=True)\n",
    "\n",
    "# List of sorted BAM files\n",
    "sorted_bam_files = [os.path.join('sorted_bam', f) for f in [\n",
    "    'SRR087416_sorted.bam', 'SRR085725_sorted.bam',\n",
    "    'SRR085471_sorted.bam', 'SRR085473_sorted.bam',\n",
    "    'SRR085474_sorted.bam', 'SRR085726_sorted.bam']]\n",
    "\n",
    "# Path to Picard JAR file (adjust as needed)\n",
    "picard_jar_path = '/home/mahendra/Desktop/Python/Project/picard.jar'\n",
    "\n",
    "if not os.path.exists(picard_jar_path):\n",
    "    raise FileNotFoundError(f\"Picard JAR file not found at {picard_jar_path}\")\n",
    "\n",
    "# Run Picard MarkDuplicates\n",
    "for sorted_bam in sorted_bam_files:\n",
    "    dedup_bam = os.path.join(dedup_bam_dir, os.path.basename(sorted_bam).replace('_sorted.bam', '_dedup.bam'))\n",
    "    metrics_file = os.path.join(dedup_bam_dir, os.path.basename(sorted_bam).replace('_sorted.bam', '_metrics.txt'))\n",
    "\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            'java', '-Xmx4g', '-jar', picard_jar_path, 'MarkDuplicates',\n",
    "            f'I={sorted_bam}',\n",
    "            f'O={dedup_bam}',\n",
    "            f'M={metrics_file}',\n",
    "            'REMOVE_DUPLICATES=true',\n",
    "            'CREATE_INDEX=true'\n",
    "        ], check=True)\n",
    "        print(f\"Deduplication completed for {sorted_bam}, output BAM: {dedup_bam}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during deduplication for {sorted_bam}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da46c765-5c0a-4222-af7a-5b1aa5d64b91",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"\n",
    "    background-image: url('https://i.postimg.cc/K87ByXmr/stage5.jpg');\n",
    "    background-size: cover;\n",
    "    background-repeat: no-repeat;\n",
    "    font-family: 'Arial', sans-serif;\n",
    "    font-size: 24px;\n",
    "    color: white;\n",
    "    text-align: center;\n",
    "    border-radius: 15px 50px;\n",
    "    padding: 20px 40px;\n",
    "    margin: 20px 0;\n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\">\n",
    "    <b>Final Quality Check:  Qualimap, Samtools Stats, and MultiQC</b>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "60b6da7b-dc63-4559-a4d9-8ca602542ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java memory size is set to 1200M\n",
      "Launching application...\n",
      "\n",
      "QualiMap v.2.3\n",
      "Built on 2023-05-19 16:57\n",
      "\n",
      "Selected tool: bamqc\n",
      "Available memory (Mb): 35\n",
      "Max memory (Mb): 1258\n",
      "Sun Nov 17 11:51:58 IST 2024\t\tWARNING\tOutput folder already exists, the results will be saved there\n",
      "\n",
      "Starting bam qc....\n",
      "Loading sam header...\n",
      "Loading locator...\n",
      "Loading reference...\n",
      "Number of windows: 400, effective number of windows: 1104\n",
      "Chunk of reads size: 1000\n",
      "Number of threads: 8\n",
      "Processed 110 out of 1104 windows...\n",
      "Processed 220 out of 1104 windows...\n",
      "Processed 330 out of 1104 windows...\n",
      "Processed 440 out of 1104 windows...\n",
      "Processed 550 out of 1104 windows...\n",
      "Processed 660 out of 1104 windows...\n",
      "Processed 770 out of 1104 windows...\n",
      "Processed 880 out of 1104 windows...\n",
      "Processed 990 out of 1104 windows...\n",
      "Processed 1100 out of 1104 windows...\n",
      "Total processed windows:1104\n",
      "Number of reads: 7642762\n",
      "Number of valid reads: 6717101\n",
      "Number of correct strand reads:0\n",
      "Sun Nov 17 11:52:20 IST 2024\t\tWARNING\tSAMRecordParser marked 423 problematic reads.\n",
      "\n",
      "Inside of regions...\n",
      "Num mapped reads: 6717101\n",
      "Num mapped first of pair: 0\n",
      "Num mapped second of pair: 0\n",
      "Num singletons: 0\n",
      "Time taken to analyze reads: 22\n",
      "Computing descriptors...\n",
      "numberOfMappedBases: 240622234\n",
      "referenceSize: 3298430636\n",
      "numberOfSequencedBases: 240615589\n",
      "numberOfAs: 62491648\n",
      "Computing per chromosome statistics...\n",
      "Computing histograms...\n",
      "Overall analysis time: 22\n",
      "end of bam qc\n",
      "Computing report...\n",
      "Writing PDF:HTML report...\n",
      "HTML report created successfully\n",
      "\n",
      "PDF file created successfully \n",
      "\n",
      "Finished\n",
      "Qualimap completed for deduplicated_bam/SRR087416_dedup.bam. Results in qualimap_output/SRR087416\n",
      "Java memory size is set to 1200M\n",
      "Launching application...\n",
      "\n",
      "QualiMap v.2.3\n",
      "Built on 2023-05-19 16:57\n",
      "\n",
      "Selected tool: bamqc\n",
      "Available memory (Mb): 35\n",
      "Max memory (Mb): 1258\n",
      "Sun Nov 17 11:52:23 IST 2024\t\tWARNING\tOutput folder already exists, the results will be saved there\n",
      "\n",
      "Starting bam qc....\n",
      "Loading sam header...\n",
      "Loading locator...\n",
      "Loading reference...\n",
      "Number of windows: 400, effective number of windows: 1104\n",
      "Chunk of reads size: 1000\n",
      "Number of threads: 8\n",
      "Processed 110 out of 1104 windows...\n",
      "Processed 220 out of 1104 windows...\n",
      "Processed 330 out of 1104 windows...\n",
      "Processed 440 out of 1104 windows...\n",
      "Processed 550 out of 1104 windows...\n",
      "Processed 660 out of 1104 windows...\n",
      "Processed 770 out of 1104 windows...\n",
      "Processed 880 out of 1104 windows...\n",
      "Processed 990 out of 1104 windows...\n",
      "Processed 1100 out of 1104 windows...\n",
      "Total processed windows:1104\n",
      "Number of reads: 8002756\n",
      "Number of valid reads: 6731388\n",
      "Number of correct strand reads:0\n",
      "Sun Nov 17 11:52:47 IST 2024\t\tWARNING\tSAMRecordParser marked 2124 problematic reads.\n",
      "\n",
      "Inside of regions...\n",
      "Num mapped reads: 6731388\n",
      "Num mapped first of pair: 0\n",
      "Num mapped second of pair: 0\n",
      "Num singletons: 0\n",
      "Time taken to analyze reads: 24\n",
      "Computing descriptors...\n",
      "numberOfMappedBases: 234454103\n",
      "referenceSize: 3298430636\n",
      "numberOfSequencedBases: 234448842\n",
      "numberOfAs: 57528393\n",
      "Computing per chromosome statistics...\n",
      "Computing histograms...\n",
      "Overall analysis time: 24\n",
      "end of bam qc\n",
      "Computing report...\n",
      "Writing PDF:HTML report...\n",
      "HTML report created successfully\n",
      "\n",
      "PDF file created successfully \n",
      "\n",
      "Finished\n",
      "Qualimap completed for deduplicated_bam/SRR085726_dedup.bam. Results in qualimap_output/SRR085726\n",
      "Java memory size is set to 1200M\n",
      "Launching application...\n",
      "\n",
      "QualiMap v.2.3\n",
      "Built on 2023-05-19 16:57\n",
      "\n",
      "Selected tool: bamqc\n",
      "Available memory (Mb): 35\n",
      "Max memory (Mb): 1258\n",
      "Sun Nov 17 11:52:49 IST 2024\t\tWARNING\tOutput folder already exists, the results will be saved there\n",
      "\n",
      "Starting bam qc....\n",
      "Loading sam header...\n",
      "Loading locator...\n",
      "Loading reference...\n",
      "Number of windows: 400, effective number of windows: 1104\n",
      "Chunk of reads size: 1000\n",
      "Number of threads: 8\n",
      "Processed 110 out of 1104 windows...\n",
      "Processed 220 out of 1104 windows...\n",
      "Processed 330 out of 1104 windows...\n",
      "Processed 440 out of 1104 windows...\n",
      "Processed 550 out of 1104 windows...\n",
      "Processed 660 out of 1104 windows...\n",
      "Processed 770 out of 1104 windows...\n",
      "Processed 880 out of 1104 windows...\n",
      "Processed 990 out of 1104 windows...\n",
      "Processed 1100 out of 1104 windows...\n",
      "Total processed windows:1104\n",
      "Number of reads: 8612698\n",
      "Number of valid reads: 7496544\n",
      "Number of correct strand reads:0\n",
      "Sun Nov 17 11:53:14 IST 2024\t\tWARNING\tSAMRecordParser marked 140 problematic reads.\n",
      "\n",
      "Inside of regions...\n",
      "Num mapped reads: 7496544\n",
      "Num mapped first of pair: 0\n",
      "Num mapped second of pair: 0\n",
      "Num singletons: 0\n",
      "Time taken to analyze reads: 25\n",
      "Computing descriptors...\n",
      "numberOfMappedBases: 268357143\n",
      "referenceSize: 3298430636\n",
      "numberOfSequencedBases: 268350486\n",
      "numberOfAs: 67924486\n",
      "Computing per chromosome statistics...\n",
      "Computing histograms...\n",
      "Overall analysis time: 25\n",
      "end of bam qc\n",
      "Computing report...\n",
      "Writing PDF:HTML report...\n",
      "HTML report created successfully\n",
      "\n",
      "PDF file created successfully \n",
      "\n",
      "Finished\n",
      "Qualimap completed for deduplicated_bam/SRR085725_dedup.bam. Results in qualimap_output/SRR085725\n",
      "Java memory size is set to 1200M\n",
      "Launching application...\n",
      "\n",
      "QualiMap v.2.3\n",
      "Built on 2023-05-19 16:57\n",
      "\n",
      "Selected tool: bamqc\n",
      "Available memory (Mb): 35\n",
      "Max memory (Mb): 1258\n",
      "Sun Nov 17 11:53:17 IST 2024\t\tWARNING\tOutput folder already exists, the results will be saved there\n",
      "\n",
      "Starting bam qc....\n",
      "Loading sam header...\n",
      "Loading locator...\n",
      "Loading reference...\n",
      "Number of windows: 400, effective number of windows: 1104\n",
      "Chunk of reads size: 1000\n",
      "Number of threads: 8\n",
      "Processed 110 out of 1104 windows...\n",
      "Processed 220 out of 1104 windows...\n",
      "Processed 330 out of 1104 windows...\n",
      "Processed 440 out of 1104 windows...\n",
      "Processed 550 out of 1104 windows...\n",
      "Processed 660 out of 1104 windows...\n",
      "Processed 770 out of 1104 windows...\n",
      "Processed 880 out of 1104 windows...\n",
      "Processed 990 out of 1104 windows...\n",
      "Processed 1100 out of 1104 windows...\n",
      "Total processed windows:1104\n",
      "Number of reads: 9339262\n",
      "Number of valid reads: 7883882\n",
      "Number of correct strand reads:0\n",
      "Sun Nov 17 11:53:41 IST 2024\t\tWARNING\tSAMRecordParser marked 27 problematic reads.\n",
      "\n",
      "Inside of regions...\n",
      "Num mapped reads: 7883882\n",
      "Num mapped first of pair: 0\n",
      "Num mapped second of pair: 0\n",
      "Num singletons: 0\n",
      "Time taken to analyze reads: 24\n",
      "Computing descriptors...\n",
      "numberOfMappedBases: 274558548\n",
      "referenceSize: 3298430636\n",
      "numberOfSequencedBases: 274552524\n",
      "numberOfAs: 68161934\n",
      "Computing per chromosome statistics...\n",
      "Computing histograms...\n",
      "Overall analysis time: 24\n",
      "end of bam qc\n",
      "Computing report...\n",
      "Writing PDF:HTML report...\n",
      "HTML report created successfully\n",
      "\n",
      "PDF file created successfully \n",
      "\n",
      "Finished\n",
      "Qualimap completed for deduplicated_bam/SRR085474_dedup.bam. Results in qualimap_output/SRR085474\n",
      "Java memory size is set to 1200M\n",
      "Launching application...\n",
      "\n",
      "QualiMap v.2.3\n",
      "Built on 2023-05-19 16:57\n",
      "\n",
      "Selected tool: bamqc\n",
      "Available memory (Mb): 35\n",
      "Max memory (Mb): 1258\n",
      "Sun Nov 17 11:53:44 IST 2024\t\tWARNING\tOutput folder already exists, the results will be saved there\n",
      "\n",
      "Starting bam qc....\n",
      "Loading sam header...\n",
      "Loading locator...\n",
      "Loading reference...\n",
      "Number of windows: 400, effective number of windows: 1104\n",
      "Chunk of reads size: 1000\n",
      "Number of threads: 8\n",
      "Processed 110 out of 1104 windows...\n",
      "Processed 220 out of 1104 windows...\n",
      "Processed 330 out of 1104 windows...\n",
      "Processed 440 out of 1104 windows...\n",
      "Processed 550 out of 1104 windows...\n",
      "Processed 660 out of 1104 windows...\n",
      "Processed 770 out of 1104 windows...\n",
      "Processed 880 out of 1104 windows...\n",
      "Processed 990 out of 1104 windows...\n",
      "Processed 1100 out of 1104 windows...\n",
      "Total processed windows:1104\n",
      "Number of reads: 4812614\n",
      "Number of valid reads: 3748023\n",
      "Number of correct strand reads:0\n",
      "Sun Nov 17 11:54:05 IST 2024\t\tWARNING\tSAMRecordParser marked 5296 problematic reads.\n",
      "\n",
      "Inside of regions...\n",
      "Num mapped reads: 3748023\n",
      "Num mapped first of pair: 0\n",
      "Num mapped second of pair: 0\n",
      "Num singletons: 0\n",
      "Time taken to analyze reads: 21\n",
      "Computing descriptors...\n",
      "numberOfMappedBases: 130537020\n",
      "referenceSize: 3298430636\n",
      "numberOfSequencedBases: 130533121\n",
      "numberOfAs: 32057838\n",
      "Computing per chromosome statistics...\n",
      "Computing histograms...\n",
      "Overall analysis time: 21\n",
      "end of bam qc\n",
      "Computing report...\n",
      "Writing PDF:HTML report...\n",
      "HTML report created successfully\n",
      "\n",
      "PDF file created successfully \n",
      "\n",
      "Finished\n",
      "Qualimap completed for deduplicated_bam/SRR085473_dedup.bam. Results in qualimap_output/SRR085473\n",
      "Java memory size is set to 1200M\n",
      "Launching application...\n",
      "\n",
      "QualiMap v.2.3\n",
      "Built on 2023-05-19 16:57\n",
      "\n",
      "Selected tool: bamqc\n",
      "Available memory (Mb): 35\n",
      "Max memory (Mb): 1258\n",
      "Sun Nov 17 11:54:07 IST 2024\t\tWARNING\tOutput folder already exists, the results will be saved there\n",
      "\n",
      "Starting bam qc....\n",
      "Loading sam header...\n",
      "Loading locator...\n",
      "Loading reference...\n",
      "Number of windows: 400, effective number of windows: 1104\n",
      "Chunk of reads size: 1000\n",
      "Number of threads: 8\n",
      "Processed 110 out of 1104 windows...\n",
      "Processed 220 out of 1104 windows...\n",
      "Processed 330 out of 1104 windows...\n",
      "Processed 440 out of 1104 windows...\n",
      "Processed 550 out of 1104 windows...\n",
      "Processed 660 out of 1104 windows...\n",
      "Processed 770 out of 1104 windows...\n",
      "Processed 880 out of 1104 windows...\n",
      "Processed 990 out of 1104 windows...\n",
      "Processed 1100 out of 1104 windows...\n",
      "Total processed windows:1104\n",
      "Number of reads: 8695701\n",
      "Number of valid reads: 7539265\n",
      "Number of correct strand reads:0\n",
      "Sun Nov 17 11:54:32 IST 2024\t\tWARNING\tSAMRecordParser marked 73 problematic reads.\n",
      "\n",
      "Inside of regions...\n",
      "Num mapped reads: 7539265\n",
      "Num mapped first of pair: 0\n",
      "Num mapped second of pair: 0\n",
      "Num singletons: 0\n",
      "Time taken to analyze reads: 24\n",
      "Computing descriptors...\n",
      "numberOfMappedBases: 269889258\n",
      "referenceSize: 3298430636\n",
      "numberOfSequencedBases: 269881575\n",
      "numberOfAs: 67859516\n",
      "Computing per chromosome statistics...\n",
      "Computing histograms...\n",
      "Overall analysis time: 24\n",
      "end of bam qc\n",
      "Computing report...\n",
      "Writing PDF:HTML report...\n",
      "HTML report created successfully\n",
      "\n",
      "PDF file created successfully \n",
      "\n",
      "Finished\n",
      "Qualimap completed for deduplicated_bam/SRR085471_dedup.bam. Results in qualimap_output/SRR085471\n",
      "Samtools stats completed for deduplicated_bam/SRR087416_dedup.bam. Output in samtools_stats_output/SRR087416_stats.txt\n",
      "Samtools stats completed for deduplicated_bam/SRR085726_dedup.bam. Output in samtools_stats_output/SRR085726_stats.txt\n",
      "Samtools stats completed for deduplicated_bam/SRR085725_dedup.bam. Output in samtools_stats_output/SRR085725_stats.txt\n",
      "Samtools stats completed for deduplicated_bam/SRR085474_dedup.bam. Output in samtools_stats_output/SRR085474_stats.txt\n",
      "Samtools stats completed for deduplicated_bam/SRR085473_dedup.bam. Output in samtools_stats_output/SRR085473_stats.txt\n",
      "Samtools stats completed for deduplicated_bam/SRR085471_dedup.bam. Output in samtools_stats_output/SRR085471_stats.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[38;5;208m///\u001b[0m \u001b]8;id=233344;https://multiqc.info\u001b\\\u001b[1mMultiQC\u001b[0m\u001b]8;;\u001b\\ 🔍 \u001b[2mv1.25.1\u001b[0m\n",
      "\n",
      "\u001b[34m       file_search\u001b[0m | Search path: /home/mahendra/Desktop/Python/Project/qualimap_output\n",
      "\u001b[34m       file_search\u001b[0m | Search path: /home/mahendra/Desktop/Python/Project/samtools_stats_output\n",
      "\u001b[2K         \u001b[34msearching\u001b[0m | \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[32m288/288\u001b[0m  88\u001b[0m \u001b[2mqualimap_output/SRR085474/report.pdf\u001b[0m\n",
      "\u001b[?25h\u001b[34m          qualimap\u001b[0m | Found 6 BamQC reports\n",
      "\u001b[34m          samtools\u001b[0m | Found 6 stats reports\n",
      "\u001b[34m     write_results\u001b[0m | Data        : multiqc_output/multiqc_data\n",
      "\u001b[34m     write_results\u001b[0m | Report      : multiqc_output/multiqc_report.html\n",
      "\u001b[34m           multiqc\u001b[0m | MultiQC complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiQC completed. Aggregated report available in: multiqc_output\n"
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "#dedup_bam_dir = 'deduplicated_bam'  # Directory containing deduplicated BAM files\n",
    "qualimap_output_dir = 'qualimap_output'  # Qualimap results directory\n",
    "samtools_stats_output_dir = 'samtools_stats_output'  # Directory for Samtools stats output\n",
    "multiqc_output_dir = 'multiqc_output'  # MultiQC aggregated results directory\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(qualimap_output_dir, exist_ok=True)\n",
    "os.makedirs(samtools_stats_output_dir, exist_ok=True)\n",
    "os.makedirs(multiqc_output_dir, exist_ok=True)\n",
    "\n",
    "# List deduplicated BAM files\n",
    "dedup_bam_files = [os.path.join(dedup_bam_dir, f) for f in os.listdir(dedup_bam_dir) if f.endswith('_dedup.bam')]\n",
    "\n",
    "# Step 1: Run Qualimap BAMQC\n",
    "for bam_file in dedup_bam_files:\n",
    "    sample_name = os.path.basename(bam_file).replace('_dedup.bam', '')\n",
    "    sample_output_dir = os.path.join(qualimap_output_dir, sample_name)\n",
    "    os.makedirs(sample_output_dir, exist_ok=True)\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            'qualimap', 'bamqc',\n",
    "            '-bam', bam_file,\n",
    "            '-outdir', sample_output_dir,\n",
    "            '-outformat', 'PDF:HTML'\n",
    "        ], check=True)\n",
    "        print(f\"Qualimap completed for {bam_file}. Results in {sample_output_dir}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running Qualimap for {bam_file}: {e}\")\n",
    "\n",
    "# Step 2: Run Samtools stats\n",
    "for bam_file in dedup_bam_files:\n",
    "    sample_name = os.path.basename(bam_file).replace('_dedup.bam', '')\n",
    "    stats_output_file = os.path.join(samtools_stats_output_dir, f\"{sample_name}_stats.txt\")\n",
    "    try:\n",
    "        with open(stats_output_file, 'w') as stats_out:\n",
    "            subprocess.run(['samtools', 'stats', bam_file], stdout=stats_out, check=True)\n",
    "        print(f\"Samtools stats completed for {bam_file}. Output in {stats_output_file}\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running Samtools stats for {bam_file}: {e}\")\n",
    "\n",
    "# Step 3: Run MultiQC to aggregate results\n",
    "try:\n",
    "    subprocess.run(['multiqc', qualimap_output_dir, samtools_stats_output_dir, '-o', multiqc_output_dir], check=True)\n",
    "    print(\"MultiQC completed. Aggregated report available in:\", multiqc_output_dir)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(\"Error running MultiQC:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "13620992-eaa6-4aa1-bf6a-cc65839bbc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"800\"\n",
       "            src=\"multiqc_output/multiqc_report.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ed1cad6fcb0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the MultiQC report\n",
    "multiqc_report_path = os.path.join(multiqc_output_dir, \"multiqc_report.html\")\n",
    "# Display the report in the notebook\n",
    "IFrame(multiqc_report_path, width=1000, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea33159-c507-4aca-bf1d-4009b02003c6",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"\n",
    "    background-image: url('https://i.postimg.cc/K87ByXmr/stage5.jpg');\n",
    "    background-size: cover;\n",
    "    background-repeat: no-repeat;\n",
    "    font-family: 'Arial', sans-serif;\n",
    "    font-size: 24px;\n",
    "    color: white;\n",
    "    text-align: center;\n",
    "    border-radius: 15px 50px;\n",
    "    padding: 20px 40px;\n",
    "    margin: 20px 0;\n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\">\n",
    "    <b>Reads Quantification using HTseq</b>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "ad3fa2b6-9199-4f11-95e5-14b15dc4625a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Quantifying Reads:   0%|                                                                                                                                        | 0/6 [00:00<?, ?file/s]100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1900000 GFF lines processed.\n",
      "2000000 GFF lines processed.\n",
      "2100000 GFF lines processed.\n",
      "2200000 GFF lines processed.\n",
      "2300000 GFF lines processed.\n",
      "2400000 GFF lines processed.\n",
      "2500000 GFF lines processed.\n",
      "2600000 GFF lines processed.\n",
      "2700000 GFF lines processed.\n",
      "2800000 GFF lines processed.\n",
      "2900000 GFF lines processed.\n",
      "3000000 GFF lines processed.\n",
      "3100000 GFF lines processed.\n",
      "3200000 GFF lines processed.\n",
      "3300000 GFF lines processed.\n",
      "3400000 GFF lines processed.\n",
      "3500000 GFF lines processed.\n",
      "3600000 GFF lines processed.\n",
      "3700000 GFF lines processed.\n",
      "3800000 GFF lines processed.\n",
      "3900000 GFF lines processed.\n",
      "4000000 GFF lines processed.\n",
      "4100000 GFF lines processed.\n",
      "4200000 GFF lines processed.\n",
      "4300000 GFF lines processed.\n",
      "4400000 GFF lines processed.\n",
      "4500000 GFF lines processed.\n",
      "4600000 GFF lines processed.\n",
      "4697665 GFF lines processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "300000 alignment records processed.\n",
      "400000 alignment records processed.\n",
      "500000 alignment records processed.\n",
      "600000 alignment records processed.\n",
      "700000 alignment records processed.\n",
      "800000 alignment records processed.\n",
      "900000 alignment records processed.\n",
      "1000000 alignment records processed.\n",
      "1100000 alignment records processed.\n",
      "1200000 alignment records processed.\n",
      "1300000 alignment records processed.\n",
      "1400000 alignment records processed.\n",
      "1500000 alignment records processed.\n",
      "1600000 alignment records processed.\n",
      "1700000 alignment records processed.\n",
      "1800000 alignment records processed.\n",
      "1900000 alignment records processed.\n",
      "2000000 alignment records processed.\n",
      "2100000 alignment records processed.\n",
      "2200000 alignment records processed.\n",
      "2300000 alignment records processed.\n",
      "2400000 alignment records processed.\n",
      "2500000 alignment records processed.\n",
      "2600000 alignment records processed.\n",
      "2700000 alignment records processed.\n",
      "2800000 alignment records processed.\n",
      "2900000 alignment records processed.\n",
      "3000000 alignment records processed.\n",
      "3100000 alignment records processed.\n",
      "3200000 alignment records processed.\n",
      "3300000 alignment records processed.\n",
      "3400000 alignment records processed.\n",
      "3500000 alignment records processed.\n",
      "3600000 alignment records processed.\n",
      "3700000 alignment records processed.\n",
      "3800000 alignment records processed.\n",
      "3900000 alignment records processed.\n",
      "4000000 alignment records processed.\n",
      "4100000 alignment records processed.\n",
      "4200000 alignment records processed.\n",
      "4300000 alignment records processed.\n",
      "4400000 alignment records processed.\n",
      "4500000 alignment records processed.\n",
      "4600000 alignment records processed.\n",
      "4700000 alignment records processed.\n",
      "4800000 alignment records processed.\n",
      "4900000 alignment records processed.\n",
      "5000000 alignment records processed.\n",
      "5100000 alignment records processed.\n",
      "5200000 alignment records processed.\n",
      "5300000 alignment records processed.\n",
      "5400000 alignment records processed.\n",
      "5500000 alignment records processed.\n",
      "5600000 alignment records processed.\n",
      "5700000 alignment records processed.\n",
      "5800000 alignment records processed.\n",
      "5900000 alignment records processed.\n",
      "6000000 alignment records processed.\n",
      "6100000 alignment records processed.\n",
      "6200000 alignment records processed.\n",
      "6300000 alignment records processed.\n",
      "6400000 alignment records processed.\n",
      "6500000 alignment records processed.\n",
      "6600000 alignment records processed.\n",
      "6700000 alignment records processed.\n",
      "6800000 alignment records processed.\n",
      "6900000 alignment records processed.\n",
      "7000000 alignment records processed.\n",
      "7100000 alignment records processed.\n",
      "7200000 alignment records processed.\n",
      "7300000 alignment records processed.\n",
      "7400000 alignment records processed.\n",
      "7500000 alignment records processed.\n",
      "7600000 alignment records processed.\n",
      "7642762 alignment records processed.\n",
      "Quantifying Reads:  17%|█████████████████████▏                                                                                                         | 1/6 [04:03<20:17, 243.48s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts saved to read_counts/SRR087416_counts.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1900000 GFF lines processed.\n",
      "2000000 GFF lines processed.\n",
      "2100000 GFF lines processed.\n",
      "2200000 GFF lines processed.\n",
      "2300000 GFF lines processed.\n",
      "2400000 GFF lines processed.\n",
      "2500000 GFF lines processed.\n",
      "2600000 GFF lines processed.\n",
      "2700000 GFF lines processed.\n",
      "2800000 GFF lines processed.\n",
      "2900000 GFF lines processed.\n",
      "3000000 GFF lines processed.\n",
      "3100000 GFF lines processed.\n",
      "3200000 GFF lines processed.\n",
      "3300000 GFF lines processed.\n",
      "3400000 GFF lines processed.\n",
      "3500000 GFF lines processed.\n",
      "3600000 GFF lines processed.\n",
      "3700000 GFF lines processed.\n",
      "3800000 GFF lines processed.\n",
      "3900000 GFF lines processed.\n",
      "4000000 GFF lines processed.\n",
      "4100000 GFF lines processed.\n",
      "4200000 GFF lines processed.\n",
      "4300000 GFF lines processed.\n",
      "4400000 GFF lines processed.\n",
      "4500000 GFF lines processed.\n",
      "4600000 GFF lines processed.\n",
      "4697665 GFF lines processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "300000 alignment records processed.\n",
      "400000 alignment records processed.\n",
      "500000 alignment records processed.\n",
      "600000 alignment records processed.\n",
      "700000 alignment records processed.\n",
      "800000 alignment records processed.\n",
      "900000 alignment records processed.\n",
      "1000000 alignment records processed.\n",
      "1100000 alignment records processed.\n",
      "1200000 alignment records processed.\n",
      "1300000 alignment records processed.\n",
      "1400000 alignment records processed.\n",
      "1500000 alignment records processed.\n",
      "1600000 alignment records processed.\n",
      "1700000 alignment records processed.\n",
      "1800000 alignment records processed.\n",
      "1900000 alignment records processed.\n",
      "2000000 alignment records processed.\n",
      "2100000 alignment records processed.\n",
      "2200000 alignment records processed.\n",
      "2300000 alignment records processed.\n",
      "2400000 alignment records processed.\n",
      "2500000 alignment records processed.\n",
      "2600000 alignment records processed.\n",
      "2700000 alignment records processed.\n",
      "2800000 alignment records processed.\n",
      "2900000 alignment records processed.\n",
      "3000000 alignment records processed.\n",
      "3100000 alignment records processed.\n",
      "3200000 alignment records processed.\n",
      "3300000 alignment records processed.\n",
      "3400000 alignment records processed.\n",
      "3500000 alignment records processed.\n",
      "3600000 alignment records processed.\n",
      "3700000 alignment records processed.\n",
      "3800000 alignment records processed.\n",
      "3900000 alignment records processed.\n",
      "4000000 alignment records processed.\n",
      "4100000 alignment records processed.\n",
      "4200000 alignment records processed.\n",
      "4300000 alignment records processed.\n",
      "4400000 alignment records processed.\n",
      "4500000 alignment records processed.\n",
      "4600000 alignment records processed.\n",
      "4700000 alignment records processed.\n",
      "4800000 alignment records processed.\n",
      "4900000 alignment records processed.\n",
      "5000000 alignment records processed.\n",
      "5100000 alignment records processed.\n",
      "5200000 alignment records processed.\n",
      "5300000 alignment records processed.\n",
      "5400000 alignment records processed.\n",
      "5500000 alignment records processed.\n",
      "5600000 alignment records processed.\n",
      "5700000 alignment records processed.\n",
      "5800000 alignment records processed.\n",
      "5900000 alignment records processed.\n",
      "6000000 alignment records processed.\n",
      "6100000 alignment records processed.\n",
      "6200000 alignment records processed.\n",
      "6300000 alignment records processed.\n",
      "6400000 alignment records processed.\n",
      "6500000 alignment records processed.\n",
      "6600000 alignment records processed.\n",
      "6700000 alignment records processed.\n",
      "6800000 alignment records processed.\n",
      "6900000 alignment records processed.\n",
      "7000000 alignment records processed.\n",
      "7100000 alignment records processed.\n",
      "7200000 alignment records processed.\n",
      "7300000 alignment records processed.\n",
      "7400000 alignment records processed.\n",
      "7500000 alignment records processed.\n",
      "7600000 alignment records processed.\n",
      "7700000 alignment records processed.\n",
      "7800000 alignment records processed.\n",
      "7900000 alignment records processed.\n",
      "8000000 alignment records processed.\n",
      "8002756 alignment records processed.\n",
      "Quantifying Reads:  33%|██████████████████████████████████████████▎                                                                                    | 2/6 [07:59<15:55, 238.81s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts saved to read_counts/SRR085726_counts.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1900000 GFF lines processed.\n",
      "2000000 GFF lines processed.\n",
      "2100000 GFF lines processed.\n",
      "2200000 GFF lines processed.\n",
      "2300000 GFF lines processed.\n",
      "2400000 GFF lines processed.\n",
      "2500000 GFF lines processed.\n",
      "2600000 GFF lines processed.\n",
      "2700000 GFF lines processed.\n",
      "2800000 GFF lines processed.\n",
      "2900000 GFF lines processed.\n",
      "3000000 GFF lines processed.\n",
      "3100000 GFF lines processed.\n",
      "3200000 GFF lines processed.\n",
      "3300000 GFF lines processed.\n",
      "3400000 GFF lines processed.\n",
      "3500000 GFF lines processed.\n",
      "3600000 GFF lines processed.\n",
      "3700000 GFF lines processed.\n",
      "3800000 GFF lines processed.\n",
      "3900000 GFF lines processed.\n",
      "4000000 GFF lines processed.\n",
      "4100000 GFF lines processed.\n",
      "4200000 GFF lines processed.\n",
      "4300000 GFF lines processed.\n",
      "4400000 GFF lines processed.\n",
      "4500000 GFF lines processed.\n",
      "4600000 GFF lines processed.\n",
      "4697665 GFF lines processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "300000 alignment records processed.\n",
      "400000 alignment records processed.\n",
      "500000 alignment records processed.\n",
      "600000 alignment records processed.\n",
      "700000 alignment records processed.\n",
      "800000 alignment records processed.\n",
      "900000 alignment records processed.\n",
      "1000000 alignment records processed.\n",
      "1100000 alignment records processed.\n",
      "1200000 alignment records processed.\n",
      "1300000 alignment records processed.\n",
      "1400000 alignment records processed.\n",
      "1500000 alignment records processed.\n",
      "1600000 alignment records processed.\n",
      "1700000 alignment records processed.\n",
      "1800000 alignment records processed.\n",
      "1900000 alignment records processed.\n",
      "2000000 alignment records processed.\n",
      "2100000 alignment records processed.\n",
      "2200000 alignment records processed.\n",
      "2300000 alignment records processed.\n",
      "2400000 alignment records processed.\n",
      "2500000 alignment records processed.\n",
      "2600000 alignment records processed.\n",
      "2700000 alignment records processed.\n",
      "2800000 alignment records processed.\n",
      "2900000 alignment records processed.\n",
      "3000000 alignment records processed.\n",
      "3100000 alignment records processed.\n",
      "3200000 alignment records processed.\n",
      "3300000 alignment records processed.\n",
      "3400000 alignment records processed.\n",
      "3500000 alignment records processed.\n",
      "3600000 alignment records processed.\n",
      "3700000 alignment records processed.\n",
      "3800000 alignment records processed.\n",
      "3900000 alignment records processed.\n",
      "4000000 alignment records processed.\n",
      "4100000 alignment records processed.\n",
      "4200000 alignment records processed.\n",
      "4300000 alignment records processed.\n",
      "4400000 alignment records processed.\n",
      "4500000 alignment records processed.\n",
      "4600000 alignment records processed.\n",
      "4700000 alignment records processed.\n",
      "4800000 alignment records processed.\n",
      "4900000 alignment records processed.\n",
      "5000000 alignment records processed.\n",
      "5100000 alignment records processed.\n",
      "5200000 alignment records processed.\n",
      "5300000 alignment records processed.\n",
      "5400000 alignment records processed.\n",
      "5500000 alignment records processed.\n",
      "5600000 alignment records processed.\n",
      "5700000 alignment records processed.\n",
      "5800000 alignment records processed.\n",
      "5900000 alignment records processed.\n",
      "6000000 alignment records processed.\n",
      "6100000 alignment records processed.\n",
      "6200000 alignment records processed.\n",
      "6300000 alignment records processed.\n",
      "6400000 alignment records processed.\n",
      "6500000 alignment records processed.\n",
      "6600000 alignment records processed.\n",
      "6700000 alignment records processed.\n",
      "6800000 alignment records processed.\n",
      "6900000 alignment records processed.\n",
      "7000000 alignment records processed.\n",
      "7100000 alignment records processed.\n",
      "7200000 alignment records processed.\n",
      "7300000 alignment records processed.\n",
      "7400000 alignment records processed.\n",
      "7500000 alignment records processed.\n",
      "7600000 alignment records processed.\n",
      "7700000 alignment records processed.\n",
      "7800000 alignment records processed.\n",
      "7900000 alignment records processed.\n",
      "8000000 alignment records processed.\n",
      "8100000 alignment records processed.\n",
      "8200000 alignment records processed.\n",
      "8300000 alignment records processed.\n",
      "8400000 alignment records processed.\n",
      "8500000 alignment records processed.\n",
      "8600000 alignment records processed.\n",
      "8612698 alignment records processed.\n",
      "Quantifying Reads:  50%|███████████████████████████████████████████████████████████████▌                                                               | 3/6 [12:13<12:18, 246.16s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts saved to read_counts/SRR085725_counts.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1900000 GFF lines processed.\n",
      "2000000 GFF lines processed.\n",
      "2100000 GFF lines processed.\n",
      "2200000 GFF lines processed.\n",
      "2300000 GFF lines processed.\n",
      "2400000 GFF lines processed.\n",
      "2500000 GFF lines processed.\n",
      "2600000 GFF lines processed.\n",
      "2700000 GFF lines processed.\n",
      "2800000 GFF lines processed.\n",
      "2900000 GFF lines processed.\n",
      "3000000 GFF lines processed.\n",
      "3100000 GFF lines processed.\n",
      "3200000 GFF lines processed.\n",
      "3300000 GFF lines processed.\n",
      "3400000 GFF lines processed.\n",
      "3500000 GFF lines processed.\n",
      "3600000 GFF lines processed.\n",
      "3700000 GFF lines processed.\n",
      "3800000 GFF lines processed.\n",
      "3900000 GFF lines processed.\n",
      "4000000 GFF lines processed.\n",
      "4100000 GFF lines processed.\n",
      "4200000 GFF lines processed.\n",
      "4300000 GFF lines processed.\n",
      "4400000 GFF lines processed.\n",
      "4500000 GFF lines processed.\n",
      "4600000 GFF lines processed.\n",
      "4697665 GFF lines processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "300000 alignment records processed.\n",
      "400000 alignment records processed.\n",
      "500000 alignment records processed.\n",
      "600000 alignment records processed.\n",
      "700000 alignment records processed.\n",
      "800000 alignment records processed.\n",
      "900000 alignment records processed.\n",
      "1000000 alignment records processed.\n",
      "1100000 alignment records processed.\n",
      "1200000 alignment records processed.\n",
      "1300000 alignment records processed.\n",
      "1400000 alignment records processed.\n",
      "1500000 alignment records processed.\n",
      "1600000 alignment records processed.\n",
      "1700000 alignment records processed.\n",
      "1800000 alignment records processed.\n",
      "1900000 alignment records processed.\n",
      "2000000 alignment records processed.\n",
      "2100000 alignment records processed.\n",
      "2200000 alignment records processed.\n",
      "2300000 alignment records processed.\n",
      "2400000 alignment records processed.\n",
      "2500000 alignment records processed.\n",
      "2600000 alignment records processed.\n",
      "2700000 alignment records processed.\n",
      "2800000 alignment records processed.\n",
      "2900000 alignment records processed.\n",
      "3000000 alignment records processed.\n",
      "3100000 alignment records processed.\n",
      "3200000 alignment records processed.\n",
      "3300000 alignment records processed.\n",
      "3400000 alignment records processed.\n",
      "3500000 alignment records processed.\n",
      "3600000 alignment records processed.\n",
      "3700000 alignment records processed.\n",
      "3800000 alignment records processed.\n",
      "3900000 alignment records processed.\n",
      "4000000 alignment records processed.\n",
      "4100000 alignment records processed.\n",
      "4200000 alignment records processed.\n",
      "4300000 alignment records processed.\n",
      "4400000 alignment records processed.\n",
      "4500000 alignment records processed.\n",
      "4600000 alignment records processed.\n",
      "4700000 alignment records processed.\n",
      "4800000 alignment records processed.\n",
      "4900000 alignment records processed.\n",
      "5000000 alignment records processed.\n",
      "5100000 alignment records processed.\n",
      "5200000 alignment records processed.\n",
      "5300000 alignment records processed.\n",
      "5400000 alignment records processed.\n",
      "5500000 alignment records processed.\n",
      "5600000 alignment records processed.\n",
      "5700000 alignment records processed.\n",
      "5800000 alignment records processed.\n",
      "5900000 alignment records processed.\n",
      "6000000 alignment records processed.\n",
      "6100000 alignment records processed.\n",
      "6200000 alignment records processed.\n",
      "6300000 alignment records processed.\n",
      "6400000 alignment records processed.\n",
      "6500000 alignment records processed.\n",
      "6600000 alignment records processed.\n",
      "6700000 alignment records processed.\n",
      "6800000 alignment records processed.\n",
      "6900000 alignment records processed.\n",
      "7000000 alignment records processed.\n",
      "7100000 alignment records processed.\n",
      "7200000 alignment records processed.\n",
      "7300000 alignment records processed.\n",
      "7400000 alignment records processed.\n",
      "7500000 alignment records processed.\n",
      "7600000 alignment records processed.\n",
      "7700000 alignment records processed.\n",
      "7800000 alignment records processed.\n",
      "7900000 alignment records processed.\n",
      "8000000 alignment records processed.\n",
      "8100000 alignment records processed.\n",
      "8200000 alignment records processed.\n",
      "8300000 alignment records processed.\n",
      "8400000 alignment records processed.\n",
      "8500000 alignment records processed.\n",
      "8600000 alignment records processed.\n",
      "8700000 alignment records processed.\n",
      "8800000 alignment records processed.\n",
      "8900000 alignment records processed.\n",
      "9000000 alignment records processed.\n",
      "9100000 alignment records processed.\n",
      "9200000 alignment records processed.\n",
      "9300000 alignment records processed.\n",
      "9339262 alignment records processed.\n",
      "Quantifying Reads:  67%|████████████████████████████████████████████████████████████████████████████████████▋                                          | 4/6 [16:45<08:32, 256.23s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts saved to read_counts/SRR085474_counts.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1900000 GFF lines processed.\n",
      "2000000 GFF lines processed.\n",
      "2100000 GFF lines processed.\n",
      "2200000 GFF lines processed.\n",
      "2300000 GFF lines processed.\n",
      "2400000 GFF lines processed.\n",
      "2500000 GFF lines processed.\n",
      "2600000 GFF lines processed.\n",
      "2700000 GFF lines processed.\n",
      "2800000 GFF lines processed.\n",
      "2900000 GFF lines processed.\n",
      "3000000 GFF lines processed.\n",
      "3100000 GFF lines processed.\n",
      "3200000 GFF lines processed.\n",
      "3300000 GFF lines processed.\n",
      "3400000 GFF lines processed.\n",
      "3500000 GFF lines processed.\n",
      "3600000 GFF lines processed.\n",
      "3700000 GFF lines processed.\n",
      "3800000 GFF lines processed.\n",
      "3900000 GFF lines processed.\n",
      "4000000 GFF lines processed.\n",
      "4100000 GFF lines processed.\n",
      "4200000 GFF lines processed.\n",
      "4300000 GFF lines processed.\n",
      "4400000 GFF lines processed.\n",
      "4500000 GFF lines processed.\n",
      "4600000 GFF lines processed.\n",
      "4697665 GFF lines processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "300000 alignment records processed.\n",
      "400000 alignment records processed.\n",
      "500000 alignment records processed.\n",
      "600000 alignment records processed.\n",
      "700000 alignment records processed.\n",
      "800000 alignment records processed.\n",
      "900000 alignment records processed.\n",
      "1000000 alignment records processed.\n",
      "1100000 alignment records processed.\n",
      "1200000 alignment records processed.\n",
      "1300000 alignment records processed.\n",
      "1400000 alignment records processed.\n",
      "1500000 alignment records processed.\n",
      "1600000 alignment records processed.\n",
      "1700000 alignment records processed.\n",
      "1800000 alignment records processed.\n",
      "1900000 alignment records processed.\n",
      "2000000 alignment records processed.\n",
      "2100000 alignment records processed.\n",
      "2200000 alignment records processed.\n",
      "2300000 alignment records processed.\n",
      "2400000 alignment records processed.\n",
      "2500000 alignment records processed.\n",
      "2600000 alignment records processed.\n",
      "2700000 alignment records processed.\n",
      "2800000 alignment records processed.\n",
      "2900000 alignment records processed.\n",
      "3000000 alignment records processed.\n",
      "3100000 alignment records processed.\n",
      "3200000 alignment records processed.\n",
      "3300000 alignment records processed.\n",
      "3400000 alignment records processed.\n",
      "3500000 alignment records processed.\n",
      "3600000 alignment records processed.\n",
      "3700000 alignment records processed.\n",
      "3800000 alignment records processed.\n",
      "3900000 alignment records processed.\n",
      "4000000 alignment records processed.\n",
      "4100000 alignment records processed.\n",
      "4200000 alignment records processed.\n",
      "4300000 alignment records processed.\n",
      "4400000 alignment records processed.\n",
      "4500000 alignment records processed.\n",
      "4600000 alignment records processed.\n",
      "4700000 alignment records processed.\n",
      "4800000 alignment records processed.\n",
      "4812614 alignment records processed.\n",
      "Quantifying Reads:  83%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 5/6 [19:53<03:51, 231.69s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts saved to read_counts/SRR085473_counts.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100000 GFF lines processed.\n",
      "200000 GFF lines processed.\n",
      "300000 GFF lines processed.\n",
      "400000 GFF lines processed.\n",
      "500000 GFF lines processed.\n",
      "600000 GFF lines processed.\n",
      "700000 GFF lines processed.\n",
      "800000 GFF lines processed.\n",
      "900000 GFF lines processed.\n",
      "1000000 GFF lines processed.\n",
      "1100000 GFF lines processed.\n",
      "1200000 GFF lines processed.\n",
      "1300000 GFF lines processed.\n",
      "1400000 GFF lines processed.\n",
      "1500000 GFF lines processed.\n",
      "1600000 GFF lines processed.\n",
      "1700000 GFF lines processed.\n",
      "1800000 GFF lines processed.\n",
      "1900000 GFF lines processed.\n",
      "2000000 GFF lines processed.\n",
      "2100000 GFF lines processed.\n",
      "2200000 GFF lines processed.\n",
      "2300000 GFF lines processed.\n",
      "2400000 GFF lines processed.\n",
      "2500000 GFF lines processed.\n",
      "2600000 GFF lines processed.\n",
      "2700000 GFF lines processed.\n",
      "2800000 GFF lines processed.\n",
      "2900000 GFF lines processed.\n",
      "3000000 GFF lines processed.\n",
      "3100000 GFF lines processed.\n",
      "3200000 GFF lines processed.\n",
      "3300000 GFF lines processed.\n",
      "3400000 GFF lines processed.\n",
      "3500000 GFF lines processed.\n",
      "3600000 GFF lines processed.\n",
      "3700000 GFF lines processed.\n",
      "3800000 GFF lines processed.\n",
      "3900000 GFF lines processed.\n",
      "4000000 GFF lines processed.\n",
      "4100000 GFF lines processed.\n",
      "4200000 GFF lines processed.\n",
      "4300000 GFF lines processed.\n",
      "4400000 GFF lines processed.\n",
      "4500000 GFF lines processed.\n",
      "4600000 GFF lines processed.\n",
      "4697665 GFF lines processed.\n",
      "100000 alignment records processed.\n",
      "200000 alignment records processed.\n",
      "300000 alignment records processed.\n",
      "400000 alignment records processed.\n",
      "500000 alignment records processed.\n",
      "600000 alignment records processed.\n",
      "700000 alignment records processed.\n",
      "800000 alignment records processed.\n",
      "900000 alignment records processed.\n",
      "1000000 alignment records processed.\n",
      "1100000 alignment records processed.\n",
      "1200000 alignment records processed.\n",
      "1300000 alignment records processed.\n",
      "1400000 alignment records processed.\n",
      "1500000 alignment records processed.\n",
      "1600000 alignment records processed.\n",
      "1700000 alignment records processed.\n",
      "1800000 alignment records processed.\n",
      "1900000 alignment records processed.\n",
      "2000000 alignment records processed.\n",
      "2100000 alignment records processed.\n",
      "2200000 alignment records processed.\n",
      "2300000 alignment records processed.\n",
      "2400000 alignment records processed.\n",
      "2500000 alignment records processed.\n",
      "2600000 alignment records processed.\n",
      "2700000 alignment records processed.\n",
      "2800000 alignment records processed.\n",
      "2900000 alignment records processed.\n",
      "3000000 alignment records processed.\n",
      "3100000 alignment records processed.\n",
      "3200000 alignment records processed.\n",
      "3300000 alignment records processed.\n",
      "3400000 alignment records processed.\n",
      "3500000 alignment records processed.\n",
      "3600000 alignment records processed.\n",
      "3700000 alignment records processed.\n",
      "3800000 alignment records processed.\n",
      "3900000 alignment records processed.\n",
      "4000000 alignment records processed.\n",
      "4100000 alignment records processed.\n",
      "4200000 alignment records processed.\n",
      "4300000 alignment records processed.\n",
      "4400000 alignment records processed.\n",
      "4500000 alignment records processed.\n",
      "4600000 alignment records processed.\n",
      "4700000 alignment records processed.\n",
      "4800000 alignment records processed.\n",
      "4900000 alignment records processed.\n",
      "5000000 alignment records processed.\n",
      "5100000 alignment records processed.\n",
      "5200000 alignment records processed.\n",
      "5300000 alignment records processed.\n",
      "5400000 alignment records processed.\n",
      "5500000 alignment records processed.\n",
      "5600000 alignment records processed.\n",
      "5700000 alignment records processed.\n",
      "5800000 alignment records processed.\n",
      "5900000 alignment records processed.\n",
      "6000000 alignment records processed.\n",
      "6100000 alignment records processed.\n",
      "6200000 alignment records processed.\n",
      "6300000 alignment records processed.\n",
      "6400000 alignment records processed.\n",
      "6500000 alignment records processed.\n",
      "6600000 alignment records processed.\n",
      "6700000 alignment records processed.\n",
      "6800000 alignment records processed.\n",
      "6900000 alignment records processed.\n",
      "7000000 alignment records processed.\n",
      "7100000 alignment records processed.\n",
      "7200000 alignment records processed.\n",
      "7300000 alignment records processed.\n",
      "7400000 alignment records processed.\n",
      "7500000 alignment records processed.\n",
      "7600000 alignment records processed.\n",
      "7700000 alignment records processed.\n",
      "7800000 alignment records processed.\n",
      "7900000 alignment records processed.\n",
      "8000000 alignment records processed.\n",
      "8100000 alignment records processed.\n",
      "8200000 alignment records processed.\n",
      "8300000 alignment records processed.\n",
      "8400000 alignment records processed.\n",
      "8500000 alignment records processed.\n",
      "8600000 alignment records processed.\n",
      "8695701 alignment records processed.\n",
      "Quantifying Reads: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 6/6 [24:21<00:00, 243.62s/file]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts saved to read_counts/SRR085471_counts.txt\n",
      "Read quantification completed for all BAM files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Directories for input and output\n",
    "#dedup_bam_dir = 'dedup_bam'  # BAM files already deduplicated using Picard\n",
    "count_output_dir = 'read_counts'\n",
    "os.makedirs(count_output_dir, exist_ok=True)\n",
    "\n",
    "# Reference annotation file for quantification\n",
    "gff_file = '/home/mahendra/Desktop/Python/Project/GTF/GCF_000001405.40_GRCh38.p14_genomic.gtf'\n",
    "if not os.path.exists(gff_file):\n",
    "    print(\"GTF file not found. Downloading...\")\n",
    "    os.makedirs('GTF', exist_ok=True)\n",
    "    subprocess.run(['wget', '-q', '-O', 'GCF_000001405.40_GRCh38.p14_genomic.gtf.gz',\n",
    "                    'https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/405/GCF_000001405.40_GRCh38.p14/GCF_000001405.40_GRCh38.p14_genomic.gtf.gz'])\n",
    "    subprocess.run(['gunzip', 'GCF_000001405.40_GRCh38.p14_genomic.gtf.gz'])\n",
    "    subprocess.run(['mv', 'GCF_000001405.40_GRCh38.p14_genomic.gtf', gff_file])\n",
    "    print(\"GTF file downloaded and prepared.\")\n",
    "\n",
    "# List of deduplicated BAM files\n",
    "dedup_bam_files = [os.path.join(dedup_bam_dir, f) for f in os.listdir(dedup_bam_dir) if f.endswith('_dedup.bam')]\n",
    "\n",
    "# Process each deduplicated BAM file\n",
    "for dedup_bam_file in tqdm(dedup_bam_files, desc=\"Quantifying Reads\", unit=\"file\"):\n",
    "    # Define output file for counts\n",
    "    count_file = os.path.join(count_output_dir, os.path.basename(dedup_bam_file).replace('_dedup.bam', '_counts.txt'))\n",
    "\n",
    "    # Run htseq-count\n",
    "    subprocess.run([\n",
    "        'htseq-count',\n",
    "        '-f', 'bam',        # Input file format\n",
    "        '-r', 'pos',        # Sort order: positional\n",
    "        '-s', 'no',         # Strand-specific: adjust based on your data\n",
    "        '-t', 'exon',       # Feature type: exon\n",
    "        '-i', 'gene_id',    # Identifier attribute\n",
    "        dedup_bam_file,\n",
    "        gff_file\n",
    "    ], stdout=open(count_file, 'w'))\n",
    "\n",
    "    print(f\"Counts saved to {count_file}\")\n",
    "\n",
    "print(\"Read quantification completed for all BAM files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7fceb4-5957-4136-b51e-c44817312d34",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "<h1 style=\"\n",
    "    background-image: url('https://i.postimg.cc/K87ByXmr/stage5.jpg');\n",
    "    background-size: cover;\n",
    "    background-repeat: no-repeat;\n",
    "    font-family: 'Arial', sans-serif;\n",
    "    font-size: 24px;\n",
    "    color: white;\n",
    "    text-align: center;\n",
    "    border-radius: 15px 50px;\n",
    "    padding: 20px 40px;\n",
    "    margin: 20px 0;\n",
    "    box-shadow: 0px 4px 8px rgba(0, 0, 0, 0.5);\">\n",
    "    <b>Reads Metrics integration with metadata</b>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d1ac6ee-4353-4a84-a8c0-d40e1a4c7462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRR085474</th>\n",
       "      <th>SRR085473</th>\n",
       "      <th>SRR085726</th>\n",
       "      <th>SRR085471</th>\n",
       "      <th>SRR087416</th>\n",
       "      <th>SRR085725</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1BG</th>\n",
       "      <td>48</td>\n",
       "      <td>34</td>\n",
       "      <td>68</td>\n",
       "      <td>53</td>\n",
       "      <td>44</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1BG-AS1</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1CF</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M</th>\n",
       "      <td>1173</td>\n",
       "      <td>438</td>\n",
       "      <td>439</td>\n",
       "      <td>1419</td>\n",
       "      <td>475</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2M-AS1</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2ML1</th>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>28</td>\n",
       "      <td>50</td>\n",
       "      <td>31</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2ML1-AS1</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A2MP1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A3GALT2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A4GALT</th>\n",
       "      <td>42</td>\n",
       "      <td>120</td>\n",
       "      <td>94</td>\n",
       "      <td>32</td>\n",
       "      <td>59</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SRR085474  SRR085473  SRR085726  SRR085471  SRR087416  SRR085725\n",
       "A1BG              48         34         68         53         44         40\n",
       "A1BG-AS1          11          3         17         16         13         10\n",
       "A1CF               0          0          1          1          0          0\n",
       "A2M             1173        438        439       1419        475       1068\n",
       "A2M-AS1           21          1          3         15          8         19\n",
       "A2ML1             55         47         28         50         31         21\n",
       "A2ML1-AS1          0          5          0          0          2          0\n",
       "A2MP1              1          0          3          0          3          1\n",
       "A3GALT2            0          1          1          1          2          0\n",
       "A4GALT            42        120         94         32         59         46"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Set the path to the directory containing the count files\n",
    "count_output_dir = 'read_counts'  # Adjust this path to where your count files are stored\n",
    "\n",
    "# Step 2.1: Combine count files into a single DataFrame\n",
    "count_files = [os.path.join(count_output_dir, f) for f in os.listdir(count_output_dir) if f.endswith('_counts.txt')]\n",
    "\n",
    "# Initialize an empty DataFrame to combine the counts\n",
    "counts_df = pd.DataFrame()\n",
    "\n",
    "# Read each count file and merge them into counts_df\n",
    "for count_file in count_files:\n",
    "    sample_name = os.path.basename(count_file).replace('_counts.txt', '')  # Get sample name from the file name\n",
    "    counts = pd.read_csv(count_file, sep='\\t', index_col=0, header=None, names=[sample_name])  # Read counts\n",
    "\n",
    "    # Join the new count file to the counts_df\n",
    "    if counts_df.empty:\n",
    "        counts_df = counts\n",
    "    else:\n",
    "        counts_df = counts_df.join(counts, how='outer')\n",
    "\n",
    "# Step 2.2: Prepare simplified metadata for DESeq2\n",
    "# Create the simplified metadata DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'SRR_ID': [\"SRR087416\", \"SRR085471\", \"SRR085473\", \"SRR085474\", \"SRR085726\", \"SRR085725\"],  # SRR_IDs corresponding to samples\n",
    "    'Sample': [\n",
    "        \"Alzheimer's whole brain\",\n",
    "        \"Normal brain, temporal lobe\",\n",
    "        \"Alzheimer's brain, temporal lobe\",\n",
    "        \"Normal brain, frontal lobe\",\n",
    "        \"Alzheimer's brain, frontal lobe\",\n",
    "        \"Normal whole brain\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Simplify the metadata to focus on 'SRR_ID' and 'Sample'\n",
    "metadata_simplified = df[['SRR_ID', 'Sample']].copy()\n",
    "\n",
    "# Extract the condition from the 'Sample' column (e.g., 'Alzheimer's brain' -> 'AD')\n",
    "metadata_simplified['condition'] = metadata_simplified['Sample'].apply(lambda x: 'AD' if \"Alzheimer\" in x else 'Normal')\n",
    "\n",
    "# Set the SRR_ID as the index (to match counts columns)\n",
    "metadata_simplified.set_index('SRR_ID', inplace=True)\n",
    "\n",
    "# Ensure that the length of metadata matches the number of columns in counts_df\n",
    "if len(metadata_simplified) != counts_df.shape[1]:\n",
    "    raise ValueError(f\"Metadata length ({len(metadata_simplified)}) does not match count data columns ({counts_df.shape[1]}).\")\n",
    "\n",
    "# Step 2.3: Align metadata with counts_df\n",
    "metadata_simplified = metadata_simplified.loc[counts_df.columns]\n",
    "\n",
    "# Display the final counts_df and metadata DataFrame to ensure proper alignment\n",
    "print(\"Counts DataFrame:\")\n",
    "counts_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9238e05e-c1cc-445c-8fa0-fdc63e507615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simplified Metadata DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SRR085474</th>\n",
       "      <td>Normal brain, frontal lobe</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR085473</th>\n",
       "      <td>Alzheimer's brain, temporal lobe</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR085726</th>\n",
       "      <td>Alzheimer's brain, frontal lobe</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR085471</th>\n",
       "      <td>Normal brain, temporal lobe</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR087416</th>\n",
       "      <td>Alzheimer's whole brain</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR085725</th>\n",
       "      <td>Normal whole brain</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Sample condition\n",
       "SRR085474        Normal brain, frontal lobe    Normal\n",
       "SRR085473  Alzheimer's brain, temporal lobe        AD\n",
       "SRR085726   Alzheimer's brain, frontal lobe        AD\n",
       "SRR085471       Normal brain, temporal lobe    Normal\n",
       "SRR087416           Alzheimer's whole brain        AD\n",
       "SRR085725                Normal whole brain    Normal"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nSimplified Metadata DataFrame:\")\n",
    "metadata_simplified.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "358af735-b4bd-4242-82db-9afeb1c25bfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50042, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9dff6a5e-384d-4485-ae9c-a8637a1ca8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_simplified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "649061f8-9436-4014-b98a-33529164dc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR085474_counts.txt: (50042, 1)\n",
      "SRR085473_counts.txt: (50042, 1)\n",
      "SRR085726_counts.txt: (50042, 1)\n",
      "SRR085471_counts.txt: (50042, 1)\n",
      "SRR087416_counts.txt: (50042, 1)\n",
      "SRR085725_counts.txt: (50042, 1)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of each count file\n",
    "for count_file in count_files:\n",
    "    counts = pd.read_csv(count_file, sep='\\t', index_col=0, header=None)\n",
    "    print(f\"{os.path.basename(count_file)}: {counts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "facbdc6b-3071-4776-b386-97771813894c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['__alignment_not_unique', '__ambiguous', '__no_feature',\n",
      "       '__not_aligned', '__too_low_aQual'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(counts_df.index[counts_df.index.str.startswith('__')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0643fcc-9aea-4372-89d9-6953f340f379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Counts DataFrame shape: (50037, 6)\n"
     ]
    }
   ],
   "source": [
    "counts_df = counts_df[~counts_df.index.str.startswith('__')]\n",
    "print(\"Filtered Counts DataFrame shape:\", counts_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bcddb176-9b68-45da-bb8b-492c18058a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts columns: ['SRR085474', 'SRR085473', 'SRR085726', 'SRR085471', 'SRR087416', 'SRR085725']\n",
      "Metadata index: ['SRR085474', 'SRR085473', 'SRR085726', 'SRR085471', 'SRR087416', 'SRR085725']\n"
     ]
    }
   ],
   "source": [
    "print(\"Counts columns:\", counts_df.columns.tolist())\n",
    "print(\"Metadata index:\", metadata_simplified.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec142a39-e87c-4cac-ab01-09bc37023b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts DataFrame shape after filtering: (50037, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"Counts DataFrame shape after filtering:\", counts_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "baf52d44-c293-4e84-aa09-f3c1df62684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_df.to_csv('cleaned_counts_matrix.csv')\n",
    "metadata_simplified.to_csv('cleaned_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696019cd-8f16-47a0-9157-154c9a26855b",
   "metadata": {},
   "source": [
    "Part One Done:), Please Open `pipeline2.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
