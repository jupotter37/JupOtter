{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40797eb2-fe9e-47aa-81de-071a70a65212",
   "metadata": {},
   "source": [
    "# PCA for Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd2547d-53c2-437b-99ed-af646e473a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler,OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n",
    "pd.set_option('display.max_columns',100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc90f38-9fbe-4da0-9e7b-339a3df08403",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/modified-Data_Cortex_Nuclear.csv\")\n",
    "# Dropping unique IDs\n",
    "df = df.drop(columns=['MouseID'])\n",
    "df.info()\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d088fa97-7227-47c4-a922-7d70031eb732",
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_targets = ['Type of Mouse',\"Treatment\",'Training','class',]\n",
    "for col in possible_targets:\n",
    "    print(f'\\n- {col}:')\n",
    "    print(df[col].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9425e056-f09c-4a77-b268-178e4df2a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "target = \"Training\"\n",
    "X = df.drop(columns = possible_targets)\n",
    "y = df[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a780279b-3cc1-4fb2-98cb-6659a76aff76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "msno.matrix(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b265f5-19fc-41ea-bae8-229bed7d4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in nulls with 0 and verify all nulls are addressed\n",
    "X = X.fillna(0)\n",
    "X.isna().sum().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e22cdad-5ab5-46ea-9a1b-ebf84f477143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "# Fit & transform data.\n",
    "scaled_df = scaler.fit_transform(X)\n",
    "scaled_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d42357c-ba47-4aa1-b471-ebcf17540fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the correlation matrix and plotting\n",
    "corr = scaled_df.corr()\n",
    "sns.heatmap(corr, cmap='coolwarm');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1771113-14ce-4328-93c1-279abf517c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a scatter_matrix with pandas\n",
    "pd.plotting.scatter_matrix(scaled_df, figsize=(40,40));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea599ff5-ba25-42de-a656-1c86637b5be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select features to plot\n",
    "np.random.seed(42)\n",
    "random_features = np.random.choice(scaled_df.columns,3)\n",
    "# plot thee randomly selected features\n",
    "sns.pairplot(scaled_df,  vars=random_features);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d2143e-6f0c-46f7-a066-b12d251ccada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate scaled features with target\n",
    "plot_df = pd.concat([scaled_df, df[target]], axis=1)\n",
    "# Plot with color coding based on target\n",
    "g = sns.pairplot(data=plot_df,  vars=random_features, hue='Training')\n",
    "g.fig.suptitle('Visualizing Raw Features - Colored by Training', y=1.01);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979b3afc-4662-44ca-b6ea-4c45b4da72b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate PCA to make 3 principal components\n",
    "pca = PCA(n_components=3)\n",
    "# Create and define the principal components\n",
    "principal_components = pca.fit_transform(scaled_df)\n",
    "# Preview the results\n",
    "principal_components.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb9a1d1-9a34-4168-91ea-15e10eb1c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance explained by each PC\n",
    "pca.explained_variance_ratio_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef20216-ecc9-40cc-9cc1-3cfa96548173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of variance explained by 3 principal components\n",
    "pca.explained_variance_ratio_.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd6e7f2-d856-422b-b0f3-5f8b83c1a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate principal components with target\n",
    "plot_df_pca = pd.concat([principal_components, df[target]], axis=1)\n",
    "# Plot with color coding based on target\n",
    "g_pca = sns.pairplot(data=plot_df_pca,  vars=principal_components.columns, hue='Training')\n",
    "g_pca.fig.suptitle('Visualizing First 3 PCs - Colored by Training', y=1.01);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befa509b-736c-411b-a76b-3df6b7d0e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "# Make a 3d scatter plot with a PC on each axis and color by the target\n",
    "fig = px.scatter_3d(plot_df_pca, x='pca0',y='pca1',z='pca2', width=800, height=600, color = \"Training\")\n",
    "fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f531b0-c1f2-49b4-8fee-16d97e632e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_scatter3d(fig):\n",
    "    fig.update_traces({'marker':{'size':3}})\n",
    "    fig.show(config={'scrollZoom':False})\n",
    "update_scatter3d(fig)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b67aa1-64b8-494c-80b9-d4e6e5ae462c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See avaialbe templates\n",
    "pio.templates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1fde35-76cc-4355-921e-98e28f1ff8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a 3d scatter plot with a PC on each axis and color by the target\n",
    "# Change template style to plotly_dark\n",
    "fig = px.scatter_3d(plot_df_pca, x='pca0',y='pca1',z='pca2', width=800, height=600, color = \"Training\", template = 'plotly_dark')\n",
    "update_scatter3d(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6936c17-c975-4721-95de-f551f4344fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ca79df9-42d7-4feb-9881-27162011368b",
   "metadata": {},
   "source": [
    "# PCA to Speed up Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ac285-9759-4a91-862e-5edb38478621",
   "metadata": {},
   "source": [
    "## PCA for Supervised Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0541706c-5d99-48de-8dca-e1144222db18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pd.set_option('display.max_columns',200)\n",
    "pd.set_option(\"display.max_info_rows\", 800)\n",
    "pd.set_option('display.max_info_columns',800)\n",
    "\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300bb4f7-ba25-4d6f-aeb3-295b5ea97fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def classification_metrics(y_true, y_pred, label='',\n",
    "                           output_dict=False, figsize=(8,4),\n",
    "                           normalize='true', cmap='Blues',\n",
    "                           colorbar=False):\n",
    "    # Get the classification report\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    ## Print header and report\n",
    "    header = \"-\"*70\n",
    "    print(header, f\" Classification Metrics: {label}\", header, sep='\\n')\n",
    "    print(report)\n",
    "    ## CONFUSION MATRICES SUBPLOTS\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "    # create a confusion matrix  of raw counts\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=None, cmap='gist_gray', colorbar=colorbar,\n",
    "                ax = axes[0],);\n",
    "    axes[0].set_title(\"Raw Counts\")\n",
    "    # create a confusion matrix with the test data\n",
    "    ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=normalize, cmap=cmap, colorbar=colorbar,\n",
    "                ax = axes[1]);\n",
    "    axes[1].set_title(\"Normalized Confusion Matrix\")\n",
    "    # Adjust layout and show figure\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    # Return dictionary of classification_report\n",
    "    if output_dict==True:\n",
    "        report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "        return report_dict\n",
    "\n",
    "\n",
    "def evaluate_classification(model, X_train, y_train, X_test, y_test,\n",
    "                         figsize=(6,4), normalize='true', output_dict = False,\n",
    "                            cmap_train='Blues', cmap_test=\"Reds\",colorbar=False):\n",
    "    # Get predictions for training data\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    # Call the helper function to obtain regression metrics for training data\n",
    "    results_train = classification_metrics(y_train, y_train_pred, #verbose = verbose,\n",
    "                                     output_dict=True, figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_train,\n",
    "                                     label='Training Data')\n",
    "    print()\n",
    "    # Get predictions for test data\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    # Call the helper function to obtain regression metrics for test data\n",
    "    results_test = classification_metrics(y_test, y_test_pred, #verbose = verbose,\n",
    "                                  output_dict=True,figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_test,\n",
    "                                    label='Test Data' )\n",
    "    if output_dict == True:\n",
    "        # Store results in a dataframe if ouput_frame is True\n",
    "        results_dict = {'train':results_train,\n",
    "                    'test': results_test}\n",
    "        return results_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893ff6b3-c173-4ad3-ac2e-0aee885c32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "df = pd.read_csv('Data/pd_speech_features.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a08d4-3812-4215-9da5-01b85142587f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048adb79-3d68-40c2-b035-7431e36112b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689762bc-7f34-406e-9a1c-98e4fd56506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and cols to drop\n",
    "target_col = 'class'\n",
    "drop_cols = ['id']\n",
    "# Define X and y\n",
    "y = df[target_col].copy()\n",
    "X = df.drop(columns=[target_col,*drop_cols]).copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f127df-1b1d-4249-82d7-3b11d6f7c5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, random_state=321)\n",
    "X_train.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765b383-f06f-493b-b6f2-9308cb726de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "# Fit & transform data.\n",
    "X_train_tf = scaler.fit_transform(X_train)\n",
    "X_test_tf = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249b41f8-3458-474d-800a-ff467c2bb076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for class balance of target\n",
    "y_train.value_counts(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2947769-e41a-4d40-8657-6149c61c32a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE,SMOTENC\n",
    "smote = SMOTE()\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train_tf, y_train)\n",
    "y_train_sm.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa6bd86-40e2-422d-bd77-10b3da2d401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datetime library\n",
    "import datetime as dt\n",
    "\n",
    "# Record the start time\n",
    "start = dt.datetime.now()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "clf.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# Record the end time and calc duration\n",
    "end = dt.datetime.now()\n",
    "dur_baseline = end-start\n",
    "\n",
    "evaluate_classification(clf, X_train_sm,y_train_sm, X_test_tf, y_test)\n",
    "print(f'Training time was: {dur_baseline}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a790441f-0e9f-448a-ab10-ed6094a0f80a",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaadb934-8a60-43f5-93b8-7f3231d3d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate & fit data using PCA\n",
    "pca = PCA(n_components=3)\n",
    "X_train_pca = pca.fit_transform(X_train_sm)\n",
    "X_test_pca = pca.transform(X_test_tf)\n",
    "X_train_pca.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098b02f1-bb78-46d5-9a66-500c57c6b0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the start time\n",
    "start = dt.datetime.now()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_pca, y_train_sm)\n",
    "\n",
    "# Record the end time and calc duration\n",
    "end = dt.datetime.now()\n",
    "dur_pca = end-start\n",
    "\n",
    "evaluate_classification(clf, X_train_pca,y_train_sm, X_test_pca, y_test)\n",
    "print(f'Training time was: {dur_pca}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9108c2-229c-4141-b891-4e61eb0e1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare speeds before and after PCA\n",
    "compare_speed = dur_baseline/dur_pca\n",
    "print(f\"Using PCs was {compare_speed:.2f} times faster!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb38545-34a3-434b-b9fc-2d352fc7d3f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e48a1-2336-425f-8d4a-9ad3e42376e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit PCA\n",
    "pca = PCA()\n",
    "pca.fit(X_train_sm, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb6d093-9074-4e39-8677-8956e4173d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine how much variance is explained by each PC\n",
    "explained = pd.Series(pca.explained_variance_ratio_, name='Explained Variance Ratio')\n",
    "explained\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a48fb60-13cb-4514-b603-2a248fe71716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the cumulative sum of the percentage of explained variance for each component and those before it.\n",
    "ax = explained.cumsum().plot(marker='.')\n",
    "# add a line to mark .9 (or 90%) variance explained\n",
    "ax.axhline(.9, color='k');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e144d01-4bba-4ff0-a0b4-d044c4bf77a9",
   "metadata": {},
   "source": [
    "### Specifying the Explained Variance\r\n",
    "Rather than specifying the number of components to return, an alternate method is to specify the minimum proportion of explained variance you are willing to accept. PCA will automatically reduce the number of components just enough to meet your specification.\r\n",
    "\r\n",
    "To specify the proportion of variance, give the n_components argument a float between 0 and 1, and it will return the number of components required to explain the given variance.\r\n",
    "\r\n",
    "The code below is an example of how to ensure that enough components are returned to explain 85% of the variance. Instead of using an integer in the n_components argument to designate the number of components, we use a decimal value to indicate the amount of variance to be explained. PCA() will then automatically use enough principal components to meet this level of explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d1fcb7-1c3e-45d7-8230-8ef933ed501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PCA to address 85% of the variance\n",
    "pca85 = PCA(n_components=.85)\n",
    "# fit and transform on training data\n",
    "X_train_pca85 = pca85.fit_transform(X_train_sm)\n",
    "# transform test data\n",
    "X_test_pca85 = pca85.transform(X_test_tf)\n",
    "# obtain the number of PCs used\n",
    "pca85.n_components_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9dbeb-a30f-4b12-ba68-44254d9203ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the start time\n",
    "start = dt.datetime.now()\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train_pca85, y_train_sm)\n",
    "\n",
    "# Record the end time and calc duration\n",
    "end = dt.datetime.now()\n",
    "dur_pca_85 = end-start\n",
    "\n",
    "evaluate_classification(clf, X_train_pca85,y_train_sm, X_test_pca85, y_test)\n",
    "print(f'Training time was: {dur_pca_85}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5ff3b1-5119-416c-b749-cd50952aed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_speed = dur_baseline/dur_pca_85\n",
    "print(f\"Using PC's with .85 was {compare_speed:.2f} times faster!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72c7fb4-2175-485e-892a-0b5cbd1dcd66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4aa044fd-ecf2-49d8-b123-8b7ac42c267d",
   "metadata": {},
   "source": [
    "# Feature Engineering: Overloaded Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6516beb5-48ea-49d0-96a3-8d2765a7a098",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vReZBM5OC6GLYbacisp_ToNiu3CLWxqPXw7mWBsdRjnYOFLWNufdQ4qd8u5qTzUF2_sBUAMEi5cgy1U/pub?gid=1040198428&single=true&output=csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267fcad8-7e4b-4fe7-b165-58862839ba2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summing Features:\n",
    "df['TotalFamily'] = df['SibSp'] + df['Parch'] \n",
    "df = df.drop(['SibSp', 'Parch'], axis=1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2fb86-71c7-4a1a-a7be-dd582640e821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating Features:\n",
    "\n",
    "df['Age'] = df['Age'].round(-1)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e7203-869b-486b-84f7-b3898d00870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GenderAge'] = df['Sex'] + df['Age'].astype('string')\n",
    "df.drop(columns=['Sex','Age'], inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9654e-b0c8-4870-b13f-e1755605d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squaring and Multiplying Features\n",
    "\n",
    "df['NormedFare'] = df['Fare'] * df['Pclass']**2\n",
    "df.drop(columns='Fare', inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe87a25-fe91-4647-9612-972760874cfa",
   "metadata": {},
   "source": [
    "# Feature Engineering: Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b57083-7854-4893-b92b-f2f0df421ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vReZBM5OC6GLYbacisp_ToNiu3CLWxqPXw7mWBsdRjnYOFLWNufdQ4qd8u5qTzUF2_sBUAMEi5cgy1U/pub?gid=1040198428&single=true&output=csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34034b8b-67e0-4852-9ede-4e0eb4cb864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating Features: Strings\n",
    "\n",
    "# create 2 new columns, FirstName and LastName by splitting the Name column\n",
    "df[['LastName','FirstName']] = df['Name'].str.split(',', expand=True)\n",
    "# drop the 'Name' column\n",
    "df.drop('Name', axis=1, inplace=True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c92f50-7577-45cf-baf8-a32550ce3e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean-up\n",
    "\n",
    "df.loc[0,'FirstName']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211fad1f-729e-46b9-9ce3-b9e17b4491e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FirstName'] = df['FirstName'].str.strip()\n",
    "df.loc[0, 'FirstName']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd39bbd9-309f-4fc1-b063-065b84008f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining Strings\n",
    "\n",
    "df['Name'] = df['FirstName'] + ' ' + df['LastName']\n",
    "df.drop(columns=['LastName','FirstName'], inplace= True)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8282ecf-450e-4cad-b1fc-6df559e9a0ef",
   "metadata": {},
   "source": [
    "# Feature Engineering: Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40012c6f-e74e-4a19-9224-9d1bd14ae7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df2 = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vSrgrUnz8mdosU-_k0aECouymqwds_mlaHpYlXzRtf7MBJ4N1r1inCfSDebaXwTVfLtH133EhwKf3mi/pub?gid=394699239&single=true&output=csv',                  usecols=['date','price','bedrooms','bathrooms'])\n",
    "df2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6591632-e15f-4946-bba6-3c0666288246",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['date'] = pd.to_datetime(df2['date'])\n",
    "df2.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590db5d-eaa6-4f1d-826c-e4f33d330e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['year'] = df2['date'].dt.year\n",
    "df2['month (numeric)'] = df2['date'].dt.month\n",
    "df2['month (name)'] = df2['date'].dt.month_name()\n",
    "df2['day of month'] = df2['date'].dt.day\n",
    "df2['day of week (numeric)'] = df2['date'].dt.weekday\n",
    "df2['day of week (name)'] = df2['date'].dt.day_name()\n",
    "df2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd76a4d0-a8c9-4f71-a328-16fb545445f0",
   "metadata": {},
   "source": [
    "# Feature Engineering: Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce585f-d8d4-4ddb-a61e-ca66046935f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vReZBM5OC6GLYbacisp_ToNiu3CLWxqPXw7mWBsdRjnYOFLWNufdQ4qd8u5qTzUF2_sBUAMEi5cgy1U/pub?gid=1040198428&single=true&output=csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d414ac08-0233-46c8-b65f-25494ebd4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the median fare price\n",
    "median_fare = df['Fare'].median()\n",
    "# define a function that returns 'Expensive' or 'Cheap'\n",
    "def bin_fare(fare):\n",
    "    if fare > median_fare:    \n",
    "        return 'Expensive'  \n",
    "    else:    \n",
    "        return 'Cheap'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d1f1f6-28df-4623-826a-e100bc1c5de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply bin_fare() function to each item in the 'Fare' column\n",
    "df['Fare'] = df['Fare'].apply(bin_fare)\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4707df-d5f2-4f4e-a868-41ae45915d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age'] = df['Age'].apply(lambda x: 'elderly' if x > 30 else 'young')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f89bb76-37fa-4601-8755-3c7bc765f992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a5bc0f4-69ad-4609-ac62-6bea937a26f8",
   "metadata": {},
   "source": [
    "# Feature Engineering 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532e0a28-19d0-41ff-aebe-5e411099f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Preprocessing tools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Setting options\n",
    "n=800\n",
    "pd.set_option('display.max_columns',n)\n",
    "pd.set_option(\"display.max_info_rows\", n)\n",
    "pd.set_option('display.max_info_columns',n)\n",
    "from sklearn import set_config\n",
    "set_config(transform_output='pandas')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258673d0-875c-441d-83a6-7df2623a5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "def classification_metrics(y_true, y_pred, label=\"\",\n",
    "                           output_dict=False, figsize=(8,4),\n",
    "                           normalize='true', cmap='Blues',\n",
    "                           colorbar=False):\n",
    "  # Get the classification report\n",
    "  report = classification_report(y_true, y_pred)\n",
    "  ## Print header and report\n",
    "  header = \"-\"*70\n",
    "  print(header, f\" Classification Metrics: {label}\", header, sep='\\n')\n",
    "  print(report)\n",
    "  ## CONFUSION MATRICES SUBPLOTS\n",
    "  fig, axes = plt.subplots(ncols=2, figsize=figsize)\n",
    "  # create a confusion matrix  of raw counts\n",
    "  ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=None, cmap='gist_gray', colorbar=colorbar,\n",
    "                ax = axes[0],);\n",
    "  axes[0].set_title(\"Raw Counts\")\n",
    "  # create a confusion matrix with the test data\n",
    "  ConfusionMatrixDisplay.from_predictions(y_true, y_pred,\n",
    "                normalize=normalize, cmap=cmap, colorbar=colorbar,\n",
    "                ax = axes[1]);\n",
    "  axes[1].set_title(\"Normalized Confusion Matrix\")\n",
    "  # Adjust layout and show figure\n",
    "  fig.tight_layout()\n",
    "  plt.show()\n",
    "  # Return dictionary of classification_report\n",
    "  if output_dict==True:\n",
    "    report_dict = classification_report(y_true, y_pred, output_dict=True)\n",
    "    return report_dict\n",
    "    \n",
    "    \n",
    "    \n",
    "def evaluate_classification(model, X_train, y_train, X_test, y_test,\n",
    "                         figsize=(6,4), normalize='true', output_dict = False,\n",
    "                            cmap_train='Blues', cmap_test=\"Reds\",colorbar=False):\n",
    "  # Get predictions for training data\n",
    "  y_train_pred = model.predict(X_train)\n",
    "  # Call the helper function to obtain regression metrics for training data\n",
    "  results_train = classification_metrics(y_train, y_train_pred, #verbose = verbose,\n",
    "                                     output_dict=True, figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_train,\n",
    "                                     label='Training Data')\n",
    "  print()\n",
    "  # Get predictions for test data\n",
    "  y_test_pred = model.predict(X_test)\n",
    "  # Call the helper function to obtain regression metrics for test data\n",
    "  results_test = classification_metrics(y_test, y_test_pred, #verbose = verbose,\n",
    "                                  output_dict=True,figsize=figsize,\n",
    "                                         colorbar=colorbar, cmap=cmap_test,\n",
    "                                    label='Test Data' )\n",
    "  if output_dict == True:\n",
    "    # Store results in a dataframe if ouput_frame is True\n",
    "    results_dict = {'train':results_train,\n",
    "                    'test': results_test}\n",
    "    return results_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95720d2-f923-4438-b75a-a6a082da226f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df = pd.read_csv('pd_speech_features.csv')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c09840-2f7d-4dbf-afb6-5e4cd4406889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7598430-7564-42cf-9a91-4712f6828091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "df.isna().sum().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ebe021-60cd-42b0-82ce-64cb23bf1990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the unique dtypes\n",
    "df.dtypes.unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6d821e-8ffa-43b6-ad93-feb03e15b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target\n",
    "target_col = 'class'\n",
    "\n",
    "# Make list of columns to drop. In this case just the id column for now\n",
    "drop_cols = ['id']\n",
    "\n",
    "# Define X and y\n",
    "y = df[target_col].copy()\n",
    "X = df.drop(columns=[target_col,*drop_cols]).copy()\n",
    "\n",
    "# Train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y, random_state=321)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c73a6a-4fbd-416d-a024-67846d949503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled=scaler.transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6938cd1a-acbe-4b74-af69-6ae321fbd322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the balance of the target\n",
    "y.value_counts(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d39b0c-ee81-413e-b4d2-4f25dea7923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 42)\n",
    "X_train_sm,y_train_sm = smote.fit_resample(X_train_scaled, y_train)\n",
    "y_train_sm.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168a5153-1d93-4170-ad4d-563329b6ae5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a default random forest with a random state for reproductibility\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit on the training data\n",
    "rf_clf.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# Evaluate with the custom function\n",
    "evaluate_classification(rf_clf, X_train_sm,y_train_sm, X_test_scaled, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9b4af-fa0d-436e-8b71-c16410e724dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a correlation heatmap of all features\n",
    "corr = X_train_sm.corr()\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(corr,cmap='coolwarm');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbe88b9-4930-41ad-99c7-cf204175617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collinearity import SelectNonCollinear\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb07d83-bb32-4975-a7c8-96a0131f5d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the selector, indicate theshold for r, also include the appropriate scoring metric for the task\n",
    "selector = SelectNonCollinear(correlation_threshold = 0.75, scoring = f_classif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe68524-621d-4260-a8c4-d91f79d6635b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit on the training data, use .values\n",
    "selector.fit(X_train_sm.values, y_train_sm.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554fff6e-7aa9-4790-b2c5-8d805fa718f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mask for filtering\n",
    "non_collinear = selector.get_support()\n",
    "non_collinear[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d01096-2dd4-40bb-a529-236f32201867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many features are below the theshold\n",
    "non_collinear.count(True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da3acd5-0ef1-4aa7-93a6-1d4cce23ee6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many features are above the theshold\n",
    "non_collinear.count(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b29b1e5-8a2a-48ac-aefe-7e2f556d3c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the T/F a series with the column names as the index\n",
    "non_collinear_series = pd.Series(selector.get_support(), index=X_train_sm.columns)\n",
    "non_collinear_series\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d6b24b-17aa-4735-a387-710ca4e6508a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter training data\n",
    "training_data_to_keep = X_train_sm.values[:, non_collinear]\n",
    "# Filter column names\n",
    "columns = np.array(X_train_sm.columns)[non_collinear]\n",
    "# Make traing data into a dataframe\n",
    "X_train_no_corr = pd.DataFrame(training_data_to_keep, columns = columns)\n",
    "\n",
    "# Filter testing data\n",
    "test_data_to_keep = X_test_scaled.values[:, non_collinear]\n",
    "# Make test data into a dataframe\n",
    "X_test_no_corr = pd.DataFrame(test_data_to_keep, columns = columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e3932f-5007-4e7e-a4b6-925fe31bed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make correlation heatmap for non_collinear features\n",
    "corr = no_corr_df.corr()\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(corr,cmap='coolwarm');\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd06142-2bb6-41d5-9a10-dcf1dc1cd170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the performance\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train_no_corr, y_train_sm)\n",
    "evaluate_classification(rf_clf, X_train_no_corr, y_train_sm, X_test_no_corr, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43a4021-c190-40bd-98f4-834fb559048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0d0e5e-d32c-45bd-b006-9fb4c0a3d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for constant-features\n",
    "selector = VarianceThreshold(threshold=0.00)\n",
    "selector.fit(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419024eb-a19d-44dc-b479-4071f77cf718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get support returns true/false for keeping features\n",
    "keep_features = selector.get_support()\n",
    "keep_features[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d283f914-ca97-48b9-982e-25a952af28d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features to keep (non-constant features)\n",
    "keep_features.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15426b-3927-4b5f-8ccd-aca8c0ff8094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for quasi-constant-features\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "selector.fit(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8debde59-24c7-401d-972b-49c74f86c1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get support returns true/false for keeping features\n",
    "keep_features = selector.get_support()\n",
    "keep_features[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4c8741-ecbd-4022-ba26-ffa6e53705ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of features to keep (non-quasi-constant features)\n",
    "keep_features.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1731689-3de3-41c3-895e-cc3d03d5e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter based on variance\n",
    "X_train_var = X_train.loc[:,keep_features]\n",
    "X_test_var = X_test.loc[:,keep_features]\n",
    "X_train_var\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393fa02-9d48-4b4f-bdec-7d12089c3800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use standardscaler to Scale\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train_var)\n",
    "X_train_var_scaled = scaler.transform(X_train_var)\n",
    "X_test_var_scaled = standard=scaler.transform(X_test_var)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf2e1a-5e99-4640-93c8-836a326ca621",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 42)\n",
    "X_train_var_scaled_sm, y_train_sm = smote.fit_resample(X_train_var_scaled, y_train)\n",
    "y_train_sm.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f46b35-3f95-4ead-bd27-84f33ca13d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the performance\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train_var_scaled_sm, y_train_sm)\n",
    "evaluate_classification(rf_clf, X_train_var_scaled_sm, y_train_sm, X_test_var_scaled, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71c7268-a9f1-497d-b750-b666ba238824",
   "metadata": {},
   "source": [
    "# Feature Engineering 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3876e6-1c40-45ba-bbdd-09bf762532a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "# Instantiate a lostistic regression model\n",
    "log_reg = LogisticRegression(C=1e12)\n",
    "# Define the selector object using the model. Use default threshold (mean)\n",
    "selector = SelectFromModel(log_reg)\n",
    "# Fit the selector on the training data\n",
    "selector.fit(X_train_sm ,y_train_sm)\n",
    "selector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecede2e-a044-49a8-9599-cc516af63b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain threshold used\n",
    "selector.threshold_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68c1ead-005d-4758-a0f6-e1c40b2dfecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the shape of the output for coefficents?\n",
    "selector.estimator_.coef_.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c531eb-b355-4321-9ae0-6d5d9c73d79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View first coefficient\n",
    "selector.estimator_.coef_[0,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4631206f-158a-434f-bd13-59663c88ef1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce this array to one dimension\n",
    "flattened = selector.estimator_.coef_.flatten() \n",
    "flattened.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34719cb7-3257-4fb0-b8d2-3278b2a3146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access first value of 1d array\n",
    "flattened[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab62d4a7-d60a-4166-9a67-1e836f5a4ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the coefs a series with the column names as the index\n",
    "coeffs = pd.Series(flattened, index=X_train_sm.columns)\n",
    "coeffs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe5e520-1766-453a-a517-d75649dc710e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .get_support returns an array of T/F whether it is above threshold\n",
    "above_threshold = selector.get_support()\n",
    "above_threshold[0:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387dcf0-f1cd-436d-be4a-9cd3f9b04180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the coeffs series to include only those above the threshold\n",
    "coeffs[above_threshold]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc70072-16cc-4e35-a921-59b37c7573d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .get_support returns an array of T/F whether it is above threshold\n",
    "above_threshold = selector.get_support()\n",
    "# Only include the features that are above the threshold in X train and X test\n",
    "X_train_sel = X_train_sm.loc[:,above_threshold]\n",
    "X_test_sel = X_test_scaled.loc[:,above_threshold]\n",
    "X_train_sel.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c70d951-6392-4d4c-b673-0fb39b1644d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate default random forest\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "# Fit on selected featuers\n",
    "rf_clf.fit(X_train_sel, y_train_sm)\n",
    "# Evaluate with custom function\n",
    "evaluate_classification(rf_clf, X_train_sel, y_train_sm, X_test_sel, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab60477-d73e-4eea-bafb-661304287920",
   "metadata": {},
   "source": [
    "### Example Wrapper Method-Using  Forward Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aee1bd1-a5ac-45cd-b57b-08db68387277",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3699b752-8107-4657-8679-beb9981dbd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "dt = DecisionTreeClassifier(random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6728263-99b6-46d2-bbf6-68164470d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the SequentialFeatureSelector\n",
    "sk_sfs = SequentialFeatureSelector(dt, n_features_to_select=50,\n",
    "                                direction = 'forward', cv=2,\n",
    "                                 n_jobs=-1)\n",
    "sk_sfs.fit(X_train_sel,y_train_sm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dae6dc6-ee0e-4bdf-a373-ec6380716e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview array of T/F for selected (or not) features\n",
    "sk_sfs.support_[0:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7538525-23d3-4b2d-93e4-8e1b42bb55d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .support_ returns an array of T/F whether it is above threshold\n",
    "features_to_keep = sk_sfs.support_\n",
    "# Only include the features selected\n",
    "X_train_50 = X_train_sel.loc[:,features_to_keep]\n",
    "X_test_50 = X_test_sel.loc[:,features_to_keep]\n",
    "X_train_50.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845ed728-660d-4507-9e47-b6087ba2f241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate default random forest\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "# Fit on 50 selected featuers\n",
    "rf_clf.fit(X_train_50, y_train_sm)\n",
    "# Evaluate with custom function\n",
    "evaluate_classification(rf_clf, X_train_50, y_train_sm, X_test_50, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3b799b-d6f1-45fb-8159-5cc2de86e1be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb7d172-ab1b-4ebf-bfdd-36d4f8307a65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36bfa95-b98a-45e0-951c-a842bc752afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63982088-f7ac-4e52-b044-d87d6ca66921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f89d3f1-cbff-4edc-915a-076ef056edfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bba418-2447-4d1d-9b39-df3f77c2f913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc283a42-642a-42d7-b517-1481a3035510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec1a686-0aaa-4337-b0fe-36770dde23cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa8401-6f36-42f0-8369-957be6af17ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4dee46-8edf-454b-b93c-d147eb0d78f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22ddf06-c3e9-4ed4-b215-0967d9c406f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3120d1e1-192d-4a50-a686-24fc02d0bb86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
