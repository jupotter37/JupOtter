{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# data wrangling\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, date, timedelta\n\n# data visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n# offline interactive visualization\nfrom plotly.offline import plot, iplot, init_notebook_mode\ninit_notebook_mode(connected=True)\n\n# regression\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nimport statsmodels.graphics.api as smg\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Worldometer data\n# ================\n\nworldometer_data = pd.read_csv('../input/corona-virus-report/worldometer_data.csv')\n\n# Replace missing values '' with NAN and then 0\nworldometer_data = worldometer_data.replace('', np.nan).fillna(0)\n\n# Correcting Country name \nworldometer_data['Country/Region'].replace({'USA':'US', 'UAE':'United Arab Emirates', 'S. Korea':'South Korea', \\\n                                           'UK':'United Kingdom'}, inplace=True)\n\n# Grouped by day, country\n# =======================\n\nfull_grouped = pd.read_csv('../input/corona-virus-report/full_grouped.csv')\n\n# Merge in population data\nfull_grouped = full_grouped.merge(worldometer_data[['Country/Region', 'Population']], how='left', on='Country/Region')\n\nfull_grouped['Date'] = pd.to_datetime(full_grouped['Date'], format = '%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_= plt.plot(full_grouped[full_grouped['Country/Region']=='New Zealand']['Date'],full_grouped[full_grouped['Country/Region']=='New Zealand']['Active'])\nplt.show()\nprint(full_grouped[(full_grouped['Country/Region']=='New Zealand') &(full_grouped['Date']=='2020-07-14')]['Active'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_country(country, date): \n    temp = full_grouped[full_grouped['Country/Region']==country]\n    temp['recent_wave'] = np.where(temp['Date'] >= date,1,0)\n\n    fig = px.line(temp, x='Date', y='Confirmed', color='recent_wave', \\\n                  title = 'Infections for ' + str(country), height=600)      \n    fig.show()\n    \n    fig = px.line(temp, x='Date', y='Recovered', color='recent_wave', \\\n              title = 'Recovered Patients ' + str(country), height=600)      \n    fig.show()\n    \n    return country, date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country, date = plot_country('New Zealand', '2020-07-14')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calibrate model\n\ndef estimate_sir_param(country, date):\n    \n    # Assume everyone is at risk\n    # Identify the maximum population and the latest date in the time series for the country\n    population  = full_grouped[full_grouped['Country/Region']==country][\"Population\"].max()\n    latest_date = full_grouped[full_grouped['Country/Region']==country][\"Date\"].max()\n    \n    time_series_length = (latest_date - datetime.strptime(date,'%Y-%m-%d')).days + 1\n\n    temp = full_grouped[full_grouped['Country/Region']==country]\n    temp['recent_wave'] = np.where(temp['Date'] >= date,1,0)\n    \n    # Initialize Numpy arrays for total population (the maximum population), \n    # susceptible population (empty), and change in time (i.e., 1 day)\n    N  = np.array([population] * time_series_length)\n    S  = np.array([])\n    dt = np.array([1] * (time_series_length-1))\n\n    # Apply the condition N = S+I+(R+D)\n    # Filter time-series to those of the recent wave\n    I = np.array(temp[temp['recent_wave']==1]['Active'])\n    R = np.array(temp[temp['recent_wave']==1]['Recovered'])\n    D = np.array(temp[temp['recent_wave']==1]['Deaths'])\n\n    # R includes both Recovered and Death for brevity\n    S = N - I - (R + D)\n\n    ## 1. Estimate beta\n    \n    x = (S * I) / N\n    \n    # Copy all elements except the last\n    x = x[:-1].copy()\n    \n    # Take the first difference\n    dS = np.diff(S)\n    y = dS/dt\n\n    # Fit into a linear regression\n    results = sm.OLS(y, x, missing='drop').fit()\n    beta = results.params\n    print(results.summary())\n    print('\\n')\n    print('*'*80)\n    print(f\"Transmission rate or Beta is: {beta}\")\n    print('*'*80)\n    \n    ## 2. Estimate gamma\n    \n    x = I[:-1].copy()\n    dR = np.diff(R+D)\n    y = dR/dt\n\n    results = sm.OLS(endog=y, exog=x, missing='drop').fit()\n    gamma = results.params\n    print (results.summary())\n    print('\\n')\n    print('*'*80)\n    print(f\"Recovery (and Mortality) rate or Gamma is: {gamma}\")\n    print('*'*80)\n    \n    #3. Calculate R\n\n    print('\\n')\n    print('*'*80)\n    print(f\"Reproduction number or R is: {-beta/gamma}\")\n    print('*'*80)\n    \n    return -beta.astype('float'), gamma.astype('float'), datetime.strptime(date,'%Y-%m-%d').date()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"beta, gamma, date = estimate_sir_param('New Zealand', date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sir_model(I0=0.01, beta=0.6, gamma=0.1, days=365, date=date.today()):\n    \"\"\"\n    Function will take in initial state for infected population,\n    Transmission rate (beta) and recovery rate(gamma) as input.\n    \n    The function returns the maximum percentage of infectious population,\n    the number of days to reach the maximum (inflection point),\n    the maximum percentage of population infected,\n    the number of days to reach 80% of the maximum percentage of population infected.\n    \n    \"\"\"\n    ## Initialize model parameters\n    N = 1          #Total population in percentage, i.e., 1 = 100%\n    I = I0         #Initial state of I default value 1% of population, i.e., I0 = 0.01\n    S = N - I      #Initial state of S\n    R = 0          #Initial State of R\n    C = I          #Initial State of Total Cases\n    beta  = beta   #Transmission Rate\n    gamma = gamma  #Recovery Rate\n\n    ## Initialize empty lists\n    inf  = []       # List of Infectious population for each day\n    day  = []       # Time period in day\n    suc  = []       # List of Susceptible population for each day\n    rec  = []       # List of Recovered population for each day\n    conf = []       # List of Total Cases population for each day\n    \n    ## Project into the future\n    for i in range(days):\n        day.append(i)\n        inf.append(I)\n        suc.append(S)\n        rec.append(R)\n        conf.append(C)\n\n        new_inf= I*S*beta/N            #New infections equation (1)   \n        new_rec= I*gamma               #New Recoveries equation (2)\n        \n        I=I+new_inf-new_rec            #Total infectious population for next day\n        S=max(min(S - new_inf, N), 0)  #Total infectious population for next day\n        R=min(R + new_rec, N)          #Total recovered population for next day\n        \n        C=C+new_inf                    #Total confirmed cases for next day\n\n    ## Pinpoint important milestones    \n    max_inf = round(np.array(inf).max()*100,2)        #Peak infectious population in percentage\n    inflection_day = inf.index(np.array(inf).max())   #Peak infectious population in days\n    max_conf = round(np.array(conf).max()*100,2)      #Overall infected population in percentage\n    plateau_day = np.array(np.where(np.array(conf) >= 0.8*np.array(conf).max())).min()   #Peak infectious population in days\n        \n    print(f\"Maximum Infectious population at a time :{max_inf}%\")\n    print(f\"Number of Days to Reach Maximum Infectious Population (Inflection Point):{inflection_day} days or {date + timedelta(days=inflection_day)}\")\n    print(f\"Total Infected population :{max_conf}%\")\n    print(f\"Number of Days to Reach 80% of the Projected Confirmed Cases (Plateau Point):{plateau_day} days or {date + timedelta(days=plateau_day.item())}\")\n\n    ## Visualize the model outputs\n    sns.set(style=\"darkgrid\")\n    plt.figure(figsize=(10,6))\n    plt.title(f\"SIR Model: R = {round(beta/gamma,2)}\", fontsize=18)\n    sns.lineplot(day,inf, label=\"Infectious\")\n    sns.lineplot(day,suc,label=\"Succeptible\")\n    sns.lineplot(day,rec, label=\"Recovered\")\n    \n    plt.legend()\n    plt.xlabel(\"Time (in days)\")\n    plt.ylabel(\"Fraction of Population\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sir_model(I0=0.000006, beta = beta.item(), gamma = gamma.item(), days=730, date = date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1: We can see that since New Zealand has a really good medical treatment system, the recovery rate is really high\n    so we can reach the inflection point in day 1. We also reach the plateau point really fast at 2020-08-25, which is 42 days\n    after the starting point.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Q2**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import and wrangle with stock_ret dataset\nnz50 = pd.read_csv('../input/nz50data/NZ50.csv')\nnz50['Date'] = pd.to_datetime(nz50['Date'])\nnz50.tail()\n\n# Calculate daily Total Returns for the NZ50 (excluding dividends)\nnz50['day_return'] = nz50['Close']/nz50['Close'].shift(1) - 1\n\nnz50 = nz50.loc[:].copy()\nnz50['cum_return'] = np.cumprod(nz50['day_return']+1)\nnz50.info()\nnz50.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the negative runs in the NZ50 (i.e., from one peak to another)\n# Initialize an empty list for cumulative returns from one peak to another \nneg_run = []\n\n# Store the previous maximum cumulative return\nmax_cum_nz50_now = nz50['cum_return'].iloc[0]   \n\n# enumerate() method adds counter (t) to an iterable (nz50['day_return']) and \n# returns a tuple (t, stock_ret['day_return'])\nfor t, val in enumerate(nz50['day_return']):\n    \n    # First return in the daily return series\n    if t == 0:\n        \n        # If daily return is negative\n        if val < 0:\n            \n            # Append the negative return to neg_run list\n            neg_run.append(val)\n            \n        else:\n            \n            # Append a zero to neg_run list\n            neg_run.append(0)\n            \n    # Not the first return in the daily return series\n    else:\n        \n        # If the cumulative return at time t is less than the previous maximum cumulative return\n        # i.e., the previous all time high\n        if nz50['cum_return'].iloc[t] < max_cum_nz50_now:\n            \n            # cumulate/compound the return at time t with the return at time t-1\n            # i.e., tally the loss\n            neg_run.append((1 + neg_run[t-1])*(1 + val) - 1) \n            \n        # If the cumulative return at time t is more than the previous maximum cumulative return\n        else:\n            \n            # stop the loss tally and append a zero to the negative run list\n            neg_run.append(0)                                \n            \n            # replace the previous all time high with the new high\n            max_cum_nz50_now = nz50['cum_return'].iloc[t]\n\n# Add the variable to the dataframe stock_ret\nnz50['neg_run'] = neg_run","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the nz50 time series\nsns.lineplot(x='Date', y='Close', data=nz50, color='red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the peak-to-peak negative run\nsns.lineplot(x='Date', y='neg_run', data=nz50, color='red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Recap that a neg_run is the peak-to-peak run \n# Identify and label each neg_run sequentially (e.g., the 10th neg_run is tagged as 10)\n# The label serves as the groupby variable to examine the characteristics of each run\n\n# Initialize label value\nlabel = 1\n\n# Initialize the indicator value of whether stock_ret['neg_run'] (or loss tally) is within a peak-to-peak run\nwithin_negative_run = False\n\n# Initialize an empty list for negative run number\nneg_run_num = []\n\n# Identify and label each cycle of negative run, which ends with a zero\n# The cumulative return (or loss tally) during the cycle is negative\nfor i in nz50['neg_run']:\n    \n    # Loss tally is negative\n    if i < 0:\n        \n        # Append the label to neg_run_num list\n        neg_run_num.append(label)\n        \n        # Switch the state for within_negative_run\n        within_negative_run = True\n        \n    # Loss tally is zero - negative run ends\n    else:\n        \n        # Append a zero to neg_run_num list\n        neg_run_num.append(0)\n        \n        # Increment label value by 1 if within_negative_run is True\n        # This happens only for a 'new' cycle of negative run\n        # The label doesn't increment by 1 in market run-up after the exit from a negative run\n        # i.e., reaching new all-time highs after exiting from a cycle of negative run\n        if within_negative_run:\n            label += 1\n            within_negative_run = False\n            \nnz50['neg_run_num'] = neg_run_num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Identify and label each peak (previous all time high) to trough (the lowest point) within each peak-to-peak run\n# This is also known as the maximum drawdown\n# The integer label runs sequentially (e.g., the 10th peak-to-trough is tagged as 10)\n\n# Initialize the label value\nlabel = 1\n\n# Initialize the search status of whether the lowest point within a negative run has been discovered\nis_neg_run_min = False\n\n# Initialize an empty list for peak-to-trough run number\npeak_trough_num = []\n\nfor t, val in enumerate(nz50['neg_run_num']):\n    \n    # Identify the lowest point (i.e., cumulated returns) within a negative run\n    trough = min(nz50[nz50['neg_run_num']==val]['neg_run'])\n    \n    # Recap that if the cumulative return at time t is more than the previous maximum cumulative return\n    # The loss tally will stop with a zero appended to the negative run list (i.e., the negative run has ended)\n    # neg_run_num will also be appended with a zero when neg_run is zero\n\n    # While still within a peak-to-peak negative run\n    if val > 0:\n        \n        # Append zero to peak_trough_num if the lowest point has been discovered\n        if is_neg_run_min:\n            peak_trough_num.append(0)\n            \n        # Lowest point within a negative run has not been discovered\n        else:\n            if nz50.iloc[t]['neg_run'] == trough:\n                is_neg_run_min = True\n                peak_trough_num.append(val)\n            else:\n                peak_trough_num.append(val)\n                \n    # Out of the peak-to-peak negative run\n    else:\n        is_neg_run_min = False\n        peak_trough_num.append(val)\n            \nnz50['peak_trough_num'] = peak_trough_num","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Groupby's to check out the durations and maximum loss or drawdown of each market decline identified\n# There are 263 peak-to-peak negative runs\n\n# By peak-to-peak run number, count the number of days \nrun_len = nz50[nz50['neg_run_num']>0].groupby('neg_run_num').count()['neg_run']\n\n# By peak-to-peak run number, count lowest cumulative returns (i.e., maximum drawdown)\nmaximum_drawdown = nz50[nz50['neg_run_num']>0].groupby('neg_run_num').min()['neg_run']\n\n# By peak-to-trough run number, count the number of days\npeak_trough_dur = nz50[nz50['peak_trough_num']>0].groupby('peak_trough_num').count()['neg_run']\n\nfig, ax = plt.subplots(3)\nax[0].plot(run_len.sort_values(ascending=False).reset_index(drop=True))\nax[0].set_title(\"Time between Two Peaks (Days)\")\nax[1].plot(peak_trough_dur.sort_values(ascending=False).reset_index(drop=True))\nax[1].set_title(\"Time to Maximum Drawdown (Days)\")\nax[2].plot(maximum_drawdown.sort_values(ascending=False).reset_index(drop=True))\nax[2].set_title(\"Maximum Drawdown (%)\")\nfig.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Store groupby results in a new dataframe with the 263 runs\ndeclines_df = pd.DataFrame()\n\ndeclines_df['run_len'] = run_len\ndeclines_df['maximum_drawdown'] = maximum_drawdown\ndeclines_df['peak_trough_dur'] = peak_trough_dur\n\ndeclines_df.tail(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create 6 buckets by the magnitude of drawdown\ndrawdown_bin = []\nfor i in maximum_drawdown:\n    if i >= 0.00:\n        drawdown_bin.append(0)\n    elif i >= -0.05:\n        drawdown_bin.append(1)\n    elif i >= -0.10:\n        drawdown_bin.append(2)\n    elif i >= -0.20:\n        drawdown_bin.append(3)\n    elif i >= -0.30:\n        drawdown_bin.append(4)\n    else:\n        drawdown_bin.append(5)\n\ndeclines_df['drawdown_bin'] = drawdown_bin","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Overall means for drawdown metrics\nnp.mean(declines_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count the number of drawdowns in each drawdown bucket\ndeclines_df.groupby('drawdown_bin').count()['run_len']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the number of declines in each magnitude bucket in probability term\n\n# Calculate the probability of being in a drawdown bin relative to all drawdown bins\nprob_bucket = declines_df.groupby('drawdown_bin').count()['run_len']/sum(declines_df.groupby('drawdown_bin').count()['run_len'])\n\n# Plot the probabilities for each drawdown bin\nfig, ax = plt.subplots(figsize=(10,6))\nbin_names = ['-5% or Better','-5% to -10%','-10% to -20%','-20% to -30%','-30% or Worse']\nsns.barplot(x=prob_bucket, y=bin_names);\nax.set_xlabel(\"Probability\",fontsize=14)\nax.set_ylabel(\"Drawdown Bin\",fontsize=14)\n\n# Probability is between 0 and 1 - limit the range of possible value for x-axis\nax.set_xlim(0, 1)\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What happens after the market has already dropped by 5%\n\n# Calculate the probability for \nworst_probs = prob_bucket[1:]/sum(prob_bucket[1:])\n\n# probability of decline more than 10%\nprint(\"The probability of a further decline of more than 10% is\", sum(worst_probs[1:]))     \n\n# probability of decline being more than 20%\nprint(\"The probability of a further decline of more than 20% is\", sum(worst_probs[2:]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the mean maximum drawdown for each drawdown bucket of negative runs \ndeclines_df.groupby('drawdown_bin').mean()['maximum_drawdown']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the metrics of each drawdown bucket and store in a dataframe for plots\n\n# Calculate the peak-to-peak and peak-to-trough duration for each run\nduration_df = declines_df.groupby('drawdown_bin').mean()[['peak_trough_dur','run_len']]\nduration_df.reset_index(inplace=True)\n\n# Time to recover (in days)\nduration_df['recover_dur'] = duration_df['run_len'] - duration_df['peak_trough_dur']\n\n# Time to recover relative to time to the trough\nduration_df['recover_to_peak_trough_ratio'] = duration_df['recover_dur'] / duration_df['peak_trough_dur']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the metrics\nfig, ax = plt.subplots(figsize=(10,6))\nbin_names = ['-5% or Better','-5% to -10%','-10% to -20%','-20% to -30%','-30% or Worse']\nsns.barplot(x=bin_names, y=duration_df['recover_dur'])\nax.set_xlabel(\"Market Decline Bin\",fontsize=14)\nax.set_ylabel(\"Recovery Time in Days\",fontsize=14)\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"duration_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the Number and percentage of negative days\nprint(\"The number of negative daily returns: \", len([i for i in nz50['day_return'] if i<0]))\nprint(\"The number of daily returns: \", nz50.shape[0])\nprint(\"The fraction of negative daily returns: \", len([i for i in nz50['day_return'] if i<0])/nz50.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculate the Mean length of drawdown\nprint(\"The average length of peak-to-trough market downturn: \", np.mean(declines_df['peak_trough_dur']), \"days\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}