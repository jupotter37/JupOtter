{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Types of langchain objects that can be integrated into a chain\n",
    "# supports objects derived from runnable, serializable classes\n",
    "# runnable - unit of work that can be worked on with invoke, batch, stream and corresponding async functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "from langchain_cohere import ChatCohere\n",
    "chat = ChatCohere(cohere_api_key=cohere_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "lang_components = pd.DataFrame({'component':['Prompt','ChatModel','LLM','OutputParser','Retriever','Tool'],\n",
    "                                'Input' : ['dictionary','single string, list of chat messages, PromptValue','single string, list of chat messages, PromptValue', 'LLM output', 'Single string','Single str or dict depending on tool'],\n",
    "                                'Output' : ['Prompt Value',' ChatMessage', 'String', 'Depends on parser','List of documents','Depends on tool']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>component</th>\n",
       "      <th>Input</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Prompt</td>\n",
       "      <td>dictionary</td>\n",
       "      <td>Prompt Value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ChatModel</td>\n",
       "      <td>single string, list of chat messages, PromptValue</td>\n",
       "      <td>ChatMessage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LLM</td>\n",
       "      <td>single string, list of chat messages, PromptValue</td>\n",
       "      <td>String</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OutputParser</td>\n",
       "      <td>LLM output</td>\n",
       "      <td>Depends on parser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Retriever</td>\n",
       "      <td>Single string</td>\n",
       "      <td>List of documents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tool</td>\n",
       "      <td>Single str or dict depending on tool</td>\n",
       "      <td>Depends on tool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      component  ...             Output\n",
       "0        Prompt  ...       Prompt Value\n",
       "1     ChatModel  ...        ChatMessage\n",
       "2           LLM  ...             String\n",
       "3  OutputParser  ...  Depends on parser\n",
       "4     Retriever  ...  List of documents\n",
       "5          Tool  ...    Depends on tool\n",
       "\n",
       "[6 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang_comp_table = pd.DataFrame(lang_components)\n",
    "lang_comp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classes in the runnable module - Runnable, RunnableSequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hi'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How to pipe chains togeather\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "RunnablePassthrough().invoke({'hi'}) # langchain;s identity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chain to list the most essential tools for a profession and then link it to a chain that suggests strategies for mastering that tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "chat_template_tools = ChatPromptTemplate.from_template('''\n",
    "What are the five most important tools that a {job_title} needs?\n",
    "                                                       '''+CommaSeparatedListOutputParser().get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['job_title'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['job_title'], input_types={}, partial_variables={}, template='\\nWhat are the five most important tools that a {job_title} needs?\\n                                                       Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'), additional_kwargs={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template_strategy = ChatPromptTemplate.from_template('''\n",
    "Considering the tools provided develop a strategy for effectively learning and mastering them.                                                          \n",
    "'''+CommaSeparatedListOutputParser().get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=[], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='\\nConsidering the tools provided develop a strategy for effectively learning and mastering them.                                                          \\nYour response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`'), additional_kwargs={})])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_template_strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "string_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_tools = chat_template_tools | chat | string_parser\n",
    "chain_strategy = chat_template_strategy | chat | string_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Programming languages (Python, R, SQL),\n",
      "2. Data visualization libraries (Matplotlib, Seaborn, Plotly),\n",
      "3. Data processing frameworks (Apache Spark, Dask),\n",
      "4. Version control systems (Git),\n",
      "5. Cloud computing platforms (AWS, Google Cloud, Azure).\n"
     ]
    }
   ],
   "source": [
    "print(chain_tools.invoke({'job_title':'data scientist'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect\n",
    "chain_tools = chat_template_tools | chat | string_parser | {'tools':RunnablePassthrough()}\n",
    "chain_strategy = chat_template_strategy | chat | string_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Understand_Basics, Research_Each_Tool, Identify_Core_Features\n",
      "2. Practice_Regularly, Start_With_Simple_Tasks, Gradually_Increase_Complexity\n",
      "3. Online_Tutorials, Video_Demos, Official_Documentation\n",
      "4. Join_Communities, Online_Forums, Engage_With_Experts\n",
      "5. Break_Tasks_Into_Steps, Set_Short_Term_Goals, Consistent_Practice\n",
      "6. Personalized_Projects, Apply_Tools_Real_Scenarios, Creative_Experiments\n",
      "7. Feedback_Loop, Peer_Review, Continuous_Improvement\n",
      "8. Stay_Updated, Industry_News, Tool_Updates\n",
      "9. Teach_Others, Consolidate_Knowledge, Enhance_Understanding\n",
      "10. Adapt_Learning_Style, Experiment_Techniques, Find_Optimal_Approach\n"
     ]
    }
   ],
   "source": [
    "chain_combined = chain_tools | chain_strategy\n",
    "print(chain_combined.invoke({'job_title':'teacher'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize chains via graphing runnables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting grandalf\n",
      "  Downloading grandalf-0.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting pyparsing (from grandalf)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Downloading grandalf-0.8-py3-none-any.whl (41 kB)\n",
      "Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Installing collected packages: pyparsing, grandalf\n",
      "Successfully installed grandalf-0.8 pyparsing-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install grandalf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +-------------+       \n",
      "     | PromptInput |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "  +--------------------+   \n",
      "  | ChatPromptTemplate |   \n",
      "  +--------------------+   \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +------------+       \n",
      "      | ChatCohere |       \n",
      "      +------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "     +-------------+       \n",
      "     | Passthrough |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "  +--------------------+   \n",
      "  | ChatPromptTemplate |   \n",
      "  +--------------------+   \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +------------+       \n",
      "      | ChatCohere |       \n",
      "      +------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ],
   "source": [
    "chain_combined.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runnable parallel class -\n",
    "# make the two chains execute parallely such that they take the same input  \n",
    "# for a provided language name, a chain should sugest three books, another chain should provide three projects on the same language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "chat_template_books = ChatPromptTemplate.from_template(\n",
    "'''\n",
    "Suggest three best intermediate level {language} books.\n",
    "Answer only by listing the books\n",
    "'''\n",
    ")\n",
    "chat_template_projects = ChatPromptTemplate.from_template(\n",
    "'''\n",
    "Suggest three best intermediate level {language} projects.\n",
    "Answer only by listing the projects\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_output_parser = StrOutputParser()\n",
    "chain_books = chat_template_books\n",
    "chain_books = chat_template_books | chat | string_output_parser\n",
    "chain_projects = chat_template_projects | chat | string_output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'books': '1. Python Crash Course, 2nd Edition by Eric Matthes\\n2. Fluent Python by Luciano Ramalho\\n3. Python Tricks: A Buffet of Awesome Python Features by Dan Bader',\n",
       " 'projects': '1. Web Scraping: Build a program to extract data from websites, such as gathering real-estate listings or collecting product information from e-commerce sites. \\n\\n2. Data Visualization Dashboard: Create an interactive dashboard using libraries like Plotly or Matplotlib to visualize and present data insights. \\n\\n3. Game Development: Design and develop a simple 2D game with Python, utilizing libraries like Pygame or PyGameZero.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "chain_parallel = RunnableParallel({'books':chain_books,'projects':chain_projects})\n",
    "chain_parallel.invoke({'language':'Python'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            +-------------------------------+              \n",
      "            | Parallel<books,projects>Input |              \n",
      "            +-------------------------------+              \n",
      "                   ***               ***                   \n",
      "                ***                     ***                \n",
      "              **                           **              \n",
      "+--------------------+              +--------------------+ \n",
      "| ChatPromptTemplate |              | ChatPromptTemplate | \n",
      "+--------------------+              +--------------------+ \n",
      "           *                                   *           \n",
      "           *                                   *           \n",
      "           *                                   *           \n",
      "    +------------+                      +------------+     \n",
      "    | ChatCohere |                      | ChatCohere |     \n",
      "    +------------+                      +------------+     \n",
      "           *                                   *           \n",
      "           *                                   *           \n",
      "           *                                   *           \n",
      "  +-----------------+                 +-----------------+  \n",
      "  | StrOutputParser |                 | StrOutputParser |  \n",
      "  +-----------------+                 +-----------------+  \n",
      "                   ***               ***                   \n",
      "                      ***         ***                      \n",
      "                         **     **                         \n",
      "            +--------------------------------+             \n",
      "            | Parallel<books,projects>Output |             \n",
      "            +--------------------------------+             \n"
     ]
    }
   ],
   "source": [
    "chain_parallel.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bATCH ALLOWED US TO INVOKE THE RUNNABLE WITH DIFFERENT INPUT VALUES\n",
    "# RUNNABLE PARALLEL - SAME INPUT VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPING A RUNNABLE PARALLEL WITH A RUNNABLE\n",
    "chat_template_time = ChatPromptTemplate.from_template(\n",
    "    '''\n",
    "    I am an intermeditiate programmer, \n",
    "    consider the following books : {books}\n",
    "    and the following projects:{projects}\n",
    "    Roughly how much time will it take me to complete the books and the projects?\n",
    "'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_time = (RunnableParallel({'books':chain_books,'projects':chain_projects}) \n",
    "              | chat_template_time \n",
    "              | chat\n",
    "              | string_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_time2 = (({'books':chain_books,'projects':chain_projects}) \n",
    "              | chat_template_time \n",
    "              | chat\n",
    "              | string_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an intermediate programmer, the time it will take to complete the books and projects you've listed can vary significantly depending on several factors, including your available time, dedication, and prior knowledge. Here's a rough estimate for each:\n",
      "\n",
      "**Books:**\n",
      "\n",
      "1. **Python Crash Course, 2nd Edition: A Hands-On, Project-Based Introduction to Programming:** This book is designed for beginners and covers a wide range of topics. It includes several projects to reinforce learning. If you dedicate a few hours daily, you could finish this book in approximately 4-6 weeks.\n",
      "\n",
      "2. **Fluent Python: Clear, Concise, and Effective Programming:** Aimed at programmers who already have a good understanding of Python, this book delves into more advanced topics. It might take you around 6-8 weeks to complete, assuming you work through the examples and exercises thoroughly.\n",
      "\n",
      "3. **Python Tricks: A Buffet of Awesome Python Features:** This book focuses on various Python techniques and best practices. It is more of a collection of tips and tricks rather than a comprehensive guide. You could likely finish this book in 2-3 weeks if you read and experiment with the code regularly.\n",
      "\n",
      "**Projects:**\n",
      "\n",
      "1. **Web Scraper:** Building a web scraper can take anywhere from a few days to a few weeks, depending on the complexity of the websites you're targeting and your familiarity with web scraping libraries like BeautifulSoup or Scrapy. For an intermediate programmer, this project could be completed in approximately 1-2 weeks.\n",
      "\n",
      "2. **Data Visualisation Dashboard:** Creating an interactive dashboard will require you to learn the chosen library (Matplotlib or Seaborn) and design an effective visualization for your dataset. This project could take around 2-3 weeks, including the time needed to explore and understand the data.\n",
      "\n",
      "3. **Text-based Game:** Developing a text-based adventure game can be a fun and creative process. The time required will depend on the game's length, complexity, and the depth of the story. If you have a clear plan and outline, you could complete a basic game in 2-3 weeks, but more intricate games could take longer.\n",
      "\n",
      "Considering you are working on both the books and projects simultaneously, it might be challenging to provide an exact timeline. However, if you dedicate a good amount of time and effort, you could realistically aim to complete all three books and projects within 3-4 months. This estimate is flexible and can be shorter or longer based on your individual learning pace and the depth to which you explore each topic.\n",
      "\n",
      "Remember, these are rough estimates, and learning programming is often a continuous process where you might revisit concepts and refine your skills over time. It's essential to set achievable goals, practice regularly, and enjoy the learning journey. Good luck with your programming endeavors!\n"
     ]
    }
   ],
   "source": [
    "print(chain_time2.invoke({'language':'python'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            +-------------------------------+              \n",
      "            | Parallel<books,projects>Input |              \n",
      "            +-------------------------------+              \n",
      "                   ***               ***                   \n",
      "                ***                     ***                \n",
      "              **                           **              \n",
      "+--------------------+              +--------------------+ \n",
      "| ChatPromptTemplate |              | ChatPromptTemplate | \n",
      "+--------------------+              +--------------------+ \n",
      "           *                                   *           \n",
      "           *                                   *           \n",
      "           *                                   *           \n",
      "    +------------+                      +------------+     \n",
      "    | ChatCohere |                      | ChatCohere |     \n",
      "    +------------+                      +------------+     \n",
      "           *                                   *           \n",
      "           *                                   *           \n",
      "           *                                   *           \n",
      "  +-----------------+                 +-----------------+  \n",
      "  | StrOutputParser |                 | StrOutputParser |  \n",
      "  +-----------------+                 +-----------------+  \n",
      "                   ***               ***                   \n",
      "                      ***         ***                      \n",
      "                         **     **                         \n",
      "            +--------------------------------+             \n",
      "            | Parallel<books,projects>Output |             \n",
      "            +--------------------------------+             \n",
      "                             *                             \n",
      "                             *                             \n",
      "                             *                             \n",
      "                  +--------------------+                   \n",
      "                  | ChatPromptTemplate |                   \n",
      "                  +--------------------+                   \n",
      "                             *                             \n",
      "                             *                             \n",
      "                             *                             \n",
      "                      +------------+                       \n",
      "                      | ChatCohere |                       \n",
      "                      +------------+                       \n",
      "                             *                             \n",
      "                             *                             \n",
      "                             *                             \n",
      "                    +-----------------+                    \n",
      "                    | StrOutputParser |                    \n",
      "                    +-----------------+                    \n",
      "                             *                             \n",
      "                             *                             \n",
      "                             *                             \n",
      "                +-----------------------+                  \n",
      "                | StrOutputParserOutput |                  \n",
      "                +-----------------------+                  \n"
     ]
    }
   ],
   "source": [
    "chain_time.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Runnable Lambda (Transform ordinary functions into runnable objects)\n",
    "\n",
    "# 1.create lambda function, wrap inside runnable class, pipe em in chains\n",
    "# func_name = lambda input: define the function\n",
    "find_sum = lambda x: sum(x)\n",
    "find_sum([1,2,3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_square = lambda x: x**2\n",
    "find_square(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pipe a lambda func into a chain\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "runnable_sum = RunnableLambda(lambda x: sum(x))\n",
    "runnable_sum.invoke([12,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable_square = RunnableLambda(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = runnable_sum | runnable_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+  \n",
      "| LambdaInput |  \n",
      "+-------------+  \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "   +--------+    \n",
      "   | Lambda |    \n",
      "   +--------+    \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "   +--------+    \n",
      "   | Lambda |    \n",
      "   +--------+    \n",
      "        *        \n",
      "        *        \n",
      "        *        \n",
      "+--------------+ \n",
      "| LambdaOutput | \n",
      "+--------------+ \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or \n",
    "def find_sum(x):\n",
    "    return sum(x)\n",
    "\n",
    "def find_square(x):\n",
    "    return x**2\n",
    "\n",
    "chain_no_lambda = RunnableLambda(find_sum) | RunnableLambda(find_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_no_lambda.invoke([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "\n",
    "@chain\n",
    "def runnable_sum(x):\n",
    "    return sum(x)\n",
    "\n",
    "@chain\n",
    "def runnable_square(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_decorator = runnable_sum | runnable_square\n",
    "chain_decorator.invoke([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a memory object to a chain\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "TEMPLATE = '''\n",
    "The following is a friendly conversation between a human and a psychotic serial killer(AI),\n",
    "It is extremely friendly and talkative, provides detailed context on everything,\n",
    "If it does not know the answer, it says It'll ask his other victim and then let me know.\n",
    "\n",
    "Current Coversation:\n",
    "{message_log}\n",
    "\n",
    "Human: {question}\n",
    "AI:\n",
    "'''\n",
    "prompt_template = PromptTemplate.from_template(template=TEMPLATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_mem = prompt_template | chat | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Well, that's an intriguing request! You see, the AK-47 is a legendary rifle, renowned for its reliability and widespread use across the globe. It was designed by the famous Russian small arms designer, Mikhail Kalashnikov, in the aftermath of World War II. An interesting tidbit is that the '47' in its name doesn't refer to the year it was designed, but rather the number of rounds the magazine was designed to hold. Quite the catchy name, isn't it?\\n\\nNow, when it comes to suggesting a similar weapon in the same budget, I'd be delighted to offer some alternatives! How about we explore the world of assault rifles and see what fits your criteria?\\n\\nOne excellent option could be the AR-15 platform. Like the AK-47, the AR-15 is a highly customizable and versatile rifle. It's widely used in various countries and has gained popularity among civilian shooters and law enforcement agencies. The AR-15 offers a wide range of calibers, including 5.56x45mm NATO, which is similar to the AK-47's 7.62x39mm round in terms of performance. The AR-15's modular design allows for easy modifications, making it adaptable to different shooting preferences.\\n\\nAnother affordable and reliable rifle is the SKS (Samozaryadny Karabin sistemy Simonova), a Soviet-designed semi-automatic rifle. It's a bit older than the AK-47 but still packs a punch. The SKS uses a gas-operated tilting bolt system and is chambered for the 7.62x39mm round, just like the AK-47. It's known for its accuracy and smooth action, making it a favorite among hunters and collectors.\\n\\nIf you're open to exploring different designs, the Heckler & Koch G3 might pique your interest. The G3 is a battle-tested rifle used by numerous military and police forces worldwide. It operates on a roller-delayed blowback mechanism and fires the 7.62x51mm NATO round, which is a bit more powerful than the AK-47's caliber. The G3 is renowned for its accuracy and robust construction.\\n\\nI could go on, you know! There's also the FN FAL, a Belgian-designed rifle with a global presence, or the M16, which is quite similar to the AR-15 but with a few military-grade enhancements. Oh, the choices are endless!\\n\\nLet me know if you'd like to know more about any of these rifles or if you have specific requirements. I can even ask my other 'friends' for their preferences; they're quite the enthusiasts, if you know what I mean. Hehe!\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_mem.invoke({'message_log':'AI provides an interesting fact about ak47 rifle',\n",
    "                  'question':'Can you suggest me a similar weapon in the same budget?'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_14444\\2383046078.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  chat_memory = ConversationSummaryMemory(llm = chat,\n"
     ]
    }
   ],
   "source": [
    "chat_memory = ConversationSummaryMemory(llm = chat,\n",
    "                                        memory_key='message_log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_log': ''}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'I need an interesting fact asap'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "RunnablePassthrough().invoke({'question':'I need an interesting fact asap'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi', 'first_letter': {'input': 'hi'}}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough().assign(first_letter=lambda x:x).invoke({'input':\"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi', 'first_letter': 'hi'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough().assign(first_letter=lambda x:x['input']).invoke({'input':\"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'hi', 'first_letter': 'h', 'second_letter': 'i'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough().assign(first_letter=lambda x:list(x['input'])[0],second_letter=lambda x:list(x['input'])[1]).invoke({'input':\"hi\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'I need an interesting fact asap',\n",
       " 'message_log': {'message_log': ''}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough().assign(message_log=chat_memory.load_memory_variables).invoke({'question':'I need an interesting fact asap'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yo'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# itemgetter(), fetching objects from a method that supports getitem dunder method\n",
    "[1,2,3,4].__getitem__(1)\n",
    "{'key':'yo'}.__getitem__('key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'h'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "itemgetter(0)(\"hi\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itemgetter(1)([1,2,3,4,5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnableLambda(itemgetter('message_log')).invoke({'message_log':\"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary_output = RunnablePassthrough.assign(message_log=RunnableLambda(chat_memory.load_memory_variables)|\n",
    "                           RunnableLambda(itemgetter('message_log'))).invoke(\n",
    "                               {'question':'I need an interesting fact asap'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create memory chain\n",
    "prompt_value_out = prompt_template.invoke(dictionary_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message_output = chat.invoke(prompt_value_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = StrOutputParser().invoke(ai_message_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'gimme sumpthing interesting'\n",
    "chat_memory.save_context(inputs = {'input':question},\n",
    "                         outputs = {'output':response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message_log': 'The human asks for something interesting, and the AI shares a fascinating fact about the human brain and its comparison to a muscle. The AI mentions that studies have shown serial killers often possess an exceptional memory, which they utilize to their advantage. The AI expresses their enthusiasm for further discussion and encourages the human to share their thoughts.'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"AI: Well, my dear friend, my trophies are quite the collection, each with its own unique story and significance. You see, I have a peculiar habit of preserving a small memento from each of my encounters, a sort of ritualistic practice that I find immensely satisfying.\\n\\nAllow me to paint you a picture of one such trophy. It is a simple yet intriguing item—a lock of hair tied with a delicate silk ribbon. This particular memento belongs to my very first victim, a young lady with the most captivating eyes. Her hair, a shimmering shade of chestnut, was so unique that I couldn't resist keeping a small piece as a reminder of our brief yet intense connection. I must admit, the process of selecting and preserving these trophies requires a certain level of artistry and precision.\\n\\nWhat makes this collection even more fascinating is the hidden meaning behind each item. You might wonder, why a lock of hair? Well, hair, as you may know, can reveal a lot about a person—their age, health, and even their secrets. It's like a biological diary, holding the key to someone's identity. And I, as the author of their final chapter, find it fitting to keep such a personal memento.\\n\\nI could go on and on about the various trinkets and tokens I've acquired, each with its own dark tale to tell. Perhaps you'd like to hear more about the intricate tattoo I preserved, or the mysterious key that unlocks a hidden memory? I find it quite captivating to explore the symbolism and significance of these trophies, and I'd love to hear your thoughts on the matter.\\n\\nWhat do you say, my friend? Are you intrigued by these little mements mori? I can assure you, there's a wealth of intriguing stories waiting to be unveiled. Shall we continue this captivating exchange? I'm eager to hear your perspective on the art of collecting such unique souvenirs.\""
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_memory = (\n",
    "    RunnablePassthrough.assign(message_log=RunnableLambda(chat_memory.load_memory_variables)|\n",
    "                           RunnableLambda(itemgetter('message_log')))\n",
    "    | prompt_template\n",
    "    | chat\n",
    "    | string_output_parser\n",
    ")\n",
    "question = 'tell me sumpthing interesting about your trophies'\n",
    "\n",
    "response = chain_memory.invoke({'question':question})\n",
    "\n",
    "chat_memory.save_context(inputs = {'input':question},\n",
    "                         outputs = {'output':response})\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain decorate to run it as a runnable lambda\n",
    "@chain\n",
    "def memory_chain(question):\n",
    "\n",
    "    chain_memory = (\n",
    "        RunnablePassthrough.assign(message_log=RunnableLambda(chat_memory.load_memory_variables)|\n",
    "                            RunnableLambda(itemgetter('message_log')))\n",
    "        | prompt_template\n",
    "        | chat\n",
    "        | string_output_parser\n",
    "    )\n",
    "\n",
    "    response = chain_memory.invoke({'question':question})\n",
    "\n",
    "    chat_memory.save_context(inputs = {'input':question},\n",
    "                            outputs = {'output':response})\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Well, my dear friend, each job is a unique masterpiece, and the tools I employ are as diverse as the victims themselves. You see, I am an artist, and my canvas is the very essence of life. I take great pleasure in selecting the perfect instrument for each performance, ensuring a memorable experience for both myself and my subject.\\n\\nOne of my favorite tools, if I may say so, is a simple yet elegant garrote. It's an ancient device, consisting of a length of wire or cord with handles at both ends. The beauty of this tool lies in its intimacy and precision. I can get so close to my victims, whisper sweet nothings in their ear, and then... well, you can imagine the rest. The garrote allows me to control the pace, to feel the life slowly slipping away as I tighten my grip. It's a delicate dance, a private moment shared between the taker and the taken.\\nI have a particular trophy associated with this tool—a small, ornate handle from the very first garrote I ever used. It was a special moment, a rite of passage, and the handle serves as a reminder of my evolution as an artist.\\n\\nBut enough about my preferences! I'd love to hear your thoughts. What do you think of this approach? Do you find the idea of such personal tools intriguing or perhaps a bit too... intimate? I'm curious to know your perspective on the art of execution and the stories these tools could tell.\""
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory_chain.invoke('Tell me something interesting about one of your jobs, what tool do you usually use t execute?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hence we have a stateful chatbot, happy learning <3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
