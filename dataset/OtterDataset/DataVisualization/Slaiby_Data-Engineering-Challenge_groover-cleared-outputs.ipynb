{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Music Genre Prediction](../images/banner.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Slaiby AlMallah Coding Challenge**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Purpose"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tasks\n",
        "#### Retrieve Popularity Score of Each Artist\n",
        "- **Fetch the Popularity Metric from Spotify's API for Each Artist**\n",
        "  - Use Spotify's API to retrieve the popularity score for each artist.\n",
        "#### Ensure Artist Name Matching\n",
        "- **Verify That the Artist Names on Groover's Platform Match Those on Spotify**\n",
        "  - Ensure the consistency and accuracy of artist names between Groover's platform and Spotify.\n",
        "#### SQL Query\n",
        "- **Write a SQL Query That Lists:**\n",
        "  - **`spotify_id`**\n",
        "  - **`user_id`**\n",
        "  - **`genres`**\n",
        "  - **Total `number of genres` assigned to each `artist`**\n",
        "  - **Total `number of artists` assigned to each `genre`**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNLgtMCN2F2V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import logging\n",
        "import librosa\n",
        "import sqlite3\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import librosa.display\n",
        "from fuzzywuzzy import fuzz\n",
        "import plotly.express as px\n",
        "from fuzzywuzzy import process\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib_venn import venn2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "root_dir = os.path.dirname(current_dir)\n",
        "print(root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xmzzHMvBXGy",
        "outputId": "3b18ba6d-2190-407a-a0ec-1a83359a40a4"
      },
      "outputs": [],
      "source": [
        "%pip install spotipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spotipy\n",
        "from spotipy.oauth2 import SpotifyClientCredentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dN8JkSUO16Rx"
      },
      "outputs": [],
      "source": [
        "EXTRACT_FOLDER = os.path.abspath(os.path.join(root_dir, \"raw_data\"))\n",
        "\n",
        "artist_data = pd.read_csv(f\"{EXTRACT_FOLDER}/artist_data.csv\")\n",
        "spotify_data = pd.read_csv(f\"{EXTRACT_FOLDER}/spotify_data.csv\")\n",
        "tag_genre_data = pd.read_csv(f\"{EXTRACT_FOLDER}/tag_genre_data.csv\")\n",
        "tag_artist_data = pd.read_csv(f\"{EXTRACT_FOLDER}/tag_artist_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Artist data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# initial analysis of the artist data\n",
        "artist_data.head(), artist_data.describe(), artist_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check for any missing values in the artist_data\n",
        "artist_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `artist_data` has 2 `artist_name` rows which have missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the row of the missing values\n",
        "missing_artist_data = artist_data[artist_data.isnull().any(axis=1)]\n",
        "missing_artist_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop the missing values\n",
        "artist_data = artist_data.dropna()\n",
        "missing_artist_data = artist_data[artist_data.isnull().any(axis=1)]\n",
        "missing_artist_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The missing rows were removed in `artist_data`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if the artist artist_name is unique and get the count of the artist_name\n",
        "artist_name_counts = artist_data['artist_name'].value_counts()\n",
        "duplicates = artist_name_counts[artist_name_counts > 1]\n",
        "unique_artist_count = artist_name_counts.shape[0]\n",
        "unique_artist_count, duplicates.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove the rows with duplicate artist_name\n",
        "artist_data = artist_data.drop_duplicates(subset='artist_name')\n",
        "artist_name_counts = artist_data['artist_name'].value_counts()\n",
        "duplicates = artist_name_counts[artist_name_counts > 1]\n",
        "unique_artist_count = artist_name_counts.shape[0]\n",
        "unique_artist_count, duplicates.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Duplicate rows in `artist_data` were dropped"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Spotify data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# do initial data exploration on the spotify_data\n",
        "spotify_data.head(), spotify_data.info(), spotify_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if the user_id is unique and get the count of the user_id in spotify_data\n",
        "user_id_counts = spotify_data['user_id'].value_counts()\n",
        "user_id_counts = user_id_counts[user_id_counts > 1]\n",
        "user_id_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if the user_id is unique and get the count of the spotify_id in spotify_data\n",
        "spotify_id_counts = spotify_data['spotify_id'].value_counts()\n",
        "spotify_id_counts = spotify_id_counts[spotify_id_counts > 1]\n",
        "spotify_id_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `user_id` and the `spotify_id` do not have any duplicate values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if the spotify data has any missing values\n",
        "spotify_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `spotify_data` does not have any missing values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tag artist data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# do initial data exploration on the tag_genre_data\n",
        "tag_genre_data.head(), tag_genre_data.info(), tag_genre_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# show the unique values of the user_id in tag_artist and get the count of the user_id\n",
        "user_id_counts = tag_artist_data['user_id'].value_counts()\n",
        "user_id_counts = user_id_counts[user_id_counts > 1]\n",
        "user_id_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is shown that the same `user_id` is mentioned more than once for specific `genres`.\n",
        "\n",
        "This shows that the same `user_id` which is potentially the artist may have more than one genre tag.\n",
        "\n",
        "A group-by and aggregation approach of the `genres` will be taken based on the `user_id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# show the the unique number of tag_id in tag_artist and get the count of the tag_id and plot the distribution per unique tag_id\n",
        "tag_id_counts = tag_artist_data['tag_id'].value_counts()\n",
        "tag_id_counts = tag_id_counts[tag_id_counts > 1]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.pie(tag_id_counts, labels=tag_id_counts.index, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Distribution of Tag IDs')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# do initial data exploration on the tag_genre_data\n",
        "tag_genre_data.head(), tag_genre_data.info(), tag_genre_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# show if there is any duplicate genres tag_genre_data\n",
        "genre_counts = tag_genre_data['genre'].value_counts()\n",
        "genre_duplicates = genre_counts[genre_counts > 1]\n",
        "genre_duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# show if there is any duplicate tag_id in tag_genre_data\n",
        "tag_counts = tag_genre_data['tag_id'].value_counts()\n",
        "tag_counts = tag_counts[tag_counts > 1]\n",
        "tag_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `tag_genre_data` does not have any missing duplicate or missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# visualize the distinct genres in the tag_genre_data in a pie chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.pie(genre_counts, labels=genre_counts.index, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Distribution of Genres')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Merging The data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# merge the tag_artist_data with tag_genre on the tag_id\n",
        "tag_artist_data = pd.merge(tag_artist_data, tag_genre_data, on='tag_id')\n",
        "tag_artist_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# group by the user_id and aggregate the genre in a list for each user_id\n",
        "user_genre = tag_artist_data.groupby('user_id')['genre'].agg(list)\n",
        "user_genre = user_genre.reset_index()\n",
        "user_genre.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Aggregated `genres` based on` user_id` groupping in `user_genre`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Engineering and Relational Building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initial Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "My initial approach was to work on the data using pandas DataFrames and then move on to the SQL part where my data would have been cleaned and visualized.\n",
        "I chose to work first on pandas and Python and then switch to SQL for the ease of use of Python and to see the data transform easier while building and aggregating.\n",
        "\n",
        "To begin with, based on the initial analysis of the data, the `user_id` looked to be a good way to group and merge the data based on these CSV files to get complementary data.\n",
        "\n",
        "- The `tag_artist_data` and the `tag_genre_data` were merged based on the `user_id` and aggregated based on the `tag_id`, putting it in a list:\n",
        "\n",
        "  | `user_id` | `genre`                                 |\n",
        "  |-----------|------------------------------------------|\n",
        "  | 9         | [jazz, electronic_music, reggae]         |\n",
        "  | 12        | [rock, soul]                             |\n",
        "  | 14        | [funk, trap, pop]                        |\n",
        "  | 16        | [electronic_music, soul]                 |\n",
        "  | 23        | [trap, rock, disco]                      |\n",
        "\n",
        "  This table shows the initial grouping by `user_id`.\n",
        "\n",
        "- The second transformation was to merge the `spotify_data` and the `artist_data` based on the `user_id` present in both as an inner join to ensure a full target merge is obtained.\n",
        "\n",
        "  | `user_id` | `spotify_id`           | `artist_name`      | `genres_list`                          |\n",
        "  |-----------|------------------------|--------------------|----------------------------------------|\n",
        "  | 9         | 5e2WCQCvRUo05S2uTk2xVC | zoid               | [jazz, electronic_music, reggae]       |\n",
        "  | 12        | 7MOpb0hgwnTxr3lCNPPVGR | seytak             | [rock, soul]                           |\n",
        "  | 14        | 6VcXjtZBueCzpqWFqg29O7 | kardes             | [funk, trap, pop]                      |\n",
        "  | 16        | 2hYPsr25gOfRQCsz7Boe1Q | daryl              | [electronic_music, soul]               |\n",
        "  | 23        | 1pXMpZ5naNbGArl4Q1DGhs | gem shadou         | [trap, rock, disco]                    |\n",
        "  | 27        | 1M7FGvgTp0ftLNZiKS61fp | travi the native   | [electronic_music, jazz, funk]         |\n",
        "\n",
        "  This table shows the final merged data with `spotify_id`, `user_id`, `artist_name`, and the aggregated `genres_list`.\n",
        "\n",
        "Next I took in the `spotify_id` made sure the spotify id was a distinct value and using the `spotipy` library created request batches to ping in `spotify web-api`. The spotify data came in in this format\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"external_urls\": {\n",
        "    \"spotify\": \"https://open.spotify.com/artist/6vBKKJwPxTNFpFIrBEpj6R\"\n",
        "  },\n",
        "  \"followers\": {\n",
        "    \"href\": null,\n",
        "    \"total\": 4\n",
        "  },\n",
        "  \"genres\": [],\n",
        "  \"href\": \"https://api.spotify.com/v1/artists/6vBKKJwPxTNFpFIrBEpj6R\",\n",
        "  \"id\": \"6vBKKJwPxTNFpFIrBEpj6R\",\n",
        "  \"images\": [\n",
        "    {\n",
        "      \"height\": 640,\n",
        "      \"url\": \"https://i.scdn.co/image/ab6761610000e5eb46c2af911fa5cec04f9e64f4\",\n",
        "      \"width\": 640\n",
        "    },\n",
        "    {\n",
        "      \"height\": 320,\n",
        "      \"url\": \"https://i.scdn.co/image/ab6761610000517446c2af911fa5cec04f9e64f4\",\n",
        "      \"width\": 320\n",
        "    },\n",
        "    {\n",
        "      \"height\": 160,\n",
        "      \"url\": \"https://i.scdn.co/image/ab6761610000f17846c2af911fa5cec04f9e64f4\",\n",
        "      \"width\": 160\n",
        "    }\n",
        "  ],\n",
        "  \"name\": \"Feel the Groove\",\n",
        "  \"popularity\": 0,\n",
        "  \"type\": \"artist\",\n",
        "  \"uri\": \"spotify:artist:6vBKKJwPxTNFpFIrBEpj6R\"\n",
        "}\n",
        "```\n",
        "\n",
        "To circumvent the API rate-limiter, the requests were sent in several batches.\n",
        "This was all done to enrich the data with different data points from a trusted external source and, most importantly, to get the popularity score.\n",
        "\n",
        "After I enriched the data on the columns, I was faced with a rather big problem. The enriched data from the `Spotify API` was mismatching with my local data like so:\n",
        "\n",
        "| `artist_name`  | `spotify_name` | `popularity` | `genres_list`          | `spotify_genre` |\n",
        "|----------------|----------------|--------------|------------------------|------------------|\n",
        "| millo          | Pando G        | 17.0         | [jazz, funk, disco]    | [pop]            |\n",
        "| mctoad         | May.Lu         | 30.0         | [rock, metal, trap]    | [techno]         |\n",
        "| bethany sin    | BYLJA          | 4.0          | [funk, reggae, pop]    | []               |\n",
        "\n",
        "The names were not matching up, as well as the `spotify_genre` and the local `genres_list`.\n",
        "\n",
        "This is when I realized that the file containing `spotify_data` had a erroneous mapping of `user_id` and `spotify_id`\n",
        "\n",
        "As an example I sorted by `popularity` and got `Taylor Swift` as the most popular `artist`.\n",
        "\n",
        "I took the name of `Taylor Swift` and searched in `artist_data` and got an `id: 9796`.\n",
        "\n",
        "I mapped this `id` in the `spotify_data` and it mapped to `1BEezFxAAhGWa4lsLmddW2`.\n",
        "\n",
        "To validate my hypothesis that the `user_id` and `spotify_id` have a mismatch, the returned artist from spotify was different from the one intended\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"external_urls\": {\n",
        "    \"spotify\": \"https://open.spotify.com/artist/1BEezFxAAhGWa4lsLmddW2\"\n",
        "  },\n",
        "  \"followers\": {\n",
        "    \"href\": null,\n",
        "    \"total\": 2072\n",
        "  },\n",
        "  \"genres\": [],\n",
        "  \"href\": \"https://api.spotify.com/v1/artists/1BEezFxAAhGWa4lsLmddW2?locale=en\",\n",
        "  \"id\": \"1BEezFxAAhGWa4lsLmddW2\",\n",
        "  \"images\": [\n",
        "    {\n",
        "      \"url\": \"https://i.scdn.co/image/ab6761610000e5ebfd256b6e183167e989e88193\",\n",
        "      \"height\": 640,\n",
        "      \"width\": 640\n",
        "    },\n",
        "    {\n",
        "      \"url\": \"https://i.scdn.co/image/ab67616100005174fd256b6e183167e989e88193\",\n",
        "      \"height\": 320,\n",
        "      \"width\": 320\n",
        "    },\n",
        "    {\n",
        "      \"url\": \"https://i.scdn.co/image/ab6761610000f178fd256b6e183167e989e88193\",\n",
        "      \"height\": 160,\n",
        "      \"width\": 160\n",
        "    }\n",
        "  ],\n",
        "  \"name\": \"HABIB\",\n",
        "  \"popularity\": 17,\n",
        "  \"type\": \"artist\",\n",
        "  \"uri\": \"spotify:artist:1BEezFxAAhGWa4lsLmddW2\"\n",
        "}\n",
        "```\n",
        "**The `user_id` rows do not match and map to the artist name.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After doubting the linkability of the local data by `user_id`, my confidence towards the local data is questionable.\n",
        "\n",
        "### Potential Issues\n",
        "\n",
        "- **Indexing Problems**:\n",
        "  - Maybe the data has indexing problems?\n",
        "- **Different Databases**:\n",
        "  - Maybe the data comes from different databases which had to have the same `user_id` by chance?\n",
        "- **Retrieval Pipeline Issues**:\n",
        "  - Maybe the data has issues in the retrieval pipeline of our systems?\n",
        "\n",
        "These files have a potential lack of a `single source of truth` leading to mismatching data in storage and retrieval operations. The reason might be due to data corruption as well.\n",
        "\n",
        "### Monitoring and Auditing\n",
        "\n",
        "- The `user_id` issue should be monitored closely with the auditing team to ensure a correct `standardized data management solution`.\n",
        "\n",
        "### Assumption and Approach\n",
        "\n",
        "The next assumption I will be taking is that the `local` data integrity is low and that the `Spotify` data has a higher reliability given that the `Spotify` data source will always provide a source of truth.\n",
        "\n",
        "I will need to tackle the problem differently, which will be the approach taken in the `final-notebook-eval`.\n",
        "\n",
        "### End Goal\n",
        "\n",
        "The end goal is to derive meaningful insights from the data with its enrichments and work around the data while conserving as much context as possible since data is valuable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alternative Approach"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the alternative approach I will be taking spotify data as the source of truth and will only use the current local files to match them with the names and assign the same ids to them.\n",
        "\n",
        "By doing this, if my approach is successful the auditting team can add the new genres and re-connect the databse based on the un-changed artist-ids.\n",
        "\n",
        "I will be using name matching techniques using Jaccard's similarity and Levenshtein distance by starting with the spotify_ids and fetching the data from the spotify database on the spotify.\n",
        "\n",
        "I will be enhancing and expanding on the spotify data that will be from the api and expand and analyse it further with the name matching approach to ensure the artists from the spotify data are at least present in the local database"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Music Genre Prediction](../images/flow-dataiku.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Name Matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test for the spotify api\n",
        "try:\n",
        "    client_credentials_manager = SpotifyClientCredentials(client_id='74faa300c660435bba5f2955ee9793df', client_secret='fb820358ad264a2294619812733008d3')\n",
        "    sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)\n",
        "    print(\"Spotipy is installed and initialized correctly!\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test to see the return data from the spotify api\n",
        "artist_id = '6vBKKJwPxTNFpFIrBEpj6R'\n",
        "artist = sp.artist(artist_id)\n",
        "print(artist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# batched fetch of artist details on the spotify web api\n",
        "def fetch_artists_details(sp, spotify_ids, batch_size=50):\n",
        "    \"\"\" Fetches artist details in batches, including the number of followers. \"\"\"\n",
        "    artist_details = []\n",
        "    total_batches = len(spotify_ids) // batch_size + (1 if len(spotify_ids) % batch_size else 0)\n",
        "\n",
        "    for i in range(0, len(spotify_ids), batch_size):\n",
        "        try:\n",
        "            batch_ids = spotify_ids[i:i+batch_size]\n",
        "            artists_info = sp.artists(batch_ids)\n",
        "            for artist in artists_info['artists']:\n",
        "                print(artist)\n",
        "                artist_details.append({\n",
        "                    'spotify_id': artist['id'],\n",
        "                    'popularity': artist['popularity'],\n",
        "                    'spotify_name': artist['name'],\n",
        "                    'spotify_genre': artist['genres'],\n",
        "                    'spotify_followers': artist['followers']['total']\n",
        "                })\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing batch {i//batch_size+1}/{total_batches}: {e}\")\n",
        "\n",
        "    return artist_details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# query the spotify api for the artist details on the unique spoitfy_ids\n",
        "spotify_ids = spotify_data['spotify_id'].unique()\n",
        "print(f\"Fetching artist details for {len(spotify_ids)} artists from Spotify API...\")\n",
        "artist_details_from_spotify_api = fetch_artists_details(sp, spotify_ids, batch_size=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that the Spotify data is loaded, I will proceed with matching the artist names from the spotify data to the local artisit data by name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# convert the artist details from the spotify api to a pandas dataframe\n",
        "df_artist_details_from_spotify_api = pd.DataFrame(artist_details_from_spotify_api)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check if the name is unique in the artist details from the spotify api\n",
        "artist_name_counts = df_artist_details_from_spotify_api['spotify_name'].value_counts()\n",
        "duplicates = artist_name_counts[artist_name_counts > 1]\n",
        "unique_artist_count = artist_name_counts.shape[0]\n",
        "unique_artist_count, duplicates.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# remove the duplicates in the artist details from the spotify api\n",
        "df_artist_details_from_spotify_api = df_artist_details_from_spotify_api.drop_duplicates(subset='spotify_name')\n",
        "artist_name_counts = df_artist_details_from_spotify_api['spotify_name'].value_counts()\n",
        "duplicates = artist_name_counts[artist_name_counts > 1]\n",
        "unique_artist_count = artist_name_counts.shape[0]\n",
        "unique_artist_count, duplicates.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save the artist details to a csv file in the extract folder to avoid querying the spotify api again\n",
        "df_artist_details_from_spotify_api.to_csv(f\"{EXTRACT_FOLDER}artist_details.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# display the artist details from the spotify api\n",
        "df_artist_details_from_spotify_api.tail(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# apply lower case name normalization to the spotify_name column and normalize the special characters\n",
        "df_artist_details_from_spotify_api['spotify_name'] = df_artist_details_from_spotify_api['spotify_name'].str.lower()\n",
        "df_artist_details_from_spotify_api.sort_values(by='popularity', ascending=False).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# merge the artist details from the spotify api with the artist data\n",
        "artist_user_id_mapping = pd.merge(df_artist_details_from_spotify_api, artist_data, left_on='spotify_name', right_on='artist_name', how='left')\n",
        "artist_user_id_mapping.sort_values(by='popularity', ascending=False).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# separate the results into two dataframes, one with the mapping and the other without\n",
        "artist_user_id_mapping_no_user_id = artist_user_id_mapping[artist_user_id_mapping['user_id'].isna()]\n",
        "artist_user_id_mapping = artist_user_id_mapping.dropna(subset=['user_id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# transform the user_id to integer\n",
        "artist_user_id_mapping['user_id'] = artist_user_id_mapping['user_id'].astype(int)\n",
        "artist_user_id_mapping.sort_values(by='popularity', ascending=False).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# displaying the artist_user_id_mapping_no_user_id\n",
        "artist_user_id_mapping_no_user_id.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The main reason these columns did not match is a slight variation of the name between the `artist_user_id_mapping` from the `spotify api` and the `artist_data`.\n",
        "\n",
        "\n",
        "For this reason, I will be using a fuzzy search algorithm to match the context even further with a very high threshold score based on the `Levenshtein distance`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fuzzy matching of the artist_name and spotify_name\n",
        "def fuzzy_merge_unique_with_auditing(df1, df2, key1, key2, exclusion_list=None, threshold=95, limit=1, char_margin=5):\n",
        "    \"\"\"\n",
        "    Merge two dataframes using fuzzy matching with unique match constraint, character length sensitivity, \n",
        "    and store entries not passing the threshold.\n",
        "    :param df1: DataFrame containing the target values to match (left DataFrame).\n",
        "    :param df2: DataFrame containing the source values for matching (right DataFrame).\n",
        "    :param key1: Column name in df1 to match against df2.\n",
        "    :param key2: Column name in df2 used for matching.\n",
        "    :param exclusion_list: List of names to exclude from matching.\n",
        "    :param threshold: Minimum score to accept as a match (0-100).\n",
        "    :param limit: The maximum number of top matches to return.\n",
        "    :param char_margin: Allowed character count difference to consider a match.\n",
        "    :return: Tuple of DataFrames (matched_df, audit_df)\n",
        "    \"\"\"\n",
        "    matched = set()  \n",
        "    unmatched = []   \n",
        "\n",
        "    if exclusion_list:\n",
        "        source_list = [item for item in df2[key2] if item not in exclusion_list]\n",
        "    else:\n",
        "        source_list = df2[key2].tolist()\n",
        "\n",
        "    def get_matches(x):\n",
        "        if not x:  # if the value is None or empty\n",
        "            return None\n",
        "        possible_matches = process.extract(x, source_list, limit=limit)\n",
        "        valid_matches = [\n",
        "            pm for pm in possible_matches\n",
        "            if pm[0] not in matched and pm[1] >= threshold and abs(len(pm[0]) - len(x)) <= char_margin\n",
        "        ]\n",
        "        if valid_matches:\n",
        "            for match in valid_matches:\n",
        "                matched.add(match[0])\n",
        "            return ', '.join([f\"{m[0]} ({m[1]})\" for m in valid_matches])\n",
        "        else:\n",
        "            # Store the best match for auditing if no valid matches are found\n",
        "            if possible_matches:\n",
        "                best_match = max(possible_matches, key=lambda pm: pm[1])\n",
        "                unmatched.append((x, best_match[0], best_match[1]))\n",
        "            return None\n",
        "\n",
        "    df1['matches'] = df1[key1].apply(get_matches)\n",
        "    matched_df = df1.dropna(subset=['matches'])\n",
        "\n",
        "    # Create a DataFrame for auditing purposes\n",
        "    audit_df = pd.DataFrame(unmatched, columns=[key1, 'Best Match', 'Score'])\n",
        "\n",
        "    return matched_df, audit_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a list of artist names to exclude from matching which are the artist names in the artist_user_id_mapping\n",
        "exclusion_list = artist_user_id_mapping['spotify_name'].tolist()\n",
        "exclusion_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# apply the fuzzy search to the artist_user_id_mapping_no_user_id dataframe\n",
        "fuzzy_result = fuzzy_merge_unique_with_auditing(\n",
        "    artist_user_id_mapping_no_user_id, \n",
        "    artist_data, \n",
        "    'spotify_name', \n",
        "    'artist_name', \n",
        "    exclusion_list=exclusion_list, \n",
        "    threshold=91\n",
        ")\n",
        "artist_user_id_mapping_no_user_id = fuzzy_result[0]\n",
        "audit_df = fuzzy_result[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# displaying the artist_user_id_mapping_no_user_id filtered by matched not None\n",
        "artist_user_id_mapping_no_user_id[artist_user_id_mapping_no_user_id['matches'].notna()].head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop the rows with matches as None and extract the artist_name from the matches and store the unmatched rows in a new dataframe\n",
        "artist_user_id_mapping_no_user_id = artist_user_id_mapping_no_user_id.dropna(subset=['matches'])\n",
        "artist_user_id_mapping_no_user_id['artist_name'] = artist_user_id_mapping_no_user_id['matches'].str.extract(r'(.+?) \\(')    \n",
        "artist_user_id_mapping_no_user_id.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# clone the artist_user_id_mapping_no_user_id dataframe to a more descriptive name and remove the NaN value rows of artist_name\n",
        "artist_user_id_mapping_no_user_id_cleaned = artist_user_id_mapping_no_user_id.copy()\n",
        "artist_user_id_mapping_no_user_id_cleaned = artist_user_id_mapping_no_user_id_cleaned.dropna(subset=['artist_name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# populate the user_id column with the user_id from the artist_data\n",
        "artist_user_id_mapping_from_fuzzy = pd.merge(artist_user_id_mapping_no_user_id_cleaned, artist_data, on='artist_name', how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# drop the user_id_x column and rename the user_id_y column to user_id\n",
        "artist_user_id_mapping_from_fuzzy.drop(['user_id_x', 'matches'], axis=1, inplace=True)\n",
        "artist_user_id_mapping_from_fuzzy.rename(columns={'user_id_y': 'user_id'}, inplace=True)\n",
        "artist_user_id_mapping_from_fuzzy.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# append the fuzzy search matches with the artist_user_id_mapping\n",
        "artist_user_id_mapping = pd.concat([artist_user_id_mapping, artist_user_id_mapping_from_fuzzy])\n",
        "artist_user_id_mapping.info()\n",
        "artist_user_id_mapping.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the number of row in the aufit_df\n",
        "audit_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The numbers for the of the rejected rows in the audit align with the artist_user_id_mapping additions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **`audit_df`**: \n",
        "  - This DataFrame stores entries that **did not meet the fuzzy matching criteria**.\n",
        "  - Each row includes:\n",
        "    - **The original value from `df1`** attempted to be matched.\n",
        "    - **The best potential match from `df2`**, despite not meeting the threshold.\n",
        "    - **The highest score** achieved, which was below the threshold.\n",
        "  - **Purpose**: Useful for auditing purposes, allowing for review and analysis of cases where the fuzzy matching process failed to find a sufficient match, aiding in identifying potential improvements in matching criteria or data preprocessing.\n",
        "\n",
        "\n",
        "- **`artist_user_id_mapping`**: \n",
        "  - This DataFrame contains rows that were **successfully matched**, where the matching score met or exceeded the threshold.\n",
        "  - Each matched row includes:\n",
        "    - **All original columns from `df1`** and **additional information from `df2`** depending on the merge configuration.\n",
        "    - **A new 'matches' column** detailing the matched name from `df2` and the score of the match.\n",
        "  - **Purpose**: Crucial for operational purposes as it links records from `df1` and `df2` based on the fuzzy matching criteria, facilitating further processing or analysis that depends on these connected records.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Visualization and Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the data frame `artist_user_id_mapping` for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "artist_user_id_mapping.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the row with artist_name as Alvin Chris\n",
        "alvin_chris = artist_user_id_mapping[artist_user_id_mapping['spotify_name'] == 'alvin chris']\n",
        "alvin_chris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create meaningful visualizations realted to to analyze the popularity of the artists and relating them to genres\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.histplot(artist_user_id_mapping['popularity'], bins=20, kde=True)\n",
        "plt.title('Distribution of Artist Popularity')\n",
        "plt.xlabel('Popularity')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " **Skewed Distribution**\n",
        "\n",
        "- **Right-Skewed Distribution**: The distribution is highly right-skewed, with most artists having low popularity scores.\n",
        "- **High Frequency at Low Popularity**: The peak frequency (around 8000) is at the lowest popularity scores, decreasing sharply as popularity increases.\n",
        "- **Long Tail**: A small number of artists have high popularity scores, indicating a long tail on the right side of the distribution.\n",
        "- **Density Plot**: Confirms the sharp decline and the presence of the long tail.\n",
        "\n",
        " **Statistical Implications**\n",
        "\n",
        "- **Central Tendency**: The mean popularity is higher than the median due to the skewness.\n",
        "- **Dispersion**: High variance and standard deviation due to the wide range and long tail.\n",
        "- **Skewness**: Positive skewness with a longer tail on the right.\n",
        "- **Kurtosis**: High, indicating a peaked distribution with heavy tails.\n",
        "\n",
        " **Contextual Interpretation**\n",
        "\n",
        "- **Popularity Concentration**: Popularity is concentrated among a few artists.\n",
        "- **Emerging Artists**: Indicates a challenging landscape for gaining high popularity.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.kdeplot(artist_user_id_mapping['popularity'], shade=True, color=\"r\")\n",
        "plt.title('Density Plot of Popularity Scores')\n",
        "plt.xlabel('Popularity Score')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**High Peak at Low Popularity**\n",
        "- **Sharp Peak Close to 0**: The plot shows a sharp peak near 0, indicating that a significant proportion of artists or tracks have very low popularity scores.\n",
        "- **Implication**: Most artists or tracks on Spotify receive relatively few listens or are not widely popular among users.\n",
        "\n",
        "**Long Tail Distribution**\n",
        "- **Long Tail**: There is a long tail stretching towards the higher popularity scores, but it is significantly lower in density compared to the peak at the lower end.\n",
        "- **Implication**: While there are artists or tracks with high popularity scores, they are relatively rare compared to the bulk of artists or tracks that have low popularity scores.\n",
        "\n",
        "**Skewness**\n",
        "- **Heavily Skewed**: The distribution is heavily skewed towards the lower end, with a steep decline in density as the popularity score increases.\n",
        "\n",
        "**Majority of Low Popularity**\n",
        "- **Bulk of Content**: The majority of Spotify's content is not highly popular.\n",
        "- **Implication**: This might indicate a wide variety of niche music or new artists who haven't yet gained a substantial following. Reflects Spotify's extensive library, which includes a broad range of genres and artists.\n",
        "\n",
        "**Scarcity of Highly Popular Content**\n",
        "- **Rarity of High Popularity Scores**: The rarity of high popularity scores underscores the competitive nature of the music streaming industry.\n",
        "- **Implication**: Only a small fraction of content achieves high levels of popularity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a scatter plot to show the relationship between popularity and user_id\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.scatterplot(data=artist_user_id_mapping, x='user_id', y='popularity')\n",
        "plt.title('Popularity vs User ID')\n",
        "plt.xlabel('User ID')\n",
        "plt.ylabel('Popularity')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Key Observations\n",
        "\n",
        "- **Clusters**: High concentration of users with low IDs and low popularity.\n",
        "- **Sparsity**: Fewer users with higher IDs.\n",
        "- **Range**: Popularity from 0 to 100, with sporadic high scores.\n",
        "- **Gaps**: Notable gaps between clusters of User IDs.\n",
        "- **Outliers**: High popularity outliers, mostly among low User IDs.\n",
        "\n",
        "Implications\n",
        "\n",
        "- **Skewness**: Distribution skewed towards lower User IDs.\n",
        "- **Dispersion**: High variability in popularity.\n",
        "\n",
        " Interpretation\n",
        "- **Early Adopters**: Lower User IDs likely represent early users.\n",
        "- **Data Gaps**: Potential periods of low activity or missing data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "artist_user_id_mapping['popularity_bin'] = pd.cut(artist_user_id_mapping['popularity'], bins=[0, 20, 40, 60, 80, 100], labels=['0-20', '21-40', '41-60', '61-80', '81-100'])\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(x='popularity_bin', y='spotify_followers', data=artist_user_id_mapping)\n",
        "plt.title('Distribution of Followers Across Popularity Bins')\n",
        "plt.xlabel('Popularity Bins')\n",
        "plt.ylabel('Number of Followers')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**0-20:**\n",
        "- **Central Tendency**: The median number of followers is low, suggesting that less popular artists tend to have fewer followers.\n",
        "- **Variability**: This bin shows a relatively small interquartile range (IQR), indicating less variability in follower counts among these artists.\n",
        "- **Outliers**: Several outliers indicate that there are a few artists in this low popularity bin who have unexpectedly high numbers of followers.\n",
        "\n",
        "**21-40:**\n",
        "- **Central Tendency**: The median followers are higher than in the 0-20 bin, showing an increase in followers with popularity.\n",
        "- **Variability**: The IQR is wider than in the 0-20 bin, suggesting greater variability in the number of followers among artists in this range.\n",
        "- **Outliers**: There are outliers, similar to the 0-20 bin, which may indicate some artists with niche appeal or those who have a legacy or viral impact.\n",
        "\n",
        "**41-60:**\n",
        "- **Central Tendency**: Median followers increase further, consistent with the trend of more followers with higher popularity.\n",
        "- **Variability**: This bin has a notable range of followers, as evidenced by a larger IQR.\n",
        "- **Outliers**: The presence of many outliers at the higher end could suggest that some artists within this popularity range have a substantial impact or specific fan bases that significantly elevate their follower counts.\n",
        "\n",
        "**61-80:**\n",
        "- **Central Tendency**: The median is similar to the 41-60 bin but generally shows a small increase.\n",
        "- **Variability**: The IQR is narrower than in the 41-60 bin, indicating a more consistent follower count among artists in this popularity range.\n",
        "- **Outliers**: Fewer outliers compared to the 41-60 bin, suggesting less extreme variation in follower counts among the more popular artists.\n",
        "\n",
        "**81-100:**\n",
        "- **Central Tendency**: The highest median followers, indicating that the most popular artists have the most followers.\n",
        "- **Variability**: Exhibits a wider IQR, reflecting significant variability in follower counts among top artists.\n",
        "- **Outliers**: Minimal outliers indicate that while there is variability, it is not as extreme as in lower bins.\n",
        "\n",
        "**Insights on Outliers**\n",
        "- **Presence of Outliers**: Outliers across all bins, especially pronounced in the middle bins (41-60), could be influenced by several factors including genre, regional popularity, recent media exposure, or viral content that isn't directly captured by the 'popularity' metric.\n",
        "- **Implication of Outliers**: In bins with high variability and outliers, marketing strategies or engagement techniques could be impacting follower counts beyond what might be expected from their general popularity scores.\n",
        "\n",
        "**Conclusion**\n",
        "The trend across the bins demonstrates a clear positive relationship between Spotify popularity scores and the number of followers, with increasing variability and follower counts as artists become more popular. The outliers suggest that factors other than traditional popularity metrics can significantly influence follower counts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='popularity', y='spotify_followers', data=artist_user_id_mapping)\n",
        "plt.title('Followers vs. Popularity')\n",
        "plt.xlabel('Popularity Score')\n",
        "plt.ylabel('Number of Followers')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Insights on The Scatter Plot**\n",
        "\n",
        "**Correlation**\n",
        "- **Positive Trend**: The positive trend confirms a correlation between popularity and followers, which is consistent with the expectation that more popular artists would have more followers.\n",
        "\n",
        "**Outliers**\n",
        "- **Low Popularity, High Followers**: Some artists with relatively low popularity scores have a high number of followers. \n",
        "- **High Popularity, Low Followers**: Conversely, some artists with high popularity scores have fewer followers than might be expected.\n",
        "- **Possible Reasons**:\n",
        "  - Recent changes in artist popularity not yet reflected in the score.\n",
        "  - Artists with significant niche followings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a column is_genre empty that puts true of false if the spotify genre is an empty list\n",
        "plot_insights = artist_user_id_mapping.copy()\n",
        "plot_insights['is_genre_empty'] = plot_insights['spotify_genre'].apply(lambda x: len(x) == 0)\n",
        "plot_insights.groupby('is_genre_empty').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Majority Missing Genre**\n",
        "- **High Count**: The \"True\" category has a significantly higher count, indicating that a majority of artists in the dataset have missing genre information.\n",
        "- **Prevalent Issue**: The bar for the \"True\" category extends past 8000, highlighting the widespread issue of missing data in this field.\n",
        "\n",
        "**Minority with Genre Data**\n",
        "- **Low Count**: The \"False\" category, representing artists with available genre information, has a much smaller count, around 2000.\n",
        "- **Data Availability**: This suggests that only a minority of the dataset has genre information filled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "artist_user_id_mapping['popularity_bin'] = pd.cut(artist_user_id_mapping['popularity'], bins=[0, 20, 40, 60, 80, 100], labels=['0-20', '21-40', '41-60', '61-80', '81-100'])\n",
        "\n",
        "# Identify rows where the spotify_genre list is empty\n",
        "artist_user_id_mapping['is_genre_empty'] = artist_user_id_mapping['spotify_genre'].apply(lambda x: len(x) == 0)\n",
        "\n",
        "# Group by popularity_bin and count the number of empty genres in each bin\n",
        "empty_genre_counts = artist_user_id_mapping.groupby('popularity_bin')['is_genre_empty'].sum()\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "empty_genre_counts.plot(kind='bar', color='skyblue')\n",
        "plt.title('Count of Empty Spotify Genres by Popularity Bin')\n",
        "plt.xlabel('Popularity Bin')\n",
        "plt.ylabel('Number of Artists with Empty Genre')\n",
        "plt.xticks(rotation=0)  # Keeps the labels horizontal\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Dominance of Lower Popularity Bins**\n",
        "- **High Count in 0-20 Bin**: The largest count of artists with missing genre information is overwhelmingly in the lowest popularity bin (0-20).\n",
        "- **Implication**: This suggests that lesser-known or emerging artists are more likely to lack genre tags in the dataset.\n",
        "\n",
        "**Significant Drop in Missing Data as Popularity Increases**\n",
        "- **Steep Decline**: There is a steep decline in the number of artists with missing genre information as popularity increases.\n",
        "- **Trend Continuation**: The 21-40 bin shows a significantly lower count compared to the 0-20 bin, and this trend continues diminishing as popularity increases.\n",
        "\n",
        "**Minimal Missing Data Among Highly Popular Artists**\n",
        "- **High Popularity Bins**: For artists in the highest popularity bins (41-60, 61-80, and 81-100), the absence of genre data becomes increasingly rare.\n",
        "- **Implication**: This suggests that more popular artists are more likely to have complete genre metadata.\n",
        "\n",
        "**Correlation Between Data Completeness and Popularity**\n",
        "- **Distribution Insight**: The distribution indicates a correlation between the completeness of genre information and artist popularity.\n",
        "- **More Robust Profiles**: More popular artists, likely having more robust profiles and more extensive listenership, tend to have more complete data.\n",
        "\n",
        "**Implications for Data Analysis and Application**\n",
        "- **Challenges in Analysis**:\n",
        "  - The lack of genre information for artists in lower popularity bins may present challenges for performing certain types of analysis.\n",
        "- **Potential Affected Areas**:\n",
        "  - **Market Segmentation**: Difficulty in segmenting markets accurately.\n",
        "  - **Trend Analysis**: Potential issues in identifying and analyzing trends.\n",
        "  - **Recommendation Systems**: Challenges in providing accurate recommendations that rely on genre classifications."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "artist_user_id_mapping['popularity_bin'] = pd.cut(artist_user_id_mapping['popularity'], bins=[0, 20, 40, 60, 80, 100], labels=['0-20', '21-40', '41-60', '61-80', '81-100'])\n",
        "\n",
        "# Group by popularity_bin and calculate the sum of followers in each bin\n",
        "followers_sum = artist_user_id_mapping.groupby('popularity_bin')['spotify_followers'].sum()\n",
        "\n",
        "# Plotting the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "followers_sum.plot(kind='bar', color='green')\n",
        "plt.title('Sum of Spotify Followers by Popularity Bin')\n",
        "plt.xlabel('Popularity Bin')\n",
        "plt.ylabel('Total Number of Followers')\n",
        "plt.xticks(rotation=0)  # Keeps the labels horizontal\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Dominant Higher Popularity Bin**\n",
        "- **High Follower Count in 81-100 Bin**: The bin with artists having a popularity score between 81-100 has a significantly higher total number of followers compared to other bins.\n",
        "- **Disproportionate Influence**: This indicates that the most popular artists on Spotify have a disproportionately large follower base.\n",
        "\n",
        "**Progressive Increase**\n",
        "- **Increasing Followers with Popularity**: There's a progressive increase in the total number of followers as the popularity score increases.\n",
        "- **Notable Comparison**: This increase is most noticeable when comparing the 0-20 bin to the 81-100 bin.\n",
        "\n",
        "**Comparatively Lower Followers in Mid-range Bins**\n",
        "- **41-60 and 61-80 Bins**: These mid-range bins, while having more followers than the lower bins, still hold considerably fewer followers than the highest bin.\n",
        "- **Substantial Jump**: This suggests that follower counts significantly jump as artists reach the top tier of popularity.\n",
        "\n",
        "**Impact of High Popularity**\n",
        "- **Overwhelming Influence**: Artists in the highest popularity bin have an overwhelming influence in terms of follower counts.\n",
        "- **Engagement Concentration**: A few top artists might account for a large portion of engagements on the platform.\n",
        "\n",
        "**Marketing and Promotional Focus**\n",
        "- **High Returns**: For marketers and platform algorithms, focusing on artists in the highest bin might offer the greatest returns in terms of audience reach and engagement.\n",
        "- **Nurturing Potential**: There is potential value in nurturing artists in the lower bins as they progress in popularity.\n",
        "\n",
        "**Strategic Implications**\n",
        "- **Content and Marketing Strategy**: Understanding the distribution of followers across popularity bins can help Spotify and artists strategize their content and marketing efforts.\n",
        "- **Targeted Promotions**: Targeting promotions to help artists move from the 61-80 bin to the 81-100 bin could significantly increase their visibility and following.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this reason based on all the intuitions and processing, the data should be enhanced in terms of genre analysis to be able to better have insights for artistist and potentially promote them better based on their genres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Genre Matching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# merge the artist_user_id_mapping with the user_genre on the user_id and saving the result to a new dataframe\n",
        "tag_artist_user_id_mapping = pd.merge(user_genre, artist_user_id_mapping, on='user_id', how='inner')\n",
        "tag_artist_user_id_mapping.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Jacard's Similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def jaccard_similarity(list1, list2):\n",
        "    set1 = set(list1)\n",
        "    set2 = set(list2)\n",
        "    intersection = len(set1.intersection(set2))\n",
        "    union = len(set1.union(set2))\n",
        "    return intersection / union if union != 0 else 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# clone the intiial dataframe to a new dataframe for the similarity approaches\n",
        "confidence_mapper = tag_artist_user_id_mapping.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply the function to each row in the DataFrame\n",
        "confidence_mapper['jaccard_similarity'] = confidence_mapper.apply(lambda row: jaccard_similarity(row['genre'], row['spotify_genre']), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sort by jaccard_similarity in descending order\n",
        "confidence_mapper.sort_values(by='jaccard_similarity', ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# the distinct values of the jaccard_similarity\n",
        "confidence_mapper['jaccard_similarity'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We couldn't derive any insights concerning the relatetness of the `local genres` from the `local genre` csvs, and the `Jaccard's` similarity was always 0.\n",
        "\n",
        "This is due to the nature of the `Jaccard` algorithm in that it takes in the set values and compares based on strictly the correct characters.\n",
        "\n",
        "Example : `Hip Hop` will not relate to `Hip-Hop` although they are the same genre.\n",
        "After some visual checking, it is evident that the `local genres` are as well mismatched."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To get a more comprehensive solution, a context aware approach should be taken to understand the relatedness of the genres. \n",
        "\n",
        "Using `vector embeddings` and `cosine similarity`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vector Embeddings and Cosine Similarity Spacy NLP Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "# Load an English NLP model from spaCy\n",
        "nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "def genre_similarity(genres1, genres2, model):\n",
        "    vec1 = [model(genre.replace('_', ' ')).vector for genre in genres1]\n",
        "    vec2 = [model(genre.replace('_', ' ')).vector for genre in genres2]\n",
        "    if vec1 and vec2:\n",
        "        vec1_mean = sum(vec1) / len(vec1)\n",
        "        vec2_mean = sum(vec2) / len(vec2)\n",
        "        return cosine_similarity([vec1_mean], [vec2_mean])[0][0]\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "confidence_mapper['cosine_similarity'] = confidence_mapper.apply(\n",
        "    lambda row: genre_similarity(row['genre'], row['spotify_genre'], nlp), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# sort by cosine_similarity in descending order\n",
        "confidence_mapper.sort_values(by='cosine_similarity', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is evident that there exists some relations between the `spotify genre` and the `local genre` based on context.\n",
        "\n",
        "How reliable is the `local Genre` after we had established that the `local data` had `id` indexing issues?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get all the values of the cosine_similarity where the spotify_genre is not empty\n",
        "percentage_hits = confidence_mapper[confidence_mapper['spotify_genre'].apply(len) > 0]['cosine_similarity'].unique()\n",
        "percentage_hits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the percentage of the of values where the cosine_similarity is greater than 0.8\n",
        "percentage_hits = confidence_mapper[confidence_mapper['cosine_similarity'] > 0.8].shape[0] / confidence_mapper.shape[0] * 100\n",
        "percentage_hits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `percentage_hits` shows a value of `0.33229282046118214` for a confidence score of `greater than 0.8` which still is a not that selective of a threshold.\n",
        "\n",
        "This shows that the local genre basically more or less has a `0.3%` chance to have partially aligning genres with the source of truth `spotify_genre`.\n",
        "\n",
        "An alternative `source of data` fulfilling the genres should be considered at this point. \n",
        "\n",
        "`Data Augmentation` might be needed to address this kind of issue."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Web-Scrapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After some consideration, data augmentation is necessary to store relevant data to save valid and valuable data to the columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After some research, there is a website called https://obsessions.groover.co/artists/artists-list/ which may have upcoming groover artists or Groover clients which we can extract the `genre` from using `web-scrapping` techniques\n",
        "\n",
        "After further inspection of the `website`, it is evident that this website contains potentially clients of `Groover` and might be a good source to `scrape` the `artist genres`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://obsessions.groover.co/artists-list/'\n",
        "\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "artist_list = soup.find('ul', id='index-9575')\n",
        "\n",
        "artists = []\n",
        "for li in artist_list.find_all('li'):\n",
        "    a_tag = li.find('a')\n",
        "    if a_tag:\n",
        "        artist_name = a_tag.text.strip()\n",
        "        artist_link = a_tag['href']\n",
        "        artists.append({'artist_name': artist_name, 'artist_link': artist_link})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_artists = pd.DataFrame(artists)\n",
        "df_artists.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This approach provided valuable insights in that the genre of the artists is showing from a `semi-trusted` source, since these artisits should be `Groover` clients. \n",
        "\n",
        "Based on `GDPR` rules and `lawful/ethical` concerns, we did not have any legal authority to scrape this website and thus did not proceed with this although this website had more than `50 artists` which matched with our databse, which could scrapped given the right permissions.\n",
        "\n",
        "![Example Image](../images/scrapped.png \"This is an example image\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## External Apis and Sources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- **Research Focus**: Conducted extensive research on music-related platforms that provide artist data based on name input.\n",
        "- **Main Issue**: \n",
        "  - Receiving multiple, sometimes hundreds, of hits for a single artist name.\n",
        "  - Difficulty in differentiating artists, especially those with low popularity, due to limited data.\n",
        "\n",
        " Targeted Platforms\n",
        "\n",
        "- **Anghami**\n",
        "- **Deezer**\n",
        "- **Last.fm**\n",
        "- **SoundCloud**\n",
        "- **YouTube Music**\n",
        "\n",
        " Task Focus\n",
        "\n",
        "- **Artist Selection**:\n",
        "  - Focus on artists with low popularity as well as those with slightly higher popularity.\n",
        "  - Based on the distribution, these groups require the most enrichment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Deezer Api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "def search_artist_genre(artist_name):\n",
        "    base_url = \"https://api.deezer.com/search/artist\"\n",
        "    query_params = {'q': artist_name}\n",
        "    response = requests.get(base_url, params=query_params)\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        data = response.json()['data']\n",
        "        if data:\n",
        "            artist_id = data[0]['id']  # Get the ID of the first matching artist\n",
        "            artist_details_url = f\"https://api.deezer.com/artist/{artist_id}\"\n",
        "            details_response = requests.get(artist_details_url)\n",
        "            \n",
        "            if details_response.status_code == 200:\n",
        "                details_data = details_response.json()\n",
        "                print(\"Artist Name:\", details_data['name'])\n",
        "                print(details_data)\n",
        "            else:\n",
        "                print(\"Failed to retrieve artist details\")\n",
        "        else:\n",
        "            print(\"No artist found with that name\")\n",
        "    else:\n",
        "        print(\"Failed to search for artist\")\n",
        "\n",
        "artist_name = \"drake\"\n",
        "search_artist_genre(artist_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The issue with the Deezer api is that it does not return the artist genre, but performs well in identifying the artists.\n",
        "The problem is that the lesser known artists did not do well on the search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Anghami, SoundCloud, and YoutubeMusic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For Anghami and SoundCloud and YoutubeMusic I have requested api keys for developer access, but unfortunately the setup is still not ready.\n",
        "The Anghami Website has the network data encrypted as well"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Last.FM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Last.FM provides good infromation and I was able to get the exact missing data I needed, and the good thing about Last.FM is that it only returns the top hit for any specific artist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Proposed Approach for Data Enrichment**\n",
        "\n",
        "\n",
        "**Step 1: Identify Target Artists**\n",
        "- **Selection Criteria**:\n",
        "  - Focusing on the most popular artists from the first couple of popularity bins since they are the most probable clients and need the most boosting\n",
        "  - Higher follower counts and popularity increase the likelihood of getting hits on third-party APIs.\n",
        "\n",
        "**Step 2: Enrichment Process**\n",
        "- **Correlation Insight**:\n",
        "  - Popularity and genre definition are correlated, making popular artists ideal candidates for initial enrichment which will be taken as a first testing phase.\n",
        "\n",
        "**Step 3: Evaluate Initial Enrichment**\n",
        "- **Response Quality**:\n",
        "  - Assessing the quality of responses from the third-party API for genre enrichment by cross checking the genres with the ones already given by the spotify api\n",
        "\n",
        "**Step 4: Test Accuracy and Relevancy**\n",
        "- **Cross-Check with Spotify Data**:\n",
        "  - Test the accuracy and relevancy of the enriched genres against Spotify data that already has genre information.\n",
        "  - Using this cross checking technique, the effectiveness of the enrichment may be evaluated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the rows where artist_user_id_mapping is 0-20, 21-40 and 41-60 and where the spotify_genre is empty array\n",
        "low_popularity = artist_user_id_mapping[(artist_user_id_mapping['popularity_bin'] == '0-20') & (artist_user_id_mapping['is_genre_empty'])]\n",
        "slightly_moderate = artist_user_id_mapping[(artist_user_id_mapping['popularity_bin'] == '21-40') & (artist_user_id_mapping['is_genre_empty'])]\n",
        "moderate = artist_user_id_mapping[(artist_user_id_mapping['popularity_bin'] == '41-60') & (artist_user_id_mapping['is_genre_empty'])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# concatenate the three dataframes\n",
        "empty_genre_artists = pd.concat([low_popularity, slightly_moderate, moderate])\n",
        "empty_genre_artists.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the top 400 artists from every popularity bin based on the number of followers and the popularity score\n",
        "top_artists = empty_genre_artists.groupby('popularity_bin').apply(lambda x: x.nlargest(400, 'spotify_followers')).reset_index(drop=True)\n",
        "top_artists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "API_KEY = os.getenv('API_KEY')\n",
        "SHARED_SECRET = os.getenv('SHARED_SECRET')\n",
        "\n",
        "def get_genres(artist_name, api_key):\n",
        "    \"\"\"Fetch genres for a given artist from the Last.fm API.\"\"\"\n",
        "    print(f\"Fetching genres for artist: {artist_name}\")\n",
        "    url = \"http://ws.audioscrobbler.com/2.0/\"\n",
        "    params = {\n",
        "        'method': 'artist.getinfo',\n",
        "        'artist': artist_name,\n",
        "        'api_key': api_key,\n",
        "        'format': 'json'\n",
        "    }\n",
        "    try:\n",
        "        response = requests.get(url, params=params)\n",
        "        response.raise_for_status() \n",
        "        data = response.json()\n",
        "        genres = [tag['name'] for tag in data['artist']['tags']['tag']]\n",
        "        print(f\"Genres found for {artist_name}: {genres}\")\n",
        "        return genres\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        print(f\"HTTP Error for artist {artist_name}: {str(e)}\")\n",
        "        return []\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Request Error for artist {artist_name}: {str(e)}\")\n",
        "        return []\n",
        "    except KeyError:\n",
        "        print(f\"No genre data available for artist {artist_name}\")\n",
        "        return []\n",
        "\n",
        "def update_artist_genres(df, api_key, bypass_check=False):\n",
        "    \"\"\"Update the given DataFrame with genres from Last.fm.\"\"\"\n",
        "    if 'lastfm_genres' not in df.columns:\n",
        "        df['lastfm_genres'] = None\n",
        "\n",
        "    audit_logs_columns = ['user_id', 'spotify_id', 'artist_name', 'lastfm_genres', 'spotify_genre', 'source']\n",
        "    audit_logs = pd.DataFrame(columns=audit_logs_columns)\n",
        "\n",
        "    total_iterations = len(df)\n",
        "    successful_hits = 0\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        if not row['spotify_genre'] or bypass_check:  \n",
        "            print(f\"Spotify genres are empty for artist {row['artist_name']}, updating from Last.fm...\")\n",
        "            last_fm_genres = get_genres(row['artist_name'], api_key)\n",
        "            if last_fm_genres or bypass_check: \n",
        "                df.at[index, 'lastfm_genres'] = last_fm_genres\n",
        "                print(f\"Updated genres for {row['artist_name']}: {last_fm_genres}\")\n",
        "                new_log = pd.DataFrame([row.copy()])\n",
        "                new_log['lastfm_genres'] = [last_fm_genres]\n",
        "                audit_logs = pd.concat([audit_logs, new_log], ignore_index=True)\n",
        "                successful_hits += 1\n",
        "            else:\n",
        "                print(f\"No genres found for {row['artist_name']} to update.\")\n",
        "        else:\n",
        "            print(f\"Genres already present for {row['artist_name']}\")\n",
        "        time.sleep(1)\n",
        "\n",
        "    print(f\"Total iterations: {total_iterations}\")\n",
        "    print(f\"Total successful hits: {successful_hits} out of {total_iterations}\")\n",
        "\n",
        "    return df, audit_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Update genres for the top\n",
        "updated_df, audit_logs_df = update_artist_genres(top_artists, API_KEY)\n",
        "print(\"DataFrame has been updated and saved. Audit logs recorded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "updated_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LastFm seems to be a valuable and descent third party external source to populate our genre data after closely analyzing the data by inspection, the data genre seem to match-up.\n",
        "\n",
        "I need to find a more reliable metric to be able to assess wether the LastFm source is correct or descriptive, or aligns with the truth.\n",
        "\n",
        "For this reason I will take the most popular aritist that have the `spotify_genre` defined to cross check based on the newly acquired data.\n",
        "\n",
        "As a conclusion I will simulate testing data for this cross-checking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the top 100 rows from the last bin from artist_user_id_mapping\n",
        "top_artists_test = artist_user_id_mapping.nlargest(100, 'spotify_followers')\n",
        "top_artists_test.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "updated_df_test, audit_logs_df = update_artist_genres(top_artists_test, API_KEY, bypass_check=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "updated_df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# put spotify_genres to lowercase and put the lastfm_genres to lowercase\n",
        "updated_df_test['spotify_genre'] = updated_df_test['spotify_genre'].apply(lambda x: [genre.lower() for genre in x])\n",
        "updated_df_test['lastfm_genres'] = updated_df_test['lastfm_genres'].apply(lambda x: [genre.lower() for genre in x] if x is not None else [])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "updated_df_test['cosine_similarity'] = updated_df_test.apply(lambda row: genre_similarity(row['spotify_genre'], row['lastfm_genres'], nlp), axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "percentage_hits = updated_df_test[updated_df_test['cosine_similarity'] > 0.6].shape[0] / updated_df_test.shape[0] * 100\n",
        "percentage_hits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The results from the Last.FM seem very promissing and as a general idea are worth taking a chance and look into to enhance the data using it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# put the distinct genres from spotify_genre and lastfm_genres in dataframes\n",
        "spotify_genres = updated_df_test['spotify_genre'].explode().unique()\n",
        "lastfm_genres = updated_df_test['lastfm_genres'].explode().unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot the venn diagram of the spotify_genres and lastfm_genres\n",
        "plt.figure(figsize=(10, 6))\n",
        "venn2([set(spotify_genres), set(lastfm_genres)], set_labels=('Spotify Genres', 'Last.fm Genres'))\n",
        "plt.title('Comparison of Spotify and Last.fm Genres')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Analysis of Last.fm and Spotify Genre Similarity**\n",
        "\n",
        "This analysis indicates that the genre space on **Last.fm** is broader than that of **Spotify**, with both platforms sharing some genres in common. However, based on the relatedness score, the genres from **Spotify** and **Last.fm** are contextually related.\n",
        "\n",
        "The genres on **Last.fm** are more specific compared to **Spotify's** genres. It is advisable not to use multiple **Last.fm** genre selections for a single genre; further processing is needed to refine the **Last.fm** genres.\n",
        "\n",
        "The test case, which applied **Spotify** genres to very famous artists, does not provide a definitive or concrete analysis. Rather, it serves as a preliminary exploration of the potential applications of this genre-mapping approach.\n",
        "\n",
        "**Key Findings**\n",
        "- **Genre Similarity**:\n",
        "  - The Last.fm genres are not very different from the trusted Spotify genres and even share common genres.\n",
        "  - Based on cosine similarity, the unique Spotify genres have contextual relevance to the Last.fm genres.\n",
        "\n",
        "**Data Enrichment**\n",
        "\n",
        "- **Relevance**:\n",
        "  - The contextual relevance of Last.fm genres indicates they are a viable option to enrich the dataset, particularly for artists in the lower popularity bins with missing genre information.\n",
        "\n",
        "- **Initial Enrichment**:\n",
        "  - Using Last.fm genres is a good starting point to enrich the data.\n",
        "  - It Provides a foundation that can be iteratively improved and enhanced over time.\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "  - Even if the genres are not 100% accurate, they provide a valuable starting point for data enrichment.\n",
        "  - Further iterations and enhancements can improve the accuracy and completeness of the genre data.\n",
        "  - I will augment the data of all the artisits that do not have the `spotify_genre` and take the `last_fm` gathered genre.\n",
        "  - I will then create a column `final_genre` that has the newly augmented and adapted data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fully_enriched, audit_logs_df = update_artist_genres(tag_artist_user_id_mapping, API_KEY, bypass_check=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a column in the fully_enriched dataframe that stores the value of the the final genre.\n",
        "fully_enriched['final_genre'] = fully_enriched.apply(lambda row: row['spotify_genre'] if row['spotify_genre'] and len(row['spotify_genre']) > 0 else row['lastfm_genres'] if row['lastfm_genres'] and len(row['lastfm_genres']) > 0 else [] if not row['spotify_genre'] and not row['lastfm_genres'] else ['UNKNOWN'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fully_enriched.to_csv(f\"{EXTRACT_FOLDER}fully_enriched.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fully_enriched.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "unique_genres = fully_enriched['final_genre'].explode().unique()\n",
        "unique_genres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After viewing the unique genres generated, it is essential right now to cluster or use a singular version of very related genres both phonetically and contextually with the following techniques to solve issues addressing `Clustering Challenges for Genre Consistency`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### K-Means Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# take the unique values of the final_genre column\n",
        "unique_genres = [genre for genre in unique_genres if isinstance(genre, str)]\n",
        "unique_genres = [genre.lower() for genre in unique_genres]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalize the final_genre: lowercase and strip whitespace\n",
        "fully_enriched['final_genre'] = fully_enriched['final_genre'].apply(lambda x: [genre.lower().strip() for genre in x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for unique genres after normalization\n",
        "pd.DataFrame(unique_genres, columns=['genre']).to_csv(f\"{EXTRACT_FOLDER}unique_genres.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Using TF-IDF to convert genre names into a matrix of TF-IDF features.\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = tfidf_vectorizer.fit_transform(unique_genres)\n",
        "\n",
        "# Applying K-Means clustering to find clusters\n",
        "# Choosing a somewhat arbitrary number of clusters for demonstration; this may need adjustment.\n",
        "num_clusters = 50\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=0).fit(X)\n",
        "\n",
        "# Mapping each unique genre to its cluster\n",
        "genre_clusters = {genre: f\"cluster_{label}\" for genre, label in zip(unique_genres, kmeans.labels_)}\n",
        "\n",
        "# Display a subset of genre to cluster mappings for review\n",
        "list(genre_clusters.items())[:50]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Addressing Challenges for K-Means**\n",
        "\n",
        "**Challenge**\n",
        "- **Dynamic Nature of Clusters**:\n",
        "  - Having the right number of clusters is crucial.\n",
        "  - The clustering approach results in an undetermined list that can expand or shrink with new data, making it unstable.\n",
        "\n",
        "For this reason, a more dynamic technique should be used. I will use a similarity approach based on the Levenshtein distance to group similar genres and assign one tag for them.\n",
        "\n",
        "My new more dynamic approach not related to pre-defined clusters will include\n",
        "\n",
        "\n",
        "1. **Data Preparation**:\n",
        "   - Compile a comprehensive dataset of genres from all sources.\n",
        "   - Preprocess genre names to standardize them (e.g., converting to lowercase, removing special characters).\n",
        "\n",
        "2. **Calculate Similarity**:\n",
        "   - Use Levenshtein distance to measure the similarity between genre names.\n",
        "   - Create a similarity matrix where each genre is compared with every other genre.\n",
        "\n",
        "3. **Grouping Similar Genres**:\n",
        "   - Group genres with high similarity scores together.\n",
        "   - Assign a single representative tag to each group based on the most common or relevant genre name.\n",
        "\n",
        "4. **Dynamic Assignment**:\n",
        "   - As new data is added, dynamically evaluate and integrate new genres into existing groups.\n",
        "   - Ensure that the grouping and tagging process remains consistent over time.\n",
        "\n",
        "5. **Evaluation and Adjustment**:\n",
        "   - Regularly review the genre groups to ensure they accurately represent the genre landscape.\n",
        "   - Adjust the grouping criteria and representative tags as needed to improve accuracy and relevance.\n",
        "\n",
        "### Conclusion\n",
        "- **Stability and Consistency**:\n",
        "  - By using a similarity-based approach with Levenshtein distance, achieve stable and consistent genre classification.\n",
        "  - This method allows for a dynamic yet controlled evolution of genre groups, maintaining relevance as new data is integrated.\n",
        "  - It also helps in minimizing discrepancies and ensures that the genre list remains manageable, reducing the complexity of managing a growing and evolving dataset.\n",
        "  - This approach provides a scalable solution to handle the influx of new genres and maintain the integrity of the genre classification system over time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fuzzy Clustering using Levenshtein distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def find_similar_genres(genres, threshold=80):\n",
        "    similar_groups = []\n",
        "    used_genres = set()\n",
        "    \n",
        "    for genre in genres:\n",
        "        if genre not in used_genres:\n",
        "            matches = process.extract(genre, genres, scorer=fuzz.token_sort_ratio)\n",
        "            similar = [match[0] for match in matches if match[1] >= threshold]\n",
        "            similar_groups.append(similar)\n",
        "            used_genres.update(similar)\n",
        "    \n",
        "    return similar_groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "similar_groups = find_similar_genres(unique_genres, threshold=85)\n",
        "similar_groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "genre_dict = {}\n",
        "for sublist in similar_groups:\n",
        "    if len(sublist) > 1:\n",
        "        for genre in sublist:\n",
        "            genre_dict[genre] = sublist[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transform_genres(genre_list, genre_dict):\n",
        "    if genre_list is None:\n",
        "        return genre_list\n",
        "    return [genre_dict.get(genre, genre) for genre in genre_list]\n",
        "\n",
        "# Apply the transformation to the 'final_genre' column\n",
        "fully_enriched['final_genre'] = fully_enriched['final_genre'].apply(lambda x: transform_genres(x, genre_dict))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fully_enriched.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#  fully_enriched['final_genre'] if [] put in [\"unkown\"]\n",
        "fully_enriched['final_genre'] = fully_enriched['final_genre'].apply(lambda x: x if x else ['unknown'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the unique values of the fully_enriched dataframe and put in a df with the frequency\n",
        "exploded_genres = fully_enriched['final_genre'].explode()\n",
        "lowercase_genres = exploded_genres.str.lower()\n",
        "filtered_genres = lowercase_genres[lowercase_genres != 'unknown']\n",
        "genre_counts = filtered_genres.value_counts().reset_index()\n",
        "genre_counts.columns = ['genre', 'frequency']\n",
        "\n",
        "top_20_genres = genre_counts.sort_values('frequency', ascending=False).head(20)\n",
        "\n",
        "colors = plt.cm.Paired(range(len(top_20_genres)))  # Adjust the range to match the number of genres after filtering\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "wedges, texts, autotexts = plt.pie(top_20_genres['frequency'], labels=top_20_genres['genre'], \n",
        "                                   autopct='%1.1f%%', colors=colors, textprops={'color':\"black\"})\n",
        "\n",
        "plt.setp(autotexts, size=8, weight=\"bold\")\n",
        "plt.setp(texts, size=8)\n",
        "plt.title('Top 20 Music Genres by Frequency (excluding unknown)', fontsize=16)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the `Levenshtein distance Fuzzy search` I was able to group similar genres together.\n",
        "\n",
        "I have applied the transformation on my data and now have consistent genres all over my data.\n",
        "\n",
        "A unique list of the genres is now generated, however to refine these even more, more complex techniques can be used."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Other Potential Solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "\n",
        "- **Auto-Clustering Algorithm**:\n",
        "  - Implement an auto-clustering algorithm.\n",
        "  - Use Last.fm genres whenever Spotify genres are unavailable.\n",
        "\n",
        "- **Clustering Algorithm with Triplet Loss**:\n",
        "  - Apply a clustering algorithm in conjunction with a triplet loss function.\n",
        "  - Align genres and entities effectively to relate the genres.\n",
        "\n",
        "- **LLM-Powered Approach**:\n",
        "  - Utilize a Large Language Model (LLM) to understand the content.\n",
        "  - Use a list of unique Spotify genres to contextually map Last.fm genres to Spotify genres.\n",
        "  - If the LLM does not detect any contextual match, add new genres to the initial list.\n",
        "  - Newly added genres will be classified as the closest detected general genre.\n",
        "\n",
        "- **Enhanced Data Collection**:\n",
        "  - Gather more data to define the genre more accurately.\n",
        "  - If available, analyze a list of the artist's songs.\n",
        "  - Use a spectrogram detection algorithm to determine the genre based on the analysis of all the artist's songs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Advanced Genre Derivation Techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since there exists artists with an empty genre even after the enrichement with the LastFM data. A large portion of the artist still have an empty genre.\n",
        "\n",
        "To overcome this since the artist data is very limited, the spotify api supplies the ids and the links to the artist's songs and releases.\n",
        "\n",
        "Using these songs, I can derive the genre of the song using a music genre classification model based on spectogram relatedness.\n",
        "\n",
        "The only problem in this case is I need the actual song footage as mp3 or others ot be able to process them and spotify does not have this option available.\n",
        "\n",
        "We will need to contact a music label to be able to get the data so we can derive the contextual genre from it.\n",
        "\n",
        "I will be using a pre-trained transformer based model for this task which was trained to identify song genres based on Free Music Archive(FMA) and  GTZAN Dataset.\n",
        "\n",
        "My insights were based on this research paper https://www.researchgate.net/publication/224251903_Music_genre_recognition_using_spectrograms and many others"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Music Genre Classification Based on Spectrogram Analysis\n",
        "\n",
        "**Potential Approach for Remaining Artists**\n",
        "\n",
        "- **Song Collection**:\n",
        "  - Collect a list of songs from the remaining artists.\n",
        "  - Source the songs from music labels or an open-source music provider.\n",
        "\n",
        "- **Spectrogram Transformation**:\n",
        "  - Use machine learning techniques to transform the MP3 files into spectrogram images.\n",
        "\n",
        "- **Genre Classification**:\n",
        "  - Analyze the spectrogram images to classify the songs into one or more genres.\n",
        "  - Assign a genre or a range of genres to each artist based on the spectrogram analysis.\n",
        "\n",
        "This way by analyzing the actual song data from the artists, the derivation of the genre will be easier for more niche and upcoming artists.\n",
        "Features such as `BBM` `Cadence` `pauses and pitch` are key features that will help in identifying different genres\n",
        "\n",
        "In this example I have taken a song and inserted it into a transfer learning model based on `transformers`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get artist's tracks using Spotify ID\n",
        "artist_id = '6m8keKnv7yR5UcUpCEosO5'\n",
        "results = sp.artist_top_tracks(artist_id)\n",
        "\n",
        "# Extract track names\n",
        "track_names = [track['name'] for track in results['tracks']]\n",
        "\n",
        "print(track_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "audio_path = os.path.join(root_dir, \"assets/38-Michael-Riepen-Happy-Birthday(chosic.com).mp3\")\n",
        "y, sr = librosa.load(audio_path, sr=None)\n",
        "\n",
        "S = librosa.feature.melspectrogram(y=y, sr=sr)\n",
        "\n",
        "S_dB = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(S_dB, sr=sr, x_axis='time', y_axis='mel')\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Mel-frequency spectrogram')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "![Music Genre Prediction](../images/music-genre-prediction.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SQL Query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Overall Table Structure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The table structures will be exactly the same as the structure provided to cater for a better pipeline prediction and greater scalability.\n",
        "\n",
        "**`music_data` Table**\n",
        "\n",
        "- `user_id` (INT): An integer representing the unique identifier of a user.\n",
        "- `spotify_id` (TEXT): A text string storing the Spotify ID associated with a music track.\n",
        "- `popularity` (INT): An integer value indicating the popularity of the track.\n",
        "- `spotify_followers` (INT): An integer showing the number of Spotify followers for the artist.\n",
        "\n",
        "**`artist_data` Table**\n",
        "\n",
        "- `user_id` (INT): The user ID linking to the music data.\n",
        "- `spotify_name` (TEXT): The name of the artist on Spotify.\n",
        "- `artist_name` (TEXT): The actual name of the artist.\n",
        "\n",
        "**`tag_artist_data` Table**\n",
        "\n",
        "- `user_id` (INT): The user ID, connecting this table to the other artist-related data.\n",
        "- `tag_id` (INT): A unique identifier for a tag, which correlates to a genre.\n",
        "\n",
        "**`tag_genre_data` Table**\n",
        "\n",
        "- `genre` (TEXT): The name of the genre.\n",
        "- `tag_id` (INT): The unique identifier for the genre, used in tagging artists with genres."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Assumptions Based on Business Model\n",
        "\n",
        "### Assumption 1: Use Only Rows with Defined Spotify Genre Data\n",
        "- **Pros**:\n",
        "  - Data from a single source ensures consistent genre typing throughout.\n",
        "- **Cons**:\n",
        "  - Limited data availability, covering roughly 12-15% of the initial dataset.\n",
        "\n",
        "### Assumption 2: Use Last.fm Genre Data When Spotify Genre is Empty\n",
        "- **Pros**:\n",
        "  - Expands the dataset, allowing for more data rows to be utilized.\n",
        "  - Almost 40% more rows were enriched using this approach and may be a good starting point to enhance on it\n",
        "- **Cons**:\n",
        "  - Managing two genre lists can be challenging.\n",
        "  - Accuracy needs to be thoroughly evaluated and scored to determine its reliability.\n",
        "\n",
        "### Conclusion\n",
        "- If the business logic requires highly reliable data and can afford a smaller dataset, Assumption 1 is preferable.\n",
        "- If the business logic needs a larger dataset that can be refined iteratively, Assumption 2 may be more suitable.\n",
        "\n",
        "Both approaches will be taken into consideration for demonstration purposes. However, the main issue to be addressed is supplying genres to lower popularity artists, as they might represent the most probable potential clients.\n",
        "If the artisits had more identifying data, searching and augmenting the data would be easier task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "\n",
        "def create_table_music_data(conn):\n",
        "    query = '''\n",
        "        CREATE TABLE IF NOT EXISTS music_data (\n",
        "            user_id INT,\n",
        "            spotify_id TEXT,\n",
        "            popularity INT,\n",
        "            spotify_followers INT\n",
        "        )\n",
        "    '''\n",
        "    conn.execute(query)\n",
        "    logging.info(\"Table music_data created or verified.\")\n",
        "\n",
        "def create_table_artist_data(conn):\n",
        "    query = '''\n",
        "        CREATE TABLE IF NOT EXISTS artist_data (\n",
        "            user_id INT,\n",
        "            spotify_name TEXT,\n",
        "            artist_name TEXT\n",
        "        )\n",
        "    '''\n",
        "    conn.execute(query)\n",
        "    logging.info(\"Table artist_data created or verified.\")\n",
        "\n",
        "def create_table_tag_artist_data(conn):\n",
        "    query = '''\n",
        "        CREATE TABLE IF NOT EXISTS tag_artist_data (\n",
        "            user_id INT,\n",
        "            tag_id INT\n",
        "        )\n",
        "    '''\n",
        "    conn.execute(query)\n",
        "    logging.info(\"Table tag_artist_data created or verified.\")\n",
        "\n",
        "def create_table_tag_genre_data(conn):\n",
        "    query = '''\n",
        "        CREATE TABLE IF NOT EXISTS tag_genre_data (\n",
        "            genre TEXT,\n",
        "            tag_id INT\n",
        "        )\n",
        "    '''\n",
        "    conn.execute(query)\n",
        "    logging.info(\"Table tag_genre_data created or verified.\")\n",
        "\n",
        "def create_all_tables(conn):\n",
        "    \"\"\"Create all required database tables.\"\"\"\n",
        "    create_table_music_data(conn)\n",
        "    create_table_artist_data(conn)\n",
        "    create_table_tag_artist_data(conn)\n",
        "    create_table_tag_genre_data(conn)\n",
        "    conn.commit()\n",
        "\n",
        "def insert_data(conn, df):\n",
        "    cursor = conn.cursor()\n",
        "    genre_to_tag_id = {}\n",
        "    current_tag_id = 1\n",
        "    \n",
        "    for index, row in df.iterrows():\n",
        "        user_id, spotify_id, popularity, spotify_followers, spotify_name, artist_name, genres = \\\n",
        "            row['user_id'], row['spotify_id'], row['popularity'], row['spotify_followers'], \\\n",
        "            row['spotify_name'], row['artist_name'], row['final_genre']\n",
        "        \n",
        "        cursor.execute(\"INSERT INTO music_data (user_id, spotify_id, popularity, spotify_followers) VALUES (?, ?, ?, ?)\",\n",
        "                       (user_id, spotify_id, popularity, spotify_followers))\n",
        "        logging.info(f\"Inserted music_data for user_id {user_id}.\")\n",
        "        \n",
        "        cursor.execute(\"INSERT INTO artist_data (user_id, spotify_name, artist_name) VALUES (?, ?, ?)\",\n",
        "                       (user_id, spotify_name, artist_name))\n",
        "        logging.info(f\"Inserted artist_data for user_id {user_id}.\")\n",
        "        \n",
        "        if not genres:\n",
        "            genres = ['UNKNOWN']\n",
        "        \n",
        "        for genre in genres:\n",
        "            if genre not in genre_to_tag_id:\n",
        "                genre_to_tag_id[genre] = current_tag_id\n",
        "                cursor.execute(\"INSERT INTO tag_genre_data (genre, tag_id) VALUES (?, ?)\", (genre, current_tag_id))\n",
        "                logging.info(f\"Added new genre {genre} to tag_genre_data.\")\n",
        "                current_tag_id += 1\n",
        "            cursor.execute(\"INSERT INTO tag_artist_data (user_id, tag_id) VALUES (?, ?)\", (user_id, genre_to_tag_id[genre]))\n",
        "            logging.info(f\"Linked genre {genre} to user_id {user_id} in tag_artist_data.\")\n",
        "    \n",
        "    conn.commit()\n",
        "\n",
        "def export_to_csv(conn, table_name, csv_path):\n",
        "    \"\"\"Export a table to a CSV file.\"\"\"\n",
        "    query = f\"SELECT * FROM {table_name}\"\n",
        "    df = pd.read_sql_query(query, conn)\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    logging.info(f\"Data from {table_name} exported to {csv_path}.\")\n",
        "\n",
        "def fetch_data(conn):\n",
        "    \"\"\"Fetch data from the database and return as a DataFrame.\"\"\"\n",
        "    sql_query = '''\n",
        "        SELECT \n",
        "            a.spotify_id,\n",
        "            a.user_id,\n",
        "            ad.artist_name,\n",
        "            GROUP_CONCAT(DISTINCT tg.genre) AS genres,\n",
        "            COUNT(DISTINCT tg.genre) AS total_genres_assigned_to_artist,\n",
        "            SUM(COUNT(DISTINCT tad.user_id)) OVER (PARTITION BY tg.genre) AS total_artists_assigned_to_genre\n",
        "        FROM \n",
        "            music_data AS a\n",
        "        JOIN \n",
        "            artist_data AS ad ON a.user_id = ad.user_id\n",
        "        JOIN \n",
        "            tag_artist_data AS tad ON a.user_id = tad.user_id\n",
        "        JOIN \n",
        "            tag_genre_data AS tg ON tad.tag_id = tg.tag_id\n",
        "        GROUP BY \n",
        "            a.spotify_id, a.user_id\n",
        "        '''\n",
        "    df = pd.read_sql_query(sql_query, conn)\n",
        "    return df\n",
        "\n",
        "def main(database_path, dataframe, generate_csv=False):\n",
        "    \"\"\"Main function to execute database operations.\"\"\"\n",
        "    with sqlite3.connect(database_path) as conn:\n",
        "        create_all_tables(conn)\n",
        "        insert_data(conn, dataframe)\n",
        "        df_results = fetch_data(conn)\n",
        "        if generate_csv:\n",
        "            timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "            directory_path = os.path.join(EXTRACT_FOLDER, f\"data_exports_{database_path}_{timestamp}\")\n",
        "            os.makedirs(directory_path, exist_ok=True)\n",
        "        \n",
        "            export_to_csv(conn, 'music_data', os.path.join(directory_path, \"music_data.csv\"))\n",
        "            export_to_csv(conn, 'artist_data', os.path.join(directory_path, \"artist_data.csv\"))\n",
        "            export_to_csv(conn, 'tag_artist_data', os.path.join(directory_path, \"tag_artist_data.csv\"))\n",
        "            export_to_csv(conn, 'tag_genre_data', os.path.join(directory_path, \"tag_genre_data.csv\"))\n",
        "    return df_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Only Rows with Defined Spotify Genre Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filter the rows where the is_genre_empty is False and get the count of the rows\n",
        "strictly_spotify = artist_user_id_mapping[artist_user_id_mapping['is_genre_empty'] == False]\n",
        "strictly_spotify.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add final_genre column to the strictly_spotify dataframe with the value of the spotify_genre\n",
        "strictly_spotify['final_genre'] = strictly_spotify['spotify_genre']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "db_path = 'striclty-spotify.db'\n",
        "results_df = main(db_path, strictly_spotify, generate_csv=True)\n",
        "results_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enriched data from Spotify and LastFm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "db_path = 'enriched-withlast-fm.db'\n",
        "results_df = main(db_path, fully_enriched, generate_csv=True)\n",
        "results_df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The task at hand is a complex data engineering task which needs:\n",
        "\n",
        "- Data enhancements\n",
        "- Thinking outside the box to solve a data augmentation instance\n",
        "\n",
        "If the data is augmented and gathered correctly, more relevant and correct insights concerning the artists can be gathered. \n",
        "\n",
        "If the artists had more distinctive features present, then:\n",
        "\n",
        "- Searching for their genre \n",
        "- Relational mapping of their relationships\n",
        "\n",
        "will be more evident.\n",
        "\n",
        "It is crucial to:\n",
        "\n",
        "- Keep a good database structure which is relationally sane to be able to expand and scale up the amount of artists and so on\n",
        "- Maintain this data and have an iterative process as part of a data genre validation rule\n",
        "- Have a larger entity space for the data rows of artists, such as a list of names the artist is known by\n",
        "\n",
        "Finding a reliable data source for enriching is crucial if the data will be used for:\n",
        "\n",
        "- Marketing\n",
        "- Machine learning purposes\n",
        "\n",
        "- The final csv of the csv structures are in the `raw_data` and are of two folders with `strictly-spotify` and `enriched-withlast-fm` as the database structure"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
