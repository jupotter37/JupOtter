{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#'''Importing Data Manipulation Modules'''\nimport numpy as np                 # Linear Algebra\nimport pandas as pd                # Data Processing, CSV file I/O (e.g. pd.read_csv)\n\n#'''Seaborn and Matplotlib Visualization'''\nimport matplotlib                  # 2D Plotting Library\nimport matplotlib.pyplot as plt\nimport seaborn as sns              # Python Data Visualization Library based on matplotlib\nplt.style.use('fivethirtyeight')\n%matplotlib inline\n\n#'''Plotly Visualizations'''\nimport plotly as plotly                # Interactive Graphing Library for Python\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly.offline as py\ninit_notebook_mode(connected=True)\nimport os\n%pylab inline\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/red-wine-quality-cortez-et-al-2009/winequality-red.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def quality(dataframe):\n    dataframe.loc[(dataframe['quality'] >= 2) & (dataframe['quality'] <= 6.5), 'quality'] = 0\n    \n    dataframe.loc[(dataframe['quality'] > 6.5) & (dataframe['quality'] <= 8), 'quality'] = 1\n           \n    return dataframe\n\nquality(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = df.drop(['quality'],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = df['quality']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = (df.quality.unique())\ncolors = ['Crimson', 'DarkBlue']\n\ntrace = go.Histogram(x=df.quality,marker=dict(color=colors,line=dict(color='black', width=2)),opacity=0.75)\nlayout = go.Layout(\n    title='Quality distribution',\n    xaxis=dict(\n        title='Bad wine - Great wine'\n    ),\n    yaxis=dict(\n        title='Count'\n    ),\n    bargap=0.2,\n    bargroupgap=0.1, paper_bgcolor='rgb(243, 243, 243)',\n    plot_bgcolor=\"rgb(243, 243, 243)\")\nfig = go.Figure(data=[trace], layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dia = y\ndata = x\ndata_n_2 = (data - data.mean()) / (data.std())              # standardization\n\n\ndata = pd.concat([y,data_n_2],axis=1)\ndata = pd.melt(data,id_vars=\"quality\",\n                    var_name=\"features\",\n                    value_name='value')\nplt.figure(figsize=(10,10))\nsns.violinplot(x=\"features\", y=\"value\", hue=\"quality\", data=data,split=True, inner=\"quart\")\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dia = y\ndata = x\ndata_n_2 = (data - data.mean()) / (data.std())              # standardization\ndata = pd.concat([y,data_n_2],axis=1)\ndata = pd.melt(data,id_vars=\"quality\",\n                    var_name=\"features\",\n                    value_name='value')\nplt.figure(figsize=(10,10))\ntic = time.time()\nsns.swarmplot(x=\"features\", y=\"value\", hue=\"quality\", data=data,palette=[\"black\", \"silver\"])\n\nplt.xticks(rotation=90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f,ax = plt.subplots(figsize=(10, 10))\nsns.heatmap(x.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score,confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import KFold\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)\naccuracies = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nx_train = sc_X.fit_transform(x_train)\nx_test = sc_X.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rf = RandomForestClassifier(random_state=43)      \nclr_rf = clf_rf.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ac = accuracy_score(y_test,clf_rf.predict(x_test))\n\nprint('Accuracy is: ',ac)\ncm = confusion_matrix(y_test,clf_rf.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_selection import RFECV\n\n# The \"accuracy\" scoring is proportional to the number of correct classifications\nclf_rf_1 = RandomForestClassifier(random_state = 42) \nrfecv = RFECV(estimator=clf_rf_1, step=1, cv=k_fold,scoring='accuracy')   #10-fold cross-validation\nrfecv = rfecv.fit(x_train, y_train)\n\nprint('Optimal number of features :', rfecv.n_features_)\nprint('Best features :', x.columns[rfecv.support_])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_1 = df[['volatile acidity','citric acid','total sulfur dioxide','density','sulphates','alcohol']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x_1,y, test_size=0.25, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nx_train = sc_X.fit_transform(x_train)\nx_test = sc_X.transform(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf_rf_1 = RandomForestClassifier(random_state=43)      \nclr_rf_1 = clf_rf_1.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ac = accuracy_score(y_test,clf_rf_1.predict(x_test))\naccuracies['Random_Forest'] = ac\n\nprint('Accuracy is: ',ac, '\\n')\ncm = confusion_matrix(y_test,clf_rf_1.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('RFC Reports\\n',classification_report(y_test, clf_rf_1.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure()\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score of number of selected features\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LogisticRegression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogmodel = LogisticRegression() \nlogmodel.fit(x_train,y_train)\n\nac = accuracy_score(y_test,logmodel.predict(x_test))\naccuracies['Logistic regression'] = ac\n\nprint('Accuracy is: ',ac, '\\n')\ncm = confusion_matrix(y_test,logmodel.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('Logistic regression Reports\\n',classification_report(y_test, logmodel.predict(x_test)))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nfrom sklearn.neighbors import KNeighborsClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Neighbors\nneighbors = np.arange(0,25)\n\n#Create empty list that will hold cv scores\ncv_scores = []\n\n#Perform 10-fold cross validation on training set for odd values of k:\nfor k in neighbors:\n    k_value = k+1\n    knn = KNeighborsClassifier(n_neighbors = k_value, weights='uniform', p=2, metric='euclidean')\n    kfold = model_selection.KFold(n_splits=10, random_state=123)\n    scores = model_selection.cross_val_score(knn, x_train, y_train, cv=k_fold, scoring='accuracy')\n    cv_scores.append(scores.mean()*100)\n    print(\"k=%d %0.2f (+/- %0.2f)\" % (k_value, scores.mean()*100, scores.std()*100))\n\noptimal_k = neighbors[cv_scores.index(max(cv_scores))]\nprint (\"The optimal number of neighbors is %d with %0.1f%%\" % (optimal_k, cv_scores[optimal_k]))\n\nplt.plot(neighbors, cv_scores)\nplt.xlabel('Number of Neighbors K')\nplt.ylabel('Train Accuracy')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=9)\nknn.fit(x_train, y_train)\n\nac = accuracy_score(y_test,knn.predict(x_test))\naccuracies['KNN'] = ac\n\n\nprint('Accuracy is: ',ac, '\\n')\ncm = confusion_matrix(y_test,knn.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('KNN Reports\\n',classification_report(y_test, knn.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\ndtree = DecisionTreeClassifier(criterion='gini') #criterion = entopy, gini\ndtree.fit(x_train, y_train)\n\nac = accuracy_score(y_test,dtree.predict(x_test))\nprint('Accuracy is: ',ac, '\\n')\ncm = confusion_matrix(y_test,dtree.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('DecisionTree Reports\\n',classification_report(y_test, dtree.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import plot_tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,15))\nplot_tree(dtree,\n         filled=True,\n         rounded=True,\n         feature_names=x_1.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = dtree.cost_complexity_pruning_path(x_train, y_train)\nccp_alphas = path.ccp_alphas\nccp_alphas = ccp_alphas[:-1]\n\ndtrees = []\n\nfor ccp_alpha in ccp_alphas:\n    dtree = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n    dtree.fit(x_train,y_train)\n    dtrees.append(dtree)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_scores = [dtree.score(x_train,y_train) for dtree in dtrees]\ntest_scores = [dtree.score(x_test, y_test) for dtree in dtrees]\n\nfig, ax = plt.subplots()\nax.set_xlabel('alpha')\nax.set_ylabel('accuracy')\nax.set_title('Accuracy vs alpha for training and testing sets')\nax.plot(ccp_alphas, train_scores, marker = 'o', label = 'train', drawstyle='steps-post')\nax.plot(ccp_alphas, test_scores, marker = 'o', label = 'test', drawstyle='steps-post')\nax.legend()\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create an array to store the results of each fold during cross validation\nf,ax = plt.subplots(figsize=(18, 8))\nalpha_loop_values = []\n\nfor ccp_alpha in ccp_alphas:\n    dtree = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n    scores =cross_val_score(dtree, x_train, y_train, cv=kfold, scoring='accuracy')\n    alpha_loop_values.append([ccp_alpha, np.mean(scores),np.std(scores)])\n    \nalpha_results = pd.DataFrame(alpha_loop_values,\n                             columns=['alpha','mean_accuracy','std'])\nalpha_results.plot(x='alpha',\n                   y='mean_accuracy',\n                   yerr='std',\n                   marker='o',\n                   linestyle='--',\n                   ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha_results[(alpha_results['alpha'] > 0.003)\n              & \n              (alpha_results['alpha'] < 0.004)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dtree1 = DecisionTreeClassifier(random_state=42,\n                                ccp_alpha=0.003672)\ndtree1 = dtree1.fit(x_train, y_train)\n\nac = accuracy_score(y_test,dtree1.predict(x_test))\naccuracies['decisiontree'] = ac\n\n\nprint('Accuracy is: ',ac,'\\n')\ncm = confusion_matrix(y_test,dtree1.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('Decision Tree Reports\\n',classification_report(y_test, dtree1.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {'C':[0.5,1,10,100],\n     'gamma': ['scale',1,0.1,0.01,0.001,0.0001],\n     'kernel': ['rbf']},\n]\n\noptimal_params = GridSearchCV(\n        SVC(),\n        param_grid,\n        cv = k_fold,\n        scoring='accuracy',\n        verbose = 0\n    )\noptimal_params.fit(x_train, y_train)\nprint(optimal_params.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc1= SVC(random_state = 42, C = 10, gamma = 1, kernel = 'rbf')\nsvc1.fit(x_train, y_train)\n\nac = accuracy_score(y_test,svc1.predict(x_test))\naccuracies['SVM'] = ac\n\n\nprint('Accuracy is: ',ac, '\\n')\ncm = confusion_matrix(y_test,svc1.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('SVM report\\n',classification_report(y_test, svc1.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# GaussianNB"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\ngaussiannb= GaussianNB()\ngaussiannb.fit(x_train, y_train)\n\nac = accuracy_score(y_test,gaussiannb.predict(x_test))\naccuracies['GaussianNB'] = ac\n\n\nprint('Accuracy is: ',ac,'\\n')\ncm = confusion_matrix(y_test,gaussiannb.predict(x_test))\nsns.heatmap(cm,annot=True,fmt=\"d\")\n\nprint('GaussianNB report\\n',classification_report(y_test, gaussiannb.predict(x_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"colors = [\"purple\", \"green\", \"orange\", \"magenta\",\"#CFC60E\",\"#0FBBAE\"]\n\nplt.rcParams['figure.figsize'] = (18,8)\n\nx=list(accuracies.keys())\ny=list(accuracies.values())\n\nbars = plt.bar(x, height=y, width=.4, color = colors)\n\nxlocs, xlabs = plt.xticks()\n\nxlocs=[i for i in x]\nxlabs=[i for i in x]\n\nplt.xlabel('Algorithms', size = 20)\nplt.ylabel('Accuracy %', size = 20)\nplt.xticks(xlocs, xlabs, size = 15)\n\nfor bar in bars:\n    yval = bar.get_height()\n    plt.text(bar.get_x() + .1, yval + .005, yval, size = 15)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax_arr = plt.subplots(nrows = 2, ncols = 3, figsize = (20,15))\nfrom sklearn import metrics\n\n#RandomForest\nprobs = clf_rf_1.predict_proba(x_test)\npreds = probs[:,1]\nfprrfc, tprrfc, thresholdrfc = metrics.roc_curve(y_test, preds)\nroc_aucrfc = metrics.auc(fprrfc, tprrfc)\n\nax_arr[0,0].plot(fprrfc, tprrfc, 'b', label = 'AUC = %0.2f' % roc_aucrfc)\nax_arr[0,0].plot([0, 1], [0, 1],'r--')\nax_arr[0,0].set_title('ROC Random Forest ',fontsize=20)\nax_arr[0,0].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[0,0].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[0,0].legend(loc = 'lower right', prop={'size': 16})\n\n#LOGMODEL\nprobs = logmodel.predict_proba(x_test)\npreds = probs[:,1]\nfprlog, tprlog, thresholdlog = metrics.roc_curve(y_test, preds)\nroc_auclog = metrics.auc(fprlog, tprlog)\n\nax_arr[0,1].plot(fprlog, tprlog, 'b', label = 'AUC = %0.2f' % roc_auclog)\nax_arr[0,1].plot([0, 1], [0, 1],'r--')\nax_arr[0,1].set_title('ROC Logistic ',fontsize=20)\nax_arr[0,1].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[0,1].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[0,1].legend(loc = 'lower right', prop={'size': 16})\n\n#KNN\nprobs = knn.predict_proba(x_test)\npreds = probs[:,1]\nfprknn, tprknn, thresholdknn = metrics.roc_curve(y_test, preds)\nroc_aucknn = metrics.auc(fprknn, tprknn)\n\nax_arr[0,2].plot(fprknn, tprknn, 'b', label = 'AUC = %0.2f' % roc_aucknn)\nax_arr[0,2].plot([0, 1], [0, 1],'r--')\nax_arr[0,2].set_title('ROC KNN ',fontsize=20)\nax_arr[0,2].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[0,2].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[0,2].legend(loc = 'lower right', prop={'size': 16})\n\n#DECISION TREE\nprobs = dtree1.predict_proba(x_test)\npreds = probs[:,1]\nfprdtree, tprdtree, thresholddtree = metrics.roc_curve(y_test, preds)\nroc_aucdtree = metrics.auc(fprdtree, tprdtree)\n\nax_arr[1,0].plot(fprdtree, tprdtree, 'b', label = 'AUC = %0.2f' % roc_aucdtree)\nax_arr[1,0].plot([0, 1], [0, 1],'r--')\nax_arr[1,0].set_title('ROC Decision Tree ',fontsize=20)\nax_arr[1,0].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[1,0].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[1,0].legend(loc = 'lower right', prop={'size': 16})\n\n\n#Gaussiannb\n\nprobs = gaussiannb.predict_proba(x_test)\npreds = probs[:,1]\nfprgau, tprgau, thresholdgau = metrics.roc_curve(y_test, preds)\nroc_aucgau = metrics.auc(fprgau, tprgau)\n\nax_arr[1,1].plot(fprgau, tprgau, 'b', label = 'AUC = %0.2f' % roc_aucgau)\nax_arr[1,1].plot([0, 1], [0, 1],'r--')\nax_arr[1,1].set_title('ROC Gaussian ',fontsize=20)\nax_arr[1,1].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[1,1].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[1,1].legend(loc = 'lower right', prop={'size': 16})\n\n#All plots\nax_arr[1,2].plot(fprrfc, tprrfc, 'b', label = 'rfc', color='black')\nax_arr[1,2].plot(fprlog, tprlog, 'b', label = 'Logistic', color='blue')\nax_arr[1,2].plot(fprknn, tprknn, 'b', label = 'Knn', color='brown')\nax_arr[1,2].plot(fprdtree, tprdtree, 'b', label = 'Decision Tree', color='green')\nax_arr[1,2].plot(fprgau, tprgau, 'b', label = 'Gaussiannb', color='grey')\nax_arr[1,2].set_title('Receiver Operating Comparison ',fontsize=20)\nax_arr[1,2].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[1,2].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[1,2].legend(loc = 'lower right', prop={'size': 16})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Thanks for watching, upvote if you like:)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}