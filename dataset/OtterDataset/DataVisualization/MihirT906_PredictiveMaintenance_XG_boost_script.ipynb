{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "# Off FutureWarnings\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "#Resampling\n",
    "from imblearn.over_sampling import SMOTENC \n",
    "from sklearn.utils import class_weight\n",
    "#Dimension Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, OrdinalEncoder, OneHotEncoder \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Models\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Models Pipelines\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "# Model evaluation\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score, precision_score, f1_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# Save model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air_temperature</th>\n",
       "      <th>Process_temperature</th>\n",
       "      <th>Rotational_speed</th>\n",
       "      <th>Torque</th>\n",
       "      <th>Tool_wear</th>\n",
       "      <th>Machine_failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "      <th>Failure_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>9995</td>\n",
       "      <td>Medium</td>\n",
       "      <td>298.8</td>\n",
       "      <td>308.4</td>\n",
       "      <td>1604</td>\n",
       "      <td>29.5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>9996</td>\n",
       "      <td>High</td>\n",
       "      <td>298.9</td>\n",
       "      <td>308.4</td>\n",
       "      <td>1632</td>\n",
       "      <td>31.8</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>9997</td>\n",
       "      <td>Medium</td>\n",
       "      <td>299.0</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1645</td>\n",
       "      <td>33.4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>9998</td>\n",
       "      <td>High</td>\n",
       "      <td>299.0</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>48.5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>9999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>299.0</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1500</td>\n",
       "      <td>40.2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9976 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    Type  Air_temperature  Process_temperature  \\\n",
       "0              0  Medium            298.1                308.6   \n",
       "1              1     Low            298.2                308.7   \n",
       "2              2     Low            298.1                308.5   \n",
       "3              3     Low            298.2                308.6   \n",
       "4              4     Low            298.2                308.7   \n",
       "...          ...     ...              ...                  ...   \n",
       "9971        9995  Medium            298.8                308.4   \n",
       "9972        9996    High            298.9                308.4   \n",
       "9973        9997  Medium            299.0                308.6   \n",
       "9974        9998    High            299.0                308.7   \n",
       "9975        9999  Medium            299.0                308.7   \n",
       "\n",
       "      Rotational_speed  Torque  Tool_wear  Machine_failure  TWF  HDF  PWF  \\\n",
       "0                 1551    42.8          0                0    0    0    0   \n",
       "1                 1408    46.3          3                0    0    0    0   \n",
       "2                 1498    49.4          5                0    0    0    0   \n",
       "3                 1433    39.5          7                0    0    0    0   \n",
       "4                 1408    40.0          9                0    0    0    0   \n",
       "...                ...     ...        ...              ...  ...  ...  ...   \n",
       "9971              1604    29.5         14                0    0    0    0   \n",
       "9972              1632    31.8         17                0    0    0    0   \n",
       "9973              1645    33.4         22                0    0    0    0   \n",
       "9974              1408    48.5         25                0    0    0    0   \n",
       "9975              1500    40.2         30                0    0    0    0   \n",
       "\n",
       "      OSF  RNF Failure_type  \n",
       "0       0    0           NF  \n",
       "1       0    0           NF  \n",
       "2       0    0           NF  \n",
       "3       0    0           NF  \n",
       "4       0    0           NF  \n",
       "...   ...  ...          ...  \n",
       "9971    0    0           NF  \n",
       "9972    0    0           NF  \n",
       "9973    0    0           NF  \n",
       "9974    0    0           NF  \n",
       "9975    0    0           NF  \n",
       "\n",
       "[9976 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Upload df\n",
    "df = pd.read_csv('cleaned_data.csv') \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score \n",
    "\n",
    "def get_metrics(y_true, y_pred, unique_classes):\n",
    "    # Calculating F1 scores for each class\n",
    "    f1_scores_per_class = f1_score(y_true, y_pred, average=None, labels=unique_classes)\n",
    "    recall_scores_per_class = recall_score(y_true, y_pred, average=None, labels=unique_classes)\n",
    "    precision_scores_per_class = precision_score(y_true, y_pred, average=None, labels=unique_classes)\n",
    "    class_f1_scores = dict(zip(unique_classes, f1_scores_per_class))\n",
    "    class_recall_scores = dict(zip(unique_classes, recall_scores_per_class))\n",
    "    class_precision_scores = dict(zip(unique_classes, precision_scores_per_class))\n",
    "    dict_metrics = {\n",
    "    'Accuracy': accuracy_score(y_true, y_pred),\n",
    "    'Balanced Accuracy': balanced_accuracy_score(y_true, y_pred),\n",
    "    'Macro Recall': recall_score(y_true, y_pred, average='macro'), \n",
    "    'Macro Precision': precision_score(y_true, y_pred, average='macro'), \n",
    "    'Macro F1': f1_score(y_true, y_pred, average='macro'),\n",
    "    'F1 Scores per Class': class_f1_scores,\n",
    "    'Recall Scores per Class': class_recall_scores,\n",
    "    'Precision Scores per Class': class_precision_scores\n",
    "    }\n",
    "    return dict_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Type</th>\n",
       "      <th>Air_temperature</th>\n",
       "      <th>Process_temperature</th>\n",
       "      <th>Rotational_speed</th>\n",
       "      <th>Torque</th>\n",
       "      <th>Tool_wear</th>\n",
       "      <th>Machine_failure</th>\n",
       "      <th>TWF</th>\n",
       "      <th>HDF</th>\n",
       "      <th>PWF</th>\n",
       "      <th>OSF</th>\n",
       "      <th>RNF</th>\n",
       "      <th>Failure_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Medium</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1551</td>\n",
       "      <td>42.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Low</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>46.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Low</td>\n",
       "      <td>298.1</td>\n",
       "      <td>308.5</td>\n",
       "      <td>1498</td>\n",
       "      <td>49.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Low</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1433</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Low</td>\n",
       "      <td>298.2</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>40.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>9995</td>\n",
       "      <td>Medium</td>\n",
       "      <td>298.8</td>\n",
       "      <td>308.4</td>\n",
       "      <td>1604</td>\n",
       "      <td>29.5</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>9996</td>\n",
       "      <td>High</td>\n",
       "      <td>298.9</td>\n",
       "      <td>308.4</td>\n",
       "      <td>1632</td>\n",
       "      <td>31.8</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>9997</td>\n",
       "      <td>Medium</td>\n",
       "      <td>299.0</td>\n",
       "      <td>308.6</td>\n",
       "      <td>1645</td>\n",
       "      <td>33.4</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>9998</td>\n",
       "      <td>High</td>\n",
       "      <td>299.0</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1408</td>\n",
       "      <td>48.5</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9975</th>\n",
       "      <td>9999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>299.0</td>\n",
       "      <td>308.7</td>\n",
       "      <td>1500</td>\n",
       "      <td>40.2</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9976 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    Type  Air_temperature  Process_temperature  \\\n",
       "0              0  Medium            298.1                308.6   \n",
       "1              1     Low            298.2                308.7   \n",
       "2              2     Low            298.1                308.5   \n",
       "3              3     Low            298.2                308.6   \n",
       "4              4     Low            298.2                308.7   \n",
       "...          ...     ...              ...                  ...   \n",
       "9971        9995  Medium            298.8                308.4   \n",
       "9972        9996    High            298.9                308.4   \n",
       "9973        9997  Medium            299.0                308.6   \n",
       "9974        9998    High            299.0                308.7   \n",
       "9975        9999  Medium            299.0                308.7   \n",
       "\n",
       "      Rotational_speed  Torque  Tool_wear  Machine_failure  TWF  HDF  PWF  \\\n",
       "0                 1551    42.8          0                0    0    0    0   \n",
       "1                 1408    46.3          3                0    0    0    0   \n",
       "2                 1498    49.4          5                0    0    0    0   \n",
       "3                 1433    39.5          7                0    0    0    0   \n",
       "4                 1408    40.0          9                0    0    0    0   \n",
       "...                ...     ...        ...              ...  ...  ...  ...   \n",
       "9971              1604    29.5         14                0    0    0    0   \n",
       "9972              1632    31.8         17                0    0    0    0   \n",
       "9973              1645    33.4         22                0    0    0    0   \n",
       "9974              1408    48.5         25                0    0    0    0   \n",
       "9975              1500    40.2         30                0    0    0    0   \n",
       "\n",
       "      OSF  RNF Failure_type  \n",
       "0       0    0           NF  \n",
       "1       0    0           NF  \n",
       "2       0    0           NF  \n",
       "3       0    0           NF  \n",
       "4       0    0           NF  \n",
       "...   ...  ...          ...  \n",
       "9971    0    0           NF  \n",
       "9972    0    0           NF  \n",
       "9973    0    0           NF  \n",
       "9974    0    0           NF  \n",
       "9975    0    0           NF  \n",
       "\n",
       "[9976 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMERIC_FEATURES = ['Air_temperature', 'Process_temperature', 'Rotational_speed', 'Torque', 'Tool_wear']\n",
    "CATEGORIC_FEATURES = ['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Air_temperature</th>\n",
       "      <th>Process_temperature</th>\n",
       "      <th>Rotational_speed</th>\n",
       "      <th>Torque</th>\n",
       "      <th>Tool_wear</th>\n",
       "      <th>Type_High</th>\n",
       "      <th>Type_Low</th>\n",
       "      <th>Type_Medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.951551</td>\n",
       "      <td>-0.946692</td>\n",
       "      <td>0.065483</td>\n",
       "      <td>0.289789</td>\n",
       "      <td>-1.695147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.901538</td>\n",
       "      <td>-0.879314</td>\n",
       "      <td>-0.732576</td>\n",
       "      <td>0.643119</td>\n",
       "      <td>-1.647949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.951551</td>\n",
       "      <td>-1.014071</td>\n",
       "      <td>-0.230301</td>\n",
       "      <td>0.956069</td>\n",
       "      <td>-1.616484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.901538</td>\n",
       "      <td>-0.946692</td>\n",
       "      <td>-0.593055</td>\n",
       "      <td>-0.043351</td>\n",
       "      <td>-1.585019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.901538</td>\n",
       "      <td>-0.879314</td>\n",
       "      <td>-0.732576</td>\n",
       "      <td>0.007125</td>\n",
       "      <td>-1.553553</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Air_temperature  Process_temperature  Rotational_speed    Torque  \\\n",
       "0        -0.951551            -0.946692          0.065483  0.289789   \n",
       "1        -0.901538            -0.879314         -0.732576  0.643119   \n",
       "2        -0.951551            -1.014071         -0.230301  0.956069   \n",
       "3        -0.901538            -0.946692         -0.593055 -0.043351   \n",
       "4        -0.901538            -0.879314         -0.732576  0.007125   \n",
       "\n",
       "   Tool_wear  Type_High  Type_Low  Type_Medium  \n",
       "0  -1.695147        0.0       0.0          1.0  \n",
       "1  -1.647949        0.0       1.0          0.0  \n",
       "2  -1.616484        0.0       1.0          0.0  \n",
       "3  -1.585019        0.0       1.0          0.0  \n",
       "4  -1.553553        0.0       1.0          0.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create preprocessor ColumnTransformer to do OneHotEncoder for CATEGORIC_FEATURES and StandardScaler() for NUMERIC_FEATURES\n",
    "# Define the pipelines for numeric and categorical transformations\n",
    "num_pipeline = Pipeline([\n",
    "    ('num_features', StandardScaler()) \n",
    "    ])\n",
    "cat_pipeline = Pipeline([ \n",
    "    ('cat_features', OneHotEncoder())\n",
    "    ])\n",
    "# Create the ColumnTransformer\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num_trans', num_pipeline, NUMERIC_FEATURES),\n",
    "    ('cat_trans', cat_pipeline, CATEGORIC_FEATURES) ])\n",
    "# Fit and transform the data\n",
    "df_transformed = preprocessor.fit_transform(df)\n",
    "# Converting the transformed data back to a dataframe for easier visualization\n",
    "# The transformed data will have new column names, especially for the one hot encoded categories \n",
    "encoded_feature_names = preprocessor.named_transformers_['cat_trans'].get_feature_names_out(CATEGORIC_FEATURES) \n",
    "new_column_names = list(NUMERIC_FEATURES) + list(encoded_feature_names)\n",
    "df_transformed = pd.DataFrame(df_transformed, columns=new_column_names)\n",
    "df_transformed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df[df['Failure_type'] != 'TWF']s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df.copy()\n",
    "X = df_model[NUMERIC_FEATURES + CATEGORIC_FEATURES]\n",
    "y = df['Failure_type']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HDF', 'NF', 'OSF', 'PWF', 'TWF'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_classes = np.unique(y_train)\n",
    "unique_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/e4_predictive_maintenance/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/e4_predictive_maintenance/lib/python3.12/site-packages/sklearn/utils/__init__.py:505\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[0;32m--> 505\u001b[0m     col_idx \u001b[38;5;241m=\u001b[39m \u001b[43mall_columns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "File \u001b[0;32m~/anaconda3/envs/e4_predictive_maintenance/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Fit pipeline with sample weights\u001b[39;00m\n\u001b[1;32m      8\u001b[0m weights \u001b[38;5;241m=\u001b[39m class_weight\u001b[38;5;241m.\u001b[39mcompute_sample_weight(class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39my_train_encoded) \n\u001b[0;32m----> 9\u001b[0m \u001b[43mpip_model_no_pca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel__sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Step 1: Generate Predictions\u001b[39;00m\n\u001b[1;32m     12\u001b[0m y_pred_encoded \u001b[38;5;241m=\u001b[39m pip_model_no_pca\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m~/anaconda3/envs/e4_predictive_maintenance/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/e4_predictive_maintenance/lib/python3.12/site-packages/sklearn/pipeline.py:471\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \n\u001b[1;32m    430\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 471\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/e4_predictive_maintenance/lib/python3.12/site-packages/sklearn/pipeline.py:408\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, routed_params)\u001b[0m\n\u001b[1;32m    406\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/anaconda3/envs/e4_predictive_maintenance/lib/python3.12/site-packages/joblib/memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/e4_predictive_maintenance/lib/python3.12/site-packages/sklearn/pipeline.py:1303\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1303\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   1306\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m   1307\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/e4_predictive_maintenance/lib/python3.12/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/e4_predictive_maintenance/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/e4_predictive_maintenance/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:906\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    903\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[1;32m    904\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[0;32m--> 906\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    907\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m    909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _routing_enabled():\n",
      "File \u001b[0;32m~/anaconda3/envs/e4_predictive_maintenance/lib/python3.12/site-packages/sklearn/compose/_column_transformer.py:496\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    494\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[1;32m    495\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[0;32m--> 496\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[0;32m~/anaconda3/envs/e4_predictive_maintenance/lib/python3.12/site-packages/sklearn/utils/__init__.py:513\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    510\u001b[0m         column_indices\u001b[38;5;241m.\u001b[39mappend(col_idx)\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 513\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA given column is not a column of the dataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m column_indices\n",
      "\u001b[0;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "# Creating pipeline without PCA analysis and balanced class with parameter by model \n",
    "pip_model_no_pca = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBClassifier(random_state=2023)) \n",
    "])\n",
    "\n",
    "# Fit pipeline with sample weights\n",
    "weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train_encoded) \n",
    "pip_model_no_pca.fit(X_train, y_train_encoded, model__sample_weight=weights)\n",
    "\n",
    "# Step 1: Generate Predictions\n",
    "y_pred_encoded = pip_model_no_pca.predict(X_test)\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Step 2: Evaluate Metrics\n",
    "metrics = get_metrics(y_test, y_pred, unique_classes)\n",
    "\n",
    "# Step 3: View Results metrics\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating pipeline without PCA analysis and balanced class with parameter by model \n",
    "# pip_model_no_pca = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('model', XGBClassifier(random_state=2023)) \n",
    "# ])\n",
    "\n",
    "# # Fit pipeline with sample weights\n",
    "# weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train_encoded) \n",
    "# pip_model_no_pca.fit(X_train, y_train_encoded, model__sample_weight=weights)\n",
    "\n",
    "# # Step 1: Generate Predictions\n",
    "# y_pred_encoded = cross_val_predict(pip_model_no_pca, X_test, y_test_encoded, cv=3)\n",
    "# y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# # Step 2: Evaluate Metrics\n",
    "# metrics = classification_report(y_test, y_pred, target_names=unique_classes)\n",
    "\n",
    "# # Step 3: View Results metrics\n",
    "# print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# # Define the cross-validation strategy (Stratified K-Fold with k=3)\n",
    "\n",
    "# # Updated pipeline definition (same as before)\n",
    "# pip_model_no_pca = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('model', XGBClassifier(random_state=2023))\n",
    "# ])\n",
    "\n",
    "# # Fit pipeline with sample weights\n",
    "# pip_model_no_pca.fit(X_train, y_train_encoded, model__sample_weight=weights)\n",
    "\n",
    "# # Step 1: Generate Predictions using cross-validation\n",
    "# y_pred_cv = cross_val_predict(pip_model_no_pca, X_train, y_train_encoded, cv=3, n_jobs=-1)\n",
    "\n",
    "# # Step 2: Evaluate Metrics\n",
    "# metrics_cv = classification_report(y_train_encoded, y_pred_cv, target_names=unique_classes, output_dict=True)\n",
    "\n",
    "# # Step 3: View Results\n",
    "# print(\"Cross-validation metrics:\")\n",
    "# print(metrics_cv)\n",
    "\n",
    "# # Optional: You can also access individual metric scores like F1-score\n",
    "# f1_macro_cv = metrics_cv['macro avg']['f1-score']\n",
    "# print(f\"Average F1-score (macro) across CV folds: {f1_macro_cv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is overfitting\n",
    "# y_pred_encoded = pip_model_no_pca.predict(X_train)\n",
    "# y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# # Step 2: Evaluate Metrics\n",
    "# metrics = get_metrics(y_train, y_pred, unique_classes)\n",
    "\n",
    "# # Step 3: View Results metrics\n",
    "# metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 588 candidates, totalling 1764 fits\n",
      "Best fine-tuned model parameters:\n",
      "{'model__alpha': 0.001, 'model__eta': 0.2, 'model__lambda': 0, 'model__max_depth': None, 'model__n_estimators': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9839679358717435,\n",
       " 'Balanced Accuracy': 0.766281838316722,\n",
       " 'Macro Recall': 0.766281838316722,\n",
       " 'Macro Precision': 0.6626252587991719,\n",
       " 'Macro F1': 0.7061134766834248,\n",
       " 'F1 Scores per Class': {'HDF': 0.9047619047619048,\n",
       "  'NF': 0.9917098445595854,\n",
       "  'OSF': 0.7692307692307693,\n",
       "  'PWF': 0.8648648648648649,\n",
       "  'TWF': 0.0},\n",
       " 'Recall Scores per Class': {'HDF': 0.9047619047619048,\n",
       "  'NF': 0.9891472868217054,\n",
       "  'OSF': 0.9375,\n",
       "  'PWF': 1.0,\n",
       "  'TWF': 0.0},\n",
       " 'Precision Scores per Class': {'HDF': 0.9047619047619048,\n",
       "  'NF': 0.9942857142857143,\n",
       "  'OSF': 0.6521739130434783,\n",
       "  'PWF': 0.7619047619047619,\n",
       "  'TWF': 0.0}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tune_params = {\n",
    "    'model__n_estimators': [100],\n",
    "    'model__max_depth': [None, 2, 6, 20],\n",
    "    'model__lambda': [0, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'model__alpha': [0, 0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'model__eta': [0.2, 0.3, 0.4],\n",
    "}\n",
    "# Running a new GridSearchCV for fine-tuning\n",
    "fine_tune_grid = GridSearchCV(pip_model_no_pca, fine_tune_params, cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
    "fine_tune_grid.fit(X_train, y_train_encoded, model__sample_weight=weights)\n",
    "\n",
    "# Collecting and printing the fine-tuned results\n",
    "fine_tuned_results = pd.DataFrame(fine_tune_grid.cv_results_) \n",
    "fine_tuned_best_index = fine_tuned_results['mean_test_score'].idxmax()\n",
    "fine_tuned_best_params = fine_tuned_results.loc[fine_tuned_best_index, 'params']\n",
    "\n",
    "# Print best model parameters\n",
    "print(\"Best fine-tuned model parameters:\") \n",
    "print(fine_tuned_best_params)\n",
    "# Finding the best estimator paramaters \n",
    "tuned_model = fine_tune_grid.best_estimator_ \n",
    "y_pred_encoded = tuned_model.predict(X_test)\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "# View new perfomance (focus on F1-score) \n",
    "get_metrics(y_test, y_pred, unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine_tuned_results[['param_model__alpha', 'param_model__lambda', 'param_model__eta', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.999874686716792,\n",
       " 'Balanced Accuracy': 0.9999741435035553,\n",
       " 'Macro Recall': 0.9999741435035553,\n",
       " 'Macro Precision': 0.9969230769230769,\n",
       " 'Macro F1': 0.9984366833191263,\n",
       " 'F1 Scores per Class': {'HDF': 1.0,\n",
       "  'NF': 0.9999353545801279,\n",
       "  'OSF': 1.0,\n",
       "  'PWF': 0.9922480620155039,\n",
       "  'TWF': 1.0},\n",
       " 'Recall Scores per Class': {'HDF': 1.0,\n",
       "  'NF': 0.9998707175177763,\n",
       "  'OSF': 1.0,\n",
       "  'PWF': 1.0,\n",
       "  'TWF': 1.0},\n",
       " 'Precision Scores per Class': {'HDF': 1.0,\n",
       "  'NF': 1.0,\n",
       "  'OSF': 1.0,\n",
       "  'PWF': 0.9846153846153847,\n",
       "  'TWF': 1.0}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating pipeline without PCA analysis and balanced class with parameter by model \n",
    "pip_model_no_pca = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBClassifier(random_state=2023)) \n",
    "])\n",
    "\n",
    "# Fit pipeline with sample weights\n",
    "weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train_encoded) \n",
    "tuned_model.fit(X_train, y_train_encoded, model__sample_weight=weights)\n",
    "\n",
    "# Step 1: Generate Predictions\n",
    "y_pred_encoded = tuned_model.predict(X_train)\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Step 2: Evaluate Metrics\n",
    "tuned_metrics = get_metrics(y_train, y_pred, unique_classes)\n",
    "\n",
    "# Step 3: View Results metrics\n",
    "tuned_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.9839679358717435,\n",
       " 'Balanced Accuracy': 0.766281838316722,\n",
       " 'Macro Recall': 0.766281838316722,\n",
       " 'Macro Precision': 0.6626252587991719,\n",
       " 'Macro F1': 0.7061134766834248,\n",
       " 'F1 Scores per Class': {'HDF': 0.9047619047619048,\n",
       "  'NF': 0.9917098445595854,\n",
       "  'OSF': 0.7692307692307693,\n",
       "  'PWF': 0.8648648648648649,\n",
       "  'TWF': 0.0},\n",
       " 'Recall Scores per Class': {'HDF': 0.9047619047619048,\n",
       "  'NF': 0.9891472868217054,\n",
       "  'OSF': 0.9375,\n",
       "  'PWF': 1.0,\n",
       "  'TWF': 0.0},\n",
       " 'Precision Scores per Class': {'HDF': 0.9047619047619048,\n",
       "  'NF': 0.9942857142857143,\n",
       "  'OSF': 0.6521739130434783,\n",
       "  'PWF': 0.7619047619047619,\n",
       "  'TWF': 0.0}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating pipeline without PCA analysis and balanced class with parameter by model \n",
    "pip_model_no_pca = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', XGBClassifier(random_state=2023)) \n",
    "])\n",
    "\n",
    "# Fit pipeline with sample weights\n",
    "weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train_encoded) \n",
    "tuned_model.fit(X_train, y_train_encoded, model__sample_weight=weights)\n",
    "\n",
    "# Step 1: Generate Predictions\n",
    "y_pred_encoded = tuned_model.predict(X_test)\n",
    "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "\n",
    "# Step 2: Evaluate Metrics\n",
    "tuned_metrics = get_metrics(y_test, y_pred, unique_classes)\n",
    "\n",
    "# Step 3: View Results metrics\n",
    "tuned_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n         HDF       0.77      0.48      0.59        21\\n          NF       0.98      0.99      0.99      1935\\n         OSF       1.00      0.44      0.61        16\\n         PWF       0.64      0.56      0.60        16\\n         TWF       0.33      0.12      0.18         8\\n\\n    accuracy                           0.98      1996\\n   macro avg       0.75      0.52      0.59      1996\\nweighted avg       0.98      0.98      0.98      1996\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>param_model__eta</th>\n",
       "      <th>param_model__lambda</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.203434</td>\n",
       "      <td>0.033296</td>\n",
       "      <td>0.024932</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 0, 'model__eta': 0.2, 'model_...</td>\n",
       "      <td>0.783770</td>\n",
       "      <td>0.753945</td>\n",
       "      <td>0.722238</td>\n",
       "      <td>0.753318</td>\n",
       "      <td>0.025124</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.150273</td>\n",
       "      <td>0.006672</td>\n",
       "      <td>0.009369</td>\n",
       "      <td>0.003589</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 0, 'model__eta': 0.2, 'model_...</td>\n",
       "      <td>0.602214</td>\n",
       "      <td>0.609258</td>\n",
       "      <td>0.665875</td>\n",
       "      <td>0.625782</td>\n",
       "      <td>0.028495</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.192170</td>\n",
       "      <td>0.027190</td>\n",
       "      <td>0.022562</td>\n",
       "      <td>0.003956</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 0, 'model__eta': 0.2, 'model_...</td>\n",
       "      <td>0.783770</td>\n",
       "      <td>0.753945</td>\n",
       "      <td>0.722238</td>\n",
       "      <td>0.753318</td>\n",
       "      <td>0.025124</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.211864</td>\n",
       "      <td>0.032995</td>\n",
       "      <td>0.024695</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 0, 'model__eta': 0.2, 'model_...</td>\n",
       "      <td>0.751082</td>\n",
       "      <td>0.736616</td>\n",
       "      <td>0.718570</td>\n",
       "      <td>0.735422</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.153609</td>\n",
       "      <td>0.039899</td>\n",
       "      <td>0.020210</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 0, 'model__eta': 0.2, 'model_...</td>\n",
       "      <td>0.775827</td>\n",
       "      <td>0.754467</td>\n",
       "      <td>0.720494</td>\n",
       "      <td>0.750263</td>\n",
       "      <td>0.022784</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0.107893</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.006759</td>\n",
       "      <td>0.001996</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 100, 'model__eta': 0.4, 'mode...</td>\n",
       "      <td>0.457652</td>\n",
       "      <td>0.435711</td>\n",
       "      <td>0.492631</td>\n",
       "      <td>0.461998</td>\n",
       "      <td>0.023440</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>0.096764</td>\n",
       "      <td>0.014629</td>\n",
       "      <td>0.008215</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 100, 'model__eta': 0.4, 'mode...</td>\n",
       "      <td>0.450964</td>\n",
       "      <td>0.439568</td>\n",
       "      <td>0.494351</td>\n",
       "      <td>0.461628</td>\n",
       "      <td>0.023602</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>0.071470</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.004610</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 100, 'model__eta': 0.4, 'mode...</td>\n",
       "      <td>0.434434</td>\n",
       "      <td>0.416671</td>\n",
       "      <td>0.480470</td>\n",
       "      <td>0.443858</td>\n",
       "      <td>0.026885</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>0.103796</td>\n",
       "      <td>0.018925</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 100, 'model__eta': 0.4, 'mode...</td>\n",
       "      <td>0.450964</td>\n",
       "      <td>0.439568</td>\n",
       "      <td>0.494351</td>\n",
       "      <td>0.461628</td>\n",
       "      <td>0.023602</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>0.079380</td>\n",
       "      <td>0.008080</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>100</td>\n",
       "      <td>0.4</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 100, 'model__eta': 0.4, 'mode...</td>\n",
       "      <td>0.450042</td>\n",
       "      <td>0.439568</td>\n",
       "      <td>0.494351</td>\n",
       "      <td>0.461320</td>\n",
       "      <td>0.023744</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.203434      0.033296         0.024932        0.005607   \n",
       "1         0.150273      0.006672         0.009369        0.003589   \n",
       "2         0.192170      0.027190         0.022562        0.003956   \n",
       "3         0.211864      0.032995         0.024695        0.002909   \n",
       "4         0.153609      0.039899         0.020210        0.000209   \n",
       "..             ...           ...              ...             ...   \n",
       "583       0.107893      0.002079         0.006759        0.001996   \n",
       "584       0.096764      0.014629         0.008215        0.004125   \n",
       "585       0.071470      0.003058         0.004610        0.000073   \n",
       "586       0.103796      0.018925         0.005839        0.001002   \n",
       "587       0.079380      0.008080         0.005279        0.000174   \n",
       "\n",
       "    param_model__alpha param_model__eta param_model__lambda  \\\n",
       "0                    0              0.2                   0   \n",
       "1                    0              0.2                   0   \n",
       "2                    0              0.2                   0   \n",
       "3                    0              0.2                   0   \n",
       "4                    0              0.2               0.001   \n",
       "..                 ...              ...                 ...   \n",
       "583                100              0.4                  10   \n",
       "584                100              0.4                 100   \n",
       "585                100              0.4                 100   \n",
       "586                100              0.4                 100   \n",
       "587                100              0.4                 100   \n",
       "\n",
       "    param_model__max_depth param_model__n_estimators  \\\n",
       "0                     None                       100   \n",
       "1                        2                       100   \n",
       "2                        6                       100   \n",
       "3                       20                       100   \n",
       "4                     None                       100   \n",
       "..                     ...                       ...   \n",
       "583                     20                       100   \n",
       "584                   None                       100   \n",
       "585                      2                       100   \n",
       "586                      6                       100   \n",
       "587                     20                       100   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'model__alpha': 0, 'model__eta': 0.2, 'model_...           0.783770   \n",
       "1    {'model__alpha': 0, 'model__eta': 0.2, 'model_...           0.602214   \n",
       "2    {'model__alpha': 0, 'model__eta': 0.2, 'model_...           0.783770   \n",
       "3    {'model__alpha': 0, 'model__eta': 0.2, 'model_...           0.751082   \n",
       "4    {'model__alpha': 0, 'model__eta': 0.2, 'model_...           0.775827   \n",
       "..                                                 ...                ...   \n",
       "583  {'model__alpha': 100, 'model__eta': 0.4, 'mode...           0.457652   \n",
       "584  {'model__alpha': 100, 'model__eta': 0.4, 'mode...           0.450964   \n",
       "585  {'model__alpha': 100, 'model__eta': 0.4, 'mode...           0.434434   \n",
       "586  {'model__alpha': 100, 'model__eta': 0.4, 'mode...           0.450964   \n",
       "587  {'model__alpha': 100, 'model__eta': 0.4, 'mode...           0.450042   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.753945           0.722238         0.753318        0.025124   \n",
       "1             0.609258           0.665875         0.625782        0.028495   \n",
       "2             0.753945           0.722238         0.753318        0.025124   \n",
       "3             0.736616           0.718570         0.735422        0.013300   \n",
       "4             0.754467           0.720494         0.750263        0.022784   \n",
       "..                 ...                ...              ...             ...   \n",
       "583           0.435711           0.492631         0.461998        0.023440   \n",
       "584           0.439568           0.494351         0.461628        0.023602   \n",
       "585           0.416671           0.480470         0.443858        0.026885   \n",
       "586           0.439568           0.494351         0.461628        0.023602   \n",
       "587           0.439568           0.494351         0.461320        0.023744   \n",
       "\n",
       "     rank_test_score  \n",
       "0                  9  \n",
       "1                353  \n",
       "2                  9  \n",
       "3                157  \n",
       "4                 27  \n",
       "..               ...  \n",
       "583              548  \n",
       "584              554  \n",
       "585              573  \n",
       "586              554  \n",
       "587              567  \n",
       "\n",
       "[588 rows x 16 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuned_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_results = fine_tuned_results[['param_model__alpha', 'param_model__lambda', 'param_model__eta', 'mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>param_model__eta</th>\n",
       "      <th>param_model__lambda</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.203434</td>\n",
       "      <td>0.033296</td>\n",
       "      <td>0.024932</td>\n",
       "      <td>0.005607</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 0, 'model__eta': 0.2, 'model_...</td>\n",
       "      <td>0.783770</td>\n",
       "      <td>0.753945</td>\n",
       "      <td>0.722238</td>\n",
       "      <td>0.753318</td>\n",
       "      <td>0.025124</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.122729</td>\n",
       "      <td>0.007057</td>\n",
       "      <td>0.014816</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 0.001, 'model__eta': 0.2, 'mo...</td>\n",
       "      <td>0.792543</td>\n",
       "      <td>0.752593</td>\n",
       "      <td>0.729624</td>\n",
       "      <td>0.758253</td>\n",
       "      <td>0.025997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.164408</td>\n",
       "      <td>0.022737</td>\n",
       "      <td>0.020759</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 0.01, 'model__eta': 0.2, 'mod...</td>\n",
       "      <td>0.786467</td>\n",
       "      <td>0.750735</td>\n",
       "      <td>0.716409</td>\n",
       "      <td>0.751204</td>\n",
       "      <td>0.028603</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.160915</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>0.023316</td>\n",
       "      <td>0.005877</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 0.1, 'model__eta': 0.2, 'mode...</td>\n",
       "      <td>0.758145</td>\n",
       "      <td>0.754791</td>\n",
       "      <td>0.721028</td>\n",
       "      <td>0.744655</td>\n",
       "      <td>0.016763</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.161201</td>\n",
       "      <td>0.038591</td>\n",
       "      <td>0.017675</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 1, 'model__eta': 0.2, 'model_...</td>\n",
       "      <td>0.711580</td>\n",
       "      <td>0.703707</td>\n",
       "      <td>0.692547</td>\n",
       "      <td>0.702611</td>\n",
       "      <td>0.007809</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>0.122539</td>\n",
       "      <td>0.012837</td>\n",
       "      <td>0.012578</td>\n",
       "      <td>0.003378</td>\n",
       "      <td>10</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 10, 'model__eta': 0.2, 'model...</td>\n",
       "      <td>0.544155</td>\n",
       "      <td>0.531775</td>\n",
       "      <td>0.598202</td>\n",
       "      <td>0.558044</td>\n",
       "      <td>0.028843</td>\n",
       "      <td>435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.127488</td>\n",
       "      <td>0.015520</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>100</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>{'model__alpha': 100, 'model__eta': 0.2, 'mode...</td>\n",
       "      <td>0.453845</td>\n",
       "      <td>0.439568</td>\n",
       "      <td>0.493667</td>\n",
       "      <td>0.462360</td>\n",
       "      <td>0.022892</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.203434      0.033296         0.024932        0.005607   \n",
       "84        0.122729      0.007057         0.014816        0.000367   \n",
       "168       0.164408      0.022737         0.020759        0.004926   \n",
       "252       0.160915      0.035700         0.023316        0.005877   \n",
       "336       0.161201      0.038591         0.017675        0.002436   \n",
       "420       0.122539      0.012837         0.012578        0.003378   \n",
       "504       0.127488      0.015520         0.006682        0.000669   \n",
       "\n",
       "    param_model__alpha param_model__eta param_model__lambda  \\\n",
       "0                    0              0.2                   0   \n",
       "84               0.001              0.2                   0   \n",
       "168               0.01              0.2                   0   \n",
       "252                0.1              0.2                   0   \n",
       "336                  1              0.2                   0   \n",
       "420                 10              0.2                   0   \n",
       "504                100              0.2                   0   \n",
       "\n",
       "    param_model__max_depth param_model__n_estimators  \\\n",
       "0                     None                       100   \n",
       "84                    None                       100   \n",
       "168                   None                       100   \n",
       "252                   None                       100   \n",
       "336                   None                       100   \n",
       "420                   None                       100   \n",
       "504                   None                       100   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "0    {'model__alpha': 0, 'model__eta': 0.2, 'model_...           0.783770   \n",
       "84   {'model__alpha': 0.001, 'model__eta': 0.2, 'mo...           0.792543   \n",
       "168  {'model__alpha': 0.01, 'model__eta': 0.2, 'mod...           0.786467   \n",
       "252  {'model__alpha': 0.1, 'model__eta': 0.2, 'mode...           0.758145   \n",
       "336  {'model__alpha': 1, 'model__eta': 0.2, 'model_...           0.711580   \n",
       "420  {'model__alpha': 10, 'model__eta': 0.2, 'model...           0.544155   \n",
       "504  {'model__alpha': 100, 'model__eta': 0.2, 'mode...           0.453845   \n",
       "\n",
       "     split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.753945           0.722238         0.753318        0.025124   \n",
       "84            0.752593           0.729624         0.758253        0.025997   \n",
       "168           0.750735           0.716409         0.751204        0.028603   \n",
       "252           0.754791           0.721028         0.744655        0.016763   \n",
       "336           0.703707           0.692547         0.702611        0.007809   \n",
       "420           0.531775           0.598202         0.558044        0.028843   \n",
       "504           0.439568           0.493667         0.462360        0.022892   \n",
       "\n",
       "     rank_test_score  \n",
       "0                  9  \n",
       "84                 1  \n",
       "168               19  \n",
       "252               71  \n",
       "336              276  \n",
       "420              435  \n",
       "504              530  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_results = fine_tuned_results[(fine_tuned_results['param_model__lambda'] == 0) & (fine_tuned_results['param_model__eta'] == 0.2) & (fine_tuned_results['param_model__max_depth'].isna())]\n",
    "filtered_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>param_model__lambda</th>\n",
       "      <th>param_model__eta</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.753318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.758253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.751204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.744655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.702611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.558044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.462360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_model__alpha param_model__lambda param_model__eta  mean_test_score\n",
       "0                    0                   0              0.2         0.753318\n",
       "84               0.001                   0              0.2         0.758253\n",
       "168               0.01                   0              0.2         0.751204\n",
       "252                0.1                   0              0.2         0.744655\n",
       "336                  1                   0              0.2         0.702611\n",
       "420                 10                   0              0.2         0.558044\n",
       "504                100                   0              0.2         0.462360"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easy_results = filtered_results[['param_model__alpha', 'param_model__lambda', 'param_model__eta', 'mean_test_score']]\n",
    "easy_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGhCAYAAABCse9yAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA/W0lEQVR4nO3deXhU5cH+8XtmksyQkARCICyJAdnCviTs4quCQfhpRduS1jaoxVrqilStlL5vK29fcWkRsUJFwYgLYqVYWkGICgaEWsBAVfZFEyAhJJBMAmSbmd8fgZGQkGRCMmdm8v1c11ySM+ec3PNckdw8c84zJpfL5RIAAIAPMxsdAAAAoD4UFgAA4PMoLAAAwOdRWAAAgM+jsAAAAJ9HYQEAAD6PwgIAAHxekNEBmorT6dTx48cVHh4uk8lkdBwAANAALpdLxcXF6ty5s8zmy8+jBExhOX78uOLi4oyOAQAAGiE7O1uxsbGXfT5gCkt4eLikqhccERFhcBoAANAQdrtdcXFx7t/jlxMwheXC20AREREUFgAA/Ex9l3Nw0S0AAPB5FBYAAODzKCwAAMDnUVgAAIDPo7AAAACfR2EBAAA+j8ICAAB8HoUFAAD4PAoLAADweRQWAADg8ygsAADA51FYAACAzwuYDz+84FBesVqfq/sDlDwVZDErKixEEbagej+cCQAANL2AKyy3vrRFZmtos5w7xGJWdOsQtWttVXTrEEW3trr/3D7cev7rqu1tQ0NkMVNuAABoCgFXWNqGBstiC2nSc5ZXOlVSVqlyh1PHi0p1vKi03mPMJikqrKq8RJ8vNe0u+nN0uFXRYVZFh4eoXZhVIUG8OwcAwOWYXC6Xy+gQTcFutysyMlJFRUWKiIho8vOXVjiUX1KmgpJy5ZeUnX+Uf/ff4qptBWfKdfpsuTwd1QhbUFWJaW1V+4tmai6etWnfuqrghIYEXM8EALRQDf39zW++BrIFWxTbNlSxbet/u6nS4dSpM+UXFZoyd9k5eVHBKThTta3S6ZK9tFL20kodPnmm3vO3CrYoOrz67M2l5eZCwYloxXU3AAD/R2FpBkEWszpE2NQhwlbvvk6nS0XnKi6Zsak+k3OypFwF5/9cWuHUuQqHsk+dU/apc/WeP9hiUruL3nqKPj9Lc+ksTnRrq6LCuO4GAOCbKCwGM5tNahsWorZhIeoZU/e+LpdLZ8od7tmZk8XltbxN9d1MTnFppSocLuXaS5Vrr/+6G5NJigoNqTFTEx0e4r7e5uILja1BliYaBQAA6kZh8SMmk0mtrUFqbQ1S1+iwevcvrXCo4Mx3szP5xVVFpqCWmZxT56+7KThTroIz5dKJ+vOE24Iue71NdGur2l+Y1Qm3KizEwltTAIBGa1RhWbhwoZ577jnl5OSoX79+mj9/vsaOHVvrvnfddZdef/31Gtv79u2rr7/+WpKUlpamu+++u8Y+586dk81W/9sqqJ0t2KIubVqpS5tW9e5b6XDq1Nny6rM1xeXKP3P+vxcVnIIzZapwuFRcWqni0kodzq//uhtbsNk9O9O+dS2zOOdnbaLCQtSGW8IBAJfwuLCsWLFCM2bM0MKFCzVmzBi9/PLLmjhxonbv3q2rrrqqxv4vvPCCnn76affXlZWVGjRokH74wx9W2y8iIkL79u2rto2y4j1BFrM6hNvUIbz+MXe5Llx3c3G5qbpDKr/koreqzpedcxUOlVY4dfT0OR09Xf91N2aT1Da0qrxEhYWoXesLf7aq3YVtYVW3iUeFhahtaLCCLNwWDgCBzOPbmkeMGKGhQ4dq0aJF7m19+vTR5MmTNXfu3HqPf//993X77bfryJEjio+Pl1Q1wzJjxgwVFhY2OEdZWZnKysrcX9vtdsXFxTXbbc1ovDNllRfdIVXzouLvZnLKZC+tbNT3aBMa7C4yF8pNdOuLSk+Y1V1+2oaGsO4NAPiIZrmtuby8XDt27NATTzxRbXtycrK2bNnSoHMsWbJE48ePd5eVC0pKShQfHy+Hw6HBgwfrf//3fzVkyJDLnmfu3Ll68sknPYkPg4RZgxRmDdJV7eq/JbzC4dTp89fRnDr/34KSMvefT5Vc2F61rfBchVwuqfBshQrPVjTotnCp6vqbi2dpvis6F2Z0rNW22YK5wBgAjORRYcnPz5fD4VBMTPXbWWJiYpSbm1vv8Tk5OVq7dq3efvvtatsTEhKUlpamAQMGyG6364UXXtCYMWO0a9cu9ezZs9ZzzZo1SzNnznR/fWGGBf4t2INbwqWqa28Kz1W4r605daHonC82F5ebgpKqRf2cLrmvv/mm4GyDvk9ra9BFszXni0zrC3+uuh6n3UWzOa1CKDgA0JQaddHtpXd7uFyuBt0BkpaWpjZt2mjy5MnVto8cOVIjR450fz1mzBgNHTpUL774ohYsWFDruaxWq6xWq+fhEVCCLGb3RbtSeL37O50uFZ6r0Knzi/adumg2p7YZndNnqhb2KymrVElZpbJONazgtAq2XHL9TYh7rZuLS0+7MKuiWodwFxUA1MOjwhIdHS2LxVJjNiUvL6/GrMulXC6Xli5dqtTUVIWE1P1ZP2azWcOGDdOBAwc8iQfUy2w2uUtDjw717+9yuWQ/V/ndLI17BqesetG5aEan3FG1uN+xwnM6Vlj/RcaSFBJkPv8WVc23o9pd9FbVhYITbmUFYwAti0eFJSQkRImJiUpPT9dtt93m3p6enq5bb721zmM//fRTHTx4UNOmTav3+7hcLu3cuVMDBgzwJB7Q5EwmkyJDgxUZGqyr29e/v8tVNRtz4aMZqkpM2SXX33xXbvJLylRW6VR5pVM5RaXKacAHa0pVKxhfeufUpXdPXZjdaRcWoghbsMzcKg7Aj3n8ltDMmTOVmpqqpKQkjRo1SosXL1ZWVpamT58uqerakmPHjmnZsmXVjluyZIlGjBih/v371zjnk08+qZEjR6pnz56y2+1asGCBdu7cqZdeeqmRLwswhslkUrgtWOG2YMW3q39xP5fLpbPljouKTNkl19/UnNE5W+5QhcOlE/YynbCX1fs9JMliNqltaFV5aR9u1aQBnfTDpFgFczs4AD/hcWFJSUlRQUGB5syZo5ycHPXv319r1qxx3/WTk5OjrKysascUFRVp5cqVeuGFF2o9Z2Fhoe69917l5uYqMjJSQ4YMUUZGhoYPH96IlwT4D5PJ5L6LKi6q/ruopO9WMD516YXGl95RdX6f4rJKOZwu923k+04Ua/PBfC3OOKSZyb1184BOzL4A8Hker8Piqxp6HzfQ0pRVOnT6TIW73OzJsevlTw9XfQSDpL6dIvTYTb11Xa/2XBcDwOsa+vubwgK0QCVllVq6+YgWZxxWSVnVYn3Du0Xp1zf1VmJ8lMHpALQkFBYA9Tp1plyLNh7U61u/VXmlU5I0vk8HPTqhtxI68v8RgOZHYQHQYMcLz2nBxwf07vZsOV2SySRNHtxFj4zv1aAVigGgsSgsADx26GSJ5q3frw++zJFUdfv0j4dfpQdu6NGgD8YEAE9RWAA02pdHi/Tsur3adCBfUtXKvT+7pqvuvba7IlsFG5wOQCChsAC4YlsO5evZD/dpZ3ahJCmyVbB+eV133TmqK5+XBKBJUFgANAmXy6X1u0/oj+v26UBeiSQpJsKqh8b11JSkOBafA3BFKCwAmpTD6dKqzGN6Pn2/+zOSurYLZfE5AFeEwgKgWZRVOvT251n68ycHWXwOwBWjsABoVhcWn3sl47CKWXwOQCNRWAB4BYvPAbgSFBYAXnVh8bm/7jgqh9PF4nMAGoTCAsAQLD4HwBMUFgCGYvE5AA1BYQHgE1h8DkBdKCwAfAaLzwG4HAoLAJ/jcLr0fuYxzWPxOQDnUVgA+KyySoeWf56lF1l8DmjxKCwAfB6LzwGgsADwGyw+B7RcFBYAfofF54CWh8ICwG+x+BzQclBYAPg9Fp8DAh+FBUDAYPE5IHBRWAAEFJfLpfTdJ/Qci88BAYXCAiAgsfgcEFgoLAACGovPAYGBwgKgRWDxOcC/UVgAtCgsPgf4JwoLgBaJxecA/0JhAdCisfgc4B8oLAAgFp8DfB2FBQAuwuJzgG+isADAJWpbfK5DuFUPj2fxOcAoFBYAuAwWnwN8B4UFAOrB4nOA8SgsANBALD4HGIfCAgAeOn2mXIs+PaS0Ld+w+BzgJRQWAGiknKKqxefe3c7ic0Bzo7AAwBVi8Tmg+VFYAKCJsPgc0HwoLADQxFh8Dmh6FBYAaAYsPgc0LQoLADQjFp8DmgaFBQC8gMXngCvT0N/fjZq7XLhwobp16yabzabExERt2rTpsvveddddMplMNR79+vWrtt/KlSvVt29fWa1W9e3bV6tWrWpMNADwKmuQRXeN6aaMx6/Xr27spXBrkHbn2HX3a9v065X/MToeEDA8LiwrVqzQjBkzNHv2bGVmZmrs2LGaOHGisrKyat3/hRdeUE5OjvuRnZ2tqKgo/fCHP3Tvs3XrVqWkpCg1NVW7du1SamqqpkyZos8//7zxrwwAvCjMGqQHx/VUxuPX695rr5bFbNK724/q88MFRkcDAoLHbwmNGDFCQ4cO1aJFi9zb+vTpo8mTJ2vu3Ln1Hv/+++/r9ttv15EjRxQfHy9JSklJkd1u19q1a9373XTTTWrbtq2WL1/eoFy8JQTAl/z2/S/15r+yNCg2Uu/fP4a3hoDLaJa3hMrLy7Vjxw4lJydX256cnKwtW7Y06BxLlizR+PHj3WVFqpphufScEyZMqPOcZWVlstvt1R4A4CseHtdLYSEW7TpapH/+J8foOIDf86iw5Ofny+FwKCYmptr2mJgY5ebm1nt8Tk6O1q5dq3vuuafa9tzcXI/POXfuXEVGRrofcXFxHrwSAGhe7cOt+sV/dZckPbtur8oqHQYnAvxboy66vXRq0+VyNWi6My0tTW3atNHkyZOv+JyzZs1SUVGR+5Gdnd2w8ADgJfeM7aYO4VZlnzqnN/9V+3V+ABrGo8ISHR0ti8VSY+YjLy+vxgzJpVwul5YuXarU1FSFhIRUe65jx44en9NqtSoiIqLaAwB8SWhIkGbe2EuS9OInB1R0rsLgRID/8qiwhISEKDExUenp6dW2p6ena/To0XUe++mnn+rgwYOaNm1ajedGjRpV45zr16+v95wA4Ot+kBirXjGtVXi2Qgs3HjQ6DuC3PH5LaObMmXr11Ve1dOlS7dmzR4888oiysrI0ffp0SVVv1UydOrXGcUuWLNGIESPUv3//Gs89/PDDWr9+vZ555hnt3btXzzzzjD766CPNmDHD81cEAD4kyGLWExMTJEmvffaNjp4+a3AiwD95XFhSUlI0f/58zZkzR4MHD1ZGRobWrFnjvusnJyenxposRUVFWrlyZa2zK5I0evRovfPOO3rttdc0cOBApaWlacWKFRoxYkQjXhIA+Jbre3fQqKvbqbzSqT+t3290HMAvsTQ/AHjBl0eLdMufN0uS/vngNerfJdLgRIBvaNal+QEAnhkQG6lbB3eWJM1du0cB8m9FwGsoLADgJY8m91aIxazPDhZo4/6TRscB/AqFBQC8JC4qVHeN6SpJenrNXjmczLIADUVhAQAvuv+6HopsFax9J4q1csdRo+MAfoPCAgBeFBkarAdv6CFJ+lP6Pp0rZ8l+oCEoLADgZamj4hXbtpVO2Mu0ZPNho+MAfoHCAgBeZg2y6LEJvSVJf/n0sPJLygxOBPg+CgsAGOCWgZ01MDZSJWWVWvDxAaPjAD6PwgIABjCbTZo1sY8k6e3Ps3T4ZInBiQDfRmEBAIOM6t5O4xI6qNLp0jMf7jU6DuDTKCwAYKAnJibIbJLWfX1C2785ZXQcwGdRWADAQD1jwpUyLE6S9NQaluwHLofCAgAGe2R8L7UKtuiLrEKt/SrX6DiAT6KwAIDBOkTY9PNrr5YkPfvhXpVXOg1OBPgeCgsA+IBfXHu1oltb9U3BWb39+bdGxwF8DoUFAHxAmDVIj9zYU5K04JODspdWGJwI8C0UFgDwESlJcerePkynzpTrLxsPGR0H8CkUFgDwEUEWs544v5jcks1HdLzwnMGJAN9BYQEAHzK+TwcN7xalskqn5qXvNzoO4DMoLADgQ0wmk34zqWqWZeUXR7X7uN3gRIBvoLAAgI8ZHNdGNw/sJJdLmrt2j9FxAJ9AYQEAH/T4hAQFW0zadCBfGftPGh0HMByFBQB80FXtQpU6sqskae7avXI4WbIfLRuFBQB81IM39FC4LUh7cux6P/OY0XEAQ1FYAMBHtQ0L0f3X95Ak/Wn9PpVWOAxOBBiHwgIAPuyu0V3VpU0rHS8q1dLPjhgdBzAMhQUAfJgt2KJHJ/SSJC3acEinzpQbnAgwBoUFAHzcrYO6qF/nCBWXVWrBxweMjgMYgsICAD7ObP5uMbk3//Wtvsk/Y3AiwPsoLADgB8b0iNZ1vdur0unSc+v2GR0H8DoKCwD4iScmJshskj74MkdfZJ02Og7gVRQWAPATCR0j9IPEWEnSUx/skcvFYnJoOSgsAOBHZt7YW7Zgs7Z/e1rrd58wOg7gNRQWAPAjHSNtuueaqyVJz6zdqwqH0+BEgHdQWADAz/ziv65Wu7AQHc4/o3e2ZRsdB/AKCgsA+JlwW7AeHt9TkvTCR/tVUlZpcCKg+VFYAMAP/Xj4Vbo6Okz5JeV6+dNDRscBmh2FBQD8ULDFrMdvSpAkvbLpsE7YSw1OBDQvCgsA+KkJ/WKUFN9WpRVOzVu/3+g4QLOisACAnzKZTJp1fsn+v+7I1r7cYoMTAc2HwgIAfiwxvq0m9u8op0t6eu0eo+MAzYbCAgB+7vGbEhRkNmnDvpPacjDf6DhAs6CwAICf6xYdpp+OjJckPbV2j5xOluxH4KGwAEAAePCGHgq3BumrY3at3nXc6DhAk6OwAEAAaNfaqunXdZckPbdun0orHAYnApoWhQUAAsS0a7qpU6RNxwrPadnWb4yOAzSpRhWWhQsXqlu3brLZbEpMTNSmTZvq3L+srEyzZ89WfHy8rFarunfvrqVLl7qfT0tLk8lkqvEoLWUhJABoKFuwRTNv7CVJ+vMnB1V4ttzgREDT8biwrFixQjNmzNDs2bOVmZmpsWPHauLEicrKyrrsMVOmTNHHH3+sJUuWaN++fVq+fLkSEhKq7RMREaGcnJxqD5vN5vkrAoAW7PahsUroGC57aaVe/OSg0XGAJmNyuVweXU4+YsQIDR06VIsWLXJv69OnjyZPnqy5c+fW2P/DDz/Uj370Ix0+fFhRUVG1njMtLU0zZsxQYWGhZ+kvYrfbFRkZqaKiIkVERDT6PADg7zL2n9TUpf9WsMWkT351neKiQo2OBFxWQ39/ezTDUl5erh07dig5Obna9uTkZG3ZsqXWY1avXq2kpCQ9++yz6tKli3r16qVHH31U586dq7ZfSUmJ4uPjFRsbq5tvvlmZmZl1ZikrK5Pdbq/2AABI1/Zqr7E9o1XhcOnZdfuMjgM0CY8KS35+vhwOh2JiYqptj4mJUW5ubq3HHD58WJs3b9ZXX32lVatWaf78+Xrvvfd0//33u/dJSEhQWlqaVq9ereXLl8tms2nMmDE6cODAZbPMnTtXkZGR7kdcXJwnLwUAAtoTExNkMkn/2HVcu7ILjY4DXLFGXXRrMpmqfe1yuWpsu8DpdMpkMumtt97S8OHDNWnSJM2bN09paWnuWZaRI0fqpz/9qQYNGqSxY8fq3XffVa9evfTiiy9eNsOsWbNUVFTkfmRnZzfmpQBAQOrXOVK3DekiSXpqzR55+O4/4HM8KizR0dGyWCw1ZlPy8vJqzLpc0KlTJ3Xp0kWRkZHubX369JHL5dLRo0drD2U2a9iwYXXOsFitVkVERFR7AAC+82hyb1mDzPr8yCl9vCfP6DjAFfGosISEhCgxMVHp6enVtqenp2v06NG1HjNmzBgdP35cJSUl7m379++X2WxWbGxsrce4XC7t3LlTnTp18iQeAOAindu00s+u6SZJevrDvap0OA1OBDSex28JzZw5U6+++qqWLl2qPXv26JFHHlFWVpamT58uqeqtmqlTp7r3v+OOO9SuXTvdfffd2r17tzIyMvTYY4/pZz/7mVq1aiVJevLJJ7Vu3TodPnxYO3fu1LRp07Rz5073OQEAjfPL67qrbWiwDuaV6N3ttc9qA/4gyNMDUlJSVFBQoDlz5ignJ0f9+/fXmjVrFB9f9cFbOTk51dZkad26tdLT0/Xggw8qKSlJ7dq105QpU/SHP/zBvU9hYaHuvfde5ebmKjIyUkOGDFFGRoaGDx/eBC8RAFquCFuwHhrXU0/+Y7fmpe/XrYM7K8zq8V/9gOE8XofFV7EOCwDUrrzSqRuf/1TfFpzVjPE9NWN8L6MjAW7Nsg4LAMD/hASZ9fiEqtXFF2ccVl4xH3sC/0NhAYAWYNKAjhoc10Znyx16Pv3yd2ACvorCAgAtgMlk0uz/10eStGJblg7mFRucCPAMhQUAWohhXaOU3DdGTpf09Nq9RscBPEJhAYAW5NcTE2Qxm/TRnjz963CB0XGABqOwAEAL0r19a/14eNVnr81ds0dOZ0DcKIoWgMICAC3Mw+N6KSzEol1Hi/TPL3OMjgM0CIUFAFqY9uFWTf+v7pKk59btVVmlw+BEQP0oLADQAk0b200dwq3KPnVOb2z91ug4QL0oLADQAoWGBOlXyVUr3r74yUEVna0wOBFQNwoLALRQP0iMU6+Y1io6V6GFGw8aHQeoE4UFAFooi9mkWROrFpN7bcs3Onr6rMGJgMujsABAC3Zd7/Ya3b2dyiud+uO6fUbHAS6LwgIALZjJ9N0sy/s7j+urY0UGJwJqR2EBgBZuQGykJg/uLEl6as0euVwsJgffQ2EBAOjRCb0VYjFry6ECbdx/0ug4QA0UFgCAYtuG6q4xXSVJT6/ZKwdL9sPHUFgAAJKk+6/rochWwdp3oljv7cg2Og5QDYUFACBJigwN1oM39JAkzUvfr7PllQYnAr5DYQEAuKWOildcVCudsJdpyaYjRscB3CgsAAA3a5BFj01IkCT95dNDOllcZnAioAqFBQBQzc0DOmlgbKTOlDu04OMDRscBJFFYAACXMJtN+s2kqsXk3v53lg6dLDE4EUBhAQDUYuTV7TS+Twc5nC49++Feo+MAFBYAQO1+fVOCzCZp3dcntO2bU0bHQQtHYQEA1KpnTLhShl0liSX7YTwKCwDgsh65sadCQyzKzCrU2q9yjY6DFozCAgC4rA7hNv187NWSpGc+3KvySqfBidBSUVgAAHW699qrFd3aqm8Lzuqtz781Og5aKAoLAKBOYdYgPXJjT0nSgo8PyF5aYXAitEQUFgBAvVKS4tSjQ2udPluhRRsPGR0HLRCFBQBQryCLWU/cVLVk/9LNR3S88JzBidDSUFgAAA0yrk8HDe8WpbJKp/60fr/RcdDCUFgAAA1iMpk0+/yS/X/LPKrdx+0GJ0JLQmEBADTYoLg2umVQZ7lc0ty1e4yOgxaEwgIA8Mhjyb0VbDFp04F8Zew/aXQctBAUFgCAR65qF6qpo7pKqlqy3+FkyX40PwoLAMBjD97QQxG2IO3NLdaqzGNGx0ELQGEBAHisTWiI7r++hyTpT+v3qbTCYXAiBDoKCwCgUe4c3VVd2rRSTlGplmw+YnQcBDgKCwCgUWzBFj06oZckadHGQyooKTM4EQIZhQUA0Gi3Duqi/l0iVFJWqRc/OWh0HAQwCgsAoNHMZpN+M7FqMbk3//Wtvsk/Y3AiBCoKCwDgiozuEa3rerdXpdOlZ9ftNToOAhSFBQBwxWZN7COzSVrzZa52fHva6DgIQBQWAMAV690xXD9MjJMkzV2zRy4Xi8mhaTWqsCxcuFDdunWTzWZTYmKiNm3aVOf+ZWVlmj17tuLj42W1WtW9e3ctXbq02j4rV65U3759ZbVa1bdvX61ataox0QAABnnkxl6yBZu1/dvTWvf1CaPjIMB4XFhWrFihGTNmaPbs2crMzNTYsWM1ceJEZWVlXfaYKVOm6OOPP9aSJUu0b98+LV++XAkJCe7nt27dqpSUFKWmpmrXrl1KTU3VlClT9PnnnzfuVQEAvK5jpE0/H3u1JOmZD/eqwuE0OBECicnl4bzdiBEjNHToUC1atMi9rU+fPpo8ebLmzp1bY/8PP/xQP/rRj3T48GFFRUXVes6UlBTZ7XatXbvWve2mm25S27ZttXz58gblstvtioyMVFFRkSIiIjx5SQCAJlJcWqHrntuogjPl+t9b+yn1/GcOAZfT0N/fHs2wlJeXa8eOHUpOTq62PTk5WVu2bKn1mNWrVyspKUnPPvusunTpol69eunRRx/VuXPn3Pts3bq1xjknTJhw2XNKVW8z2e32ag8AgLHCbcGaMb6nJGn+RwdUXFphcCIECo8KS35+vhwOh2JiYqptj4mJUW5ubq3HHD58WJs3b9ZXX32lVatWaf78+Xrvvfd0//33u/fJzc316JySNHfuXEVGRrofcXFxnrwUAEAz+dHwq3R1dJgKzpTr5U8PGx0HAaJRF92aTKZqX7tcrhrbLnA6nTKZTHrrrbc0fPhwTZo0SfPmzVNaWlq1WRZPzilJs2bNUlFRkfuRnZ3dmJcCAGhiwRazHr+p6jrFVzcfVm5RqcGJEAg8KizR0dGyWCw1Zj7y8vJqzJBc0KlTJ3Xp0kWRkZHubX369JHL5dLRo0clSR07dvTonJJktVoVERFR7QEA8A0T+sUoKb6tSiucmpe+z+g4CAAeFZaQkBAlJiYqPT292vb09HSNHj261mPGjBmj48ePq6SkxL1t//79MpvNio2NlSSNGjWqxjnXr19/2XMCAHybyWTSb/5f1ZL97+04qr25XGeIK+PxW0IzZ87Uq6++qqVLl2rPnj165JFHlJWVpenTp0uqeqtm6tSp7v3vuOMOtWvXTnfffbd2796tjIwMPfbYY/rZz36mVq1aSZIefvhhrV+/Xs8884z27t2rZ555Rh999JFmzJjRNK8SAOB1Q69qq0kDOsrpkp5ey5L9uDIeF5aUlBTNnz9fc+bM0eDBg5WRkaE1a9YoPj5ekpSTk1NtTZbWrVsrPT1dhYWFSkpK0k9+8hPdcsstWrBggXuf0aNH65133tFrr72mgQMHKi0tTStWrNCIESOa4CUCAIzy+IQEBZlN2rjvpD47mG90HPgxj9dh8VWswwIAvun3q79W2pZv1K9zhP7xwDUymy9/QwVanmZZhwUAAE89NK6nwq1B+vq4XX/fdczoOPBTFBYAQLOKCgvRL6/vLkn647r9Kq1wGJwI/ojCAgBodj8b002dIm06VnhOr2/5xug48EMUFgBAs7MFW/Sr5N6SpD9vOKjTZ8oNTgR/Q2EBAHjFbUO6qE+nCBWXVurPGw4aHQd+hsICAPAKi9mkWROrluxftvUbZRWcNTgR/AmFBQDgNdf2aq+xPaNV4XDp2XUsJoeGo7AAALxq1sQ+Mpmkf/4nRzuzC42OAz9BYQEAeFXfzhG6fUjVZ8k9tWaPAmT9UjQzCgsAwOt+ldxL1iCz/n3klD7ak2d0HPgBCgsAwOs6t2mln13TTZL09No9qnQ4DU4EX0dhAQAY4pfXdVdUWIgOnTyjFduzjY4DH0dhAQAYIsIWrIdu6CFJej79gErKKg1OBF9GYQEAGOaOEfHq2i5U+SVleiXjsNFx4MMoLAAAw4QEmfX4TVWLyS3OOKw8e6nBieCrKCwAAENN7N9RQ65qo3MVDj3/0QGj48BHUVgAAIYymUyaPamPJGnFtiwdOFFscCL4IgoLAMBwSV2jNKFfjJwu6em1LNmPmigsAACf8PhNCbKYTfp4b562HiowOg58DIUFAOATurdvrTuGXyVJmrt2j5xOluzHdygsAACf8fD4ngoLseg/R4v0j/8cNzoOfAiFBQDgM6JbWzX9v7pLkp5bt09llQ6DE8FXUFgAAD7lnrFXKybCqqOnz+mNrd8aHQc+gsICAPAprUIs+tWNvSVJL35yUEVnKwxOBF9AYQEA+JzvJ8aqd0y4is5V6KWNB42OAx9AYQEA+ByL2aQnJlUt2Z/22TfKPnXW4EQwGoUFAOCTruvVXqO7t1O5w6k/rd9ndBwYjMICAPBJJpNJvzm/ZP/7O4/ry6NFBieCkSgsAACf1b9LpG4b0kWS9NSaPXK5WEyupaKwAAB82q+SeykkyKythwu0cd9Jo+PAIBQWAIBPi20bqrtHd5VUtWR/pcNpbCAYgsICAPB5913fQ21Cg7X/RIne23HU6DgwAIUFAODzIlsF64Hre0iS5qXv19nySoMTwdsoLAAAv5A6Kl5xUa2UV1ymVzcdMToOvIzCAgDwC9Ygix6fULWY3MufHtLJ4jKDE8GbKCwAAL9x88BOGhQbqTPlDr3w8X6j48CLKCwAAL9hMpk06/xicsv/na2DeSUGJ4K3UFgAAH5l5NXtNL5PBzmcLj374V6j48BLKCwAAL/zxMQEWcwmrd99Qv8+csroOPACCgsAwO/06BCulGFxkqT/+2C3KlhMLuBRWAAAfmnG+J5qbQ3SrqNF+sM/dxsdB82MwgIA8Esdwm2aN2WQTCbp9a3f6s1/fWt0JDQjCgsAwG8l9+uoR5N7S5J+t/prbTmYb3AiNBcKCwDAr913XXdNHtxZDqdLv3zrC32Tf8boSGgGFBYAgF8zmUx6+vsDNTiujYrOVWja69tkL60wOhaaGIUFAOD3bMEWLZ6aqE6RNh06eUYPvp2pSu4cCiiNKiwLFy5Ut27dZLPZlJiYqE2bNl12340bN8pkMtV47N373WI/aWlpte5TWlramHgAgBaoQ7hNr0xNki3YrE/3n9TctSwqF0g8LiwrVqzQjBkzNHv2bGVmZmrs2LGaOHGisrKy6jxu3759ysnJcT969uxZ7fmIiIhqz+fk5Mhms3kaDwDQgvXvEql5UwZLkpZsPqIV2+r+3QT/4XFhmTdvnqZNm6Z77rlHffr00fz58xUXF6dFixbVeVyHDh3UsWNH98NisVR73mQyVXu+Y8eOdZ6vrKxMdru92gMAgEkDOumR8b0kSb99/yt9frjA4ERoCh4VlvLycu3YsUPJycnVticnJ2vLli11HjtkyBB16tRJ48aN04YNG2o8X1JSovj4eMXGxurmm29WZmZmneebO3euIiMj3Y+4uDhPXgoAIIA9NK6Hbh7YSRWOqjuHsk+dNToSrpBHhSU/P18Oh0MxMTHVtsfExCg3N7fWYzp16qTFixdr5cqV+tvf/qbevXtr3LhxysjIcO+TkJCgtLQ0rV69WsuXL5fNZtOYMWN04MCBy2aZNWuWioqK3I/s7GxPXgoAIICZTCY994NBGtAlUqfOlGva69tUzJ1Dfs3kcrlcDd35+PHj6tKli7Zs2aJRo0a5t//f//2f3njjjWoX0tbllltukclk0urVq2t93ul0aujQobr22mu1YMGCBp3TbrcrMjJSRUVFioiIaNAxAIDAlltUqu/9ebPyiss0LqGDFk9NksVsMjoWLtLQ398ezbBER0fLYrHUmE3Jy8urMetSl5EjR9Y5e2I2mzVs2LA69wEAoD4dI21aPDVJ1iCzPt6bp2fXceeQv/KosISEhCgxMVHp6enVtqenp2v06NENPk9mZqY6dep02eddLpd27txZ5z4AADTE4Lg2evYHAyVJL396WCt3HDU4ERojyNMDZs6cqdTUVCUlJWnUqFFavHixsrKyNH36dElV15YcO3ZMy5YtkyTNnz9fXbt2Vb9+/VReXq4333xTK1eu1MqVK93nfPLJJzVy5Ej17NlTdrtdCxYs0M6dO/XSSy810csEALRktw7uooN5JXrxk4Oa9bcv1TU6VInxUUbHggc8LiwpKSkqKCjQnDlzlJOTo/79+2vNmjWKj4+XJOXk5FRbk6W8vFyPPvqojh07platWqlfv3764IMPNGnSJPc+hYWFuvfee5Wbm6vIyEgNGTJEGRkZGj58eBO8RAAApEfG99L+E8Va9/UJ/eKNHfr7A9eoS5tWRsdCA3l00a0v46JbAEB9zpZX6vuLtmpPjl19OkXovemjFGb1+N/uaELNctEtAAD+LDQkSK/emaTo1lbtybFr5rs75XQGxL/bAx6FBQDQonRp00ovpyYqxGLWuq9PaF76fqMjoQEoLACAFicxvq2e/v4ASdKfNxzU33ceMzgR6kNhAQC0SLcPjdX0/+ouSXrsvf9oZ3ahsYFQJwoLAKDFemxCb43v00HllU79fNl25RSdMzoSLoPCAgBosSxmk+b/aIh6x4TrZHGZ7l22Q+fKHUbHQi0oLACAFq21terOoaiwEH15rEiP/nWXAmTFj4BCYQEAtHhxUaH6y08TFWwx6YMvc/TCx3yWna+hsAAAIGl4tyj93+SqO4fmf3RAH/wnx+BEuBiFBQCA86YMi9M913STJP3qrzv15dEigxPhAgoLAAAXmTWpj67r3V6lFVV3DuXZS42OBFFYAACoxmI2acGPh6hHh9bKtZfq52/sUGkFdw4ZjcICAMAlImzBWnJnktqEBmtXdqF+vfI/3DlkMAoLAAC1iG8XpoU/Gaogs0l/33lcCzceMjpSi0ZhAQDgMkZ3j9aTt/aTJD23bp8+/CrX4EQtF4UFAIA6/GREvO4cFS9JmvnuTu0+bjc4UctEYQEAoB7/fXNfXdMjWmfLHbrn9W06WVxmdKQWh8ICAEA9gixmvXTHUF0dHabjRaWa/uYOlVVy55A3UVgAAGiAyNBgvXpnkiJsQdrx7WnN+tuX3DnkRRQWAAAa6Or2rfXST4bKYjbpb18c0+KMw0ZHajEoLAAAeGBsz/b6n5v7SpKe/nCvPt5zwuBELQOFBQAAD00dFa87Rlwll0t6aHmm9uUWGx0p4FFYAADwkMlk0pPf66eRV0fpTLlD9yzbplNnyo2OFdAoLAAANEKwxaxFP0lUfLtQZZ86p+lv7lB5pdPoWAGLwgIAQCO1DQvRkjuTFG4N0r+PnNL//P0r7hxqJhQWAACuQI8O4VpwxxCZTdI727L12mffGB0pIFFYAAC4Qtf37qDfTOojSfrDB7u1cV+ewYkCD4UFAIAmMO2abpqSFCunS3rw7UwdzCsxOlJAobAAANAETCaT/jB5gIZ3jVJxWaXueX2bCs9y51BTobAAANBEQoLMWvTToYpt20rfFJzVfW99oQoHdw41BQoLAABNqF1rq169M0lhIRZtOVSgJ//xtdGRAgKFBQCAJpbQMUIv/GiITCbpzX9l6Y2t3xgdye9RWAAAaAbj+8bo1zclSJJ+/4/d2nwg3+BE/o3CAgBAM/nFtVfr9iFd5HC6dN9bO3Qk/4zRkfwWhQUAgGZiMpn01O0DNOSqNrKXVmra69tUdK7C6Fh+icICAEAzsgVb9HJqojpH2nT45Bk98PYXquTOIY9RWAAAaGYdwm165c4ktQq2aNOBfP3hgz1GR/I7FBYAALygX+dIPZ8ySJKUtuUbvf15lsGJ/AuFBQAAL7mpfyf96sZekqT/+ftX2nqowOBE/oPCAgCAFz1wQw/dMqizKp0u/fKtHcoqOGt0JL9AYQEAwItMJpOe+8FADYqNVOHZCk17fZuKS7lzqD4UFgAAvMwWbNHiqUmKibDqQF6JHlqeKYfTZXQsn0ZhAQDAADERNr0yNUm2YLM27Dupp9dy51BdKCwAABhkYGwb/fGHVXcOvbLpiN7dnm1wIt9FYQEAwEA3D+ysh8b1lCTNXvWltn1zyuBEvonCAgCAwWaM66lJAzqqwuHS9Dd2KPsUdw5dqlGFZeHCherWrZtsNpsSExO1adOmy+67ceNGmUymGo+9e/dW22/lypXq27evrFar+vbtq1WrVjUmGgAAfsdsNumPPxykfp0jVHCmXD9ftl0lZZVGx/IpHheWFStWaMaMGZo9e7YyMzM1duxYTZw4UVlZda/Yt2/fPuXk5LgfPXv2dD+3detWpaSkKDU1Vbt27VJqaqqmTJmizz//3PNXBACAHwoNCdKrdyapfbhVe3OLNeOdnXJy55CbyeVyeTQaI0aM0NChQ7Vo0SL3tj59+mjy5MmaO3dujf03btyo66+/XqdPn1abNm1qPWdKSorsdrvWrl3r3nbTTTepbdu2Wr58ea3HlJWVqayszP213W5XXFycioqKFBER4clLAgDAZ2RmnVbK4n+pvNKp+67rrsdvSjA6UrOy2+2KjIys9/e3RzMs5eXl2rFjh5KTk6ttT05O1pYtW+o8dsiQIerUqZPGjRunDRs2VHtu69atNc45YcKEOs85d+5cRUZGuh9xcXGevBQAAHzSkKva6tnvD5QkLdx4SKsyjxqcyDd4VFjy8/PlcDgUExNTbXtMTIxyc3NrPaZTp05avHixVq5cqb/97W/q3bu3xo0bp4yMDPc+ubm5Hp1TkmbNmqWioiL3IzubW8EAAIFh8pAuuu+67pKkX6/8Ul9knTY4kfGCGnOQyWSq9rXL5aqx7YLevXurd+/e7q9HjRql7Oxs/fGPf9S1117bqHNKktVqldVqbUx8AAB83qPJvXUgr0Tpu0/o3mU7tPqBMercppXRsQzj0QxLdHS0LBZLjZmPvLy8GjMkdRk5cqQOHDjg/rpjx45XfE4AAAKJ2WzS/JTBSugYrvySMv182XadLW+5dw55VFhCQkKUmJio9PT0atvT09M1evToBp8nMzNTnTp1cn89atSoGudcv369R+cEACDQhFmr7hxqFxair4/b9at3d7XYO4c8fkto5syZSk1NVVJSkkaNGqXFixcrKytL06dPl1R1bcmxY8e0bNkySdL8+fPVtWtX9evXT+Xl5XrzzTe1cuVKrVy50n3Ohx9+WNdee62eeeYZ3Xrrrfr73/+ujz76SJs3b26ilwkAgH+KbRuql1MT9eNX/qW1X+Vq/scHNPPGXkbH8jqPC0tKSooKCgo0Z84c5eTkqH///lqzZo3i4+MlSTk5OdXWZCkvL9ejjz6qY8eOqVWrVurXr58++OADTZo0yb3P6NGj9c477+i3v/2t/vu//1vdu3fXihUrNGLEiCZ4iQAA+LekrlF66rYBeuy9/2jBxwfUs0Nr3TKos9GxvMrjdVh8VUPv4wYAwF89tWaPFmccljXIrL9OH6WBsW2MjnTFmmUdFgAAYJxf35SgGxI6qKzSqZ8v267colKjI3kNhQUAAD9hMZv0wo8Gq2eH1jphL9O9b2xXaYXD6FheQWEBAMCPhNuCteTOYWobGqz/HC3SY+/9RwFydUedKCwAAPiZq9qFatFPExVkNukfu47rz58cNDpSs6OwAADgh0Ze3U7/O7m/JOlP6fu19sscgxM1LwoLAAB+6sfDr9LdY7pKkma+u0tfHSsyNlAzorAAAODHZk/qo2t7tde5Cod+vmy78ooD884hCgsAAH4syGLWiz8eoqvbhymnqFS/eGNHQN45RGEBAMDPRbaqunMoslWwMrMKNetvXwbcnUMUFgAAAkC36DAt/MlQWcwmrco8pr98etjoSE2KwgIAQIAY0yNav7+lryTp2XV7lb77hMGJmg6FBQCAAJI6qqtSR8bL5ZIefidTe3LsRkdqEhQWAAACzP/c0ldjerTT2XKH7nl9u/JLyoyOdMUoLAAABJhgi1kv3TFUXduF6ljhOf3yzR0qq/TvO4coLAAABKA2oSF69c5hCrcFads3p/XbVV/59Z1DFBYAAAJUjw6t9eKPh8hskv6646iWbD5idKRGo7AAABDAruvdQb/9f1V3Dj21Zo827M0zOFHjUFgAAAhwd4/pqh8Ni5PTJT24PFMHThQbHcljFBYAAAKcyWTSnFv7a3i3KJWUVWra69t1+ky50bE8QmEBAKAFCAky6y8/TVRcVCtlnTqrX761Q+WVTqNjNRiFBQCAFiIqLERL7hymsBCL/nX4lH63+mu/uXOIwgIAQAvSKyZcC348RCaTtPzfWXp9yzdGR2oQCgsAAC3MuD4xmjUxQZI055+7lbH/pMGJ6kdhAQCgBfr52Kv1/aGxcrqk+9/+QodOlhgdqU4UFgAAWiCTyaSnbu+vxPi2Ki6t1D2vb1fR2QqjY10WhQUAgBbKGmTRy6mJ6tKmlY7kn9H9b3+hCodv3jlEYQEAoAWLbm3VK1OTFBpi0eaD+frDP3cbHalWFBYAAFq4vp0j9HzKYEnS61u/1Zv/+tbYQLWgsAAAAE3o11GPTegtSfrd6q+15WC+wYmqo7AAAABJ0n3XddfkwZ3lcLr0y7e+0Df5Z4yO5EZhAQAAkqruHHr6+wM1KK6Nis5VaNrr22Qv9Y07hygsAADAzRZs0SupieoUadOhk2f04NuZqvSBO4coLAAAoJoOETa9MjVJtmCzPt1/UnPX7jU6EoUFAADU1L9LpOZNGSxJWrL5iFZsyzI0D4UFAADUatKATnpkfC9J0m/f/0qfHy4wLEuQYd8ZAAD4vIfG9dD+vGLtzCpUuC3YsBwUFgAAcFkmk0l//MEgnSmvVHRrq2E5KCwAAKBOrUIsahViMTQD17AAAACfR2EBAAA+j8ICAAB8HoUFAAD4PAoLAADweRQWAADg8ygsAADA5zWqsCxcuFDdunWTzWZTYmKiNm3a1KDjPvvsMwUFBWnw4MHVtqelpclkMtV4lJaWNiYeAAAIMB4XlhUrVmjGjBmaPXu2MjMzNXbsWE2cOFFZWXV/KFJRUZGmTp2qcePG1fp8RESEcnJyqj1sNpun8QAAQADyuLDMmzdP06ZN0z333KM+ffpo/vz5iouL06JFi+o87he/+IXuuOMOjRo1qtbnTSaTOnbsWO0BAAAgeVhYysvLtWPHDiUnJ1fbnpycrC1btlz2uNdee02HDh3S7373u8vuU1JSovj4eMXGxurmm29WZmZmnVnKyspkt9urPQAAQGDyqLDk5+fL4XAoJiam2vaYmBjl5ubWesyBAwf0xBNP6K233lJQUO0fXZSQkKC0tDStXr1ay5cvl81m05gxY3TgwIHLZpk7d64iIyPdj7i4OE9eCgAA8CONuujWZDJV+9rlctXYJkkOh0N33HGHnnzySfXq1euy5xs5cqR++tOfatCgQRo7dqzeffdd9erVSy+++OJlj5k1a5aKiorcj+zs7Ma8FAAA4Ac8+rTm6OhoWSyWGrMpeXl5NWZdJKm4uFjbt29XZmamHnjgAUmS0+mUy+VSUFCQ1q9frxtuuKHGcWazWcOGDatzhsVqtcpq/e5jrl0ulyTx1hAAAH7kwu/tC7/HL8ejwhISEqLExESlp6frtttuc29PT0/XrbfeWmP/iIgIffnll9W2LVy4UJ988onee+89devWrdbv43K5tHPnTg0YMKDB2YqLiyWJt4YAAPBDxcXFioyMvOzzHhUWSZo5c6ZSU1OVlJSkUaNGafHixcrKytL06dMlVb1Vc+zYMS1btkxms1n9+/evdnyHDh1ks9mqbX/yySc1cuRI9ezZU3a7XQsWLNDOnTv10ksvNThX586dlZ2drfDwcA0fPlzbtm2rsc+wYcMatP3ir+12u+Li4pSdna2IiIgG52msy2VsruPr27+u5xs6npfbbuQ415WzOY69knGu6/natte3LZB/phuyb1P9TDPOjHNzH99Sxtnlcqm4uFidO3eucz+PC0tKSooKCgo0Z84c5eTkqH///lqzZo3i4+MlSTk5OfWuyXKpwsJC3XvvvcrNzVVkZKSGDBmijIwMDR8+vMHnMJvNio2NlSRZLJZaB7Sh22vbLyIiwiv/M1wuY3MdX9/+dT3vz+N8ue/fXMdeyTjX9Xxt2xu6LRB/phuyb1P9TDPOjHNzH9+SxrmumZULPC4sknTffffpvvvuq/W5tLS0Oo/9/e9/r9///vfVtj3//PN6/vnnGxOlVvfff/8Vbb/cft5wpd/b0+Pr27+u5/15nK/0+3tznOt6vrbtDd3mLd78mW7Ivk31M804N34fxrnp9g3Uca6NyVXfVS4tnN1uV2RkpIqKirz2L/+WiHH2HsbaOxhn72CcvcMXxpkPP6yH1WrV7373u2p3JKHpMc7ew1h7B+PsHYyzd/jCODPDAgAAfB4zLAAAwOdRWAAAgM+jsAAAAJ9HYQEAAD6PwgIAAHwehaUJFRcXa9iwYRo8eLAGDBigV155xehIASk7O1vXXXed+vbtq4EDB+qvf/2r0ZEC1m233aa2bdvqBz/4gdFRAso///lP9e7dWz179tSrr75qdJyAxc+vd3jr72Rua25CDodDZWVlCg0N1dmzZ9W/f39t27ZN7dq1MzpaQMnJydGJEyc0ePBg5eXlaejQodq3b5/CwsKMjhZwNmzYoJKSEr3++ut67733jI4TECorK9W3b19t2LBBERERGjp0qD7//HNFRUUZHS3g8PPrHd76O5kZliZksVgUGhoqSSotLZXD4aj347LhuU6dOmnw4MGSqj5MMyoqSqdOnTI2VIC6/vrrFR4ebnSMgPLvf/9b/fr1U5cuXRQeHq5JkyZp3bp1RscKSPz8eoe3/k5uUYUlIyNDt9xyizp37iyTyaT333+/xj4LFy5Ut27dZLPZlJiYqE2bNnn0PQoLCzVo0CDFxsbq8ccfV3R0dBOl9x/eGOcLtm/fLqfTqbi4uCtM7X+8Oc74zpWO+/Hjx9WlSxf317GxsTp27Jg3ovsVfr69pynHujn/Tm5RheXMmTMaNGiQ/vznP9f6/IoVKzRjxgzNnj1bmZmZGjt2rCZOnFjt06cTExPVv3//Go/jx49Lktq0aaNdu3bpyJEjevvtt3XixAmvvDZf4o1xlqSCggJNnTpVixcvbvbX5Iu8Nc6o7krHvbZZV5PJ1KyZ/VFT/HyjYZpqrJv972RXCyXJtWrVqmrbhg8f7po+fXq1bQkJCa4nnniiUd9j+vTprnfffbexEQNCc41zaWmpa+zYsa5ly5Y1RUy/15w/zxs2bHB9//vfv9KIAakx4/7ZZ5+5Jk+e7H7uoYcecr311lvNntWfXcnPNz+/nmnsWHvj7+QWNcNSl/Lycu3YsUPJycnVticnJ2vLli0NOseJEydkt9slVX2yZUZGhnr37t3kWf1ZU4yzy+XSXXfdpRtuuEGpqanNEdPvNcU4w3MNGffhw4frq6++0rFjx1RcXKw1a9ZowoQJRsT1W/x8e09DxtpbfycHNduZ/Ux+fr4cDodiYmKqbY+JiVFubm6DznH06FFNmzZNLpdLLpdLDzzwgAYOHNgccf1WU4zzZ599phUrVmjgwIHu91rfeOMNDRgwoKnj+q2mGGdJmjBhgr744gudOXNGsbGxWrVqlYYNG9bUcQNGQ8Y9KChIf/rTn3T99dfL6XTq8ccf505CDzX055uf3yvXkLH21t/JFJZLXPpessvlavD7y4mJidq5c2czpAo8VzLO11xzjZxOZ3PECjhXMs6SuHulkeob9+9973v63ve+5+1YAae+cebnt+nUNdbe+juZt4TOi46OlsViqfGvz7y8vBrNEo3HOHsH42wMxt07GGfv8aWxprCcFxISosTERKWnp1fbnp6ertGjRxuUKvAwzt7BOBuDcfcOxtl7fGmsW9RbQiUlJTp48KD76yNHjmjnzp2KiorSVVddpZkzZyo1NVVJSUkaNWqUFi9erKysLE2fPt3A1P6HcfYOxtkYjLt3MM7e4zdj3Wz3H/mgDRs2uCTVeNx5553ufV566SVXfHy8KyQkxDV06FDXp59+alxgP8U4ewfjbAzG3TsYZ+/xl7Hms4QAAIDP4xoWAADg8ygsAADA51FYAACAz6OwAAAAn0dhAQAAPo/CAgAAfB6FBQAA+DwKCwAA8HkUFgAA4PMoLAAAwOdRWAAAgM+jsAAAAJ/3/wFFp4dGjtdlhQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(easy_results['param_model__alpha'], easy_results['mean_test_score'])\n",
    "plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([None, 2, 6, 20], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuned_results['param_model__max_depth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "e4_predictive_maintenance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
