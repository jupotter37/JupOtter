{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-24T13:36:09.987105Z",
     "start_time": "2023-11-24T13:36:09.903988Z"
    }
   },
   "outputs": [],
   "source": [
    "#data science and visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#creation of dataset\n",
    "import _lib.ml_workflow.create_dataset as cds\n",
    "from _lib.export import to_csv\n",
    "from _lib.raman_lib.misc import load_data\n",
    "\n",
    "#quality control\n",
    "import _lib.ml_workflow.quality_control as qc\n",
    "from _lib.raman_lib.preprocessing import RangeLimiter\n",
    "from _lib.raman_lib.visualization import plot_spectra_peaks\n",
    "from _lib.raman_lib.spectra_scoring import score_names\n",
    "\n",
    "#preprocessing\n",
    "from _lib.ml_workflow.preprocess_data import preprocess\n",
    "\n",
    "#model creation\n",
    "from sklearn.model_selection import LeaveOneGroupOut, cross_validate, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.cluster import FeatureAgglomeration\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "from sklearn.pipeline import Pipeline\n",
    "from _lib.raman_lib.preprocessing import PeakPicker\n",
    "\n",
    "#file handling\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# define the paths to all experiment data\n",
    "path_group_0 = \"/Users/Praktikum/Downloads/DATA_tsv_aggregated_2/Ascites/Gram_-/Enterobacteriacea/Enterobacter/d_E._aerogenes\"\n",
    "path_group_1 = \"/Users/Praktikum/Downloads/DATA_tsv_aggregated_2/Ascites/Gram_-/Enterobacteriacea/Enterobacter/e_E._cloacae\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T13:36:09.996568Z",
     "start_time": "2023-11-24T13:36:09.907339Z"
    }
   },
   "id": "ba556eab9c01a73e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define parameters\n",
    "In order to function properly, the provided code depends on predefined parameters like output paths, limits and thresholds for the quality control, ...\n",
    "## Define data paths\n",
    "Define the location of the data, and where quality-controlled and preprocessed data should be stored. Both of them rely on a unique file-prefix that describes the data being analyzed."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11e036c91d7db2d8"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "FILE_PREFIX = \"Enterobacter\"\n",
    "DATASET_OUT = \"./01_GroupK/data/\" + FILE_PREFIX + \".csv\"\n",
    "RESULT_DIR = \"./01_GroupK/result/\" + FILE_PREFIX\n",
    "QC_OUT = RESULT_DIR + \"/\" + FILE_PREFIX + \"_qc.csv\"\n",
    "PREP_OUT = RESULT_DIR + \"/\" + FILE_PREFIX + \"_preprocessed.csv\"\n",
    "LDA_DIR = RESULT_DIR + \"/\" + \"lda_dim_reduction\"\n",
    "REG_DIR = RESULT_DIR + \"/\" + \"regularized_models/\"\n",
    "TREE_DIR = RESULT_DIR + \"/\" + \"tree_based_models/\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T13:36:10.054982Z",
     "start_time": "2023-11-24T13:36:09.913160Z"
    }
   },
   "id": "1946c00c0f432539"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define quality scoring parameters\n",
    "The quality control only uses peaks in a given interval, recognizes peaks via a filter (Sav-Gol) and scores them based on some metrics. Finally, the best N spectra are selected.\n",
    "### Spectral Range Limits"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "66d7b25691ed478d"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "QC_LIM_LOW = 450\n",
    "QC_LIM_HIGH = 1650"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T13:36:10.057655Z",
     "start_time": "2023-11-24T13:36:09.916725Z"
    }
   },
   "id": "fff0616d8e842c0c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Peak Detection"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f63cf8bfe34cc1a8"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "QC_WINDOW = 35\n",
    "QC_THRESHOLD = 0.001\n",
    "QC_MIN_HEIGHT = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T13:36:10.067307Z",
     "start_time": "2023-11-24T13:36:09.920734Z"
    }
   },
   "id": "f81d42c2fd60e19d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Scoring"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d20494720e3b96b8"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "QC_SCORE = 1\n",
    "QC_PEAKS = 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T13:36:10.070175Z",
     "start_time": "2023-11-24T13:36:09.925259Z"
    }
   },
   "id": "418848038e5d1a9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Number of spectra to keep"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c551c0e33d85517"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "QC_NUM = 300"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T13:36:10.073264Z",
     "start_time": "2023-11-24T13:36:09.928141Z"
    }
   },
   "id": "42f0202cfb120473"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define Preprocessing Parameter\n",
    "### Spectral Range Limits"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc7e2a73121e88a1"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "PREP_LIM_LOW = QC_LIM_LOW\n",
    "PREP_LIM_HIGH = QC_LIM_HIGH"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T13:36:10.079205Z",
     "start_time": "2023-11-24T13:36:09.932194Z"
    }
   },
   "id": "11b623608b1feaae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Window-width for smoothing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d22fa452dd59a708"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "PREP_WINDOW = 15"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T13:36:10.081935Z",
     "start_time": "2023-11-24T13:36:09.934916Z"
    }
   },
   "id": "8de2ac3f3e1b555"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Settings for Cross Validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cfc9eac0cc292189"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "SCORING = ['roc_auc', 'accuracy', 'f1']\n",
    "N_TRIALS = 20\n",
    "N_FOLDS = 5\n",
    "N_CORES = -1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T13:36:10.087765Z",
     "start_time": "2023-11-24T13:36:09.937975Z"
    }
   },
   "id": "d427a6785448fbef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define number of threads/core to use"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b93c86726cec1a27"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cnt_jobs = 40"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "40506560a51c63e0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create the dataset\n",
    "Create the dataset using the implementation provided by D. Zimmermann.\n",
    "For the creation of the dataset, the two source dirs, as well as the desired labels are needed.\n",
    "Furthermore, an output directory is needed, to store the created dataset "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fe948f6032b8211"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "root - INFO - Loading data\n",
      "root - INFO - Loading data\n",
      "root - INFO - Loading data\n",
      "root - INFO - Loading files from /Users/Praktikum/Downloads/DATA_tsv_aggregated_2/Ascites/Gram_-/Enterobacteriacea/Enterobacter/d_E._aerogenes\n",
      "root - INFO - Loading files from /Users/Praktikum/Downloads/DATA_tsv_aggregated_2/Ascites/Gram_-/Enterobacteriacea/Enterobacter/d_E._aerogenes\n",
      "root - INFO - Loading files from /Users/Praktikum/Downloads/DATA_tsv_aggregated_2/Ascites/Gram_-/Enterobacteriacea/Enterobacter/d_E._aerogenes\n",
      "root - INFO - Loading files from /Users/Praktikum/Downloads/DATA_tsv_aggregated_2/Ascites/Gram_-/Enterobacteriacea/Enterobacter/e_E._cloacae\n",
      "root - INFO - Loading files from /Users/Praktikum/Downloads/DATA_tsv_aggregated_2/Ascites/Gram_-/Enterobacteriacea/Enterobacter/e_E._cloacae\n",
      "root - INFO - Loading files from /Users/Praktikum/Downloads/DATA_tsv_aggregated_2/Ascites/Gram_-/Enterobacteriacea/Enterobacter/e_E._cloacae\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'E'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[24], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(datadir):\n\u001B[1;32m      3\u001B[0m     os\u001B[38;5;241m.\u001B[39mmakedirs(datadir)\n\u001B[0;32m----> 5\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mcds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mpath_control\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath_etoposide\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43md_E._aerogenes\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43me_E._cloacae\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrouped\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m dataset\u001B[38;5;241m.\u001B[39mto_csv(DATASET_OUT, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/Documents/repos/ML_Model_Validation/_lib/ml_workflow/create_dataset.py:85\u001B[0m, in \u001B[0;36mcreate_dataset\u001B[0;34m(dirs_in, labels, grouped)\u001B[0m\n\u001B[1;32m     82\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m grouped \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     83\u001B[0m             \u001B[38;5;66;03m# for HL_540:\u001B[39;00m\n\u001B[1;32m     84\u001B[0m             parts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(file\u001B[38;5;241m.\u001B[39mname)\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 85\u001B[0m             groups\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mparts\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     86\u001B[0m             \u001B[38;5;66;03m# for HL_428:\u001B[39;00m\n\u001B[1;32m     87\u001B[0m             \u001B[38;5;66;03m# groups.append(int(str(file.name).lstrip(\"RE\")[0]))\u001B[39;00m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mall\u001B[39m([np\u001B[38;5;241m.\u001B[39marray_equal(element, wns[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;28;01mfor\u001B[39;00m element \u001B[38;5;129;01min\u001B[39;00m wns]):\n",
      "\u001B[0;31mValueError\u001B[0m: invalid literal for int() with base 10: 'E'"
     ]
    }
   ],
   "source": [
    "datadir = Path(DATASET_OUT).parent\n",
    "if not os.path.exists(datadir):\n",
    "    os.makedirs(datadir)\n",
    "\n",
    "dataset = cds.create_dataset([path_group_0, path_group_1], ['d_E._aerogenes', 'e_E._cloacae'], grouped=True)\n",
    "dataset.to_csv(DATASET_OUT, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T13:36:10.411818Z",
     "start_time": "2023-11-24T13:36:09.942878Z"
    }
   },
   "id": "a89e1a63a6c033fb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Do quality control\n",
    "Asses the spectra based on their quality, and remove low quality spectra"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61b13fd9e23ddc42"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_in = Path(DATASET_OUT)\n",
    "path_out = Path(RESULT_DIR)\n",
    "\n",
    "if not os.path.exists(path_out):\n",
    "    os.makedirs(path_out)\n",
    "\n",
    "path_out_data = path_out / (path_in.stem + \"_qc.csv\")\n",
    "path_out_scores = path_out / (path_in.stem + \"_qc_scores.csv\")\n",
    "\n",
    "data = pd.read_csv(path_in)\n",
    "\n",
    "data_out, _, score_dict = qc.score_sort_spectra(data,\n",
    "                                                n=QC_NUM,\n",
    "                                                limits=[QC_LIM_LOW, QC_LIM_HIGH],\n",
    "                                                bl_method=\"asls\",\n",
    "                                                sg_window=QC_WINDOW,\n",
    "                                                threshold=QC_THRESHOLD,\n",
    "                                                min_height=QC_MIN_HEIGHT,\n",
    "                                                score_measure=QC_SCORE,\n",
    "                                                n_peaks_influence=QC_PEAKS,\n",
    "                                                detailed=True)\n",
    "\n",
    "visualize = False\n",
    "if visualize:\n",
    "    data_vis = data.drop(columns=[\"label\", \"file\", \"group\"]).values.astype(float)\n",
    "    wns_vis = data.drop(columns=[\"label\", \"file\", \"group\"]).columns.astype(float)\n",
    "\n",
    "    rl = RangeLimiter(lim=[QC_LIM_LOW, QC_LIM_HIGH],\n",
    "                      reference=wns_vis)\n",
    "\n",
    "    data_rl = rl.fit_transform(data_vis)\n",
    "    wns_rl = wns_vis[rl.lim_[0]:rl.lim_[1]]\n",
    "\n",
    "    plot_spectra_peaks(wns_rl,\n",
    "                       data_rl,\n",
    "                       score_dict[\"peak_pos\"],\n",
    "                       labels=score_dict[\"total_scores\"])\n",
    "\n",
    "data_out.to_csv(path_out_data, index=False)\n",
    "\n",
    "pd.DataFrame({score_names[QC_SCORE]: score_dict[\"intensity_scores\"],\n",
    "              \"N Peaks\": score_dict[\"peak_scores\"]}).to_csv(\n",
    "    path_out_scores, index=False\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T13:36:10.413658Z",
     "start_time": "2023-11-24T13:36:10.413316Z"
    }
   },
   "id": "73f701f36659ab53"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess the data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "400014d013f6e91f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_in = Path(QC_OUT)\n",
    "path_out = Path(RESULT_DIR)\n",
    "\n",
    "filename = path_in.stem.removesuffix(\"_qc\")\n",
    "\n",
    "if not os.path.exists(path_out):\n",
    "    os.makedirs(path_out)\n",
    "\n",
    "path_out = path_out / (filename + \"_preprocessed.csv\")\n",
    "\n",
    "data = load_data(QC_OUT)\n",
    "\n",
    "# save groups and remove column, otherwise preprocess won't work\n",
    "groups = np.asarray(data.group)\n",
    "data = data.drop(columns=[\"group\"])\n",
    "\n",
    "data_prep = preprocess(data, limits=[PREP_LIM_LOW, PREP_LIM_HIGH], sg_window=PREP_WINDOW)\n",
    "\n",
    "#add groups again\n",
    "data_prep.insert(2, \"group\", groups)\n",
    "\n",
    "data_prep.to_csv(path_out, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T13:36:10.415743Z",
     "start_time": "2023-11-24T13:36:10.415336Z"
    }
   },
   "id": "241a139a0b6a349f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implement GroupKFold CV\n",
    "## LDA Dimensionality Reduction "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fc845c98c61b204"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_in = PREP_OUT\n",
    "#path_out = Path(args.out)\n",
    "\n",
    "#filename = path_in.stem\n",
    "\n",
    "data = load_data(path_in)\n",
    "\n",
    "X = data.drop(columns=[\"label\", \"file\", \"group\"])\n",
    "wns = np.asarray(X.columns.astype(float))\n",
    "X = np.asarray(X)\n",
    "y = np.array(data.label)\n",
    "y, y_key = pd.factorize(y)\n",
    "\n",
    "#split the dataset according to the groups\n",
    "groups = np.array(data.group)\n",
    "logo = LeaveOneGroupOut()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-24T13:36:10.417046Z"
    }
   },
   "id": "3980fbf704d03a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Baseline with LDA alone"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f72be05bbfdde2b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf = LinearDiscriminantAnalysis()\n",
    "result = cross_validate(clf, X, y, cv=logo, scoring=SCORING, return_train_score=True, groups=groups, n_jobs=cnt_jobs)\n",
    "to_csv(result, path=LDA_DIR + \"/lda\", scoring=SCORING, param_opt=False)\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-24T13:36:10.418475Z"
    }
   },
   "id": "59488b940e5c4f07"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Selection with PCA followed by LDA"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d6c0c38a589da66"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\"pca__n_components\": range(\n",
    "    1, 51, 10\n",
    ")}\n",
    "clf = Pipeline([(\"pca\", PCA()),\n",
    "                (\"lda\", LinearDiscriminantAnalysis())])\n",
    "grid_rf = GridSearchCV(clf, param_grid=param_grid, cv=logo, scoring=SCORING, refit='accuracy',\n",
    "                       return_train_score=True, verbose=3, n_jobs=cnt_jobs).fit(X, y, groups=groups)\n",
    "\n",
    "to_csv(grid_rf.cv_results_, scoring=SCORING, path=LDA_DIR + \"/pca_lda\", param_opt=True)\n",
    "\n",
    "print(\" Results from Grid Search \")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid_rf.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid_rf.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid_rf.best_params_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-24T13:36:10.420323Z"
    }
   },
   "id": "2b2f27d8615f8d80"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Non-Negative Matrix Factorization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8976ecf9d4d35ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\"\"\"clf = Pipeline([(\"nmf\", NMF(init=\"nndsvda\", tol=1e-2, max_iter=5000)),\n",
    "                (\"lda\", LinearDiscriminantAnalysis())])\n",
    "cross_validate(clf, X, y, cv=logo, groups=groups, scoring=SCORING)\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-24T13:36:10.422260Z"
    }
   },
   "id": "bc1c2e81e55099d8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Agglomeration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e5bf2c1156fe795"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\"agglo__n_clusters\": range(\n",
    "    5, 41, 5\n",
    ")}\n",
    "clf = Pipeline([(\"agglo\", FeatureAgglomeration(connectivity=np.diag(np.ones(len(wns))) +\n",
    "                                                            np.diag(np.ones(len(wns) - 1), 1) +\n",
    "                                                            np.diag(np.ones(len(wns) - 1), -1))),\n",
    "                (\"lda\", LinearDiscriminantAnalysis())])\n",
    "grid_rf = GridSearchCV(clf, param_grid=param_grid, cv=logo, scoring=SCORING, refit='accuracy',\n",
    "                       return_train_score=True, verbose=3, n_jobs=cnt_jobs).fit(X, y, groups=groups)\n",
    "to_csv(grid_rf.cv_results_, scoring=SCORING, path=LDA_DIR + \"/fa_lda\", param_opt=True)\n",
    "\n",
    "print(\" Results from Grid Search \")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid_rf.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid_rf.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid_rf.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T13:36:10.425215Z",
     "start_time": "2023-11-24T13:36:10.424322Z"
    }
   },
   "id": "6804202644eee4a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### PeakPicker"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b19756db8f8e23a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\"peaks__min_dist\": range(\n",
    "    10, 151, 10\n",
    ")}\n",
    "clf = Pipeline([(\"peaks\", PeakPicker()),\n",
    "                (\"lda\", LinearDiscriminantAnalysis())])\n",
    "grid_rf = GridSearchCV(clf, param_grid=param_grid, cv=logo, scoring=SCORING, refit='accuracy', return_train_score=True,\n",
    "                       verbose=3, n_jobs=cnt_jobs).fit(X, y, groups=groups)\n",
    "to_csv(grid_rf.cv_results_, scoring=SCORING, path=LDA_DIR + \"/peak_lda\", param_opt=True)\n",
    "\n",
    "print(\" Results from Grid Search \")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid_rf.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid_rf.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid_rf.best_params_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T13:36:10.426839Z",
     "start_time": "2023-11-24T13:36:10.425885Z"
    }
   },
   "id": "868088c52bd4cf2d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regularized Models\n",
    "### Logistic Regression L1 Penalty"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "71a273c36d1071c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"logreg__C\": np.logspace(-2, 1, 16)\n",
    "}\n",
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression(solver=\"liblinear\",\n",
    "                                  penalty=\"l1\", max_iter=1000, random_state=41))\n",
    "])\n",
    "\n",
    "grid_rf = GridSearchCV(clf, param_grid=param_grid, cv=logo, scoring=SCORING, refit='accuracy', return_train_score=True,\n",
    "                       verbose=3, n_jobs=cnt_jobs).fit(X, y, groups=groups)\n",
    "to_csv(grid_rf.cv_results_, scoring=SCORING, path=REG_DIR + \"/logreg_l1\", param_opt=True)\n",
    "\n",
    "print(\" Results from Grid Search \")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid_rf.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid_rf.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid_rf.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-24T13:36:10.427303Z",
     "start_time": "2023-11-24T13:36:10.427144Z"
    }
   },
   "id": "2f93fb06e6ed1b30"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression L2 Penalty"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d47732564c6e02bf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"logreg__C\": np.logspace(-5, 1, 13)\n",
    "}\n",
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression(solver=\"liblinear\",\n",
    "                                  penalty=\"l2\", max_iter=1000, random_state=51))\n",
    "])\n",
    "\n",
    "grid_rf = GridSearchCV(clf, param_grid=param_grid, cv=logo, scoring=SCORING, refit='accuracy', return_train_score=True,\n",
    "                       verbose=3, n_jobs=cnt_jobs).fit(X, y, groups=groups)\n",
    "to_csv(grid_rf.cv_results_, scoring=SCORING, path=REG_DIR + \"/logreg_l2\", param_opt=True)\n",
    "\n",
    "print(\" Results from Grid Search \")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid_rf.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid_rf.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid_rf.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-24T13:36:10.428046Z"
    }
   },
   "id": "8431821dfd6e5cd0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear SVM L1 Penalty"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64f78845352350ce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"svm__C\": np.logspace(-3, 0, 16)\n",
    "}\n",
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", LinearSVC(penalty=\"l1\", dual=False, max_iter=10000))\n",
    "])\n",
    "\n",
    "grid_rf = GridSearchCV(clf, param_grid=param_grid, cv=logo, scoring=SCORING, refit='accuracy', return_train_score=True,\n",
    "                       verbose=3, n_jobs=cnt_jobs).fit(X, y, groups=groups)\n",
    "to_csv(grid_rf.cv_results_, scoring=SCORING, path=REG_DIR + \"/svm_l1\", param_opt=True)\n",
    "\n",
    "print(\" Results from Grid Search \")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid_rf.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid_rf.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid_rf.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-24T13:36:10.428997Z"
    }
   },
   "id": "630691a86c31488"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear SVM L2 Penalty"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "656d77c3d1dd24da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"svm__C\": np.logspace(-5, -1, 13)\n",
    "}\n",
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", LinearSVC(penalty=\"l2\", max_iter=5000))\n",
    "])\n",
    "\n",
    "grid_rf = GridSearchCV(clf, param_grid=param_grid, cv=logo, scoring=SCORING, refit='accuracy', return_train_score=True,\n",
    "                       verbose=3, n_jobs=cnt_jobs).fit(X, y, groups=groups)\n",
    "to_csv(grid_rf.cv_results_, scoring=SCORING, path=REG_DIR + \"/svm_l2\", param_opt=True)\n",
    "\n",
    "print(\" Results from Grid Search \")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid_rf.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid_rf.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid_rf.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-24T13:36:10.429942Z"
    }
   },
   "id": "3b16cea4429e180e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tree-based models\n",
    "### Basic Decision Tree\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95fb7c0c054e5a33"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"ccp_alpha\": np.logspace(-3, -1, 9)\n",
    "}\n",
    "clf = DecisionTreeClassifier(random_state=653)\n",
    "\n",
    "grid_rf = GridSearchCV(clf, param_grid=param_grid, cv=logo, scoring=SCORING, refit='accuracy', return_train_score=True,\n",
    "                       verbose=3, n_jobs=cnt_jobs).fit(X, y, groups=groups)\n",
    "to_csv(grid_rf.cv_results_, scoring=SCORING, path=TREE_DIR + \"/decision_tree\", param_opt=True)\n",
    "\n",
    "print(\" Results from Grid Search \")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid_rf.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid_rf.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid_rf.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-24T13:36:10.431567Z"
    }
   },
   "id": "cdc163f7218b48e4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14dffad87ad86dc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"colsample_bytree\": np.linspace(0.01, 0.2, 20)\n",
    "}\n",
    "clf = LGBMClassifier(boosting_type=\"rf\",\n",
    "                     subsample=0.8,\n",
    "                     subsample_freq=1,\n",
    "                     max_bin=10,\n",
    "                     max_depth=8,\n",
    "                     random_state=2434)\n",
    "\n",
    "grid_rf = GridSearchCV(clf, param_grid=param_grid, cv=logo, scoring=SCORING, refit='accuracy', return_train_score=True,\n",
    "                       verbose=3, n_jobs=cnt_jobs).fit(X, y, groups=groups)\n",
    "to_csv(grid_rf.cv_results_, scoring=SCORING, path=TREE_DIR + \"/random_forest\", param_opt=True)\n",
    "\n",
    "print(\" Results from Grid Search \")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid_rf.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid_rf.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid_rf.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-24T13:36:10.432574Z"
    }
   },
   "id": "8f38d94fff6831c6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Gradient-boosted Decision Tree"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18c2a1ab5d2bb313"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\": np.linspace(0.01, 0.2, 20)\n",
    "}\n",
    "clf = LGBMClassifier(colsample_bytree=0.2,\n",
    "                     max_bin=10,\n",
    "                     max_depth=5,\n",
    "                     random_state=6233)\n",
    "\n",
    "grid_rf = GridSearchCV(clf, param_grid=param_grid, cv=logo, scoring=SCORING, refit='accuracy', return_train_score=True,\n",
    "                       verbose=3, n_jobs=cnt_jobs).fit(X, y, groups=groups)\n",
    "to_csv(grid_rf.cv_results_, scoring=SCORING, path=TREE_DIR + \"/gbdt\", param_opt=True)\n",
    "\n",
    "print(\" Results from Grid Search \")\n",
    "print(\"\\n The best estimator across ALL searched params:\\n\", grid_rf.best_estimator_)\n",
    "print(\"\\n The best score across ALL searched params:\\n\", grid_rf.best_score_)\n",
    "print(\"\\n The best parameters across ALL searched params:\\n\", grid_rf.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-24T13:36:10.433585Z"
    }
   },
   "id": "8349e8894d4725b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
