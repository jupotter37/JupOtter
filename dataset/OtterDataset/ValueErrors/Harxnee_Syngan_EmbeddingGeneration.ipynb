{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\python312\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\python312\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\python312\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\python312\\lib\\site-packages (from torch) (2024.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\python312\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python312\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\python312\\lib\\site-packages (4.44.2)\n",
      "Requirement already satisfied: filelock in c:\\python312\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\python312\\lib\\site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python312\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python312\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python312\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\python312\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\python312\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\python312\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python312\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\student\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\python312\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python312\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python312\\lib\\site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This Script Has Code to Generate Embeddings using 3 Models namely GLOVE,WORD2VEC,FASTTEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = r'C:\\Users\\student\\Desktop\\Datasets\\sample_data'\n",
    "images_folder = os.path.join(current_folder, \"Images\")\n",
    "labels_folder = os.path.join(current_folder, \"tamil_labels_300_proofread\")\n",
    "output_folder = os.path.join(current_folder, \"embeddings_300_proofread\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading Muril Model for embedding Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee0de3ed2744ac8822ab1471e04fa58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/206 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mhanj\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e045191c51334119a13aea57ea1d513a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2b704d76e74c418a0851d1a2a46009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/3.16M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37910f0d8ed7473f902ffa1683633dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/113 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mhanj\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\bitsandbytes\\cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "WARNING:tensorflow:From c:\\Users\\mhanj\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7a77be34ca4790a7a993c071897d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/953M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mhanj\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# Load MURIL model and tokenizer\n",
    "model_name = \"google/muril-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Set device (GPU if available, else CPU)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# Set device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate embeddings\n",
    "def generate_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Use mean pooling to get sentence embedding\n",
    "    embedding = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy()\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:18<00:00, 16.28it/s]\n"
     ]
    }
   ],
   "source": [
    "for image_file in tqdm(os.listdir(images_folder)):\n",
    "    image_name = os.path.splitext(image_file)[0]\n",
    "    label_file = os.path.join(labels_folder, f\"{image_name}.txt\")\n",
    "    \n",
    "    # Check if the label file exists\n",
    "    if not os.path.exists(label_file):\n",
    "        print(f\"Label file not found for {image_file}\")\n",
    "        continue\n",
    "    \n",
    "    # Read the label (description)\n",
    "    with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        description = f.read().strip()\n",
    "    \n",
    "    # Generate embedding\n",
    "    embedding = generate_embedding(description)\n",
    "    \n",
    "    # Save embedding\n",
    "    output_file = os.path.join(output_folder, f\"{image_name}.npy\")\n",
    "    np.save(output_file, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Printing 3 sample embeddings:\n",
      "\n",
      "File: image_00234.npy\n",
      "Embedding shape: (768,)\n",
      "First 10 values: [-0.00110763  0.00386116 -0.00264634 -0.01812263 -0.00447125  0.00063988\n",
      " -0.00550396 -0.00915958 -0.0029088  -0.00025061]\n",
      "Min value: -0.5953381061553955, Max value: 0.15569542348384857\n",
      "\n",
      "File: image_00243.npy\n",
      "Embedding shape: (768,)\n",
      "First 10 values: [-0.00027811  0.00291532 -0.00330758 -0.01658205 -0.00499371 -0.00028355\n",
      " -0.00818089 -0.0056842  -0.00224374 -0.00181728]\n",
      "Min value: -0.5964596271514893, Max value: 0.15918126702308655\n",
      "\n",
      "File: image_00109.npy\n",
      "Embedding shape: (768,)\n",
      "First 10 values: [-0.00222336  0.00096072 -0.00247957 -0.01388167 -0.00400691  0.00228519\n",
      " -0.00787494 -0.00564079 -0.00286657 -0.00044924]\n",
      "Min value: -0.5972206592559814, Max value: 0.15914572775363922\n"
     ]
    }
   ],
   "source": [
    "# Print sample embeddings\n",
    "def print_sample_embeddings(folder, num_samples=3):\n",
    "    print(f\"\\nPrinting {num_samples} sample embeddings:\")\n",
    "    embedding_files = [f for f in os.listdir(folder) if f.endswith('.npy')]\n",
    "    \n",
    "    if not embedding_files:\n",
    "        print(\"No embedding files found.\")\n",
    "        return\n",
    "    \n",
    "    samples = random.sample(embedding_files, min(num_samples, len(embedding_files)))\n",
    "    \n",
    "    for sample in samples:\n",
    "        file_path = os.path.join(folder, sample)\n",
    "        embedding = np.load(file_path)\n",
    "        print(f\"\\nFile: {sample}\")\n",
    "        print(f\"Embedding shape: {embedding.shape}\")\n",
    "        print(f\"First 10 values: {embedding[:10]}\")\n",
    "        print(f\"Min value: {np.min(embedding)}, Max value: {np.max(embedding)}\")\n",
    "\n",
    "# Call the function to print sample embeddings\n",
    "print_sample_embeddings(output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastText Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from gensim.models.fasttext import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, filename):\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024  # 1 KB\n",
    "\n",
    "    with open(filename, 'wb') as file, tqdm(\n",
    "        desc=filename,\n",
    "        total=total_size,\n",
    "        unit='iB',\n",
    "        unit_scale=True,\n",
    "        unit_divisor=1024,\n",
    "    ) as progress_bar:\n",
    "        for data in response.iter_content(block_size):\n",
    "            size = file.write(data)\n",
    "            progress_bar.update(size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('tamil_models', exist_ok=True)\n",
    "# Download FastText model for Tamil\n",
    "print(\"Downloading FastText model for Tamil...\")\n",
    "fasttext_url = \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ta.300.bin.gz\"\n",
    "fasttext_gz_path = 'tamil_models/cc.ta.300.bin.gz'\n",
    "fasttext_bin_path = 'tamil_models/cc.ta.300.bin'\n",
    "\n",
    "download_file(fasttext_url, fasttext_gz_path)\n",
    "\n",
    "print(\"Extracting FastText model...\")\n",
    "with gzip.open(fasttext_gz_path, 'rb') as f_in:\n",
    "    with open(fasttext_bin_path, 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)\n",
    "\n",
    "os.remove(fasttext_gz_path)  # Remove the .gz file after extraction\n",
    "\n",
    "print(\"Loading FastText model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\student\\AppData\\Local\\Temp\\ipykernel_8532\\94384607.py:2: DeprecationWarning: Call to deprecated `load_fasttext_format` (use load_facebook_vectors (to use pretrained embeddings) or load_facebook_model (to continue training with the loaded full model, more RAM) instead).\n",
      "  fasttext_model = FastText.load_fasttext_format(fasttext_bin_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText model saved.\n"
     ]
    }
   ],
   "source": [
    "fasttext_bin_path = 'tamil_models/cc.ta.300.bin'\n",
    "fasttext_model = FastText.load_fasttext_format(fasttext_bin_path)\n",
    "fasttext_model.save('tamil_models/fasttext_tamil.model')\n",
    "print(\"FastText model saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = r'C:\\Users\\student\\Desktop\\Datasets\\sample_data'\n",
    "images_folder = os.path.join(current_folder, \"Images\")\n",
    "labels_folder = os.path.join(current_folder, \"tamil_labels_300_proofread\")\n",
    "output_folder = os.path.join(current_folder, \"embeddings_300_proofread_fasttext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding_fasttext(text, model):\n",
    "    # Tokenize the text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Generate embeddings for each word and take the mean\n",
    "    embeddings = []\n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            embeddings.append(model.wv[word])\n",
    "        else:\n",
    "            # If word is not found, use a zero vector\n",
    "            embeddings.append(np.zeros(model.vector_size))\n",
    "    \n",
    "    # Calculate the mean of the word embeddings to get a sentence embedding\n",
    "    embedding = np.mean(embeddings, axis=0)\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim==3.8.3\n",
      "  Downloading gensim-3.8.3.tar.gz (23.4 MB)\n",
      "     ---------------------------------------- 0.0/23.4 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/23.4 MB 991.0 kB/s eta 0:00:24\n",
      "      --------------------------------------- 0.3/23.4 MB 4.1 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 0.6/23.4 MB 5.8 MB/s eta 0:00:04\n",
      "     - -------------------------------------- 1.0/23.4 MB 6.6 MB/s eta 0:00:04\n",
      "     -- ------------------------------------- 1.5/23.4 MB 7.4 MB/s eta 0:00:03\n",
      "     --- ------------------------------------ 2.0/23.4 MB 8.5 MB/s eta 0:00:03\n",
      "     ---- ----------------------------------- 2.4/23.4 MB 9.2 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 3.0/23.4 MB 9.6 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 3.1/23.4 MB 9.6 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 3.1/23.4 MB 9.6 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 3.1/23.4 MB 9.6 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 3.1/23.4 MB 9.6 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 3.1/23.4 MB 9.6 MB/s eta 0:00:03\n",
      "     ----- ---------------------------------- 3.4/23.4 MB 6.0 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 3.7/23.4 MB 6.3 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 4.2/23.4 MB 6.6 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 4.7/23.4 MB 7.0 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 5.2/23.4 MB 7.4 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 5.7/23.4 MB 7.6 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 6.2/23.4 MB 7.8 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 6.7/23.4 MB 8.0 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 7.2/23.4 MB 8.2 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 7.6/23.4 MB 8.4 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 8.0/23.4 MB 8.4 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 8.4/23.4 MB 8.5 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 8.4/23.4 MB 8.5 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 8.4/23.4 MB 8.5 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 8.4/23.4 MB 8.5 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 8.4/23.4 MB 8.5 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 8.4/23.4 MB 8.5 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 8.4/23.4 MB 8.5 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 8.4/23.4 MB 8.5 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 8.9/23.4 MB 6.9 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 9.3/23.4 MB 7.0 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 10.0/23.4 MB 7.2 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 10.5/23.4 MB 7.5 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 10.5/23.4 MB 7.5 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 10.5/23.4 MB 7.3 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 10.5/23.4 MB 7.3 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 10.5/23.4 MB 7.3 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 10.6/23.4 MB 6.5 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 11.0/23.4 MB 6.6 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 11.7/23.4 MB 6.6 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 12.1/23.4 MB 6.7 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 12.6/23.4 MB 6.6 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 13.1/23.4 MB 6.6 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 13.6/23.4 MB 7.7 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 13.6/23.4 MB 7.7 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 13.6/23.4 MB 7.7 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 13.6/23.4 MB 7.7 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 13.6/23.4 MB 7.7 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 13.8/23.4 MB 6.6 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 14.2/23.4 MB 6.6 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 14.7/23.4 MB 6.7 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 15.2/23.4 MB 6.7 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 15.7/23.4 MB 6.6 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 16.3/23.4 MB 6.6 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 16.7/23.4 MB 6.7 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 17.2/23.4 MB 6.6 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 17.7/23.4 MB 6.6 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 17.8/23.4 MB 6.7 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 17.8/23.4 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 17.8/23.4 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 17.8/23.4 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 17.8/23.4 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 18.1/23.4 MB 5.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 18.6/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 19.1/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 19.6/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 19.9/23.4 MB 6.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 19.9/23.4 MB 6.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 19.9/23.4 MB 6.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 19.9/23.4 MB 6.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 19.9/23.4 MB 6.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 20.3/23.4 MB 6.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 20.8/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 21.3/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 21.8/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 22.2/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 22.8/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.2/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.4/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------  23.4/23.4 MB 7.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 23.4/23.4 MB 6.7 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [64 lines of output]\n",
      "      C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:261: UserWarning: Unknown distribution option: 'test_suite'\n",
      "        warnings.warn(msg)\n",
      "      C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py:261: UserWarning: Unknown distribution option: 'tests_require'\n",
      "        warnings.warn(msg)\n",
      "      running dist_info\n",
      "      creating C:\\Users\\student\\AppData\\Local\\Temp\\pip-modern-metadata-4smdjsei\\gensim.egg-info\n",
      "      writing C:\\Users\\student\\AppData\\Local\\Temp\\pip-modern-metadata-4smdjsei\\gensim.egg-info\\PKG-INFO\n",
      "      writing dependency_links to C:\\Users\\student\\AppData\\Local\\Temp\\pip-modern-metadata-4smdjsei\\gensim.egg-info\\dependency_links.txt\n",
      "      writing requirements to C:\\Users\\student\\AppData\\Local\\Temp\\pip-modern-metadata-4smdjsei\\gensim.egg-info\\requires.txt\n",
      "      writing top-level names to C:\\Users\\student\\AppData\\Local\\Temp\\pip-modern-metadata-4smdjsei\\gensim.egg-info\\top_level.txt\n",
      "      writing manifest file 'C:\\Users\\student\\AppData\\Local\\Temp\\pip-modern-metadata-4smdjsei\\gensim.egg-info\\SOURCES.txt'\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"C:\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Python312\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 149, in prepare_metadata_for_build_wheel\n",
      "          return hook(metadata_directory, config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 373, in prepare_metadata_for_build_wheel\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 503, in run_setup\n",
      "          super().run_setup(setup_script=setup_script)\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 318, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 367, in <module>\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\__init__.py\", line 117, in setup\n",
      "          return distutils.core.setup(**attrs)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 183, in setup\n",
      "          return run_commands(dist)\n",
      "                 ^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\core.py\", line 199, in run_commands\n",
      "          dist.run_commands()\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 954, in run_commands\n",
      "          self.run_command(cmd)\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\dist.py\", line 950, in run_command\n",
      "          super().run_command(command)\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\dist.py\", line 973, in run_command\n",
      "          cmd_obj.run()\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\command\\dist_info.py\", line 93, in run\n",
      "          self.egg_info.run()\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 311, in run\n",
      "          self.find_sources()\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 319, in find_sources\n",
      "          mm.run()\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 540, in run\n",
      "          self.add_defaults()\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\command\\egg_info.py\", line 578, in add_defaults\n",
      "          sdist.add_defaults(self)\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\command\\sdist.py\", line 108, in add_defaults\n",
      "          super().add_defaults()\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\sdist.py\", line 238, in add_defaults\n",
      "          self._add_defaults_ext()\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\command\\sdist.py\", line 322, in _add_defaults_ext\n",
      "          build_ext = self.get_finalized_command('build_ext')\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 303, in get_finalized_command\n",
      "          cmd_obj.ensure_finalized()\n",
      "        File \"C:\\Users\\student\\AppData\\Local\\Temp\\pip-build-env-u8hwl7m3\\overlay\\Lib\\site-packages\\setuptools\\_distutils\\cmd.py\", line 111, in ensure_finalized\n",
      "          self.finalize_options()\n",
      "        File \"<string>\", line 111, in finalize_options\n",
      "      AttributeError: 'dict' object has no attribute '__NUMPY_SETUP__'\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#This version of gensim is needed to run the key_to_index command\n",
    "! pip install gensim==3.8.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\student\\AppData\\Local\\Temp\\ipykernel_8532\\2330281311.py:5: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  mod = load_facebook_model('tamil_models\\cc.ta.300.bin')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#Reloading the new version of Fasttext model\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "\n",
    "# Load the FastText model\n",
    "mod = load_facebook_model('tamil_models\\cc.ta.300.bin')\n",
    "model = mod.wv\n",
    "\n",
    "# Check if a word is present in the model vocabulary\n",
    "print('sviluppatore' in model.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 320.23it/s]\n"
     ]
    }
   ],
   "source": [
    "for image_file in tqdm(os.listdir(images_folder)):\n",
    "    image_name = os.path.splitext(image_file)[0]\n",
    "    \n",
    "    label_file = os.path.join(labels_folder, f\"{image_name}.txt\")\n",
    "    \n",
    "    # Check if the label file exists\n",
    "    if not os.path.exists(label_file):\n",
    "        print(f\"Label file not found for {image_file}\")\n",
    "        continue\n",
    "    \n",
    "    # Read the label (description)\n",
    "    with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        description = f.read().strip()\n",
    "    \n",
    "    # Generate embedding using FastText\n",
    "    embedding = generate_embedding_fasttext(description,mod)\n",
    "    \n",
    "    # Save embedding as .npy file\n",
    "    output_file = os.path.join(output_folder, f\"{image_name}.npy\")\n",
    "    np.save(output_file, embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Glove Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: invalid escape sequence '\\g'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\g'\n",
      "C:\\Users\\student\\AppData\\Local\\Temp\\ipykernel_8532\\895928523.py:14: SyntaxWarning: invalid escape sequence '\\g'\n",
      "  glove_extracted_path = 'tamil_models\\glove.6B\\glove.6B.50d.txt'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe Model...\n",
      "Loaded 400000 words.\n",
      "Glove Model loaded sucessfully\n"
     ]
    }
   ],
   "source": [
    "#I have downloaded and extracted the glove model manually\n",
    "def load_glove_model(glove_file):\n",
    "    print(\"Loading GloVe Model...\")\n",
    "    glove_model = {}\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array([float(val) for val in split_line[1:]])\n",
    "            glove_model[word] = embedding\n",
    "    print(f\"Loaded {len(glove_model)} words.\")\n",
    "    return glove_model\n",
    "# Load the GloVe model\n",
    "glove_extracted_path = 'tamil_models\\glove.6B\\glove.6B.50d.txt'\n",
    "glove_model = load_glove_model(glove_extracted_path)\n",
    "print(\"Glove Model loaded sucessfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate embeddings\n",
    "def get_embedding(text, glove_model):\n",
    "    words = text.split()\n",
    "    embeddings = []\n",
    "    for word in words:\n",
    "        if word in glove_model:\n",
    "            embeddings.append(glove_model[word])\n",
    "        else:\n",
    "            # If the word is not in the GloVe model, use a zero vector\n",
    "            embeddings.append(np.zeros(len(next(iter(glove_model.values())))))\n",
    "    return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = r'C:\\Users\\student\\Desktop\\Datasets\\sample_data'\n",
    "images_folder = os.path.join(current_folder, \"Images\")\n",
    "labels_folder = os.path.join(current_folder, \"tamil_labels_300_proofread\")\n",
    "output_folder = os.path.join(current_folder, \"embeddings_300_proofread_glove\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'the'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load pre-trained GloVe vectors (e.g., 50-dimensional vectors)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m glove_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtamil_models\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mglove.6B\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mglove.6B.50d.txt\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# Replace with the actual path to your GloVe file\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m glove_model \u001b[38;5;241m=\u001b[39m \u001b[43mKeyedVectors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglove_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Now you can use the glove_model for word embeddings\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:1719\u001b[0m, in \u001b[0;36mKeyedVectors.load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header)\u001b[0m\n\u001b[0;32m   1672\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m   1673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_word2vec_format\u001b[39m(\n\u001b[0;32m   1674\u001b[0m         \u001b[38;5;28mcls\u001b[39m, fname, fvocab\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m, unicode_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1675\u001b[0m         limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, datatype\u001b[38;5;241m=\u001b[39mREAL, no_header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1676\u001b[0m     ):\n\u001b[0;32m   1677\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load KeyedVectors from a file produced by the original C word2vec-tool format.\u001b[39;00m\n\u001b[0;32m   1678\u001b[0m \n\u001b[0;32m   1679\u001b[0m \u001b[38;5;124;03m    Warnings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1717\u001b[0m \n\u001b[0;32m   1718\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load_word2vec_format\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1720\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbinary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43municode_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatatype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mno_header\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1722\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\gensim\\models\\keyedvectors.py:2059\u001b[0m, in \u001b[0;36m_load_word2vec_format\u001b[1;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype, no_header, binary_chunk_size)\u001b[0m\n\u001b[0;32m   2057\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2058\u001b[0m     header \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mto_unicode(fin\u001b[38;5;241m.\u001b[39mreadline(), encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[1;32m-> 2059\u001b[0m     vocab_size, vector_size \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m header\u001b[38;5;241m.\u001b[39msplit()]  \u001b[38;5;66;03m# throws for invalid file format\u001b[39;00m\n\u001b[0;32m   2060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m limit:\n\u001b[0;32m   2061\u001b[0m     vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(vocab_size, limit)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'the'"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Load pre-trained GloVe vectors (e.g., 50-dimensional vectors)\n",
    "glove_file = r'tamil_models\\glove.6B\\glove.6B.50d.txt'  # Replace with the actual path to your GloVe file\n",
    "glove_model = KeyedVectors.load_word2vec_format(glove_file, binary=False)\n",
    "\n",
    "# Now you can use the glove_model for word embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'wv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m     description \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Generate embedding using FastText\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m embedding \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_embedding_fasttext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43mglove_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Save embedding as .npy file\u001b[39;00m\n\u001b[0;32m     19\u001b[0m output_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.npy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[33], line 8\u001b[0m, in \u001b[0;36mgenerate_embedding_fasttext\u001b[1;34m(text, model)\u001b[0m\n\u001b[0;32m      6\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m words:\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwv\u001b[49m:\n\u001b[0;32m      9\u001b[0m         embeddings\u001b[38;5;241m.\u001b[39mappend(model\u001b[38;5;241m.\u001b[39mwv[word])\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;66;03m# If word is not found, use a zero vector\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'wv'"
     ]
    }
   ],
   "source": [
    "for image_file in tqdm(os.listdir(images_folder)):\n",
    "    image_name = os.path.splitext(image_file)[0]\n",
    "    \n",
    "    label_file = os.path.join(labels_folder, f\"{image_name}.txt\")\n",
    "    \n",
    "    # Check if the label file exists\n",
    "    if not os.path.exists(label_file):\n",
    "        print(f\"Label file not found for {image_file}\")\n",
    "        continue\n",
    "    \n",
    "    # Read the label (description)\n",
    "    with open(label_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        description = f.read().strip()\n",
    "    \n",
    "    # Generate embedding using FastText\n",
    "    embedding = generate_embedding_fasttext(description,glove_model)\n",
    "    \n",
    "    # Save embedding as .npy file\n",
    "    output_file = os.path.join(output_folder, f\"{image_name}.npy\")\n",
    "    np.save(output_file, embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
