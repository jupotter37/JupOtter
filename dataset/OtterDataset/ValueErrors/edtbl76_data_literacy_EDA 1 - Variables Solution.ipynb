{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2abe75df-c5f6-4128-b0ba-b3c0138186c9",
   "metadata": {},
   "source": [
    "# Intro to EDA (Exploratory Data Analysis)\n",
    "\n",
    "Since this is the first section on EDA. we should talk quickly about the process itself. \n",
    "\n",
    "```TBD```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822cf112a3790b7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a395780-e681-4cf6-845a-c13721fb7905",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912fcb73-6e52-4758-b91c-465bf554afdb",
   "metadata": {},
   "source": [
    "# Intro to Variables\n",
    "\n",
    "## Variable Types\n",
    "\n",
    "The columns represent the variables in a dataframe or table. \n",
    "\n",
    "**2 Types of Variables**\n",
    "1. Categorical\n",
    "2. Numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd71c2a9-040e-4773-bcbc-660ec74d5617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>country</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Norm of the ...</td>\n",
       "      <td>United States</td>\n",
       "      <td>missing</td>\n",
       "      <td>PG</td>\n",
       "      <td>91.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Jandino: Wha...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2016</td>\n",
       "      <td>R</td>\n",
       "      <td>94.516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Transformers...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2013</td>\n",
       "      <td>G</td>\n",
       "      <td>1.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Transformers...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2016</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>1.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Movie</td>\n",
       "      <td>#realityhigh...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2017</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>99.248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     type            title         country release_year rating  duration\n",
       "0   0    Movie  Norm of the ...   United States      missing     PG    91.071\n",
       "1   1    Movie  Jandino: Wha...  United Kingdom         2016      R    94.516\n",
       "2   2  TV Show  Transformers...   United States         2013      G     1.127\n",
       "3   3  TV Show  Transformers...   United States         2016  TV-14     1.687\n",
       "4   4    Movie  #realityhigh...   United States         2017  TV-14    99.248"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and show the data\n",
    "netflix = pandas.read_csv('netflix_kaggle_movies.csv')\n",
    "netflix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86268bb4-33a6-4b95-9567-555e7d2bb49a",
   "metadata": {},
   "source": [
    "Let's break down the variables. \n",
    "\n",
    "1. **id**: This is an id or label. Even though numbers are used to represent the labels, these are **categorical** variables.\n",
    "2. **type**: This is a category... so it's a **categorical** variable.\n",
    "3. **title**: This is a **categorical** variable.\n",
    "4. **country**: This is a **categorical** variable.\n",
    "5. **release_year**: This is a **numerical** variable.\n",
    "6. **rating**: This is a **categorical** variable.\n",
    "7. **duration**: This is a **numerical** variable.\n",
    "\n",
    "Note: Years can be challenging depending on the context. In this context we can think of it as something we \"count\", which will become more clear as we move on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f89ce4e-2bd6-4308-88ea-17e3698cb73d",
   "metadata": {},
   "source": [
    "### Categorical Variables (a.k.a. Qualitative Variables)\n",
    "\n",
    "There are three types of categorical variables. \n",
    "\n",
    "1. **nominal variables**: which describe something\n",
    "2. **ordinal variables**: which rank or order something\n",
    "3. **binary variables**: which have two (*and only two*) possible variations.\n",
    "\n",
    "Ordinal Variables are often the most confusing, because ordering and ranking has an obvious numeric context. However, the numeric context is *incalculable*. For instance, if we are analyzing Olympians on the podium, we don't generally average their place (although, this gets even more complicated.. because we calculate the average position someone places across multiple races. This is a whole different ball of yarn.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08131006-584f-4ab5-8eb4-264664ea49e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>country</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Norm of the ...</td>\n",
       "      <td>United States</td>\n",
       "      <td>missing</td>\n",
       "      <td>PG</td>\n",
       "      <td>91.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Jandino: Wha...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2016</td>\n",
       "      <td>R</td>\n",
       "      <td>94.516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Transformers...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2013</td>\n",
       "      <td>G</td>\n",
       "      <td>1.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Transformers...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2016</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>1.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Movie</td>\n",
       "      <td>#realityhigh...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2017</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>99.248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     type            title         country release_year rating  duration\n",
       "0   0    Movie  Norm of the ...   United States      missing     PG    91.071\n",
       "1   1    Movie  Jandino: Wha...  United Kingdom         2016      R    94.516\n",
       "2   2  TV Show  Transformers...   United States         2013      G     1.127\n",
       "3   3  TV Show  Transformers...   United States         2016  TV-14     1.687\n",
       "4   4    Movie  #realityhigh...   United States         2017  TV-14    99.248"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisit Netflix Again\n",
    "netflix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96b9d30-3da3-41d8-b522-c14f2dc05835",
   "metadata": {},
   "source": [
    "Let's revisit the list of variables again. This time we're going to further categorize the variables based on their sub category of categorical variables. \n",
    "\n",
    "| **Variable Name** | **Variable Type** | **Sub Type** |\n",
    "|-|-|-|\n",
    "| id | categorical | nominal* |\n",
    "| type | categorical | nominal | \n",
    "| title | categorical | nominal | \n",
    "| country | categorical | nominal | \n",
    "| release_year | numerical | TBD | \n",
    "| rating | categorical | ordinal | \n",
    "| duration | numerical | TBD | \n",
    "\n",
    "```\n",
    "NOTE: id is ambiguous right now. The easiest example I can think of is database IDs. Some auto-generated database IDs are deliberately sequential. This would make the id an ordinal variable. However, other IDs are UUIDs, which aren't sequential, making them nominal.\n",
    "\n",
    "Think about the use case. For time series data, we'd rank observations/rows/records based on the time of creation. However, depending on the fidelity of the capability of measuring time as well as these records being captured across a distributed system, uniqueness isn't guaranteed, so an ID might be required in data stores where uniqueness is a requirement of a record.\n",
    "\n",
    "Sometimes it's important to distinguish between insertion order and actual occurrence. This can also be established by another timestamp, but an auto-generated sequential id would serve the same purpose. (There are arguments that this violates single responsibility) .\n",
    "\n",
    "As a rule of thumb, I prefer to build databases where the ID is a unique identifier (therefore a nominal variable). This is a generally accepted sensible default.  However, we must always plan for someone making bad, ignorant or rushed decisions! Never assume the ID isn't moonlighting as an ordinal variable. \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f5dcab3-49b5-46ea-ad33-beaee2e6a3cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binary for type?? Let's prove it using some of the aggregations we've learned.\n",
    "netflix.type.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78755ac-c119-41ae-9810-1db36466a46a",
   "metadata": {},
   "source": [
    "### Numerical (or Qualitative) Variables\n",
    "\n",
    "*Grace Hopper* said, \"One accurate measurement is worth a thousand expert opinions.\"\n",
    "\n",
    "**2 Types of Numerical Variables**\n",
    "1. **continuous**: (*measurements*). There must be infinitely smaller units of measurement between one unit and the next. Time, distance. \n",
    "2. **discrete**: (*counts*). These are \"whole\" things we count. People, puppies, peanut butter cups.\n",
    "\n",
    "Let's revisit that netflix data... again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e7dd36d-6cc2-467d-913e-7486887b5d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>country</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rating</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Norm of the ...</td>\n",
       "      <td>United States</td>\n",
       "      <td>missing</td>\n",
       "      <td>PG</td>\n",
       "      <td>91.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Jandino: Wha...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2016</td>\n",
       "      <td>R</td>\n",
       "      <td>94.516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Transformers...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2013</td>\n",
       "      <td>G</td>\n",
       "      <td>1.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Transformers...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2016</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>1.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Movie</td>\n",
       "      <td>#realityhigh...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2017</td>\n",
       "      <td>TV-14</td>\n",
       "      <td>99.248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     type            title         country release_year rating  duration\n",
       "0   0    Movie  Norm of the ...   United States      missing     PG    91.071\n",
       "1   1    Movie  Jandino: Wha...  United Kingdom         2016      R    94.516\n",
       "2   2  TV Show  Transformers...   United States         2013      G     1.127\n",
       "3   3  TV Show  Transformers...   United States         2016  TV-14     1.687\n",
       "4   4    Movie  #realityhigh...   United States         2017  TV-14    99.248"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5c3f70-cbbc-42b7-a265-d43f97dc722e",
   "metadata": {},
   "source": [
    "Let's revisit the list of variables again. This time we're going to finish the table based on the qualitative variables. \n",
    "\n",
    "| **Variable Name** | **Variable Type** | **Sub Type** |\n",
    "|-|-|-|\n",
    "| id | categorical | nominal* |\n",
    "| type | categorical | nominal | \n",
    "| title | categorical | nominal | \n",
    "| country | categorical | nominal | \n",
    "| release_year | numerical | discrete | \n",
    "| rating | categorical | ordinal | \n",
    "| duration | numerical | continuous | \n",
    "\n",
    "Ok. **Duration** is more obvious, because it is clearly subdivided. **Release_year** is time too, though, right? Yes, however, it was captured as a counting variable (whole numbers), not as continuous time. \n",
    "\n",
    "This is important because time and distance can be confusing. Release year isn't being used as a continuous measurement here. For example, 2000 is a \"whole number\" year, whereas 10/15/2020\\:11\\:45 is a continuous time value. (like Unix Epoch or something along those lines.) \n",
    "\n",
    "Think of it this way. Are you \"counting it\"? Then it's discrete. Or.. are you \"measuring it\"? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560e2d2e-47c7-4371-9c54-a090c18ad1f2",
   "metadata": {},
   "source": [
    "### Playing with dtypes (Numerical)\n",
    "\n",
    "dtypes is a property of a pandas DataFrame that displays all of the data types. Let's see how we did in our table...\n",
    "\n",
    "**continuous** variables are usually represented as ```float``` data types. \n",
    "**discrete** variables are usually represented as ```int``` data types. \n",
    "\n",
    "```No, int32/int64 doesn't matter. Size has more to do w/ storage.```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f130c4b3-9a7b-407d-ad2e-30b6313f20ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                int64\n",
       "type             object\n",
       "title            object\n",
       "country          object\n",
       "release_year     object\n",
       "rating           object\n",
       "duration        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1480d2f5-955f-4346-a8e1-8d36361fe8b5",
   "metadata": {},
   "source": [
    "Not bad!\n",
    "\n",
    "**id** shows up as an ```int```, which we don't hate because it is! It's a discrete number, it just happens to be a label. \n",
    "\n",
    "**release_year** is an ```object```. I'd rather see that as an ```int``` (maybe). \n",
    "\n",
    "**duration** is a ```float```, which we expected. \n",
    "\n",
    "Let's clean this up and run it again. I'd like to set **id** to a ```string```, and **release_year** to an ```int```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73b74c4d-ca86-4da6-84b8-46db3fed8195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              string[python]\n",
       "type                    object\n",
       "title                   object\n",
       "country                 object\n",
       "release_year            object\n",
       "rating                  object\n",
       "duration               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert id to a string\n",
    "netflix.id = netflix.id.astype('string')\n",
    "netflix.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e05fce50-7b1c-44cb-acc1-4ecc16017957",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'missing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# convert year to int32\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m netflix\u001b[38;5;241m.\u001b[39mrelease_year \u001b[38;5;241m=\u001b[39m \u001b[43mnetflix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelease_year\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint32\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m netflix\u001b[38;5;241m.\u001b[39mdtypes\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/generic.py:6640\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6634\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6635\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6636\u001b[0m     ]\n\u001b[1;32m   6638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6639\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6640\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6641\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'missing'"
     ]
    }
   ],
   "source": [
    "# convert year to int32\n",
    "netflix.release_year = netflix.release_year.astype(\"int32\")\n",
    "netflix.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ebf5e06c-e735-4131-9998-b871528c93aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['missing', '2016', '2013', '2017', '2014', '2015', '2009', '2012',\n",
       "       '2010', '2018', '2011', '2019', '2004', '2000', '1983', '1982',\n",
       "       '2006', '2005', '2002', '1997', '2008', '2007', '2003', '1981',\n",
       "       '1991', '1994', '1988', '1976', '1973', '1974', '1989', '1986',\n",
       "       '1984', '1978', '1998', '1972', '1979', '1960', '1959', '2001',\n",
       "       '1995', '1992', '1990', '1975', '1985', '1980', '1970', '1996',\n",
       "       '1967', '1999', '1987', '1968', '1993', '2020', '1958', '1965',\n",
       "       '1956', '1962', '1955', '1977', '1945', '1946', '1942', '1944',\n",
       "       '1947', '1943', '1969', '1954', '1966', '1971', '1964', '1925',\n",
       "       '1963'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hmm.. that caused an error... wonder why??? \n",
    "netflix.release_year.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8d5eeb-eaa6-4c58-b341-b71aa5f9c663",
   "metadata": {},
   "source": [
    "Aha!! \n",
    "\n",
    "We've run into our first numerical problemo. 'missing' isn't an int, so we need to replace this in order to properly categorize the data. We can't perform calculations on 'missing'. \n",
    "\n",
    "For now, let's \n",
    "1. replace missing w/ 0\n",
    "2. re-run the previous code to categorize the data\n",
    "3. check the ```dtypes```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6c482c1c-a512-4051-9953-4bba6f7030d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              string[python]\n",
       "type                    object\n",
       "title                   object\n",
       "country                 object\n",
       "release_year             int32\n",
       "rating                  object\n",
       "duration               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: for nans, we would do this\n",
    "# netflix.release_year.fillna(0, inplace=True)\n",
    "#\n",
    "# Since this is a string 'missing', we can replace it like this:\n",
    "netflix.release_year = netflix.release_year.replace('missing',0)\n",
    "netflix.release_year = netflix.release_year.astype(\"int32\")\n",
    "netflix.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5377a16-6375-4f0d-bce8-5819381927fc",
   "metadata": {},
   "source": [
    "### Playing with dtypes (categorical)\n",
    "\n",
    "This continues what we did above, but w/ categorical variables. \n",
    "\n",
    "**nominal** variables are usually ```object``` or ```string``` data types. The ```object``` type in pandas is more of a \"junk type\" than anything else. It is reserved for everything that it can't identify as ```intXX```, ```floatXX```, or ```bool```. Pandas doesn't automatically identify anything as a string. You have to do it explicitly. The primary reason for using ```string``` is to perform string operations like ```lower()```. \n",
    "\n",
    "**ordinal** variables are usually incorrectly encoded as ```int``` by pandas, ut they are typically ```object```. \n",
    "\n",
    "**binary** variables can be represented as bool, but are often encoded as ```object``` or ```int```. \n",
    "\n",
    "Let's go through them one at a time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d1cc06ed-be20-4964-af8e-5e198d5a98aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               object\n",
       "type             object\n",
       "title            object\n",
       "country          object\n",
       "release_year      int32\n",
       "rating           object\n",
       "duration        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I've decided I don't want id to be a string...because we can't perform most string operations on a number!\n",
    "netflix.id = netflix.id.astype('object')\n",
    "netflix.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bc9896c8-be06-4eed-8fe0-31f696091e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               object\n",
       "type               bool\n",
       "title            object\n",
       "country          object\n",
       "release_year      int32\n",
       "rating           object\n",
       "duration        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We defined type as a binary variable earlier, so let's set it to a bool.\n",
    "netflix.type = netflix.type.astype('bool')\n",
    "netflix.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f06b4d6f-4d05-44c5-a8cd-825bd973e6c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      object\n",
       "type                      bool\n",
       "title           string[python]\n",
       "country                 object\n",
       "release_year             int32\n",
       "rating                  object\n",
       "duration               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Title... hm. That really is a string. We might want to do string-y things to it. \n",
    "netflix.title = netflix.title.astype('string')\n",
    "netflix.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5562cffd-3548-4078-9831-d15a31e98a51",
   "metadata": {},
   "source": [
    "Country and Rating are both strings, but I'm going to leave them alone for now. \n",
    "In this case, both Rating and Country represent what would probably be an 'enum' in a codebase, because\n",
    "there are a finite set of potential values, and I'd like them to all be the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c161b73b-f6b8-4d87-8cb9-c10f6e46b6ea",
   "metadata": {},
   "source": [
    "### Pandas 'Category' Data Type\n",
    "\n",
    "One of the limitations of these data types is that they can't do things like tell us about order or sequencing. Pandas has a categorical method specifically for this. Let's look at the ```rating``` variable in more detail. (Remember.. we said this was **ordinal**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "408d6580-a2df-49c3-9ef4-1f7c2a53e19d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PG', 'R', 'G', 'TV-14', 'PG-13', nan, 'UNRATED', 'NOT RATED'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the unique vales of rating.\n",
    "netflix.rating.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edbb61e-2076-42d9-9ede-16ec9f705e88",
   "metadata": {},
   "source": [
    "Ugh. That's a mess. \n",
    "\n",
    "Upon **inspection** of the data, we've got to do some cleaning. \n",
    "Before we get to that step, let's thing about the sources. \n",
    "\n",
    "If the data is external, at best we can notify the stewards, although they may not actually be the owners, so the odds of it changing are low. (It's worth noting that the problem exists if you plan to re-use this data regularly.)\n",
    "\n",
    "If the data is internal, we need to note the source so that we can fix it and streamline the process in the future. \n",
    "\n",
    "*in this case we know the data is external*\n",
    "\n",
    "**Step 1: ID the problem**\n",
    "The problem, in this case, is that we have 3 different values that represent the same meaning: \n",
    "- nan\n",
    "- UNRATED\n",
    "- NOT RATED\n",
    "\n",
    "We'd have to validate that as best as we can.It's entirely possible that there is a degree of nuance. nan could be a value that was unintentinally left out, UNRATED could be a movie that was never evaluated for a rating (potentionally due to when it was released), and NOT RATED could be a movie that was explicitly not given a rating. \n",
    "\n",
    "For right now, we're going to say that we don't care why it wasn't rated. All we care about is that it wasn't. \n",
    "\n",
    "**Step 2: handle the discrepancy**\n",
    "We need to make a decision about how these values are going to be represented. A common representation is 'NR'. \n",
    "\n",
    "**Step 3: clean!!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a2917680-b140-45d8-b183-6c7615cf1709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PG', 'R', 'G', 'TV-14', 'PG-13', 'NR', 'UNRATED', 'NOT RATED'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fillna() is the best way to resolve 'nan's\n",
    "netflix.rating = netflix.rating.fillna('NR')\n",
    "netflix.rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2e186668-e22c-49f3-adfb-2e6881af1205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PG', 'R', 'G', 'TV-14', 'PG-13', 'NR'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You might remember the replace() method from the Python Pandas courses. \n",
    "## When we are doing a 1:1 find/replace, the syntax is replace(from_value, to_value)\n",
    "## doing a many:1 replace is a bit more tricky\n",
    "netflix.rating = netflix.rating.replace(\n",
    "    dict.fromkeys(['UNRATED','NOT RATED'], 'NR')\n",
    ")\n",
    "netflix.rating.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f5447-0dce-452b-ad02-78d18cd58ad6",
   "metadata": {},
   "source": [
    "Cool. We're in much better shape now. \n",
    "\n",
    "--- \n",
    "\n",
    "Before we get to that Categorical data type, I want to take a look at TV-14 vs. PG-13. \n",
    "\n",
    "Our data set includes ratings for both TV and Movies. We have a few options about how to handle this. \n",
    "\n",
    "The complex way is to manage two rating systems. This means that the rating system is conditional based on the ```type``` variable. This isn't uncommon, but it's naturally more complex. \n",
    "\n",
    "**Why** would you do this? \n",
    "In many cases, categorization through a binary/bool data type is purposely going to result in analysis of different types or categories. If our job was to compare the ratings systems (TV vs. MPA), then having two different categories for rating would make sense, because we'd likely be looking for comparisons between the two (based on some other confounding variable more than likely). In this case the nuances of the two ratings systems matter. \n",
    "\n",
    "Alternatively, we might be looking at something, else and rating is more of a categorical generalization. \n",
    "\n",
    "There are two very powerful tools that help us become more decisive. \n",
    "1. If you have the raw data, you have the ability to be wrong. This is my favorite tool. I love being wrong. \n",
    "2. **I don't know**. If you aren't sure, just make an educated guess, make a call and move forward.\n",
    "\n",
    "If you are wrong, you're going to find out quickly. Don't fight against that. Let it happen, and enjoy it. \n",
    "\n",
    "---\n",
    "\n",
    "Given that side bar, we don't really know what we're doing with this data yet. Looking at the rest of the ratings, it seems that TV-14 is the only tv rating in the bunch. The rest are all MPA ratings. As a result, to remain consistent, let's find the closest MPA rating.. which happens to be PG-13. Let's swap the values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3c44aa7b-d144-4e26-a949-19f430a1fdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['PG', 'R', 'G', 'PG-13', 'NR'], dtype=object)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix.rating = netflix.rating.replace('TV-14','PG-13')\n",
    "netflix.rating.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2a4f6b-01e5-427b-9cfb-43eb8f90d117",
   "metadata": {},
   "source": [
    "(Yes, cleaning and data analysis should be this tedious. Being open and eager to be wrong quickly, is how we end up ultimately w/ results that are **right**). \n",
    "\n",
    "So now let's create a Categorical variable! and order the ratings...\n",
    "\n",
    "Oops, what's the order? More accurately, where do we put 'NR'. There are a number of folks who things that NR should be put first. I personally think that's a bad idea, because the 'lowest' rating (G) is based on the appropriateness of the content for all audiences. If we put NR below G we'd be suggesting that content that hasn't been evaluated is appropriate for children. Instead, let's put it at the other end. \n",
    "\n",
    "```\n",
    "G, PG, PG-13, R, NR\n",
    "```\n",
    "\n",
    "It's critical to justify ordering in a clear (and intuitive manner). When it comes to governance and data dictionaries, we want to use as few words as possible. The heavier our data governance is, the more likely the users get bogged down with the experience. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f7fa933a-c52a-46f9-a2b0-ba0b267e0dc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PG', 'R', 'G', 'PG-13', 'NR']\n",
       "Categories (5, object): ['G' < 'PG' < 'PG-13' < 'R' < 'NR']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally! Categorical!\n",
    "netflix.rating = pandas.Categorical(\n",
    "    netflix.rating,\n",
    "    ['G','PG','PG-13','R','NR'],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# Now what does our data look like...\n",
    "netflix.rating.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc1deeb-1bdb-48f2-82dc-27e17567236b",
   "metadata": {},
   "source": [
    "### OHE (One-Hot Encoding)\n",
    "This is a clever technique for making comparisons. We are essentially decomposing a categorical variable into a new binary variable for each of the categories of the original variable. \n",
    "\n",
    "If you consider our ratings, we end up with\n",
    "\n",
    "G, NOT_G\n",
    "PG, NOT_PG\n",
    "PG-13, NOT_PG-13\n",
    "R, NOT_R\n",
    "\n",
    "We might not need NR anymore as it would represent a case where a movie is NOT_X for all 4 OHE variables. It ultimately depends on whether or not we want to provide a comparison for NR. \n",
    "\n",
    "**A few important notes:**\n",
    "- There is no ordering, so consider this. OHE is more popular for nominal values, but it can still be used for ordinals, *especially when we don't want to assume there is equal spacing between the categories* (i.e. like a Likert scale)\n",
    "- we use a method called ```get_dummies()``` in pandas. (the dummy is the OHE variable). It is creating an entirely new dataframe w/ a different set of variables to the original dataframe.\n",
    "- OHE works best for categories w/ a small number of variables, especially for **ML Modeling**. Adding variables increases dimensionality of the dataframe, which creates problems w/ certain ML modeling techniques. (It can make it run slower, and add noise to the calculations)\n",
    "\n",
    "So, it would make sense to use it on ```ratings```, where the distance between each rating is ambiguous. It wouldn't make sense to apply it to ```country```, because there are 200+ countries in the world (probably not as many making movies, but I digress). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a80e3b4-3c3c-4c58-a0ec-a54c55713d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>country</th>\n",
       "      <th>release_year</th>\n",
       "      <th>duration</th>\n",
       "      <th>rating_G</th>\n",
       "      <th>rating_PG</th>\n",
       "      <th>rating_PG-13</th>\n",
       "      <th>rating_R</th>\n",
       "      <th>rating_NR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Norm of the ...</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>91.071</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>Jandino: Wha...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2016</td>\n",
       "      <td>94.516</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>Transformers...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.127</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>Transformers...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.687</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>#realityhigh...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2017</td>\n",
       "      <td>99.248</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6229</th>\n",
       "      <td>6229</td>\n",
       "      <td>True</td>\n",
       "      <td>Red vs. Blue...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2015</td>\n",
       "      <td>13.101</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6230</th>\n",
       "      <td>6230</td>\n",
       "      <td>True</td>\n",
       "      <td>Maron...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2016</td>\n",
       "      <td>4.122</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6231</th>\n",
       "      <td>6231</td>\n",
       "      <td>True</td>\n",
       "      <td>Little Baby ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016</td>\n",
       "      <td>60.362</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6232</th>\n",
       "      <td>6232</td>\n",
       "      <td>True</td>\n",
       "      <td>A Young Doct...</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2013</td>\n",
       "      <td>2.082</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6233</th>\n",
       "      <td>6233</td>\n",
       "      <td>True</td>\n",
       "      <td>Friends...</td>\n",
       "      <td>United States</td>\n",
       "      <td>2003</td>\n",
       "      <td>10.972</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6234 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  type            title         country  release_year  duration  \\\n",
       "0        0  True  Norm of the ...   United States             0    91.071   \n",
       "1        1  True  Jandino: Wha...  United Kingdom          2016    94.516   \n",
       "2        2  True  Transformers...   United States          2013     1.127   \n",
       "3        3  True  Transformers...   United States          2016     1.687   \n",
       "4        4  True  #realityhigh...   United States          2017    99.248   \n",
       "...    ...   ...              ...             ...           ...       ...   \n",
       "6229  6229  True  Red vs. Blue...   United States          2015    13.101   \n",
       "6230  6230  True         Maron...   United States          2016     4.122   \n",
       "6231  6231  True  Little Baby ...             NaN          2016    60.362   \n",
       "6232  6232  True  A Young Doct...  United Kingdom          2013     2.082   \n",
       "6233  6233  True       Friends...   United States          2003    10.972   \n",
       "\n",
       "      rating_G  rating_PG  rating_PG-13  rating_R  rating_NR  \n",
       "0        False       True         False     False      False  \n",
       "1        False      False         False      True      False  \n",
       "2         True      False         False     False      False  \n",
       "3        False      False          True     False      False  \n",
       "4        False      False          True     False      False  \n",
       "...        ...        ...           ...       ...        ...  \n",
       "6229     False      False         False      True      False  \n",
       "6230     False      False         False      True      False  \n",
       "6231     False      False         False     False       True  \n",
       "6232     False      False         False      True      False  \n",
       "6233     False      False          True     False      False  \n",
       "\n",
       "[6234 rows x 11 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OHE the ratings category\n",
    "netflix_ratings_ohe = pandas.get_dummies(data=netflix,columns=['rating'])\n",
    "netflix_ratings_ohe                                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee110bd-f5f9-437e-ad18-c5b69c651f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
