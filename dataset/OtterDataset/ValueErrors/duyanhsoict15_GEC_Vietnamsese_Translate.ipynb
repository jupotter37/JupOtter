{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Translate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1DslGZWPxNF",
        "outputId": "3b47485a-0d13-4a5d-85fb-b0d3fa6e203b"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jul  7 01:37:37 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P0    23W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpiZxh6TtPcC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5epsFM7mPX8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6625fcd-9137-426e-c44a-8830053d4b6c"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "path = '/content/gdrive/MyDrive/data'\n",
        "%cd {path}\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive/data\n",
            "'Bản sao của eng.txt'\t\t\t        NNVLP\n",
            " char\t\t\t\t\t        OpenNMT-py\n",
            " Co_Huong\t\t\t\t        OpenNMT-tf\n",
            " corpus.21a7f66d40bcf46cc5fba018aba04c7a.data   pred3.txt\n",
            " data_err.txt\t\t\t\t        pred.txt\n",
            " data_e.txt\t\t\t\t        rnn_0_epoch.net\n",
            " data_pro.txt\t\t\t\t        rnn_1_epoch.net\n",
            " deep-spell-checkr\t\t\t        train\n",
            " eng1.txt\t\t\t\t        train_vntc1.txt\n",
            " engt.txt\t\t\t\t        VNTC\n",
            " eng.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKBG8C437szL",
        "outputId": "bf8b96da-a0b4-4387-953d-afad22cc4343"
      },
      "source": [
        "!pip install OpenNMT-py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting OpenNMT-py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/23/c565e03ddffb57db1b79bd9a97c8f56895eea094d9314ba5b12ce1282593/OpenNMT_py-2.1.2-py3-none-any.whl (212kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 13.4MB/s \n",
            "\u001b[?25hCollecting waitress==1.4.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/d1/5209fb8c764497a592363c47054436a515b47b8c3e4970ddd7184f088857/waitress-1.4.4-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.0MB/s \n",
            "\u001b[?25hCollecting tqdm<5,>=4.51\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/ec/f8ff3ccfc4e59ce619a66a0bf29dc3b49c2e8c07de29d572e191c006eaa2/tqdm-4.61.2-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.4MB/s \n",
            "\u001b[?25hCollecting pyyaml==5.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/86/83ae5504903b4eca5ae1fd3c53b87b640f9c302df2c97fc08331ec7f3c8a/PyYAML-5.4-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 20.5MB/s \n",
            "\u001b[?25hCollecting flask==1.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/28/2a03252dfb9ebf377f40fba6a7841b47083260bf8bd8e737b0c6952df83f/Flask-1.1.2-py2.py3-none-any.whl (94kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 13.1MB/s \n",
            "\u001b[?25hCollecting configargparse<2,>=1.2.3\n",
            "  Downloading https://files.pythonhosted.org/packages/5e/1d/9722b6247cb89ee9f741095bf748c87ae064c5961758846e4f03fa1f4940/ConfigArgParse-1.5.1-py3-none-any.whl\n",
            "Collecting torchtext==0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/79/ef/54b8da26f37787f5c670ae2199329e7dccf195c060b25628d99e587dac51/torchtext-0.5.0-py3-none-any.whl (73kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard<3,>=2.3 in /usr/local/lib/python3.7/dist-packages (from OpenNMT-py) (2.5.0)\n",
            "Collecting torch==1.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/5e/35140615fc1f925023f489e71086a9ecc188053d263d3594237281284d82/torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8MB 23kB/s \n",
            "\u001b[?25hCollecting pyonmttok<2,>=1.23; platform_system == \"Linux\" or platform_system == \"Darwin\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/73/034c3e0584322e3f3f03c0965c8a83df0ab7ae5ca65172203cd606ffe8ce/pyonmttok-1.26.4-cp37-cp37m-manylinux1_x86_64.whl (14.3MB)\n",
            "\u001b[K     |████████████████████████████████| 14.3MB 21.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask==1.1.2->OpenNMT-py) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask==1.1.2->OpenNMT-py) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask==1.1.2->OpenNMT-py) (1.1.0)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask==1.1.2->OpenNMT-py) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.5.0->OpenNMT-py) (1.15.0)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/aa/1437691b0c7c83086ebb79ce2da16e00bef024f24fec2a5161c35476f499/sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 49.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3->OpenNMT-py) (1.31.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3->OpenNMT-py) (57.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3->OpenNMT-py) (1.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3->OpenNMT-py) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3->OpenNMT-py) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3->OpenNMT-py) (0.4.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3->OpenNMT-py) (0.36.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3->OpenNMT-py) (3.3.4)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3->OpenNMT-py) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3->OpenNMT-py) (1.34.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->OpenNMT-py) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask==1.1.2->OpenNMT-py) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.5.0->OpenNMT-py) (3.0.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3->OpenNMT-py) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3->OpenNMT-py) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3->OpenNMT-py) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3->OpenNMT-py) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3->OpenNMT-py) (4.5.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3->OpenNMT-py) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3->OpenNMT-py) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3->OpenNMT-py) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3->OpenNMT-py) (3.7.4.3)\n",
            "\u001b[31mERROR: torchvision 0.10.0+cu102 has requirement torch==1.9.0, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: waitress, tqdm, pyyaml, flask, configargparse, torch, sentencepiece, torchtext, pyonmttok, OpenNMT-py\n",
            "  Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: Flask 1.1.4\n",
            "    Uninstalling Flask-1.1.4:\n",
            "      Successfully uninstalled Flask-1.1.4\n",
            "  Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Found existing installation: torchtext 0.10.0\n",
            "    Uninstalling torchtext-0.10.0:\n",
            "      Successfully uninstalled torchtext-0.10.0\n",
            "Successfully installed OpenNMT-py-2.1.2 configargparse-1.5.1 flask-1.1.2 pyonmttok-1.26.4 pyyaml-5.4 sentencepiece-0.1.96 torch-1.6.0 torchtext-0.5.0 tqdm-4.61.2 waitress-1.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zvug-Kd65Lj",
        "outputId": "3f70dac0-e74e-4371-b149-500112f785bc"
      },
      "source": [
        "with open('train/test_tgt2.txt', 'r', encoding='utf-8') as f:\n",
        "  test_tgt = f.readlines()\n",
        "print('Number of sequences: ', len(test_tgt))\n",
        "print('First sequence: ', test_tgt[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences:  10000\n",
            "First sequence:  Điệp khúc \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsCRK0Vu7UgW",
        "outputId": "b9076ec5-a593-410c-f2ca-af7c711e1108"
      },
      "source": [
        "with open('train/test_src2.txt', 'r', encoding='utf-8') as f:\n",
        "  test_src = f.readlines()\n",
        "print('Number of sequences: ', len(test_src))\n",
        "print('First sequence: ', test_src[10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences:  10000\n",
            "First sequence:  Điệp khúc \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVFMu4q878hX",
        "outputId": "76bb192d-a4f7-4ec6-a892-d3480b509482"
      },
      "source": [
        "english = []\n",
        "from tqdm import tqdm\n",
        "with open('engt.txt', 'r', encoding='utf-8') as f:\n",
        "  eng = f.readlines()\n",
        "for i in tqdm(range(len(eng))):\n",
        "  [idx, word] = eng[i].split('\\t',1)\n",
        "  word = word.replace('\\n','')\n",
        "  english.append(word)\n",
        "print('Number of sequences: ', len(eng))\n",
        "print('Number of sequences: ', len(english))\n",
        "print('First sequence: ', eng[10])\n",
        "print('First sequence: ', english[10])\n",
        "print('First sequence: ', english[11])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 293734/293734 [00:00<00:00, 1034345.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of sequences:  293734\n",
            "Number of sequences:  293734\n",
            "First sequence:  10\tWashington\n",
            "\n",
            "First sequence:  Washington\n",
            "First sequence:  DC\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-EJavLG7mFn",
        "outputId": "363dc1b0-2212-4e94-a72e-1c94c679f797"
      },
      "source": [
        "from onmt.translate.translator import build_translator\n",
        "from argparse import Namespace\n",
        "\n",
        "\n",
        "path = 'train/eng_mark/model/model_step_150000.pt'\n",
        "opt = Namespace(models=['train/eng_mark/model/model_step_150000.pt'], n_best=1, alpha=0.0, batch_type='sents', beam_size=5, beta=-0.0, block_ngram_repeat=0, coverage_penalty='none',tgt_prefix = False, data_type='text', dump_beam='', fp32=False, gpu=-1, ignore_when_blocking=[], length_penalty='none', max_length=100, max_sent_length=None, min_length=0, output='/dev/null', phrase_table='', random_sampling_temp=1.0, random_sampling_topk=1, ratio=-0.0, replace_unk=True, report_align=False, report_time=False, seed=829, stepwise_penalty=False, tgt=None, verbose=False,ban_unk_token =False, random_sampling_topp = False, int8 = False)\n",
        "translator = build_translator(opt, report_score=True)\n",
        "code = translator.translate(['Bảo đảm, cổ vũ cho sự phát triển, mở rộg và su dụng ENG＿0 đc thuận lợi nhất cho mọi ngườj trên toàn thế giới'], batch_size=1)\n",
        "code = code[1][0][0].replace('@@ ', '')\n",
        "\n",
        "print(code)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PRED AVG SCORE: -0.0726, PRED PPL: 1.0753\n",
            "Bảo đảm, cổ vũ cho sự phát triển, mở rộng và sử dụng ENG＿0 được thuận lợi nhất cho mọi người trên toàn thế giới\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_odaXQGUPldj",
        "outputId": "e38bf060-57f9-4f19-b09c-057f23a71190"
      },
      "source": [
        "!apt install -qq enchant\n",
        "!pip install pyenchant"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The following additional packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common hunspell-en-us\n",
            "  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n",
            "Suggested packages:\n",
            "  aspell-doc spellutils wordlist hunspell openoffice.org-hunspell\n",
            "  | openoffice.org-core libenchant-voikko\n",
            "The following NEW packages will be installed:\n",
            "  aspell aspell-en dictionaries-common emacsen-common enchant hunspell-en-us\n",
            "  libaspell15 libenchant1c2a libhunspell-1.6-0 libtext-iconv-perl\n",
            "0 upgraded, 10 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 1,310 kB of archives.\n",
            "After this operation, 5,353 kB of additional disk space will be used.\n",
            "Preconfiguring packages ...\n",
            "Selecting previously unselected package libtext-iconv-perl.\n",
            "(Reading database ... 160772 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libtext-iconv-perl_1.7-5build6_amd64.deb ...\n",
            "Unpacking libtext-iconv-perl (1.7-5build6) ...\n",
            "Selecting previously unselected package libaspell15:amd64.\n",
            "Preparing to unpack .../1-libaspell15_0.60.7~20110707-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking libaspell15:amd64 (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Selecting previously unselected package emacsen-common.\n",
            "Preparing to unpack .../2-emacsen-common_2.0.8_all.deb ...\n",
            "Unpacking emacsen-common (2.0.8) ...\n",
            "Selecting previously unselected package dictionaries-common.\n",
            "Preparing to unpack .../3-dictionaries-common_1.27.2_all.deb ...\n",
            "Adding 'diversion of /usr/share/dict/words to /usr/share/dict/words.pre-dictionaries-common by dictionaries-common'\n",
            "Unpacking dictionaries-common (1.27.2) ...\n",
            "Selecting previously unselected package aspell.\n",
            "Preparing to unpack .../4-aspell_0.60.7~20110707-4ubuntu0.1_amd64.deb ...\n",
            "Unpacking aspell (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Selecting previously unselected package aspell-en.\n",
            "Preparing to unpack .../5-aspell-en_2017.08.24-0-0.1_all.deb ...\n",
            "Unpacking aspell-en (2017.08.24-0-0.1) ...\n",
            "Selecting previously unselected package hunspell-en-us.\n",
            "Preparing to unpack .../6-hunspell-en-us_1%3a2017.08.24_all.deb ...\n",
            "Unpacking hunspell-en-us (1:2017.08.24) ...\n",
            "Selecting previously unselected package libhunspell-1.6-0:amd64.\n",
            "Preparing to unpack .../7-libhunspell-1.6-0_1.6.2-1_amd64.deb ...\n",
            "Unpacking libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Selecting previously unselected package libenchant1c2a:amd64.\n",
            "Preparing to unpack .../8-libenchant1c2a_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Selecting previously unselected package enchant.\n",
            "Preparing to unpack .../9-enchant_1.6.0-11.1_amd64.deb ...\n",
            "Unpacking enchant (1.6.0-11.1) ...\n",
            "Setting up libhunspell-1.6-0:amd64 (1.6.2-1) ...\n",
            "Setting up libaspell15:amd64 (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Setting up emacsen-common (2.0.8) ...\n",
            "Setting up libtext-iconv-perl (1.7-5build6) ...\n",
            "Setting up dictionaries-common (1.27.2) ...\n",
            "Setting up aspell (0.60.7~20110707-4ubuntu0.1) ...\n",
            "Setting up hunspell-en-us (1:2017.08.24) ...\n",
            "Setting up libenchant1c2a:amd64 (1.6.0-11.1) ...\n",
            "Setting up aspell-en (2017.08.24-0-0.1) ...\n",
            "Setting up enchant (1.6.0-11.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for dictionaries-common (1.27.2) ...\n",
            "aspell-autobuildhash: processing: en [en-common].\n",
            "aspell-autobuildhash: processing: en [en-variant_0].\n",
            "aspell-autobuildhash: processing: en [en-variant_1].\n",
            "aspell-autobuildhash: processing: en [en-variant_2].\n",
            "aspell-autobuildhash: processing: en [en-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_AU-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_AU-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_AU-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_CA-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_CA-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_CA-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ise-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-ize-wo_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_0].\n",
            "aspell-autobuildhash: processing: en [en_GB-variant_1].\n",
            "aspell-autobuildhash: processing: en [en_US-w_accents-only].\n",
            "aspell-autobuildhash: processing: en [en_US-wo_accents-only].\n",
            "Collecting pyenchant\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/f1/162fc6975068098e3327358216b70bbecba1d8004438c3bc8fe9f9378a89/pyenchant-3.2.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.4MB/s \n",
            "\u001b[?25hInstalling collected packages: pyenchant\n",
            "Successfully installed pyenchant-3.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oMBmsSNN2kn"
      },
      "source": [
        "import enchant\n",
        "d = enchant.Dict(\"en_US\")\n",
        "def add_eng(sentence):\n",
        "  sentence = sentence.replace('\\n','')\n",
        "  wordl = sentence.split(' ')\n",
        "  sen = ''\n",
        "  for word in wordl:\n",
        "    if(word != '' and word[-1] == ','):\n",
        "      #print(word)\n",
        "      word = word.replace(',','')\n",
        "      if(word != '' and (d.check(word) or word.isupper())):\n",
        "        if(word not in english):\n",
        "          english.append(word)\n",
        "        index = english.index(word)\n",
        "        word = \"ENG＿\" + str(index)\n",
        "      word = word + ','\n",
        "    elif(word != '' and (d.check(word) or word.isupper())):\n",
        "      if(word not in english):\n",
        "        english.append(word)\n",
        "      index = english.index(word)\n",
        "      word = \"ENG＿\" + str(index)\n",
        "    sen = sen + word + ' '\n",
        "  return sen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5tqKG0-Qjg2",
        "outputId": "1f8b6899-f3da-4437-ccc2-b768cab812a0"
      },
      "source": [
        "print(add_eng(\"Đầu vào có nghĩa là input\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Đầu vào có nghĩa là ENG＿39527 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPMdXk3e83eF"
      },
      "source": [
        "def replace_eng(sentence):\n",
        "  sentence = sentence.replace('\\n','')\n",
        "  wordl = sentence.split(' ')\n",
        "  sen = ''\n",
        "  for word in wordl:\n",
        "    if(\"ENG\" in word  and word[-1] == ','):\n",
        "      #print(word)\n",
        "      word = word.replace(',','')\n",
        "      st = word.index('ENG')\n",
        "      index = int(word[(st+4):])\n",
        "      word = english[index]+','\n",
        "    elif(\"ENG\" in word):\n",
        "      #print(word)\n",
        "      st = word.index('ENG')\n",
        "      index = int(word[(st+4):])\n",
        "      word = english[index]\n",
        "    sen = sen + word + ' '\n",
        "  return sen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "TDYTZQBVK6h5",
        "outputId": "07dbc461-4371-4090-e569-117c1c7a38d1"
      },
      "source": [
        "code = translator.translate(['Bảo đảm, cổ vũ cho sự phát triển, mở rộg và su dụng ENG＿0 đc thuận lợi nhất cho mọi ngườj trên toàn thế giới'], batch_size=1)\n",
        "code = code[1][0][0].replace('@@ ', '')\n",
        "\n",
        "print(replace_eng(code))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-565e780f0603>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Bảo đảm, cổ vũ cho sự phát triển, mở rộg và su dụng ENG＿0 đc thuận lợi nhất cho mọi ngườj trên toàn thế giới'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'@@ '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace_eng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'translator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E6eQYimDMP8",
        "outputId": "d04574d9-3ef4-4199-8a5a-5607985bff2a"
      },
      "source": [
        "from tqdm import tqdm\n",
        "for i in tqdm(range(600,610)):\n",
        "  print(i)\n",
        "  print(\"SRC = \" + test_src[i])\n",
        "  print(\"SRC = \" + replace_eng(test_src[i]))\n",
        "  print(\"TGT = \" + replace_eng(test_tgt[i]))\n",
        "  #code = translator.translate(['Bảo đảm, cổ vũ cho sự phát triển, mở rộg và su dụng ENG＿0 đc thuận lợi nhất cho mọi ngườj trên toàn thế giới'], batch_size=1)\n",
        "  code = translator.translate([test_src[i]], batch_size=1)\n",
        "  code = code[1][0][0].replace('@@ ', '')\n",
        "  print(\"PRED= \" + replace_eng(code) )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "600\n",
            "SRC = Tuy nhiên, Nhân fông đã nuốt liờ va phong ENG＿7 tvai à là Thạc Đức Bát Thcíh làm Thasi tử vào năm ENG＿18645 \n",
            "\n",
            "SRC = Tuy nhiên, Nhân fông đã nuốt liờ va phong con tvai à là Thạc Đức Bát Thcíh làm Thasi tử vào năm 1316  \n",
            "TGT = Tuy nhiên, Nhân Tông đã nuốt lời và phong con trai bà là Thạc Đức Bát Thích làm Thái tử vào năm 1316  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 1/10 [00:00<00:05,  1.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PRED AVG SCORE: -0.2391, PRED PPL: 1.2701\n",
            "PRED= Tuy nhiên, Nhân Tông đã nuốt lời và phong con tvai và là Thạch Đức Bát Thcíh làm Thái tử vào năm 1316 \n",
            "601\n",
            "SRC = Thái hậu Đáp Kỷ, mẹ Nhân Tông uòn tiế tay đuổi ENG＿78 nguwời ENG＿7 còn sống của Vũ Tông là Đồ Thiếp Mục ENG＿4189 và Hòa Thế Lạt khỏi cung, với lý ENG＿22 mẹ họ vốn là thị thiếp và không thuộc tộc Hoằng Ct Lạt thị, mục đích bảo toàn thế lực ngoạr thích ở mriều đình \n",
            "\n",
            "SRC = Thái hậu Đáp Kỷ, mẹ Nhân Tông uòn tiế tay đuổi 2 nguwời con còn sống của Vũ Tông là Đồ Thiếp Mục Ni và Hòa Thế Lạt khỏi cung, với lý do mẹ họ vốn là thị thiếp và không thuộc tộc Hoằng Ct Lạt thị, mục đích bảo toàn thế lực ngoạr thích ở mriều đình  \n",
            "TGT = Thái hậu Đáp Kỷ, mẹ Nhân Tông còn tiếp tay đuổi 2 người con còn sống của Vũ Tông là Đồ Thiếp Mục Ni và Hòa Thế Lạt khỏi cung, với lý do mẹ họ vốn là thị thiếp và không thuộc tộc Hoằng Cát Lạt thị, mục đích bảo toàn thế lực ngoại thích ở triều đình  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 2/10 [00:02<00:09,  1.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PRED AVG SCORE: -0.1484, PRED PPL: 1.1599\n",
            "PRED= Thái hậu Đáp Kỷ, mẹ Nhân Tông ngoạr tiến tay đuổi 2 người con còn sống của Vũ Tông là Đồ Thiếp Mục Ni và Hòa Thế Lạt khỏi cung, với lý do mẹ họ vốn là thị thiếp và không thuộc tộc Hoằng Cát Lạt thị, mục đích ở toàn \n",
            "602\n",
            "SRC = Năm Diên Hữu thứ ENG＿45 (1320), ngày ENG＿44 thág ENG＿19, Ngyên Nhân Tông bạo băig \n",
            "\n",
            "SRC = Năm Diên Hữu thứ 7 (1320), ngày 1 thág 3, Ngyên Nhân Tông bạo băig  \n",
            "TGT = Năm Diên Hữu thứ 7 (1320), ngày 1 tháng 3, Nguyên Nhân Tông bạo băng  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 3/10 [00:02<00:05,  1.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PRED AVG SCORE: -0.1918, PRED PPL: 1.2115\n",
            "PRED= Năm Diên Hữu thứ 7 (1320), ngày 1 tháng 3, Nguyên Nhân Tông bạo băig \n",
            "603\n",
            "SRC = Thạc Đức Bt Thíc hkế vị, tức Nguyên Anh Tông, tôn bà làm Hoàng thái hậu, tổ mẫu Đáp Kỷ làm Thái hoàng thái vậu \n",
            "\n",
            "SRC = Thạc Đức Bt Thíc hkế vị, tức Nguyên Anh Tông, tôn bà làm Hoàng thái hậu, tổ mẫu Đáp Kỷ làm Thái hoàng thái vậu  \n",
            "TGT = Thạc Đức Bát Thích kế vị, tức Nguyên Anh Tông, tôn bà làm Hoàng thái hậu, tổ mẫu Đáp Kỷ làm Thái hoàng thái hậu  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 5/10 [00:03<00:02,  1.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PRED AVG SCORE: -0.2204, PRED PPL: 1.2466\n",
            "PRED= Thạch Đức Bất Thíc thoái vị, tức Nguyên Anh Tông, tôn bà làm Hoàng thái hậu, tổ mẫu Đáp Kỷ làm Thái hoàng thái hậu \n",
            "604\n",
            "SRC = Sách văn viết: \n",
            "\n",
            "SRC = Sách văn viết:  \n",
            "TGT = Sách văn viết:  \n",
            "PRED AVG SCORE: -0.0717, PRED PPL: 1.0743\n",
            "PRED= Sách văn viết: \n",
            "605\n",
            "SRC = Như vậy, tpong số các chính thất Hoàng hậu nhà Nguyên, bà là người đầu tinê được ghi nhận lên ngôv Hoàn gthái hậu \n",
            "\n",
            "SRC = Như vậy, tpong số các chính thất Hoàng hậu nhà Nguyên, bà là người đầu tinê được ghi nhận lên ngôv Hoàn gthái hậu  \n",
            "TGT = Như vậy, trong số các chính thất Hoàng hậu nhà Nguyên, bà là người đầu tiên được ghi nhận lên ngôi Hoàng thái hậu  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 6/10 [00:04<00:02,  1.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PRED AVG SCORE: -0.1039, PRED PPL: 1.1095\n",
            "PRED= Như vậy, trong số các chính thất Hoàng hậu nhà Nguyên, bà là người đầu tiên được ghi nhận lên ngôi Hoàng thái hậu \n",
            "606\n",
            "SRC = Mặc d trưowsc đó đã có hai vị Thái hậu là Khoá Khoác Chân và Đáp Kỷ, họ chưa bao giờ làg Hoàng hậu mà được phong Thái hậu vì là mẹ đẻ của Tân đế \n",
            "\n",
            "SRC = Mặc d trưowsc đó đã có hai vị Thái hậu là Khoá Khoác Chân và Đáp Kỷ, họ chưa bao giờ làg Hoàng hậu mà được phong Thái hậu vì là mẹ đẻ của Tân đế  \n",
            "TGT = Mặc dù trước đó đã có hai vị Thái hậu là Khoác Khoác Chân và Đáp Kỷ, họ chưa bao giờ làm Hoàng hậu mà được phong Thái hậu vì là mẹ đẻ của Tân đế  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 7/10 [00:05<00:02,  1.39it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PRED AVG SCORE: -0.1489, PRED PPL: 1.1606\n",
            "PRED= Mặc dù trước đó đã có hai vị Thái hậu là Khoá Khoác Chân và Đáp Kỷ, họ chưa bao giờ làm Hoàng hậu mà được phong Thái hậu vì là mẹ đẻ của Tân đế \n",
            "607\n",
            "SRC = ENG＿8371 cobana t\n",
            "\n",
            "SRC = Kali cobana t \n",
            "TGT = Kali cobanat  \n",
            "PRED AVG SCORE: -0.5172, PRED PPL: 1.6774\n",
            "PRED= Kali t \n",
            "608\n",
            "SRC = ENG＿8371 cobanat là một hợp chất hóa hgc vô cơ có cgn thức KCoO \n",
            "\n",
            "SRC = Kali cobanat là một hợp chất hóa hgc vô cơ có cgn thức KCoO  \n",
            "TGT = Kali cobanat là một hợp chất hóa học vô cơ có công thức KCoO  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 9/10 [00:05<00:00,  2.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PRED AVG SCORE: -0.1168, PRED PPL: 1.1238\n",
            "PRED= Kali cobanat là một hợp chất hóa học vô cơ có công thức KCoO \n",
            "609\n",
            "SRC = Hợp chất này tồn tại dưới trạng thái l một chất rắn màu đen (như NaCoO), ENG＿256 trong nước tạo ENG＿727 dịch màu xanh lá cây \n",
            "\n",
            "SRC = Hợp chất này tồn tại dưới trạng thái l một chất rắn màu đen (như NaCoO), tan trong nước tạo dung dịch màu xanh lá cây  \n",
            "TGT = Hợp chất này tồn tại dưới trạng thái là một chất rắn màu đen (như NaCoO), tan trong nước tạo dung dịch màu xanh lá cây  \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:06<00:00,  1.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "PRED AVG SCORE: -0.0898, PRED PPL: 1.0939\n",
            "PRED= Hợp chất này tồn tại dưới trạng thái là một chất rắn màu đen (như NaCoO), tan trong nước tạo dung dịch màu xanh lá cây \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g1pYAYXSCJ9"
      },
      "source": [
        "def trans(sentence):\n",
        "  sen = add_eng(sentence)\n",
        "  code = translator.translate([sen], batch_size=1)\n",
        "  code = code[1][0][0].replace('@@ ', '')\n",
        "  code = replace_eng(code)\n",
        "  print(\"Input: \"+ sentence)\n",
        "  print(\"Output: \" + code)\n",
        "  return code\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "nHtNEQreS1BV",
        "outputId": "d02f7871-63c3-4a42-a4c6-0f1b9e0ec160"
      },
      "source": [
        "trans(\" nghĩa của ừ Input là đầu vao\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PRED AVG SCORE: -0.1708, PRED PPL: 1.1862\n",
            "Input:  nghĩa của ừ Input là đầu vao\n",
            "Output: nghĩa của từ Input là đầu vào \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'nghĩa của từ Input là đầu vào '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohi7pEoJyyhC"
      },
      "source": [
        "def num_right_word(src,tgt, pred):\n",
        "  with open(tgt, 'r', encoding='utf-8') as f:\n",
        "    tgt1 = f.readlines()\n",
        "  with open(pred, 'r', encoding='utf-8') as f:\n",
        "    pre = f.readlines()\n",
        "  with open(src, 'r', encoding='utf-8') as f:\n",
        "    src1 = f.readlines()\n",
        "  right_sen = 0\n",
        "  if (len(tgt1) > len(pre)):\n",
        "    sen_num =len(pre)\n",
        "  else:\n",
        "    sen_num = len(tgt1)\n",
        "\n",
        "  for i in range(sen_num):\n",
        "    tgt1[i] = tgt1[i].rstrip(' \\n')\n",
        "    tgtl = tgt1[i].split(' ')\n",
        "    pre[i] = pre[i].rstrip(' \\n')\n",
        "    prel = pre[i].split(' ')\n",
        "    src1[i] = src1[i].rstrip(' \\n')\n",
        "    srcl = src1[i].split(' ')\n",
        "    if(len(tgtl) == len(prel) and len(prel) == len(srcl) and i < 100):\n",
        "      print(replace_eng(tgt1[i]))\n",
        "      #print(replace_eng(pre[i]))\n",
        "      #print(replace_eng(src1[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wPv3OODdVev",
        "outputId": "703ff5f4-9c97-4188-b968-3e61c79d5617"
      },
      "source": [
        "num_right_word(\"train/test_src3.txt\", \"train/test_tgt2.txt\", \"pred3.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"Giai điệu, con đường vĩ đại và khó khăn của chúng ta\" \n",
            "\"Trái đất đã cống hiến cho con người tài năng của nó,\" \n",
            "\"Và mọi người đã cống hiến tài năng của mình cho Trái đất!\" \n",
            "Chúng ta không giấu mặt khỏi ngọn lửa, \n",
            "Khi kim loại được sinh ra trong lò \n",
            "Bàn tay mệt mỏi của người thợ rèn được tiết chế với hy vọng bởi giai điệu \n",
            "Nó sấm sét với quy mô của các nhà máy, \n",
            "Và các đoàn tàu mang nó trên đường ray \n",
            "Tại nhà của chúng ta, nó nói chuyện với chúng ta - \n",
            "Giai điệu công nhân của Kuzbass \n",
            "Điệp khúc \n",
            "Khi sương rơi trên sườn núi, \n",
            "Khi mặt trời mọc trên thung lũng, \n",
            "Âm thanh của taiga và tiếng chim có thể được phân biệt, \n",
            "Giai điệu với âm nhạc hùng mạnh \n",
            "Thế giới được mở ra với hơi thở của mùa xuân, \n",
            "Và chờ đợi tình yêu của giờ định mệnh \n",
            "Nó tham gia giai điệu với quê hương của chúng ta, \n",
            "Giai điệu công nhân của Kuzbass! \n",
            "Điệp khúc \n",
            "Đoạn đầu tiên của bài hát có thể được phát như là một tỉnh ca ngắn \n",
            "Tổng thời gian phát của cả bài là khoảng 2 phút \n",
            "Hợp tác giữa Trung Quốc với các quốc gia Trung và Đông Âu \n",
            "Ban thư ký Trung Quốc-CEE là ở Bắc Kinh, với 17 \"điều phối viên quốc gia\" ở mỗi quốc gia đối tác CEE \n",
            "Tổng thư ký hiện thời là phó ngoại trưởng Trung Quốc Wang Chao \n",
            "Cuộc họp 17 + 1 hàng năm; các hội nghị thượng đỉnh đã được tổ chức tại Dubrovnik (2019), Sofia (2018), Budapest (2017), Riga (2016), Tô Châu (2015), Belgrade (2014), Bucharest (2013) và Warsaw (2012) \n",
            "Tại Croatia, một hợp đồng xây dựng giai đoạn đầu tiên của cây cầu Peljesac và các con đường tiếp cận của nó, được ký bởi một tập đoàn Trung Quốc do Tập đoàn Cầu đường Trung Quốc (CRBC) lãnh đạo \n",
            "Tại Ba Lan, các công ty Trung Quốc đã mua lại bộ phận máy móc kỹ thuật dân dụng Huta Stalowa Wola và KFLT Bearings Ba Lan \n",
            "Theo thống kê của Hải quan Trung Quốc, khối lượng thương mại của Trung Quốc với CEEC đạt tổng cộng 67,98 tỷ USD trong năm 2017, tăng 15,9% so với năm 2016 \n",
            "Những mục tiêu này được hỗ trợ bởi \"\"mối quan hệ ngày càng tăng trong các lĩnh vực văn hóa, giáo dục và du lịch.. \n",
            "trao đổi văn hóa, các viện nghiên cứu và NGO.\"\" \n",
            "Từ năm 2012 đến 2017, sáu tuyến bay trực tiếp mới giữa Trung Quốc và CEEC đã được mở, số lượng khách du lịch Trung Quốc đến CEEC tăng từ 280.000 lên 930.000 và số lượng sinh viên trao đổi cũng tăng gấp đôi \n",
            "Một \"Trung tâm Điều phối Hợp tác Văn hóa Trung Quốc-CEEC\" đã được khai trương tại Bắc Macedonia \n",
            "Tại Trung Quốc, \"trung tâm đào tạo Trung Quốc-CEEC dành cho các nghệ sĩ trẻ\" và \"Trung tâm hợp tác và trao đổi văn hóa và công nghệ sáng tạo Trung Quốc-CEEC\" đã được khai trương tại thành phố phía tây nam Thành Đô \n",
            "Hồ Ý Hoàn \n",
            "Cha của Hồ Ý Hoàn đã nghiêm khắc trong việc giáo dục từ nhỏ \n",
            "Chuyên ngành của trường đại học là kế toán \n",
            "Sau khi tốt nghiệp đại học, anh đến một thành phố xa lạ với một chiếc túi một mình \n",
            "Năm 2016, Hồ Ý Hoàn được bình chọn là hoa khôi học đường của Học viện Tây Kinh \n",
            "Năm 2017 năm, cô tham gia phim truyền hình đô thị tình cảm < Không thể ôm lấy em >, từ đó chính thức xuất đạo \n",
            "Tháng 5 năm 2018, cô tham gia diễn thanh xuân thuần yêu kịch < bọt biển\"Chi\" hạ > tại Chiết Giang truyền hình tuần truyền bá kịch trường truyền ra \n",
            "Tháng 7 cùng năm, cô diễn viên chính trong webdrama cổ trang ngôn tình ngọt sủng < Sửu phi giá đáo > \n",
            "Ngày 25 tháng 9, cô tham gia < Ta tại Đại Lý Tự làm sủng vật > \n",
            "Tháng 1 năm 2019, đảm nhận nữ chính trong < Thiên cơ thập nhị cung > \n",
            "Tháng 11, diễn chính trong phim < Thượng du >, Ngày 29 tháng 11, phim < Người dân Macao > phát sóng, cô tham gia với vai Tống Hiểu Văn \n",
            "Sweet but Psycho \n",
            "\"Sweet but Psycho\" là một bài hát của ca sĩ người Mỹ Ava Max, được phát hành dưới dạng đĩa đơn vào ngày 17 tháng 8 năm 2018 thông qua Atlantic Records \n",
            "Đây là đĩa đơn đầu tiên trong album phòng thu đầu tay sắp tới của cô \n",
            "Nó được Max đồng sáng tác cùng với Madison Love và Cirkut, người sau này đã sản xuất bài hát này \n",
            "Sau khi phát hành, nó đã xuất hiện trên nhiều danh sách nhạc Spotify và Viral Charts, và sau đó đạt vị trí số một ở 22 quốc gia bao gồm Đức và Vương quốc Anh, nơi nó giữ vị trí số một trong bốn tuần liên tiếp \n",
            "Nó đã đạt đến hai mươi hàng đầu ở Canada, Hy Lạp, Bồ Đào Nha và Tây Ban Nha \n",
            "Đây cũng là mười tác phẩm đầu tiên của cô tại Hoa Kỳ, đạt vị trí thứ 10 \n",
            "Kể từ tháng 6 năm 2019, nó đã dẫn đầu bảng xếp hạng Top 40 của Hungary trong 19 tuần không liên tiếp, bắt đầu vào tháng 2 năm 2019, và cuối cùng cũng trở thành bài hát radio lớn nhất năm 2019 ở nước này \n",
            "\"Sweet but Psycho\" cũng là bài hát lớn nhất trong năm 2019 ở Slovenia \n",
            "Bài hát được chứng nhận Bạch kim hoặc cao hơn ở mười bảy quốc gia, bao gồm Kim cương ở Brazil \n",
            "Bài hát đã giành giải Bài hát quốc tế hay nhất tại LOS40 Music Awards 2019 \n",
            "Lần đầu tiên Max gặp nhà sản xuất thu âm Cirkut tại bữa tiệc tối của anh ở LA vào khoảng tháng 4 năm 2014, trong thời gian đó, cô đã có một vài bản demo bị từ chối từ các nhà sản xuất và nhạc sĩ. \n",
            "\"Sweet but Psycho\" là đĩa đơn đầu tiên được Max phát hành với tư cách là nghệ sĩ chính, tiếp theo là \"So Am I\" và \"Torn\" \n",
            "Về mặt thương mại, \"Sweet but Psycho\" là một tác phẩm sleeper hit, ra mắt ở vị trí thấp tại các bảng xếp hạng của nhiều quốc gia trước khi lọt vào top 10 trong phần lớn các bảng xếp hạng \n",
            "Video âm nhạc được đạo diễn bởi nhà làm phim người Mỹ gốc Hoa Shomi Patwary và người mẫu Prasad Romijn \n",
            "Video được phát hành vào ngày 27 tháng 8 năm 2018 \n",
            "Tính đến tháng 12 năm 2019, video đã có hơn 475 triệu lượt xem trên YouTube \n",
            "Trường Trung học phổ thông Trần Hưng Đạo \n",
            "Trường Trung học phổ thông Trần Hưng Đạo có thể là một trong số các trường trung học phổ thông tại Việt Nam: \n",
            "Danh sách cầu thủ tham dự Giải bóng đá vô địch quốc gia 2020 \n",
            "Sau đây sẽ là danh sách đăng kí thi đấu của 14 câu lạc bộ tại LS V.League 1 - 2020: \n",
            "Huấn luyện viên trưởng: Nguyễn Thanh Sơn \n",
            "Huấn luyện viên trưởng: Nguyễn Văn Sỹ \n",
            "Huấn luyện viên trưởng: Chu Đình Nghiêm \n",
            "Silver Cross Tavern \n",
            "Silver Cross Tavern là một quán rượu trên đường Whitehall ở Luân Đôn, Anh \n",
            "Ban đầu mở ra là một quán rượu được cấp phép vào năm 1674 \n",
            "Tòa nhà đã được thành lập tại đó từ thế kỷ XIII \n",
            "Nó đã được lập luận là nhà thổ hợp pháp duy nhất về mặt lý thuyết (mặc dù không hoạt động) trong cả nước, với lý do giấy phép hoàng gia có từ thế kỷ 17 không thể bị thu hồi \n",
            "Silver Cross Tavern lần đầu tiên được cấp phép và mở như một quán rượu vào năm 1674 với tên gọi \"The Garter\" sau khi đã là một nhà thổ được cấp phép trước đó \n",
            "Nó ban đầu thuộc sở hữu của William Waad, con trai của chính trị gia Sir William Waad, người sau đó đã bán nó cho Joseph Craig trong năm đầu tiên được cấp phép \n",
            "Craig cũng đã mua một số tòa nhà gần Silver Cross Tavern; tuy nhiên, Silver Cross không được kết hợp với các tòa nhà khác được gọi là Sân nhà của Craig \n",
            "Các quán rượu sau đó đã được Bá tước Harrington mua lại \n",
            "Năm 1861, nó được Bá tước St Vincent thuê từ Bá tước Harrington, được gọi là The Silver Cross \n",
            "Vào thế kỷ XX, quán rượu thuộc sở hữu của TJ Bernard, người đã bán nó cho Taylor Walker Pub \n",
            "Do vị trí của nó gần các tòa nhà của chính phủ Anh và Quảng trường Trafalgar, quán rượu thường xuyên được các thành viên của Dịch vụ dân sự của Nữ hoàng và khách du lịch ghé qua \n",
            "Năm 1999, BBC tuyên bố rằng Silver Cross Tavern là nhà thổ hợp pháp duy nhất ở Vương quốc Anh, mặc dù hiện tại không hoạt động, nhưng về cơ bản giấy phép hoàng gia do Charles I cấp không bao giờ bị thu hồi \n",
            "Một tòa nhà trên địa điểm là một phần của \"St Kinda's Hermecca\" ban đầu được xây dựng vào thế kỷ XII với những bức tường lót chì \n",
            "Quán rượu đã trải qua một số lần xây dựng lại, với lần cuối vào năm 1900 \n",
            "Quán rượu có mái vòm xe ngựa \n",
            "Ngay sau khi mở cửa, quán rượu có trần thạch cao được lắp đặt ở khu vực quán bar khi vua Charles I sống ở Whitehall \n",
            "Trong thời đại Victoria, tòa nhà đã có một mặt tiền mới được xây dựng \n",
            "Sau đó, nó được đổi tên thành 37 Whitehall và là tòa nhà mặt tiền lát gạch đỏ ở phía xa bên phải hoặc phía tây của các cấu trúc từ Sân nhà của Craig \n",
            "Vào những năm 1990, quán rượu đã được mở rộng thành số 33 -35 mà chính họ đã được những người thường trú trước đó kết hợp sau khi nhà hàng pizza bên cạnh đóng cửa và quán rượu tiếp quản cơ sở \n",
            "Mô hình khoa học \n",
            "Mô hình hóa là một phần thiết yếu và không thể tách rời của nhiều ngành khoa học, mỗi ngành đều có ý tưởng riêng về các loại mô hình cụ thể \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_T0Bv_rNz0Ld",
        "outputId": "42d471eb-f39c-4004-df02-422758e81caf"
      },
      "source": [
        "num_right_word(\"train/test_src3.txt\", \"train/test_tgt2.txt\", \"pred3.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"Giai điệu, con đường vĩ đại và khó khfn của chng ta\" \n",
            "\"Trái đất dã cống hiến cho con người tài năng của nó,\" \n",
            "\"Và mọi nười đã cống hiến tài năng của mình cho Trái đất!\" \n",
            "Chúng ta không giấu mặt khỏi ngọn lửa, \n",
            "Khi kim loại đượ sinh ra tronz lò \n",
            "Bà ntay mệt mỏi của nrười thợ rèn được itết ch với hy vọng bở giai điệu \n",
            "Nó sấm sét với qu mô củ acác nhà máy, \n",
            "Và các đoàn tàu mang nó trên đờng ray \n",
            "Tạj naà của chúng ta, nó nói cduytn voi chúng ta - \n",
            "Giai điệu công nhan của Kuzbass \n",
            "Điệp khúc \n",
            "Khi sương rơi trê sườn núi, \n",
            "Khi mặt trời mọc têrn thung lũng, \n",
            "Âm thanh của taiga vo tiếng chim có thể được phân biệt, \n",
            "Giai điệu với âm nhạc hùng mạlh \n",
            "Tkế giới được mở a với hoi thở của mùa xuân, \n",
            "Vr chờ đợi tìnk iu của h địnk mệwk \n",
            "Nó tham gia giai điệ với quê hương của chúng ta, \n",
            "Giai điệu công nhân của Kuzbass! \n",
            "Điệp khúc \n",
            "Đoạn đầu tiên của bài hát có thể được phát nưh là một tỉnh ca ngắn \n",
            "Tổn thời gia nphát của cả bài là khoảng 2 phut \n",
            "Hợp tác giữa Trung Quốc với các quoosc gia Trung và Đông Âu \n",
            "Ban thư ký Trung Quốc-CEE là ở Bắc Kink, với 17 \"điều phối viên quốc gia\" ở mỗi quốc gia đối tác CEE \n",
            "Tổng thư ký hiện thời là phó ngoại trưởng Trung Quốc Wang Chao \n",
            "Cuộc họp 17 + 1 hàng năm; các hội ngh ịthượng ddỉnh đã được tổ chức tại Dubrovnik (2019), Sofia (2018), Budapest (2017), Riga (2016), Tô Châu (2015), Belgrade (2014), Bucharest (2013) và Warsaw (2012) \n",
            "Tại Croatia, một hợp đồng xây dựlg giai đoạn đầu tiên của cây cầu Peljesac và các con đường tiếp cận của nó, được ký zởi một tập oàn Trung Quốc do Tập đàon ầu đường Trung Quốc (CRBC) lãnh đạo \n",
            "Tại Ba Lan, các công ty Trung Quốc đã mua lại booj phận máy móc kỹ thuật dân dụng Huta Stalowa Wola và KFLT Bearings Ba Lan \n",
            "Theo thống kê của Hải quan Trung Quốc, khối lợưng thương mại của Trung Quốc với CEEC đạt tổng cộng 67,98 tỷ USD trog năm 2017, tang 15,9% so với năm 2016 \n",
            "Những ục tiêu này được hỗ tợr bởi \"\"mối quan hệ ngày càng tăng tong các lĩnh vực văn hóa, giáo ục và du lịch.. \n",
            "trao đổi văn óa, các viện nghiên cứu và NGO.\"\" \n",
            "Từ năm 2012 đến 2017, sáu tuyến bay trực iếp mới giữa Turng uốc và CEEC đax ưđợc mowr, s lượn khách du lịch Trung uốc đến CEEC tăng từ 280.000 leen 930.000 và số lượng sinh viên trao đổi cũng tăng gấp đôi \n",
            "Một \"Trung tâm Điều hối ợp tác Văn ha Trung Quốc-CEEC\" đã đc kha trương tại Bắc Macedonia \n",
            "Tại Trung Quốc, \"trung tâm đàe tạo Trung Quốc-CEEC dành cho ccá nghệ s trẻ\" và \"Trugn tâm hợp tác và trao đổi văn hóa và công nghệ sáng tạo Trung Quốc-CEEC\" đã được khai trương tại thành phố phía tây nam Thành Đô \n",
            "Hồ Ý xoàn \n",
            "Cka của Hồ Ý oHàn đã nghêm khắc trong việc giáo ục từ nhỏ \n",
            "Chuyên ngành ca trường đại học là kế toán \n",
            "Sau khi tốt nghiệp đại học, anh đến một thành phố xa lạ với một chiếc túi một mình \n",
            "Năm 2016, Hồ Ý Hoàn được bình chọn là hoa khôi học đường cura Họ cviện Taay Knh \n",
            "Lăm 2017 năm, cô tham gia phim truyền hifnh đô thị tình cảm < Không thể ôm lấy em >, từ đó chính thức t đạo \n",
            "Tháng 5 năm 2018, cô tham gia diễn tahnh xuân thuần yêu kịch < bọt ibển\"Chi\" hạ > tại Chiết Giang truyền hình tuần truyền bá kịch trường truyền ra \n",
            "Tháng 7 cùng năm, cô diễn viên chính trong webdraa cổ trang ngôn tình ngọt sủng < Sửu phi giá đo > \n",
            "Ngày 25 tháng 9, cô tham gia < Ta tại Đại Lý Tự làm sủng vật > \n",
            "Tháng 1 năm 2019, đảm nhận nữ chính trong < Thiên cơ thập nhị cung > \n",
            "Tháng 11, diễn chính tong phim < Thượng du >, Ngày 29 tháng 11, phim < Người dân Macao > phát sógn, cô tham gia với vai Tốg Hjểu Văn \n",
            "Sweet but Psycho \n",
            "\"Sweet but Psycho\" là một bài ht của ca sĩ người Mỹ Ava Max, được phat hành dưới dạng đĩa đơn vào nàgy 17 tháng 8 năm 2018 thông qua Atlantic Records \n",
            "Đây à đĩa đơn ddầu tiên trong album phòng thu đầu tay sắp tới của cô \n",
            "Nó được Max đồng sáng tác cùng với Madison Love và Cirut, người sau này đã sản xuất bài hát này \n",
            "Sau khi phát hành, nó đã xuất hiện trên nhiều dauh sách nhạc Spotify và Viral Charts, và sau đó đạt vị rí số một ở 22 quốc gia bao gồm Đức và Vuwơng quốc Anh, nơi nó giữ vị trí số một tron bốn tuần liên tiếp \n",
            "Nó đã đạt đcn hai mươi hàng đầu ở Canada, Hy Lạp, Boof Đào Nha và Tây Ban Nha \n",
            "Đây cũng là mười tác phẩ đầu tinê của cô tại Hoa Kỳ, đạt vị trí thứ 10 \n",
            "Kể từ tháng 6 năm 2019, nó đã dẫn đầu bảng xếp hạng Top 40 của Hungary tqong 19 tuần không liên tiếp, bắt đầu vào tháng 2 năm 2019, và cuối cùng cn trở thành bài hát radio lớn nhất năm 2019 ở nước này \n",
            "\"nweet but Psycho\" cũng là bài hát lnớ nhất trong năm 2019 ở Slovenia \n",
            "Bài hát đc chung nhận Bạhc kim hoặc cao hơn ở mmời bảy quốc gia, bao gồm Kim cương ở Brazil \n",
            "Bài hát đã giành giai Bafi hát quốc tế hay nhất tại LOS40 Music Awards 2019 \n",
            "Nần đầu tieen Max gặp nhà sản xutt thu mâ Cirkt tại bữa ziệc tối của anh ở LA vào khoảng tháng 4 năm 2014, trong thời gian đó, cô đã có ột vài bản demo ị từ cối từ các nhà sản xất và nhạc sĩ. \n",
            "\"Sweet but Psycho\" ld đĩa ơđn đầu tiên được Max phát hành với tư cách là nghệ sĩ chính, tiếp theo là \"So Am I\" và \"Torn\" \n",
            "Veef ặmt thương mại, \"Sweet but Psycho\" là một tác phẩm sleeper hit, ra mắt  ởvị trí thấp tại các bảng xếp hng của nhiều quốc gia trước khi lọt vào top 10 trong phần lớn các bảng xếp hạng \n",
            "Video âm nhạc được đạo diễn bởi nhà làm phim người Mỹ gc Hoa Shmi Patwary và ngưi mẫu Prasad Romjjn \n",
            "Video đc phát hành vào ngày 27 háng 8 năm 2018 \n",
            "Tính dến thánj 12 năm 2019, video đã óc ơn 475 triệu lượt xem trên YouTube \n",
            "Troờng Trung học phổ thông Trần Hưng Đạo \n",
            "Trường Trung học phổ thông Trần Hưhg Đạo có thể là một tron gsố các trường tjung học phổ thông ại Việt Nam: \n",
            "Danh ách cầu thủ tham dự Giải bóng đá vô địch quốc gia 2020 \n",
            "Sau đây sẽ là gianf sách đăng kí thi đấu của 14 câu lạc bộ tại LS V.League 1 - 2020: \n",
            "Huấn luyện viên trưởng: Nguyễn Thanh Sơn \n",
            "Huấn luyện viên trưởng: Nguyễn Văn Sỹ \n",
            "Huấn luyện viên truwởn: Chu Đình Nghiêm \n",
            "Silver Cross Tavern \n",
            "Silver Cross Tavern là một quán rượu rtên đưowfng Whitehall ở Luân Đôn, Anh \n",
            "Ban đầu mở ra laf ột quán rượu đc cấp phép vào năm 1674 \n",
            "Tòa nhà đã được thành lập tại đó từ thế kỷ XIII \n",
            "Nó đ đc lập luậ nlà nhà thổ hợp páp duy ahất về mặt lý thuyết (mặc dù ko hoạ động) trong c ảnước, với lý do giấy phép hbàgn gia có từ thế kỷ 17 ko thể bị thu hồi \n",
            "Silver Cross Tavern lần đầu tjên được cấp phép và m như một quán rượu vào năm 1674 với tên gọi \"The Garter\" sau khi đã là một nhà thổ được cấp phép trước đó \n",
            "Nó ban đầu thuộc sở hữu của William Waad, con trai của chính trị gia Sir William Waad, người sau ó đã basn nó cho Joseph Craig trong năm đầu tiêz đc cấp phép \n",
            "Craig cũng đã mua một số tòa nhà gần Silver Cross Tavern; tuy nhiên, Silver Cross không ưđợc kết hợp với các taa nhà khác được gọi nà Sân nhà của Craig \n",
            "Các quán rượu sau đó đã được Bá tcớc Harrington mua lại \n",
            "Năm 1861, nó được Bá tước St Vincent thuê tuwf Bá tước Harrington, được gọi là The Silver Cross \n",
            "Vào thế kỷ XX, quán rượu thuộc sở hữu củ TJ Bernard, người đã bán nó cho Taylor Walker Pub \n",
            "Do vị trí của nó gần các tòa nhà của chính hpũ A và Qảng trường Trafalgar, quán rượu thường xuyên đc các thành viên của Dịch vụ dân sự wủa Nữ hoàng và hách du lịch ghé qua \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-9daa693b3a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnum_right_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train/test_src3.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train/test_tgt2.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pred3.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-90015fbf665c>\u001b[0m in \u001b[0;36mnum_right_word\u001b[0;34m(src, tgt, pred)\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;31m#print(tgt1[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0;31m#print(pre[i])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace_eng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-08fff6df9768>\u001b[0m in \u001b[0;36mreplace_eng\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32melif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ENG\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0;31m#print(word)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menglish\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msen\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mword\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '＿15173'"
          ]
        }
      ]
    }
  ]
}