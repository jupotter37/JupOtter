{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataset and basic analysis and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real news:  (21417, 4)\n",
      "Fake News:  (23481, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Read the real news dataset\n",
    "real = pd.read_csv(\"../Dataset/True.csv\")\n",
    "\n",
    "# Read the fake news dataset\n",
    "fake = pd.read_csv(\"../Dataset/Fake.csv\")\n",
    "\n",
    "# Shape of real news dataset\n",
    "print(\"Real news: \", real.shape)\n",
    "\n",
    "# Shape of fake news dataset\n",
    "print(\"Fake News: \", fake.shape)\n",
    "\n",
    "# Assigning a value of 0 for all real news data and placing it in the dataframe\n",
    "class0 = [0] * len(real)\n",
    "real.insert(4, \"class\", class0, True)\n",
    "\n",
    "# Assigning a value of 1 for all fake news data and placing it in the dataframe\n",
    "class1 = [1] * len(fake)\n",
    "fake.insert(4, \"class\", class1, True)\n",
    "\n",
    "# Concatenating fake news and real news into one total dataset\n",
    "total = pd.concat([real, fake])\n",
    "total = total.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19348</th>\n",
       "      <td>A North Korea nuclear test over the Pacific? L...</td>\n",
       "      <td>SEOUL/TOKYO (Reuters) - Detonating a nuclear-t...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>September 22, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7892</th>\n",
       "      <td>Trump Jr. Offers Up Revolting Praise Of Dad: ...</td>\n",
       "      <td>Don Trump Jr., the privileged, wealthy son of ...</td>\n",
       "      <td>News</td>\n",
       "      <td>February 24, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7976</th>\n",
       "      <td>It Begins: Supreme Court Rejects Racially Ger...</td>\n",
       "      <td>This the worst fear of Republicans, conservati...</td>\n",
       "      <td>News</td>\n",
       "      <td>February 20, 2016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12177</th>\n",
       "      <td>Mexico enshrines army's role in drug war with ...</td>\n",
       "      <td>MEXICO CITY (Reuters) - Mexico s Congress on F...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>December 15, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>Freeport Indonesia mine access road reopened a...</td>\n",
       "      <td>JAKARTA (Reuters) - The Indonesian unit of Fre...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>November 13, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "19348  A North Korea nuclear test over the Pacific? L...   \n",
       "7892    Trump Jr. Offers Up Revolting Praise Of Dad: ...   \n",
       "7976    It Begins: Supreme Court Rejects Racially Ger...   \n",
       "12177  Mexico enshrines army's role in drug war with ...   \n",
       "14999  Freeport Indonesia mine access road reopened a...   \n",
       "\n",
       "                                                    text    subject  \\\n",
       "19348  SEOUL/TOKYO (Reuters) - Detonating a nuclear-t...  worldnews   \n",
       "7892   Don Trump Jr., the privileged, wealthy son of ...       News   \n",
       "7976   This the worst fear of Republicans, conservati...       News   \n",
       "12177  MEXICO CITY (Reuters) - Mexico s Congress on F...  worldnews   \n",
       "14999  JAKARTA (Reuters) - The Indonesian unit of Fre...  worldnews   \n",
       "\n",
       "                      date  class  \n",
       "19348  September 22, 2017       0  \n",
       "7892     February 24, 2016      1  \n",
       "7976     February 20, 2016      1  \n",
       "12177   December 15, 2017       0  \n",
       "14999   November 13, 2017       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19348</th>\n",
       "      <td>A North Korea nuclear test over the Pacific? L...</td>\n",
       "      <td>0</td>\n",
       "      <td>SEOUL/TOKYO (Reuters) - Detonating a nuclear-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7892</th>\n",
       "      <td>Trump Jr. Offers Up Revolting Praise Of Dad: ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Don Trump Jr., the privileged, wealthy son of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7976</th>\n",
       "      <td>It Begins: Supreme Court Rejects Racially Ger...</td>\n",
       "      <td>1</td>\n",
       "      <td>This the worst fear of Republicans, conservati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12177</th>\n",
       "      <td>Mexico enshrines army's role in drug war with ...</td>\n",
       "      <td>0</td>\n",
       "      <td>MEXICO CITY (Reuters) - Mexico s Congress on F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>Freeport Indonesia mine access road reopened a...</td>\n",
       "      <td>0</td>\n",
       "      <td>JAKARTA (Reuters) - The Indonesian unit of Fre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  class  \\\n",
       "19348  A North Korea nuclear test over the Pacific? L...      0   \n",
       "7892    Trump Jr. Offers Up Revolting Praise Of Dad: ...      1   \n",
       "7976    It Begins: Supreme Court Rejects Racially Ger...      1   \n",
       "12177  Mexico enshrines army's role in drug war with ...      0   \n",
       "14999  Freeport Indonesia mine access road reopened a...      0   \n",
       "\n",
       "                                                    text  \n",
       "19348  SEOUL/TOKYO (Reuters) - Detonating a nuclear-t...  \n",
       "7892   Don Trump Jr., the privileged, wealthy son of ...  \n",
       "7976   This the worst fear of Republicans, conservati...  \n",
       "12177  MEXICO CITY (Reuters) - Mexico s Congress on F...  \n",
       "14999  JAKARTA (Reuters) - The Indonesian unit of Fre...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shifting class to the end\n",
    "col_to_move = total.pop('class')\n",
    "total['class'] = col_to_move\n",
    "\n",
    "#Extract only the values for title (input) and class (output)\n",
    "data = total[['title','class','text']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Length 80.11171989843646\n",
      "Min Length 8\n",
      "Max Length 286\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Character Length of Titles - Min, Mean, Max\n",
    "print('Mean Length', data['title'].apply(len).mean())\n",
    "print('Min Length', data['title'].apply(len).min())\n",
    "print('Max Length', data['title'].apply(len).max())\n",
    "\n",
    "#plotting the frequency of characters on a histogram\n",
    "import seaborn as sns\n",
    "\n",
    "x = data['title'].apply(len).plot.hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with more than 8000 characters: 1545\n"
     ]
    }
   ],
   "source": [
    "num_rows = (data['text'].str.len() > 3900).sum()\n",
    "print('Number of rows with more than 8000 characters:', num_rows)\n",
    "\n",
    "#Removing rows with more than 8000 characters\n",
    "data = data[data['text'].str.len() < 3900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~', \"'\", '\"']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>stop_words_before</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19348</th>\n",
       "      <td>a north korea nuclear test over the pacific lo...</td>\n",
       "      <td>0</td>\n",
       "      <td>[S, E, O, U, L, /, T, O, K, Y, O,  , (, R, e, ...</td>\n",
       "      <td>1679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7892</th>\n",
       "      <td>trump jr offers up revolting praise of dad ‘t...</td>\n",
       "      <td>1</td>\n",
       "      <td>[D, n,  , T, r, u, p,  , J, r, ., ,,  , h, e, ...</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7976</th>\n",
       "      <td>it begins supreme court rejects racially gerr...</td>\n",
       "      <td>1</td>\n",
       "      <td>[T, h,  , h, e,  , w, r,  , f, e, r,  , f,  , ...</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12177</th>\n",
       "      <td>mexico enshrines armys role in drug war with d...</td>\n",
       "      <td>0</td>\n",
       "      <td>[M, E, X, I, C, O,  , C, I, T, Y,  , (, R, e, ...</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>freeport indonesia mine access road reopened a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[J, A, K, A, R, T, A,  , (, R, e, u, e, r, ), ...</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  class  \\\n",
       "19348  a north korea nuclear test over the pacific lo...      0   \n",
       "7892    trump jr offers up revolting praise of dad ‘t...      1   \n",
       "7976    it begins supreme court rejects racially gerr...      1   \n",
       "12177  mexico enshrines armys role in drug war with d...      0   \n",
       "14999  freeport indonesia mine access road reopened a...      0   \n",
       "\n",
       "                                                    text  stop_words_before  \n",
       "19348  [S, E, O, U, L, /, T, O, K, Y, O,  , (, R, e, ...               1679  \n",
       "7892   [D, n,  , T, r, u, p,  , J, r, ., ,,  , h, e, ...               1062  \n",
       "7976   [T, h,  , h, e,  , w, r,  , f, e, r,  , f,  , ...                672  \n",
       "12177  [M, E, X, I, C, O,  , C, I, T, Y,  , (, R, e, ...                464  \n",
       "14999  [J, A, K, A, R, T, A,  , (, R, e, u, e, r, ), ...                171  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "#Lowercase letters\n",
    "data['title'] = data['title'].str.lower()\n",
    "data['text'] = data['text'].str.lower()\n",
    "data.head()\n",
    "\n",
    "\n",
    "#Ensure that all necessary punctuations are in one list\n",
    "#Include ' and \" as they are not default\n",
    "punc = list(string.punctuation)\n",
    "punc.append('\\'')\n",
    "punc.append('\"')\n",
    "print(punc)\n",
    "\n",
    "\n",
    "#Loop through dataframe and remove all punctuations\n",
    "def removePunc(text):\n",
    "    for i in string.punctuation:\n",
    "        text = text.replace(i, '')\n",
    "    return text\n",
    "\n",
    "# Apply to the DF series\n",
    "data['title'] = data['title'].apply(removePunc)\n",
    "data['text'] = data['text'].apply(removePunc)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del class0, class1, col_to_move, fake, real, total,x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import nltk preprocessing library to convert text into a readable format\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "#Tokenize the string (create a list -> each index is a word)\n",
    "#data['title'] = data.apply(lambda row: nltk.word_tokenize(row['title']), axis=1)\n",
    "#data['text'] = data.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)\n",
    "\n",
    "#Define text lemmatization model (eg: walks will be changed to walk)\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#Loop through title dataframe and lemmatize each word\n",
    "def lemma(data):\n",
    "  return [lemmatizer.lemmatize(w) for w in data]\n",
    "\n",
    "#Apply to dataframe\n",
    "data['title'] = data['title'].apply(lemma)\n",
    "data['text'] = data['text'].apply(lemma)\n",
    "\n",
    "#Define all stopwords in the English language (it, was, for, etc.)\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "#Remove them from our dataframe\n",
    "data['title'] = data['title'].apply(lambda x: [i for i in x if i not in stop])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the number of stop words in each text before the operation\n",
    "#data['stop_words_before'] = data['text'].apply(lambda x: len([i for i in x if i in stop]))\n",
    "\n",
    "# Apply the function to remove stop words\n",
    "data['text'] = data['text'].apply(lambda x: [i for i in x if i not in stop])\n",
    "\n",
    "# Calculate the number of stop words in each text after the operation\n",
    "#data['stop_words_after'] = data['text'].apply(lambda x: len([i for i in x if i in stop]))\n",
    "\n",
    "# Plot the number of stop words before and after the operation\n",
    "#data[['stop_words_before', 'stop_words_after']].plot(kind='bar', figsize=(12, 6))\n",
    "#plt.ylabel('Number of stop words')\n",
    "#plt.show()\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign training data and testing data\n",
    "titles = data['title']\n",
    "labels = data['class']\n",
    "OR direct assignment is done below\n",
    "title_train = X_train, title_test = X_test, y_train = y_train, y_test = y_test as per previous knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "#Split data into training and testing dataset\n",
    "title_train, title_test, y_train, y_test = train_test_split(data['title'], data['class'], test_size=0.2, random_state=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Download\n",
    "Run only once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "import tensorflow_hub as hub\n",
    "import requests\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "### Specify the URL of the model and the location to store it\n",
    "model_url = \"https://tfhub.dev/google/Wiki-words-250/2?tf-hub-format=compressed\"\n",
    "model_dir = \"./\"\n",
    "\n",
    "### Download the model\n",
    "response = requests.get(model_url, stream=True)\n",
    "response.raise_for_status()\n",
    "\n",
    "### Save the model to a .tar.gz file\n",
    "model_file = os.path.join(model_dir, \"model.tar.gz\")\n",
    "with open(model_file, \"wb\") as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "### Extract the model from the .tar.gz file\n",
    "with tarfile.open(model_file, \"r:gz\") as tar:\n",
    "    tar.extractall(path=model_dir)\n",
    "\n",
    "### Load the model from the local directory\n",
    "embed = hub.load(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35918, 100)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenizing sentences into words\n",
    "# title_train_tokenized = [word_tokenize(i) for i in title_train]\n",
    "\n",
    "# Training the Word2Vec model\n",
    "model = Word2Vec(sentences=title_train, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# To convert each word in a sentence to its word2vec embedding and average them:\n",
    "indiv = []\n",
    "for sentence in title_train:\n",
    "  sentence_embedding = np.mean([model.wv[word] for word in sentence if word in model.wv.key_to_index], axis=0)\n",
    "  indiv.append(sentence_embedding)\n",
    "\n",
    "# Preprocess the sequences to account for different lengths of words\n",
    "indiv = tf.keras.preprocessing.sequence.pad_sequences(indiv, dtype='float32', padding='post')\n",
    "\n",
    "print(indiv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "Eroors and solutions\n",
    "1.\n",
    "code: model.fit(indiv, y_train,validation_data=[title_test,y_test],epochs=10)\n",
    "issue : ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list).\n",
    "solution 1: \n",
    "The validation_data argument in model.fit() should be a tuple in the form (x_val, y_val), where x_val is the validation input data and y_val is the validation target data.\n",
    "\n",
    "Try changing your code to: model.fit(indiv, y_train, validation_data=(title_test, y_test), epochs=10)\n",
    "\n",
    "Before this line, ensure that title_test and y_test are Numpy arrays or TensorFlow tensors. You can convert a list to a Numpy array using numpy.array(). For example: \n",
    "import numpy as np\n",
    "\n",
    "title_test = np.array(title_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "solution implemented : Numpyarry input need to be converted to tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n",
      "c:\\Users\\johnd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(keras.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '’'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming title_train and title_test are lists of sentences where each sentence is a list of words\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Pad sequences for consistent length\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m title_train_padded \u001b[38;5;241m=\u001b[39m \u001b[43mpad_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m title_test_padded \u001b[38;5;241m=\u001b[39m pad_sequences(title_test)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Reshape the padded arrays\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\johnd\\Project\\Program\\LSTM\\sequence.py:116\u001b[0m, in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTruncating type \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtruncating\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not understood\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;66;03m# check `trunc` has expected shape\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m trunc \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trunc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m!=\u001b[39m sample_shape:\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of sample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrunc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of sequence at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is different from expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    121\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    122\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '’'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sequence import pad_sequences\n",
    "\n",
    "# Assuming title_train and title_test are lists of sentences where each sentence is a list of words\n",
    "# Pad sequences for consistent length\n",
    "title_train_padded = pad_sequences(title_train)\n",
    "title_test_padded = pad_sequences(title_test)\n",
    "\n",
    "# Reshape the padded arrays\n",
    "title_train_reshaped = np.reshape(title_train_padded, (title_train_padded.shape[0], -1))  # -1 infers the correct shape automatically\n",
    "title_test_reshaped = np.reshape(title_test_padded, (title_test_padded.shape[0], -1))\n",
    "\n",
    "# Convert the reshaped arrays to Tensor arrays\n",
    "title_train_tensor = tf.convert_to_tensor(title_train_reshaped, dtype=tf.float32)\n",
    "title_test_tensor = tf.convert_to_tensor(title_test_reshaped, dtype=tf.float32)\n",
    "\n",
    "# Assuming y_train and y_test are already defined and are numpy arrays\n",
    "y_train_tensor = tf.convert_to_tensor(y_train, dtype=tf.float32)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m model \u001b[38;5;241m=\u001b[39m compile_model(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Converting input data to Tensor array\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m title_train_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtitle_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m title_test_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(title_train, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     69\u001b[0m y_train_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconvert_to_tensor(y_train, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mc:\\Users\\johnd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\johnd\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def compile_model(learning_rate):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.LSTM(50, return_sequences=True, dropout=0.2))\n",
    "    model.add(tf.keras.layers.LSTM(50, dropout=0.2))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dense(40, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(10, activation='relu'))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, indiv, y_train, title_test, y_test, epochs, learning_rate, batch_size):\n",
    "    try:\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                      loss=\"binary_crossentropy\",\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        early_stopping = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "        history = model.fit(indiv, y_train, validation_data=(title_test, y_test), epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "        return history\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred during training: {e}\")\n",
    "        return None\n",
    "\n",
    "def plot_metrics(history):\n",
    "    if history is not None:\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title('Model accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('Model loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Cannot plot metrics as history is None.\")\n",
    "\n",
    "# Sequential model has a 50 cell LSTM layer before Dense layers\n",
    "model = compile_model(learning_rate=1e-3)\n",
    "\n",
    "# Converting input data to Tensor array\n",
    "title_train_tensor = tf.convert_to_tensor(title_train)\n",
    "title_test_tensor = tf.convert_to_tensor(title_test)\n",
    "y_train_tensor = tf.convert_to_tensor(y_train)\n",
    "y_test_tensor = tf.convert_to_tensor(y_test)\n",
    "\n",
    "# Train model on 10 epochs / \n",
    "history = train_model(model, title_train_tensor, y_train_tensor, title_test_tensor, y_test_tensor, epochs=10, learning_rate=1e-3, batch_size=32)\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plot_metrics(history)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
