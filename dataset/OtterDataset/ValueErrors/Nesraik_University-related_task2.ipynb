{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify import NaiveBayesClassifier, accuracy\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from string import punctuation\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import spacy\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadingDataset():\n",
    "    data = pd.read_csv('Movie Dataset.csv').sample(n=1000)\n",
    "    data.dropna(inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_stop_words = stopwords.words('english')\n",
    "symbol = punctuation\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(tag):\n",
    "    if tag == 'jj':\n",
    "        return 'a'\n",
    "    elif tag in ['nn','rb','vb']:\n",
    "        return tag[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizing(word_list):\n",
    "    lemmatized_list = []\n",
    "    tagging = pos_tag(word_list)\n",
    "    for word, tag in tagging:\n",
    "        label = get_label(tag)\n",
    "        if label!=None:\n",
    "            lemmatized_list.append(lemmatizer.lemmatize(word,label))\n",
    "        else:\n",
    "            lemmatized_list.append(lemmatizer.lemmatize(word))\n",
    "    return lemmatized_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessed_text(data): \n",
    "    reviews = data['review'].to_list()\n",
    "    sentiments = data['sentimentScore'].to_list()\n",
    "\n",
    "    word_list = []\n",
    "\n",
    "    for sentence in reviews:\n",
    "        words = word_tokenize(sentence)\n",
    "        for word in words:\n",
    "            word_list.append(word.lower())\n",
    "\n",
    "    word_list = [word.lower() for word in word_list if word not in eng_stop_words and word not in symbol and word.isalpha()]\n",
    "    word_list = lemmatizing(word_list)\n",
    "\n",
    "    feature_set = []\n",
    "\n",
    "    labeled_list = list(zip(reviews,sentiments))\n",
    "\n",
    "    for sentence, label in labeled_list:\n",
    "        words = []\n",
    "        words = word_tokenize(sentence)\n",
    "        words = [word.lower() for word in words if word not in eng_stop_words and word not in symbol and word.isalpha()]\n",
    "        words = lemmatizing(words)\n",
    "\n",
    "        feature = {}\n",
    "\n",
    "        for word in words:\n",
    "            feature[word] = (word in word_list)\n",
    "        feature_set.append((feature,label))\n",
    "\n",
    "    return feature_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling():\n",
    "    data = loadingDataset()\n",
    "    feature_set = preprocessed_text(data)\n",
    "    shuffle(feature_set)\n",
    "    count = int(0.8*len(feature_set))\n",
    "    train_data = feature_set[:count]\n",
    "    test_data = feature_set[count:]\n",
    "\n",
    "    model = NaiveBayesClassifier.train(train_data)\n",
    "    file = open('model.pickle','wb')\n",
    "    pickle.dump(model,file)\n",
    "    file.close()\n",
    "\n",
    "    print(model.show_most_informative_features(n=10))\n",
    "    print(accuracy(model,test_data))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkModel():\n",
    "    try:\n",
    "        file = open('model.pickle','rb')\n",
    "        model = pickle.load(file)\n",
    "        file.close()\n",
    "    except:\n",
    "        model = modelling()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writeReview(model):\n",
    "    while True:\n",
    "        review = input('Write your review: ')\n",
    "        reviews = word_tokenize(review)\n",
    "        if(len(reviews)>20):\n",
    "            break\n",
    "    category = model.classify(FreqDist(reviews))\n",
    "    return review, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movieRecommendation(data,user_review):\n",
    "    vectorizer = CountVectorizer(ngram_range=(1,3))\n",
    "    review = list(data['review'])\n",
    "    data_vec = vectorizer.fit_transform(review)\n",
    "    user_vec = vectorizer.transform([user_review])\n",
    "\n",
    "    similarity  = cosine_similarity(data_vec,user_vec).flatten()\n",
    "    top_indices = similarity.argsort()[-2:][::-1]\n",
    "    print(top_indices)\n",
    "    counter = 1\n",
    "    for index in top_indices:\n",
    "        print(f\"{counter}: {data.iloc[index]['title']}\")\n",
    "        counter+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NER(data):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "    category = {}\n",
    "\n",
    "    for review in data['review']:\n",
    "        doc = nlp(review)\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ not in category:\n",
    "                category[ent.label_] = []\n",
    "            category[ent.label_].append(ent.text)\n",
    "\n",
    "    for label, text in category.items():\n",
    "        if label == 'LANGUAGE' or label =='LOC':\n",
    "            print(f\"{label}: {', '.join(text)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOVIE RECOMMENDATION APPLICATION BASED ON REVIEWS\n",
      "YOUR REVIEW: NO REVIEW\n",
      "YOUR REVIEW CATEGORY: UNKNOWN\n",
      "1. WRITE YOUR REVIEW\n",
      "2. VIEW MOVIE RECOMMENDATION\n",
      "3. VIEW NAMED ENTITIES RECOGNITION\n",
      "4. EXIT\n",
      "MOVIE RECOMMENDATION APPLICATION BASED ON REVIEWS\n",
      "YOUR REVIEW: The performances, particularly by Michelle Yeoh, are stellar, driving home the film's emotional core amidst its kaleidoscopic visuals. It's a must-watch for fans of innovative storytelling.\n",
      "YOUR REVIEW CATEGORY: NEGATIVE\n",
      "1. WRITE YOUR REVIEW\n",
      "2. VIEW MOVIE RECOMMENDATION\n",
      "3. VIEW NAMED ENTITIES RECOGNITION\n",
      "4. EXIT\n",
      "[677  68]\n",
      "1: Ghost in the Shell\n",
      "2: Austin Powers: International Man of Mystery\n",
      "MOVIE RECOMMENDATION APPLICATION BASED ON REVIEWS\n",
      "YOUR REVIEW: The performances, particularly by Michelle Yeoh, are stellar, driving home the film's emotional core amidst its kaleidoscopic visuals. It's a must-watch for fans of innovative storytelling.\n",
      "YOUR REVIEW CATEGORY: NEGATIVE\n",
      "1. WRITE YOUR REVIEW\n",
      "2. VIEW MOVIE RECOMMENDATION\n",
      "3. VIEW NAMED ENTITIES RECOGNITION\n",
      "4. EXIT\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3. VIEW NAMED ENTITIES RECOGNITION\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m4. EXIT\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m option \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m>> \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m option \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     18\u001b[0m     user_review, category \u001b[38;5;241m=\u001b[39m writeReview(model)\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "user_review = 0\n",
    "category = 0\n",
    "\n",
    "model = checkModel()\n",
    "data = loadingDataset()\n",
    "\n",
    "while True:\n",
    "    print('MOVIE RECOMMENDATION APPLICATION BASED ON REVIEWS')\n",
    "    print(f\"YOUR REVIEW: {'NO REVIEW' if user_review == 0 else user_review}\")\n",
    "    print(f\"YOUR REVIEW CATEGORY: {'UNKNOWN' if category == 0 else category}\")\n",
    "    print('1. WRITE YOUR REVIEW')\n",
    "    print('2. VIEW MOVIE RECOMMENDATION')\n",
    "    print('3. VIEW NAMED ENTITIES RECOGNITION')\n",
    "    print('4. EXIT')\n",
    "    option = int(input('>> '))\n",
    "\n",
    "    if option == 1:\n",
    "        user_review, category = writeReview(model)\n",
    "    elif option == 2:\n",
    "        movieRecommendation(data,user_review)\n",
    "    elif option == 3:\n",
    "        NER(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Natural_Language_Processing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
