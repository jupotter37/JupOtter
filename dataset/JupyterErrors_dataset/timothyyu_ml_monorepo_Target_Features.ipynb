{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jianboxue/anaconda/lib/python2.7/site-packages/pandas/io/data.py:33: FutureWarning: \n",
      "The pandas.io.data module is moved to a separate package (pandas-datareader) and will be removed from pandas in a future version.\n",
      "After installing the pandas-datareader package (https://github.com/pydata/pandas-datareader), you can change the import ``from pandas.io import data, wb`` to ``from pandas_datareader import data, wb``.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib as ta\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('..')\n",
    "from Data.TimeSeries import *\n",
    "from ETF.AAA import *\n",
    "\n",
    "from Data import factors\n",
    "import Quandl\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "import cvxopt as opt\n",
    "from cvxopt import blas, solvers\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from Data.TimeSeries import *\n",
    "from Data.StockDataManager import  *\n",
    "\n",
    "\n",
    "tickers = ['GOOG/NYSE_SPY']\n",
    "\n",
    "settings = Settings()\n",
    "dp = TimeSeries(settings).get_ETF_data(tickers)\n",
    "\n",
    "df = dp[tickers[0]][['Open', 'High', 'Low', 'Close', 'volume']]\n",
    "df = df['2001-01-01'::].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_day_atr_return_distance(df, win=250):\n",
    "    delta_o = np.array(df['Open'].shift(-2) - df['Open'].shift(-1))\n",
    "    atr = ta.ATR(df['High'].values, df['Low'].values, df['Close'].values, win)\n",
    "    if win == 1:\n",
    "        v = delta_o\n",
    "    else :\n",
    "        v = delta_o / atr\n",
    "\n",
    "    ndard = pd.DataFrame(data=v, index=df.index, columns=['ndard'])\n",
    "    return ndard\n",
    "\n",
    "def subsequent_day_atr_return_distance(df, seq, win=250) :\n",
    "    n = next_day_atr_return_distance(df, win)\n",
    "    n_s = n.shift(-1*seq)\n",
    "    col_new = 'ndard_{s}'.format(s=seq)\n",
    "    n_s.columns = [col_new]\n",
    "    return n_s\n",
    "\n",
    "def next_month_atr_return_distance(df, win = 250):\n",
    "    df_o = df.copy()\n",
    "\n",
    "    ## get the first trading day of the month\n",
    "    b = df_o.index[0:(len(df_o)- 1)]\n",
    "    b = b.insert(0, df_o.index[0])\n",
    "    a = df_o.index\n",
    "\n",
    "    ## get the delta of opening price, between month(1) and month(2)\n",
    "    df_f_month = df_o.loc[a[a.month <> b.month]]\n",
    "    df_f_month['delta_o'] = np.array(df_f_month['Open'].shift(-1) - df_f_month['Open'])\n",
    "\n",
    "    df_o['delta_o'] = df_f_month['delta_o']\n",
    "    df_o = df_o.fillna(method='bfill')\n",
    "    df_o['delta_o'] = df_o['delta_o'].shift(-1)\n",
    "\n",
    "    ## get ATR in the window \n",
    "    df_o['atr'] = ta.ATR(df_o['High'].values, df_o['Low'].values, df_o['Close'].values, win)\n",
    "    if win == 1:\n",
    "        v = df_o['delta_o']\n",
    "    else :\n",
    "        v = df_o['delta_o'] / df_o['atr']\n",
    "\n",
    "    nmatd = pd.DataFrame(data=v, index=df_o.index, columns=['nmatd'])\n",
    "    return nmatd\n",
    "\n",
    "def hit_or_miss_up_down_cutoff_atr(df, up=2, down=5, cutoff = 40, atrdist=250):\n",
    "    list_up_down = []\n",
    "\n",
    "    price = df['Open']\n",
    "    for i in range(len(price)) :\n",
    "        if i > len(price) - cutoff - 1:\n",
    "            list_up_down.append(0)\n",
    "        else :   \n",
    "            price_co = price[(i+1):(i+1+cutoff)]\n",
    "            v_max = max(price_co)\n",
    "            v_min = min(price_co)\n",
    "\n",
    "            i_max = price_co.argmax()\n",
    "            i_min = price_co.argmin()\n",
    "\n",
    "            # check the upper bound\n",
    "            atr = df_o['atr'][i]\n",
    "            max_reach = 0\n",
    "            min_reach = 0\n",
    "\n",
    "            if (v_max - price_co[0]) > up * atr:\n",
    "                max_reach = 1\n",
    "            if (price_co[0] - v_min) > down * atr:\n",
    "                min_reach = 1\n",
    "\n",
    "            # normalize the returns with ATR\n",
    "            if math.isnan(atr) :\n",
    "                up_down = np.NAN\n",
    "            else:\n",
    "\n",
    "                if atr <> 0:\n",
    "                    up_down = (price_co[-1] - price_co[0]) / atr\n",
    "                else :\n",
    "                    up_down = price_co[-1] - price_co[0]\n",
    "\n",
    "\n",
    "                if max_reach == 1 and min_reach == 0:\n",
    "                    up_down = up\n",
    "                elif min_reach == 1 and max_reach == 0:\n",
    "                    up_down = -1 * down\n",
    "                elif max_reach == 1 and min_reach == 1:\n",
    "                    if i_max > i_min:\n",
    "                        up_down = up\n",
    "                    if i_max < i_min:\n",
    "                        up_down = -1*down\n",
    "    #             else :\n",
    "    #                 print \"max/min no reaches\"\n",
    "    #                 print \"max_reach={a}:min_reach={b}\".format(a=max_reach, b=min_reach)\n",
    "    #                 print \"price_0={a}:price_1={b}\".format(a=price_co[0], b=price_co[-1])\n",
    "    #                 print \"up_ratio = {a}\".format(a = (v_max - price_co[0])/atr)\n",
    "    #                 print \"down_ratio = {a}\".format(a = (price_co[0] - v_min)/atr)\n",
    "\n",
    "\n",
    "            list_up_down.append(up_down)\n",
    "    #         print \"max={max}:min={min}:price={price}:atr={atr}:hit={hit}\".format(\n",
    "    #                 max=v_max, min=v_min, price=price[i], atr=atr, hit=up_down\n",
    "    #             )\n",
    "    #         print \"---------------------------------------------------------------\"\n",
    "\n",
    "    hmatr = pd.DataFrame(data=list_up_down, index=df.index, columns=['hmatr'])\n",
    "    return hmatr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-day log return\n",
    "def log_return(df) :\n",
    "    df_price = np.log(df[['Close']])\n",
    "    l_ret = df_price - df_price.shift(1)\n",
    "    return pd.DataFrame(data=l_ret.values, index=df.index, columns=['logret'])\n",
    "\n",
    "# n-day close to close (log return)\n",
    "def close_to_close(df, histLen=5) :\n",
    "    df_price = df['Close']\n",
    "    return np.log(df_price / df_price.shift(histLen))\n",
    "\n",
    "# ATR\n",
    "def atr(df, atrLen = 10):\n",
    "    import talib as ta\n",
    "    l_atr = ta.ATR(df['High'].values, df['Low'].values, df['Close'].values, atrLen)\n",
    "    return pd.DataFrame(data=l_atr, index=df.index, columns=['atr_{n}'.format(n=atrLen)])\n",
    "\n",
    "# Moving Average \n",
    "def sma(df, maLen=10) :\n",
    "    if maLen == 1:\n",
    "        l_sma = df[['Close']].values\n",
    "    else:\n",
    "        l_sma = ta.SMA(df['Close'].values, maLen)\n",
    "    return pd.DataFrame(data=l_sma, index=df.index, columns=['ma_{n}'.format(n=maLen)])\n",
    "\n",
    "# Close - MovingAverage \n",
    "# Normlaized by Log ATR\n",
    "def close_ma_ATR_log(df, histLen = 5, atrLen = 30) :\n",
    "    df_price = df[['Close']]\n",
    "    df_ma = sma(df, histLen)\n",
    "    df_atr = atr(df,  atrLen)\n",
    "\n",
    "    v1 = np.log(df_price.values / df_ma.values) #/ np.sqrt(histLen) \n",
    "    v2 =  np.log(df_atr.values)\n",
    "    v = v1/v2\n",
    "    \n",
    "    return pd.DataFrame(data=v, index=df.index, columns=['cmatr_{n}_{m}'.format(n=histLen, m=atrLen)])\n",
    "\n",
    "# MA different, normalized by ATR\n",
    "# Params: ShortLen, LongLen, Lag\n",
    "# ShortLen - the lenght for the short MA\n",
    "# longLen - the length for the long MA\n",
    "# lag - the long MA will apply with a lag. If the lag >= shortLen, the long and the short MA \n",
    "# will by apply for the 2 separated windows\n",
    "# The delta of the 2 MAs will be normalized with the ATR with len = Lag + LongLength\n",
    "def ma_diff_ATR_log(df, shortLen = 5, longLen = 51, lag = 5) :\n",
    "    df_short_ma = sma(df, shortLen)\n",
    "    df_long_ma = sma(df, longLen).shift(lag)\n",
    "    df_atr = atr(df, longLen + lag)\n",
    "\n",
    "    delta = np.log(df_short_ma.values) - np.log(df_long_ma.values)\n",
    "\n",
    "    o = delta / np.log(df_atr.values)\n",
    "    return pd.DataFrame(data=o, index=df.index, columns=['mdatr'])\n",
    "\n",
    "def ma_diff_ATR(df, shortLen = 5, longLen = 51, lag = 5) :\n",
    "    df_short_ma = sma(df, shortLen)\n",
    "    df_long_ma = sma(df, longLen).shift(lag)\n",
    "    df_atr = atr(df, longLen + lag)\n",
    "\n",
    "    delta = df_short_ma.values - df_long_ma.values\n",
    "    o = delta / df_atr.values\n",
    "    return pd.DataFrame(data=o, index=df.index, columns=['mdatr'])\n",
    "\n",
    "'''\n",
    "# ABS Price Change Oscillator\n",
    "# Using the absolute log dialy price changes (abs daily log return ). \n",
    "# The short MA using shortLen, and the long MA using shortLen*multiplier.\n",
    "# the difference is normalized by ATR using \n",
    "'''\n",
    "shortLength = 5\n",
    "multiplier = 5\n",
    "df_abs_logret = np.abs(log_return(df).values)\n",
    "\n",
    "l_ma = ta.SMA(df_abs_logret.ravel(), shortLength)\n",
    "l_ma_long = ta.SMA(df_abs_logret.ravel(), shortLength * multiplier)\n",
    "delta = l_ma - l_ma_long\n",
    "l_atr = np.log(atr(df, shortLength*multiplier))\n",
    "a = atr(df, shortLength * multiplier)\n",
    "\n",
    "\n",
    "'''\n",
    "Line Per ATR\n",
    "calcuate the least-square deviation line of the data - using the \n",
    "mean(sum(high+low+open+close)) with the window. the slope of the line divided \n",
    "by the ATR.\n",
    "parameters\n",
    "- histLen - window for the slope estimation\n",
    "- atrLen - ATR window\n",
    "output:\n",
    "DataFrame containing two columns\n",
    "- 'lpatr' line slope adjusted by ATR\n",
    "- 'slope_predict' the next day predict using the line slope\n",
    "- 'delta_predict' the \n",
    "'''\n",
    "def line_per_atr(df, histLen = 50, atrLen = 200) :\n",
    "    l_mean = df[['Open', 'High','Low', 'Close']].mean(axis=1)\n",
    "    nr = len(l_mean)\n",
    "\n",
    "    l_slope = []\n",
    "    l_predict = []\n",
    "    l_delta = []\n",
    "    \n",
    "    # sklearn linear model\n",
    "    from sklearn import linear_model\n",
    "    regr = linear_model.LinearRegression()\n",
    "    \n",
    "    for i in range(nr) :\n",
    "        if i < histLen:\n",
    "            l_slope.append(np.nan)\n",
    "            l_predict.append(np.nan)\n",
    "            l_delta.append(np.nan)\n",
    "        else :\n",
    "            y = np.reshape(l_mean[(i-histLen):i].values, [histLen, 1])\n",
    "            x = np.reshape(np.arange(histLen), [histLen, 1])\n",
    "            regr.fit(x,y)\n",
    "            slope = regr.coef_[0,0]\n",
    "            l_slope.append(slope)\n",
    "            l_predict.append(l_mean[i] + slope)\n",
    "\n",
    "    df_atr = atr(df, atrLen)\n",
    "\n",
    "    df_slope = pd.DataFrame(data=l_slope, index=df.index, columns=['slope'])\n",
    "    df_slope['lpatr'] = l_slope / df_atr.values.ravel()\n",
    "    #df_slope['close'] = df['Close']\n",
    "    df_slope['slope_predict'] = l_predict\n",
    "    df_slope['delta_predict'] = df_slope['slope_predict'].shift(1) - df['close']\n",
    "    \n",
    "    df_slope.columns = ['lpatr_{m}_{n}'.format(m=histLen, n=atrLen), \n",
    "                       'slope_predict_{m}'.format(m=histLen), \n",
    "                       'delta_predict_{m}'.format(m=histLen)]\n",
    "    return df_slope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_target = next_day_atr_return_distance(df, win=10)\n",
    "df_target = log_return(df)\n",
    "df_target.columns = ['target']\n",
    "\n",
    "df_target[df_target > 0.04] = 1\n",
    "df_target[df_target < 0.04] = 0\n",
    "\n",
    "list_df_features = []\n",
    "list_df_features.append(log_return(df))\n",
    "list_df_features.append(atr(df, atrLen=10))\n",
    "list_df_features.append(atr(df, atrLen=5))\n",
    "list_df_features.append(close_ma_ATR_log(df))\n",
    "\n",
    "df_features = pd.DataFrame()\n",
    "for l in list_df_features:\n",
    "    df_features = df_features.join(l, how='outer')\n",
    "df_features = df_features.join(df_target, how='outer')\n",
    "df_features.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    23\n",
       "dtype: float64"
      ]
     },
     "execution_count": 111,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "df_target[df_target==1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logret</th>\n",
       "      <th>atr_10</th>\n",
       "      <th>atr_5</th>\n",
       "      <th>cmatr_5_30</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-02-14 00:00:00+00:00</th>\n",
       "      <td>-0.001513</td>\n",
       "      <td>2.123884</td>\n",
       "      <td>1.991586</td>\n",
       "      <td>-0.004019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-15 00:00:00+00:00</th>\n",
       "      <td>0.009646</td>\n",
       "      <td>2.064495</td>\n",
       "      <td>1.899269</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-16 00:00:00+00:00</th>\n",
       "      <td>-0.022296</td>\n",
       "      <td>2.262046</td>\n",
       "      <td>2.327415</td>\n",
       "      <td>-0.016148</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-20 00:00:00+00:00</th>\n",
       "      <td>-0.015534</td>\n",
       "      <td>2.339841</td>\n",
       "      <td>2.469932</td>\n",
       "      <td>-0.024935</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-02-21 00:00:00+00:00</th>\n",
       "      <td>-0.021811</td>\n",
       "      <td>2.439857</td>\n",
       "      <td>2.643946</td>\n",
       "      <td>-0.037432</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "df_features.iloc[:, :].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error=0.719809\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "nr_training = int(0.5*len(df_features))\n",
    "df_1 = df_features.iloc[:nr_training, :]\n",
    "df_2 = df_features.iloc[(nr_training +1):, :]\n",
    "dtrain = xgb.DMatrix(df_1.iloc[:, :-1], label=df_1['target'].values)\n",
    "dtest = xgb.DMatrix(df_2.iloc[:, :-1], label=df_2['target'].values)\n",
    "\n",
    "# specify parameters via map, definition are same as c++ version\n",
    "param = {'max_depth':2, 'eta':1, 'silent':1, 'objective':'binary:logistic' }\n",
    "\n",
    "# specify validations set to watch performance\n",
    "watchlist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "num_round = 2\n",
    "\n",
    "\n",
    "bst = xgb.cv(param, dtrain, num_boost_round=100)\n",
    "# this is prediction\n",
    "#preds = bst.predict(dtest)\n",
    "labels = dtest.get_label()\n",
    "print ('error=%f' % ( sum(1 for i in range(len(preds)) if int(preds[i]>0.5)!=labels[i]) /float(len(preds))))\n",
    "#xgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 117,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "type(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBRegressor()\n",
    "clf.fit(df_1.iloc[:, :-1], df_1['target'])\n",
    "predictions = clf.predict(df_1.iloc[:, :-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.333377835754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, mean_absolute_error, mean_squared_error\n",
    "print(mean_squared_error(np.array(df_1['target']), predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XGBRegressor' object has no attribute 'evals_result_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-d3334a87f579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load evals result by calling the evals_result() function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevals_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Access logloss metric directly from validation_0:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'validation_0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logloss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jianboxue/anaconda/lib/python2.7/site-packages/xgboost-0.4-py2.7.egg/xgboost/sklearn.pyc\u001b[0m in \u001b[0;36mevals_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    295\u001b[0m          'validation_1': {'logloss': ['0.41965', '0.17686']}}\n\u001b[1;32m    296\u001b[0m         \"\"\"\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevals_result_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m             \u001b[0mevals_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevals_result_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'XGBRegressor' object has no attribute 'evals_result_'"
     ]
    }
   ],
   "source": [
    "# Load evals result by calling the evals_result() function\n",
    "evals_result = clf.evals_result()\n",
    "\n",
    "print('Access logloss metric directly from validation_0:')\n",
    "print(evals_result['validation_0']['logloss'])\n",
    "\n",
    "print('')\n",
    "print('Access metrics through a loop:')\n",
    "for e_name, e_mtrs in evals_result.items():\n",
    "    print('- {}'.format(e_name))\n",
    "    for e_mtr_name, e_mtr_vals in e_mtrs.items():\n",
    "        print('   - {}'.format(e_mtr_name))\n",
    "        print('      - {}'.format(e_mtr_vals))\n",
    " \n",
    "print('')\n",
    "print('Access complete dict:')\n",
    "print(evals_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}