{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:55:35.551715Z",
     "start_time": "2019-03-06T20:55:17.600041Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# List all device\n",
    "from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:55:46.490873Z",
     "start_time": "2019-03-06T20:55:35.555457Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check available GPU\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:55:46.499737Z",
     "start_time": "2019-03-06T20:55:46.494382Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n",
    "# The GPU id to use, usually either \"0\" or \"1\";\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\";  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:55:46.587445Z",
     "start_time": "2019-03-06T20:55:46.504857Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Reshape, Lambda\n",
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.activations import softmax\n",
    "from keras.optimizers import SGD\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:55:47.071271Z",
     "start_time": "2019-03-06T20:55:46.592437Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../data/dowjones_calculated/periods.txt\", \"rb\") as fp:   # Unpickling\n",
    "    dataset = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:55:47.546416Z",
     "start_time": "2019-03-06T20:55:47.540384Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_one_hot(targets, nb_classes):\n",
    "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
    "    return res.reshape(list(targets.shape)+[nb_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:55:47.537619Z",
     "start_time": "2019-03-06T20:55:47.080975Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = dataset[0][0][0]\n",
    "meanX = X_train.mean(axis=1)\n",
    "stdX = X_train.std(axis = 1)\n",
    "X_train = X_train.sub(meanX, axis=0)\n",
    "X_train = X_train.div(stdX, axis = 0)\n",
    "X_train = X_train.values\n",
    "\n",
    "y_train = dataset[0][0][1].values\n",
    "\n",
    "X_test = dataset[1][0][0].values\n",
    "y_test = dataset[1][0][1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:55:47.891185Z",
     "start_time": "2019-03-06T20:55:47.548987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (750, 31)\n",
      "y train shape: (750, 31, 2)\n",
      "x test shape: (490, 31)\n",
      "y test shape: (490, 31, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x train shape: {X_train.shape}\")\n",
    "print(f\"y train shape: {y_train.shape}\")\n",
    "print(f\"x test shape: {X_test.shape}\")\n",
    "print(f\"y test shape: {y_test.shape}\")\n",
    "# print(f\"predicted shape: {predicted.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:55:48.628708Z",
     "start_time": "2019-03-06T20:55:47.893014Z"
    }
   },
   "outputs": [],
   "source": [
    "timestep = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:55:48.695892Z",
     "start_time": "2019-03-06T20:55:48.631389Z"
    }
   },
   "outputs": [],
   "source": [
    "data = X_train\n",
    "targets = y_train\n",
    "\n",
    "train_gen = TimeseriesGenerator(data, targets,\n",
    "                               length=timestep, sampling_rate=1,\n",
    "                               batch_size=740)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:55:48.765919Z",
     "start_time": "2019-03-06T20:55:48.697287Z"
    }
   },
   "outputs": [],
   "source": [
    "data = X_test\n",
    "targets = y_test\n",
    "\n",
    "test_gen = TimeseriesGenerator(data, targets,\n",
    "                               length=timestep, sampling_rate=1,\n",
    "                               batch_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:55:49.057803Z",
     "start_time": "2019-03-06T20:55:48.771244Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train_gen[0][0]\n",
    "y_train = train_gen[0][1]\n",
    "X_test = test_gen[0][0]\n",
    "y_test = test_gen[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:55:49.619369Z",
     "start_time": "2019-03-06T20:55:49.059204Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (740, 10, 31)\n",
      "y train shape: (740, 31, 2)\n",
      "x test shape: (250, 10, 31)\n",
      "y test shape: (250, 31, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x train shape: {X_train.shape}\")\n",
    "print(f\"y train shape: {y_train.shape}\")\n",
    "print(f\"x test shape: {X_test.shape}\")\n",
    "print(f\"y test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:55:50.403790Z",
     "start_time": "2019-03-06T20:55:49.626947Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.transpose((0,2,1))\n",
    "X_train = np.reshape(X_train, (740 * 31, timestep))\n",
    "y_train = np.reshape(y_train, (740 * 31, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:55:51.041532Z",
     "start_time": "2019-03-06T20:55:50.406122Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshaping X_train for efficient modelling\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "# X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:55:51.658994Z",
     "start_time": "2019-03-06T20:55:51.043723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x train shape: (22940, 10, 1)\n",
      "y train shape: (22940, 2)\n",
      "x test shape: (250, 10, 31)\n",
      "y test shape: (250, 31, 2)\n"
     ]
    }
   ],
   "source": [
    "print(f\"x train shape: {X_train.shape}\")\n",
    "print(f\"y train shape: {y_train.shape}\")\n",
    "print(f\"x test shape: {X_test.shape}\")\n",
    "print(f\"y test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:58:59.022115Z",
     "start_time": "2019-03-06T20:55:51.662331Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18352 samples, validate on 4588 samples\n",
      "Epoch 1/1000\n",
      "18352/18352 [==============================] - 5s 248us/step - loss: 0.6928 - acc: 0.5134 - val_loss: 0.6933 - val_acc: 0.5102\n",
      "Epoch 2/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6928 - acc: 0.5147 - val_loss: 0.6928 - val_acc: 0.5157\n",
      "Epoch 3/1000\n",
      "18352/18352 [==============================] - 2s 82us/step - loss: 0.6926 - acc: 0.5144 - val_loss: 0.6928 - val_acc: 0.5170\n",
      "Epoch 4/1000\n",
      "18352/18352 [==============================] - 1s 81us/step - loss: 0.6925 - acc: 0.5147 - val_loss: 0.6926 - val_acc: 0.5214\n",
      "Epoch 5/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6926 - acc: 0.5150 - val_loss: 0.6926 - val_acc: 0.5216\n",
      "Epoch 6/1000\n",
      "18352/18352 [==============================] - 2s 86us/step - loss: 0.6925 - acc: 0.5157 - val_loss: 0.6943 - val_acc: 0.5159\n",
      "Epoch 7/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6927 - acc: 0.5157 - val_loss: 0.6931 - val_acc: 0.5124\n",
      "Epoch 8/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6925 - acc: 0.5162 - val_loss: 0.6930 - val_acc: 0.5194\n",
      "Epoch 9/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6925 - acc: 0.5128 - val_loss: 0.6926 - val_acc: 0.5137\n",
      "Epoch 10/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6925 - acc: 0.5188 - val_loss: 0.6927 - val_acc: 0.5172\n",
      "Epoch 11/1000\n",
      "18352/18352 [==============================] - 2s 82us/step - loss: 0.6924 - acc: 0.5174 - val_loss: 0.6926 - val_acc: 0.5116\n",
      "Epoch 12/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6923 - acc: 0.5183 - val_loss: 0.6927 - val_acc: 0.5109\n",
      "Epoch 13/1000\n",
      "18352/18352 [==============================] - 1s 82us/step - loss: 0.6925 - acc: 0.5167 - val_loss: 0.6925 - val_acc: 0.5155\n",
      "Epoch 14/1000\n",
      "18352/18352 [==============================] - 2s 86us/step - loss: 0.6923 - acc: 0.5185 - val_loss: 0.6932 - val_acc: 0.5194\n",
      "Epoch 15/1000\n",
      "18352/18352 [==============================] - 2s 87us/step - loss: 0.6925 - acc: 0.5158 - val_loss: 0.6928 - val_acc: 0.5100\n",
      "Epoch 16/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6923 - acc: 0.5173 - val_loss: 0.6927 - val_acc: 0.5181\n",
      "Epoch 17/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6924 - acc: 0.5168 - val_loss: 0.6929 - val_acc: 0.5181\n",
      "Epoch 18/1000\n",
      "18352/18352 [==============================] - 2s 93us/step - loss: 0.6923 - acc: 0.5179 - val_loss: 0.6928 - val_acc: 0.5118\n",
      "Epoch 19/1000\n",
      "18352/18352 [==============================] - 2s 93us/step - loss: 0.6924 - acc: 0.5181 - val_loss: 0.6932 - val_acc: 0.5096\n",
      "Epoch 20/1000\n",
      "18352/18352 [==============================] - 2s 82us/step - loss: 0.6924 - acc: 0.5174 - val_loss: 0.6928 - val_acc: 0.5153\n",
      "Epoch 21/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6924 - acc: 0.5171 - val_loss: 0.6929 - val_acc: 0.5129\n",
      "Epoch 22/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6923 - acc: 0.5187 - val_loss: 0.6931 - val_acc: 0.5111\n",
      "Epoch 23/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6923 - acc: 0.5169 - val_loss: 0.6928 - val_acc: 0.5137\n",
      "Epoch 24/1000\n",
      "18352/18352 [==============================] - 2s 91us/step - loss: 0.6923 - acc: 0.5163 - val_loss: 0.6928 - val_acc: 0.5170\n",
      "Epoch 25/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6923 - acc: 0.5178 - val_loss: 0.6929 - val_acc: 0.5139\n",
      "Epoch 26/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6923 - acc: 0.5203 - val_loss: 0.6936 - val_acc: 0.5131\n",
      "Epoch 27/1000\n",
      "18352/18352 [==============================] - 2s 82us/step - loss: 0.6921 - acc: 0.5173 - val_loss: 0.6932 - val_acc: 0.5137\n",
      "Epoch 28/1000\n",
      "18352/18352 [==============================] - 1s 81us/step - loss: 0.6921 - acc: 0.5225 - val_loss: 0.6933 - val_acc: 0.5135\n",
      "Epoch 29/1000\n",
      "18352/18352 [==============================] - 2s 82us/step - loss: 0.6922 - acc: 0.5199 - val_loss: 0.6930 - val_acc: 0.5137\n",
      "Epoch 30/1000\n",
      "18352/18352 [==============================] - 1s 80us/step - loss: 0.6921 - acc: 0.5197 - val_loss: 0.6930 - val_acc: 0.5174\n",
      "Epoch 31/1000\n",
      "18352/18352 [==============================] - 2s 86us/step - loss: 0.6923 - acc: 0.5189 - val_loss: 0.6933 - val_acc: 0.5118\n",
      "Epoch 32/1000\n",
      "18352/18352 [==============================] - 1s 81us/step - loss: 0.6919 - acc: 0.5205 - val_loss: 0.6932 - val_acc: 0.5177\n",
      "Epoch 33/1000\n",
      "18352/18352 [==============================] - 2s 82us/step - loss: 0.6923 - acc: 0.5190 - val_loss: 0.6933 - val_acc: 0.5137\n",
      "Epoch 34/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6920 - acc: 0.5208 - val_loss: 0.6934 - val_acc: 0.5144\n",
      "Epoch 35/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6919 - acc: 0.5179 - val_loss: 0.6936 - val_acc: 0.5161\n",
      "Epoch 36/1000\n",
      "18352/18352 [==============================] - 1s 81us/step - loss: 0.6920 - acc: 0.5202 - val_loss: 0.6935 - val_acc: 0.5166\n",
      "Epoch 37/1000\n",
      "18352/18352 [==============================] - 1s 81us/step - loss: 0.6919 - acc: 0.5216 - val_loss: 0.6941 - val_acc: 0.5111\n",
      "Epoch 38/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6922 - acc: 0.5187 - val_loss: 0.6936 - val_acc: 0.5118\n",
      "Epoch 39/1000\n",
      "18352/18352 [==============================] - 1s 82us/step - loss: 0.6918 - acc: 0.5186 - val_loss: 0.6940 - val_acc: 0.5109\n",
      "Epoch 40/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6921 - acc: 0.5208 - val_loss: 0.6933 - val_acc: 0.5133\n",
      "Epoch 41/1000\n",
      "18352/18352 [==============================] - 2s 87us/step - loss: 0.6921 - acc: 0.5201 - val_loss: 0.6937 - val_acc: 0.5124\n",
      "Epoch 42/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6918 - acc: 0.5183 - val_loss: 0.6937 - val_acc: 0.5122\n",
      "Epoch 43/1000\n",
      "18352/18352 [==============================] - 2s 89us/step - loss: 0.6918 - acc: 0.5203 - val_loss: 0.6936 - val_acc: 0.5172\n",
      "Epoch 44/1000\n",
      "18352/18352 [==============================] - 2s 93us/step - loss: 0.6918 - acc: 0.5224 - val_loss: 0.6939 - val_acc: 0.5179\n",
      "Epoch 45/1000\n",
      "18352/18352 [==============================] - 2s 101us/step - loss: 0.6917 - acc: 0.5230 - val_loss: 0.6938 - val_acc: 0.5163\n",
      "Epoch 46/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6920 - acc: 0.5214 - val_loss: 0.6938 - val_acc: 0.5057\n",
      "Epoch 47/1000\n",
      "18352/18352 [==============================] - 2s 87us/step - loss: 0.6920 - acc: 0.5240 - val_loss: 0.6939 - val_acc: 0.5089\n",
      "Epoch 48/1000\n",
      "18352/18352 [==============================] - 2s 95us/step - loss: 0.6918 - acc: 0.5203 - val_loss: 0.6941 - val_acc: 0.5031\n",
      "Epoch 49/1000\n",
      "18352/18352 [==============================] - 2s 89us/step - loss: 0.6920 - acc: 0.5209 - val_loss: 0.6938 - val_acc: 0.5168\n",
      "Epoch 50/1000\n",
      "18352/18352 [==============================] - 1s 81us/step - loss: 0.6918 - acc: 0.5215 - val_loss: 0.6938 - val_acc: 0.5159\n",
      "Epoch 51/1000\n",
      "18352/18352 [==============================] - 1s 80us/step - loss: 0.6916 - acc: 0.5222 - val_loss: 0.6941 - val_acc: 0.5155\n",
      "Epoch 52/1000\n",
      "18352/18352 [==============================] - 1s 81us/step - loss: 0.6918 - acc: 0.5241 - val_loss: 0.6936 - val_acc: 0.5174\n",
      "Epoch 53/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6914 - acc: 0.5259 - val_loss: 0.6941 - val_acc: 0.5194\n",
      "Epoch 54/1000\n",
      "18352/18352 [==============================] - 2s 95us/step - loss: 0.6917 - acc: 0.5210 - val_loss: 0.6936 - val_acc: 0.5155\n",
      "Epoch 55/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6915 - acc: 0.5236 - val_loss: 0.6939 - val_acc: 0.5159\n",
      "Epoch 56/1000\n",
      "18352/18352 [==============================] - 1s 80us/step - loss: 0.6916 - acc: 0.5212 - val_loss: 0.6939 - val_acc: 0.5148\n",
      "Epoch 57/1000\n",
      "18352/18352 [==============================] - 2s 86us/step - loss: 0.6911 - acc: 0.5274 - val_loss: 0.6941 - val_acc: 0.5187\n",
      "Epoch 58/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6916 - acc: 0.5251 - val_loss: 0.6941 - val_acc: 0.4989\n",
      "Epoch 59/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6916 - acc: 0.5196 - val_loss: 0.6948 - val_acc: 0.5170\n",
      "Epoch 60/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6915 - acc: 0.5251 - val_loss: 0.6943 - val_acc: 0.4989\n",
      "Epoch 61/1000\n",
      "18352/18352 [==============================] - 2s 82us/step - loss: 0.6917 - acc: 0.5203 - val_loss: 0.6939 - val_acc: 0.5181\n",
      "Epoch 62/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6913 - acc: 0.5231 - val_loss: 0.6949 - val_acc: 0.5057\n",
      "Epoch 63/1000\n",
      "18352/18352 [==============================] - 2s 90us/step - loss: 0.6912 - acc: 0.5255 - val_loss: 0.6940 - val_acc: 0.5137\n",
      "Epoch 64/1000\n",
      "18352/18352 [==============================] - 2s 106us/step - loss: 0.6911 - acc: 0.5248 - val_loss: 0.6944 - val_acc: 0.5218\n",
      "Epoch 65/1000\n",
      "18352/18352 [==============================] - 2s 105us/step - loss: 0.6912 - acc: 0.5266 - val_loss: 0.6945 - val_acc: 0.5198\n",
      "Epoch 66/1000\n",
      "18352/18352 [==============================] - 2s 93us/step - loss: 0.6914 - acc: 0.5244 - val_loss: 0.6941 - val_acc: 0.5159\n",
      "Epoch 67/1000\n",
      "18352/18352 [==============================] - 2s 96us/step - loss: 0.6912 - acc: 0.5260 - val_loss: 0.6946 - val_acc: 0.4902\n",
      "Epoch 68/1000\n",
      "18352/18352 [==============================] - 2s 94us/step - loss: 0.6912 - acc: 0.5271 - val_loss: 0.6939 - val_acc: 0.5181\n",
      "Epoch 69/1000\n",
      "18352/18352 [==============================] - 2s 93us/step - loss: 0.6910 - acc: 0.5248 - val_loss: 0.6943 - val_acc: 0.4939\n",
      "Epoch 70/1000\n",
      "18352/18352 [==============================] - 2s 90us/step - loss: 0.6913 - acc: 0.5210 - val_loss: 0.6941 - val_acc: 0.5157\n",
      "Epoch 71/1000\n",
      "18352/18352 [==============================] - 2s 82us/step - loss: 0.6908 - acc: 0.5265 - val_loss: 0.6946 - val_acc: 0.5183\n",
      "Epoch 72/1000\n",
      "18352/18352 [==============================] - 2s 94us/step - loss: 0.6909 - acc: 0.5292 - val_loss: 0.6946 - val_acc: 0.5172\n",
      "Epoch 73/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6910 - acc: 0.5212 - val_loss: 0.6947 - val_acc: 0.5148\n",
      "Epoch 74/1000\n",
      "18352/18352 [==============================] - 1s 81us/step - loss: 0.6908 - acc: 0.5223 - val_loss: 0.6945 - val_acc: 0.5126\n",
      "Epoch 75/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6909 - acc: 0.5276 - val_loss: 0.6952 - val_acc: 0.5159\n",
      "Epoch 76/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6903 - acc: 0.5289 - val_loss: 0.6952 - val_acc: 0.5089\n",
      "Epoch 77/1000\n",
      "18352/18352 [==============================] - 2s 85us/step - loss: 0.6910 - acc: 0.5244 - val_loss: 0.6945 - val_acc: 0.4993\n",
      "Epoch 78/1000\n",
      "18352/18352 [==============================] - 2s 90us/step - loss: 0.6903 - acc: 0.5258 - val_loss: 0.6948 - val_acc: 0.5163\n",
      "Epoch 79/1000\n",
      "18352/18352 [==============================] - 2s 83us/step - loss: 0.6906 - acc: 0.5251 - val_loss: 0.6947 - val_acc: 0.5052\n",
      "Epoch 80/1000\n",
      "18352/18352 [==============================] - 2s 84us/step - loss: 0.6905 - acc: 0.5224 - val_loss: 0.6950 - val_acc: 0.5150\n",
      "Epoch 81/1000\n",
      "18352/18352 [==============================] - 2s 93us/step - loss: 0.6903 - acc: 0.5271 - val_loss: 0.6957 - val_acc: 0.5181\n",
      "Epoch 82/1000\n",
      "18352/18352 [==============================] - 2s 91us/step - loss: 0.6907 - acc: 0.5263 - val_loss: 0.6948 - val_acc: 0.5177\n",
      "Epoch 83/1000\n",
      "18352/18352 [==============================] - 2s 93us/step - loss: 0.6901 - acc: 0.5263 - val_loss: 0.6950 - val_acc: 0.5159\n",
      "Epoch 84/1000\n",
      "18352/18352 [==============================] - 2s 89us/step - loss: 0.6903 - acc: 0.5284 - val_loss: 0.6947 - val_acc: 0.5089\n",
      "Epoch 85/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6904 - acc: 0.5275 - val_loss: 0.6947 - val_acc: 0.5065\n",
      "Epoch 86/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6904 - acc: 0.5266 - val_loss: 0.6949 - val_acc: 0.5065\n",
      "Epoch 87/1000\n",
      "18352/18352 [==============================] - 2s 89us/step - loss: 0.6902 - acc: 0.5268 - val_loss: 0.6947 - val_acc: 0.5089\n",
      "Epoch 88/1000\n",
      "18352/18352 [==============================] - 2s 91us/step - loss: 0.6900 - acc: 0.5289 - val_loss: 0.6948 - val_acc: 0.5150\n",
      "Epoch 89/1000\n",
      "18352/18352 [==============================] - 2s 89us/step - loss: 0.6895 - acc: 0.5311 - val_loss: 0.6952 - val_acc: 0.5050\n",
      "Epoch 90/1000\n",
      "18352/18352 [==============================] - 2s 87us/step - loss: 0.6897 - acc: 0.5302 - val_loss: 0.6964 - val_acc: 0.5183\n",
      "Epoch 91/1000\n",
      "18352/18352 [==============================] - 2s 93us/step - loss: 0.6897 - acc: 0.5308 - val_loss: 0.6950 - val_acc: 0.4996\n",
      "Epoch 92/1000\n",
      "18352/18352 [==============================] - 2s 94us/step - loss: 0.6900 - acc: 0.5313 - val_loss: 0.6952 - val_acc: 0.5155\n",
      "Epoch 93/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6900 - acc: 0.5248 - val_loss: 0.6957 - val_acc: 0.5007\n",
      "Epoch 94/1000\n",
      "18352/18352 [==============================] - 2s 86us/step - loss: 0.6899 - acc: 0.5247 - val_loss: 0.6953 - val_acc: 0.5129\n",
      "Epoch 95/1000\n",
      "18352/18352 [==============================] - 2s 92us/step - loss: 0.6900 - acc: 0.5307 - val_loss: 0.6956 - val_acc: 0.5129\n",
      "Epoch 96/1000\n",
      "18352/18352 [==============================] - 2s 87us/step - loss: 0.6896 - acc: 0.5314 - val_loss: 0.6953 - val_acc: 0.5061\n",
      "Epoch 97/1000\n",
      "18352/18352 [==============================] - 2s 96us/step - loss: 0.6893 - acc: 0.5290 - val_loss: 0.6956 - val_acc: 0.5100\n",
      "Epoch 98/1000\n",
      "18352/18352 [==============================] - 2s 89us/step - loss: 0.6890 - acc: 0.5324 - val_loss: 0.6957 - val_acc: 0.5096\n",
      "Epoch 99/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6888 - acc: 0.5299 - val_loss: 0.6961 - val_acc: 0.5129\n",
      "Epoch 100/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6890 - acc: 0.5308 - val_loss: 0.6959 - val_acc: 0.5085\n",
      "Epoch 101/1000\n",
      "18352/18352 [==============================] - 2s 96us/step - loss: 0.6893 - acc: 0.5317 - val_loss: 0.6954 - val_acc: 0.5044\n",
      "Epoch 102/1000\n",
      "18352/18352 [==============================] - 2s 88us/step - loss: 0.6892 - acc: 0.5303 - val_loss: 0.6954 - val_acc: 0.5102\n",
      "Epoch 103/1000\n",
      "18352/18352 [==============================] - 2s 92us/step - loss: 0.6893 - acc: 0.5284 - val_loss: 0.6962 - val_acc: 0.5153\n",
      "Epoch 104/1000\n",
      "18352/18352 [==============================] - 2s 94us/step - loss: 0.6885 - acc: 0.5327 - val_loss: 0.6959 - val_acc: 0.5137\n",
      "Epoch 105/1000\n",
      "18352/18352 [==============================] - 2s 89us/step - loss: 0.6889 - acc: 0.5341 - val_loss: 0.6964 - val_acc: 0.5150\n",
      "Epoch 106/1000\n",
      "18352/18352 [==============================] - 2s 94us/step - loss: 0.6888 - acc: 0.5305 - val_loss: 0.6963 - val_acc: 0.4993\n",
      "Epoch 107/1000\n",
      "18352/18352 [==============================] - 2s 97us/step - loss: 0.6883 - acc: 0.5282 - val_loss: 0.6963 - val_acc: 0.5113\n",
      "Epoch 108/1000\n",
      "18352/18352 [==============================] - 2s 94us/step - loss: 0.6881 - acc: 0.5357 - val_loss: 0.6959 - val_acc: 0.5098\n",
      "Epoch 109/1000\n",
      "18352/18352 [==============================] - 2s 95us/step - loss: 0.6883 - acc: 0.5295 - val_loss: 0.6963 - val_acc: 0.5209\n",
      "Epoch 110/1000\n",
      "18352/18352 [==============================] - 2s 94us/step - loss: 0.6884 - acc: 0.5315 - val_loss: 0.6962 - val_acc: 0.5190\n",
      "Epoch 111/1000\n",
      "18352/18352 [==============================] - 2s 92us/step - loss: 0.6880 - acc: 0.5327 - val_loss: 0.6959 - val_acc: 0.5111\n",
      "Epoch 112/1000\n",
      "18352/18352 [==============================] - 2s 93us/step - loss: 0.6881 - acc: 0.5335 - val_loss: 0.6964 - val_acc: 0.5187\n",
      "Epoch 113/1000\n",
      "18352/18352 [==============================] - 2s 96us/step - loss: 0.6883 - acc: 0.5334 - val_loss: 0.6962 - val_acc: 0.5196\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f459836c710>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "\n",
    "# The LSTM architecture\n",
    "regressor = Sequential()\n",
    "# regressor.add(LSTM(units=25, return_sequences=True, input_shape=(240, 31)))\n",
    "regressor.add(LSTM(units=25, input_shape=(timestep, 1), dropout=0.1))\n",
    "\n",
    "\n",
    "# regressor.add(LSTM(units = 10, input_shape = (X_train.shape[1], 1)))\n",
    "# regressor.add(Dropout(0.2))\n",
    "\n",
    "# regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "# regressor.add(Dropout(0.2))\n",
    "\n",
    "# regressor.add(LSTM(units = 50, return_sequences = True))\n",
    "# regressor.add(Dropout(0.2))\n",
    "\n",
    "# regressor.add(LSTM(units = 10))\n",
    "# regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(Dense(1, activation='relu'))\n",
    "\n",
    "# regressor.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# regressor.compile(loss='binary_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "regressor.compile(loss='mean_squared_error',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "regressor.fit_generator(train_gen, steps_per_epoch=len(train_gen),\n",
    "                        epochs=1000, validation_data=test_gen,\n",
    "                        callbacks=[\n",
    "                            EarlyStopping(monitor='val_loss',\n",
    "                                          mode='min', patience=10),\n",
    "                            ModelCheckpoint(filepath=\"../model/mymodel.h5\",\n",
    "                                            monitor='val_acc',\n",
    "                                            save_best_only=True)])\n",
    "# regressor.fit(X_train,y_train,epochs=1000,batch_size=128, validation_split=0.2, callbacks = [EarlyStopping(monitor='val_loss', mode='min', patience=100),\n",
    "#              ModelCheckpoint(filepath='../model/LSTM/best_model.h5', monitor='val_acc', save_best_only=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:58:59.279783Z",
     "start_time": "2019-03-06T20:58:59.024446Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_1_input to have shape (10, 1) but got array with shape (10, 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-41cf373aa06c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Evaluating our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/projet_S5/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1147\u001b[0m                              'argument.')\n\u001b[1;32m   1148\u001b[0m         \u001b[0;31m# Validate user data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/projet_S5/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/projet_S5/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected lstm_1_input to have shape (10, 1) but got array with shape (10, 31)"
     ]
    }
   ],
   "source": [
    "# Evaluating our model\n",
    "predicted = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:58:59.283617Z",
     "start_time": "2019-03-06T20:55:17.659Z"
    }
   },
   "outputs": [],
   "source": [
    "label = predicted > 0.5\n",
    "label = label * 1 # Convert boolean to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:58:59.285501Z",
     "start_time": "2019-03-06T20:55:17.660Z"
    }
   },
   "outputs": [],
   "source": [
    "(sum(y_test[:, :, 1] == label[:, :, 1])/(y_test.size/2)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:58:59.287404Z",
     "start_time": "2019-03-06T20:55:17.662Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = '../model/LSTM/my_model3.h5'\n",
    "regressor.save(model_name)  # creates a HDF5 file 'my_model.h5'\n",
    "del regressor  # deletes the existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:58:59.289295Z",
     "start_time": "2019-03-06T20:55:17.663Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.activations import softmax\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "regressor1 = load_model(model_name, custom_objects={\"softmax\": softmax})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-06T20:58:59.292134Z",
     "start_time": "2019-03-06T20:55:17.664Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted_load = regressor1.predict(X_test)\n",
    "label_load = predicted_load > 0.5\n",
    "label_load = label_load * 1 # Convert boolean to int\n",
    "(sum(y_test[:, :, 1] == label_load[:, :, 1])/(y_test.size/2)).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_S5",
   "language": "python",
   "name": "projet_s5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
