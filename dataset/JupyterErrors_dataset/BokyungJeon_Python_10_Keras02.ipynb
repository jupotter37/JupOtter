{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN인공신경망: 아키텍처가 인간의 두뇌와 닮아 인공신경망으로 불리는 여러 머신러닝 알고리즘\n",
    "# 분류 과업을 위한 논리 회귀, 회귀 문제를 위한 선형 회귀, 클러스터링을 위한 k-평균\n",
    "# 주가 예측시 주가가 과거 어느 시점보다 올랐거나 떨어졌는지 예측은 분류 문제\n",
    "# 가격자체를 예측하려면 회귀문제\n",
    "# 딥러닝은 행렬이다.\n",
    "# 딥러닝은 런타임에 데이터로 들어왔을 때 동적으로 분석해주는 것\n",
    "# 전체를 스캔해서 전반적으로 분석하는데에는 정적으로 분석하는 애들보다 능력이 떨어짐\n",
    "# 좋은 제품을 개발하기 위해서는 딥러닝뿐만아니라 레거시(과거의 전통적인 머신러닝 알고리즘)도 활용해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스칼라: 단일 수이며 0차 텐서\n",
    "# 벡터: 단일 수로 구성된 1차원 배열이며 1차 텐서\n",
    "# 행렬: 사각 배열을 가지며, 단일 수로 구성된 2개의 차원을 가짐. 2차 텐서\n",
    "# 텐서: 스칼라, 벡터, 행렬 등을 포함한 포관적인 개념. 일반적으로 텐서를 이야기할 때 3개 이상의 차원을 가진 텐서를 의미\n",
    "# 브로드캐스팅broad casting: 열 수가 서로 같으면 벡터와 행렬을 더하는 것도 가능하다. 이것을 브로드캐스팅이라고 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vec1 = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "print(vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "vec1 = np.arange(1, 11)\n",
    "print(vec1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "(4, 3)\n"
     ]
    }
   ],
   "source": [
    "mat1 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
    "print(mat1)\n",
    "print(mat1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n",
      "(4, 3)\n"
     ]
    }
   ],
   "source": [
    "mat2 = np.matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]])\n",
    "print(mat2)\n",
    "print(mat2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[ 7  8  9]\n",
      "  [10 11 12]]]\n",
      "(2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "ten1 = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "print(ten1)\n",
    "print(ten1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  4  6]\n",
      " [ 8 10 12]\n",
      " [14 16 18]\n",
      " [20 22 24]]\n"
     ]
    }
   ],
   "source": [
    "mat3 = mat1 + mat2\n",
    "print(mat3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (4,3) and (4,3) not aligned: 3 (dim 1) != 4 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a600386602ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmat4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmat1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmat2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__rmul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__rmul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__imul__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (4,3) and (4,3) not aligned: 3 (dim 1) != 4 (dim 0)"
     ]
    }
   ],
   "source": [
    "mat4 = mat1 * mat2\n",
    "print(mat4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "(3, 3)\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "mat3 = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(mat3)\n",
    "print(mat3.shape)\n",
    "\n",
    "mat4 = np.matrix([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(mat4)\n",
    "print(mat4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 30  36  42]\n",
      " [ 66  81  96]\n",
      " [102 126 150]]\n"
     ]
    }
   ],
   "source": [
    "mat5 = mat3 * mat4\n",
    "print(mat5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 행렬 연산 규칙\n",
    "# 행렬은 행과 열로 구성된다.\n",
    "# 행렬의 곱셉을 수행하기 위한 최소한의 규칙\n",
    "# m by n 행렬을 곱하려면 n by x가 되어야 한다.\n",
    "# 두 행렬 곱셈의 결과는 m by x가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  4  7 10]\n",
      " [ 2  5  8 11]\n",
      " [ 3  6  9 12]]\n",
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "# .T전치행렬 = 행과 열의 위치를 바꾼다.\n",
    "print(mat1.T)\n",
    "print(mat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[166 188 210]\n",
      " [188 214 240]\n",
      " [210 240 270]]\n"
     ]
    }
   ],
   "source": [
    "# 3 by 4 * 4 by 3 => 3 by 3\n",
    "mat5 = mat1.T * mat2\n",
    "print(mat5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 14  32  50  68]\n",
      " [ 32  77 122 167]\n",
      " [ 50 122 194 266]\n",
      " [ 68 167 266 365]]\n"
     ]
    }
   ],
   "source": [
    "# 4 by 3 * 3 by 4 => 4 by 4\n",
    "mat5 = mat1 * mat2.T\n",
    "print(mat5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "print(vec1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  2  4]\n",
      " [ 6  8 10]]\n",
      "(2, 3)\n"
     ]
    }
   ],
   "source": [
    "smartMat = np.arange(0, 11, 2).reshape((2,3))\n",
    "# np.arrange(시작, 끝, 2씩증가).reshape((행렬2,by3))\n",
    "print(smartMat)\n",
    "print(smartMat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  6  7]\n",
      " [ 8  9 10]\n",
      " [11 12 13]\n",
      " [14 15 16]]\n"
     ]
    }
   ],
   "source": [
    "test = mat1 + 4\n",
    "# 행렬에 스칼라를 더한 형태\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "(3, 4)\n"
     ]
    }
   ],
   "source": [
    "smartMat2 = np.arange(1, 13).reshape((3,4))\n",
    "\n",
    "print(smartMat2)\n",
    "print(smartMat2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# .shape[0]은 열, .shape[1]은 행\n",
    "print(mat1.shape[0])\n",
    "print(mat1.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12]\n"
     ]
    }
   ],
   "source": [
    "# 텐서 원소의 수가 동일하게 유지되는 내에 정형(차원도) 가능\n",
    "# 차원 변환이 필요한 경우: 가우스-조르단 소거법\n",
    "mat = mat1.reshape(mat1.shape[0] * mat1.shape[1])\n",
    "\n",
    "print(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "print(mat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3]\n",
      " [ 4  5  6]\n",
      " [ 7  8  9]\n",
      " [10 11 12]]\n"
     ]
    }
   ],
   "source": [
    "# 텐서를 해석하는 방법\n",
    "# 맨 앞의 숫자가 큰 집합의 개수를 의미함\n",
    "# 뒤쪽의 2개 숫자는 행렬의 모양을 의미\n",
    "# 즉 뒤쪽의 2개 숫자를 통해 행렬의 모양을 잡고, 맨앞의 숫자를 통해 해당 행렬이 몇개 있는지 파악하면 된다.\n",
    "ten2 = mat1.reshape((3, 2, 2))\n",
    "# 3개의 큰 행렬 집합 안에 2 by 2 행렬이 들어 있음\n",
    "print(mat1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 2 3]\n",
      "  [4 5 6]]\n",
      "\n",
      " [[1 2 3]\n",
      "  [4 5 6]]]\n",
      "(2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "ret = np.matrix(np.arange(1, 7)).reshape((2, 3))\n",
    "ret2 = np.matrix(np.arange(2, 8)).reshape((2, 3))\n",
    "ten3 = np.array([ret, ret])\n",
    "\n",
    "print(ten3)\n",
    "print(ten3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 1]\n",
      "  [4 4]]\n",
      "\n",
      " [[2 2]\n",
      "  [5 5]]\n",
      "\n",
      " [[3 3]\n",
      "  [6 6]]]\n",
      "(3, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(ten3.T)\n",
    "print(ten3.T.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 2, 2)\n",
      "(2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "print(ten2.shape)\n",
    "print(ten3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[  9  12  15]\n",
      "   [  9  12  15]]\n",
      "\n",
      "  [[ 19  26  33]\n",
      "   [ 19  26  33]]]\n",
      "\n",
      "\n",
      " [[[ 29  40  51]\n",
      "   [ 29  40  51]]\n",
      "\n",
      "  [[ 39  54  69]\n",
      "   [ 39  54  69]]]\n",
      "\n",
      "\n",
      " [[[ 49  68  87]\n",
      "   [ 49  68  87]]\n",
      "\n",
      "  [[ 59  82 105]\n",
      "   [ 59  82 105]]]]\n"
     ]
    }
   ],
   "source": [
    "# [ 1  2]    [1, 2, 3] \n",
    "# [ 3  4]    [4, 5, 6]  \n",
    "#            [2, 3, 4]\n",
    "#            [5, 6, 7]\n",
    "# [ 5  6]\n",
    "# [ 7  8]\n",
    "#\n",
    "# [ 9 10]\n",
    "# [11 12]\n",
    "\n",
    "ten4 = ten2.dot(ten3)\n",
    "\n",
    "\n",
    "print(ten4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "[[ 1  4]\n",
      " [ 9 16]]\n",
      "[[ 7 10]\n",
      " [15 22]]\n"
     ]
    }
   ],
   "source": [
    "testMat1 = np.arange(1, 5).reshape((2,2))\n",
    "testMat2 = np.arange(1, 5).reshape((2,2))\n",
    "\n",
    "print(testMat1)\n",
    "print(testMat2)\n",
    "# 차원이 같은 경우식 동일 위치 숫자끼리 곱셈 가능\n",
    "print(testMat1 * testMat2)\n",
    "# 행렬의 곱셈 계산식은 .dot\n",
    "print(testMat1.dot(testMat2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인공지능 공부할 때\n",
    "# 1. 선형대수 - 수리물리학 텐서파트(현재 텐서책은 따로 없음. \n",
    "#             책 추천: 보아스-쉽게나옴, 아프켄-악명높음) \n",
    "# 2. 통계학\n",
    "# 3. 공업수학(라플라스 변환, 푸리에 변환)\n",
    "# 4. 커스텀 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_Python.ipynb  04_Python.ipynb  09_Keras01.ipynb\t\t    data\r\n",
      "02_Python.ipynb  07_Github.ipynb  10_Keras02.ipynb\t\t    LICENSE\r\n",
      "03_Python.ipynb  08_MySQL.ipynb   Applied-Deep-Learning-with-Keras  README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lesson01  Lesson03  Lesson05  Lesson07\tLesson09  README.md\r\n",
      "Lesson02  Lesson04  Lesson06  Lesson08\tLICENSE\r\n"
     ]
    }
   ],
   "source": [
    "!ls Applied-Deep-Learning-with-Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity01.ipynb  data\t\t    Exercise02.ipynb  Exercise04.ipynb\r\n",
      "bank.zip\t  Exercise01.ipynb  Exercise03.ipynb  Exercise05.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls Applied-Deep-Learning-with-Keras/Lesson01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank.csv\t\tbank_data_feats_e2.csv\tbank_data_target_e2.csv\r\n",
      "bank_data_feats_a2.csv\tbank_data_feats_e3.csv\tbank-full.csv\r\n",
      "bank_data_feats.csv\tbank_data_target.csv\tbank-names.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls Applied-Deep-Learning-with-Keras/Lesson01/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0\n",
       "5  0\n",
       "6  0\n",
       "7  0\n",
       "8  0\n",
       "9  0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "feats = pd.read_csv('Applied-Deep-Learning-with-Keras/Lesson01/data/bank_data_feats_e3.csv', index_col=0)\n",
    "target = pd.read_csv('Applied-Deep-Learning-with-Keras/Lesson01/data/bank_data_target_e2.csv', index_col=0)\n",
    "target.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(feats, target, test_size=test_size, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3616, 32)\n",
      "(905, 32)\n",
      "(3616, 1)\n",
      "(905, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이어는 노드의 집합으로 이루어며, 각 노드에서는 몇 가지 연산이 이뤄진다.\n",
    "# 행렬 곱셈이 각 노드에서 이루어져 입력데이터에 가중치가 곱해짐\n",
    "# 가중치 W(weight)는 보통 0~1의 값. 마이너스나 3, 5같은 큰값도 경우에 따라선 가능.\n",
    "# 이 때 가중치와 입력값을 곱한 값들의 합도 구해지는데 이 값에 편향성이 존재할 수 있다.\n",
    "# 계산된 행렬곱에 활성화 함수 같은 다른 함수를 추가로 적용할 수 있다.\n",
    "# 입력 - 가중치 - 초기입력함수 - 활성화함수 - 결과\n",
    "\n",
    "# 밀집레이어: 완전히 연결된 레이어로 여기 속한 모든 노드는 모든 입력과 결과에 직접 연결\n",
    "\n",
    "# Conveolution콘볼루션,컨벌루션 합성곱\n",
    "# 컨벌루션 커널은 입력레이어와 컨벌루션되어 결과텐서를 만들게 된다. \n",
    "# 이는 하나 또는 그 이상의 차원에서 이뤄질 수 있다.\n",
    "\n",
    "# 풀링 레이어: 입력레이어의 차원 수를 줄이려고 사용. \n",
    "# 쓸데없는 데이터 다 안넣기 위해 적정한 수치값을 잡아 지정한다는 뜻\n",
    "\n",
    "# 순환레이어: 정보의 흐름으로부터 패턴을 배우기 때문에 각 결과값은 직전 단계의 결과와 연관성\n",
    "# 자연어나 시계열 데이터와 같은 순차적 데이터를 위한 모델을 구성할 때 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install keras\n",
    "# pip install tensorflow\n",
    "# 케라스 제공하는 모델 구조 중 가장 간단한 순차모델 Sequentail\n",
    "# 순차 클래스 모델은 레이어가 순차적으로 쌓인 모델이다.\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활성화 함수\n",
    "# 일반적으로 노드의 결과값 범위를 제한하려고 활성화 함수를 사용한다.\n",
    "# 각 노드의 결과값에 제한이 없어 마이너스 무한대 ~ 무한대 가능\n",
    "# 활성화 함수는 값을 특정범위로, 대부분 2개값 사이의 범위로 묶어두기 때문에 도움이 됨\n",
    "# 또한 특정노드를 제외할지 결정할 때도 도움이 됨\n",
    "\n",
    "# step함수: 설정한 값 아래면 다 0. 로봇쪽\n",
    "# linear함수\n",
    "# sigmoid함수: 일종의 step function (0부터 1까지기 때문)\n",
    "# tanh쌍곡선함수: 시그모이드함수 변형. x=0근처에서 기울기가 크다\n",
    "# ReLU함수: 0보다 클때만 취급. 0보다 작으면 다 0(음수 취급안함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 아키텍처 만들기\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "\n",
    "input_shape = x_train.shape[1]\n",
    "units = 1\n",
    "\n",
    "model.add(Dense(units, input_dim=input_shape))\n",
    "model.add(Activation('tanh'))\n",
    "# 활성화 함수는 레이어를 선언할 때 아규먼트 형태로 모델에 추가할 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 아키텍처 만들고 다음으로 모델 컴파일하기\n",
    "# 컴파일과정에서 (어떤 최적화를 쓸지, 최소화할 손실함수는 무엇이 될지, 모델학습의 각 단계에서 계산될 정확성과 같은 선택적인 측정지표는 무엇인지\n",
    "# 등) 모든 학습관련 매개변수를 설정\n",
    "# .compile메서드를 사용해 모델을 컴파일하고나면 학습데이터에 피팅할 준비가 된다.\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "91/91 [==============================] - 0s 840us/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 2/10\n",
      "91/91 [==============================] - 0s 874us/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 3/10\n",
      "91/91 [==============================] - 0s 868us/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 4/10\n",
      "91/91 [==============================] - 0s 914us/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 5/10\n",
      "91/91 [==============================] - 0s 928us/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 6/10\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 7/10\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 8/10\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 9/10\n",
      "91/91 [==============================] - 0s 907us/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 10/10\n",
      "91/91 [==============================] - 0s 890us/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n"
     ]
    }
   ],
   "source": [
    "# 초기화한 모델에 fit메서드를 사용할 수 있다. 다음은 많이 사용하는 아규먼트들\n",
    "# x: 모델 피팅에 사용할 학습용 특성 데이터 배열\n",
    "# y: 모델 피팅에 사용할 학습용 목표 데이터 배열\n",
    "# epochs: 모델을 실행할 세대 횟수(한 세대: 전체 학습데이터세트 한바퀴) -몇번 실행\n",
    "# batch_size: 경사gradient업데이트마다 사용할 학습데이터 표본 수\n",
    "# validation_split: 각 세대epoch 후 검증에 사용되는 학습데이터 비 - 검증에 얼마\n",
    "history = model.fit(x=x_train, y=y_train['y'], epochs=10, batch_size=32, validation_split=0.2)\n",
    "# 이 모델은 히든모델이 없이 dense(연결만 하는 것)이므로 아무리 많이 반복해도 개선이 안됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [1.8454468250274658, 1.8454467058181763, 1.8454464673995972, 1.8454467058181763, 1.8454468250274658, 1.8454464673995972, 1.8454468250274658, 1.8454467058181763, 1.8454464673995972, 1.8454468250274658], 'accuracy': [0.8803595900535583, 0.8803595900535583, 0.8803595900535583, 0.8803595900535583, 0.8803595900535583, 0.8803595900535583, 0.8803595900535583, 0.8803595900535583, 0.8803595900535583, 0.8803595900535583], 'val_loss': [1.6404985189437866, 1.6404985189437866, 1.6404985189437866, 1.6404985189437866, 1.6404985189437866, 1.6404985189437866, 1.6404985189437866, 1.6404985189437866, 1.6404985189437866, 1.6404985189437866], 'val_accuracy': [0.8936464190483093, 0.8936464190483093, 0.8936464190483093, 0.8936464190483093, 0.8936464190483093, 0.8936464190483093, 0.8936464190483093, 0.8936464190483093, 0.8936464190483093, 0.8936464190483093]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuacy')\n",
    "plt.xlabel('Loop')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Loop')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity02.ipynb     bank_data_target.csv  Exercise07.ipynb  Exercise09.ipynb\r\n",
      "bank_data_feats.csv  Exercise06.ipynb\t   Exercise08.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls Applied-Deep-Learning-with-Keras/Lesson02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feats = pd.read_csv('Applied-Deep-Learning-with-Keras/Lesson02/bank_data_feats.csv', index_col = 0)\n",
    "target = pd.read_csv('Applied-Deep-Learning-with-Keras/Lesson02/bank_data_target.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 6.2227 - accuracy: 0.5806 - val_loss: 5.6063 - val_accuracy: 0.6243\n",
      "Epoch 2/20\n",
      "91/91 [==============================] - 0s 803us/step - loss: 3.8101 - accuracy: 0.7438 - val_loss: 1.8147 - val_accuracy: 0.8798\n",
      "Epoch 3/20\n",
      "91/91 [==============================] - 0s 823us/step - loss: 1.8570 - accuracy: 0.8793 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 4/20\n",
      "91/91 [==============================] - 0s 860us/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 5/20\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 6/20\n",
      "91/91 [==============================] - 0s 998us/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 7/20\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 8/20\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 9/20\n",
      "91/91 [==============================] - 0s 993us/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 10/20\n",
      "91/91 [==============================] - 0s 886us/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 11/20\n",
      "91/91 [==============================] - 0s 875us/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 12/20\n",
      "91/91 [==============================] - 0s 952us/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 13/20\n",
      "91/91 [==============================] - 0s 973us/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 14/20\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 15/20\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 16/20\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 17/20\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 18/20\n",
      "91/91 [==============================] - 0s 823us/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 19/20\n",
      "91/91 [==============================] - ETA: 0s - loss: 1.9281 - accuracy: 0.87 - 0s 840us/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n",
      "Epoch 20/20\n",
      "91/91 [==============================] - 0s 1ms/step - loss: 1.8454 - accuracy: 0.8804 - val_loss: 1.6405 - val_accuracy: 0.8936\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(feats, target, test_size=test_size, random_state=random_state)\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "input_shape = x_train.shape[1]\n",
    "units = 1\n",
    "\n",
    "model.add(Dense(units, input_dim=input_shape))\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',  metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x=x_train, y=y_train['y'], epochs=20, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuacy')\n",
    "plt.xlabel('Loop')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Loop')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euler Formula\n",
    "# e^ix = cos(x) + i sin(x)\n",
    "# e^-ix = cos(x) - i sin(x)\n",
    "# e^ix + e^-ix = 2 cos(x)\n",
    "# cos(x) = (e^ix + e^-ix) / 2\n",
    "\n",
    "# e^ix - e^-ix= 2i sin(x)\n",
    "# sin(x) = (e^ix - e^-ix) / 2\n",
    "# tan(x) = sin(x) / cos(x)\n",
    "\n",
    "# cosh(x) = (e^x + e^-x) / 2\n",
    "# sinh(x) = (e^x - e^-x) / 2 \n",
    "# tanh(x) = sinh(x) / cosh(x)\n",
    "# tanh(x)는 -1 ~ 1 사이의 값을 가지게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#가중치 행렬의 열 수는 직전 레이어 노드수와 같게 되고, 행 수는 자기 레이어의 노드 수와 같게 된다.\n",
    "\n",
    "# x: 1 by 2\n",
    "# w1: 2 by 3\n",
    "# b1: 1by 3\n",
    "# z1 = x * w1 + b1\n",
    "# 행렬 곱셈의 규칙\n",
    "# (1 by 2)(2 by 3) ==> (1 by 3)\n",
    "# a1:값에 tanh가 적용된 (1 by 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Dataset:  300\n",
      "Num of Features:  10\n",
      "Possible Output Classes:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "#                          데이터 300개       독립변수 10개      나올 수 있는 결과 2개 0,1\n",
    "x, y = make_classification(n_samples = 300, n_features = 10, n_classes = 2)\n",
    "\n",
    "print(\"Num of Dataset: \", x.shape[0])\n",
    "print(\"Num of Features: \", x.shape[1])\n",
    "print(\"Possible Output Classes: \", np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature가 10개라는 뜻은 y = ax1 + bx2 + cx3 + dx4 + ex5 + fx6 + gx7 + hx8 + ix9 + jx10 + alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "\n",
    "# Dense(출력 개수, 활성화 함수, 입력 개수)\n",
    "# input_dim은 처음만 입력하면 된다. (나머지는 입력차원이 직전레이어에 따라 결정되기 때문) \n",
    "model.add(Dense(20, activation='tanh', input_dim=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(40, activation='tanh'))\n",
    "model.add(Dense(10, activation='tanh'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd는 로스를 최소화하는 방식으로 정의되어있음\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "60/60 [==============================] - 0s 519us/step - loss: 0.7320\n",
      "Epoch 2/1000\n",
      "60/60 [==============================] - 0s 503us/step - loss: 0.4543\n",
      "Epoch 3/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.3198\n",
      "Epoch 4/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.2451\n",
      "Epoch 5/1000\n",
      "60/60 [==============================] - 0s 515us/step - loss: 0.2022\n",
      "Epoch 6/1000\n",
      "60/60 [==============================] - 0s 595us/step - loss: 0.1767\n",
      "Epoch 7/1000\n",
      "60/60 [==============================] - 0s 478us/step - loss: 0.1609\n",
      "Epoch 8/1000\n",
      "60/60 [==============================] - 0s 506us/step - loss: 0.1493\n",
      "Epoch 9/1000\n",
      "60/60 [==============================] - 0s 466us/step - loss: 0.1415\n",
      "Epoch 10/1000\n",
      "60/60 [==============================] - 0s 468us/step - loss: 0.1366\n",
      "Epoch 11/1000\n",
      "60/60 [==============================] - 0s 492us/step - loss: 0.1319\n",
      "Epoch 12/1000\n",
      "60/60 [==============================] - 0s 498us/step - loss: 0.1284\n",
      "Epoch 13/1000\n",
      "60/60 [==============================] - 0s 496us/step - loss: 0.1260\n",
      "Epoch 14/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.1232\n",
      "Epoch 15/1000\n",
      "60/60 [==============================] - 0s 493us/step - loss: 0.1208\n",
      "Epoch 16/1000\n",
      "60/60 [==============================] - 0s 471us/step - loss: 0.1192\n",
      "Epoch 17/1000\n",
      "60/60 [==============================] - 0s 533us/step - loss: 0.1174\n",
      "Epoch 18/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.1159\n",
      "Epoch 19/1000\n",
      "60/60 [==============================] - 0s 483us/step - loss: 0.1148\n",
      "Epoch 20/1000\n",
      "60/60 [==============================] - 0s 539us/step - loss: 0.1133\n",
      "Epoch 21/1000\n",
      "60/60 [==============================] - 0s 551us/step - loss: 0.1116\n",
      "Epoch 22/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.1107\n",
      "Epoch 23/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.1092\n",
      "Epoch 24/1000\n",
      "60/60 [==============================] - 0s 488us/step - loss: 0.1082\n",
      "Epoch 25/1000\n",
      "60/60 [==============================] - 0s 521us/step - loss: 0.1074\n",
      "Epoch 26/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.1059\n",
      "Epoch 27/1000\n",
      "60/60 [==============================] - 0s 492us/step - loss: 0.1052\n",
      "Epoch 28/1000\n",
      "60/60 [==============================] - 0s 499us/step - loss: 0.1042\n",
      "Epoch 29/1000\n",
      "60/60 [==============================] - 0s 461us/step - loss: 0.1031\n",
      "Epoch 30/1000\n",
      "60/60 [==============================] - 0s 482us/step - loss: 0.1020\n",
      "Epoch 31/1000\n",
      "60/60 [==============================] - 0s 478us/step - loss: 0.1011\n",
      "Epoch 32/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.1001\n",
      "Epoch 33/1000\n",
      "60/60 [==============================] - 0s 521us/step - loss: 0.0993\n",
      "Epoch 34/1000\n",
      "60/60 [==============================] - 0s 483us/step - loss: 0.0982\n",
      "Epoch 35/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0971\n",
      "Epoch 36/1000\n",
      "60/60 [==============================] - 0s 555us/step - loss: 0.0963\n",
      "Epoch 37/1000\n",
      "60/60 [==============================] - 0s 496us/step - loss: 0.0955\n",
      "Epoch 38/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0945\n",
      "Epoch 39/1000\n",
      "60/60 [==============================] - 0s 464us/step - loss: 0.0936\n",
      "Epoch 40/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0926\n",
      "Epoch 41/1000\n",
      "60/60 [==============================] - 0s 543us/step - loss: 0.0920\n",
      "Epoch 42/1000\n",
      "60/60 [==============================] - 0s 494us/step - loss: 0.0904\n",
      "Epoch 43/1000\n",
      "60/60 [==============================] - 0s 490us/step - loss: 0.0898\n",
      "Epoch 44/1000\n",
      "60/60 [==============================] - 0s 466us/step - loss: 0.0891\n",
      "Epoch 45/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0881\n",
      "Epoch 46/1000\n",
      "60/60 [==============================] - 0s 488us/step - loss: 0.0879\n",
      "Epoch 47/1000\n",
      "60/60 [==============================] - 0s 537us/step - loss: 0.0867\n",
      "Epoch 48/1000\n",
      "60/60 [==============================] - 0s 486us/step - loss: 0.0862\n",
      "Epoch 49/1000\n",
      "60/60 [==============================] - 0s 496us/step - loss: 0.0856\n",
      "Epoch 50/1000\n",
      "60/60 [==============================] - 0s 568us/step - loss: 0.0845\n",
      "Epoch 51/1000\n",
      "60/60 [==============================] - 0s 516us/step - loss: 0.0838\n",
      "Epoch 52/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0832\n",
      "Epoch 53/1000\n",
      "60/60 [==============================] - 0s 543us/step - loss: 0.0824\n",
      "Epoch 54/1000\n",
      "60/60 [==============================] - 0s 519us/step - loss: 0.0818\n",
      "Epoch 55/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0808\n",
      "Epoch 56/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0801\n",
      "Epoch 57/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0796\n",
      "Epoch 58/1000\n",
      "60/60 [==============================] - 0s 490us/step - loss: 0.0786\n",
      "Epoch 59/1000\n",
      "60/60 [==============================] - 0s 503us/step - loss: 0.0779\n",
      "Epoch 60/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0776\n",
      "Epoch 61/1000\n",
      "60/60 [==============================] - 0s 494us/step - loss: 0.0770\n",
      "Epoch 62/1000\n",
      "60/60 [==============================] - 0s 490us/step - loss: 0.0761\n",
      "Epoch 63/1000\n",
      "60/60 [==============================] - 0s 499us/step - loss: 0.0754\n",
      "Epoch 64/1000\n",
      "60/60 [==============================] - 0s 494us/step - loss: 0.0748\n",
      "Epoch 65/1000\n",
      "60/60 [==============================] - 0s 506us/step - loss: 0.0740\n",
      "Epoch 66/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0734\n",
      "Epoch 67/1000\n",
      "60/60 [==============================] - 0s 497us/step - loss: 0.0725\n",
      "Epoch 68/1000\n",
      "60/60 [==============================] - 0s 523us/step - loss: 0.0719\n",
      "Epoch 69/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0714\n",
      "Epoch 70/1000\n",
      "60/60 [==============================] - 0s 527us/step - loss: 0.0707\n",
      "Epoch 71/1000\n",
      "60/60 [==============================] - 0s 502us/step - loss: 0.0697\n",
      "Epoch 72/1000\n",
      "60/60 [==============================] - 0s 537us/step - loss: 0.0691\n",
      "Epoch 73/1000\n",
      "60/60 [==============================] - 0s 490us/step - loss: 0.0690\n",
      "Epoch 74/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0679\n",
      "Epoch 75/1000\n",
      "60/60 [==============================] - 0s 492us/step - loss: 0.0670\n",
      "Epoch 76/1000\n",
      "60/60 [==============================] - 0s 489us/step - loss: 0.0664\n",
      "Epoch 77/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0654\n",
      "Epoch 78/1000\n",
      "60/60 [==============================] - 0s 497us/step - loss: 0.0651\n",
      "Epoch 79/1000\n",
      "60/60 [==============================] - 0s 446us/step - loss: 0.0643\n",
      "Epoch 80/1000\n",
      "60/60 [==============================] - 0s 459us/step - loss: 0.0634\n",
      "Epoch 81/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0622\n",
      "Epoch 82/1000\n",
      "60/60 [==============================] - 0s 461us/step - loss: 0.0619\n",
      "Epoch 83/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0613\n",
      "Epoch 84/1000\n",
      "60/60 [==============================] - 0s 492us/step - loss: 0.0603\n",
      "Epoch 85/1000\n",
      "60/60 [==============================] - 0s 497us/step - loss: 0.0597\n",
      "Epoch 86/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0588\n",
      "Epoch 87/1000\n",
      "60/60 [==============================] - 0s 482us/step - loss: 0.0583\n",
      "Epoch 88/1000\n",
      "60/60 [==============================] - 0s 464us/step - loss: 0.0573\n",
      "Epoch 89/1000\n",
      "60/60 [==============================] - 0s 463us/step - loss: 0.0568\n",
      "Epoch 90/1000\n",
      "60/60 [==============================] - 0s 569us/step - loss: 0.0556\n",
      "Epoch 91/1000\n",
      "60/60 [==============================] - 0s 679us/step - loss: 0.0554\n",
      "Epoch 92/1000\n",
      "60/60 [==============================] - 0s 557us/step - loss: 0.0546\n",
      "Epoch 93/1000\n",
      "60/60 [==============================] - 0s 506us/step - loss: 0.0540\n",
      "Epoch 94/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0534\n",
      "Epoch 95/1000\n",
      "60/60 [==============================] - 0s 447us/step - loss: 0.0525\n",
      "Epoch 96/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0521\n",
      "Epoch 97/1000\n",
      "60/60 [==============================] - 0s 536us/step - loss: 0.0513\n",
      "Epoch 98/1000\n",
      "60/60 [==============================] - 0s 460us/step - loss: 0.0507\n",
      "Epoch 99/1000\n",
      "60/60 [==============================] - 0s 463us/step - loss: 0.0505\n",
      "Epoch 100/1000\n",
      "60/60 [==============================] - 0s 462us/step - loss: 0.0497\n",
      "Epoch 101/1000\n",
      "60/60 [==============================] - 0s 508us/step - loss: 0.0492\n",
      "Epoch 102/1000\n",
      "60/60 [==============================] - 0s 487us/step - loss: 0.0486\n",
      "Epoch 103/1000\n",
      "60/60 [==============================] - 0s 543us/step - loss: 0.0481\n",
      "Epoch 104/1000\n",
      "60/60 [==============================] - 0s 493us/step - loss: 0.0475\n",
      "Epoch 105/1000\n",
      "60/60 [==============================] - 0s 498us/step - loss: 0.0471\n",
      "Epoch 106/1000\n",
      "60/60 [==============================] - 0s 498us/step - loss: 0.0465\n",
      "Epoch 107/1000\n",
      "60/60 [==============================] - 0s 539us/step - loss: 0.0458\n",
      "Epoch 108/1000\n",
      "60/60 [==============================] - 0s 553us/step - loss: 0.0457\n",
      "Epoch 109/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0452\n",
      "Epoch 110/1000\n",
      "60/60 [==============================] - 0s 469us/step - loss: 0.0446\n",
      "Epoch 111/1000\n",
      "60/60 [==============================] - 0s 457us/step - loss: 0.0442\n",
      "Epoch 112/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0436\n",
      "Epoch 113/1000\n",
      "60/60 [==============================] - 0s 465us/step - loss: 0.0436\n",
      "Epoch 114/1000\n",
      "60/60 [==============================] - 0s 467us/step - loss: 0.0426\n",
      "Epoch 115/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0427\n",
      "Epoch 116/1000\n",
      "60/60 [==============================] - 0s 472us/step - loss: 0.0419\n",
      "Epoch 117/1000\n",
      "60/60 [==============================] - 0s 462us/step - loss: 0.0419\n",
      "Epoch 118/1000\n",
      "60/60 [==============================] - 0s 472us/step - loss: 0.0415\n",
      "Epoch 119/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0411\n",
      "Epoch 120/1000\n",
      "60/60 [==============================] - 0s 465us/step - loss: 0.0407\n",
      "Epoch 121/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0404\n",
      "Epoch 122/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0399\n",
      "Epoch 123/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0395\n",
      "Epoch 124/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0392\n",
      "Epoch 125/1000\n",
      "60/60 [==============================] - 0s 527us/step - loss: 0.0388\n",
      "Epoch 126/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0387\n",
      "Epoch 127/1000\n",
      "60/60 [==============================] - 0s 465us/step - loss: 0.0383\n",
      "Epoch 128/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0377\n",
      "Epoch 129/1000\n",
      "60/60 [==============================] - 0s 539us/step - loss: 0.0378\n",
      "Epoch 130/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0373\n",
      "Epoch 131/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0372\n",
      "Epoch 132/1000\n",
      "60/60 [==============================] - 0s 466us/step - loss: 0.0367\n",
      "Epoch 133/1000\n",
      "60/60 [==============================] - 0s 554us/step - loss: 0.0365\n",
      "Epoch 134/1000\n",
      "60/60 [==============================] - 0s 536us/step - loss: 0.0364\n",
      "Epoch 135/1000\n",
      "60/60 [==============================] - 0s 494us/step - loss: 0.0361\n",
      "Epoch 136/1000\n",
      "60/60 [==============================] - 0s 502us/step - loss: 0.0356\n",
      "Epoch 137/1000\n",
      "60/60 [==============================] - 0s 504us/step - loss: 0.0357\n",
      "Epoch 138/1000\n",
      "60/60 [==============================] - 0s 505us/step - loss: 0.0353\n",
      "Epoch 139/1000\n",
      "60/60 [==============================] - 0s 516us/step - loss: 0.0351\n",
      "Epoch 140/1000\n",
      "60/60 [==============================] - 0s 492us/step - loss: 0.0348\n",
      "Epoch 141/1000\n",
      "60/60 [==============================] - 0s 498us/step - loss: 0.0344\n",
      "Epoch 142/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0343\n",
      "Epoch 143/1000\n",
      "60/60 [==============================] - 0s 531us/step - loss: 0.0339\n",
      "Epoch 144/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.0339\n",
      "Epoch 145/1000\n",
      "60/60 [==============================] - 0s 490us/step - loss: 0.0336\n",
      "Epoch 146/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0336\n",
      "Epoch 147/1000\n",
      "60/60 [==============================] - 0s 503us/step - loss: 0.0331\n",
      "Epoch 148/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0330\n",
      "Epoch 149/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0327\n",
      "Epoch 150/1000\n",
      "60/60 [==============================] - 0s 495us/step - loss: 0.0327\n",
      "Epoch 151/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0325\n",
      "Epoch 152/1000\n",
      "60/60 [==============================] - 0s 482us/step - loss: 0.0323\n",
      "Epoch 153/1000\n",
      "60/60 [==============================] - 0s 509us/step - loss: 0.0322\n",
      "Epoch 154/1000\n",
      "60/60 [==============================] - 0s 490us/step - loss: 0.0319\n",
      "Epoch 155/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0318\n",
      "Epoch 156/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0317\n",
      "Epoch 157/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0315\n",
      "Epoch 158/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0313\n",
      "Epoch 159/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0310\n",
      "Epoch 160/1000\n",
      "60/60 [==============================] - 0s 511us/step - loss: 0.0309\n",
      "Epoch 161/1000\n",
      "60/60 [==============================] - 0s 467us/step - loss: 0.0308\n",
      "Epoch 162/1000\n",
      "60/60 [==============================] - 0s 464us/step - loss: 0.0307\n",
      "Epoch 163/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0306\n",
      "Epoch 164/1000\n",
      "60/60 [==============================] - 0s 490us/step - loss: 0.0304\n",
      "Epoch 165/1000\n",
      "60/60 [==============================] - 0s 500us/step - loss: 0.0303\n",
      "Epoch 166/1000\n",
      "60/60 [==============================] - 0s 574us/step - loss: 0.0301\n",
      "Epoch 167/1000\n",
      "60/60 [==============================] - 0s 571us/step - loss: 0.0299\n",
      "Epoch 168/1000\n",
      "60/60 [==============================] - 0s 555us/step - loss: 0.0298\n",
      "Epoch 169/1000\n",
      "60/60 [==============================] - 0s 567us/step - loss: 0.0295\n",
      "Epoch 170/1000\n",
      "60/60 [==============================] - 0s 555us/step - loss: 0.0296\n",
      "Epoch 171/1000\n",
      "60/60 [==============================] - 0s 562us/step - loss: 0.0294\n",
      "Epoch 172/1000\n",
      "60/60 [==============================] - 0s 573us/step - loss: 0.0293\n",
      "Epoch 173/1000\n",
      "60/60 [==============================] - 0s 558us/step - loss: 0.0291\n",
      "Epoch 174/1000\n",
      "60/60 [==============================] - 0s 573us/step - loss: 0.0290\n",
      "Epoch 175/1000\n",
      "60/60 [==============================] - 0s 584us/step - loss: 0.0290\n",
      "Epoch 176/1000\n",
      "60/60 [==============================] - 0s 585us/step - loss: 0.0289\n",
      "Epoch 177/1000\n",
      "60/60 [==============================] - 0s 581us/step - loss: 0.0288\n",
      "Epoch 178/1000\n",
      "60/60 [==============================] - 0s 570us/step - loss: 0.0286\n",
      "Epoch 179/1000\n",
      "60/60 [==============================] - 0s 572us/step - loss: 0.0285\n",
      "Epoch 180/1000\n",
      "60/60 [==============================] - 0s 497us/step - loss: 0.0284\n",
      "Epoch 181/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0283\n",
      "Epoch 182/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0282\n",
      "Epoch 183/1000\n",
      "60/60 [==============================] - 0s 502us/step - loss: 0.0281\n",
      "Epoch 184/1000\n",
      "60/60 [==============================] - 0s 493us/step - loss: 0.0280\n",
      "Epoch 185/1000\n",
      "60/60 [==============================] - 0s 497us/step - loss: 0.0279\n",
      "Epoch 186/1000\n",
      "60/60 [==============================] - 0s 497us/step - loss: 0.0278\n",
      "Epoch 187/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0278\n",
      "Epoch 188/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0277\n",
      "Epoch 189/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0275\n",
      "Epoch 190/1000\n",
      "60/60 [==============================] - 0s 488us/step - loss: 0.0275\n",
      "Epoch 191/1000\n",
      "60/60 [==============================] - 0s 487us/step - loss: 0.0274\n",
      "Epoch 192/1000\n",
      "60/60 [==============================] - 0s 558us/step - loss: 0.0273\n",
      "Epoch 193/1000\n",
      "60/60 [==============================] - 0s 612us/step - loss: 0.0271\n",
      "Epoch 194/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 620us/step - loss: 0.0271\n",
      "Epoch 195/1000\n",
      "60/60 [==============================] - 0s 531us/step - loss: 0.0270\n",
      "Epoch 196/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0270\n",
      "Epoch 197/1000\n",
      "60/60 [==============================] - 0s 494us/step - loss: 0.0269\n",
      "Epoch 198/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0268\n",
      "Epoch 199/1000\n",
      "60/60 [==============================] - 0s 466us/step - loss: 0.0267\n",
      "Epoch 200/1000\n",
      "60/60 [==============================] - 0s 461us/step - loss: 0.0267\n",
      "Epoch 201/1000\n",
      "60/60 [==============================] - 0s 466us/step - loss: 0.0266\n",
      "Epoch 202/1000\n",
      "60/60 [==============================] - 0s 462us/step - loss: 0.0266\n",
      "Epoch 203/1000\n",
      "60/60 [==============================] - 0s 472us/step - loss: 0.0265\n",
      "Epoch 204/1000\n",
      "60/60 [==============================] - 0s 472us/step - loss: 0.0264\n",
      "Epoch 205/1000\n",
      "60/60 [==============================] - 0s 579us/step - loss: 0.0263\n",
      "Epoch 206/1000\n",
      "60/60 [==============================] - 0s 562us/step - loss: 0.0262\n",
      "Epoch 207/1000\n",
      "60/60 [==============================] - 0s 579us/step - loss: 0.0262\n",
      "Epoch 208/1000\n",
      "60/60 [==============================] - 0s 578us/step - loss: 0.0261\n",
      "Epoch 209/1000\n",
      "60/60 [==============================] - 0s 591us/step - loss: 0.0261\n",
      "Epoch 210/1000\n",
      "60/60 [==============================] - 0s 581us/step - loss: 0.0260\n",
      "Epoch 211/1000\n",
      "60/60 [==============================] - 0s 556us/step - loss: 0.0259\n",
      "Epoch 212/1000\n",
      "60/60 [==============================] - 0s 493us/step - loss: 0.0259\n",
      "Epoch 213/1000\n",
      "60/60 [==============================] - 0s 553us/step - loss: 0.0258\n",
      "Epoch 214/1000\n",
      "60/60 [==============================] - 0s 581us/step - loss: 0.0258\n",
      "Epoch 215/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0257\n",
      "Epoch 216/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.0256\n",
      "Epoch 217/1000\n",
      "60/60 [==============================] - 0s 504us/step - loss: 0.0256\n",
      "Epoch 218/1000\n",
      "60/60 [==============================] - 0s 567us/step - loss: 0.0255\n",
      "Epoch 219/1000\n",
      "60/60 [==============================] - 0s 494us/step - loss: 0.0255\n",
      "Epoch 220/1000\n",
      "60/60 [==============================] - 0s 509us/step - loss: 0.0254\n",
      "Epoch 221/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.0254\n",
      "Epoch 222/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0253\n",
      "Epoch 223/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0253\n",
      "Epoch 224/1000\n",
      "60/60 [==============================] - 0s 635us/step - loss: 0.0252\n",
      "Epoch 225/1000\n",
      "60/60 [==============================] - 0s 513us/step - loss: 0.0251\n",
      "Epoch 226/1000\n",
      "60/60 [==============================] - 0s 511us/step - loss: 0.0251\n",
      "Epoch 227/1000\n",
      "60/60 [==============================] - 0s 469us/step - loss: 0.0251\n",
      "Epoch 228/1000\n",
      "60/60 [==============================] - 0s 580us/step - loss: 0.0250\n",
      "Epoch 229/1000\n",
      "60/60 [==============================] - 0s 478us/step - loss: 0.0249\n",
      "Epoch 230/1000\n",
      "60/60 [==============================] - 0s 488us/step - loss: 0.0249\n",
      "Epoch 231/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.0248\n",
      "Epoch 232/1000\n",
      "60/60 [==============================] - 0s 504us/step - loss: 0.0248\n",
      "Epoch 233/1000\n",
      "60/60 [==============================] - 0s 591us/step - loss: 0.0247\n",
      "Epoch 234/1000\n",
      "60/60 [==============================] - 0s 574us/step - loss: 0.0247\n",
      "Epoch 235/1000\n",
      "60/60 [==============================] - 0s 499us/step - loss: 0.0247\n",
      "Epoch 236/1000\n",
      "60/60 [==============================] - 0s 461us/step - loss: 0.0246\n",
      "Epoch 237/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0246\n",
      "Epoch 238/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0245\n",
      "Epoch 239/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0245\n",
      "Epoch 240/1000\n",
      "60/60 [==============================] - 0s 486us/step - loss: 0.0244\n",
      "Epoch 241/1000\n",
      "60/60 [==============================] - 0s 471us/step - loss: 0.0244\n",
      "Epoch 242/1000\n",
      "60/60 [==============================] - 0s 533us/step - loss: 0.0244\n",
      "Epoch 243/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0243\n",
      "Epoch 244/1000\n",
      "60/60 [==============================] - 0s 503us/step - loss: 0.0243\n",
      "Epoch 245/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0242\n",
      "Epoch 246/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0242\n",
      "Epoch 247/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0241\n",
      "Epoch 248/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0241\n",
      "Epoch 249/1000\n",
      "60/60 [==============================] - 0s 466us/step - loss: 0.0240\n",
      "Epoch 250/1000\n",
      "60/60 [==============================] - 0s 488us/step - loss: 0.0240\n",
      "Epoch 251/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0240\n",
      "Epoch 252/1000\n",
      "60/60 [==============================] - 0s 471us/step - loss: 0.0239\n",
      "Epoch 253/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0239\n",
      "Epoch 254/1000\n",
      "60/60 [==============================] - 0s 558us/step - loss: 0.0239\n",
      "Epoch 255/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0238\n",
      "Epoch 256/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0238\n",
      "Epoch 257/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0238\n",
      "Epoch 258/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0237\n",
      "Epoch 259/1000\n",
      "60/60 [==============================] - 0s 493us/step - loss: 0.0237\n",
      "Epoch 260/1000\n",
      "60/60 [==============================] - 0s 490us/step - loss: 0.0237\n",
      "Epoch 261/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0236\n",
      "Epoch 262/1000\n",
      "60/60 [==============================] - 0s 486us/step - loss: 0.0236\n",
      "Epoch 263/1000\n",
      "60/60 [==============================] - 0s 493us/step - loss: 0.0235\n",
      "Epoch 264/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0235\n",
      "Epoch 265/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0235\n",
      "Epoch 266/1000\n",
      "60/60 [==============================] - 0s 572us/step - loss: 0.0234\n",
      "Epoch 267/1000\n",
      "60/60 [==============================] - 0s 672us/step - loss: 0.0234\n",
      "Epoch 268/1000\n",
      "60/60 [==============================] - 0s 625us/step - loss: 0.0234\n",
      "Epoch 269/1000\n",
      "60/60 [==============================] - 0s 585us/step - loss: 0.0233\n",
      "Epoch 270/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0233\n",
      "Epoch 271/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0233\n",
      "Epoch 272/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.0232\n",
      "Epoch 273/1000\n",
      "60/60 [==============================] - 0s 502us/step - loss: 0.0232\n",
      "Epoch 274/1000\n",
      "60/60 [==============================] - 0s 487us/step - loss: 0.0232\n",
      "Epoch 275/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0231\n",
      "Epoch 276/1000\n",
      "60/60 [==============================] - 0s 468us/step - loss: 0.0231\n",
      "Epoch 277/1000\n",
      "60/60 [==============================] - 0s 464us/step - loss: 0.0231\n",
      "Epoch 278/1000\n",
      "60/60 [==============================] - 0s 642us/step - loss: 0.0230\n",
      "Epoch 279/1000\n",
      "60/60 [==============================] - 0s 483us/step - loss: 0.0230\n",
      "Epoch 280/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0230\n",
      "Epoch 281/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0229\n",
      "Epoch 282/1000\n",
      "60/60 [==============================] - 0s 637us/step - loss: 0.0229\n",
      "Epoch 283/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0229\n",
      "Epoch 284/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0228\n",
      "Epoch 285/1000\n",
      "60/60 [==============================] - 0s 531us/step - loss: 0.0228\n",
      "Epoch 286/1000\n",
      "60/60 [==============================] - 0s 611us/step - loss: 0.0228\n",
      "Epoch 287/1000\n",
      "60/60 [==============================] - 0s 579us/step - loss: 0.0228\n",
      "Epoch 288/1000\n",
      "60/60 [==============================] - 0s 585us/step - loss: 0.0227\n",
      "Epoch 289/1000\n",
      "60/60 [==============================] - 0s 584us/step - loss: 0.0227\n",
      "Epoch 290/1000\n",
      "60/60 [==============================] - 0s 519us/step - loss: 0.0227\n",
      "Epoch 291/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0226\n",
      "Epoch 292/1000\n",
      "60/60 [==============================] - 0s 489us/step - loss: 0.0226\n",
      "Epoch 293/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0226\n",
      "Epoch 294/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0225\n",
      "Epoch 295/1000\n",
      "60/60 [==============================] - 0s 478us/step - loss: 0.0225\n",
      "Epoch 296/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0225\n",
      "Epoch 297/1000\n",
      "60/60 [==============================] - 0s 546us/step - loss: 0.0225\n",
      "Epoch 298/1000\n",
      "60/60 [==============================] - 0s 551us/step - loss: 0.0224\n",
      "Epoch 299/1000\n",
      "60/60 [==============================] - 0s 532us/step - loss: 0.0224\n",
      "Epoch 300/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0224\n",
      "Epoch 301/1000\n",
      "60/60 [==============================] - 0s 461us/step - loss: 0.0224\n",
      "Epoch 302/1000\n",
      "60/60 [==============================] - 0s 463us/step - loss: 0.0223\n",
      "Epoch 303/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0223\n",
      "Epoch 304/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0223\n",
      "Epoch 305/1000\n",
      "60/60 [==============================] - 0s 469us/step - loss: 0.0223\n",
      "Epoch 306/1000\n",
      "60/60 [==============================] - 0s 489us/step - loss: 0.0222\n",
      "Epoch 307/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0222\n",
      "Epoch 308/1000\n",
      "60/60 [==============================] - 0s 482us/step - loss: 0.0222\n",
      "Epoch 309/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0221\n",
      "Epoch 310/1000\n",
      "60/60 [==============================] - 0s 498us/step - loss: 0.0221\n",
      "Epoch 311/1000\n",
      "60/60 [==============================] - 0s 506us/step - loss: 0.0221\n",
      "Epoch 312/1000\n",
      "60/60 [==============================] - 0s 561us/step - loss: 0.0221\n",
      "Epoch 313/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0220\n",
      "Epoch 314/1000\n",
      "60/60 [==============================] - 0s 494us/step - loss: 0.0220\n",
      "Epoch 315/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0220\n",
      "Epoch 316/1000\n",
      "60/60 [==============================] - 0s 522us/step - loss: 0.0220\n",
      "Epoch 317/1000\n",
      "60/60 [==============================] - 0s 488us/step - loss: 0.0219\n",
      "Epoch 318/1000\n",
      "60/60 [==============================] - 0s 492us/step - loss: 0.0219\n",
      "Epoch 319/1000\n",
      "60/60 [==============================] - 0s 487us/step - loss: 0.0219\n",
      "Epoch 320/1000\n",
      "60/60 [==============================] - 0s 503us/step - loss: 0.0219\n",
      "Epoch 321/1000\n",
      "60/60 [==============================] - 0s 492us/step - loss: 0.0218\n",
      "Epoch 322/1000\n",
      "60/60 [==============================] - 0s 518us/step - loss: 0.0218\n",
      "Epoch 323/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0218\n",
      "Epoch 324/1000\n",
      "60/60 [==============================] - 0s 497us/step - loss: 0.0218\n",
      "Epoch 325/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0217\n",
      "Epoch 326/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0217\n",
      "Epoch 327/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0217\n",
      "Epoch 328/1000\n",
      "60/60 [==============================] - 0s 590us/step - loss: 0.0217\n",
      "Epoch 329/1000\n",
      "60/60 [==============================] - 0s 566us/step - loss: 0.0216\n",
      "Epoch 330/1000\n",
      "60/60 [==============================] - 0s 638us/step - loss: 0.0216\n",
      "Epoch 331/1000\n",
      "60/60 [==============================] - 0s 591us/step - loss: 0.0216\n",
      "Epoch 332/1000\n",
      "60/60 [==============================] - 0s 621us/step - loss: 0.0216\n",
      "Epoch 333/1000\n",
      "60/60 [==============================] - 0s 591us/step - loss: 0.0215\n",
      "Epoch 334/1000\n",
      "60/60 [==============================] - 0s 601us/step - loss: 0.0215\n",
      "Epoch 335/1000\n",
      "60/60 [==============================] - 0s 574us/step - loss: 0.0215\n",
      "Epoch 336/1000\n",
      "60/60 [==============================] - 0s 617us/step - loss: 0.0215\n",
      "Epoch 337/1000\n",
      "60/60 [==============================] - 0s 520us/step - loss: 0.0214\n",
      "Epoch 338/1000\n",
      "60/60 [==============================] - 0s 490us/step - loss: 0.0214\n",
      "Epoch 339/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0214\n",
      "Epoch 340/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0214\n",
      "Epoch 341/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0214\n",
      "Epoch 342/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0213\n",
      "Epoch 343/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0213\n",
      "Epoch 344/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0213\n",
      "Epoch 345/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0213\n",
      "Epoch 346/1000\n",
      "60/60 [==============================] - 0s 488us/step - loss: 0.0212\n",
      "Epoch 347/1000\n",
      "60/60 [==============================] - 0s 524us/step - loss: 0.0212\n",
      "Epoch 348/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.0212\n",
      "Epoch 349/1000\n",
      "60/60 [==============================] - 0s 469us/step - loss: 0.0212\n",
      "Epoch 350/1000\n",
      "60/60 [==============================] - 0s 545us/step - loss: 0.0211\n",
      "Epoch 351/1000\n",
      "60/60 [==============================] - 0s 497us/step - loss: 0.0211\n",
      "Epoch 352/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0211\n",
      "Epoch 353/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.0211\n",
      "Epoch 354/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0211\n",
      "Epoch 355/1000\n",
      "60/60 [==============================] - 0s 514us/step - loss: 0.0210\n",
      "Epoch 356/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0210\n",
      "Epoch 357/1000\n",
      "60/60 [==============================] - 0s 488us/step - loss: 0.0210\n",
      "Epoch 358/1000\n",
      "60/60 [==============================] - 0s 486us/step - loss: 0.0210\n",
      "Epoch 359/1000\n",
      "60/60 [==============================] - 0s 514us/step - loss: 0.0209\n",
      "Epoch 360/1000\n",
      "60/60 [==============================] - 0s 505us/step - loss: 0.0209\n",
      "Epoch 361/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0209\n",
      "Epoch 362/1000\n",
      "60/60 [==============================] - 0s 486us/step - loss: 0.0209\n",
      "Epoch 363/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0208\n",
      "Epoch 364/1000\n",
      "60/60 [==============================] - 0s 496us/step - loss: 0.0208\n",
      "Epoch 365/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.0208\n",
      "Epoch 366/1000\n",
      "60/60 [==============================] - 0s 561us/step - loss: 0.0208\n",
      "Epoch 367/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0207\n",
      "Epoch 368/1000\n",
      "60/60 [==============================] - 0s 502us/step - loss: 0.0207\n",
      "Epoch 369/1000\n",
      "60/60 [==============================] - 0s 515us/step - loss: 0.0207\n",
      "Epoch 370/1000\n",
      "60/60 [==============================] - 0s 478us/step - loss: 0.0207\n",
      "Epoch 371/1000\n",
      "60/60 [==============================] - 0s 497us/step - loss: 0.0207\n",
      "Epoch 372/1000\n",
      "60/60 [==============================] - 0s 498us/step - loss: 0.0206\n",
      "Epoch 373/1000\n",
      "60/60 [==============================] - 0s 604us/step - loss: 0.0206\n",
      "Epoch 374/1000\n",
      "60/60 [==============================] - 0s 712us/step - loss: 0.0206\n",
      "Epoch 375/1000\n",
      "60/60 [==============================] - 0s 494us/step - loss: 0.0206\n",
      "Epoch 376/1000\n",
      "60/60 [==============================] - 0s 488us/step - loss: 0.0205\n",
      "Epoch 377/1000\n",
      "60/60 [==============================] - 0s 467us/step - loss: 0.0205\n",
      "Epoch 378/1000\n",
      "60/60 [==============================] - 0s 560us/step - loss: 0.0205\n",
      "Epoch 379/1000\n",
      "60/60 [==============================] - 0s 515us/step - loss: 0.0205\n",
      "Epoch 380/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0204\n",
      "Epoch 381/1000\n",
      "60/60 [==============================] - 0s 550us/step - loss: 0.0204\n",
      "Epoch 382/1000\n",
      "60/60 [==============================] - 0s 589us/step - loss: 0.0204\n",
      "Epoch 383/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0204\n",
      "Epoch 384/1000\n",
      "60/60 [==============================] - 0s 533us/step - loss: 0.0203\n",
      "Epoch 385/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0203\n",
      "Epoch 386/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 466us/step - loss: 0.0203\n",
      "Epoch 387/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0203\n",
      "Epoch 388/1000\n",
      "60/60 [==============================] - 0s 487us/step - loss: 0.0202\n",
      "Epoch 389/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0202\n",
      "Epoch 390/1000\n",
      "60/60 [==============================] - 0s 472us/step - loss: 0.0202\n",
      "Epoch 391/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0202\n",
      "Epoch 392/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0201\n",
      "Epoch 393/1000\n",
      "60/60 [==============================] - 0s 509us/step - loss: 0.0201\n",
      "Epoch 394/1000\n",
      "60/60 [==============================] - 0s 466us/step - loss: 0.0201\n",
      "Epoch 395/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0201\n",
      "Epoch 396/1000\n",
      "60/60 [==============================] - 0s 460us/step - loss: 0.0200\n",
      "Epoch 397/1000\n",
      "60/60 [==============================] - 0s 471us/step - loss: 0.0200\n",
      "Epoch 398/1000\n",
      "60/60 [==============================] - 0s 469us/step - loss: 0.0200\n",
      "Epoch 399/1000\n",
      "60/60 [==============================] - 0s 472us/step - loss: 0.0200\n",
      "Epoch 400/1000\n",
      "60/60 [==============================] - 0s 507us/step - loss: 0.0199\n",
      "Epoch 401/1000\n",
      "60/60 [==============================] - 0s 582us/step - loss: 0.0199\n",
      "Epoch 402/1000\n",
      "60/60 [==============================] - 0s 596us/step - loss: 0.0199\n",
      "Epoch 403/1000\n",
      "60/60 [==============================] - 0s 580us/step - loss: 0.0198\n",
      "Epoch 404/1000\n",
      "60/60 [==============================] - 0s 593us/step - loss: 0.0198\n",
      "Epoch 405/1000\n",
      "60/60 [==============================] - 0s 597us/step - loss: 0.0198\n",
      "Epoch 406/1000\n",
      "60/60 [==============================] - 0s 617us/step - loss: 0.0198\n",
      "Epoch 407/1000\n",
      "60/60 [==============================] - 0s 581us/step - loss: 0.0197\n",
      "Epoch 408/1000\n",
      "60/60 [==============================] - 0s 647us/step - loss: 0.0197\n",
      "Epoch 409/1000\n",
      "60/60 [==============================] - 0s 592us/step - loss: 0.0197\n",
      "Epoch 410/1000\n",
      "60/60 [==============================] - 0s 524us/step - loss: 0.0197\n",
      "Epoch 411/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0196\n",
      "Epoch 412/1000\n",
      "60/60 [==============================] - 0s 464us/step - loss: 0.0196\n",
      "Epoch 413/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0196\n",
      "Epoch 414/1000\n",
      "60/60 [==============================] - 0s 583us/step - loss: 0.0195\n",
      "Epoch 415/1000\n",
      "60/60 [==============================] - 0s 597us/step - loss: 0.0195\n",
      "Epoch 416/1000\n",
      "60/60 [==============================] - 0s 601us/step - loss: 0.0195\n",
      "Epoch 417/1000\n",
      "60/60 [==============================] - 0s 574us/step - loss: 0.0195\n",
      "Epoch 418/1000\n",
      "60/60 [==============================] - 0s 592us/step - loss: 0.0194\n",
      "Epoch 419/1000\n",
      "60/60 [==============================] - 0s 595us/step - loss: 0.0194\n",
      "Epoch 420/1000\n",
      "60/60 [==============================] - 0s 570us/step - loss: 0.0194\n",
      "Epoch 421/1000\n",
      "60/60 [==============================] - 0s 587us/step - loss: 0.0193\n",
      "Epoch 422/1000\n",
      "60/60 [==============================] - 0s 572us/step - loss: 0.0193\n",
      "Epoch 423/1000\n",
      "60/60 [==============================] - 0s 556us/step - loss: 0.0193\n",
      "Epoch 424/1000\n",
      "60/60 [==============================] - 0s 471us/step - loss: 0.0193\n",
      "Epoch 425/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0192\n",
      "Epoch 426/1000\n",
      "60/60 [==============================] - 0s 458us/step - loss: 0.0192\n",
      "Epoch 427/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0192\n",
      "Epoch 428/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.0192\n",
      "Epoch 429/1000\n",
      "60/60 [==============================] - 0s 487us/step - loss: 0.0191\n",
      "Epoch 430/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0191\n",
      "Epoch 431/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0191\n",
      "Epoch 432/1000\n",
      "60/60 [==============================] - 0s 486us/step - loss: 0.0190\n",
      "Epoch 433/1000\n",
      "60/60 [==============================] - 0s 464us/step - loss: 0.0190\n",
      "Epoch 434/1000\n",
      "60/60 [==============================] - 0s 461us/step - loss: 0.0190\n",
      "Epoch 435/1000\n",
      "60/60 [==============================] - 0s 504us/step - loss: 0.0190\n",
      "Epoch 436/1000\n",
      "60/60 [==============================] - 0s 508us/step - loss: 0.0189\n",
      "Epoch 437/1000\n",
      "60/60 [==============================] - 0s 529us/step - loss: 0.0189\n",
      "Epoch 438/1000\n",
      "60/60 [==============================] - 0s 530us/step - loss: 0.0189\n",
      "Epoch 439/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0189\n",
      "Epoch 440/1000\n",
      "60/60 [==============================] - 0s 459us/step - loss: 0.0188\n",
      "Epoch 441/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0188\n",
      "Epoch 442/1000\n",
      "60/60 [==============================] - 0s 467us/step - loss: 0.0188\n",
      "Epoch 443/1000\n",
      "60/60 [==============================] - 0s 496us/step - loss: 0.0188\n",
      "Epoch 444/1000\n",
      "60/60 [==============================] - 0s 466us/step - loss: 0.0187\n",
      "Epoch 445/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0187\n",
      "Epoch 446/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0187\n",
      "Epoch 447/1000\n",
      "60/60 [==============================] - 0s 478us/step - loss: 0.0187\n",
      "Epoch 448/1000\n",
      "60/60 [==============================] - 0s 529us/step - loss: 0.0186\n",
      "Epoch 449/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0186\n",
      "Epoch 450/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0186\n",
      "Epoch 451/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.0186\n",
      "Epoch 452/1000\n",
      "60/60 [==============================] - 0s 496us/step - loss: 0.0185\n",
      "Epoch 453/1000\n",
      "60/60 [==============================] - 0s 518us/step - loss: 0.0185\n",
      "Epoch 454/1000\n",
      "60/60 [==============================] - 0s 463us/step - loss: 0.0185\n",
      "Epoch 455/1000\n",
      "60/60 [==============================] - 0s 487us/step - loss: 0.0185\n",
      "Epoch 456/1000\n",
      "60/60 [==============================] - 0s 461us/step - loss: 0.0184\n",
      "Epoch 457/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0184\n",
      "Epoch 458/1000\n",
      "60/60 [==============================] - 0s 467us/step - loss: 0.0184\n",
      "Epoch 459/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0184\n",
      "Epoch 460/1000\n",
      "60/60 [==============================] - 0s 510us/step - loss: 0.0184\n",
      "Epoch 461/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0183\n",
      "Epoch 462/1000\n",
      "60/60 [==============================] - 0s 465us/step - loss: 0.0183\n",
      "Epoch 463/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0183\n",
      "Epoch 464/1000\n",
      "60/60 [==============================] - 0s 508us/step - loss: 0.0183\n",
      "Epoch 465/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0182\n",
      "Epoch 466/1000\n",
      "60/60 [==============================] - 0s 462us/step - loss: 0.0182\n",
      "Epoch 467/1000\n",
      "60/60 [==============================] - 0s 458us/step - loss: 0.0182\n",
      "Epoch 468/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0182\n",
      "Epoch 469/1000\n",
      "60/60 [==============================] - 0s 506us/step - loss: 0.0182\n",
      "Epoch 470/1000\n",
      "60/60 [==============================] - 0s 458us/step - loss: 0.0181\n",
      "Epoch 471/1000\n",
      "60/60 [==============================] - 0s 487us/step - loss: 0.0181\n",
      "Epoch 472/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0181\n",
      "Epoch 473/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0181\n",
      "Epoch 474/1000\n",
      "60/60 [==============================] - 0s 520us/step - loss: 0.0181\n",
      "Epoch 475/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0180\n",
      "Epoch 476/1000\n",
      "60/60 [==============================] - 0s 500us/step - loss: 0.0180\n",
      "Epoch 477/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0180\n",
      "Epoch 478/1000\n",
      "60/60 [==============================] - 0s 471us/step - loss: 0.0180\n",
      "Epoch 479/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0180\n",
      "Epoch 480/1000\n",
      "60/60 [==============================] - 0s 465us/step - loss: 0.0179\n",
      "Epoch 481/1000\n",
      "60/60 [==============================] - 0s 483us/step - loss: 0.0179\n",
      "Epoch 482/1000\n",
      "60/60 [==============================] - 0s 460us/step - loss: 0.0179\n",
      "Epoch 483/1000\n",
      "60/60 [==============================] - 0s 499us/step - loss: 0.0179\n",
      "Epoch 484/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0179\n",
      "Epoch 485/1000\n",
      "60/60 [==============================] - 0s 454us/step - loss: 0.0178\n",
      "Epoch 486/1000\n",
      "60/60 [==============================] - 0s 511us/step - loss: 0.0178\n",
      "Epoch 487/1000\n",
      "60/60 [==============================] - 0s 483us/step - loss: 0.0178\n",
      "Epoch 488/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0178\n",
      "Epoch 489/1000\n",
      "60/60 [==============================] - 0s 483us/step - loss: 0.0178\n",
      "Epoch 490/1000\n",
      "60/60 [==============================] - 0s 468us/step - loss: 0.0178\n",
      "Epoch 491/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0177\n",
      "Epoch 492/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.0177\n",
      "Epoch 493/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0177\n",
      "Epoch 494/1000\n",
      "60/60 [==============================] - 0s 550us/step - loss: 0.0177\n",
      "Epoch 495/1000\n",
      "60/60 [==============================] - 0s 619us/step - loss: 0.0177\n",
      "Epoch 496/1000\n",
      "60/60 [==============================] - 0s 586us/step - loss: 0.0176\n",
      "Epoch 497/1000\n",
      "60/60 [==============================] - 0s 587us/step - loss: 0.0176\n",
      "Epoch 498/1000\n",
      "60/60 [==============================] - 0s 608us/step - loss: 0.0176\n",
      "Epoch 499/1000\n",
      "60/60 [==============================] - 0s 558us/step - loss: 0.0176\n",
      "Epoch 500/1000\n",
      "60/60 [==============================] - 0s 573us/step - loss: 0.0176\n",
      "Epoch 501/1000\n",
      "60/60 [==============================] - 0s 580us/step - loss: 0.0176\n",
      "Epoch 502/1000\n",
      "60/60 [==============================] - 0s 621us/step - loss: 0.0175\n",
      "Epoch 503/1000\n",
      "60/60 [==============================] - 0s 624us/step - loss: 0.0175\n",
      "Epoch 504/1000\n",
      "60/60 [==============================] - 0s 601us/step - loss: 0.0175\n",
      "Epoch 505/1000\n",
      "60/60 [==============================] - 0s 586us/step - loss: 0.0175\n",
      "Epoch 506/1000\n",
      "60/60 [==============================] - 0s 549us/step - loss: 0.0175\n",
      "Epoch 507/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0175\n",
      "Epoch 508/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0174\n",
      "Epoch 509/1000\n",
      "60/60 [==============================] - 0s 488us/step - loss: 0.0174\n",
      "Epoch 510/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0174\n",
      "Epoch 511/1000\n",
      "60/60 [==============================] - 0s 563us/step - loss: 0.0174\n",
      "Epoch 512/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0174\n",
      "Epoch 513/1000\n",
      "60/60 [==============================] - 0s 486us/step - loss: 0.0174\n",
      "Epoch 514/1000\n",
      "60/60 [==============================] - 0s 504us/step - loss: 0.0173\n",
      "Epoch 515/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0173\n",
      "Epoch 516/1000\n",
      "60/60 [==============================] - 0s 466us/step - loss: 0.0173\n",
      "Epoch 517/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0173\n",
      "Epoch 518/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0173\n",
      "Epoch 519/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0173\n",
      "Epoch 520/1000\n",
      "60/60 [==============================] - 0s 489us/step - loss: 0.0172\n",
      "Epoch 521/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0172\n",
      "Epoch 522/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0172\n",
      "Epoch 523/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0172\n",
      "Epoch 524/1000\n",
      "60/60 [==============================] - 0s 465us/step - loss: 0.0172\n",
      "Epoch 525/1000\n",
      "60/60 [==============================] - 0s 465us/step - loss: 0.0172\n",
      "Epoch 526/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0172\n",
      "Epoch 527/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0171\n",
      "Epoch 528/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0171\n",
      "Epoch 529/1000\n",
      "60/60 [==============================] - 0s 490us/step - loss: 0.0171\n",
      "Epoch 530/1000\n",
      "60/60 [==============================] - 0s 503us/step - loss: 0.0171\n",
      "Epoch 531/1000\n",
      "60/60 [==============================] - 0s 488us/step - loss: 0.0171\n",
      "Epoch 532/1000\n",
      "60/60 [==============================] - 0s 467us/step - loss: 0.0171\n",
      "Epoch 533/1000\n",
      "60/60 [==============================] - 0s 469us/step - loss: 0.0170\n",
      "Epoch 534/1000\n",
      "60/60 [==============================] - 0s 482us/step - loss: 0.0170\n",
      "Epoch 535/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0170\n",
      "Epoch 536/1000\n",
      "60/60 [==============================] - 0s 456us/step - loss: 0.0170\n",
      "Epoch 537/1000\n",
      "60/60 [==============================] - 0s 482us/step - loss: 0.0170\n",
      "Epoch 538/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.0170\n",
      "Epoch 539/1000\n",
      "60/60 [==============================] - 0s 458us/step - loss: 0.0169\n",
      "Epoch 540/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0169\n",
      "Epoch 541/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.0169\n",
      "Epoch 542/1000\n",
      "60/60 [==============================] - 0s 496us/step - loss: 0.0169\n",
      "Epoch 543/1000\n",
      "60/60 [==============================] - 0s 582us/step - loss: 0.0169\n",
      "Epoch 544/1000\n",
      "60/60 [==============================] - 0s 605us/step - loss: 0.0169\n",
      "Epoch 545/1000\n",
      "60/60 [==============================] - 0s 687us/step - loss: 0.0168\n",
      "Epoch 546/1000\n",
      "60/60 [==============================] - 0s 538us/step - loss: 0.0168\n",
      "Epoch 547/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0168\n",
      "Epoch 548/1000\n",
      "60/60 [==============================] - 0s 495us/step - loss: 0.0168\n",
      "Epoch 549/1000\n",
      "60/60 [==============================] - 0s 504us/step - loss: 0.0168\n",
      "Epoch 550/1000\n",
      "60/60 [==============================] - 0s 486us/step - loss: 0.0168\n",
      "Epoch 551/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0168\n",
      "Epoch 552/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0167\n",
      "Epoch 553/1000\n",
      "60/60 [==============================] - 0s 483us/step - loss: 0.0167\n",
      "Epoch 554/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0167\n",
      "Epoch 555/1000\n",
      "60/60 [==============================] - 0s 488us/step - loss: 0.0167\n",
      "Epoch 556/1000\n",
      "60/60 [==============================] - 0s 494us/step - loss: 0.0167\n",
      "Epoch 557/1000\n",
      "60/60 [==============================] - 0s 509us/step - loss: 0.0167\n",
      "Epoch 558/1000\n",
      "60/60 [==============================] - 0s 518us/step - loss: 0.0166\n",
      "Epoch 559/1000\n",
      "60/60 [==============================] - 0s 567us/step - loss: 0.0166\n",
      "Epoch 560/1000\n",
      "60/60 [==============================] - 0s 590us/step - loss: 0.0166\n",
      "Epoch 561/1000\n",
      "60/60 [==============================] - 0s 482us/step - loss: 0.0166\n",
      "Epoch 562/1000\n",
      "60/60 [==============================] - 0s 458us/step - loss: 0.0166\n",
      "Epoch 563/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0166\n",
      "Epoch 564/1000\n",
      "60/60 [==============================] - 0s 462us/step - loss: 0.0165\n",
      "Epoch 565/1000\n",
      "60/60 [==============================] - 0s 489us/step - loss: 0.0165\n",
      "Epoch 566/1000\n",
      "60/60 [==============================] - 0s 482us/step - loss: 0.0165\n",
      "Epoch 567/1000\n",
      "60/60 [==============================] - 0s 525us/step - loss: 0.0165\n",
      "Epoch 568/1000\n",
      "60/60 [==============================] - 0s 540us/step - loss: 0.0165\n",
      "Epoch 569/1000\n",
      "60/60 [==============================] - 0s 506us/step - loss: 0.0165\n",
      "Epoch 570/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0165\n",
      "Epoch 571/1000\n",
      "60/60 [==============================] - 0s 469us/step - loss: 0.0164\n",
      "Epoch 572/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0164\n",
      "Epoch 573/1000\n",
      "60/60 [==============================] - 0s 463us/step - loss: 0.0164\n",
      "Epoch 574/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0164\n",
      "Epoch 575/1000\n",
      "60/60 [==============================] - 0s 506us/step - loss: 0.0164\n",
      "Epoch 576/1000\n",
      "60/60 [==============================] - 0s 532us/step - loss: 0.0164\n",
      "Epoch 577/1000\n",
      "60/60 [==============================] - 0s 496us/step - loss: 0.0163\n",
      "Epoch 578/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 509us/step - loss: 0.0163\n",
      "Epoch 579/1000\n",
      "60/60 [==============================] - 0s 490us/step - loss: 0.0163\n",
      "Epoch 580/1000\n",
      "60/60 [==============================] - 0s 496us/step - loss: 0.0163\n",
      "Epoch 581/1000\n",
      "60/60 [==============================] - 0s 482us/step - loss: 0.0163\n",
      "Epoch 582/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0163\n",
      "Epoch 583/1000\n",
      "60/60 [==============================] - 0s 519us/step - loss: 0.0163\n",
      "Epoch 584/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0162\n",
      "Epoch 585/1000\n",
      "60/60 [==============================] - 0s 563us/step - loss: 0.0162\n",
      "Epoch 586/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0162\n",
      "Epoch 587/1000\n",
      "60/60 [==============================] - 0s 524us/step - loss: 0.0162\n",
      "Epoch 588/1000\n",
      "60/60 [==============================] - 0s 503us/step - loss: 0.0162\n",
      "Epoch 589/1000\n",
      "60/60 [==============================] - 0s 497us/step - loss: 0.0162\n",
      "Epoch 590/1000\n",
      "60/60 [==============================] - 0s 542us/step - loss: 0.0161\n",
      "Epoch 591/1000\n",
      "60/60 [==============================] - 0s 596us/step - loss: 0.0161\n",
      "Epoch 592/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0161\n",
      "Epoch 593/1000\n",
      "60/60 [==============================] - 0s 478us/step - loss: 0.0161\n",
      "Epoch 594/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.0161\n",
      "Epoch 595/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0161\n",
      "Epoch 596/1000\n",
      "60/60 [==============================] - 0s 471us/step - loss: 0.0160\n",
      "Epoch 597/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0160\n",
      "Epoch 598/1000\n",
      "60/60 [==============================] - 0s 471us/step - loss: 0.0160\n",
      "Epoch 599/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0160\n",
      "Epoch 600/1000\n",
      "60/60 [==============================] - 0s 495us/step - loss: 0.0160\n",
      "Epoch 601/1000\n",
      "60/60 [==============================] - 0s 499us/step - loss: 0.0160\n",
      "Epoch 602/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0159\n",
      "Epoch 603/1000\n",
      "60/60 [==============================] - 0s 468us/step - loss: 0.0159\n",
      "Epoch 604/1000\n",
      "60/60 [==============================] - 0s 529us/step - loss: 0.0159\n",
      "Epoch 605/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0159\n",
      "Epoch 606/1000\n",
      "60/60 [==============================] - 0s 503us/step - loss: 0.0159\n",
      "Epoch 607/1000\n",
      "60/60 [==============================] - 0s 486us/step - loss: 0.0159\n",
      "Epoch 608/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0159\n",
      "Epoch 609/1000\n",
      "60/60 [==============================] - 0s 489us/step - loss: 0.0158\n",
      "Epoch 610/1000\n",
      "60/60 [==============================] - 0s 508us/step - loss: 0.0158\n",
      "Epoch 611/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0158\n",
      "Epoch 612/1000\n",
      "60/60 [==============================] - 0s 482us/step - loss: 0.0158\n",
      "Epoch 613/1000\n",
      "60/60 [==============================] - 0s 461us/step - loss: 0.0158\n",
      "Epoch 614/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0158\n",
      "Epoch 615/1000\n",
      "60/60 [==============================] - 0s 565us/step - loss: 0.0157\n",
      "Epoch 616/1000\n",
      "60/60 [==============================] - 0s 586us/step - loss: 0.0157\n",
      "Epoch 617/1000\n",
      "60/60 [==============================] - 0s 562us/step - loss: 0.0157\n",
      "Epoch 618/1000\n",
      "60/60 [==============================] - 0s 503us/step - loss: 0.0157\n",
      "Epoch 619/1000\n",
      "60/60 [==============================] - 0s 518us/step - loss: 0.0157\n",
      "Epoch 620/1000\n",
      "60/60 [==============================] - 0s 496us/step - loss: 0.0157\n",
      "Epoch 621/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0156\n",
      "Epoch 622/1000\n",
      "60/60 [==============================] - 0s 489us/step - loss: 0.0156\n",
      "Epoch 623/1000\n",
      "60/60 [==============================] - 0s 494us/step - loss: 0.0156\n",
      "Epoch 624/1000\n",
      "60/60 [==============================] - 0s 493us/step - loss: 0.0156\n",
      "Epoch 625/1000\n",
      "60/60 [==============================] - 0s 487us/step - loss: 0.0156\n",
      "Epoch 626/1000\n",
      "60/60 [==============================] - 0s 487us/step - loss: 0.0156\n",
      "Epoch 627/1000\n",
      "60/60 [==============================] - 0s 546us/step - loss: 0.0155\n",
      "Epoch 628/1000\n",
      "60/60 [==============================] - 0s 583us/step - loss: 0.0155\n",
      "Epoch 629/1000\n",
      "60/60 [==============================] - 0s 542us/step - loss: 0.0155\n",
      "Epoch 630/1000\n",
      "60/60 [==============================] - 0s 515us/step - loss: 0.0155\n",
      "Epoch 631/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0155\n",
      "Epoch 632/1000\n",
      "60/60 [==============================] - 0s 471us/step - loss: 0.0155\n",
      "Epoch 633/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0154\n",
      "Epoch 634/1000\n",
      "60/60 [==============================] - 0s 472us/step - loss: 0.0154\n",
      "Epoch 635/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0154\n",
      "Epoch 636/1000\n",
      "60/60 [==============================] - 0s 496us/step - loss: 0.0154\n",
      "Epoch 637/1000\n",
      "60/60 [==============================] - 0s 525us/step - loss: 0.0154\n",
      "Epoch 638/1000\n",
      "60/60 [==============================] - 0s 483us/step - loss: 0.0154\n",
      "Epoch 639/1000\n",
      "60/60 [==============================] - 0s 467us/step - loss: 0.0153\n",
      "Epoch 640/1000\n",
      "60/60 [==============================] - 0s 506us/step - loss: 0.0153\n",
      "Epoch 641/1000\n",
      "60/60 [==============================] - 0s 553us/step - loss: 0.0153\n",
      "Epoch 642/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0153\n",
      "Epoch 643/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0153\n",
      "Epoch 644/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0153\n",
      "Epoch 645/1000\n",
      "60/60 [==============================] - 0s 520us/step - loss: 0.0152\n",
      "Epoch 646/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0152\n",
      "Epoch 647/1000\n",
      "60/60 [==============================] - 0s 504us/step - loss: 0.0152\n",
      "Epoch 648/1000\n",
      "60/60 [==============================] - 0s 482us/step - loss: 0.0152\n",
      "Epoch 649/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0152\n",
      "Epoch 650/1000\n",
      "60/60 [==============================] - 0s 503us/step - loss: 0.0151\n",
      "Epoch 651/1000\n",
      "60/60 [==============================] - 0s 465us/step - loss: 0.0151\n",
      "Epoch 652/1000\n",
      "60/60 [==============================] - 0s 505us/step - loss: 0.0151\n",
      "Epoch 653/1000\n",
      "60/60 [==============================] - 0s 562us/step - loss: 0.0151\n",
      "Epoch 654/1000\n",
      "60/60 [==============================] - 0s 604us/step - loss: 0.0151\n",
      "Epoch 655/1000\n",
      "60/60 [==============================] - 0s 539us/step - loss: 0.0151\n",
      "Epoch 656/1000\n",
      "60/60 [==============================] - 0s 523us/step - loss: 0.0150\n",
      "Epoch 657/1000\n",
      "60/60 [==============================] - 0s 534us/step - loss: 0.0150\n",
      "Epoch 658/1000\n",
      "60/60 [==============================] - 0s 472us/step - loss: 0.0150\n",
      "Epoch 659/1000\n",
      "60/60 [==============================] - 0s 536us/step - loss: 0.0150\n",
      "Epoch 660/1000\n",
      "60/60 [==============================] - 0s 600us/step - loss: 0.0150\n",
      "Epoch 661/1000\n",
      "60/60 [==============================] - 0s 663us/step - loss: 0.0149\n",
      "Epoch 662/1000\n",
      "60/60 [==============================] - 0s 627us/step - loss: 0.0149\n",
      "Epoch 663/1000\n",
      "60/60 [==============================] - 0s 528us/step - loss: 0.0149\n",
      "Epoch 664/1000\n",
      "60/60 [==============================] - 0s 589us/step - loss: 0.0149\n",
      "Epoch 665/1000\n",
      "60/60 [==============================] - 0s 551us/step - loss: 0.0149\n",
      "Epoch 666/1000\n",
      "60/60 [==============================] - 0s 492us/step - loss: 0.0149\n",
      "Epoch 667/1000\n",
      "60/60 [==============================] - 0s 505us/step - loss: 0.0148\n",
      "Epoch 668/1000\n",
      "60/60 [==============================] - 0s 538us/step - loss: 0.0148\n",
      "Epoch 669/1000\n",
      "60/60 [==============================] - 0s 616us/step - loss: 0.0148\n",
      "Epoch 670/1000\n",
      "60/60 [==============================] - 0s 596us/step - loss: 0.0148\n",
      "Epoch 671/1000\n",
      "60/60 [==============================] - 0s 619us/step - loss: 0.0148\n",
      "Epoch 672/1000\n",
      "60/60 [==============================] - 0s 560us/step - loss: 0.0147\n",
      "Epoch 673/1000\n",
      "60/60 [==============================] - 0s 463us/step - loss: 0.0147\n",
      "Epoch 674/1000\n",
      "60/60 [==============================] - 0s 471us/step - loss: 0.0147\n",
      "Epoch 675/1000\n",
      "60/60 [==============================] - 0s 543us/step - loss: 0.0147\n",
      "Epoch 676/1000\n",
      "60/60 [==============================] - 0s 572us/step - loss: 0.0147\n",
      "Epoch 677/1000\n",
      "60/60 [==============================] - 0s 607us/step - loss: 0.0146\n",
      "Epoch 678/1000\n",
      "60/60 [==============================] - 0s 513us/step - loss: 0.0146\n",
      "Epoch 679/1000\n",
      "60/60 [==============================] - 0s 498us/step - loss: 0.0146\n",
      "Epoch 680/1000\n",
      "60/60 [==============================] - 0s 494us/step - loss: 0.0146\n",
      "Epoch 681/1000\n",
      "60/60 [==============================] - 0s 495us/step - loss: 0.0146\n",
      "Epoch 682/1000\n",
      "60/60 [==============================] - 0s 567us/step - loss: 0.0146\n",
      "Epoch 683/1000\n",
      "60/60 [==============================] - 0s 599us/step - loss: 0.0145\n",
      "Epoch 684/1000\n",
      "60/60 [==============================] - 0s 592us/step - loss: 0.0145\n",
      "Epoch 685/1000\n",
      "60/60 [==============================] - 0s 609us/step - loss: 0.0145\n",
      "Epoch 686/1000\n",
      "60/60 [==============================] - 0s 594us/step - loss: 0.0145\n",
      "Epoch 687/1000\n",
      "60/60 [==============================] - 0s 500us/step - loss: 0.0145\n",
      "Epoch 688/1000\n",
      "60/60 [==============================] - 0s 490us/step - loss: 0.0144\n",
      "Epoch 689/1000\n",
      "60/60 [==============================] - 0s 462us/step - loss: 0.0144\n",
      "Epoch 690/1000\n",
      "60/60 [==============================] - 0s 482us/step - loss: 0.0144\n",
      "Epoch 691/1000\n",
      "60/60 [==============================] - 0s 469us/step - loss: 0.0144\n",
      "Epoch 692/1000\n",
      "60/60 [==============================] - 0s 521us/step - loss: 0.0144\n",
      "Epoch 693/1000\n",
      "60/60 [==============================] - 0s 497us/step - loss: 0.0143\n",
      "Epoch 694/1000\n",
      "60/60 [==============================] - 0s 471us/step - loss: 0.0143\n",
      "Epoch 695/1000\n",
      "60/60 [==============================] - 0s 505us/step - loss: 0.0143\n",
      "Epoch 696/1000\n",
      "60/60 [==============================] - 0s 489us/step - loss: 0.0143\n",
      "Epoch 697/1000\n",
      "60/60 [==============================] - 0s 483us/step - loss: 0.0143\n",
      "Epoch 698/1000\n",
      "60/60 [==============================] - 0s 539us/step - loss: 0.0142\n",
      "Epoch 699/1000\n",
      "60/60 [==============================] - 0s 486us/step - loss: 0.0142\n",
      "Epoch 700/1000\n",
      "60/60 [==============================] - 0s 504us/step - loss: 0.0142\n",
      "Epoch 701/1000\n",
      "60/60 [==============================] - 0s 518us/step - loss: 0.0142\n",
      "Epoch 702/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0142\n",
      "Epoch 703/1000\n",
      "60/60 [==============================] - 0s 487us/step - loss: 0.0141\n",
      "Epoch 704/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0141\n",
      "Epoch 705/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0141\n",
      "Epoch 706/1000\n",
      "60/60 [==============================] - 0s 462us/step - loss: 0.0141\n",
      "Epoch 707/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0141\n",
      "Epoch 708/1000\n",
      "60/60 [==============================] - 0s 486us/step - loss: 0.0140\n",
      "Epoch 709/1000\n",
      "60/60 [==============================] - 0s 496us/step - loss: 0.0140\n",
      "Epoch 710/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0140\n",
      "Epoch 711/1000\n",
      "60/60 [==============================] - 0s 483us/step - loss: 0.0140\n",
      "Epoch 712/1000\n",
      "60/60 [==============================] - 0s 531us/step - loss: 0.0140\n",
      "Epoch 713/1000\n",
      "60/60 [==============================] - 0s 519us/step - loss: 0.0139\n",
      "Epoch 714/1000\n",
      "60/60 [==============================] - 0s 605us/step - loss: 0.0139\n",
      "Epoch 715/1000\n",
      "60/60 [==============================] - 0s 599us/step - loss: 0.0139\n",
      "Epoch 716/1000\n",
      "60/60 [==============================] - 0s 649us/step - loss: 0.0139\n",
      "Epoch 717/1000\n",
      "60/60 [==============================] - 0s 595us/step - loss: 0.0138\n",
      "Epoch 718/1000\n",
      "60/60 [==============================] - 0s 578us/step - loss: 0.0138\n",
      "Epoch 719/1000\n",
      "60/60 [==============================] - 0s 528us/step - loss: 0.0138\n",
      "Epoch 720/1000\n",
      "60/60 [==============================] - 0s 574us/step - loss: 0.0138\n",
      "Epoch 721/1000\n",
      "60/60 [==============================] - 0s 570us/step - loss: 0.0138\n",
      "Epoch 722/1000\n",
      "60/60 [==============================] - 0s 601us/step - loss: 0.0138\n",
      "Epoch 723/1000\n",
      "60/60 [==============================] - 0s 589us/step - loss: 0.0137\n",
      "Epoch 724/1000\n",
      "60/60 [==============================] - 0s 597us/step - loss: 0.0137\n",
      "Epoch 725/1000\n",
      "60/60 [==============================] - 0s 584us/step - loss: 0.0137\n",
      "Epoch 726/1000\n",
      "60/60 [==============================] - 0s 586us/step - loss: 0.0137\n",
      "Epoch 727/1000\n",
      "60/60 [==============================] - 0s 573us/step - loss: 0.0137\n",
      "Epoch 728/1000\n",
      "60/60 [==============================] - 0s 605us/step - loss: 0.0136\n",
      "Epoch 729/1000\n",
      "60/60 [==============================] - 0s 595us/step - loss: 0.0136\n",
      "Epoch 730/1000\n",
      "60/60 [==============================] - 0s 556us/step - loss: 0.0136\n",
      "Epoch 731/1000\n",
      "60/60 [==============================] - 0s 567us/step - loss: 0.0136\n",
      "Epoch 732/1000\n",
      "60/60 [==============================] - 0s 466us/step - loss: 0.0135\n",
      "Epoch 733/1000\n",
      "60/60 [==============================] - 0s 467us/step - loss: 0.0135\n",
      "Epoch 734/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0135\n",
      "Epoch 735/1000\n",
      "60/60 [==============================] - 0s 462us/step - loss: 0.0135\n",
      "Epoch 736/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0135\n",
      "Epoch 737/1000\n",
      "60/60 [==============================] - 0s 500us/step - loss: 0.0134\n",
      "Epoch 738/1000\n",
      "60/60 [==============================] - 0s 466us/step - loss: 0.0134\n",
      "Epoch 739/1000\n",
      "60/60 [==============================] - 0s 468us/step - loss: 0.0134\n",
      "Epoch 740/1000\n",
      "60/60 [==============================] - 0s 516us/step - loss: 0.0134\n",
      "Epoch 741/1000\n",
      "60/60 [==============================] - 0s 544us/step - loss: 0.0133\n",
      "Epoch 742/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0133\n",
      "Epoch 743/1000\n",
      "60/60 [==============================] - 0s 496us/step - loss: 0.0133\n",
      "Epoch 744/1000\n",
      "60/60 [==============================] - 0s 511us/step - loss: 0.0133\n",
      "Epoch 745/1000\n",
      "60/60 [==============================] - 0s 496us/step - loss: 0.0133\n",
      "Epoch 746/1000\n",
      "60/60 [==============================] - 0s 500us/step - loss: 0.0132\n",
      "Epoch 747/1000\n",
      "60/60 [==============================] - 0s 513us/step - loss: 0.0132\n",
      "Epoch 748/1000\n",
      "60/60 [==============================] - 0s 499us/step - loss: 0.0132\n",
      "Epoch 749/1000\n",
      "60/60 [==============================] - 0s 512us/step - loss: 0.0132\n",
      "Epoch 750/1000\n",
      "60/60 [==============================] - 0s 510us/step - loss: 0.0132\n",
      "Epoch 751/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0131\n",
      "Epoch 752/1000\n",
      "60/60 [==============================] - 0s 502us/step - loss: 0.0131\n",
      "Epoch 753/1000\n",
      "60/60 [==============================] - 0s 520us/step - loss: 0.0131\n",
      "Epoch 754/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0131\n",
      "Epoch 755/1000\n",
      "60/60 [==============================] - 0s 498us/step - loss: 0.0131\n",
      "Epoch 756/1000\n",
      "60/60 [==============================] - 0s 489us/step - loss: 0.0130\n",
      "Epoch 757/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0130\n",
      "Epoch 758/1000\n",
      "60/60 [==============================] - 0s 527us/step - loss: 0.0130\n",
      "Epoch 759/1000\n",
      "60/60 [==============================] - 0s 497us/step - loss: 0.0130\n",
      "Epoch 760/1000\n",
      "60/60 [==============================] - 0s 508us/step - loss: 0.0129\n",
      "Epoch 761/1000\n",
      "60/60 [==============================] - 0s 564us/step - loss: 0.0129\n",
      "Epoch 762/1000\n",
      "60/60 [==============================] - 0s 560us/step - loss: 0.0129\n",
      "Epoch 763/1000\n",
      "60/60 [==============================] - 0s 515us/step - loss: 0.0129\n",
      "Epoch 764/1000\n",
      "60/60 [==============================] - 0s 498us/step - loss: 0.0129\n",
      "Epoch 765/1000\n",
      "60/60 [==============================] - 0s 526us/step - loss: 0.0128\n",
      "Epoch 766/1000\n",
      "60/60 [==============================] - 0s 602us/step - loss: 0.0128\n",
      "Epoch 767/1000\n",
      "60/60 [==============================] - 0s 598us/step - loss: 0.0128\n",
      "Epoch 768/1000\n",
      "60/60 [==============================] - 0s 627us/step - loss: 0.0128\n",
      "Epoch 769/1000\n",
      "60/60 [==============================] - 0s 608us/step - loss: 0.0127\n",
      "Epoch 770/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 630us/step - loss: 0.0127\n",
      "Epoch 771/1000\n",
      "60/60 [==============================] - 0s 589us/step - loss: 0.0127\n",
      "Epoch 772/1000\n",
      "60/60 [==============================] - 0s 587us/step - loss: 0.0127\n",
      "Epoch 773/1000\n",
      "60/60 [==============================] - 0s 629us/step - loss: 0.0127\n",
      "Epoch 774/1000\n",
      "60/60 [==============================] - 0s 607us/step - loss: 0.0126\n",
      "Epoch 775/1000\n",
      "60/60 [==============================] - 0s 603us/step - loss: 0.0126\n",
      "Epoch 776/1000\n",
      "60/60 [==============================] - 0s 560us/step - loss: 0.0126\n",
      "Epoch 777/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0126\n",
      "Epoch 778/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0126\n",
      "Epoch 779/1000\n",
      "60/60 [==============================] - 0s 549us/step - loss: 0.0125\n",
      "Epoch 780/1000\n",
      "60/60 [==============================] - 0s 572us/step - loss: 0.0125\n",
      "Epoch 781/1000\n",
      "60/60 [==============================] - 0s 478us/step - loss: 0.0125\n",
      "Epoch 782/1000\n",
      "60/60 [==============================] - 0s 463us/step - loss: 0.0125\n",
      "Epoch 783/1000\n",
      "60/60 [==============================] - 0s 507us/step - loss: 0.0124\n",
      "Epoch 784/1000\n",
      "60/60 [==============================] - 0s 573us/step - loss: 0.0124\n",
      "Epoch 785/1000\n",
      "60/60 [==============================] - 0s 574us/step - loss: 0.0124\n",
      "Epoch 786/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0124\n",
      "Epoch 787/1000\n",
      "60/60 [==============================] - 0s 460us/step - loss: 0.0124\n",
      "Epoch 788/1000\n",
      "60/60 [==============================] - 0s 478us/step - loss: 0.0123\n",
      "Epoch 789/1000\n",
      "60/60 [==============================] - 0s 483us/step - loss: 0.0123\n",
      "Epoch 790/1000\n",
      "60/60 [==============================] - 0s 458us/step - loss: 0.0123\n",
      "Epoch 791/1000\n",
      "60/60 [==============================] - 0s 451us/step - loss: 0.0123\n",
      "Epoch 792/1000\n",
      "60/60 [==============================] - 0s 469us/step - loss: 0.0122\n",
      "Epoch 793/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0122\n",
      "Epoch 794/1000\n",
      "60/60 [==============================] - 0s 482us/step - loss: 0.0122\n",
      "Epoch 795/1000\n",
      "60/60 [==============================] - 0s 467us/step - loss: 0.0122\n",
      "Epoch 796/1000\n",
      "60/60 [==============================] - 0s 461us/step - loss: 0.0122\n",
      "Epoch 797/1000\n",
      "60/60 [==============================] - 0s 462us/step - loss: 0.0121\n",
      "Epoch 798/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0121\n",
      "Epoch 799/1000\n",
      "60/60 [==============================] - 0s 467us/step - loss: 0.0121\n",
      "Epoch 800/1000\n",
      "60/60 [==============================] - 0s 471us/step - loss: 0.0121\n",
      "Epoch 801/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0120\n",
      "Epoch 802/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0120\n",
      "Epoch 803/1000\n",
      "60/60 [==============================] - 0s 482us/step - loss: 0.0120\n",
      "Epoch 804/1000\n",
      "60/60 [==============================] - 0s 490us/step - loss: 0.0120\n",
      "Epoch 805/1000\n",
      "60/60 [==============================] - 0s 456us/step - loss: 0.0120\n",
      "Epoch 806/1000\n",
      "60/60 [==============================] - 0s 486us/step - loss: 0.0119\n",
      "Epoch 807/1000\n",
      "60/60 [==============================] - 0s 489us/step - loss: 0.0119\n",
      "Epoch 808/1000\n",
      "60/60 [==============================] - 0s 530us/step - loss: 0.0119\n",
      "Epoch 809/1000\n",
      "60/60 [==============================] - 0s 545us/step - loss: 0.0119\n",
      "Epoch 810/1000\n",
      "60/60 [==============================] - 0s 516us/step - loss: 0.0118\n",
      "Epoch 811/1000\n",
      "60/60 [==============================] - 0s 512us/step - loss: 0.0118\n",
      "Epoch 812/1000\n",
      "60/60 [==============================] - 0s 576us/step - loss: 0.0118\n",
      "Epoch 813/1000\n",
      "60/60 [==============================] - 0s 485us/step - loss: 0.0118\n",
      "Epoch 814/1000\n",
      "60/60 [==============================] - 0s 502us/step - loss: 0.0118\n",
      "Epoch 815/1000\n",
      "60/60 [==============================] - 0s 483us/step - loss: 0.0117\n",
      "Epoch 816/1000\n",
      "60/60 [==============================] - 0s 497us/step - loss: 0.0117\n",
      "Epoch 817/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0117\n",
      "Epoch 818/1000\n",
      "60/60 [==============================] - 0s 466us/step - loss: 0.0117\n",
      "Epoch 819/1000\n",
      "60/60 [==============================] - 0s 459us/step - loss: 0.0117\n",
      "Epoch 820/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0116\n",
      "Epoch 821/1000\n",
      "60/60 [==============================] - 0s 569us/step - loss: 0.0116\n",
      "Epoch 822/1000\n",
      "60/60 [==============================] - 0s 520us/step - loss: 0.0116\n",
      "Epoch 823/1000\n",
      "60/60 [==============================] - 0s 462us/step - loss: 0.0116\n",
      "Epoch 824/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0115\n",
      "Epoch 825/1000\n",
      "60/60 [==============================] - 0s 489us/step - loss: 0.0115\n",
      "Epoch 826/1000\n",
      "60/60 [==============================] - 0s 458us/step - loss: 0.0115\n",
      "Epoch 827/1000\n",
      "60/60 [==============================] - 0s 464us/step - loss: 0.0115\n",
      "Epoch 828/1000\n",
      "60/60 [==============================] - 0s 493us/step - loss: 0.0115\n",
      "Epoch 829/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0114\n",
      "Epoch 830/1000\n",
      "60/60 [==============================] - 0s 466us/step - loss: 0.0114\n",
      "Epoch 831/1000\n",
      "60/60 [==============================] - 0s 471us/step - loss: 0.0114\n",
      "Epoch 832/1000\n",
      "60/60 [==============================] - 0s 528us/step - loss: 0.0114\n",
      "Epoch 833/1000\n",
      "60/60 [==============================] - 0s 468us/step - loss: 0.0113\n",
      "Epoch 834/1000\n",
      "60/60 [==============================] - 0s 552us/step - loss: 0.0113\n",
      "Epoch 835/1000\n",
      "60/60 [==============================] - 0s 557us/step - loss: 0.0113\n",
      "Epoch 836/1000\n",
      "60/60 [==============================] - 0s 586us/step - loss: 0.0113\n",
      "Epoch 837/1000\n",
      "60/60 [==============================] - 0s 569us/step - loss: 0.0113\n",
      "Epoch 838/1000\n",
      "60/60 [==============================] - 0s 581us/step - loss: 0.0112\n",
      "Epoch 839/1000\n",
      "60/60 [==============================] - 0s 574us/step - loss: 0.0112\n",
      "Epoch 840/1000\n",
      "60/60 [==============================] - 0s 489us/step - loss: 0.0112\n",
      "Epoch 841/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0112\n",
      "Epoch 842/1000\n",
      "60/60 [==============================] - 0s 488us/step - loss: 0.0112\n",
      "Epoch 843/1000\n",
      "60/60 [==============================] - 0s 483us/step - loss: 0.0111\n",
      "Epoch 844/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0111\n",
      "Epoch 845/1000\n",
      "60/60 [==============================] - 0s 468us/step - loss: 0.0111\n",
      "Epoch 846/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0111\n",
      "Epoch 847/1000\n",
      "60/60 [==============================] - 0s 469us/step - loss: 0.0111\n",
      "Epoch 848/1000\n",
      "60/60 [==============================] - 0s 500us/step - loss: 0.0110\n",
      "Epoch 849/1000\n",
      "60/60 [==============================] - 0s 487us/step - loss: 0.0110\n",
      "Epoch 850/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0110\n",
      "Epoch 851/1000\n",
      "60/60 [==============================] - 0s 497us/step - loss: 0.0110\n",
      "Epoch 852/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0109\n",
      "Epoch 853/1000\n",
      "60/60 [==============================] - 0s 500us/step - loss: 0.0109\n",
      "Epoch 854/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0109\n",
      "Epoch 855/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0109\n",
      "Epoch 856/1000\n",
      "60/60 [==============================] - 0s 509us/step - loss: 0.0108\n",
      "Epoch 857/1000\n",
      "60/60 [==============================] - 0s 490us/step - loss: 0.0108\n",
      "Epoch 858/1000\n",
      "60/60 [==============================] - 0s 488us/step - loss: 0.0108\n",
      "Epoch 859/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0108\n",
      "Epoch 860/1000\n",
      "60/60 [==============================] - 0s 482us/step - loss: 0.0108\n",
      "Epoch 861/1000\n",
      "60/60 [==============================] - 0s 498us/step - loss: 0.0107\n",
      "Epoch 862/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0107\n",
      "Epoch 863/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0107\n",
      "Epoch 864/1000\n",
      "60/60 [==============================] - 0s 496us/step - loss: 0.0107\n",
      "Epoch 865/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0106\n",
      "Epoch 866/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0106\n",
      "Epoch 867/1000\n",
      "60/60 [==============================] - 0s 571us/step - loss: 0.0106\n",
      "Epoch 868/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.0106\n",
      "Epoch 869/1000\n",
      "60/60 [==============================] - 0s 463us/step - loss: 0.0106\n",
      "Epoch 870/1000\n",
      "60/60 [==============================] - 0s 572us/step - loss: 0.0105\n",
      "Epoch 871/1000\n",
      "60/60 [==============================] - 0s 615us/step - loss: 0.0105\n",
      "Epoch 872/1000\n",
      "60/60 [==============================] - 0s 651us/step - loss: 0.0105\n",
      "Epoch 873/1000\n",
      "60/60 [==============================] - 0s 574us/step - loss: 0.0105\n",
      "Epoch 874/1000\n",
      "60/60 [==============================] - 0s 659us/step - loss: 0.0105\n",
      "Epoch 875/1000\n",
      "60/60 [==============================] - 0s 527us/step - loss: 0.0104\n",
      "Epoch 876/1000\n",
      "60/60 [==============================] - 0s 483us/step - loss: 0.0104\n",
      "Epoch 877/1000\n",
      "60/60 [==============================] - 0s 478us/step - loss: 0.0104\n",
      "Epoch 878/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0104\n",
      "Epoch 879/1000\n",
      "60/60 [==============================] - 0s 492us/step - loss: 0.0103\n",
      "Epoch 880/1000\n",
      "60/60 [==============================] - 0s 473us/step - loss: 0.0103\n",
      "Epoch 881/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0103\n",
      "Epoch 882/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0103\n",
      "Epoch 883/1000\n",
      "60/60 [==============================] - 0s 535us/step - loss: 0.0103\n",
      "Epoch 884/1000\n",
      "60/60 [==============================] - 0s 604us/step - loss: 0.0102\n",
      "Epoch 885/1000\n",
      "60/60 [==============================] - 0s 582us/step - loss: 0.0102\n",
      "Epoch 886/1000\n",
      "60/60 [==============================] - 0s 584us/step - loss: 0.0102\n",
      "Epoch 887/1000\n",
      "60/60 [==============================] - 0s 573us/step - loss: 0.0102\n",
      "Epoch 888/1000\n",
      "60/60 [==============================] - 0s 616us/step - loss: 0.0101\n",
      "Epoch 889/1000\n",
      "60/60 [==============================] - 0s 567us/step - loss: 0.0101\n",
      "Epoch 890/1000\n",
      "60/60 [==============================] - 0s 611us/step - loss: 0.0101\n",
      "Epoch 891/1000\n",
      "60/60 [==============================] - 0s 612us/step - loss: 0.0101\n",
      "Epoch 892/1000\n",
      "60/60 [==============================] - 0s 567us/step - loss: 0.0101\n",
      "Epoch 893/1000\n",
      "60/60 [==============================] - 0s 546us/step - loss: 0.0101\n",
      "Epoch 894/1000\n",
      "60/60 [==============================] - 0s 573us/step - loss: 0.0100\n",
      "Epoch 895/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0100\n",
      "Epoch 896/1000\n",
      "60/60 [==============================] - 0s 457us/step - loss: 0.0100\n",
      "Epoch 897/1000\n",
      "60/60 [==============================] - 0s 489us/step - loss: 0.0100\n",
      "Epoch 898/1000\n",
      "60/60 [==============================] - 0s 469us/step - loss: 0.0099\n",
      "Epoch 899/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0099\n",
      "Epoch 900/1000\n",
      "60/60 [==============================] - 0s 450us/step - loss: 0.0099\n",
      "Epoch 901/1000\n",
      "60/60 [==============================] - 0s 474us/step - loss: 0.0099\n",
      "Epoch 902/1000\n",
      "60/60 [==============================] - 0s 457us/step - loss: 0.0099\n",
      "Epoch 903/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0098\n",
      "Epoch 904/1000\n",
      "60/60 [==============================] - 0s 496us/step - loss: 0.0098\n",
      "Epoch 905/1000\n",
      "60/60 [==============================] - 0s 579us/step - loss: 0.0098\n",
      "Epoch 906/1000\n",
      "60/60 [==============================] - 0s 567us/step - loss: 0.0098\n",
      "Epoch 907/1000\n",
      "60/60 [==============================] - 0s 601us/step - loss: 0.0098\n",
      "Epoch 908/1000\n",
      "60/60 [==============================] - 0s 534us/step - loss: 0.0097\n",
      "Epoch 909/1000\n",
      "60/60 [==============================] - 0s 467us/step - loss: 0.0097\n",
      "Epoch 910/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0097\n",
      "Epoch 911/1000\n",
      "60/60 [==============================] - 0s 448us/step - loss: 0.0097\n",
      "Epoch 912/1000\n",
      "60/60 [==============================] - 0s 467us/step - loss: 0.0097\n",
      "Epoch 913/1000\n",
      "60/60 [==============================] - 0s 466us/step - loss: 0.0096\n",
      "Epoch 914/1000\n",
      "60/60 [==============================] - 0s 472us/step - loss: 0.0096\n",
      "Epoch 915/1000\n",
      "60/60 [==============================] - 0s 528us/step - loss: 0.0096\n",
      "Epoch 916/1000\n",
      "60/60 [==============================] - 0s 592us/step - loss: 0.0096\n",
      "Epoch 917/1000\n",
      "60/60 [==============================] - 0s 587us/step - loss: 0.0095\n",
      "Epoch 918/1000\n",
      "60/60 [==============================] - 0s 510us/step - loss: 0.0095\n",
      "Epoch 919/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0095\n",
      "Epoch 920/1000\n",
      "60/60 [==============================] - 0s 503us/step - loss: 0.0095\n",
      "Epoch 921/1000\n",
      "60/60 [==============================] - 0s 493us/step - loss: 0.0095\n",
      "Epoch 922/1000\n",
      "60/60 [==============================] - 0s 483us/step - loss: 0.0094\n",
      "Epoch 923/1000\n",
      "60/60 [==============================] - 0s 487us/step - loss: 0.0094\n",
      "Epoch 924/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0094\n",
      "Epoch 925/1000\n",
      "60/60 [==============================] - 0s 500us/step - loss: 0.0094\n",
      "Epoch 926/1000\n",
      "60/60 [==============================] - 0s 468us/step - loss: 0.0093\n",
      "Epoch 927/1000\n",
      "60/60 [==============================] - 0s 478us/step - loss: 0.0093\n",
      "Epoch 928/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0093\n",
      "Epoch 929/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0093\n",
      "Epoch 930/1000\n",
      "60/60 [==============================] - 0s 463us/step - loss: 0.0093\n",
      "Epoch 931/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0093\n",
      "Epoch 932/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0092\n",
      "Epoch 933/1000\n",
      "60/60 [==============================] - 0s 478us/step - loss: 0.0092\n",
      "Epoch 934/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0092\n",
      "Epoch 935/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0091\n",
      "Epoch 936/1000\n",
      "60/60 [==============================] - 0s 491us/step - loss: 0.0091\n",
      "Epoch 937/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0091\n",
      "Epoch 938/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0091\n",
      "Epoch 939/1000\n",
      "60/60 [==============================] - 0s 486us/step - loss: 0.0091\n",
      "Epoch 940/1000\n",
      "60/60 [==============================] - 0s 518us/step - loss: 0.0090\n",
      "Epoch 941/1000\n",
      "60/60 [==============================] - 0s 578us/step - loss: 0.0090\n",
      "Epoch 942/1000\n",
      "60/60 [==============================] - 0s 488us/step - loss: 0.0090\n",
      "Epoch 943/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0090\n",
      "Epoch 944/1000\n",
      "60/60 [==============================] - 0s 479us/step - loss: 0.0090\n",
      "Epoch 945/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0090\n",
      "Epoch 946/1000\n",
      "60/60 [==============================] - 0s 497us/step - loss: 0.0089\n",
      "Epoch 947/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0089\n",
      "Epoch 948/1000\n",
      "60/60 [==============================] - 0s 483us/step - loss: 0.0089\n",
      "Epoch 949/1000\n",
      "60/60 [==============================] - 0s 508us/step - loss: 0.0089\n",
      "Epoch 950/1000\n",
      "60/60 [==============================] - 0s 480us/step - loss: 0.0088\n",
      "Epoch 951/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0088\n",
      "Epoch 952/1000\n",
      "60/60 [==============================] - 0s 486us/step - loss: 0.0088\n",
      "Epoch 953/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0088\n",
      "Epoch 954/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0088\n",
      "Epoch 955/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0087\n",
      "Epoch 956/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0087\n",
      "Epoch 957/1000\n",
      "60/60 [==============================] - 0s 525us/step - loss: 0.0087\n",
      "Epoch 958/1000\n",
      "60/60 [==============================] - 0s 589us/step - loss: 0.0087\n",
      "Epoch 959/1000\n",
      "60/60 [==============================] - 0s 615us/step - loss: 0.0087\n",
      "Epoch 960/1000\n",
      "60/60 [==============================] - 0s 605us/step - loss: 0.0086\n",
      "Epoch 961/1000\n",
      "60/60 [==============================] - 0s 574us/step - loss: 0.0086\n",
      "Epoch 962/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 0s 583us/step - loss: 0.0086\n",
      "Epoch 963/1000\n",
      "60/60 [==============================] - 0s 599us/step - loss: 0.0086\n",
      "Epoch 964/1000\n",
      "60/60 [==============================] - 0s 584us/step - loss: 0.0086\n",
      "Epoch 965/1000\n",
      "60/60 [==============================] - 0s 624us/step - loss: 0.0085\n",
      "Epoch 966/1000\n",
      "60/60 [==============================] - 0s 602us/step - loss: 0.0085\n",
      "Epoch 967/1000\n",
      "60/60 [==============================] - 0s 596us/step - loss: 0.0085\n",
      "Epoch 968/1000\n",
      "60/60 [==============================] - 0s 611us/step - loss: 0.0085\n",
      "Epoch 969/1000\n",
      "60/60 [==============================] - 0s 608us/step - loss: 0.0084\n",
      "Epoch 970/1000\n",
      "60/60 [==============================] - 0s 598us/step - loss: 0.0084\n",
      "Epoch 971/1000\n",
      "60/60 [==============================] - 0s 586us/step - loss: 0.0084\n",
      "Epoch 972/1000\n",
      "60/60 [==============================] - 0s 572us/step - loss: 0.0084\n",
      "Epoch 973/1000\n",
      "60/60 [==============================] - 0s 583us/step - loss: 0.0083\n",
      "Epoch 974/1000\n",
      "60/60 [==============================] - 0s 575us/step - loss: 0.0083\n",
      "Epoch 975/1000\n",
      "60/60 [==============================] - 0s 607us/step - loss: 0.0083\n",
      "Epoch 976/1000\n",
      "60/60 [==============================] - 0s 593us/step - loss: 0.0083\n",
      "Epoch 977/1000\n",
      "60/60 [==============================] - 0s 575us/step - loss: 0.0083\n",
      "Epoch 978/1000\n",
      "60/60 [==============================] - 0s 618us/step - loss: 0.0082\n",
      "Epoch 979/1000\n",
      "60/60 [==============================] - 0s 576us/step - loss: 0.0082\n",
      "Epoch 980/1000\n",
      "60/60 [==============================] - 0s 648us/step - loss: 0.0082\n",
      "Epoch 981/1000\n",
      "60/60 [==============================] - 0s 558us/step - loss: 0.0082\n",
      "Epoch 982/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0082\n",
      "Epoch 983/1000\n",
      "60/60 [==============================] - 0s 482us/step - loss: 0.0081\n",
      "Epoch 984/1000\n",
      "60/60 [==============================] - 0s 470us/step - loss: 0.0081\n",
      "Epoch 985/1000\n",
      "60/60 [==============================] - 0s 484us/step - loss: 0.0081\n",
      "Epoch 986/1000\n",
      "60/60 [==============================] - 0s 564us/step - loss: 0.0081\n",
      "Epoch 987/1000\n",
      "60/60 [==============================] - 0s 501us/step - loss: 0.0080\n",
      "Epoch 988/1000\n",
      "60/60 [==============================] - 0s 478us/step - loss: 0.0080\n",
      "Epoch 989/1000\n",
      "60/60 [==============================] - 0s 460us/step - loss: 0.0080\n",
      "Epoch 990/1000\n",
      "60/60 [==============================] - 0s 471us/step - loss: 0.0080\n",
      "Epoch 991/1000\n",
      "60/60 [==============================] - 0s 493us/step - loss: 0.0080\n",
      "Epoch 992/1000\n",
      "60/60 [==============================] - 0s 487us/step - loss: 0.0079\n",
      "Epoch 993/1000\n",
      "60/60 [==============================] - 0s 481us/step - loss: 0.0079\n",
      "Epoch 994/1000\n",
      "60/60 [==============================] - 0s 477us/step - loss: 0.0079\n",
      "Epoch 995/1000\n",
      "60/60 [==============================] - 0s 462us/step - loss: 0.0079\n",
      "Epoch 996/1000\n",
      "60/60 [==============================] - 0s 476us/step - loss: 0.0079\n",
      "Epoch 997/1000\n",
      "60/60 [==============================] - 0s 495us/step - loss: 0.0078\n",
      "Epoch 998/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0078\n",
      "Epoch 999/1000\n",
      "60/60 [==============================] - 0s 471us/step - loss: 0.0078\n",
      "Epoch 1000/1000\n",
      "60/60 [==============================] - 0s 475us/step - loss: 0.0078\n"
     ]
    }
   ],
   "source": [
    "# model.fit(x, y, epoches=100, batch_size=5, verbose=0)하면 밑에 스크롤 결과 안나옴\n",
    "history = model.fit(x, y, epochs=1000, batch_size=5)\n",
    "\n",
    "\n",
    "# 초기화한 모델에 fit메서드를 사용할 수 있다. 다음은 많이 사용하는 아규먼트들\n",
    "# x: 모델 피팅에 사용할 학습용 특성 데이터 배열\n",
    "# y: 모델 피팅에 사용할 학습용 목표 데이터 배열\n",
    "# epochs: 모델을 실행할 세대 횟수(한 세대: 전체 학습데이터세트 한바퀴) -몇번 실행\n",
    "# batch_size: 경사gradient업데이트마다 사용할 학습데이터 표본 수\n",
    "# validation_split: 각 세대epoch 후 검증에 사용되는 학습데이터 비 - 검증에 얼마\n",
    "# 위에 history = model.fit(x=x_train, y=y_train['y'], epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.7320404052734375, 0.4543222188949585, 0.3198447525501251, 0.24510465562343597, 0.20217229425907135, 0.17667542397975922, 0.1608588844537735, 0.14934858679771423, 0.14152753353118896, 0.13662569224834442, 0.13190898299217224, 0.12836094200611115, 0.12602056562900543, 0.12321038544178009, 0.12080168724060059, 0.11915469914674759, 0.11737443506717682, 0.11589191108942032, 0.11478729546070099, 0.11332738399505615, 0.1116165891289711, 0.1107366532087326, 0.10923502594232559, 0.10817577689886093, 0.1073991134762764, 0.1059081181883812, 0.10521838814020157, 0.1041882187128067, 0.10309457033872604, 0.10199669003486633, 0.1011292040348053, 0.10008080303668976, 0.09926526993513107, 0.09824514389038086, 0.09712624549865723, 0.09631948173046112, 0.0955006331205368, 0.09451393783092499, 0.09360505640506744, 0.09258107841014862, 0.09198165684938431, 0.090371273458004, 0.0898057147860527, 0.08912143856287003, 0.08814756572246552, 0.08793655037879944, 0.08670322597026825, 0.08620716631412506, 0.08562079071998596, 0.08449044823646545, 0.08378180861473083, 0.08316779881715775, 0.08241962641477585, 0.08183854818344116, 0.08078369498252869, 0.0801253616809845, 0.07959430664777756, 0.07860293239355087, 0.0778999999165535, 0.07761126756668091, 0.07697588205337524, 0.07607328146696091, 0.07538101822137833, 0.07480723410844803, 0.07402421534061432, 0.07342080771923065, 0.07249776273965836, 0.07186426967382431, 0.07142610847949982, 0.07068116962909698, 0.06971347332000732, 0.06914392858743668, 0.06898140907287598, 0.06793075054883957, 0.06697510927915573, 0.06642789393663406, 0.06541145592927933, 0.0650600716471672, 0.0643024891614914, 0.06340573728084564, 0.06222916767001152, 0.06189396604895592, 0.061251163482666016, 0.060306865721940994, 0.05965424329042435, 0.05877576768398285, 0.05828559771180153, 0.05730709806084633, 0.056814517825841904, 0.05556090548634529, 0.055421873927116394, 0.05463852733373642, 0.054011255502700806, 0.05336160585284233, 0.05252746865153313, 0.05210012570023537, 0.051266394555568695, 0.05070371553301811, 0.050528839230537415, 0.049726150929927826, 0.04916759952902794, 0.048574864864349365, 0.0480768121778965, 0.04754398763179779, 0.047052592039108276, 0.04648514837026596, 0.045807287096977234, 0.04570196196436882, 0.04516231641173363, 0.044603634625673294, 0.04418020695447922, 0.043645717203617096, 0.04362044855952263, 0.04263349249958992, 0.042746782302856445, 0.041922107338905334, 0.0419219508767128, 0.04152708500623703, 0.041086532175540924, 0.04071521386504173, 0.04035224765539169, 0.039868973195552826, 0.039545688778162, 0.03915080800652504, 0.0388144925236702, 0.038715604692697525, 0.038333989679813385, 0.037742771208286285, 0.03781420364975929, 0.037332434207201004, 0.037221260368824005, 0.036706291139125824, 0.03648904338479042, 0.03642931953072548, 0.03614140301942825, 0.03562666103243828, 0.035665448755025864, 0.0352875255048275, 0.03510013222694397, 0.034834183752536774, 0.03443852439522743, 0.03431382030248642, 0.033886682242155075, 0.033915214240550995, 0.03359750285744667, 0.03356553986668587, 0.033123526722192764, 0.03302215412259102, 0.032741107046604156, 0.03265922889113426, 0.03253347799181938, 0.03233771398663521, 0.032157931476831436, 0.03185641020536423, 0.031783513724803925, 0.03166336566209793, 0.03151661902666092, 0.031259287148714066, 0.03103618696331978, 0.030857671052217484, 0.030789658427238464, 0.030659833922982216, 0.030573569238185883, 0.030353806912899017, 0.030273301526904106, 0.030085407197475433, 0.029859870672225952, 0.029753409326076508, 0.02945137955248356, 0.029644353315234184, 0.029421379789710045, 0.029313096776604652, 0.029134826734662056, 0.02902420051395893, 0.028951477259397507, 0.028918838128447533, 0.028750024735927582, 0.028637859970331192, 0.028545469045639038, 0.028389526531100273, 0.02826954610645771, 0.02822243608534336, 0.02811615914106369, 0.027971969917416573, 0.027873286977410316, 0.027833430096507072, 0.02776257134974003, 0.02766468934714794, 0.02749667875468731, 0.027463527396321297, 0.02740640938282013, 0.027324749156832695, 0.027127481997013092, 0.027147581800818443, 0.027040952816605568, 0.02695389837026596, 0.026883795857429504, 0.02683115378022194, 0.02673395723104477, 0.026701856404542923, 0.026568925008177757, 0.026584908366203308, 0.02645159140229225, 0.026377208530902863, 0.026318198069930077, 0.026249468326568604, 0.02615145593881607, 0.02612910233438015, 0.026065029203891754, 0.025989733636379242, 0.025921206921339035, 0.025886161252856255, 0.025813009589910507, 0.025778666138648987, 0.025680525228381157, 0.025616634637117386, 0.025583088397979736, 0.025521058589220047, 0.025460705161094666, 0.025412825867533684, 0.02537059597671032, 0.025298908352851868, 0.025260556489229202, 0.025195889174938202, 0.025128643959760666, 0.025072049349546432, 0.02506130561232567, 0.024993441998958588, 0.02491157501935959, 0.0248967707157135, 0.024830123409628868, 0.024796145036816597, 0.024748407304286957, 0.024688974022865295, 0.02465062402188778, 0.02462480403482914, 0.02455565147101879, 0.02451223134994507, 0.024479860439896584, 0.024447912350296974, 0.02437405101954937, 0.024354539811611176, 0.024312928318977356, 0.024266192689538002, 0.024235345423221588, 0.024188831448554993, 0.02414957620203495, 0.02410634607076645, 0.02403177320957184, 0.024030040949583054, 0.023990079760551453, 0.023943571373820305, 0.023908697068691254, 0.02387167699635029, 0.0238213911652565, 0.023801296949386597, 0.023767003789544106, 0.023702984675765038, 0.023671889677643776, 0.023662757128477097, 0.023608580231666565, 0.023576520383358, 0.023540839552879333, 0.023505564779043198, 0.023480402305722237, 0.02341563254594803, 0.02341044880449772, 0.023367909714579582, 0.023347346112132072, 0.02330203168094158, 0.023259252309799194, 0.023225152865052223, 0.023199066519737244, 0.023168914020061493, 0.02312760427594185, 0.02310194820165634, 0.023083919659256935, 0.02303992584347725, 0.023013465106487274, 0.022979559376835823, 0.02294672094285488, 0.022923775017261505, 0.022886091843247414, 0.022836171090602875, 0.022828077897429466, 0.022783366963267326, 0.022762684151530266, 0.022732717916369438, 0.02270318940281868, 0.022685252130031586, 0.022639626637101173, 0.022628048434853554, 0.022589484229683876, 0.022548608481884003, 0.02253153920173645, 0.022496307268738747, 0.022488361224532127, 0.022437453269958496, 0.022422414273023605, 0.02240023761987686, 0.022364286705851555, 0.022342825308442116, 0.022315099835395813, 0.02229165844619274, 0.02225613035261631, 0.02223389223217964, 0.022207049652934074, 0.022182844579219818, 0.02214028127491474, 0.022123217582702637, 0.022098202258348465, 0.022074086591601372, 0.022045256569981575, 0.022013051435351372, 0.02199513465166092, 0.02197066880762577, 0.021946653723716736, 0.021921517327427864, 0.021891087293624878, 0.021862594410777092, 0.02183620259165764, 0.021814731881022453, 0.021788710728287697, 0.021770929917693138, 0.021739473566412926, 0.021717416122555733, 0.021686840802431107, 0.021672086790204048, 0.02164946310222149, 0.021625204011797905, 0.021590713411569595, 0.021577101200819016, 0.021547673270106316, 0.021521760150790215, 0.02149299532175064, 0.021478286013007164, 0.021449659019708633, 0.021430635824799538, 0.021402638405561447, 0.02137945406138897, 0.021350029855966568, 0.02133217826485634, 0.021310750395059586, 0.021288886666297913, 0.021255016326904297, 0.021237334236502647, 0.021216213703155518, 0.02119389921426773, 0.021166419610381126, 0.021130556240677834, 0.021118255332112312, 0.021089037880301476, 0.021075012162327766, 0.021050959825515747, 0.02102980948984623, 0.021005650982260704, 0.020981453359127045, 0.020955760031938553, 0.020933100953698158, 0.020908910781145096, 0.02088623121380806, 0.020860580727458, 0.020841922610998154, 0.02081565372645855, 0.020787887275218964, 0.020766979083418846, 0.020747950300574303, 0.02072322927415371, 0.020696444436907768, 0.020675336942076683, 0.02065121755003929, 0.020623378455638885, 0.020603002980351448, 0.020578257739543915, 0.02055668644607067, 0.020529884845018387, 0.020505258813500404, 0.02048695646226406, 0.020460903644561768, 0.020437853410840034, 0.020411746576428413, 0.02038942277431488, 0.02036108262836933, 0.02033778466284275, 0.020315948873758316, 0.020284896716475487, 0.020262349396944046, 0.020232543349266052, 0.02021193504333496, 0.020185895264148712, 0.020161492750048637, 0.020137552171945572, 0.020107777789235115, 0.02008557692170143, 0.02005879394710064, 0.020030712708830833, 0.020007440820336342, 0.019981196150183678, 0.019954266026616096, 0.01992473378777504, 0.0199002455919981, 0.019874410703778267, 0.019845010712742805, 0.019817715510725975, 0.01978905498981476, 0.019760318100452423, 0.019734732806682587, 0.01970735937356949, 0.019666701555252075, 0.019656503573060036, 0.019634535536170006, 0.019598670303821564, 0.01956927962601185, 0.019544875249266624, 0.01951398327946663, 0.019483214244246483, 0.0194585919380188, 0.019434381276369095, 0.019403455778956413, 0.0193705502897501, 0.019349465146660805, 0.01931934431195259, 0.0192937720566988, 0.019265083596110344, 0.019238661974668503, 0.01920841448009014, 0.019178546965122223, 0.019154006615281105, 0.019125768914818764, 0.01909741759300232, 0.019071074202656746, 0.019039595499634743, 0.019008154049515724, 0.018988994881510735, 0.018965451046824455, 0.018935544416308403, 0.018907513469457626, 0.018884241580963135, 0.018855633214116096, 0.018828827887773514, 0.0188057292252779, 0.018777918070554733, 0.01875469647347927, 0.018731599673628807, 0.018710466101765633, 0.01868082396686077, 0.018651112914085388, 0.01862681470811367, 0.018604421988129616, 0.018579233437776566, 0.01855899766087532, 0.018531104549765587, 0.018511155620217323, 0.01848672144114971, 0.018466560170054436, 0.018440518528223038, 0.018414249643683434, 0.018395904451608658, 0.018371382728219032, 0.01835346780717373, 0.018328867852687836, 0.01830706186592579, 0.018286950886249542, 0.018262099474668503, 0.01823953539133072, 0.018222767859697342, 0.018201930448412895, 0.018183531239628792, 0.018158135935664177, 0.018139995634555817, 0.018117666244506836, 0.018096474930644035, 0.01808144524693489, 0.018060434609651566, 0.018041051924228668, 0.018020115792751312, 0.01799856871366501, 0.01797647960484028, 0.01795756258070469, 0.01794324815273285, 0.017915816977620125, 0.017907263711094856, 0.017885686829686165, 0.017866723239421844, 0.017849277704954147, 0.0178261399269104, 0.01781526394188404, 0.017790082842111588, 0.0177780631929636, 0.017756352201104164, 0.017737414687871933, 0.01772182807326317, 0.017702238634228706, 0.017686229199171066, 0.017671095207333565, 0.017648279666900635, 0.017633402720093727, 0.017615824937820435, 0.017595477402210236, 0.017576323822140694, 0.01756477542221546, 0.01754320226609707, 0.017528826370835304, 0.017514698207378387, 0.017497744411230087, 0.017473626881837845, 0.017462734133005142, 0.017445536330342293, 0.017428580671548843, 0.017412306740880013, 0.017393970862030983, 0.01738322526216507, 0.017361128702759743, 0.017340634018182755, 0.017324402928352356, 0.017310701310634613, 0.017291627824306488, 0.017276765778660774, 0.017266202718019485, 0.017247989773750305, 0.01722833700478077, 0.01721055433154106, 0.017197348177433014, 0.01718267798423767, 0.01716623827815056, 0.01715085469186306, 0.017133435234427452, 0.01711774617433548, 0.017100565135478973, 0.017087845131754875, 0.017071157693862915, 0.01705547422170639, 0.01703866943717003, 0.017019229009747505, 0.017005519941449165, 0.016989057883620262, 0.016975892707705498, 0.01696026138961315, 0.016937535256147385, 0.016926096752285957, 0.01690860092639923, 0.016896262764930725, 0.016878478229045868, 0.016866089776158333, 0.016841819509863853, 0.01683376356959343, 0.01681778021156788, 0.016805807128548622, 0.016780219972133636, 0.016769396141171455, 0.016753537580370903, 0.01673821359872818, 0.016720756888389587, 0.01670490764081478, 0.016689933836460114, 0.016675639897584915, 0.016658896580338478, 0.016644665971398354, 0.016630282625555992, 0.016609439626336098, 0.016599930822849274, 0.016583343967795372, 0.016568826511502266, 0.01654890552163124, 0.016536269336938858, 0.016523417085409164, 0.01650436408817768, 0.016485560685396194, 0.016472632065415382, 0.016455097123980522, 0.016439080238342285, 0.01642678491771221, 0.01641165092587471, 0.016395457088947296, 0.01637939363718033, 0.016356229782104492, 0.01633956842124462, 0.016330355778336525, 0.01631397195160389, 0.016295671463012695, 0.016281258314847946, 0.01626584120094776, 0.016253314912319183, 0.01623361185193062, 0.01622134819626808, 0.016205763444304466, 0.0161910243332386, 0.01617221161723137, 0.016158299520611763, 0.016139522194862366, 0.016122974455356598, 0.016108479350805283, 0.016085239127278328, 0.016079576686024666, 0.016060346737504005, 0.01604497618973255, 0.01602936163544655, 0.016015589237213135, 0.015998193994164467, 0.01598406583070755, 0.015969008207321167, 0.015949703752994537, 0.015930917114019394, 0.015913745388388634, 0.01590215042233467, 0.015887180343270302, 0.015870479866862297, 0.01585162989795208, 0.015829822048544884, 0.015816280618309975, 0.015807202085852623, 0.015789102762937546, 0.015767741948366165, 0.015755116939544678, 0.015739504247903824, 0.015719490125775337, 0.015707053244113922, 0.015689833089709282, 0.015673011541366577, 0.015655143186450005, 0.015638140961527824, 0.015623170882463455, 0.015607444569468498, 0.015590968541800976, 0.015572584234178066, 0.015554594807326794, 0.01554115954786539, 0.015524130314588547, 0.015505599789321423, 0.015491326339542866, 0.015473952516913414, 0.015453491359949112, 0.015436071902513504, 0.015410398133099079, 0.015402335673570633, 0.015384931117296219, 0.015369987115263939, 0.01535455510020256, 0.015336873009800911, 0.015317540615797043, 0.015302160754799843, 0.015286394394934177, 0.015267540700733662, 0.015250775031745434, 0.015230431221425533, 0.015212715603411198, 0.015196056105196476, 0.015180527232587337, 0.015159186907112598, 0.015145641751587391, 0.01512693427503109, 0.01510961540043354, 0.015087381936609745, 0.015071898698806763, 0.015055535361170769, 0.015033397823572159, 0.015011172741651535, 0.014996293000876904, 0.014983005821704865, 0.014964506030082703, 0.014947980642318726, 0.014929395169019699, 0.014910232275724411, 0.014892634004354477, 0.01487582828849554, 0.014857444912195206, 0.01483609713613987, 0.01481348555535078, 0.014794896356761456, 0.014782371930778027, 0.01476334873586893, 0.014736895449459553, 0.014726457186043262, 0.014708469621837139, 0.014689442701637745, 0.014666381292045116, 0.014647911302745342, 0.014628494158387184, 0.014613442122936249, 0.014583803713321686, 0.014564706943929195, 0.014556482434272766, 0.014528468251228333, 0.014519765973091125, 0.014496639370918274, 0.014476087875664234, 0.014462882652878761, 0.01443775836378336, 0.014416659250855446, 0.014395367354154587, 0.014381296001374722, 0.014360057190060616, 0.0143418088555336, 0.014317530207335949, 0.014301853254437447, 0.014282180927693844, 0.01425932440906763, 0.014242849312722683, 0.014224504120647907, 0.014203626662492752, 0.014183157123625278, 0.014163118787109852, 0.01414460502564907, 0.014120369218289852, 0.014104027301073074, 0.014080066233873367, 0.014063067734241486, 0.014039644971489906, 0.01401473954319954, 0.014000236056745052, 0.013982893899083138, 0.013962715864181519, 0.013942515477538109, 0.013921685516834259, 0.013902079313993454, 0.01387082226574421, 0.013846836052834988, 0.01383434422314167, 0.013818151317536831, 0.013796230778098106, 0.013776046223938465, 0.013753686100244522, 0.013731095008552074, 0.013713440857827663, 0.013690698891878128, 0.013671456836163998, 0.01365200337022543, 0.013627772219479084, 0.013609010726213455, 0.013589316979050636, 0.013557850383222103, 0.013546714559197426, 0.013513182289898396, 0.013498466461896896, 0.01348200161010027, 0.013458671979606152, 0.013438627123832703, 0.013414556160569191, 0.013396929018199444, 0.0133776580914855, 0.013343428261578083, 0.013324418105185032, 0.013312260620296001, 0.01329077035188675, 0.013268502429127693, 0.013241036795079708, 0.013226214796304703, 0.01320429053157568, 0.0131858941167593, 0.013156025670468807, 0.013142053969204426, 0.013114572502672672, 0.013098728843033314, 0.013070653192698956, 0.01305121649056673, 0.013036182150244713, 0.013003112748265266, 0.012993543408811092, 0.012964018620550632, 0.01293256226927042, 0.012919328175485134, 0.012903145514428616, 0.01287970133125782, 0.01286149863153696, 0.012837108224630356, 0.012813467532396317, 0.012785950675606728, 0.01277852337807417, 0.01274859718978405, 0.012728490866720676, 0.01270592212677002, 0.012683658860623837, 0.012655532918870449, 0.0126421507447958, 0.012609457597136497, 0.012597741559147835, 0.012578030116856098, 0.012555663473904133, 0.01251770369708538, 0.012512192130088806, 0.012487129308283329, 0.012468455359339714, 0.012445732951164246, 0.012424043379724026, 0.012402013875544071, 0.012360717169940472, 0.01235098298639059, 0.012334257364273071, 0.012305467389523983, 0.012284225784242153, 0.01226672250777483, 0.012248764745891094, 0.012228564359247684, 0.012200446799397469, 0.012181268073618412, 0.012154710479080677, 0.012139903381466866, 0.012114575132727623, 0.012093938887119293, 0.012070054188370705, 0.01203172281384468, 0.012025783769786358, 0.011992380023002625, 0.011968571692705154, 0.01196364313364029, 0.01194074098020792, 0.011914419941604137, 0.011897539719939232, 0.011874638497829437, 0.011849803850054741, 0.011828839778900146, 0.011811037547886372, 0.01178816333413124, 0.011763257905840874, 0.01174191851168871, 0.01171635091304779, 0.011696777306497097, 0.011671924032270908, 0.011650072410702705, 0.01163029670715332, 0.01160243060439825, 0.011588356457650661, 0.011565076187252998, 0.011545407585799694, 0.011521791107952595, 0.011490955017507076, 0.011478716507554054, 0.011457101441919804, 0.011433802545070648, 0.01140789408236742, 0.01138573233038187, 0.01136640552431345, 0.011345569044351578, 0.011325537227094173, 0.011302330531179905, 0.011281591840088367, 0.011255360208451748, 0.01123987790197134, 0.011214764788746834, 0.011196799576282501, 0.011177959851920605, 0.011151755228638649, 0.011127501726150513, 0.01110842451453209, 0.011085334233939648, 0.011063693091273308, 0.011051910929381847, 0.011018937453627586, 0.010999747551977634, 0.010975862853229046, 0.010957852937281132, 0.010920513421297073, 0.010915099643170834, 0.010874023661017418, 0.01086635235697031, 0.010849122889339924, 0.010819531045854092, 0.010795747861266136, 0.010784449055790901, 0.010753577575087547, 0.010737014934420586, 0.010719426907598972, 0.01070130430161953, 0.010672468692064285, 0.010638698935508728, 0.01063198409974575, 0.01061494555324316, 0.010589663870632648, 0.010560811497271061, 0.01054608728736639, 0.01052540261298418, 0.010501055046916008, 0.0104834521189332, 0.01045976486057043, 0.010431303642690182, 0.010416499339044094, 0.010396315716207027, 0.010377197526395321, 0.010338462889194489, 0.010328314267098904, 0.010310501791536808, 0.010289238765835762, 0.010264210402965546, 0.01022456493228674, 0.01020047441124916, 0.010203750804066658, 0.01017760206013918, 0.010129939764738083, 0.010131905786693096, 0.010122116655111313, 0.01009448803961277, 0.010077427141368389, 0.010053323581814766, 0.010036163032054901, 0.010006244294345379, 0.009986559860408306, 0.00997103936970234, 0.009930538013577461, 0.009923889301717281, 0.009905507788062096, 0.009875989519059658, 0.009854178875684738, 0.009837000630795956, 0.009823125787079334, 0.009793148376047611, 0.00977865420281887, 0.009757595136761665, 0.009735639207065105, 0.009709017351269722, 0.00969416182488203, 0.009663593024015427, 0.009652040898799896, 0.009632498025894165, 0.00960067380219698, 0.009587720967829227, 0.009566104039549828, 0.009539162740111351, 0.009517040103673935, 0.009505823254585266, 0.009474920108914375, 0.009463869035243988, 0.009417983703315258, 0.009408403187990189, 0.009398854337632656, 0.009372781962156296, 0.009345006197690964, 0.009338117204606533, 0.009307651780545712, 0.009296036325395107, 0.009270266629755497, 0.009251615963876247, 0.009227363392710686, 0.009205297566950321, 0.009187739342451096, 0.009144585579633713, 0.009147734381258488, 0.00912509299814701, 0.009093042463064194, 0.009064446203410625, 0.009048927575349808, 0.00903484970331192, 0.009018689393997192, 0.00899485219269991, 0.008973782882094383, 0.008952489122748375, 0.008926933631300926, 0.008911477401852608, 0.008890751749277115, 0.008868816308677197, 0.008813668042421341, 0.008824147284030914, 0.008759995922446251, 0.00877746194601059, 0.008763004094362259, 0.008735976181924343, 0.008719117380678654, 0.008690654300153255, 0.008678609505295753, 0.00865826103836298, 0.008630082942545414, 0.008611591532826424, 0.008593091741204262, 0.008570963516831398, 0.00855152029544115, 0.008522463962435722, 0.008498720824718475, 0.008490659296512604, 0.008464056998491287, 0.00843698438256979, 0.008413774892687798, 0.008397793397307396, 0.008372316136956215, 0.00834724586457014, 0.008338261395692825, 0.008314399980008602, 0.0082798907533288, 0.008268903940916061, 0.00823968555778265, 0.008229008875787258, 0.008181965909898281, 0.00818483717739582, 0.00816127099096775, 0.00814421009272337, 0.008120006881654263, 0.008092896081507206, 0.008075248450040817, 0.00804003607481718, 0.008035033009946346, 0.00800542812794447, 0.007984180934727192, 0.007963784970343113, 0.007942539639770985, 0.007921607233583927, 0.007869178429245949, 0.007868941873311996, 0.00785568356513977, 0.007839368656277657, 0.007801130414009094, 0.007789980620145798, 0.007760531734675169]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAfmklEQVR4nO3dfZhcdX338fdnZnY3IQ8EyIKBhCRggCIiyBrhtioiakDuYG9RSVHwoaW9WwqKly1USy3qVZ+qoKYKIlioGBGfUhob7wKKVMAsikiAyBICLEGzCc8Jye7Ofu8/5szu7OzZZLPJyezu+byua66Zc85vZr4nB+azv/P0U0RgZmb5VWh0AWZm1lgOAjOznHMQmJnlnIPAzCznHARmZjnnIDAzyzkHgdl2SJonKSSVRtD2vZJu3xN1me1ODgKbMCStk9QtaWbd/HuSH/N5jals5wLFbE9zENhE8wiwpDoh6eXA5MaVYzb2OQhsorkOOLtm+hzg2toGkvaWdK2kLkmPSvqYpEKyrCjp85I2SloLvDXlvd+Q9KSkJyR9UlJxVwqW1CLpMknrk8dlklqSZTMl3STpGUlPSfp5Ta1/l9TwvKQ1kt64K3VYfjkIbKK5E5gu6Y+SH+h3Af9e1+bLwN7AIcDrqQTH+5Jlfw6cBhwLtAFn1L3334Be4KVJmzcDf7aLNX8UOB44BngFsBD4WLLsw0An0AocAPw9EJIOB84DXhUR04C3AOt2sQ7LKQeBTUTVXsGbgAeBJ6oLasLh4oh4PiLWAf8CvCdp8k7gsoh4PCKeAv655r0HAKcAH4yIzRGxAfgicOYu1nsWcGlEbIiILuCfaurpAWYBcyOiJyJ+HpUbhJWBFuBISU0RsS4iHt7FOiynHAQ2EV0H/CnwXup2CwEzgWbg0Zp5jwIHJa8PBB6vW1Y1F2gCnkx21TwDXAHsv4v1HphSz4HJ688BHcBPJK2VdBFARHQAHwQ+DmyQtEzSgZiNgoPAJpyIeJTKQeNTge/XLd5I5a/suTXzDmag1/AkMKduWdXjwDZgZkTMSB7TI+Jlu1jy+pR61ifr8nxEfDgiDgH+N3Bh9VhARFwfEX+cvDeAz+xiHZZTDgKbqD4AnBQRm2tnRkQZuAH4lKRpkuYCFzJwHOEG4HxJsyXtA1xU894ngZ8A/yJpuqSCpEMlvX4n6mqRNKnmUQC+DXxMUmty6usl1XoknSbppZIEPEdll1BZ0uGSTkoOKm8FXkyWme00B4FNSBHxcES0D7P4b4DNwFrgduB64Opk2deBlcBvgF8xtEdxNpVdS/cDTwM3UtmHP1IvUPnRrj5OAj4JtAP3Ar9NvveTSfsFwH8n77sD+NeI+CmV4wOfptLD+T2V3VN/vxN1mPWTB6YxM8s39wjMzHLOQWBmlnMOAjOznHMQmJnl3Li7E+LMmTNj3rx5jS7DzGxcufvuuzdGRGvasnEXBPPmzaO9fbizAs3MLI2kR4db5l1DZmY55yAwM8s5B4GZWc45CMzMcs5BYGaWcw4CM7OccxCYmeVcboJg1bqn+MJP1tDd29foUszMxpTcBMHdjz7Nl27poLfPQWBmVis3QaDk2cMvmJkNlp8gSJLAOWBmNlh+giDpE3hENjOzwfITBO4RmJmlyk0QVLlDYGY2WKZBIGmRpDWSOiRdlLL8i5LuSR6/k/RMhrVUXjgIzMwGyWw8AklFYCnwJqATWCVpeUTcX20TER+qaf83wLGZ1VP9TieBmdkgWfYIFgIdEbE2IrqBZcDp22m/BPh2VsX0dwicA2Zmg2QZBAcBj9dMdybzhpA0F5gP3DLM8nMltUtq7+rqGlUxAz0CMzOrlWUQKGXecL/DZwI3RkQ5bWFEXBkRbRHR1tqaOuTmjouRTx81M0uTZRB0AnNqpmcD64dpeyYZ7hYCnz5qZjacLINgFbBA0nxJzVR+7JfXN5J0OLAPcEeGtfgWE2Zmw8gsCCKiFzgPWAk8ANwQEaslXSppcU3TJcCyyHqfTXXXkPsEZmaDZHb6KEBErABW1M27pG7641nWUFXw0WIzs1S5ubK4eq+hPgeBmdkg+QmC/oPFTgIzs1r5CYLk2QeLzcwGy08Q+PRRM7NU+QkCj0dgZpYqN0GA7zVkZpYqN0GQdr8LMzPLUxD032uowYWYmY0x+QmC5Nmnj5qZDZafIPAxAjOzVPkLgsaWYWY25uQnCHz6qJlZqvwEgXsEZmapchMEVe4QmJkNlpsgqJ4+6j6Bmdlg+QmC5Nk9AjOzwfITBD5GYGaWKj9BgK8sNjNLk2kQSFokaY2kDkkXDdPmnZLul7Ra0vXZ1VJ59pXFZmaDZTZmsaQisBR4E9AJrJK0PCLur2mzALgYeE1EPC1p/8zqSZ7dIzAzGyzLHsFCoCMi1kZEN7AMOL2uzZ8DSyPiaYCI2JBVMb7FhJlZuiyD4CDg8ZrpzmRercOAwyT9j6Q7JS1K+yBJ50pql9Te1dU1ynKSYwTeNWRmNkiWQZA2BED9r3AJWACcCCwBrpI0Y8ibIq6MiLaIaGttbR1dMe4RmJmlyjIIOoE5NdOzgfUpbX4UET0R8Qiwhkow7HYemMbMLF2WQbAKWCBpvqRm4ExgeV2bHwJvAJA0k8quorVZFOOBaczM0mUWBBHRC5wHrAQeAG6IiNWSLpW0OGm2Etgk6X7gVuAjEbEpi3o8MI2ZWbrMTh8FiIgVwIq6eZfUvA7gwuSRKR8jMDNLl58ri32LCTOzVPkJAg9MY2aWKjdBgHsEZmapchMEvsWEmVm63ARBQd41ZGaWJjdB4IPFZmbp8hMEHo/AzCxVfoKg/zoCJ4GZWa38BEHy7BgwMxssN0GAryw2M0uVmyCQxyMwM0uVnyDwviEzs1T5CYLk2TlgZjZYfoLA4xGYmaXKURBUnn2MwMxssPwEQfLsHoGZ2WD5CQLfYsLMLFVuggCPR2BmlirTIJC0SNIaSR2SLkpZ/l5JXZLuSR5/ll0tlWfHgJnZYJmNWSypCCwF3gR0AqskLY+I++uaficizsuqjv56qi+cBGZmg2TZI1gIdETE2ojoBpYBp2f4fdvVf/qok8DMbJAsg+Ag4PGa6c5kXr23S7pX0o2S5mRVjM8aMjNLl2UQKGVe/c/wfwDzIuJo4L+Bf0v9IOlcSe2S2ru6ukZXjG86Z2aWKssg6ARq/8KfDayvbRARmyJiWzL5deC4tA+KiCsjoi0i2lpbW0dVzMBN58zMrFaWQbAKWCBpvqRm4ExgeW0DSbNqJhcDD2RVjAemMTNLl9lZQxHRK+k8YCVQBK6OiNWSLgXaI2I5cL6kxUAv8BTw3qzq6a8r6y8wMxtnMgsCgIhYAayom3dJzeuLgYuzrKHKxwjMzNLl5spi+UbUZmap8hME7hGYmaXKXxA0tgwzszEnP0GAB6YxM0uTnyDwwDRmZqnyEwTJs3sEZmaD5ScIfIzAzCxVjoLAA9OYmaXJTRAUkyDocxCYmQ2SmyAoVIOgr8GFmJmNMbkJguoxAvcIzMwGy00QFAq+jsDMLE1+gsA9AjOzVDkKgurB4gYXYmY2xuQmCHyMwMwsXW6CoODTR83MUuUmCPqvI/C+ITOzQXITBD5GYGaWLjdBoGRNvWvIzGywTINA0iJJayR1SLpoO+3OkBSS2rKqpSBfR2BmliazIJBUBJYCpwBHAkskHZnSbhpwPnBXVrWAryMwMxtOlj2ChUBHRKyNiG5gGXB6SrtPAJ8FtmZYi48RmJkNY0RBIOlQSS3J6xMlnS9pxg7edhDweM10ZzKv9nOPBeZExE07+P5zJbVLau/q6hpJySmfUXl2j8DMbLCR9gi+B5QlvRT4BjAfuH4H71HKvP5fYUkF4IvAh3f05RFxZUS0RURba2vrCEserODTR83MUo00CPoiohf4E+CyiPgQMGsH7+kE5tRMzwbW10xPA44CfippHXA8sDyrA8ZF7xoyM0s10iDokbQEOAeo7sZp2sF7VgELJM2X1AycCSyvLoyIZyNiZkTMi4h5wJ3A4oho36k1GCHvGjIzSzfSIHgfcALwqYh4RNJ84N+394akB3EesBJ4ALghIlZLulTS4l0pejQkIXmoSjOzeqWRNIqI+6mc4omkfYBpEfHpEbxvBbCibt4lw7Q9cSS17IqC5F1DZmZ1RnrW0E8lTZe0L/Ab4BpJX8i2tN2vIO8aMjOrN9JdQ3tHxHPA/wGuiYjjgJOzKysbco/AzGyIkQZBSdIs4J0MHCwedwo+RmBmNsRIg+BSKgd9H46IVZIOAR7KrqxsFCTK7hKYmQ0y0oPF3wW+WzO9Fnh7VkVlpehdQ2ZmQ4z0YPFsST+QtEHSHyR9T9LsrIvb3eSDxWZmQ4x019A1VC4GO5DK/YL+I5k3rhQK8jECM7M6Iw2C1oi4JiJ6k8c3gdHd9KeBfB2BmdlQIw2CjZLeLamYPN4NbMqysCz4OgIzs6FGGgTvp3Lq6O+BJ4EzqNx2YlzxdQRmZkONKAgi4rGIWBwRrRGxf0S8jcrFZeOKryMwMxtqV0You3C3VbGH+DoCM7OhdiUI0gaeGdN8sNjMbKhdCYJx95NaKHjXkJlZve1eWSzpedJ/8AVMzqSiDFV6BA4CM7Na2w2CiJi2pwrZEwoSZeeAmdkgu7JraNwpyIPXm5nVy1UQlAoFnzVkZlYn0yCQtEjSGkkdki5KWf6Xkn4r6R5Jt0s6Mst6igXR6yAwMxsksyCQVASWAqcARwJLUn7or4+Il0fEMcBngUyHvywVRbmvL8uvMDMbd7LsESwEOiJibUR0A8uA02sbJMNfVk0h41NS3SMwMxtqRAPTjNJBwOM1053Aq+sbSfprKlcpNwMnpX2QpHOBcwEOPvjgURdU9JXFZmZDZNkjSLvyeMivcEQsjYhDgb8DPpb2QRFxZUS0RURba+vo735dLDgIzMzqZRkEncCcmunZwPrttF8GvC3DepJjBA4CM7NaWQbBKmCBpPmSmoEzqYxy1k/SgprJtwIPZVgPxULBxwjMzOpkdowgInolnQesBIrA1RGxWtKlQHtELAfOk3Qy0AM8DZyTVT0AJe8aMjMbIsuDxUTECmBF3bxLal5fkOX31/NZQ2ZmQ+XqyuLKWUO+jsDMrFa+gsAHi83MhshVEPgYgZnZULkKAh8jMDMbKldB4B6BmdlQuQoC9wjMzIbKXRC4R2BmNliugsAD05iZDZWrIHCPwMxsqFwFQakousu+oMzMrFaugqC5WKCn3EeEewVmZlW5C4IIfOaQmVmNXAVBU6myuj3ePWRm1i9XQdBcrKxud6+DwMysKl9BUHIQmJnVy1cQVHsE3jVkZtYvX0HgHoGZ2RD5DAL3CMzM+mUaBJIWSVojqUPSRSnLL5R0v6R7Jd0saW6W9TQlu4Z6en36qJlZVWZBIKkILAVOAY4Elkg6sq7Zr4G2iDgauBH4bFb1QG2PoJzl15iZjStZ9ggWAh0RsTYiuoFlwOm1DSLi1ojYkkzeCczOsJ7+g8XbfIzAzKxflkFwEPB4zXRnMm84HwB+nLZA0rmS2iW1d3V1jbqgSU1JEPQ4CMzMqrIMAqXMS905L+ndQBvwubTlEXFlRLRFRFtra+uoC9qruQTA5u7eUX+GmdlEU8rwszuBOTXTs4H19Y0knQx8FHh9RGzLsB72ai4CsKXbxwjMzKqy7BGsAhZImi+pGTgTWF7bQNKxwBXA4ojYkGEtwEAQvOggMDPrl1kQREQvcB6wEngAuCEiVku6VNLipNnngKnAdyXdI2n5MB+3W1R3DblHYGY2IMtdQ0TECmBF3bxLal6fnOX315vUVECCLT5GYGbWL1dXFkticlPRPQIzsxq5CgKAvSc38cyWnkaXYWY2ZuQuCPad0sxTmzM9OcnMbFzJaRB0N7oMM7MxI3dBsN+UZjY5CMzM+uUuCPad0uIegZlZjdwFwX5Tm9nSXWZrj88cMjODHAbBvlOaAbx7yMwskbsgaJ3aAsAfntva4ErMzMaG3AXBvJl7AfDops0NrsTMbGzIXRDM2XcvSgXx4O+fb3QpZmZjQu6CoKVU5BVzZnDn2qcaXYqZ2ZiQuyAAOOGQ/bjviWd5fqtvNWFmls8gOHQ/yn3BXe4VmJnlMwiOm7sPM6e2cPX/PNLoUszMGi6XQTCpqcj/PfFQfvHwJu54eFOjyzEza6hcBgHAWa8+mP2ntfD5n6yh3BeNLsfMrGFyGwSTmop85C2Hc/ejT3P5zQ81uhwzs4bJdKjKse6M42Zz1yNP8aWbH6J1WgvvOX5uo0syM9vjMu0RSFokaY2kDkkXpSx/naRfSeqVdEaWtQxTH59821G88Yj9+Ycf3sd1d6zb0yWYmTVcZkEgqQgsBU4BjgSWSDqyrtljwHuB67OqY0cmNRVZetYrOfHwVv7hR6v55xUP0OdjBmaWI1n2CBYCHRGxNiK6gWXA6bUNImJdRNwL9GVYxw5Naipy1dltvPv4g7nitrWcv+zXvk21meVGlkFwEPB4zXRnMm+nSTpXUruk9q6urt1SXL1SscAnTj+Ki045gpvufZKzrrqLTS94bGMzm/iyDAKlzBvVPpeIuDIi2iKirbW1dRfLGp4k/vL1h/KvZ72S+554ltO+fDu/+4NvTmdmE1uWQdAJzKmZng2sz/D7dptTXz6L7/zFCbzYU+a0L9/O0ls76Ck3dO+VmVlmsgyCVcACSfMlNQNnAssz/L7d6pg5M/jxBa/l1fP35XMr1/D2r/6Cjg0vNLosM7PdLrMgiIhe4DxgJfAAcENErJZ0qaTFAJJeJakTeAdwhaTVWdUzGrP2nsy171/Il5ccyyMbN7PosttYemsHve4dmNkEoojxdapkW1tbtLe37/Hv3fjCNj72g/v4r9W/5/ADpvHxxS/jhEP32+N1mJmNhqS7I6ItbVlubzGxs2ZObeFr7zmOr/zpsWztLbPk63fy4Rt+wzNbuhtdmpnZLnEQ7KTTjj6QH1/wWv7qxEP54T1P8LrP3spVP1/ri9DMbNxyEIzCXs0l/nbREaw4/7Uc8ZLpfPI/H+Cca37Juo2bG12amdlOcxDsgsNfMo3v/MXxfOJtR7Fq3VMsuvw2rrtjnXsHZjauOAh2kSTec/xcfvaRN/CqefvyDz9azdlX/5LOp7c0ujQzsxFxEOwmB0yfxLXvX8in/uQo7n70aU76/M98IZqZjQsOgt1IEme9ei4rLngtr3npfnxu5RpOvfznrPjtk95dZGZjloMgA/NnTuGa9y3k62e3Ue4L/upbv2LR5bfxg193snlbb6PLMzMbxBeUZazcF9x073q+cksHD214gWmTSpx61Cze+ao5HDtnBoVC2r35zMx2r+1dUOYg2EP6+oJfPLyJb//yMf7zt08CcMD0Fk47+kDe8rKXcMycGTSX3EEzs2w4CMaYPzy3lVsf3MDND27gZ2u66C730Vws8NoFM3nl3H04Zs4MXjFnBlNbcj2ktJntRg6CMezZF3u4/aGN3LF2I7/o2MTa5KK0UkHMmjGJI2dN55DWqcyfOYVDZk7hkNap7LNXE5J3KZnZyG0vCPwnZ4PtPbmJtx49i7cePQuAZ7f08JvOZ1i17inWbtzMA08+xy0PbqCnPBDY0yeVOHDGZPafPomDZkxi5tQW9pvSzMxpLew3pYX9p7ew9+QmpraUmNRUbNSqmdk44SAYY/beq4nXHdbK6w4bGImtt9xH59Mv8sjGzTzc9QKPbtrCY09tYdPmbdy//lme2tzNcGenNpcKTJ/UxPTJJaZNamJqS5G9mktMaS4ypaXElJYSezUX2au5yOSmIpOSx+SmIpObi0xqKtBSKtJSKtBcqn9doFT0cQ2z8c5BMA6UigXmzZzCvJlTeMMR+w9ZXu4LntnSzabN3XQ9v42u57fx3NYent/ay3Nbe3juxepzDy92l9n0wha2dJfZ0t3LC9t62doz+oveCoKWUpHmUoGmYiUcmorqn+5/LhYoFUVTsbK8qVigVCjQXBKlQmHw/Pp2xQJNhcHLSjXTlfdvf3n1+0tF0VQo+GwtsxoOggmgWBD7TW1hv6ktHHbAtJ1+f2+5j629fbzYXWZrT/XRx4s9ZV7sKdPd28e23upzH9t6ynSX+9jWk0z3lukpB9t6++ju7aOnXPOcvH6xp0zP1j56ykFPuY/e8sDrynTQXe6jty8o74GL7wqiP2BKxYEgqgZFbcCUBoXXwHQpaddcTGmftOtfnvK+YkGUCqJYqCwv9E8PPBf7pwtD5m+vjYPOdoaDwCgVC0wtFsbMWUp9fUFPXyUoepMwqb7uKQe9fZXg6EmCo2cHyyufUXmutu8tV76jtzz88t6+gc/r6Q1e6O0d8rk9dXXUvq/R0kOlMDC/KIqqCZJiZXlRDIRKcSBkSsl0fSAWC3Xz6pbVzyv1B+3Q0GxKvrcaqLU9u6ZCgWLyvqZipZ3tHmPj/3yzGoWCaCkUGSO5NCoRlZ5Nb1/S06kGVd9A4JRrHpXpSrtyzXvL9dNJm76I/s/oLSefE7XTyXdE5TP6v2/QdKVNXwx8Rn1dW3vLlPuCnvLAd/f0B20l9Mq1oboHb6Ui0d97qw2jgV2CA6+LhWrgDN+zq37WcMtT31PbExzy/qHzqgGW9n3Fghp2NmCm/6tJWgRcDhSBqyLi03XLW4BrgeOATcC7ImJdljWZ7QlS8kNQJFdnbkUSUNXAGBQSg0KkLwmeam9uYFm5tieWLKu+LqfMqwZrb11A1fcaq2E3XM9uaE+yUtOePMM+LVAGwkx88OTDWPyKA3f792YWBJKKwFLgTUAnsErS8oi4v6bZB4CnI+Klks4EPgO8K6uazCxbkpLjKTCZiRGA5b7BodEfEilBMjiY0kOm3BcDPcO6XZQ9qe8ZeL3PXk2ZrGOWPYKFQEdErAWQtAw4HagNgtOBjyevbwS+Ikkx3q5yM7MJq3IMZWKE2nCyPAn8IODxmunOZF5qm4joBZ4F9qv/IEnnSmqX1N7V1ZVRuWZm+ZRlEKQd9aj/S38kbYiIKyOiLSLaWltbU95iZmajlWUQdAJzaqZnA+uHayOpBOwNPJVhTWZmVifLIFgFLJA0X1IzcCawvK7NcuCc5PUZwC0+PmBmtmdldrA4InolnQespHL66NURsVrSpUB7RCwHvgFcJ6mDSk/gzKzqMTOzdJleRxARK4AVdfMuqXm9FXhHljWYmdn2+daRZmY55yAwM8u5cTdCmaQu4NFRvn0msHE3ljMeeJ3zweucD7uyznMjIvX8+3EXBLtCUvtwQ7VNVF7nfPA650NW6+xdQ2ZmOecgMDPLubwFwZWNLqABvM754HXOh0zWOVfHCMzMbKi89QjMzKyOg8DMLOdyEwSSFklaI6lD0kWNrmd3kTRH0q2SHpC0WtIFyfx9Jf0/SQ8lz/sk8yXpS8m/w72SXtnYNRgdSUVJv5Z0UzI9X9Jdyfp+J7nRIZJakumOZPm8RtY9WpJmSLpR0oPJtj4hB9v4Q8l/0/dJ+rakSRNxO0u6WtIGSffVzNvpbSvpnKT9Q5LOSfuu4eQiCGqGzTwFOBJYIunIxla12/QCH46IPwKOB/46WbeLgJsjYgFwczINlX+DBcnjXOCre77k3eIC4IGa6c8AX0zW92kqw6BCzXCowBeTduPR5cB/RcQRwCuorPuE3caSDgLOB9oi4igqN66sDmc70bbzN4FFdfN2attK2hf4R+DVVEaH/MdqeIxIREz4B3ACsLJm+mLg4kbXldG6/ojKONFrgFnJvFnAmuT1FcCSmvb97cbLg8rYFjcDJwE3URngaCNQqt/eVO5+e0LyupS0U6PXYSfXdzrwSH3dE3wbV0cv3DfZbjcBb5mo2xmYB9w32m0LLAGuqJk/qN2OHrnoETCyYTPHvaQ7fCxwF3BARDwJkDzvnzSbCP8WlwF/C/Ql0/sBz0RluFMYvE4jGg51jDsE6AKuSXaHXSVpChN4G0fEE8DngceAJ6lst7uZ2Nu51s5u213a5nkJghENiTmeSZoKfA/4YEQ8t72mKfPGzb+FpNOADRFxd+3slKYxgmXjRQl4JfDViDgW2MzAroI0436dk90apwPzgQOBKVR2i9SbSNt5JIZbz11a/7wEwUiGzRy3JDVRCYFvRcT3k9l/kDQrWT4L2JDMH+//Fq8BFktaByyjsnvoMmBGMtwpDF6niTAcaifQGRF3JdM3UgmGibqNAU4GHomIrojoAb4P/C8m9nautbPbdpe2eV6CYCTDZo5LkkRlpLcHIuILNYtqhwE9h8qxg+r8s5OzD44Hnq12QceDiLg4ImZHxDwq2/GWiDgLuJXKcKcwdH3H9XCoEfF74HFJhyez3gjczwTdxonHgOMl7ZX8N15d5wm7nevs7LZdCbxZ0j5Jb+rNybyRafRBkj14MOZU4HfAw8BHG13PblyvP6bSBbwXuCd5nEpl/+jNwEPJ875Je1E5g+ph4LdUzspo+HqMct1PBG5KXh8C/BLoAL4LtCTzJyXTHcnyQxpd9yjX9RigPdnOPwT2mejbGPgn4EHgPuA6oGUibmfg21SOg/RQ+cv+A6PZtsD7k/XvAN63MzX4FhNmZjmXl11DZmY2DAeBmVnOOQjMzHLOQWBmlnMOAjOznHMQmO2ApBcaXYNZlhwEZmY55yAwGwVJcyXdnNwT/mZJB+9g/jclfU3SzyX9LrlnktmY4CAwG52vANdGxNHAt4Av7WA+VG41/HrgrcDXJE3ac+WaDc9XFpvtgKQXImJq3byNVO4X35Pc9O/JiJi5nfnfBG6LiKuT998GnB8R9+zh1TEbwj0Cs91juL+oYjtt/FeYjQkOArPR+QWVu58CnAXcvoP5AO+QVJB0KJWbp63ZE4Wa7Yh3DZntgKQ+Bt/b/QtU7o9/NTCTyuhh74uIx5JR4tLmf5PKGLttwAHAhRFx055aB7PtcRCY7QFJENwUETc2uhazet41ZGaWc+4RmJnlnHsEZmY55yAwM8s5B4GZWc45CMzMcs5BYGaWc/8fF5m4z+6PEWcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Loop')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 40)                840       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,481\n",
      "Trainable params: 1,481\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
