{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/foldingdiff/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "dataset = \"MPNN\"\n",
    "method = \"AlphaDesign\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_nll_flatten(S, log_probs):\n",
    "    \"\"\" Negative log probabilities \"\"\"\n",
    "    criterion = torch.nn.NLLLoss(reduction='none')\n",
    "    loss = criterion(log_probs, S)\n",
    "    loss_av = loss.mean()\n",
    "    return loss, loss_av\n",
    "\n",
    "def get_metric(S, log_probs):\n",
    "    nll_loss, _ = loss_nll_flatten(S, log_probs)\n",
    "    chain_mask = torch.ones_like(nll_loss)\n",
    "    loss = torch.sum(nll_loss * chain_mask).cpu().data.numpy()\n",
    "    weight = torch.sum(chain_mask).cpu().data.numpy()\n",
    "    return {\"loss\":loss, \"weight\":weight}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Results on test sets of 'CATH4.2', 'CATH4.3', 'MPNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_perp_recovery(result):\n",
    "    import torch.nn as nn\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "    \n",
    "    \n",
    "    all_conf = []\n",
    "    all_rec = []\n",
    "    all_lens = []\n",
    "    for i in range(len(result['title'])):\n",
    "        recovery = (result['true_seq'][i] == result['pred_probs'][i].argmax(dim=1)).float().mean()\n",
    "        \n",
    "        # loss = criterion(torch.log(result['pred_probs'][i]), result['true_seq'][i])\n",
    "        conf = result['pred_probs'][i].max(dim=-1)[0].mean()\n",
    "        \n",
    "\n",
    "        all_conf.append(conf.item())\n",
    "        all_rec.append(recovery.item())\n",
    "        all_lens.append(len(result['true_seq'][i]))\n",
    "    \n",
    "    # print(torch.exp(torch.cat(all_perp).mean()))\n",
    "    all_conf = np.array(all_conf)\n",
    "    all_rec = np.array(all_rec)\n",
    "    all_lens = np.array(all_lens)\n",
    "\n",
    "    summary = {}\n",
    "    if dataset in ['CATH4.2', 'CATH4.3']:\n",
    "        summary['conf(0,100)'] = np.median(all_conf[all_lens<100])\n",
    "        summary['conf(100,300)'] = np.median(all_conf[(100<=all_lens)&(all_lens<300)])\n",
    "        summary['conf(300, 500)'] = np.median(all_conf[(300<=all_lens)&(all_lens<500)])\n",
    "        summary['conffull'] = np.median(all_conf)\n",
    "        \n",
    "        summary['rec(0,100)'] = np.median(all_rec[all_lens<100])\n",
    "        summary['rec(100,300)'] = np.median(all_rec[(100<=all_lens)&(all_lens<300)])\n",
    "        summary['rec(300, 500)'] = np.median(all_rec[(300<=all_lens)&(all_lens<500)])\n",
    "        summary['recfull'] = np.median(all_rec)\n",
    "        \n",
    "    if dataset in ['MPNN']:\n",
    "        summary['conf(0,100)'] = np.median(all_conf[all_lens<100])\n",
    "        summary['conf(100,500)'] = np.median(all_conf[(100<=all_lens)&(all_lens<500)])\n",
    "        summary['conf(500, 1000)'] = np.median(all_conf[(500<=all_lens)&(all_lens<1000)])\n",
    "        summary['conffull'] = np.median(all_conf)\n",
    "        \n",
    "        summary['rec(0,100)'] = np.median(all_rec[all_lens<100])\n",
    "        summary['rec(100,500)'] = np.median(all_rec[(100<=all_lens)&(all_lens<500)])\n",
    "        summary['rec(500, 1000)'] = np.median(all_rec[(500<=all_lens)&(all_lens<1000)])\n",
    "        summary['recfull'] = np.median(all_rec)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data CATH4.2 method StructGNN \t result 0.31\t0.45\t0.45\t0.43\t0.26\t0.36\t0.36\t0.35\n",
      "data CATH4.2 method GraphTrans \t result 0.31\t0.43\t0.43\t0.43\t0.25\t0.35\t0.35\t0.34\n",
      "data CATH4.2 method GCA \t result 0.34\t0.46\t0.47\t0.45\t0.27\t0.38\t0.38\t0.37\n",
      "data CATH4.2 method GVP \t result 0.40\t0.52\t0.53\t0.51\t0.28\t0.40\t0.41\t0.39\n",
      "data CATH4.2 method AlphaDesign \t result 0.36\t0.49\t0.49\t0.47\t0.33\t0.43\t0.44\t0.42\n",
      "data CATH4.2 method ProteinMPNN \t result 0.38\t0.51\t0.52\t0.50\t0.32\t0.47\t0.47\t0.45\n",
      "data CATH4.2 method PiFold \t result 0.44\t0.58\t0.60\t0.57\t0.39\t0.53\t0.56\t0.52\n",
      "data CATH4.2 method KWDesign \t result 0.50\t0.68\t0.72\t0.67\t0.44\t0.62\t0.66\t0.61\n",
      "data CATH4.3 method StructGNN \t result 0.35\t0.41\t0.47\t0.41\t0.30\t0.34\t0.40\t0.34\n",
      "data CATH4.3 method GraphTrans \t result 0.37\t0.42\t0.48\t0.42\t0.29\t0.34\t0.39\t0.34\n",
      "data CATH4.3 method GCA \t result 0.38\t0.43\t0.49\t0.43\t0.32\t0.36\t0.41\t0.36\n",
      "data CATH4.3 method GVP \t result 0.45\t0.51\t0.55\t0.50\t0.33\t0.38\t0.45\t0.38\n",
      "data CATH4.3 method AlphaDesign \t result 0.41\t0.48\t0.53\t0.47\t0.37\t0.43\t0.47\t0.42\n",
      "data CATH4.3 method ProteinMPNN \t result 0.42\t0.49\t0.57\t0.49\t0.38\t0.44\t0.52\t0.44\n",
      "data CATH4.3 method PiFold \t result 0.47\t0.56\t0.64\t0.55\t0.43\t0.52\t0.59\t0.51\n",
      "data CATH4.3 method KWDesign \t result 0.58\t0.68\t0.76\t0.67\t0.51\t0.61\t0.69\t0.60\n",
      "data MPNN method StructGNN \t result 0.49\t0.49\t0.50\t0.49\t0.41\t0.41\t0.42\t0.41\n",
      "data MPNN method GraphTrans \t result 0.48\t0.47\t0.48\t0.48\t0.40\t0.39\t0.40\t0.40\n",
      "data MPNN method GCA \t result 0.45\t0.45\t0.46\t0.45\t0.41\t0.41\t0.42\t0.41\n",
      "data MPNN method GVP \t result 0.51\t0.53\t0.55\t0.54\t0.44\t0.42\t0.45\t0.43\n",
      "data MPNN method AlphaDesign \t result 0.52\t0.53\t0.54\t0.53\t0.48\t0.49\t0.50\t0.49\n",
      "data MPNN method ProteinMPNN \t result 0.54\t0.56\t0.58\t0.57\t0.52\t0.53\t0.55\t0.53\n",
      "data MPNN method PiFold \t result 0.56\t0.60\t0.63\t0.61\t0.54\t0.58\t0.60\t0.58\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/gaozhangyang/experiments/OpenCPD/results/MPNN/KWDesign/results.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mCATH4.2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCATH4.3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMPNN\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \u001b[39mfor\u001b[39;00m method \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mStructGNN\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGraphTrans\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGCA\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGVP\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAlphaDesign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mProteinMPNN\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPiFold\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mKWDesign\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m         result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/gaozhangyang/experiments/OpenCPD/results/\u001b[39;49m\u001b[39m{\u001b[39;49;00mdataset\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mmethod\u001b[39m}\u001b[39;49;00m\u001b[39m/results.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m         summary \u001b[39m=\u001b[39m summary_perp_recovery(result)\n\u001b[1;32m      5\u001b[0m         summary_string \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(summary\u001b[39m.\u001b[39mvalues()))\n",
      "File \u001b[0;32m~/anaconda3/envs/foldingdiff/lib/python3.8/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/foldingdiff/lib/python3.8/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/foldingdiff/lib/python3.8/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/gaozhangyang/experiments/OpenCPD/results/MPNN/KWDesign/results.pt'"
     ]
    }
   ],
   "source": [
    "for dataset in ['CATH4.2', 'CATH4.3', 'MPNN']:\n",
    "    for method in ['StructGNN', 'GraphTrans', 'GCA', 'GVP', 'AlphaDesign', 'ProteinMPNN', 'PiFold', 'KWDesign']:\n",
    "        result = torch.load(f\"/gaozhangyang/experiments/OpenCPD/results/{dataset}/{method}/results.pt\")\n",
    "        summary = summary_perp_recovery(result)\n",
    "        summary_string = '\\t'.join('{:.2f}'.format(x) for x in list(summary.values()))\n",
    "        \n",
    "        print(\"data {} method {} \\t result {}\".format(dataset, method, summary_string))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Results on CASP15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def summary_perp_recovery(result):\n",
    "    all_conf = []\n",
    "    all_rec = []\n",
    "    all_class = []\n",
    "    for i in range(len(result['title'])):\n",
    "        recovery = (result['true_seq'][i] == result['pred_probs'][i].argmax(dim=1)).float().mean()\n",
    "        conf = result['pred_probs'][i].max(dim=-1)[0].mean()\n",
    "        \n",
    "        all_conf.append(conf.item())\n",
    "        all_rec.append(recovery.item())\n",
    "        all_class.append(result['classification'][i])\n",
    "    \n",
    "    # print(torch.exp(torch.cat(all_perp).mean()))\n",
    "    all_conf = np.array(all_conf)\n",
    "    all_rec = np.array(all_rec)\n",
    "    all_class = np.array(all_class)\n",
    "    # print(set(all_class))\n",
    "    # print(np.sort(all_rec))\n",
    "\n",
    "    summary = {}\n",
    "    mask = np.array([ one in ['FM'] for one in all_class])\n",
    "    summary['FM'] = np.median(all_conf[mask])\n",
    "    mask = np.array([ one not in ['FM'] for one in all_class])\n",
    "    summary['TBM'] = np.median(all_conf[mask])\n",
    "    mask = np.array([ one in ['TBM-easy'] for one in all_class])\n",
    "    summary['TBM-easy'] = np.median(all_conf[mask])\n",
    "    mask = np.array([ one in ['TBM-hard'] for one in all_class])\n",
    "    summary['TBM-hard'] = np.median(all_conf[mask])\n",
    "    summary['Full'] = np.median(all_conf)\n",
    "    \n",
    "    mask = np.array([ one in ['FM'] for one in all_class])\n",
    "    summary['rec FM'] = np.median(all_rec[mask])\n",
    "    mask = np.array([ one not in ['FM/TBM'] for one in all_class])\n",
    "    summary['rec TBM'] = np.median(all_rec[mask])\n",
    "    mask = np.array([ one in ['TBM-easy'] for one in all_class])\n",
    "    summary['rec TBM-easy'] = np.median(all_rec[mask])\n",
    "    mask = np.array([ one in ['TBM-hard'] for one in all_class])\n",
    "    summary['rec TBM-hard'] = np.median(all_rec[mask])\n",
    "    summary['rec Full'] = np.median(all_rec)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.load(f\"/gaozhangyang/experiments/OpenCPD/results/{dataset}/{method}/results_casp15.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "2\n",
      "20\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(sum([one =='FM' for one in result['classification']]))\n",
    "print(sum([one =='FM/TBM' for one in result['classification']]))\n",
    "print(sum([one =='TBM-easy' for one in result['classification']]))\n",
    "print(sum([one =='TBM-hard' for one in result['classification']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data CATH4.2 method StructGNN \t result 0.41\t0.46\t0.48\t0.43\t0.45\t0.35\t0.35\t0.38\t0.35\t0.35\n",
      "data CATH4.2 method GraphTrans \t result 0.39\t0.45\t0.46\t0.42\t0.44\t0.33\t0.36\t0.37\t0.36\t0.36\n",
      "data CATH4.2 method GCA \t result 0.48\t0.52\t0.53\t0.48\t0.50\t0.39\t0.40\t0.41\t0.38\t0.40\n",
      "data CATH4.2 method GVP \t result 0.48\t0.49\t0.50\t0.50\t0.49\t0.37\t0.39\t0.42\t0.39\t0.39\n",
      "data CATH4.2 method AlphaDesign \t result 0.44\t0.49\t0.50\t0.46\t0.48\t0.41\t0.42\t0.46\t0.41\t0.42\n",
      "data CATH4.2 method ProteinMPNN \t result 0.49\t0.52\t0.53\t0.51\t0.52\t0.44\t0.44\t0.46\t0.40\t0.44\n",
      "data CATH4.2 method PiFold \t result 0.52\t0.56\t0.59\t0.53\t0.55\t0.47\t0.47\t0.50\t0.47\t0.47\n",
      "data CATH4.2 method KWDesign \t result 0.55\t0.66\t0.70\t0.62\t0.64\t0.49\t0.55\t0.59\t0.55\t0.54\n",
      "data CATH4.3 method StructGNN \t result 0.40\t0.44\t0.45\t0.43\t0.44\t0.35\t0.36\t0.38\t0.37\t0.36\n",
      "data CATH4.3 method GraphTrans \t result 0.39\t0.45\t0.46\t0.43\t0.45\t0.35\t0.35\t0.37\t0.35\t0.35\n",
      "data CATH4.3 method GCA \t result 0.46\t0.49\t0.51\t0.44\t0.48\t0.37\t0.41\t0.43\t0.40\t0.41\n",
      "data CATH4.3 method GVP \t result 0.47\t0.49\t0.50\t0.48\t0.49\t0.37\t0.39\t0.41\t0.38\t0.39\n",
      "data CATH4.3 method AlphaDesign \t result 0.44\t0.50\t0.50\t0.47\t0.48\t0.40\t0.42\t0.44\t0.44\t0.42\n",
      "data CATH4.3 method ProteinMPNN \t result 0.49\t0.52\t0.53\t0.49\t0.52\t0.44\t0.46\t0.48\t0.43\t0.46\n",
      "data CATH4.3 method PiFold \t result 0.54\t0.55\t0.56\t0.51\t0.54\t0.47\t0.49\t0.52\t0.49\t0.49\n",
      "data CATH4.3 method KWDesign \t result 0.59\t0.66\t0.70\t0.63\t0.65\t0.50\t0.57\t0.59\t0.60\t0.56\n",
      "data MPNN method StructGNN \t result 0.46\t0.49\t0.53\t0.47\t0.48\t0.39\t0.41\t0.42\t0.41\t0.41\n",
      "data MPNN method GraphTrans \t result 0.43\t0.49\t0.51\t0.45\t0.48\t0.38\t0.41\t0.44\t0.40\t0.41\n",
      "data MPNN method GCA \t result 0.45\t0.48\t0.49\t0.45\t0.47\t0.40\t0.43\t0.44\t0.43\t0.43\n",
      "data MPNN method GVP \t result 0.51\t0.53\t0.55\t0.53\t0.53\t0.40\t0.43\t0.47\t0.43\t0.43\n",
      "data MPNN method AlphaDesign \t result 0.49\t0.53\t0.54\t0.50\t0.51\t0.43\t0.46\t0.48\t0.46\t0.46\n",
      "data MPNN method ProteinMPNN \t result 0.56\t0.55\t0.58\t0.55\t0.55\t0.52\t0.52\t0.55\t0.51\t0.52\n",
      "data MPNN method PiFold \t result 0.55\t0.57\t0.59\t0.53\t0.57\t0.52\t0.53\t0.53\t0.52\t0.53\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/gaozhangyang/experiments/OpenCPD/results/MPNN/KWDesign/results_casp15.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mCATH4.2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCATH4.3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMPNN\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m      2\u001b[0m     \u001b[39mfor\u001b[39;00m method \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mStructGNN\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGraphTrans\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGCA\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mGVP\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mAlphaDesign\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mProteinMPNN\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mPiFold\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mKWDesign\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m         result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/gaozhangyang/experiments/OpenCPD/results/\u001b[39;49m\u001b[39m{\u001b[39;49;00mdataset\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mmethod\u001b[39m}\u001b[39;49;00m\u001b[39m/results_casp15.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m         summary \u001b[39m=\u001b[39m summary_perp_recovery(result)\n\u001b[1;32m      5\u001b[0m         summary_string \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(summary\u001b[39m.\u001b[39mvalues()))\n",
      "File \u001b[0;32m~/anaconda3/envs/foldingdiff/lib/python3.8/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/foldingdiff/lib/python3.8/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/foldingdiff/lib/python3.8/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/gaozhangyang/experiments/OpenCPD/results/MPNN/KWDesign/results_casp15.pt'"
     ]
    }
   ],
   "source": [
    "for dataset in ['CATH4.2', 'CATH4.3', 'MPNN']:\n",
    "    for method in ['StructGNN', 'GraphTrans', 'GCA', 'GVP', 'AlphaDesign', 'ProteinMPNN', 'PiFold', 'KWDesign']:\n",
    "        result = torch.load(f\"/gaozhangyang/experiments/OpenCPD/results/{dataset}/{method}/results_casp15.pt\")\n",
    "        summary = summary_perp_recovery(result)\n",
    "        summary_string = '\\t'.join('{:.2f}'.format(x) for x in list(summary.values()))\n",
    "        \n",
    "        print(\"data {} method {} \\t result {}\".format(dataset, method, summary_string))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Results on noisy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_perp_recovery(result):\n",
    "    import torch.nn as nn\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "    \n",
    "    \n",
    "    all_conf = []\n",
    "    all_rec = []\n",
    "    all_lens = []\n",
    "    for i in range(len(result['title'])):\n",
    "        recovery = (result['true_seq'][i] == result['pred_probs'][i].argmax(dim=1)).float().mean()\n",
    "        \n",
    "        # loss = criterion(torch.log(result['pred_probs'][i]), result['true_seq'][i])\n",
    "        conf = result['pred_probs'][i].max(dim=-1)[0].mean()\n",
    "        \n",
    "\n",
    "        all_conf.append(conf.item())\n",
    "        all_rec.append(recovery.item())\n",
    "        all_lens.append(len(result['true_seq'][i]))\n",
    "    \n",
    "    # print(torch.exp(torch.cat(all_perp).mean()))\n",
    "    all_conf = np.array(all_conf)\n",
    "    all_rec = np.array(all_rec)\n",
    "    all_lens = np.array(all_lens)\n",
    "\n",
    "    summary = {}\n",
    "    if dataset in ['CATH4.2', 'CATH4.3']:\n",
    "        summary['conf(0,100)'] = np.median(all_conf[all_lens<100])\n",
    "        summary['conf(100,300)'] = np.median(all_conf[(100<=all_lens)&(all_lens<300)])\n",
    "        summary['conf(300, 500)'] = np.median(all_conf[(300<=all_lens)&(all_lens<500)])\n",
    "        summary['conffull'] = np.median(all_conf)\n",
    "        \n",
    "        summary['rec(0,100)'] = np.median(all_rec[all_lens<100])\n",
    "        summary['rec(100,300)'] = np.median(all_rec[(100<=all_lens)&(all_lens<300)])\n",
    "        summary['rec(300, 500)'] = np.median(all_rec[(300<=all_lens)&(all_lens<500)])\n",
    "        summary['recfull'] = np.median(all_rec)\n",
    "        \n",
    "    if dataset in ['MPNN']:\n",
    "        summary['conf(0,100)'] = np.median(all_conf[all_lens<100])\n",
    "        summary['conf(100,500)'] = np.median(all_conf[(100<=all_lens)&(all_lens<500)])\n",
    "        summary['conf(500, 1000)'] = np.median(all_conf[(500<=all_lens)&(all_lens<1000)])\n",
    "        summary['conffull'] = np.median(all_conf)\n",
    "        \n",
    "        summary['rec(0,100)'] = np.median(all_rec[all_lens<100])\n",
    "        summary['rec(100,500)'] = np.median(all_rec[(100<=all_lens)&(all_lens<500)])\n",
    "        summary['rec(500, 1000)'] = np.median(all_rec[(500<=all_lens)&(all_lens<1000)])\n",
    "        summary['recfull'] = np.median(all_rec)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data CATH4.3 method StructGNN \t result 0.27\t0.26\t0.28\t0.27\t0.19\t0.20\t0.21\t0.20\n",
      "data CATH4.3 method GraphTrans \t result 0.26\t0.26\t0.27\t0.26\t0.19\t0.19\t0.20\t0.20\n",
      "data CATH4.3 method GCA \t result 0.25\t0.25\t0.26\t0.25\t0.19\t0.19\t0.20\t0.19\n",
      "data CATH4.3 method GVP \t result 0.47\t0.53\t0.56\t0.52\t0.32\t0.37\t0.43\t0.38\n",
      "data CATH4.3 method AlphaDesign \t result 0.16\t0.16\t0.15\t0.16\t0.18\t0.18\t0.18\t0.18\n",
      "data CATH4.3 method ProteinMPNN \t result 0.31\t0.30\t0.32\t0.31\t0.22\t0.23\t0.25\t0.23\n",
      "data CATH4.3 method PiFold \t result 0.28\t0.29\t0.32\t0.29\t0.26\t0.28\t0.29\t0.28\n",
      "data CATH4.3 method KWDesign \t result 0.33\t0.42\t0.45\t0.40\t0.29\t0.37\t0.41\t0.35\n"
     ]
    }
   ],
   "source": [
    "dataset = 'CATH4.3'\n",
    "for eps in [0.02, 0.2, 0.5, 1.0]:\n",
    "    for method in ['StructGNN', 'GraphTrans', 'GCA', 'GVP', 'AlphaDesign', 'ProteinMPNN', 'PiFold', 'KWDesign']:\n",
    "        result = torch.load(f\"/gaozhangyang/experiments/OpenCPD/results/{dataset}/{method}_{eps}/results.pt\")\n",
    "        summary = summary_perp_recovery(result)\n",
    "        summary_string = '\\t'.join('{:.2f}'.format(x) for x in list(summary.values()))\n",
    "        \n",
    "        print(\"data {} method {} \\t result {}\".format(dataset, method, summary_string))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "foldingdiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
