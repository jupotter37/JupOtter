{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lenet GPU Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1V0DrfF-rzrrOa-fotlb37F_JCLXht6xE",
      "authorship_tag": "ABX9TyMhKVEW25G1R+SCZ+X3B3Uc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/butchland/fastai_xla_extensions/blob/master/explore_nbs/Lenet_GPU_Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-tBqdi3QkwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9ZfMyQ-QBNc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e353b791-2d15-4751-ce37-222f1464d60a"
      },
      "source": [
        "!curl -s https://course.fast.ai/setup/colab | bash"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updating fastai...\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKG0jp3qQaiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRPhSOcdQxUj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "dbdc9f73-dddb-4def-e89d-85e40c23a5a3"
      },
      "source": [
        "!pip install git+https://github.com/fastai/fastcore > /dev/null\n",
        "!pip install git+https://github.com/fastai/fastai2 > /dev/null"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Running command git clone -q https://github.com/fastai/fastcore /tmp/pip-req-build-63uhmdc8\n",
            "  Running command git clone -q https://github.com/fastai/fastai2 /tmp/pip-req-build-f_m_2atp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3W8ceW8Sfcq",
        "colab_type": "text"
      },
      "source": [
        "### import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4lEWn5oRcnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.vision.all import *"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufciiDFgSlMi",
        "colab_type": "text"
      },
      "source": [
        "### load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40b2trH0RiTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "00f34d6b-9a05-4f2d-849c-adb5eb8ecc4c"
      },
      "source": [
        "path = untar_data(URLs.MNIST_SAMPLE)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fVYN5xCSowS",
        "colab_type": "text"
      },
      "source": [
        "### datablock and dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLLL8RpURx0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datablock = DataBlock(\n",
        "    blocks=(ImageBlock, CategoryBlock),\n",
        "    get_items = get_image_files,\n",
        "    get_y=parent_label,\n",
        "    splitter=GrandparentSplitter(),\n",
        "    item_tfms=Resize(28),\n",
        "    batch_tfms=[]\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXhcup22T3p9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "outputId": "dbf815ff-7069-4c09-f519-9b96b895bb3c"
      },
      "source": [
        "datablock.summary(path)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting-up type transforms pipelines\n",
            "Collecting items from /root/.fastai/data/mnist_sample\n",
            "Found 14434 items\n",
            "2 datasets of sizes 12396,2038\n",
            "Setting up Pipeline: PILBase.create\n",
            "Setting up Pipeline: parent_label -> Categorize\n",
            "\n",
            "Building one sample\n",
            "  Pipeline: PILBase.create\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_sample/train/7/50359.png\n",
            "    applying PILBase.create gives\n",
            "      PILImage mode=RGB size=28x28\n",
            "  Pipeline: parent_label -> Categorize\n",
            "    starting from\n",
            "      /root/.fastai/data/mnist_sample/train/7/50359.png\n",
            "    applying parent_label gives\n",
            "      7\n",
            "    applying Categorize gives\n",
            "      TensorCategory(1)\n",
            "\n",
            "Final sample: (PILImage mode=RGB size=28x28, TensorCategory(1))\n",
            "\n",
            "\n",
            "Setting up after_item: Pipeline: Resize -> ToTensor\n",
            "Setting up before_batch: Pipeline: \n",
            "Setting up after_batch: Pipeline: IntToFloatTensor\n",
            "\n",
            "Building one batch\n",
            "Applying item_tfms to the first sample:\n",
            "  Pipeline: Resize -> ToTensor\n",
            "    starting from\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(1))\n",
            "    applying Resize gives\n",
            "      (PILImage mode=RGB size=28x28, TensorCategory(1))\n",
            "    applying ToTensor gives\n",
            "      (TensorImage of size 3x28x28, TensorCategory(1))\n",
            "\n",
            "Adding the next 3 samples\n",
            "\n",
            "No before_batch transform to apply\n",
            "\n",
            "Collating items in a batch\n",
            "\n",
            "Applying batch_tfms to the batch built\n",
            "  Pipeline: IntToFloatTensor\n",
            "    starting from\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([1, 1, 1, 1], device='cuda:0'))\n",
            "    applying IntToFloatTensor gives\n",
            "      (TensorImage of size 4x3x28x28, TensorCategory([1, 1, 1, 1], device='cuda:0'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8dpOfrTS95n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15aa95a4-0b0b-4122-b902-e38eef839eed"
      },
      "source": [
        "dls = datablock.dataloaders(path)\n",
        "dls.vocab"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2) ['3','7']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1EIPoFLUIuX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "221fea5b-e1ca-4579-a243-abd08d954d08"
      },
      "source": [
        "dls.show_batch()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 648x648 with 9 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoJrJqx8BO30",
        "colab_type": "text"
      },
      "source": [
        "# Lenet with convs and F.max_pool2d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfJVAsAerFku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyLenet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyLenet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6,16,3)\n",
        "        self.hiden4 = nn.Linear(400, 2) # 2 outputs instead of 10\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = self.hiden4(x)\n",
        "        return x\n",
        "    \n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYtbx-hsZzn_",
        "colab_type": "text"
      },
      "source": [
        "### Import verbose callback"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "231bOGyIZ5-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai2.test_utils import *"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw-vTFtlgf9K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VerboseCallback?"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJXkmPvqTZbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "lenet = MyLenet()\n",
        "learn = Learner(dls, lenet, metrics=[error_rate, accuracy],cbs=VerboseCallback())\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MiziK2xxZpbl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "7ab40d10-abef-44bf-b325-64b56a36ba35"
      },
      "source": [
        "learn.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "MyLenet (Input shape: ['64 x 3 x 28 x 28'])\n",
              "================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "================================================================\n",
              "Conv2d               64 x 6 x 26 x 26     168        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 16 x 11 x 11    880        True      \n",
              "________________________________________________________________\n",
              "Linear               64 x 2               802        True      \n",
              "________________________________________________________________\n",
              "\n",
              "Total params: 1,850\n",
              "Total trainable params: 1,850\n",
              "Total non-trainable params: 0\n",
              "\n",
              "Optimizer used: <function Adam at 0x7f2257da3d90>\n",
              "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback\n",
              "  - VerboseCallback"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evkvSGRzZtko",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "c9050c2d-c58c-4b6f-c060-12dd5ac74a92"
      },
      "source": [
        "learn.show_training_loop()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Fit\n",
            "   - begin_fit      : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "  Start Epoch Loop\n",
            "     - begin_epoch    : [Recorder, ProgressCallback]\n",
            "    Start Train\n",
            "       - begin_train    : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      Start Batch Loop\n",
            "         - begin_batch    : []\n",
            "         - after_pred     : []\n",
            "         - after_loss     : []\n",
            "         - after_backward : []\n",
            "         - after_step     : []\n",
            "         - after_cancel_batch: []\n",
            "         - after_batch    : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      End Batch Loop\n",
            "    End Train\n",
            "     - after_cancel_train: [Recorder]\n",
            "     - after_train    : [Recorder, ProgressCallback]\n",
            "    Start Valid\n",
            "       - begin_validate : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      Start Batch Loop\n",
            "         - **CBs same as train batch**: []\n",
            "      End Batch Loop\n",
            "    End Valid\n",
            "     - after_cancel_validate: [Recorder]\n",
            "     - after_validate : [Recorder, ProgressCallback]\n",
            "  End Epoch Loop\n",
            "   - after_cancel_epoch: []\n",
            "   - after_epoch    : [Recorder]\n",
            "End Fit\n",
            " - after_cancel_fit: []\n",
            " - after_fit      : [ProgressCallback]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-GahuFvTcHk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "40a8845c-265c-458e-d896-b0d42e643bf7"
      },
      "source": [
        "learn.fit_one_cycle(1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.042765</td>\n",
              "      <td>0.056226</td>\n",
              "      <td>0.019627</td>\n",
              "      <td>0.980373</td>\n",
              "      <td>00:24</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "begin_epoch\n",
            "begin_train\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "after_train\n",
            "begin_validate\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "after_validate\n",
            "after_epoch\n",
            "after_fit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoJpiJ4lr6WA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7f1dbcf8-90f8-4927-9937-477a970ee4a5"
      },
      "source": [
        "learn.validate()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin_fit\n",
            "begin_epoch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "begin_validate\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "after_validate\n",
            "after_epoch\n",
            "after_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [0.07420620322227478,0.02453385666012764,0.9754661321640015]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YujM_GLxBW4_",
        "colab_type": "text"
      },
      "source": [
        "# Lenet with layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RETI5TWYyn6C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Lenet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Lenet2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        self.fc1 = nn.Linear(400, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 2) # Only 2 outputs instead of 10\n",
        "    def forward(self, x):\n",
        "        # Max pooling over a (2, 2) window\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UNVAT2_Tgb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "lenet2 = Lenet2()\n",
        "learn2 = Learner(dls,lenet2, metrics=[error_rate, accuracy],cbs=VerboseCallback)\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odd_55uGZbLy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "41499099-b531-4c65-a77c-35ac9cf3b190"
      },
      "source": [
        "learn2.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "Lenet2 (Input shape: ['64 x 3 x 28 x 28'])\n",
              "================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "================================================================\n",
              "Conv2d               64 x 6 x 26 x 26     168        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 16 x 11 x 11    880        True      \n",
              "________________________________________________________________\n",
              "Linear               64 x 120             48,120     True      \n",
              "________________________________________________________________\n",
              "Linear               64 x 84              10,164     True      \n",
              "________________________________________________________________\n",
              "Linear               64 x 2               170        True      \n",
              "________________________________________________________________\n",
              "\n",
              "Total params: 59,502\n",
              "Total trainable params: 59,502\n",
              "Total non-trainable params: 0\n",
              "\n",
              "Optimizer used: <function Adam at 0x7f2257da3d90>\n",
              "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback\n",
              "  - VerboseCallback"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njAt5XwQZeo8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "975ae403-9acb-485a-dc2d-5a37c8fd605b"
      },
      "source": [
        "learn2.show_training_loop()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start Fit\n",
            "   - begin_fit      : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "  Start Epoch Loop\n",
            "     - begin_epoch    : [Recorder, ProgressCallback]\n",
            "    Start Train\n",
            "       - begin_train    : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      Start Batch Loop\n",
            "         - begin_batch    : []\n",
            "         - after_pred     : []\n",
            "         - after_loss     : []\n",
            "         - after_backward : []\n",
            "         - after_step     : []\n",
            "         - after_cancel_batch: []\n",
            "         - after_batch    : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      End Batch Loop\n",
            "    End Train\n",
            "     - after_cancel_train: [Recorder]\n",
            "     - after_train    : [Recorder, ProgressCallback]\n",
            "    Start Valid\n",
            "       - begin_validate : [TrainEvalCallback, Recorder, ProgressCallback]\n",
            "      Start Batch Loop\n",
            "         - **CBs same as train batch**: []\n",
            "      End Batch Loop\n",
            "    End Valid\n",
            "     - after_cancel_validate: [Recorder]\n",
            "     - after_validate : [Recorder, ProgressCallback]\n",
            "  End Epoch Loop\n",
            "   - after_cancel_epoch: []\n",
            "   - after_epoch    : [Recorder]\n",
            "End Fit\n",
            " - after_cancel_fit: []\n",
            " - after_fit      : [ProgressCallback]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag_62Vo8afS9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xb,yb = learn2.dls.one_batch()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0frS7KwTiF9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9980eecf-7b54-418d-a351-b0c1e7127bca"
      },
      "source": [
        "\n",
        "learn2.fit_one_cycle(1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.054064</td>\n",
              "      <td>0.035105</td>\n",
              "      <td>0.010795</td>\n",
              "      <td>0.989205</td>\n",
              "      <td>00:25</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "begin_epoch\n",
            "begin_train\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_backward\n",
            "after_step\n",
            "after_batch\n",
            "after_train\n",
            "begin_validate\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "after_validate\n",
            "after_epoch\n",
            "after_fit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5hVwXWH0DW0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e443c935-7bbe-4a2a-91b1-ac8f115a16ac"
      },
      "source": [
        "learn2.validate()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin_fit\n",
            "begin_epoch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "begin_validate\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "after_batch\n",
            "after_validate\n",
            "after_epoch\n",
            "after_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#3) [0.03510477766394615,0.010794896632432938,0.9892051219940186]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bO4LWDFcZX5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdeNARoitRPW",
        "colab_type": "text"
      },
      "source": [
        "# patch one_batch with the code and some extra prints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUqCVrDa7hFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import traceback\n",
        "\n",
        "@patch_to(Learner)\n",
        "def one_batch(self, i, b):\n",
        "        print(f\"******************** self is {self} i is {i}\")\n",
        "        self.iter = i\n",
        "        try:\n",
        "            self._split(b);                                  self('begin_batch')\n",
        "            self.pred = self.model(*self.xb);                self('after_pred')\n",
        "            if len(self.yb) == 0: return\n",
        "            self.loss = self.loss_func(self.pred, *self.yb); self('after_loss')\n",
        "            print(f\"******************** self.loss is {self.loss}\")\n",
        "            print(f\"******************** self.loss.device = {self.loss.device}\")\n",
        "            if not self.training: return\n",
        "            print(f\"******************** will calculate gradient for loss {type(self.loss)} {self.loss.shape}\")\n",
        "            try:\n",
        "              self.loss.backward()\n",
        "            except Exception as e:\n",
        "              print(f\"******************** did fail\")\n",
        "              print(f\"{e}\")\n",
        "              tb = sys.exc_info()[2]\n",
        "              #etype, value, tb = e\n",
        "              traceback.print_tb(tb) #print_exception(e)\n",
        "\n",
        "            self.loss.backward();                            self('after_backward')\n",
        "            print(f\"******************** PASSED\")\n",
        "            self.opt.step();                                 self('after_step')\n",
        "            self.opt.zero_grad()\n",
        "        except CancelBatchException:                         self('after_cancel_batch')\n",
        "        finally:                                             self('after_batch')\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l3uDp5OdhxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "efd22d4d-b37b-45d6-8a91-aaa0d8553c35"
      },
      "source": [
        "\n",
        "#my_one_batch(tpu_learner, 0, 64)\n",
        "print(learn2.splitter)\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<function trainable_params at 0x7f2275a08378>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh6B2piLdkdN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "06fcfe81-8ec9-4e9f-9c55-69930cb6a3f6"
      },
      "source": [
        "\n",
        "print(learn2._split)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Learner._split of <fastai2.learner.Learner object at 0x7f2256b405c0>>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe2FbKgudl7l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "2d2092c1-7449-4588-a732-efc69a28be2d"
      },
      "source": [
        "\n",
        "learn2.fit(1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "begin_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.014093</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "begin_epoch\n",
            "begin_train\n",
            "******************** self is <fastai2.learner.Learner object at 0x7f2256b405c0> i is 0\n",
            "begin_batch\n",
            "after_pred\n",
            "after_loss\n",
            "******************** self.loss is 0.014092803932726383\n",
            "******************** self.loss.device = cuda:0\n",
            "******************** will calculate gradient for loss <class 'torch.Tensor'> torch.Size([])\n",
            "after_batch\n",
            "after_train\n",
            "after_epoch\n",
            "after_fit\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-7c96e3de52df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/utils.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m;\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m;\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-1e32554548bb>\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m     23\u001b[0m               \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_tb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#print_exception(e)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"******************** PASSED\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlIYRtvinEnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn3 = Learner(dls,lenet2, metrics=[error_rate, accuracy])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB_BBsO8oDnR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "1c592152-c6ae-4a87-8719-ad4c3f088f15"
      },
      "source": [
        "learn3.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "Lenet2 (Input shape: ['64 x 3 x 28 x 28'])\n",
              "================================================================\n",
              "Layer (type)         Output Shape         Param #    Trainable \n",
              "================================================================\n",
              "Conv2d               64 x 6 x 26 x 26     168        True      \n",
              "________________________________________________________________\n",
              "Conv2d               64 x 16 x 11 x 11    880        True      \n",
              "________________________________________________________________\n",
              "Linear               64 x 120             48,120     True      \n",
              "________________________________________________________________\n",
              "Linear               64 x 84              10,164     True      \n",
              "________________________________________________________________\n",
              "Linear               64 x 2               170        True      \n",
              "________________________________________________________________\n",
              "\n",
              "Total params: 59,502\n",
              "Total trainable params: 59,502\n",
              "Total non-trainable params: 0\n",
              "\n",
              "Optimizer used: <function Adam at 0x7f2257da3d90>\n",
              "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
              "\n",
              "Callbacks:\n",
              "  - TrainEvalCallback\n",
              "  - Recorder\n",
              "  - ProgressCallback"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tb6Gj7BKoGna",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "outputId": "ec6431f9-25ec-401f-eba4-a3528a6e7e3a"
      },
      "source": [
        "learn3.fit(1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>error_rate</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.008904</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "******************** self is <fastai2.learner.Learner object at 0x7f2256a76a90> i is 0\n",
            "******************** self.loss is 0.008904187008738518\n",
            "******************** self.loss.device = cuda:0\n",
            "******************** will calculate gradient for loss <class 'torch.Tensor'> torch.Size([])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-20bb22a4140b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/utils.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m;\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m;\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-1e32554548bb>\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m     23\u001b[0m               \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_tb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#print_exception(e)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"******************** PASSED\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rAVTzvRoQBK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "9847a638-a660-4506-cc69-a52603f1dfdd"
      },
      "source": [
        "learn3.lr_find()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "******************** self is <fastai2.learner.Learner object at 0x7f2256a76a90> i is 0\n",
            "******************** self.loss is 0.1876199096441269\n",
            "******************** self.loss.device = cuda:0\n",
            "******************** will calculate gradient for loss <class 'torch.Tensor'> torch.Size([])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-a0a84c475a8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/callback/schedule.py\u001b[0m in \u001b[0;36mlr_find\u001b[0;34m(self, start_lr, end_lr, num_it, stop_div, show_plot, suggestions)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mn_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0mcb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLRFinder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_it\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop_div\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_logging\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshow_plot\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecorder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_lr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msuggestions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastcore/utils.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0minit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'init_args'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0minst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mto_return\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, n_epoch, lr, wd, cbs, reset_opt)\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m;\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_epoch_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mCancelEpochException\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36m_do_epoch_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m;\u001b[0m                        \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'begin_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCancelTrainException\u001b[0m\u001b[0;34m:\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_cancel_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m                                             \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/fastai2/learner.py\u001b[0m in \u001b[0;36mall_batches\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mall_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-1e32554548bb>\u001b[0m in \u001b[0;36mone_batch\u001b[0;34m(self, i, b)\u001b[0m\n\u001b[1;32m     23\u001b[0m               \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_tb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#print_exception(e)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_backward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"******************** PASSED\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m                                 \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yvpagz9oU0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}