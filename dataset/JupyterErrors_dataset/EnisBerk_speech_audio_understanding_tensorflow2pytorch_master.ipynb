{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow2pytorch_master.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EnisBerk/speech_audio_understanding/blob/master/tensorflow2pytorch_master.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "dRpHisuHplqc",
        "colab_type": "code",
        "outputId": "b3001b99-57dd-4921-8726-ab4627a7f7b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install https://download.pytorch.org/whl/cu100/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl\n",
        "!pip3 install torchvision\n",
        "!pip install numpy scipy resampy six pysoundfile pydub\n",
        "\n",
        "!pip install -U git+https://github.com/Microsoft/MMdnn.git@master\n",
        "\n",
        "!pip install tensorflow six\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.0.1.post2 from https://download.pytorch.org/whl/cu100/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl in /usr/local/lib/python3.6/dist-packages (1.0.1.post2)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.0.1.post2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.16.1)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.16.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.1.0)\n",
            "Requirement already satisfied: resampy in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (1.11.0)\n",
            "Requirement already satisfied: pysoundfile in /usr/local/lib/python3.6/dist-packages (0.9.0.post1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.6/dist-packages (0.23.1)\n",
            "Requirement already satisfied: numba>=0.32 in /usr/local/lib/python3.6/dist-packages (from resampy) (0.40.1)\n",
            "Requirement already satisfied: cffi>=0.6 in /usr/local/lib/python3.6/dist-packages (from pysoundfile) (1.12.0)\n",
            "Requirement already satisfied: llvmlite>=0.25.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.32->resampy) (0.27.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=0.6->pysoundfile) (2.19)\n",
            "Collecting git+https://github.com/Microsoft/MMdnn.git@master\n",
            "  Cloning https://github.com/Microsoft/MMdnn.git (to revision master) to /tmp/pip-req-build-nn79nnrd\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from mmdnn==0.2.3) (1.16.1)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from mmdnn==0.2.3) (3.6.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from mmdnn==0.2.3) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from mmdnn==0.2.3) (5.4.1)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->mmdnn==0.2.3) (40.8.0)\n",
            "Building wheels for collected packages: mmdnn\n",
            "  Building wheel for mmdnn (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-coucwdfo/wheels/8c/32/7c/0d1fe129de14a44724cbba5de825891bab6992851fe52606c5\n",
            "Successfully built mmdnn\n",
            "Installing collected packages: mmdnn\n",
            "  Found existing installation: mmdnn 0.2.3\n",
            "    Uninstalling mmdnn-0.2.3:\n",
            "      Successfully uninstalled mmdnn-0.2.3\n",
            "Successfully installed mmdnn-0.2.3\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.13.0rc1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (1.11.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.13.0rc0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.7)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.6.1)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.9)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0rc0->tensorflow) (2.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python3.6/dist-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0rc0->tensorflow) (5.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Co0iEWLopmjm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import torch\n",
        "import imp\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "from pydub import AudioSegment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5N7qeYWVpn0e",
        "colab_type": "code",
        "outputId": "98b75012-eaeb-4804-a43e-7a492f6052fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "!curl -O https://storage.googleapis.com/audioset/vggish_model.ckpt\n",
        "!curl -O https://storage.googleapis.com/audioset/vggish_pca_params.npz\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        " # Copy the source files to the current directory.\n",
        "\n",
        "!cp models/research/audioset/* .\n",
        "\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  277M  100  277M    0     0   141M      0  0:00:01  0:00:01 --:--:--  141M\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 73020  100 73020    0     0  3961k      0 --:--:-- --:--:-- --:--:-- 3961k\n",
            "fatal: destination path 'models' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "phc-bfovpqHc",
        "colab_type": "code",
        "outputId": "d591ecc7-c470-4647-b415-cc27db7901dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "import vggish_slim\n",
        "import vggish_params\n",
        "import vggish_input\n",
        "\n",
        "\n",
        "def CreateVGGishNetwork(hop_size=0.96):   # Hop size is in seconds.\n",
        "  \"\"\"Define VGGish model, load the checkpoint, and save model.\n",
        "  \"\"\"\n",
        "  vggish_slim.define_vggish_slim()\n",
        "  checkpoint_path = 'vggish_model.ckpt'\n",
        "  vggish_params.EXAMPLE_HOP_SECONDS = hop_size\n",
        "  \n",
        "  vggish_slim.load_vggish_slim_checkpoint(sess, checkpoint_path)\n",
        "\n",
        "  features_tensor = sess.graph.get_tensor_by_name(\n",
        "      vggish_params.INPUT_TENSOR_NAME)\n",
        "  embedding_tensor = sess.graph.get_tensor_by_name(\n",
        "      vggish_params.OUTPUT_TENSOR_NAME)\n",
        "  saver = tf.train.Saver()\n",
        "  save_path = saver.save(sess, \"tf_vggish_model.ckpt\")\n",
        "  print(\"INPUT_TENSOR_NAME: \",vggish_params.INPUT_TENSOR_NAME)\n",
        "  print(\"OUTPUT_TENSOR_NAME: \",vggish_params.OUTPUT_TENSOR_NAME)\n",
        "  layers = {'conv1': 'vggish/conv1/Relu',\n",
        "            'pool1': 'vggish/pool1/MaxPool',\n",
        "            'conv2': 'vggish/conv2/Relu',\n",
        "            'pool2': 'vggish/pool2/MaxPool',\n",
        "            'conv3': 'vggish/conv3/conv3_2/Relu',\n",
        "            'pool3': 'vggish/pool3/MaxPool',\n",
        "            'conv4': 'vggish/conv4/conv4_2/Relu',\n",
        "            'pool4': 'vggish/pool4/MaxPool',\n",
        "            'fc1': 'vggish/fc1/fc1_2/Relu',\n",
        "            'fc2': 'vggish/fc2/Relu',\n",
        "            'embedding': 'vggish/embedding',\n",
        "            'features': 'vggish/input_features',\n",
        "         }\n",
        "  g = tf.get_default_graph()\n",
        "  for k in layers:\n",
        "    layers[k] = g.get_tensor_by_name( layers[k] + ':0')\n",
        "    \n",
        "  return {'features': features_tensor,\n",
        "          'embedding': embedding_tensor,\n",
        "          'layers': layers,\n",
        "         }\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SDhdM0JSpqyk",
        "colab_type": "code",
        "outputId": "e405f8ae-1c34-4e0a-a69e-e3c73196e599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "sess = tf.Session()\n",
        "\n",
        "vgg=CreateVGGishNetwork()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/layers/python/layers/layers.py:1624: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.flatten instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n",
            "INPUT_TENSOR_NAME:  vggish/input_features:0\n",
            "OUTPUT_TENSOR_NAME:  vggish/embedding:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZlNOalT2qKep",
        "colab_type": "code",
        "outputId": "80de6c2d-3c87-444d-f95c-180ba9650ec1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "cell_type": "code",
      "source": [
        "!mmconvert -sf tensorflow -in tf_vggish_model.ckpt.meta -iw tf_vggish_model.ckpt --dstNode vggish/embedding -df pytorch -om tf_to_pytorch_vggish_model.pth"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parse file [tf_vggish_model.ckpt.meta] with binary format successfully.\n",
            "Tensorflow model file [tf_vggish_model.ckpt.meta] loaded successfully.\n",
            "Tensorflow checkpoint file [tf_vggish_model.ckpt] loaded successfully. [18] variables loaded.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/mmdnn/conversion/tensorflow/tensorflow_parser.py:263: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.compat.v1.graph_util.extract_sub_graph\n",
            "2019-02-25 02:26:33.363435: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying fold_constants\n",
            "2019-02-25 02:26:33.394145: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-02-25 02:26:33.394428: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x35851e0 executing computations on platform Host. Devices:\n",
            "2019-02-25 02:26:33.394479: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-02-25 02:26:33.462310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-02-25 02:26:33.462866: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3584b00 executing computations on platform CUDA. Devices:\n",
            "2019-02-25 02:26:33.462904: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2019-02-25 02:26:33.463281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 10.47GiB\n",
            "2019-02-25 02:26:33.463316: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
            "2019-02-25 02:26:33.867085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-02-25 02:26:33.867173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
            "2019-02-25 02:26:33.867202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
            "2019-02-25 02:26:33.867466: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2019-02-25 02:26:33.867531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10137 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "IR network structure is saved as [250eee1e29b74e3dbf614b1db597a114.json].\n",
            "IR network structure is saved as [250eee1e29b74e3dbf614b1db597a114.pb].\n",
            "IR weights are saved as [250eee1e29b74e3dbf614b1db597a114.npy].\n",
            "Parse file [250eee1e29b74e3dbf614b1db597a114.pb] with binary format successfully.\n",
            "Target network code snippet is saved as [tf_to_pytorch_vggish_model.py].\n",
            "Target weights are saved as [250eee1e29b74e3dbf614b1db597a114.npy].\n",
            "PyTorch model file is saved as [tf_to_pytorch_vggish_model.pth], generated by [tf_to_pytorch_vggish_model.py] and [250eee1e29b74e3dbf614b1db597a114.npy]. Notice that you may need [tf_to_pytorch_vggish_model.py] to load the model back.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZvcU6ooqPgbA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7S6Y8ibcN5On",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "5c34eedb-68cc-4d2f-8770-f0f661a2c921"
      },
      "cell_type": "code",
      "source": [
        "MainModel = imp.load_source('MainModel', \"tf_to_pytorch_vggish_model.py\")\n",
        "\n",
        "the_model = torch.load(\"tf_to_pytorch_vggish_model.pth\")\n",
        "the_model.eval()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KitModel(\n",
              "  (vggish_conv1_Conv2D): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (vggish_conv2_Conv2D): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (vggish_conv3_conv3_1_Conv2D): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (vggish_conv3_conv3_2_Conv2D): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (vggish_conv4_conv4_1_Conv2D): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (vggish_conv4_conv4_2_Conv2D): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
              "  (vggish_fc1_fc1_1_MatMul): Linear(in_features=12288, out_features=4096, bias=True)\n",
              "  (vggish_fc1_fc1_2_MatMul): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "  (vggish_fc2_MatMul): Linear(in_features=4096, out_features=128, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "agt9n0bYN6Wr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Generate Input\n",
        "num_secs = 3\n",
        "freq = 1000\n",
        "sr = 44100\n",
        "t = np.linspace(0, num_secs, int(num_secs * sr))\n",
        "x = np.sin(2 * np.pi * freq * t)  # Unit amplitude input signal\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aopWIP19PX8N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "13f51e2a-e466-47ff-8160-8ee685cf1d14"
      },
      "cell_type": "code",
      "source": [
        "#THIS CELL WILL GIVE ERROR:\n",
        "\n",
        "# line 39 at tf_to_pytorch_vggish_model.py changes input shape:\n",
        "#  vggish_Reshape  = torch.reshape(input = x, shape = (-1,96,64,1))\n",
        "# however it should be (-1,1,96,64) since pytorch uses N,C,H,W \n",
        "\n",
        "#pre-process input\n",
        "input_batch = vggish_input.waveform_to_examples(x, sr)\n",
        "\n",
        "input_batch=torch.from_numpy(input_batch)\n",
        "\n",
        "output=the_model(input_batch)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-1b001928b424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minput_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthe_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/tf_to_pytorch_vggish_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvggish_Flatten_flatten_Reshape_shape_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mvggish_Reshape\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m96\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mvggish_conv1_Conv2D_pad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvggish_Reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mvggish_conv1_Conv2D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvggish_conv1_Conv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvggish_conv1_Conv2D_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 96, 64, 1]' is invalid for input of size 18432"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "L9Kc29zGRCYG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# GET MODIFIED tf_to_pytorch_vggish_model.py for correct input shape\n",
        "!curl -O https://gist.githubusercontent.com/EnisBerk/321dcd19bf388eed8a0f5af5562324a3/raw/f581e7547c7eb6fa4cc46395d8370fddd1bbaa8f/tf_to_pytorch_vggish_model.py\n",
        "# RELOAD It\n",
        "MainModel = imp.load_source('MainModel', \"tf_to_pytorch_vggish_model.py\")\n",
        "\n",
        "the_model = torch.load(\"tf_to_pytorch_vggish_model.pth\")\n",
        "the_model.eval()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ztb6V1ooSCSY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#THIS CELL WILL GIVE ERROR:\n",
        "#pytorch weights are float32 so input needs to be float32 as well\n",
        "#pre-process input\n",
        "\n",
        "input_batch = vggish_input.waveform_to_examples(x, sr)\n",
        "\n",
        "input_batch=torch.from_numpy(input_batch)\n",
        "\n",
        "output=the_model.forward(input_batch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sD_NM4m3TfZ0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Finally this works, however results are different than tensorflow\n",
        "input_batch = vggish_input.waveform_to_examples(x, sr)\n",
        "# make input float32\n",
        "input_batch=input_batch.astype(np.float32)\n",
        "\n",
        "input_batch=torch.from_numpy(input_batch)\n",
        "\n",
        "output=the_model.forward(input_batch)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ghQ4egVRze7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# INFERENCE WITH tensorflow\n",
        "# Produce a batch of log mel spectrogram examples.\n",
        "input_batch = vggish_input.waveform_to_examples(x, sr)\n",
        "\n",
        "# cast to float to make sure inputs are same\n",
        "input_batch=input_batch.astype(np.float32)\n",
        "\n",
        "[embedding_batch] = sess.run([vgg['embedding']],\n",
        "                             feed_dict={vgg['features']: input_batch})\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-n9mxrfKUbL7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"checksum(tf): \",embedding_batch.sum())\n",
        "print(\"checksum(pytorch):\",output.sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UddqAcoWYaNe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6i-0rdLhZ7wJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}