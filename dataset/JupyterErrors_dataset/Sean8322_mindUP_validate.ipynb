{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2420596030527015219\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 662495444135034523\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 8048149321268545793\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 7586159002\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4580141010605556298\n",
      "physical_device_desc: \"device: 0, name: Graphics Device, pci bus id: 0000:17:00.0, compute capability: 7.5\"\n",
      "]\n",
      "1.12.0\n",
      "3.5.6 |Anaconda, Inc.| (default, Aug 26 2018, 21:41:56) \n",
      "[GCC 7.3.0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from eegmodels.EEGModels import EEGNet, ShallowConvNet, DeepConvNet\n",
    "import tensorflow as tf\n",
    "from numpy import argmax\n",
    "import seaborn as sn\n",
    "import math\n",
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import Masking\n",
    "import sklearn\n",
    "from sklearn.preprocessing import normalize\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "from multiprocessing import Pool\n",
    "import h5py\n",
    "import tensorflow.keras as keras\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras import backend as K\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if len(physical_devices) > 0:\n",
    "#        tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "print(device_lib.list_local_devices()) # list of DeviceAttributes\n",
    "import pandas as pd\n",
    "# %gui qt\n",
    "import numpy as np\n",
    "# import mne\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import vispy\n",
    "# print(vispy.sys_info())\n",
    "# BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))\n",
    "# sys.path.append(BASE_DIR)\n",
    "%matplotlib inline\n",
    "# mne.utils.set_config('MNE_USE_CUDA', 'true')  \n",
    "# mne.cuda.init_cuda(verbose=True)\n",
    "\n",
    "np.set_printoptions(precision=8)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "hot= {\n",
    "    'paced':0,\n",
    "    'slowBreath':1,\n",
    "    'stressor':2,\n",
    "    'baseline':3,\n",
    "    'sync':4,\n",
    "    'survey':5,\n",
    "    'rest':6\n",
    "}\n",
    "\n",
    "good={\n",
    "    'paced':True,\n",
    "    'slowBreath':True,\n",
    "    'rest':False,\n",
    "    'baseline':True,\n",
    "    'sync':False,\n",
    "    'survey':False,\n",
    "    'stressor':True\n",
    "}\n",
    "print(tf.__version__)\n",
    "print(sys.version)\n",
    "#./gdrive-linux-x64 upload -r --parent 1vhs7zre7sOnRuWLeVT_sL7SMQpfFnrkx ~/pench/models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transp(l): \n",
    "  \n",
    "    # we have nested loops in comprehensions \n",
    "    # value of i is assigned using inner loop \n",
    "    # then value of item is directed by row[i] \n",
    "    # and appended to l2 \n",
    "    l =[[row[i] for row in l] for i in range(len(l[0]))] \n",
    "\n",
    "    \n",
    "    return l\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "273 273 273 273\n"
     ]
    }
   ],
   "source": [
    "m=[]\n",
    "f=[]\n",
    "flipChannels=[]\n",
    "isEqualChunks=[]\n",
    "\n",
    "#Non filtered + CNN EEGNet trained on filtered\n",
    "dat='/home/sean/pench/pickled-avg/'\n",
    "flipChannels.extend([2]*13)\n",
    "isEqualChunks.extend([5]*39)\n",
    "fi='/home/sean/pench/models-eegLib/Deep/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "flipChannels.extend([1]*13)\n",
    "fi='/home/sean/pench/models-eegLib/Shallow/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "flipChannels.extend([0]*13)\n",
    "fi='/home/sean/pench/models-eegLib/EEGNet/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "\n",
    "\n",
    "#filtered + CNN EEGNet trained on filtered\n",
    "dat='/home/sean/pench/pickled-filt/'\n",
    "flipChannels.extend([2]*13)\n",
    "isEqualChunks.extend([5]*39)\n",
    "fi='/home/sean/pench/models-eegLib/Deep/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "flipChannels.extend([1]*13)\n",
    "fi='/home/sean/pench/models-eegLib/Shallow/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "flipChannels.extend([0]*13)\n",
    "fi='/home/sean/pench/models-eegLib/EEGNet/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "\n",
    "#filtered + CNN EEGNet trained on NON filtered\n",
    "dat='/home/sean/pench/pickled-filt/'\n",
    "flipChannels.extend([2]*13)\n",
    "isEqualChunks.extend([5]*39)\n",
    "fi='/home/sean/pench/models-eegLib-pure/Deep/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "flipChannels.extend([1]*13)\n",
    "fi='/home/sean/pench/models-eegLib-pure/Shallow/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "flipChannels.extend([0]*13)\n",
    "fi='/home/sean/pench/models-eegLib-pure/EEGNet/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "\n",
    "#Non filtered + CNN EEGNet trained on NON filtered\n",
    "dat='/home/sean/pench/pickled-avg/'\n",
    "flipChannels.extend([2]*13)\n",
    "isEqualChunks.extend([5]*39)\n",
    "fi='/home/sean/pench/models-eegLib-pure/Deep/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "flipChannels.extend([1]*13)\n",
    "fi='/home/sean/pench/models-eegLib-pure/Shallow/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "flipChannels.extend([0]*13)\n",
    "fi='/home/sean/pench/models-eegLib-pure/EEGNet/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "\n",
    "\n",
    "\n",
    "#filtered + CNN EEGNet trained on NON filtered\n",
    "dat='/home/sean/pench/pickled-filt/'\n",
    "flipChannels.extend([2]*13)\n",
    "isEqualChunks.extend([5]*39)\n",
    "fi='/home/sean/pench/models-eegLib-high/Deep/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "flipChannels.extend([1]*13)\n",
    "fi='/home/sean/pench/models-eegLib-high/Shallow/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "flipChannels.extend([0]*13)\n",
    "fi='/home/sean/pench/models-eegLib-high/EEGNet/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "\n",
    "#Non filtered + CNN EEGNet trained on NON filtered\n",
    "dat='/home/sean/pench/pickled-avg/'\n",
    "flipChannels.extend([2]*13)\n",
    "isEqualChunks.extend([5]*39)\n",
    "fi='/home/sean/pench/models-eegLib-high/Deep/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "flipChannels.extend([1]*13)\n",
    "fi='/home/sean/pench/models-eegLib-high/Shallow/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "flipChannels.extend([0]*13)\n",
    "fi='/home/sean/pench/models-eegLib-high/EEGNet/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "\n",
    "\n",
    "dat='/home/sean/pench/pickled-filt/'\n",
    "\n",
    "# #filtered +  Original LSTM trained on AVG\n",
    "flipChannels.extend([False]*13*3)\n",
    "# isEqualChunks.extend([False]*13)\n",
    "# fi='/home/sean/pench/models/'\n",
    "# m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "# f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "\n",
    "# #filtered +  ModelV2 LSTM trained on AVG\n",
    "# isEqualChunks.extend([10]*13)\n",
    "# fi='/home/sean/pench/modelsv2/'\n",
    "# m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "# f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "\n",
    "#filtered +  Dual LSTM trained on filtered\n",
    "isEqualChunks.extend([5]*13)\n",
    "fi='/home/sean/pench/models-filt-double-lstm/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "\n",
    "#filtered +  Dual LSTM trained on high pass\n",
    "isEqualChunks.extend([5]*13)\n",
    "fi='/home/sean/pench/models-high-double-lstm/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "\n",
    "dat='/home/sean/pench/pickled-avg/'\n",
    "\n",
    "# #Non filtered + Original LSTM trained on AVG\n",
    "# isEqualChunks.extend([False]*13)\n",
    "# fi='/home/sean/pench/models/'\n",
    "# m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "# f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "\n",
    "# #Non filtered + ModelV2 LSTM trained on AVG\n",
    "# isEqualChunks.extend([10]*13)\n",
    "# fi='/home/sean/pench/modelsv2/'\n",
    "# m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "# f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "\n",
    "\n",
    "#Non filtered +  Dual LSTM trained on filtered\n",
    "isEqualChunks.extend([5]*13)\n",
    "fi='/home/sean/pench/models-filt-double-lstm/'\n",
    "m.extend(sorted([fi+f for f in os.listdir(fi) if f.find('.h5')!=-1]))\n",
    "f.extend(sorted([dat+ f for f in os.listdir(dat) if not f.startswith('.')]))\n",
    "\n",
    "print(len(m), len(f), len(isEqualChunks), len(flipChannels))\n",
    "arr=np.transpose(np.array([m, f, isEqualChunks, flipChannels]))\n",
    "arr=arr.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(arr):\n",
    "    mode=arr[0]\n",
    "    fil=arr[1]\n",
    "    isEqualChunks=arr[2]\n",
    "    flipChannels=arr[3]\n",
    "    print('model is', mode)\n",
    "    print('data is', fil)\n",
    "#     name=name+'-1000ep'\n",
    "    if not os.path.exists(mode):\n",
    "        return 0\n",
    "    data=pickle.load(open(fil, 'rb'))\n",
    "    features=[]\n",
    "    labels=[]\n",
    "    add=[]\n",
    "    prev='sync'\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        if good[data[i][20]]:\n",
    "    #         print(data[i][20])\n",
    "            if prev!=data[i][20] :\n",
    "                print(prev, data[i][20], len(add))\n",
    "                features.append(add)\n",
    "                labels.append(hot[prev])\n",
    "                add = []\n",
    "\n",
    "            add.append(data[i][1:17])\n",
    "            prev=data[i][20]\n",
    "    features=features[1:]\n",
    "    labels=labels[1:]\n",
    "\n",
    "    if isEqualChunks.isdigit():\n",
    "        features=np.array(features)\n",
    "        prelim=np.array(labels)\n",
    "        splitted=[]\n",
    "        labels=[]\n",
    "        uniformLength=int(isEqualChunks)*125\n",
    "        print('uniform is', uniformLength)\n",
    "        for i in range(len(features)):\n",
    "            splits=math.ceil(len(features[i])/uniformLength)\n",
    "            features[i]=np.array(features[i])\n",
    "#             print(splits, features[i].shape)\n",
    "            result = np.full((uniformLength*splits, 16), -9999)\n",
    "#             print('prepad', len(features[i]))\n",
    "            result[:features[i].shape[0],:features[i].shape[1]] = features[i]\n",
    "            features[i]=result\n",
    "            np.pad(features[i], ((0, (splits*uniformLength)-len(features)), (0, 0)), 'constant', constant_values=(-9999))\n",
    "#             print('postpad', len(features[i]))\n",
    "            elem=np.array_split(np.array(features[i]), splits)\n",
    "            for chunk in elem:\n",
    "                splitted.append(chunk)\n",
    "                labels.append(prelim[i])\n",
    "#             print(len(elem), len(splitted))\n",
    "#             print([len(elem[i]) for i in range(len(elem))])\n",
    "\n",
    "\n",
    "        labels=np.array(labels)\n",
    "        features=np.array(splitted)\n",
    "    else:\n",
    "        labels=np.array(labels)\n",
    "        features=np.array(features)\n",
    "    \n",
    "    if flipChannels != 'False':\n",
    "#         p = Pool(5)\n",
    "        tk = []\n",
    "        for elem in features:\n",
    "            tk.append(np.transpose(elem))\n",
    "        features=tk\n",
    "#         features=p.map(np.transpose, features)\n",
    "        for i in range(len(features)):\n",
    "            features[i]=np.array([features[i]])\n",
    "    print(len(features), len(features[0]))\n",
    "    features=np.array(features)\n",
    "    \n",
    "    #     try:\n",
    "    #         features.append(data[i][19]['bpm'])\n",
    "\n",
    "    #     except Exception as e: \n",
    "    #         print(e, i)\n",
    "    #         print(data[i])\n",
    "\n",
    "    #     for k in range(1, 17):\n",
    "    #         add.append([data[i][k]])\n",
    "    #     add.append([data[0][19]['bpm']])\n",
    "    #     labels.append([float(hot[data[i][20]])])\n",
    "\n",
    "    print(labels)\n",
    "    print(type(labels), type(features))\n",
    "    # train_X = np.array(features[0:int(7*len(features)/10)])\n",
    "    # train_y = np.array(labels[0:int(7*len(labels)/10)])\n",
    "\n",
    "    # test_X = np.array(features[int(7*len(features)/10):len(features)])\n",
    "    # test_y = np.array(labels[int(7*len(labels)/10):len(labels)])\n",
    "\n",
    "#     features = np.array(features)\n",
    "#     labels = np.array(labels)\n",
    "    x=features\n",
    "    y = to_categorical(labels, num_classes=4)\n",
    "\n",
    "    print(labels)\n",
    "\n",
    "    print(\"x shape is\", x.shape)\n",
    "    print(\"y shape is\", y.shape)\n",
    "\n",
    "    x=keras.preprocessing.sequence.pad_sequences(x, maxlen=None, dtype='float32', padding='pre', truncating='pre', value=-9999)\n",
    "    # train_y=normalize(train_y.reshape(-1, 1), axis=0)\n",
    "    # test_y=normalize(test_y.reshape(-1, 1), axis=0)\n",
    "\n",
    "    # name=name+'fixed-eeg-block-2-cat'\n",
    "    # make a prediction\n",
    "    models  = [EEGNet(nb_classes=4, Chans=16, Samples =625), ShallowConvNet(nb_classes=4, Chans=16, Samples =625), DeepConvNet(nb_classes=4, Chans=16, Samples =625)]\n",
    "    print(models)\n",
    "    if flipChannels != 'False':\n",
    "        print('flipChannels', flipChannels)\n",
    "        model=models[int(flipChannels)]\n",
    "#         model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#         model = model.load_weights(mode)\n",
    "        print(model)\n",
    "        print(model.summary())\n",
    "    else:\n",
    "        model = keras.models.load_model(mode)\n",
    "    yhat = model.predict(np.array(x))\n",
    "    results=np.array([yhat, y])\n",
    "    print('results',results)\n",
    "    \n",
    "    \n",
    "    return [fil, mode, results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep-2000ep-2000ep.h5',\n",
       " '/home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_11-26-48-TWO',\n",
       " '5',\n",
       " '2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f7ae4a0ab70>, <tensorflow.python.keras.engine.training.Model object at 0x7f7b005de4e0>, <tensorflow.python.keras.engine.training.Model object at 0x7f7b64138eb8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f7b64138eb8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.2724371  0.1472772  0.47616002 0.10412568]\n",
      "  [0.2726907  0.14762093 0.4751414  0.1045469 ]\n",
      "  [0.27294815 0.14767215 0.47384858 0.10553109]\n",
      "  ...\n",
      "  [0.2729171  0.14662668 0.47583255 0.10462363]\n",
      "  [0.27092907 0.1485084  0.4763235  0.10423901]\n",
      "  [0.00000043 0.00000393 0.30672833 0.6932673 ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "out=predict(arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# out[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5234394d30>, <tensorflow.python.keras.engine.training.Model object at 0x7f526404c6a0>, <tensorflow.python.keras.engine.training.Model object at 0x7f52bf5e6b38>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f52bf5e6b38>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00876948 0.5565599  0.0122631  0.42240748]\n",
      "  [0.00882622 0.5556866  0.01231756 0.42316964]\n",
      "  [0.00880269 0.5588927  0.01228611 0.42001843]\n",
      "  ...\n",
      "  [0.00874287 0.55890644 0.01213241 0.42021826]\n",
      "  [0.00889801 0.55539    0.0123799  0.42333212]\n",
      "  [0.00024371 0.9004985  0.08464238 0.01461542]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5234c94748>, <tensorflow.python.keras.engine.training.Model object at 0x7f525068e6d8>, <tensorflow.python.keras.engine.training.Model object at 0x7f52bc36fb38>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f52bc36fb38>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f52bfaad908>, <tensorflow.python.keras.engine.training.Model object at 0x7f5223ea5d68>, <tensorflow.python.keras.engine.training.Model object at 0x7f5251629470>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5251629470>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.24048324 0.         0.7595167  0.        ]\n",
      "  [0.9999968  0.         0.00000324 0.        ]\n",
      "  [0.99999654 0.         0.00000348 0.        ]\n",
      "  ...\n",
      "  [1.         0.         0.         0.        ]\n",
      "  [1.         0.         0.         0.        ]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f52bf81ce80>, <tensorflow.python.keras.engine.training.Model object at 0x7f52509f1b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f5251553780>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5251553780>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f52bc08db70>, <tensorflow.python.keras.engine.training.Model object at 0x7f5250c6f358>, <tensorflow.python.keras.engine.training.Model object at 0x7f5251fedbe0>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5251fedbe0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f52bc574d68>, <tensorflow.python.keras.engine.training.Model object at 0x7f52342a3cf8>, <tensorflow.python.keras.engine.training.Model object at 0x7f5250cded68>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5250cded68>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5250e5ab38>, <tensorflow.python.keras.engine.training.Model object at 0x7f5223d038d0>, <tensorflow.python.keras.engine.training.Model object at 0x7f52504d2fd0>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f52504d2fd0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f52bf9afcf8>, <tensorflow.python.keras.engine.training.Model object at 0x7f52351e7b38>, <tensorflow.python.keras.engine.training.Model object at 0x7f5250aacc88>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5250aacc88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_61 (Conv2D)           (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5234e42748>, <tensorflow.python.keras.engine.training.Model object at 0x7f5234b87d30>, <tensorflow.python.keras.engine.training.Model object at 0x7f52354b6da0>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f52354b6da0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_27 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_67 (Conv2D)           (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_68 (Conv2D)           (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_69 (Conv2D)           (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_70 (Conv2D)           (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_71 (Conv2D)           (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5235545e80>, <tensorflow.python.keras.engine.training.Model object at 0x7f5251fc4c50>, <tensorflow.python.keras.engine.training.Model object at 0x7f52230aeb00>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f52230aeb00>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_30 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_75 (Conv2D)           (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_76 (Conv2D)           (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_77 (Conv2D)           (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_78 (Conv2D)           (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_79 (Conv2D)           (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5235348c18>, <tensorflow.python.keras.engine.training.Model object at 0x7f526467fcc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f52226309b0>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f52226309b0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_33 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_83 (Conv2D)           (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_84 (Conv2D)           (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_84 (Batc (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_85 (Conv2D)           (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_85 (Batc (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_86 (Conv2D)           (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_86 (Batc (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_87 (Conv2D)           (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_87 (Batc (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.01706986 0.05481526 0.7206155  0.20749937]\n",
      "  [0.0169655  0.05509336 0.7190474  0.2088937 ]\n",
      "  [0.01684545 0.05413574 0.72113675 0.20788214]\n",
      "  ...\n",
      "  [0.01705905 0.05477078 0.7217584  0.20641173]\n",
      "  [0.01709461 0.05583208 0.71678174 0.21029156]\n",
      "  [0.         0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f52229866d8>, <tensorflow.python.keras.engine.training.Model object at 0x7f5208afaeb8>, <tensorflow.python.keras.engine.training.Model object at 0x7f5222168c18>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5222168c18>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_36 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_91 (Conv2D)           (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_92 (Conv2D)           (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_92 (Batc (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_93 (Conv2D)           (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_93 (Batc (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_94 (Conv2D)           (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_94 (Batc (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_82 (Dropout)         (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_95 (Conv2D)           (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_95 (Batc (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_83 (Dropout)         (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5250cc6a20>, <tensorflow.python.keras.engine.training.Model object at 0x7f5200e8f780>, <tensorflow.python.keras.engine.training.Model object at 0x7f5221ca7ef0>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5221ca7ef0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_39 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_99 (Conv2D)           (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_100 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_100 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_87 (Dropout)         (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_101 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_101 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_102 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_102 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_103 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_103 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_90 (Dropout)         (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5264aa0ba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f520064f9e8>, <tensorflow.python.keras.engine.training.Model object at 0x7f5220dc5b38>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f520064f9e8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_41 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_105 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_106 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_107 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_41 (Averag (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_93 (Dropout)         (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.0042877  0.04351778 0.64624506 0.30594948]\n",
      "  [0.00442449 0.04432232 0.6517726  0.29948062]\n",
      "  [0.00436564 0.04316776 0.6516757  0.30079094]\n",
      "  ...\n",
      "  [0.00434373 0.04421987 0.6416631  0.3097733 ]\n",
      "  [0.00464929 0.04402197 0.64019895 0.3111298 ]\n",
      "  [0.00236983 0.33350745 0.64580154 0.01832123]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5200694a90>, <tensorflow.python.keras.engine.training.Model object at 0x7f5222e9fc88>, <tensorflow.python.keras.engine.training.Model object at 0x7f52096fc710>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5222e9fc88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_44 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_113 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_114 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_115 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_44 (Averag (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_100 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.9998323  0.         0.00016773 0.        ]\n",
      "  [0.99978715 0.         0.00021282 0.        ]\n",
      "  [0.99983156 0.         0.00016843 0.        ]\n",
      "  ...\n",
      "  [0.99987125 0.         0.0001287  0.        ]\n",
      "  [0.9998728  0.         0.00012713 0.        ]\n",
      "  [0.9998661  0.         0.0001338  0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5221fb1dd8>, <tensorflow.python.keras.engine.training.Model object at 0x7f5208458b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f5208ba7b00>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5208458b70>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_47 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_121 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_122 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_123 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_47 (Averag (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_107 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.99999833 0.         0.00000161 0.        ]\n",
      "  [0.99999833 0.         0.00000168 0.        ]\n",
      "  [0.99999857 0.         0.00000141 0.        ]\n",
      "  ...\n",
      "  [0.9999988  0.         0.00000114 0.        ]\n",
      "  [0.9999989  0.         0.00000113 0.        ]\n",
      "  [0.9999995  0.         0.00000052 0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5235d31b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f520010eac8>, <tensorflow.python.keras.engine.training.Model object at 0x7f52081b6c18>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f520010eac8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_50 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_129 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_130 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_131 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_50 (Averag (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_114 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00001939 0.99993837 0.         0.00004219]\n",
      "  [0.00002317 0.9999341  0.         0.00004278]\n",
      "  [0.00002486 0.9999368  0.         0.00003822]\n",
      "  ...\n",
      "  [0.00002081 0.9999386  0.         0.00004052]\n",
      "  [0.00001993 0.9999404  0.         0.00003968]\n",
      "  [0.00002217 0.99992824 0.         0.00004964]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f52225efbe0>, <tensorflow.python.keras.engine.training.Model object at 0x7f52349ed710>, <tensorflow.python.keras.engine.training.Model object at 0x7f5220d9fac8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f52349ed710>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_53 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_137 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_138 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_139 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_53 (Averag (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.35627943 0.42377716 0.12087397 0.09906939]\n",
      "  [0.35627943 0.42377716 0.12087397 0.09906939]\n",
      "  [0.35627943 0.42377716 0.12087397 0.09906939]\n",
      "  ...\n",
      "  [0.4884381  0.3580288  0.05055404 0.10297912]\n",
      "  [0.63775814 0.3138633  0.00930554 0.03907306]\n",
      "  [0.4485414  0.2265042  0.24551967 0.07943469]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5208f637b8>, <tensorflow.python.keras.engine.training.Model object at 0x7f5200c99940>, <tensorflow.python.keras.engine.training.Model object at 0x7f5200305d30>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5200c99940>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_56 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_145 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_146 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_147 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_182 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_56 (Averag (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_183 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_128 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_36 (Flatten)         (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_184 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.9995338  0.0000046  0.00000804 0.00045351]\n",
      "  [0.9995338  0.0000046  0.00000804 0.00045351]\n",
      "  [0.9995338  0.0000046  0.00000804 0.00045351]\n",
      "  ...\n",
      "  [0.9998981  0.00000632 0.0000018  0.00009383]\n",
      "  [0.99994147 0.00000867 0.00000186 0.00004799]\n",
      "  [0.99946207 0.0000072  0.0000085  0.00052232]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51f9e12ac8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f9c77898>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f9dc5c88>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51f9c77898>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_59 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_153 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_154 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_155 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_192 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_59 (Averag (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_193 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_135 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_38 (Flatten)         (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_194 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00000001 0.9510211  0.00001667 0.0489622 ]\n",
      "  [0.00000001 0.9453958  0.00001791 0.05458627]\n",
      "  [0.00000001 0.947566   0.00001592 0.05241818]\n",
      "  ...\n",
      "  [0.00000001 0.9530064  0.00002662 0.04696702]\n",
      "  [0.00000001 0.95410776 0.00002905 0.04586318]\n",
      "  [0.00000001 0.9565293  0.0000273  0.04344341]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f52085eccc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f5209087b00>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f991cc50>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5209087b00>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_62 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_161 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_162 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_163 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_202 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_62 (Averag (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_203 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_142 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_40 (Flatten)         (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_204 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.9999981  0.         0.         0.00000187]\n",
      "  [0.9999981  0.         0.         0.00000187]\n",
      "  [0.9999981  0.         0.         0.00000187]\n",
      "  ...\n",
      "  [0.9999981  0.         0.         0.00000187]\n",
      "  [0.9999981  0.         0.         0.00000187]\n",
      "  [0.999998   0.         0.         0.00000204]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5200db4be0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f8865d68>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f8c7ed68>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51f8865d68>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_65 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_169 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_170 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_171 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_212 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_65 (Averag (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_213 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_149 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_42 (Flatten)         (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_214 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5221bc4d68>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f0cfbe80>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f8d4fac8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51f0cfbe80>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_68 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_177 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_178 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_179 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_222 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_68 (Averag (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_223 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_156 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_44 (Flatten)         (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_224 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00831188 0.         0.9916882  0.00000001]\n",
      "  [0.0098652  0.         0.9901348  0.00000001]\n",
      "  [0.01575377 0.         0.98424625 0.00000001]\n",
      "  ...\n",
      "  [0.00482585 0.         0.9951741  0.00000002]\n",
      "  [0.00410477 0.         0.99589527 0.00000002]\n",
      "  [0.00035743 0.         0.9996426  0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f52086d7c18>, <tensorflow.python.keras.engine.training.Model object at 0x7f5200215fd0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f9636cf8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5200215fd0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_71 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_185 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_186 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_187 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_232 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_71 (Averag (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_233 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_163 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_46 (Flatten)         (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_234 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.02420649 0.03045211 0.82744217 0.11789925]\n",
      "  [0.02608745 0.03222201 0.81244755 0.12924303]\n",
      "  [0.0228239  0.02795959 0.8390121  0.1102045 ]\n",
      "  ...\n",
      "  [0.02639053 0.03149991 0.8164767  0.12563291]\n",
      "  [0.02419315 0.0310825  0.82723665 0.11748772]\n",
      "  [0.         0.00001266 0.9971533  0.00283399]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f52087b1ac8>, <tensorflow.python.keras.engine.training.Model object at 0x7f52000b0a20>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f10dfcc0>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f52000b0a20>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_74 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_193 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_194 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_195 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_242 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_74 (Averag (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_243 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_170 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_48 (Flatten)         (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_244 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.96253955 0.         0.00000336 0.03745706]\n",
      "  [0.96253955 0.         0.00000336 0.03745706]\n",
      "  [0.96253955 0.         0.00000336 0.03745706]\n",
      "  ...\n",
      "  [0.96253955 0.         0.00000336 0.03745706]\n",
      "  [0.96253955 0.         0.00000336 0.03745706]\n",
      "  [0.96253955 0.         0.00000336 0.03745706]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f52002fcd68>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f173dc88>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f8bdcb70>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51f173dc88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_77 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_201 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_202 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_203 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_252 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_77 (Averag (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_253 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_177 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_50 (Flatten)         (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_254 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00000009 0.9999999  0.         0.00000003]\n",
      "  [0.00000012 0.9999999  0.         0.00000003]\n",
      "  [0.0000001  0.9999999  0.         0.00000003]\n",
      "  ...\n",
      "  [0.00000378 0.99999607 0.         0.00000009]\n",
      "  [0.00000118 0.9999988  0.         0.00000005]\n",
      "  [0.00000013 0.9999999  0.         0.00000004]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51f9fadfd0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f87e2eb8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f0785be0>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51f9fadfd0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_79 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_208 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_208 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_26 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_209 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_260 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_78 (Averag (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_182 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_26 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_210 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_261 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_79 (Averag (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_183 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.13035259 0.1477728  0.5057604  0.21611422]\n",
      "  [0.12971383 0.1479163  0.5060815  0.21628834]\n",
      "  [0.1299232  0.14744096 0.50624794 0.21638791]\n",
      "  ...\n",
      "  [0.12988459 0.14769074 0.5065251  0.21589954]\n",
      "  [0.13036522 0.14729911 0.5065158  0.21581985]\n",
      "  [0.         0.         0.9999945  0.00000547]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f52001f0c50>, <tensorflow.python.keras.engine.training.Model object at 0x7f51e0bd8ba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f10557b8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f52001f0c50>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_82 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_216 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_216 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_27 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_217 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_270 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_81 (Averag (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_189 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_27 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_218 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_271 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_82 (Averag (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_190 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51f9d7ccf8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f10cef60>, <tensorflow.python.keras.engine.training.Model object at 0x7f51e94c89e8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51f9d7ccf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_85 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_224 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_224 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_28 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_225 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_280 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_84 (Averag (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_196 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_28 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_226 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_281 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_85 (Averag (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_197 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1.         0.         0.         0.        ]\n",
      "  [1.         0.         0.         0.        ]\n",
      "  [1.         0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.00000004 0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51f895d710>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f06aeb38>, <tensorflow.python.keras.engine.training.Model object at 0x7f51e9755be0>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51f895d710>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_88 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_232 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_232 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_29 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_233 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_290 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_87 (Averag (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_203 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_29 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_234 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_291 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_88 (Averag (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_204 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51f1dc2a58>, <tensorflow.python.keras.engine.training.Model object at 0x7f51f122bcc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51e88b6ba8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51f1dc2a58>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_91 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_240 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_240 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_30 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_241 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_300 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_90 (Averag (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_210 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_30 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_242 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_301 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_91 (Averag (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_211 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.00007387 0.99992454 0.00000155]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f52005cbbe0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d889ab38>, <tensorflow.python.keras.engine.training.Model object at 0x7f51e0e7deb8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f52005cbbe0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_94 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_248 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_248 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_31 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_249 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_310 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_93 (Averag (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_217 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_31 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_250 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_311 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_94 (Averag (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_218 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51f132c780>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d9a6d898>, <tensorflow.python.keras.engine.training.Model object at 0x7f51e1e98ba8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51f132c780>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_97 (InputLayer)        (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_256 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_256 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_32 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_257 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_320 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_96 (Averag (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_224 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_32 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_258 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_321 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_97 (Averag (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_225 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51f097ad30>, <tensorflow.python.keras.engine.training.Model object at 0x7f51c976dc88>, <tensorflow.python.keras.engine.training.Model object at 0x7f51e806bb70>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51f097ad30>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_100 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_264 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_264 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_33 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_265 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_330 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_99 (Averag (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_231 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_33 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_266 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_331 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_100 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_232 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51e9d0f6d8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51e8e0acc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d9d52e10>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51e9d0f6d8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_103 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_272 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_272 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_34 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_273 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_340 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_102 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_238 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_34 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_274 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_341 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_103 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_239 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51e900ce48>, <tensorflow.python.keras.engine.training.Model object at 0x7f51e92a8fd0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d98acb00>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51e900ce48>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_106 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_280 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_280 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_35 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_281 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_350 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_105 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_245 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_35 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_282 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_351 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_106 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_246 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51e894ad68>, <tensorflow.python.keras.engine.training.Model object at 0x7f51e8cf0780>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d96deac8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51e894ad68>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_109 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_288 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_288 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_36 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_289 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_360 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_108 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_252 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_36 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_290 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_361 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_109 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_253 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.16644186 0.10531577 0.40162593 0.3266165 ]\n",
      "  [0.16550453 0.10510961 0.4024192  0.3269666 ]\n",
      "  [0.16562453 0.10432449 0.40094745 0.32910347]\n",
      "  ...\n",
      "  [0.16678822 0.10529643 0.4011362  0.32677916]\n",
      "  [0.16605037 0.10563673 0.40136316 0.32694975]\n",
      "  [0.         0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51e0b9ba90>, <tensorflow.python.keras.engine.training.Model object at 0x7f51e8fd69e8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d1fb0c88>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51e0b9ba90>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_112 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_296 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_296 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_37 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_297 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_370 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_111 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_259 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_37 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_298 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_371 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_112 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_260 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         1.         0.         0.        ]\n",
      "  [0.         1.         0.         0.        ]\n",
      "  [0.         1.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.9999999  0.         0.00000013]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51e0934d30>, <tensorflow.python.keras.engine.training.Model object at 0x7f51e083cc88>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d830ae48>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51e0934d30>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_115 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_304 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_304 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_38 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_305 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_380 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_114 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_266 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_38 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_306 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_381 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_115 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_267 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51d8380be0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d952db00>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d833d9e8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51d833d9e8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_120 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_315 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_316 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_316 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_395 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_156 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_276 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_317 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_317 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_396 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_157 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_277 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_318 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_318 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_397 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_158 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_278 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_319 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_319 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_398 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_159 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_279 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_79 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_399 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  ...\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.00000031 0.9999932  0.00000648 0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51f0065b00>, <tensorflow.python.keras.engine.training.Model object at 0x7f51c8fb0a58>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d032cc88>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51d032cc88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_123 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_323 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_324 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_324 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_405 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_160 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_283 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_325 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_325 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_406 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_161 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_284 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_326 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_326 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_407 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_162 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_285 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_327 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_327 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_408 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_163 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_286 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_81 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_409 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.14221594 0.00003581 0.83331996 0.02442831]\n",
      "  [0.92082906 0.0791679  0.00000042 0.00000263]\n",
      "  [0.10816805 0.02652133 0.00000051 0.86531013]\n",
      "  ...\n",
      "  [0.60094655 0.02232158 0.3655346  0.01119726]\n",
      "  [0.54155606 0.0056622  0.39255834 0.06022347]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51d93e4a20>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d8ba5c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d06aeb70>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51d06aeb70>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_126 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_331 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_332 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_332 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_415 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_164 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_290 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_333 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_333 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_416 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_165 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_291 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_334 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_334 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_417 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_166 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_292 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_335 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_335 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_418 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_167 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_293 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_83 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_419 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00907848 0.9896534  0.00058007 0.00068804]\n",
      "  [0.0002327  0.99962306 0.00001262 0.00013157]\n",
      "  [0.00062261 0.9856399  0.00148812 0.01224928]\n",
      "  ...\n",
      "  [0.00559163 0.9666876  0.0027585  0.02496231]\n",
      "  [0.00734732 0.8129539  0.00288138 0.1768174 ]\n",
      "  [0.         1.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51c86fdd68>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d17e9780>, <tensorflow.python.keras.engine.training.Model object at 0x7f51b81aeac8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51b81aeac8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_129 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_339 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_340 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_340 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_425 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_168 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_297 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_341 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_341 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_426 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_169 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_298 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_342 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_342 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_427 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_170 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_299 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_343 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_343 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_428 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_171 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_300 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_85 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_429 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.3122115  0.00480459 0.45205396 0.23092997]\n",
      "  [0.10667772 0.01999805 0.45398173 0.41934252]\n",
      "  [0.18187675 0.05346541 0.57115954 0.19349827]\n",
      "  ...\n",
      "  [0.3166902  0.01206214 0.4612183  0.21002935]\n",
      "  [0.06760906 0.00508547 0.23042987 0.6968756 ]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51d9244710>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d0323cf8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51b1675e48>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51b1675e48>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_132 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_347 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_348 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_348 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_435 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_172 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_304 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_349 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_349 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_436 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_173 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_305 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_350 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_350 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_437 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_174 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_306 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_351 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_351 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_438 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_175 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_307 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_87 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_439 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.7062706  0.0796939  0.11016413 0.10387138]\n",
      "  [0.05656986 0.12321648 0.6745562  0.1456575 ]\n",
      "  [0.3435847  0.47152218 0.08464725 0.10024586]\n",
      "  ...\n",
      "  [0.29592007 0.33508626 0.3294597  0.03953398]\n",
      "  [0.36303627 0.29804885 0.32851166 0.01040324]\n",
      "  [0.         1.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51d1bb3cc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d16b4be0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51b94cab70>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51b94cab70>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_135 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_355 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_356 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_356 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_445 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_176 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_311 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_357 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_357 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_446 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_177 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_312 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_358 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_358 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_447 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_178 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_313 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_359 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_359 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_448 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_179 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_314 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_89 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_449 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.35274225 0.05085251 0.21084696 0.3855582 ]\n",
      "  [0.07736011 0.305228   0.4433608  0.17405105]\n",
      "  [0.18162996 0.05836713 0.690835   0.06916793]\n",
      "  ...\n",
      "  [0.35075307 0.08213164 0.30381745 0.26329783]\n",
      "  [0.3233161  0.23159806 0.26617402 0.17891185]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51b88cdba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d0dfbbe0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51b14db6d8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51b14db6d8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_138 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_363 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_364 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_364 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_455 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_180 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_318 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_365 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_365 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_456 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_181 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_319 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_366 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_366 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_457 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_182 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_320 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_367 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_367 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_458 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_183 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_321 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_91 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_459 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.13052286 0.04853705 0.00300509 0.817935  ]\n",
      "  [0.2430455  0.29284915 0.00049516 0.46361023]\n",
      "  [0.6646211  0.03744554 0.00222046 0.2957129 ]\n",
      "  ...\n",
      "  [0.75300753 0.1073723  0.00327133 0.13634884]\n",
      "  [0.00806627 0.00081962 0.00013554 0.9909786 ]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51d1a6c240>, <tensorflow.python.keras.engine.training.Model object at 0x7f51b91abba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51b0a99c50>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51b0a99c50>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_141 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_371 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_372 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_372 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_465 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_184 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_325 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_373 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_373 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_466 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_185 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_326 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_374 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_374 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_467 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_186 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_327 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_375 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_375 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_468 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_187 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_328 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_93 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_469 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         0.00006198 0.         0.999938  ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         1.         0.         0.        ]\n",
      "  ...\n",
      "  [0.13868181 0.8296597  0.02571286 0.00594563]\n",
      "  [0.00266462 0.9833678  0.000189   0.01377852]\n",
      "  [0.         1.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51b8935b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d1d6fef0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51b156bb38>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51b156bb38>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_144 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_379 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_380 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_380 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_475 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_188 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_332 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_381 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_381 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_476 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_189 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_333 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_382 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_382 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_477 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_190 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_334 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_383 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_383 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_478 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_191 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_335 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_95 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_479 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.39721397 0.00508247 0.00480325 0.5929003 ]\n",
      "  [0.25397006 0.03817954 0.011812   0.6960384 ]\n",
      "  [0.13995406 0.05280302 0.03519191 0.772051  ]\n",
      "  ...\n",
      "  [0.3370737  0.19567975 0.2069737  0.26027286]\n",
      "  [0.22459967 0.4812821  0.01177375 0.28234455]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51b91afc18>, <tensorflow.python.keras.engine.training.Model object at 0x7f51b96adb70>, <tensorflow.python.keras.engine.training.Model object at 0x7f51b1b39780>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51b1b39780>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_147 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_387 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_388 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_388 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_485 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_192 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_339 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_389 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_389 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_486 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_193 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_340 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_390 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_390 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_487 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_194 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_341 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_391 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_391 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_488 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_195 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_342 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_97 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_489 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.0006954  0.0002049  0.00014358 0.9989561 ]\n",
      "  [0.00016287 0.00003661 0.00023165 0.9995689 ]\n",
      "  [0.00090785 0.00231189 0.00082621 0.99595404]\n",
      "  ...\n",
      "  [0.00014491 0.0028649  0.00197117 0.99501896]\n",
      "  [0.00014587 0.13637508 0.00015704 0.863322  ]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51b867cb38>, <tensorflow.python.keras.engine.training.Model object at 0x7f51b11c6fd0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d83f9cf8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51d83f9cf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_150 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_395 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_396 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_396 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_495 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_196 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_346 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_397 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_397 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_496 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_197 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_347 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_398 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_398 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_497 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_198 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_348 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_399 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_399 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_498 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_199 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_349 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_99 (Flatten)         (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_499 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  ...\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.   0.   1.   0.  ]]\n",
      "\n",
      " [[0.   0.   0.   1.  ]\n",
      "  [0.   0.   0.   1.  ]\n",
      "  [0.   0.   0.   1.  ]\n",
      "  ...\n",
      "  [0.   0.   1.   0.  ]\n",
      "  [0.   0.   1.   0.  ]\n",
      "  [0.   0.   1.   0.  ]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51b15cec88>, <tensorflow.python.keras.engine.training.Model object at 0x7f51b154beb8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51ab3a7be0>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51ab3a7be0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_153 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_403 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_404 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_404 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_505 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_200 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_353 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_405 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_405 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_506 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_201 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_354 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_406 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_406 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_507 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_202 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_355 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_407 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_407 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_508 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_203 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_356 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_101 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_509 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.93935907 0.03487065 0.00092016 0.02485004]\n",
      "  [0.31738907 0.68156105 0.00036798 0.00068181]\n",
      "  [0.9903562  0.00338175 0.0058226  0.00043954]\n",
      "  ...\n",
      "  [0.3553723  0.44467506 0.09970067 0.10025189]\n",
      "  [0.6568284  0.12303518 0.07184102 0.1482953 ]\n",
      "  [0.9591547  0.00386669 0.         0.03697864]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Deep/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51b168fef0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a8e9eeb8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51aa6b1be0>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51aa6b1be0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_156 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_411 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_412 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_412 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_515 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_204 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_360 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_413 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_413 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_516 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_205 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_361 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_414 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_414 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_517 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_206 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_362 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_415 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_415 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_518 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_207 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_363 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_103 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_519 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.0406406  0.01689288 0.3761015  0.566365  ]\n",
      "  [0.09786228 0.17887221 0.58983386 0.13343167]\n",
      "  [0.01482906 0.14165226 0.680687   0.16283165]\n",
      "  ...\n",
      "  [0.01218208 0.02046854 0.1325217  0.83482766]\n",
      "  [0.2598023  0.14439024 0.5613176  0.03448983]\n",
      "  [0.         0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51b1479e80>, <tensorflow.python.keras.engine.training.Model object at 0x7f51b1b1dcf8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51aa35eba8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51b1b1dcf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_158 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_417 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_418 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_419 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_522 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_158 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_523 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_366 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_104 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_524 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         0.         0.02609389 0.97390616]\n",
      "  [0.         0.         0.02609389 0.97390616]\n",
      "  [0.         0.         0.02609389 0.97390616]\n",
      "  ...\n",
      "  [0.         0.         0.02609389 0.97390616]\n",
      "  [0.         0.         0.02609389 0.97390616]\n",
      "  [0.0000001  0.00000004 0.9036893  0.09631063]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51b82f4c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f51aa6f7be0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a9350e80>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51aa6f7be0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_161 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_425 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_426 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_427 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_532 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_161 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_533 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_373 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_106 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_534 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00000072 0.00000001 0.9999993  0.        ]\n",
      "  [0.00000757 0.00000012 0.99999225 0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  ...\n",
      "  [0.00058702 0.00006176 0.9993315  0.00001977]\n",
      "  [0.0007309  0.00001692 0.9992505  0.00000169]\n",
      "  [0.         0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51b03d0b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f51ab197ac8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a8195d30>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51ab197ac8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_164 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_433 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_434 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_435 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_542 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_164 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_543 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_380 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_108 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_544 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00000001 0.99999225 0.00000648 0.00000124]\n",
      "  [0.00000001 0.999992   0.00000729 0.00000064]\n",
      "  [0.         0.9999993  0.00000053 0.00000021]\n",
      "  ...\n",
      "  [0.         0.99999905 0.00000081 0.00000013]\n",
      "  [0.00000001 0.999992   0.00000753 0.00000042]\n",
      "  [0.         1.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51aa9fea20>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a0c62d30>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a95c0c18>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51a0c62d30>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_167 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_441 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_442 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_443 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_552 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_167 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_553 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_387 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_110 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_110 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_554 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00683374 0.00010798 0.00528562 0.98777264]\n",
      "  [0.11389878 0.00833844 0.01881798 0.85894483]\n",
      "  [0.17855564 0.02395057 0.02909552 0.7683983 ]\n",
      "  ...\n",
      "  [0.60071623 0.05541567 0.01715927 0.32670882]\n",
      "  [0.77342844 0.02080447 0.00859855 0.19716859]\n",
      "  [0.1598971  0.29644564 0.1554454  0.38821182]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51ab3fed30>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a8d13c50>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a3260b00>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51a8d13c50>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_170 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_449 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_450 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_451 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_562 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_170 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_563 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_394 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_112 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_112 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_564 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00481824 0.7580622  0.00254946 0.23457006]\n",
      "  [0.06983401 0.67200243 0.02809835 0.23006521]\n",
      "  [0.07683987 0.2801897  0.01561911 0.6273514 ]\n",
      "  ...\n",
      "  [0.03799805 0.62616426 0.0326908  0.3031469 ]\n",
      "  [0.01128999 0.5724452  0.0520766  0.36418822]\n",
      "  [0.00000003 0.63325256 0.         0.36674744]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51aa6d4ba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51c9b61b00>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a36d59e8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51c9b61b00>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_173 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_457 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_458 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_459 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_572 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_173 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_573 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_401 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_114 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_114 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_574 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00662272 0.0523027  0.94000065 0.00107396]\n",
      "  [0.02126823 0.34370357 0.62754    0.00748821]\n",
      "  [0.01359693 0.6073949  0.3772618  0.00174639]\n",
      "  ...\n",
      "  [0.02152588 0.06528065 0.90719634 0.00599717]\n",
      "  [0.05864203 0.36180368 0.5769109  0.00264334]\n",
      "  [0.00012983 0.00375036 0.99611986 0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51c85fb780>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a993ba58>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a2d13c88>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51a993ba58>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_176 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_465 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_466 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_467 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_582 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_176 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_583 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_408 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_116 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_116 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_584 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.01062992 0.40478352 0.5844785  0.00010816]\n",
      "  [0.02622722 0.1595077  0.81409585 0.00016925]\n",
      "  [0.02304046 0.3252488  0.6516235  0.00008726]\n",
      "  ...\n",
      "  [0.01479987 0.05076456 0.9343614  0.00007414]\n",
      "  [0.01643187 0.12043606 0.86309737 0.00003471]\n",
      "  [0.03720902 0.87431836 0.08581893 0.00265371]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51a8e429e8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a95b0c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a2311b70>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51a95b0c88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_179 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_473 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_474 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_475 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_592 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_179 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_593 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_415 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_118 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_118 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_594 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.9999976  0.00000007 0.         0.00000222]\n",
      "  [0.9999963  0.00000016 0.         0.00000352]\n",
      "  [0.994072   0.00000546 0.00000168 0.0059208 ]\n",
      "  ...\n",
      "  [0.90337867 0.02649563 0.04382801 0.02629771]\n",
      "  [0.986193   0.00442442 0.00199743 0.00738515]\n",
      "  [0.9999981  0.00000007 0.         0.00000184]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51a830dc50>, <tensorflow.python.keras.engine.training.Model object at 0x7f51d034acc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51c910a780>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51d034acc0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_182 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_481 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_482 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_483 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_602 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_182 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_603 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_422 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_120 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_120 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_604 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.01003803 0.89135945 0.02528686 0.07331562]\n",
      "  [0.00095032 0.9826245  0.01498573 0.00143952]\n",
      "  [0.01982122 0.32149386 0.4351209  0.22356407]\n",
      "  ...\n",
      "  [0.0343204  0.555368   0.33454636 0.0757652 ]\n",
      "  [0.00953816 0.09610152 0.34365433 0.55070597]\n",
      "  [0.         0.9999229  0.00007323 0.00000389]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51a8fa5cf8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a0caeb38>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a05e0748>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51a0caeb38>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_185 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_489 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_490 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_491 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_612 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_185 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_613 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_429 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_122 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_122 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_614 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00000268 0.01501876 0.09426898 0.89070964]\n",
      "  [0.00000143 0.00549257 0.04907785 0.94542813]\n",
      "  [0.00000222 0.00717616 0.0366673  0.95615435]\n",
      "  ...\n",
      "  [0.00000158 0.00338566 0.3258803  0.67073244]\n",
      "  [0.0000087  0.00259393 0.36822972 0.6291677 ]\n",
      "  [0.         0.00000009 0.00001092 0.9999889 ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51a15c1c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a28bebe0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a043def0>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51a28bebe0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_188 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_497 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_498 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_499 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_622 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_188 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_623 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_436 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_124 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_124 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_624 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00261604 0.99737465 0.00000933 0.        ]\n",
      "  [0.00261604 0.99737465 0.00000933 0.        ]\n",
      "  [0.00261604 0.99737465 0.00000933 0.        ]\n",
      "  ...\n",
      "  [0.00261604 0.99737465 0.00000933 0.        ]\n",
      "  [0.00261604 0.99737465 0.00000933 0.        ]\n",
      "  [0.00001296 0.00000037 0.00025707 0.9997296 ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51a2e6cb38>, <tensorflow.python.keras.engine.training.Model object at 0x7f51b0e37b00>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a05bad30>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51b0e37b00>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_191 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_505 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_506 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_507 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_632 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_191 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_633 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_443 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_126 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_126 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_634 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.56140363 0.13460481 0.29101026 0.01298132]\n",
      "  [0.02520265 0.00087733 0.9735031  0.00041692]\n",
      "  [0.05282753 0.9025023  0.04225657 0.00241365]\n",
      "  ...\n",
      "  [0.1617718  0.41503254 0.29456392 0.12863177]\n",
      "  [0.59682584 0.00224872 0.40002814 0.00089727]\n",
      "  [0.01248118 0.86291146 0.10770553 0.01690188]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/Shallow/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51a277fcf8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a10f9be0>, <tensorflow.python.keras.engine.training.Model object at 0x7f519b1f7b70>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51a10f9be0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_194 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_513 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_514 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_515 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_642 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_194 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_643 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_450 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_128 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_128 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_644 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.15635811 0.01783996 0.05647679 0.76932514]\n",
      "  [0.01097618 0.02320538 0.04477919 0.9210392 ]\n",
      "  [0.00874456 0.02444059 0.11380944 0.8530054 ]\n",
      "  ...\n",
      "  [0.03156272 0.0904833  0.12316334 0.75479054]\n",
      "  [0.04125367 0.01090571 0.01074489 0.9370957 ]\n",
      "  [0.         0.00028509 0.00012642 0.99958843]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51a32efd68>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a1018c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f519b0a2b70>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51a32efd68>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_196 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_520 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_520 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_65 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_521 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_650 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_195 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_455 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_65 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_522 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_651 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_196 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_456 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  ...\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.99862397 0.         0.001373   0.00000308]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51a123ac18>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a0d78b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f519a772a20>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51a123ac18>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_199 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_528 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_528 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_66 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_529 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_660 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_198 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_462 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_66 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_530 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_661 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_199 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_463 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00534325 0.303817   0.00062963 0.6902101 ]\n",
      "  [0.00006749 0.00144511 0.00000006 0.99848723]\n",
      "  [0.73618835 0.00000001 0.00573767 0.25807396]\n",
      "  ...\n",
      "  [0.13219605 0.24465348 0.15414    0.46901053]\n",
      "  [0.15452193 0.31362087 0.12297766 0.40887952]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51b9bbed30>, <tensorflow.python.keras.engine.training.Model object at 0x7f519b917c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f519a52ddd8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51b9bbed30>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_202 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_536 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_536 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_67 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_537 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_670 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_201 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_469 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_67 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_538 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_671 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_202 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_470 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.2771789  0.14868449 0.10656057 0.467576  ]\n",
      "  [0.1308051  0.17502241 0.14222999 0.55194247]\n",
      "  [0.1576247  0.40299326 0.21649311 0.22288895]\n",
      "  ...\n",
      "  [0.223454   0.33410245 0.20878664 0.23365691]\n",
      "  [0.08389931 0.28195095 0.16685067 0.467299  ]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f519bcffeb8>, <tensorflow.python.keras.engine.training.Model object at 0x7f519a8c0d30>, <tensorflow.python.keras.engine.training.Model object at 0x7f519a49ffd0>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f519bcffeb8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_205 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_544 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_544 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_68 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_545 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_680 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_204 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_476 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_68 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_546 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_681 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_205 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_477 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.1082013  0.05568769 0.66914505 0.1669659 ]\n",
      "  [0.24027011 0.11938808 0.43046287 0.20987894]\n",
      "  [0.2320059  0.11721199 0.43694773 0.21383439]\n",
      "  ...\n",
      "  [0.1885643  0.09354377 0.47312963 0.2447623 ]\n",
      "  [0.20195802 0.11682007 0.5635321  0.11768984]\n",
      "  [0.         0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f519b8c4cc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f519b983be0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51981cfac8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f519b8c4cc0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_208 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_552 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_552 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_69 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_553 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_690 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_207 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_483 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_69 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_554 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_691 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_208 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_484 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.09697398 0.07383147 0.45194632 0.3772482 ]\n",
      "  [0.24704474 0.11126007 0.346028   0.29566717]\n",
      "  [0.4524545  0.06586751 0.2380346  0.24364339]\n",
      "  ...\n",
      "  [0.24695195 0.23393244 0.2562781  0.26283747]\n",
      "  [0.31220847 0.3670383  0.16804671 0.15270646]\n",
      "  [0.         0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f519b286780>, <tensorflow.python.keras.engine.training.Model object at 0x7f519a50bd30>, <tensorflow.python.keras.engine.training.Model object at 0x7f5193ee49e8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f519b286780>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_211 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_560 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_560 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_70 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_561 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_700 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_210 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_490 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_70 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_562 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_701 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_211 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_491 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.21170634 0.24446219 0.09065276 0.4531787 ]\n",
      "  [0.28518152 0.19541454 0.07970704 0.4396969 ]\n",
      "  [0.22867288 0.15868714 0.17748497 0.43515497]\n",
      "  ...\n",
      "  [0.32494476 0.2677458  0.09341078 0.31389865]\n",
      "  [0.28064534 0.16175368 0.11402594 0.44357508]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f519ab62f60>, <tensorflow.python.keras.engine.training.Model object at 0x7f519974beb8>, <tensorflow.python.keras.engine.training.Model object at 0x7f5198cdebe0>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f519ab62f60>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_214 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_568 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_568 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_71 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_569 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_710 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_213 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_497 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_71 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_570 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_711 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_214 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_498 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.04051959 0.23106799 0.08377074 0.6446417 ]\n",
      "  [0.00928804 0.04945108 0.02613855 0.91512233]\n",
      "  [0.03362293 0.129704   0.03930698 0.7973661 ]\n",
      "  ...\n",
      "  [0.03588776 0.09201855 0.04049697 0.83159673]\n",
      "  [0.02683933 0.05610824 0.04206091 0.8749915 ]\n",
      "  [0.         0.9999713  0.         0.00002878]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51b94b99b0>, <tensorflow.python.keras.engine.training.Model object at 0x7f5192281cc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f5192715b70>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51b94b99b0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_217 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_576 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_576 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_72 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_577 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_720 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_216 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_504 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_72 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_578 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_721 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_217 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_505 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         0.         0.         1.        ]\n",
      "  [0.         0.00000015 0.         0.9999999 ]\n",
      "  [0.34963062 0.64690125 0.00227885 0.00118921]\n",
      "  ...\n",
      "  [0.2408709  0.2875574  0.24911785 0.22245389]\n",
      "  [0.33117315 0.21982595 0.19963661 0.24936426]\n",
      "  [0.         1.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51a1eb0da0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51b1cdb748>, <tensorflow.python.keras.engine.training.Model object at 0x7f5192953a90>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51a1eb0da0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_220 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_584 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_584 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_73 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_585 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_730 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_219 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_511 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_73 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_586 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_731 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_220 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_512 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.20193033 0.25816166 0.38624215 0.15366586]\n",
      "  [0.24874853 0.17812966 0.23792112 0.33520067]\n",
      "  [0.15085514 0.3337555  0.17913686 0.33625248]\n",
      "  ...\n",
      "  [0.19402094 0.19316173 0.29137903 0.3214383 ]\n",
      "  [0.10041045 0.32703766 0.313031   0.25952092]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51996a4ba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f51937daf60>, <tensorflow.python.keras.engine.training.Model object at 0x7f519286fb70>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51996a4ba8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_223 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_592 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_592 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_74 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_593 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_740 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_222 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_518 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_74 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_594 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_741 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_223 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_519 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.50453025 0.04056278 0.12962697 0.32527998]\n",
      "  [0.53128004 0.05077519 0.10056951 0.31737527]\n",
      "  [0.45815194 0.05268418 0.14872678 0.34043705]\n",
      "  ...\n",
      "  [0.42129046 0.03575804 0.08579852 0.45715302]\n",
      "  [0.2564681  0.08007419 0.19825369 0.46520397]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5191c61a20>, <tensorflow.python.keras.engine.training.Model object at 0x7f51905f4d30>, <tensorflow.python.keras.engine.training.Model object at 0x7f519339bc50>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5191c61a20>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_226 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_600 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_600 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_75 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_601 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_750 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_225 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_525 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_75 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_602 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_751 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_226 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_526 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  ...\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.   0.   0.   1.  ]]\n",
      "\n",
      " [[0.   0.   0.   1.  ]\n",
      "  [0.   0.   0.   1.  ]\n",
      "  [0.   0.   0.   1.  ]\n",
      "  ...\n",
      "  [0.   0.   1.   0.  ]\n",
      "  [0.   0.   1.   0.  ]\n",
      "  [0.   0.   1.   0.  ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5198df17b8>, <tensorflow.python.keras.engine.training.Model object at 0x7f5192f8b9e8>, <tensorflow.python.keras.engine.training.Model object at 0x7f5190bd3c18>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5198df17b8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_229 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_608 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_608 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_76 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_609 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_760 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_228 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_532 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_76 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_610 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_761 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_229 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_533 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.4272518  0.38342902 0.03336233 0.15595685]\n",
      "  [0.5968558  0.00192009 0.02180949 0.37941465]\n",
      "  [0.2716343  0.04890831 0.46700555 0.21245183]\n",
      "  ...\n",
      "  [0.24123292 0.14849594 0.26972052 0.3405506 ]\n",
      "  [0.40774584 0.47603637 0.07473317 0.04148457]\n",
      "  [0.         0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib/EEGNet/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51984ddbe0>, <tensorflow.python.keras.engine.training.Model object at 0x7f5192de0be0>, <tensorflow.python.keras.engine.training.Model object at 0x7f519005e6d8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51984ddbe0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_232 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_616 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_616 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_77 (Depthwi (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_617 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_770 (Activation)  (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_231 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_539 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_77 (Separab (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_618 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_771 (Activation)  (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_232 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_540 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.1679891  0.3118617  0.24134493 0.27880433]\n",
      "  [0.15396833 0.46945617 0.19480857 0.18176693]\n",
      "  [0.15627739 0.21344386 0.4400703  0.1902084 ]\n",
      "  ...\n",
      "  [0.25720465 0.25676242 0.21939819 0.26663476]\n",
      "  [0.18513468 0.40234086 0.2783652  0.13415931]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5192e0fc18>, <tensorflow.python.keras.engine.training.Model object at 0x7f51b86d8b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f519048ce48>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f519048ce48>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_237 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_627 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_628 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_628 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_785 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_312 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_549 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_629 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_629 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_786 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_313 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_550 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_630 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_630 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_787 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_314 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_551 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_631 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_631 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_788 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_315 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_552 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_157 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_789 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  ...\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.01267957 0.00060696 0.87506694 0.11164655]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f519271bb00>, <tensorflow.python.keras.engine.training.Model object at 0x7f519254ba20>, <tensorflow.python.keras.engine.training.Model object at 0x7f519055ac50>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f519055ac50>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_240 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_635 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_636 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_636 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_795 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_316 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_556 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_637 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_637 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_796 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_317 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_557 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_638 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_638 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_797 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_318 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_558 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_639 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_639 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_798 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_319 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_559 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_159 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_799 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00000635 0.9225977  0.07725261 0.00014336]\n",
      "  [0.00000001 0.         0.         1.        ]\n",
      "  [0.00000009 0.00001611 0.9999838  0.        ]\n",
      "  ...\n",
      "  [0.01417738 0.05234137 0.2213247  0.71215653]\n",
      "  [0.01215389 0.04371117 0.80640423 0.13773076]\n",
      "  [0.         0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5191fd4b38>, <tensorflow.python.keras.engine.training.Model object at 0x7f5192d14c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f518a686d30>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f518a686d30>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_243 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_643 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_644 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_644 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_805 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_320 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_563 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_645 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_645 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_806 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_321 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_564 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_646 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_646 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_807 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_322 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_565 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_647 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_647 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_808 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_323 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_566 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_161 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_809 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.31667465 0.00047135 0.4981351  0.18471888]\n",
      "  [0.32148677 0.00023241 0.6189773  0.05930351]\n",
      "  [0.09417118 0.00067017 0.30304682 0.60211176]\n",
      "  ...\n",
      "  [0.4112658  0.00009557 0.40989152 0.17874719]\n",
      "  [0.21343847 0.00110931 0.65944487 0.12600738]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5193b27ba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f5189119ac8>, <tensorflow.python.keras.engine.training.Model object at 0x7f518b219d68>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f518b219d68>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_246 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_651 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_652 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_652 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_815 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_324 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_570 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_653 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_653 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_816 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_325 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_571 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_654 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_654 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_817 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_326 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_572 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_655 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_655 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_818 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_327 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_573 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_163 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_819 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.17998007 0.28299332 0.45408183 0.08294478]\n",
      "  [0.02078394 0.22594544 0.44444317 0.30882743]\n",
      "  [0.09201963 0.07118337 0.7139274  0.12286967]\n",
      "  ...\n",
      "  [0.08337273 0.23387976 0.56248754 0.12025996]\n",
      "  [0.07633663 0.0871706  0.5456622  0.2908305 ]\n",
      "  [0.         0.         0.9971245  0.00287544]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51a86a8a90>, <tensorflow.python.keras.engine.training.Model object at 0x7f5188b79cc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f518a511ba8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f518a511ba8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_249 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_659 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_660 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_660 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_825 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_328 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_577 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_661 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_661 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_826 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_329 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_578 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_662 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_662 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_827 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_330 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_579 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_663 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_663 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_828 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_331 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_580 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_165 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_829 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.03743272 0.43213448 0.08566132 0.44477153]\n",
      "  [0.09918846 0.61448324 0.02390963 0.2624187 ]\n",
      "  [0.02680936 0.9288204  0.01752884 0.02684141]\n",
      "  ...\n",
      "  [0.06105551 0.6328015  0.02637167 0.27977142]\n",
      "  [0.07917215 0.4477316  0.04507282 0.42802337]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51b1d99cc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a0820c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f518a1ebc88>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f518a1ebc88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_252 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_667 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_668 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_668 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_835 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_332 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_584 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_669 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_669 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_836 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_333 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_585 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_670 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_670 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_837 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_334 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_586 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_671 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_671 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_838 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_335 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_587 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_167 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_839 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.6520365  0.2258915  0.07217635 0.04989564]\n",
      "  [0.7072234  0.14314608 0.13050522 0.01912533]\n",
      "  [0.8604223  0.08985434 0.03086416 0.01885917]\n",
      "  ...\n",
      "  [0.6162074  0.22721131 0.12014448 0.0364368 ]\n",
      "  [0.9187706  0.04665421 0.03167595 0.00289918]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51b9766358>, <tensorflow.python.keras.engine.training.Model object at 0x7f5189e9fa20>, <tensorflow.python.keras.engine.training.Model object at 0x7f5188f52cc0>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5188f52cc0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_255 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_675 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_676 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_676 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_845 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_336 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_591 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_677 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_677 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_846 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_337 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_592 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_678 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_678 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_847 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_338 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_593 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_679 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_679 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_848 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_339 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_594 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_169 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_849 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.9983791  0.0001027  0.0015007  0.00001752]\n",
      "  [0.8925409  0.00526451 0.10189055 0.00030408]\n",
      "  [0.9941514  0.00039851 0.0052975  0.00015249]\n",
      "  ...\n",
      "  [0.9908227  0.00041804 0.00867852 0.0000808 ]\n",
      "  [0.9940591  0.00002501 0.00590326 0.00001262]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5191d88e48>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9f04bc18>, <tensorflow.python.keras.engine.training.Model object at 0x7f5189006b00>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5189006b00>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_258 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_683 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_684 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_684 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_855 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_340 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_598 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_685 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_685 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_856 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_341 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_599 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_686 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_686 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_857 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_342 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_600 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_687 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_687 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_858 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_343 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_601 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_171 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_859 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         1.         0.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.00000022 0.99999976 0.        ]\n",
      "  ...\n",
      "  [0.00357146 0.17521787 0.8146695  0.0065412 ]\n",
      "  [0.01185395 0.2391155  0.642454   0.10657649]\n",
      "  [0.         0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51a3645fd0>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a9adbb70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9fb30be0>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f9fb30be0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_261 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_691 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_692 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_692 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_865 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_344 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_605 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_693 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_693 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_866 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_345 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_606 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_694 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_694 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_867 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_346 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_607 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_695 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_695 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_868 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_347 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_608 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_173 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_869 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.617366   0.19085766 0.07030556 0.12147077]\n",
      "  [0.32439747 0.4218631  0.09008729 0.16365208]\n",
      "  [0.07691373 0.8430259  0.04285145 0.03720887]\n",
      "  ...\n",
      "  [0.08937404 0.3412418  0.14310041 0.42628372]\n",
      "  [0.05102828 0.84496886 0.02538403 0.07861889]\n",
      "  [0.         1.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f518a588a58>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5ff659b0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9ea39c18>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f9ea39c18>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_264 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_699 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_700 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_700 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_875 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_348 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_612 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_701 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_701 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_876 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_349 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_613 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_702 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_702 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_877 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_350 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_614 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_703 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_703 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_878 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_351 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_615 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_175 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_879 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.7786229  0.20047912 0.00295432 0.01794367]\n",
      "  [0.94561815 0.03613999 0.00397968 0.01426219]\n",
      "  [0.9439806  0.04063879 0.00092813 0.01445252]\n",
      "  ...\n",
      "  [0.84025484 0.00380785 0.08036624 0.07557108]\n",
      "  [0.60572726 0.35276064 0.00692333 0.03458884]\n",
      "  [0.         1.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f518a61cda0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5f735780>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9fb24ac8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f9fb24ac8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_267 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_707 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_708 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_708 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_885 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_352 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_619 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_709 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_709 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_886 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_353 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_620 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_710 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_710 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_887 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_354 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_621 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_711 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_711 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_888 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_355 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_622 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_177 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_889 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  ...\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.   0.   0.   1.  ]]\n",
      "\n",
      " [[0.   0.   0.   1.  ]\n",
      "  [0.   0.   0.   1.  ]\n",
      "  [0.   0.   0.   1.  ]\n",
      "  ...\n",
      "  [0.   0.   1.   0.  ]\n",
      "  [0.   0.   1.   0.  ]\n",
      "  [0.   0.   1.   0.  ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5189069b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9ee84e80>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9e63cb38>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f9e63cb38>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_270 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_715 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_716 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_716 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_895 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_356 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_626 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_717 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_717 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_896 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_357 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_627 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_718 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_718 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_897 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_358 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_628 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_719 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_719 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_898 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_359 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_629 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_179 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_899 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.43573436 0.00837315 0.30965865 0.24623385]\n",
      "  [0.00007327 0.00181337 0.05183141 0.94628185]\n",
      "  [0.29078797 0.00008246 0.39083883 0.3182907 ]\n",
      "  ...\n",
      "  [0.4620117  0.0255163  0.3131881  0.19928382]\n",
      "  [0.3031694  0.13946198 0.32984155 0.22752708]\n",
      "  [0.9914629  0.         0.00000001 0.00853706]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5189da99b0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9cb1ec88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9dbfab70>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f9dbfab70>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_273 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_723 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_724 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_724 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_905 (Activation)  (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_360 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_633 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_725 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_725 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_906 (Activation)  (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_361 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_634 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_726 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_726 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_907 (Activation)  (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_362 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_635 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_727 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_727 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_908 (Activation)  (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_363 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_636 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_181 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_909 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.25715238 0.15435044 0.3488379  0.23965925]\n",
      "  [0.12217151 0.07657923 0.3859829  0.41526636]\n",
      "  [0.3260725  0.15514793 0.36526364 0.15351589]\n",
      "  ...\n",
      "  [0.31974295 0.16730562 0.11107805 0.40187344]\n",
      "  [0.06757029 0.5605833  0.35528582 0.01656049]\n",
      "  [0.         0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51885267b8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9c2976d8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9e296a20>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f9c2976d8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_275 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_729 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_730 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_731 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_912 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_275 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_913 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_639 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_182 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_914 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.8326984  0.         0.         0.16730155]\n",
      "  [0.8326984  0.         0.         0.16730155]\n",
      "  [0.8326984  0.         0.         0.16730155]\n",
      "  ...\n",
      "  [0.8326984  0.         0.         0.16730155]\n",
      "  [0.8326984  0.         0.         0.16730155]\n",
      "  [0.14465173 0.         0.         0.8553482 ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5188d42f60>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9f94be48>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9cf4ec18>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f9f94be48>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_278 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_737 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_738 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_739 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_922 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_278 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_923 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_646 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_184 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_924 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.01147443 0.00000025 0.00000001 0.98852533]\n",
      "  [0.16338946 0.00000028 0.00000002 0.83661026]\n",
      "  [0.0027969  0.         0.         0.9972031 ]\n",
      "  ...\n",
      "  [0.14418943 0.00055428 0.00014587 0.85511047]\n",
      "  [0.19165784 0.00269505 0.00042256 0.80522454]\n",
      "  [0.5717937  0.         0.         0.42820626]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f9e5849e8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9d6cdcf8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5fccbba8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f9d6cdcf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_281 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_745 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_746 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_747 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_932 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_281 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_933 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_653 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_186 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_934 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.09631534 0.0000003  0.9032802  0.00040414]\n",
      "  [0.08552371 0.0000004  0.9135499  0.000926  ]\n",
      "  [0.08711308 0.00000033 0.9124014  0.00048525]\n",
      "  ...\n",
      "  [0.03558465 0.00000054 0.96361613 0.00079871]\n",
      "  [0.04482543 0.00000062 0.95033145 0.00484252]\n",
      "  [0.00016556 0.         0.9998344  0.00000001]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f9eab0da0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5ff71780>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9d7aeac8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f5ff71780>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_284 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_753 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_754 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_755 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_942 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_284 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_943 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_660 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_188 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_944 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.03352018 0.9535965  0.00790137 0.00498192]\n",
      "  [0.34530726 0.60385644 0.01629999 0.03453631]\n",
      "  [0.5702703  0.39055833 0.01807196 0.02109946]\n",
      "  ...\n",
      "  [0.14293529 0.77040976 0.06803563 0.01861939]\n",
      "  [0.18854466 0.7305948  0.06728733 0.01357312]\n",
      "  [0.00007352 0.9999182  0.00000135 0.00000692]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f9e25bb70>, <tensorflow.python.keras.engine.training.Model object at 0x7f51a0728fd0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9ceb0cf8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51a0728fd0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_287 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_761 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_762 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_763 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_952 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_287 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_953 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_667 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_190 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_954 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.01958427 0.01738327 0.95259124 0.01044121]\n",
      "  [0.02078329 0.01079185 0.95887923 0.00954571]\n",
      "  [0.00693943 0.02663737 0.96150225 0.00492101]\n",
      "  ...\n",
      "  [0.01122799 0.0014453  0.98202366 0.00530307]\n",
      "  [0.04023218 0.00178985 0.8846879  0.07329004]\n",
      "  [0.         0.         1.         0.00000005]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f9d057be0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9cf5cb00>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5e3a5e80>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f9cf5cb00>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_290 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_769 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_770 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_771 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_962 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_290 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_963 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_674 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_192 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_964 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00811557 0.44389814 0.14824897 0.3997373 ]\n",
      "  [0.00223609 0.6228417  0.03029588 0.34462634]\n",
      "  [0.00920238 0.45202357 0.14201601 0.39675808]\n",
      "  ...\n",
      "  [0.01663179 0.6004135  0.046996   0.33595866]\n",
      "  [0.02444081 0.5641768  0.0623569  0.34902558]\n",
      "  [0.         0.9990277  0.00000195 0.00097035]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f9cf11ac8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5fcdfa20>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5e0f0c50>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f5fcdfa20>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_293 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_777 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_778 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_779 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_972 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_293 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_973 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_681 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_194 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_974 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00000001 0.99662113 0.00000048 0.00337837]\n",
      "  [0.         0.99861145 0.00000047 0.0013881 ]\n",
      "  [0.         0.9950665  0.00000113 0.00493228]\n",
      "  ...\n",
      "  [0.         0.9989949  0.00000085 0.00100426]\n",
      "  [0.00000001 0.99642724 0.00000079 0.00357203]\n",
      "  [0.00000002 0.9972807  0.00000132 0.00271793]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5199c39be0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9d6fac18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5dbc5710>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f9d6fac18>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_296 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_785 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_786 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_787 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_982 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_296 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_983 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_688 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_196 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_984 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.01934769 0.00000588 0.7022907  0.27835575]\n",
      "  [0.00386702 0.00003153 0.00002297 0.99607855]\n",
      "  [0.0020586  0.00008894 0.67204404 0.32580844]\n",
      "  ...\n",
      "  [0.01066736 0.00102663 0.73275644 0.2555496 ]\n",
      "  [0.07904359 0.01586286 0.13041104 0.7746825 ]\n",
      "  [0.00004626 0.00000171 0.09611189 0.9038401 ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f5f444c50>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5ee49ba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5e019e80>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f5ee49ba8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_299 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_793 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_794 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_795 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_992 (Activation)  (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_299 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_993 (Activation)  (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_695 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_198 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_994 (Activation)  (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.03803134 0.9273609  0.02327537 0.01133243]\n",
      "  [0.14693438 0.6506142  0.03867302 0.16377838]\n",
      "  [0.1303833  0.54691875 0.2881342  0.03456375]\n",
      "  ...\n",
      "  [0.27290657 0.61610234 0.04620596 0.0647851 ]\n",
      "  [0.09247938 0.73141557 0.17369851 0.0024066 ]\n",
      "  [0.0000001  0.9999989  0.00000096 0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5199390f28>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5b39aac8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5d420cf8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f5b39aac8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_302 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_801 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_802 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_803 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1002 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_302 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1003 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_702 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_200 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1004 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.03470559 0.072313   0.78538525 0.10759612]\n",
      "  [0.01595112 0.0953712  0.6941301  0.19454753]\n",
      "  [0.04777959 0.06705729 0.6490261  0.236137  ]\n",
      "  ...\n",
      "  [0.38778326 0.03812075 0.28239912 0.29169694]\n",
      "  [0.15949655 0.18198054 0.5251523  0.13337062]\n",
      "  [0.00007528 0.00250141 0.9442285  0.05319477]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51925cbc18>, <tensorflow.python.keras.engine.training.Model object at 0x7f51995deb38>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5ceaa748>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f51995deb38>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_305 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_809 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_810 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_811 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1012 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_305 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1013 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_709 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_202 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1014 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.9998468  0.00015312 0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f5f523c18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5e811b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5c235e48>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f5e811b70>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_308 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_817 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_818 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_819 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1022 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_308 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1023 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_716 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_204 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1024 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.04571469 0.00000746 0.95056236 0.00371551]\n",
      "  [0.00617211 0.00000012 0.99315697 0.00067078]\n",
      "  [0.00696667 0.00001452 0.9928982  0.00012063]\n",
      "  ...\n",
      "  [0.39646447 0.13658586 0.37864435 0.08830528]\n",
      "  [0.00434414 0.00025631 0.93224967 0.06314994]\n",
      "  [0.42807886 0.00236506 0.47692522 0.0926308 ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51993dcb00>, <tensorflow.python.keras.engine.training.Model object at 0x7f5198a7da20>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5c2b6c50>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5198a7da20>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_311 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_825 (Conv2D)          (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_826 (Conv2D)          (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_827 (Bat (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1032 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_311 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1033 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_723 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_206 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1034 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.02232412 0.11449759 0.79999125 0.06318709]\n",
      "  [0.0988979  0.16956621 0.3524765  0.37905937]\n",
      "  [0.09046059 0.2299832  0.5664664  0.11308984]\n",
      "  ...\n",
      "  [0.02361828 0.0825635  0.2979222  0.59589607]\n",
      "  [0.12611748 0.03068348 0.75924283 0.08395626]\n",
      "  [0.00188141 0.00172855 0.996097   0.00029302]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f5199688b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5c5e8c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5ad7dd30>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f5199688b70>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_313 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_832 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_832 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_104 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_833 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1040 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_312 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_728 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_104 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_834 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1041 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_313 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_729 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  ...\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.00000576 0.00000002 0.         0.99999416]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f5cd69ba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5b24dac8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f59f6cd68>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f5cd69ba8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_316 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_840 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_840 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_105 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_841 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1050 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_315 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_735 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_105 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_842 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1051 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_316 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_736 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.01655095 0.07114684 0.82259214 0.08971011]\n",
      "  [0.06579244 0.7274168  0.20432904 0.00246165]\n",
      "  [0.06776881 0.00002539 0.93215394 0.00005186]\n",
      "  ...\n",
      "  [0.16390131 0.25987276 0.31493902 0.26128688]\n",
      "  [0.2304194  0.26261216 0.26550388 0.24146457]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f5cc2ea20>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9dfe0e10>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5971fba8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f5cc2ea20>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_319 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_848 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_848 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_106 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_849 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1060 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_318 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_742 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_106 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_850 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1061 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_319 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_743 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.14605716 0.71053654 0.12863575 0.01477049]\n",
      "  [0.03111467 0.08729202 0.8586208  0.02297249]\n",
      "  [0.11005048 0.5158071  0.36123583 0.01290653]\n",
      "  ...\n",
      "  [0.04604203 0.23586184 0.6939062  0.02418999]\n",
      "  [0.11526379 0.59762335 0.24908933 0.03802351]\n",
      "  [0.         1.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f5cbb7c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5bba4c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f59b04c88>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f5cbb7c88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_322 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_856 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_856 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_107 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_857 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1070 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_321 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_749 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_107 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_858 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1071 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_322 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_750 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.22575736 0.30859002 0.23517087 0.23048176]\n",
      "  [0.20935883 0.26107267 0.27323145 0.25633705]\n",
      "  [0.23792858 0.24020399 0.27407363 0.24779381]\n",
      "  ...\n",
      "  [0.23997857 0.27338636 0.24981138 0.23682366]\n",
      "  [0.13101375 0.27757686 0.2873655  0.30404383]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f5c84cb00>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f58208a20>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f57b78cc0>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f5c84cb00>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_325 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_864 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_864 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_108 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_865 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1080 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_324 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_756 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_108 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_866 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1081 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_325 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_757 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.34163228 0.14457513 0.20979796 0.30399463]\n",
      "  [0.46717983 0.15450794 0.18894292 0.18936926]\n",
      "  [0.07600255 0.22530535 0.4840641  0.21462797]\n",
      "  ...\n",
      "  [0.28864825 0.28106898 0.23675965 0.19352317]\n",
      "  [0.22210798 0.377914   0.17222163 0.22775641]\n",
      "  [0.00032143 0.         0.         0.9996786 ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f5d672e48>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5a0cfd68>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f586c4b00>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f5d672e48>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_328 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_872 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_872 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_109 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_873 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1090 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_327 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_763 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_109 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_874 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1091 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_328 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_764 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.4149214  0.15928867 0.20648314 0.21930675]\n",
      "  [0.32564896 0.20930092 0.1787785  0.28627154]\n",
      "  [0.2420888  0.2226463  0.23030272 0.3049622 ]\n",
      "  ...\n",
      "  [0.23836528 0.25964183 0.2411313  0.2608616 ]\n",
      "  [0.33514562 0.28389534 0.18365456 0.19730443]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f5ae68fd0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f59af5eb8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f576eabe0>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f5ae68fd0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_331 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_880 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_880 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_110 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_881 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1100 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_330 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_770 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_110 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_882 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1101 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_331 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_771 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.1822503  0.22731446 0.33460778 0.25582746]\n",
      "  [0.20001562 0.15869859 0.24631412 0.3949717 ]\n",
      "  [0.25041917 0.11952775 0.24503484 0.3850182 ]\n",
      "  ...\n",
      "  [0.13879183 0.08781511 0.44348565 0.32990745]\n",
      "  [0.19492182 0.17429014 0.4411664  0.18962158]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f5aaeaa58>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f580379b0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f570b6c18>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f5aaeaa58>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_334 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_888 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_888 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_111 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_889 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1110 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_333 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_777 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_111 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_890 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1111 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_334 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_778 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         0.         0.         1.        ]\n",
      "  [0.00003867 0.00570618 0.03592115 0.9583339 ]\n",
      "  [0.01262358 0.00014281 0.49362093 0.49361274]\n",
      "  ...\n",
      "  [0.28889552 0.10903767 0.30256167 0.29950514]\n",
      "  [0.14672646 0.09765486 0.2818075  0.47381118]\n",
      "  [0.         0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f59111da0>, <tensorflow.python.keras.engine.training.Model object at 0x7f5189cb6828>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f56e9fac8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f59111da0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_337 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_896 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_896 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_112 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_897 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1120 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_336 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_784 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_112 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_898 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1121 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_337 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_785 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.29916167 0.32644305 0.09624313 0.2781521 ]\n",
      "  [0.23773617 0.22997785 0.18523856 0.34704748]\n",
      "  [0.32432225 0.24608332 0.18404198 0.2455525 ]\n",
      "  ...\n",
      "  [0.225647   0.25593537 0.30974087 0.20867677]\n",
      "  [0.23927209 0.24566154 0.22533385 0.28973252]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f58d10b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f555ecef0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f56e5eb38>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f58d10b70>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_340 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_904 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_904 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_113 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_905 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1130 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_339 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_791 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_113 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_906 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1131 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_340 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_792 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.2729067  0.45570928 0.10968682 0.16169716]\n",
      "  [0.28432906 0.372053   0.13804303 0.20557496]\n",
      "  [0.32414153 0.317732   0.13609958 0.22202681]\n",
      "  ...\n",
      "  [0.11050408 0.64800245 0.06887665 0.17261685]\n",
      "  [0.8227984  0.07392671 0.08557591 0.01769901]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f591279b0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f540f5cc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5595db70>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f591279b0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_343 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_912 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_912 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_114 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_913 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1140 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_342 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_798 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_114 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_914 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1141 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_343 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_799 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  ...\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.   0.   0.   1.  ]]\n",
      "\n",
      " [[0.   0.   0.   1.  ]\n",
      "  [0.   0.   0.   1.  ]\n",
      "  [0.   0.   0.   1.  ]\n",
      "  ...\n",
      "  [0.   0.   1.   0.  ]\n",
      "  [0.   0.   1.   0.  ]\n",
      "  [0.   0.   1.   0.  ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f579887b8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f53861710>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5559ca20>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f579887b8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_346 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_920 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_920 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_115 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_921 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1150 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_345 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_805 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_115 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_922 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1151 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_346 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_806 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.38006583 0.2468364  0.14142184 0.23167588]\n",
      "  [0.27948275 0.15208915 0.10020194 0.46822616]\n",
      "  [0.0686447  0.4466925  0.31241605 0.17224677]\n",
      "  ...\n",
      "  [0.25922364 0.29869565 0.20162201 0.24045874]\n",
      "  [0.22688076 0.23703505 0.40515178 0.13093236]\n",
      "  [0.09750134 0.00002346 0.9024752  0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f56cf1ef0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f57923e80>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5392ac88>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f56cf1ef0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_349 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_928 (Conv2D)          (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_928 (Bat (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_116 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_929 (Bat (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1160 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_348 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_812 (Dropout)        (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_116 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_930 (Bat (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1161 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_349 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_813 (Dropout)        (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.06139218 0.4384456  0.0978668  0.40229538]\n",
      "  [0.16269305 0.502389   0.24781777 0.08710016]\n",
      "  [0.08506788 0.5174059  0.24427003 0.15325615]\n",
      "  ...\n",
      "  [0.4368221  0.21022016 0.22458579 0.12837203]\n",
      "  [0.2631092  0.277583   0.3357481  0.1235597 ]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f5196c908>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f55c91a20>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f54a54c50>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f54a54c50>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_354 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_939 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_940 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_940 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1175 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_468 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_822 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_941 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_941 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1176 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_469 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_823 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_942 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_942 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1177 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_470 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_824 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_943 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_943 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1178 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_471 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_825 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_235 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1179 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.49531037 0.42013007 0.02921242 0.05534713]\n",
      "  [0.4959424  0.4192187  0.02912242 0.05571648]\n",
      "  [0.49515867 0.41990784 0.02925597 0.05567757]\n",
      "  ...\n",
      "  [0.4946539  0.42038926 0.02931858 0.05563829]\n",
      "  [0.49477294 0.420454   0.02921891 0.05555417]\n",
      "  [0.00229986 0.48628068 0.48708794 0.02433151]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f56209c18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f52c2afd0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5b7facc0>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f5b7facc0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_357 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_947 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_948 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_948 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1185 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_472 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_829 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_949 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_949 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1186 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_473 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_830 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_950 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_950 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1187 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_474 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_831 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_951 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_951 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1188 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_475 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_832 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_237 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1189 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f56b919b0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5f8579e8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5774ac88>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f5774ac88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_360 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_955 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_956 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_956 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1195 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_476 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_836 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_957 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_957 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1196 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_477 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_837 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_958 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_958 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1197 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_478 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_838 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_959 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_959 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1198 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_479 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_839 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_239 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1199 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f55e13da0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5370b780>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f55f76ac8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f55f76ac8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_363 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_963 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_964 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_964 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1205 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_480 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_843 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_965 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_965 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1206 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_481 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_844 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_966 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_966 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1207 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_482 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_845 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_967 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_967 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1208 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_483 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_846 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_241 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1209 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f54c0d898>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9e509898>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f56867c88>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f56867c88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_366 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_971 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_972 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_972 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1215 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_484 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_850 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_973 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_973 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1216 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_485 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_851 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_974 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_974 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1217 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_486 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_852 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_975 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_975 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1218 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_487 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_853 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_243 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1219 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f51895f6d68>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f598e2c50>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f9c0f1eb8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f9c0f1eb8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_369 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_979 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_980 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_980 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1225 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_488 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_857 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_981 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_981 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1226 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_489 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_858 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_982 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_982 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1227 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_490 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_859 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_983 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_983 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1228 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_491 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_860 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_245 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1229 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f5504db00>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f51a3ba90>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f5329dcc0>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f5329dcc0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_372 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_987 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_988 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_988 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1235 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_492 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_864 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_989 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_989 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1236 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_493 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_865 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_990 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_990 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1237 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_494 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_866 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_991 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_991 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1238 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_495 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_867 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_247 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1239 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f518acb79e8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f51200da0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f53130b38>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f53130b38>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_375 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_995 (Conv2D)          (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_996 (Conv2D)          (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_996 (Bat (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1245 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_496 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_871 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_997 (Conv2D)          (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_997 (Bat (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1246 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_497 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_872 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_998 (Conv2D)          (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_998 (Bat (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1247 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_498 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_873 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_999 (Conv2D)          (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_999 (Bat (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1248 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_499 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_874 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_249 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1249 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f511627b8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f57113780>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f53141a20>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f53141a20>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_378 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1003 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1004 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1004 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1255 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_500 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_878 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1005 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1005 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1256 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_501 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_879 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1006 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1006 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1257 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_502 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_880 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1007 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1007 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1258 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_503 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_881 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_251 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1259 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f59475c50>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4fec7cf8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f51f409b0>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f51f409b0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_381 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1011 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1012 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1012 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1265 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_504 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_885 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1013 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1013 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1266 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_505 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_886 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1014 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1014 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1267 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_506 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_887 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1015 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1015 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1268 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_507 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_888 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_253 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1269 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f573765f8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f57666a90>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f53b95cc0>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f53b95cc0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_384 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1019 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1020 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1020 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1275 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_508 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_892 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1021 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1021 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1276 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_509 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_893 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1022 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1022 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1277 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_510 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_894 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1023 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1023 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1278 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_511 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_895 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_255 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_255 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1279 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.20438285 0.31750402 0.20883912 0.26927403]\n",
      "  [0.20664085 0.31664932 0.20989165 0.26681817]\n",
      "  [0.20355363 0.3144857  0.2108885  0.27107212]\n",
      "  ...\n",
      "  [0.19920768 0.31419608 0.21434402 0.2722522 ]\n",
      "  [0.20122038 0.32120052 0.21003722 0.26754186]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f4f89ae48>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4f01ada0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f50b83b38>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f50b83b38>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_387 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1027 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1028 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1028 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1285 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_512 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_899 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1029 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1029 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1286 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_513 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_900 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1030 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1030 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1287 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_514 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_901 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1031 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1031 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1288 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_515 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_902 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_257 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_257 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1289 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Deep/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f5966a7b8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f52bcc6d8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f510dca20>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f510dca20>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_390 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1035 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1036 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1036 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1295 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_516 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_906 (Dropout)        (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1037 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1037 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1296 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_517 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_907 (Dropout)        (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1038 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1038 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1297 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_518 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_908 (Dropout)        (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1039 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1039 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1298 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_519 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_909 (Dropout)        (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_259 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_259 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1299 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f4e801cc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4e015c18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f514e5b70>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4e015c18>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_392 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1041 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1042 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1043 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1302 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_392 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1303 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_912 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_260 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_260 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1304 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.05082356 0.9177143  0.03140334 0.00005879]\n",
      "  [0.05106805 0.9169023  0.03197004 0.00005963]\n",
      "  [0.05036443 0.91819555 0.03138243 0.00005758]\n",
      "  ...\n",
      "  [0.05157572 0.91629267 0.03207457 0.00005704]\n",
      "  [0.0528553  0.9154318  0.03165454 0.0000584 ]\n",
      "  [0.03665705 0.9440813  0.01886345 0.00039826]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f500fcb38>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4cf2ffd0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f50381748>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4cf2ffd0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_395 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1049 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1050 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1051 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1312 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_395 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1313 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_919 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_262 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_262 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1314 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.9968267  0.         0.0031732  0.        ]\n",
      "  [0.99674326 0.         0.00325681 0.        ]\n",
      "  [0.99574417 0.         0.00425586 0.        ]\n",
      "  ...\n",
      "  [0.9974643  0.         0.00253564 0.        ]\n",
      "  [0.9966145  0.         0.00338552 0.        ]\n",
      "  [0.9958839  0.         0.00411609 0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f4e7e7b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f52cf5be0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4f74dd30>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f52cf5be0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_398 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1057 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1058 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1059 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1322 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_398 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1323 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_926 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_264 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_264 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1324 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         0.         0.05089261 0.9491074 ]\n",
      "  [0.         0.         0.05194795 0.94805205]\n",
      "  [0.         0.         0.05252508 0.94747484]\n",
      "  ...\n",
      "  [0.         0.         0.04412311 0.9558768 ]\n",
      "  [0.         0.         0.04412311 0.9558768 ]\n",
      "  [0.         0.         0.04689457 0.95310545]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f5281fc88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4c756eb8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4e4a5ba8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4c756eb8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_401 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1065 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1066 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1067 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1332 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_401 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1333 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_933 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_266 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_266 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1334 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00042512 0.00070271 0.89454657 0.10432563]\n",
      "  [0.0003777  0.00073832 0.9025025  0.09638147]\n",
      "  [0.00033017 0.00074028 0.91723055 0.08169898]\n",
      "  ...\n",
      "  [0.00042512 0.00070271 0.89454657 0.10432563]\n",
      "  [0.00042512 0.00070271 0.89454657 0.10432563]\n",
      "  [0.00046888 0.00073002 0.8936944  0.10510674]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f50e04eb8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4be8bd30>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4e616fd0>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4be8bd30>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_404 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1073 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1074 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1075 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1342 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_404 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1343 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_940 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_268 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_268 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1344 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         1.         0.00000003 0.        ]\n",
      "  [0.         1.         0.00000003 0.        ]\n",
      "  [0.         1.         0.00000003 0.        ]\n",
      "  ...\n",
      "  [0.         1.         0.00000005 0.        ]\n",
      "  [0.         1.         0.00000004 0.        ]\n",
      "  [0.         1.         0.00000001 0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f54292c50>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4a590ba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4dc8de80>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4a590ba8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_407 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1081 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1082 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1083 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1352 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_407 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1353 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_947 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_270 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_270 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1354 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.9999472  0.         0.         0.00005283]\n",
      "  [0.99991584 0.         0.         0.00008411]\n",
      "  [0.99990916 0.         0.         0.00009082]\n",
      "  ...\n",
      "  [0.9999491  0.         0.         0.00005088]\n",
      "  [0.99995244 0.         0.         0.00004757]\n",
      "  [0.9999505  0.         0.         0.00004949]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f52469b00>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f50ccfa58>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4d48ac88>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f50ccfa58>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_410 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1089 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1090 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1091 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1362 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_410 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1363 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_954 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_272 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_272 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1364 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         0.9995259  0.00006427 0.00040982]\n",
      "  [0.         0.9995142  0.00006855 0.00041721]\n",
      "  [0.         0.999509   0.00006799 0.00042308]\n",
      "  ...\n",
      "  [0.         0.9991574  0.00023676 0.00060579]\n",
      "  [0.         0.99931145 0.000171   0.00051754]\n",
      "  [0.         0.9990965  0.00025649 0.000647  ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f50ae5eb8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4bbc3eb8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4caf5be0>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4bbc3eb8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_413 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1097 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1098 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1099 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1372 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_413 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1373 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_961 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_274 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_274 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1374 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f54b97cc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f50e3ac18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4bfc3b00>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f50e3ac18>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_416 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1105 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1106 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1107 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1382 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_416 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1383 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_968 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_276 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_276 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1384 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00000004 0.         0.99993086 0.00006909]\n",
      "  [0.00000004 0.         0.99993086 0.00006909]\n",
      "  [0.00000004 0.         0.99993086 0.00006909]\n",
      "  ...\n",
      "  [0.00000004 0.         0.99993086 0.00006909]\n",
      "  [0.00000004 0.         0.99993086 0.00006909]\n",
      "  [0.00000003 0.         0.99986184 0.00013814]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f4fc02710>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4957bcf8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4b3e4e48>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4957bcf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_419 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1113 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1114 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1115 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1392 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_419 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1393 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_975 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_278 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_278 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1394 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.3568023  0.         0.         0.64319766]\n",
      "  [0.3568023  0.         0.         0.64319766]\n",
      "  [0.3568023  0.         0.         0.64319766]\n",
      "  ...\n",
      "  [0.44736832 0.         0.         0.5526317 ]\n",
      "  [0.4487637  0.         0.         0.5512363 ]\n",
      "  [0.43011612 0.         0.         0.5698838 ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f4caa3e48>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4cb7dd30>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4b28efd0>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4cb7dd30>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_422 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1121 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1122 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1123 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1402 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_422 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1403 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_982 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_280 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_280 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1404 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.05582888 0.00106161 0.0021459  0.9409635 ]\n",
      "  [0.05572932 0.00096889 0.00175353 0.9415482 ]\n",
      "  [0.05724255 0.00101328 0.00181629 0.9399279 ]\n",
      "  ...\n",
      "  [0.06035503 0.00095476 0.00172091 0.93696934]\n",
      "  [0.05627263 0.00101579 0.00163811 0.9410734 ]\n",
      "  [0.         0.         0.00000001 1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f4e109c50>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4840aba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4a36de80>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4840aba8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_425 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1129 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1130 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1131 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1412 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_425 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1413 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_989 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_282 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_282 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1414 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00051593 0.01446456 0.         0.98501945]\n",
      "  [0.00081033 0.02041507 0.         0.97877455]\n",
      "  [0.00044513 0.01451018 0.         0.98504466]\n",
      "  ...\n",
      "  [0.00030063 0.00187847 0.         0.99782085]\n",
      "  [0.00029934 0.00185326 0.         0.99784744]\n",
      "  [0.00030063 0.00187847 0.         0.99782085]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/Shallow/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f4cc96c18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4c416cc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4ab449b0>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4c416cc0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_428 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1137 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1138 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1139 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1422 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_428 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1423 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_996 (Dropout)        (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_284 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_284 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1424 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.24938056 0.6549951  0.00103734 0.09458695]\n",
      "  [0.24938056 0.6549951  0.00103734 0.09458695]\n",
      "  [0.24938056 0.6549951  0.00103734 0.09458695]\n",
      "  ...\n",
      "  [0.24938056 0.6549951  0.00103734 0.09458695]\n",
      "  [0.24938056 0.6549951  0.00103734 0.09458695]\n",
      "  [0.26445702 0.16544951 0.00007243 0.570021  ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f4c80eb00>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f491cfa90>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4a19ecc0>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4c80eb00>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_430 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1144 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1144 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_143 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1145 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1430 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_429 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1001 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_143 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1146 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1431 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_430 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1002 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.24996303 0.09921278 0.49628994 0.15453431]\n",
      "  [0.25001898 0.09925287 0.49638277 0.15434532]\n",
      "  [0.2497912  0.09895511 0.4970079  0.15424573]\n",
      "  ...\n",
      "  [0.25018907 0.09930482 0.49640483 0.15410137]\n",
      "  [0.2496834  0.09898971 0.49643618 0.15489069]\n",
      "  [0.         1.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f4c8679e8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4c0bcda0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f48852b38>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4c8679e8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_433 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1152 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1152 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_144 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1153 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1440 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_432 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1008 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_144 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1154 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1441 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_433 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1009 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f491c3b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4a030710>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f487d1a20>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f491c3b70>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_436 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1160 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1160 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_145 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1161 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1450 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_435 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1015 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_145 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1162 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1451 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_436 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1016 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f4ba6ec88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f493d9c18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f48366b70>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4ba6ec88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_439 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1168 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1168 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_146 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1169 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1460 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_438 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1022 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_146 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1170 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1461 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_439 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1023 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f4818cb38>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f45202fd0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f47ac1cf8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4818cb38>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_442 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1176 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1176 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_147 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1177 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1470 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_441 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1029 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_147 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1178 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1471 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_442 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1030 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f4e370e10>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4a6f9780>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4795fac8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4e370e10>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_445 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1184 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1184 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_148 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1185 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1480 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_444 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1036 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_148 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1186 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1481 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_445 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1037 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f44c58710>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f441b2c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f45fcddd8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f44c58710>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_448 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1192 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1192 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_149 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1193 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1490 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_447 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1043 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_149 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1194 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1491 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_448 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1044 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f45a48ba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f48175c18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4602f710>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f45a48ba8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_451 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1200 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1200 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_150 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1201 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1500 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_450 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1050 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_150 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1202 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1501 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_451 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1051 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f490b7fd0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4215fb70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4518ec18>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f490b7fd0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_454 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1208 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1208 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_151 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1209 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1510 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_453 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1057 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_151 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1210 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1511 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_454 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1058 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f43a45a90>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4769b9e8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f446d5c50>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f43a45a90>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_457 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1216 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1216 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_152 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1217 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1520 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_456 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1064 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_152 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1218 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1521 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_457 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1065 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f485c6e10>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f45f8b7b8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f43bc7b00>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f485c6e10>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_460 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1224 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1224 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_153 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1225 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1530 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_459 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1071 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_153 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1226 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1531 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_460 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1072 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.14508453 0.44884852 0.19863698 0.20742996]\n",
      "  [0.14549977 0.44919756 0.1985307  0.20677191]\n",
      "  [0.14558515 0.44783765 0.19916238 0.20741484]\n",
      "  ...\n",
      "  [0.14519721 0.44723615 0.19948226 0.20808445]\n",
      "  [0.14501804 0.4475262  0.1995769  0.2078788 ]\n",
      "  [0.         1.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f46d04c18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f459e3fd0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4388ccc0>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f46d04c18>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_463 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1232 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1232 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_154 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1233 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1540 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_462 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1078 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_154 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1234 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1541 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_463 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1079 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-pure/EEGNet/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f4211aeb8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3deefe80>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f42adeb38>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4211aeb8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_466 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1240 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1240 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_155 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1241 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1550 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_465 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1085 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_155 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1242 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1551 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_466 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1086 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f470cab70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f457eccc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f402b2ba8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f402b2ba8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_471 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1251 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1252 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1252 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1565 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_624 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1095 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1253 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1253 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1566 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_625 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1096 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1254 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1254 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1567 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_626 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1097 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1255 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1255 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1568 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_627 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1098 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_313 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_313 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1569 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  ...\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.00000002 0.07456683 0.02634341 0.89908975]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f43591c18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4143eb38>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3e5ddeb8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f3e5ddeb8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_474 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1259 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1260 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1260 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1575 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_628 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1102 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1261 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1261 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1576 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_629 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1103 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1262 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1262 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1577 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_630 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1104 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1263 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1263 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1578 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_631 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1105 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_315 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_315 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1579 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00133981 0.72765046 0.00191357 0.26909617]\n",
      "  [0.00002754 0.9988549  0.00000103 0.00111661]\n",
      "  [0.00000059 0.00016435 0.         0.999835  ]\n",
      "  ...\n",
      "  [0.21026884 0.43745837 0.08103063 0.27124214]\n",
      "  [0.36792728 0.45650768 0.07232513 0.10323985]\n",
      "  [0.         0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f478eea58>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f43c439b0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3b6d2c50>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f3b6d2c50>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_477 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1267 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1268 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1268 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1585 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_632 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1109 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1269 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1269 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1586 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_633 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1110 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1270 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1270 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1587 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_634 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1111 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1271 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1271 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1588 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_635 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1112 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_317 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_317 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1589 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.18318602 0.72394294 0.09266001 0.000211  ]\n",
      "  [0.3134414  0.32581148 0.3599685  0.00077869]\n",
      "  [0.11804098 0.863745   0.01806553 0.00014851]\n",
      "  ...\n",
      "  [0.06810559 0.91724277 0.01413481 0.00051686]\n",
      "  [0.45481235 0.23629692 0.30851227 0.00037844]\n",
      "  [0.         0.08967856 0.9103214  0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f4546fc88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3d062be0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f4445dac8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f4445dac8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_480 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1275 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1276 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1276 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1595 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_636 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1116 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1277 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1277 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1596 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_637 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1117 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1278 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1278 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1597 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_638 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1118 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1279 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1279 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1598 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_639 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1119 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_319 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_319 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1599 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.07918043 0.20152795 0.2360267  0.48326486]\n",
      "  [0.11279472 0.07081707 0.10077672 0.7156115 ]\n",
      "  [0.203387   0.05399923 0.07201947 0.6705943 ]\n",
      "  ...\n",
      "  [0.09408604 0.14829361 0.05741191 0.7002084 ]\n",
      "  [0.05875294 0.04873631 0.0592955  0.8332153 ]\n",
      "  [0.00000745 0.9999925  0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f43463b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3df2dac8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3dd69cf8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f3dd69cf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_483 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1283 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1284 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1284 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1605 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_640 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1123 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1285 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1285 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1606 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_641 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1124 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1286 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1286 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1607 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_642 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1125 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1287 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1287 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1608 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_643 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1126 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_321 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_321 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1609 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.17546035 0.04160653 0.4107389  0.3721942 ]\n",
      "  [0.76848024 0.04252268 0.04072671 0.14827038]\n",
      "  [0.7156685  0.07594782 0.19625644 0.01212719]\n",
      "  ...\n",
      "  [0.75698584 0.03078462 0.13119534 0.08103415]\n",
      "  [0.6314375  0.09960976 0.16560116 0.10335156]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f3eef5a58>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3b303dd8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3e8feb70>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f3e8feb70>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_486 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1291 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1292 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1292 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1615 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_644 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1130 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1293 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1293 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1616 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_645 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1131 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1294 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1294 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1617 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_646 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1132 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1295 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1295 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1618 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_647 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1133 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_323 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_323 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1619 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.9404122  0.01083135 0.03589188 0.01286458]\n",
      "  [0.6846715  0.03892691 0.02833883 0.24806269]\n",
      "  [0.95233107 0.01013639 0.00488499 0.03264757]\n",
      "  ...\n",
      "  [0.83838284 0.10994722 0.01559822 0.03607173]\n",
      "  [0.6680547  0.0540941  0.04122467 0.23662652]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f43d58b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f41a3a710>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3cc40a58>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f3cc40a58>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_489 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1299 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1300 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1300 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1625 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_648 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1137 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1301 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1301 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1626 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_649 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1138 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1302 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1302 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1627 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_650 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1139 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1303 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1303 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1628 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_651 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1140 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_325 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_325 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1629 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.03532745 0.00066049 0.96400726 0.00000478]\n",
      "  [0.13192622 0.00184905 0.8657991  0.00042559]\n",
      "  [0.04315855 0.00592518 0.95084333 0.0000729 ]\n",
      "  ...\n",
      "  [0.02675619 0.00026396 0.97297084 0.00000906]\n",
      "  [0.04485249 0.000215   0.9548704  0.00006219]\n",
      "  [0.         0.         0.00639907 0.9936009 ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f444b3cf8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3e6e5c18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3c970d68>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f3c970d68>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_492 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1307 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1308 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1308 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1635 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_652 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1144 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1309 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1309 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1636 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_653 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1145 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1310 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1310 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1637 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_654 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1146 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1311 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1311 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1638 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_655 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1147 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_327 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_327 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1639 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         1.         0.         0.        ]\n",
      "  [0.         0.99999523 0.         0.00000477]\n",
      "  [0.         1.         0.         0.        ]\n",
      "  ...\n",
      "  [0.00183888 0.9797102  0.00137775 0.01707322]\n",
      "  [0.00015432 0.99280554 0.00261154 0.00442864]\n",
      "  [0.         1.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f3db95b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3f3d1c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3c706d30>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f3c706d30>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_495 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1315 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1316 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1316 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1645 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_656 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1151 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1317 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1317 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1646 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_657 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1152 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1318 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1318 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1647 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_658 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1153 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1319 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1319 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1648 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_659 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1154 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_329 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_329 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1649 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.03220331 0.02169998 0.00952493 0.93657184]\n",
      "  [0.03916853 0.2879032  0.0398736  0.63305473]\n",
      "  [0.02439835 0.0202082  0.00702863 0.9483648 ]\n",
      "  ...\n",
      "  [0.2789786  0.22348656 0.06468365 0.43285123]\n",
      "  [0.37689146 0.07763315 0.01534125 0.53013414]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f3d391fd0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3bd66eb8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3a692ba8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f3a692ba8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_498 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1323 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1324 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1324 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1655 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_660 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1158 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1325 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1325 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1656 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_661 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1159 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1326 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1326 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1657 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_662 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1160 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1327 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1327 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1658 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_663 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1161 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_331 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_331 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1659 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.8025623  0.168661   0.02724899 0.00152781]\n",
      "  [0.08814417 0.03574293 0.8758537  0.00025922]\n",
      "  [0.40658408 0.32803196 0.23958892 0.02579504]\n",
      "  ...\n",
      "  [0.16734545 0.00029029 0.8277879  0.00457641]\n",
      "  [0.84890866 0.02506842 0.06988072 0.05614218]\n",
      "  [0.         0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f3e0bce80>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3d233d68>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f39e47fd0>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f39e47fd0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_501 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1331 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1332 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1332 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1665 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_664 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1165 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1333 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1333 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1666 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_665 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1166 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1334 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1334 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1667 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_666 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1167 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1335 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1335 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1668 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_667 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1168 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_333 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_333 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1669 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  ...\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.   1.   0.   0.  ]]\n",
      "\n",
      " [[0.   0.   0.   1.  ]\n",
      "  [0.   0.   0.   1.  ]\n",
      "  [0.   0.   0.   1.  ]\n",
      "  ...\n",
      "  [0.   0.   1.   0.  ]\n",
      "  [0.   0.   1.   0.  ]\n",
      "  [0.   0.   1.   0.  ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f3c8e9160>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3ddabba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f39dece80>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f39dece80>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_504 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1339 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1340 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1340 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1675 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_668 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1172 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1341 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1341 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1676 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_669 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1173 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1342 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1342 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1677 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_670 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1174 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1343 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1343 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1678 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_671 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1175 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_335 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_335 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1679 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.04763216 0.24275774 0.03847266 0.6711375 ]\n",
      "  [0.00716688 0.9271078  0.00042164 0.06530363]\n",
      "  [0.00017908 0.01228322 0.02558246 0.9619552 ]\n",
      "  ...\n",
      "  [0.05651438 0.57924116 0.09250943 0.27173504]\n",
      "  [0.01245899 0.65393513 0.04160811 0.29199773]\n",
      "  [0.31491536 0.0057468  0.6790152  0.00032257]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f3b860b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f380d9a20>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f39afbcc0>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f39afbcc0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_507 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1347 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1348 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1348 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1685 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_672 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1179 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1349 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1349 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1686 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_673 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1180 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1350 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1350 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1687 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_674 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1181 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1351 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1351 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1688 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_675 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1182 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_337 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_337 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1689 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.05069075 0.6257253  0.03043575 0.2931481 ]\n",
      "  [0.23007624 0.5196387  0.02513373 0.22515132]\n",
      "  [0.5364175  0.17510131 0.0216461  0.2668351 ]\n",
      "  ...\n",
      "  [0.2242216  0.33240926 0.12998022 0.31338885]\n",
      "  [0.13752143 0.37658843 0.32070252 0.16518767]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f3d47dd30>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f41c66c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f39135b38>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f41c66c88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_509 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1353 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1354 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1355 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1692 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_509 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1693 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1185 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_338 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_338 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1694 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         0.01488155 0.         0.9851185 ]\n",
      "  [0.         0.01488155 0.         0.9851185 ]\n",
      "  [0.         0.01488155 0.         0.9851185 ]\n",
      "  ...\n",
      "  [0.         0.01488155 0.         0.9851185 ]\n",
      "  [0.         0.01488155 0.         0.9851185 ]\n",
      "  [0.         0.00121597 0.         0.998784  ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f3c2e6ba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f399f4ac8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f38a319b0>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f399f4ac8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_512 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1361 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1362 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1363 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1702 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_512 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1703 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1192 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_340 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_340 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1704 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.0005203  0.9781004  0.01482109 0.0065582 ]\n",
      "  [0.00030359 0.9810121  0.00444311 0.01424114]\n",
      "  [0.00000162 0.9967217  0.0022368  0.0010398 ]\n",
      "  ...\n",
      "  [0.0015149  0.9729135  0.00352471 0.02204685]\n",
      "  [0.00784864 0.88855577 0.0176693  0.08592632]\n",
      "  [0.00000048 0.99960285 0.00039026 0.00000642]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f3e23bac8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f368b59e8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3734fbe0>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f368b59e8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_515 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1369 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1370 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1371 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1712 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_515 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1713 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1199 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_342 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_342 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1714 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00017147 0.76637566 0.20462032 0.02883249]\n",
      "  [0.00006678 0.75112545 0.16106223 0.08774557]\n",
      "  [0.0002589  0.71577257 0.25168735 0.03228128]\n",
      "  ...\n",
      "  [0.00004142 0.843329   0.02978697 0.1268426 ]\n",
      "  [0.00066563 0.73412764 0.08579122 0.17941543]\n",
      "  [0.         0.9970186  0.00285052 0.00013096]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f3a02fdd8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f387fe780>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f37220ac8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f387fe780>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_518 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1377 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1378 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1379 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1722 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_518 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1723 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1206 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_344 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_344 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1724 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00274365 0.04878831 0.10852758 0.8399405 ]\n",
      "  [0.00116186 0.01332093 0.06550607 0.9200111 ]\n",
      "  [0.01327643 0.10394137 0.2378984  0.6448838 ]\n",
      "  ...\n",
      "  [0.00609228 0.0875765  0.05214166 0.8541895 ]\n",
      "  [0.02748532 0.16287404 0.1289532  0.6806875 ]\n",
      "  [0.00000487 0.00045065 0.3019496  0.6975949 ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f40129d30>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f388b3c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f374e6dd8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f388b3c88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_521 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1385 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1386 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1387 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1732 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_521 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1733 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1213 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_346 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_346 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1734 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.5808159  0.00935296 0.34350404 0.06632712]\n",
      "  [0.20979275 0.00228689 0.6770743  0.11084604]\n",
      "  [0.762188   0.00109606 0.21557601 0.0211399 ]\n",
      "  ...\n",
      "  [0.67985076 0.00183038 0.26801196 0.05030686]\n",
      "  [0.7782284  0.00309717 0.1608719  0.05780251]\n",
      "  [0.9997484  0.         0.00024804 0.00000352]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f39fa5ba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f408d6c18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f360de710>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f408d6c18>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_524 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1393 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1394 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1395 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1742 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_524 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1743 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1220 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_348 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_348 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1744 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.08006724 0.4725231  0.00091122 0.44649845]\n",
      "  [0.14665431 0.48608878 0.00481499 0.36244196]\n",
      "  [0.01444567 0.503041   0.00092159 0.48159173]\n",
      "  ...\n",
      "  [0.06214026 0.58873886 0.00272163 0.34639925]\n",
      "  [0.02918905 0.6810473  0.00294423 0.28681946]\n",
      "  [0.00038692 0.0229389  0.         0.9766742 ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f3a8f3fd0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f40be6b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f365eec18>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f40be6b70>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_527 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1401 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1402 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1403 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1752 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_527 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1753 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1227 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_350 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_350 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1754 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.05983276 0.9390057  0.00091631 0.0002453 ]\n",
      "  [0.08141848 0.91842276 0.00008931 0.00006945]\n",
      "  [0.06776901 0.93115246 0.0005497  0.00052891]\n",
      "  ...\n",
      "  [0.31477612 0.68448925 0.00026058 0.00047402]\n",
      "  [0.0733305  0.92644477 0.00009977 0.000125  ]\n",
      "  [0.04908548 0.9504754  0.00027227 0.00016677]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f35059f60>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f38f8ae80>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f35e9bc88>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f38f8ae80>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_530 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1409 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1410 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1411 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1762 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_530 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1763 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1234 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_352 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_352 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1764 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.33212632 0.         0.6678737  0.        ]\n",
      "  [0.99735224 0.         0.0026478  0.        ]\n",
      "  [0.88718414 0.0000002  0.11281572 0.        ]\n",
      "  ...\n",
      "  [0.01880329 0.00014989 0.98104274 0.00000409]\n",
      "  [0.01935207 0.00012629 0.9805217  0.00000001]\n",
      "  [0.14893855 0.         0.85106146 0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f41539d30>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f37801c18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f339aef60>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f37801c18>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_533 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1417 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1418 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1419 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1772 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_533 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1773 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1241 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_354 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_354 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1774 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00149705 0.1647029  0.80866987 0.02513023]\n",
      "  [0.00125019 0.00408977 0.99397755 0.00068246]\n",
      "  [0.00227025 0.14214137 0.8345204  0.02106798]\n",
      "  ...\n",
      "  [0.28993955 0.03405207 0.6158717  0.06013659]\n",
      "  [0.00066273 0.00354717 0.9301584  0.06563167]\n",
      "  [0.         0.00000006 1.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f36889ba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f35c12a90>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3481ad30>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f35c12a90>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_536 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1425 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1426 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1427 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1782 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_536 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1783 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1248 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_356 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_356 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1784 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00096933 0.01537649 0.9835783  0.0000759 ]\n",
      "  [0.00036351 0.0048532  0.99475116 0.00003219]\n",
      "  [0.00080694 0.01294422 0.9861881  0.00006071]\n",
      "  ...\n",
      "  [0.00059015 0.0054263  0.9934409  0.00054262]\n",
      "  [0.00687442 0.0106524  0.9820362  0.000437  ]\n",
      "  [0.00000002 0.00124831 0.9987515  0.00000007]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f38f5f9e8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3cc1ecc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f32facba8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f3cc1ecc0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_539 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1433 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1434 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1435 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1792 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_539 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1793 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1255 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_358 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_358 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1794 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1.         0.         0.         0.        ]\n",
      "  [1.         0.         0.         0.        ]\n",
      "  [1.         0.         0.         0.        ]\n",
      "  ...\n",
      "  [1.         0.         0.         0.        ]\n",
      "  [1.         0.         0.         0.        ]\n",
      "  [0.         0.0000061  0.00007669 0.99991727]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f35794c50>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f33a31b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f33069a20>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f33a31b70>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_542 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1441 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1442 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1443 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1802 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_542 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1803 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1262 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_360 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_360 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1804 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00129558 0.01273353 0.98533916 0.00063176]\n",
      "  [0.00385754 0.00255988 0.9933355  0.00024713]\n",
      "  [0.01264326 0.08795852 0.8990302  0.00036808]\n",
      "  ...\n",
      "  [0.533268   0.20216677 0.17612362 0.0884416 ]\n",
      "  [0.00101158 0.00427152 0.98711514 0.00760182]\n",
      "  [0.09668598 0.03496484 0.86776435 0.00058478]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f389457f0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f340cba20>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f32727c50>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f340cba20>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_545 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1449 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1450 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1451 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_1812 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_545 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_1813 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1269 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_362 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_362 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_1814 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.01281708 0.00475888 0.00397672 0.9784474 ]\n",
      "  [0.00762834 0.00149763 0.01271049 0.97816354]\n",
      "  [0.03268286 0.00168308 0.00861566 0.95701844]\n",
      "  ...\n",
      "  [0.09912038 0.15790783 0.04248272 0.70048904]\n",
      "  [0.00412987 0.00046073 0.00010585 0.99530363]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f36781e48>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f32b15128>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f33f139b0>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f36781e48>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_547 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1456 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1456 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_182 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1457 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1820 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_546 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1274 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_182 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1458 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1821 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_547 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1275 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  ...\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.25       0.25       0.25       0.25      ]\n",
      "  [0.00033538 0.         0.99966466 0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f33df2b38>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f33b06a90>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f30711cc0>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f33df2b38>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_550 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1464 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1464 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_183 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1465 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1830 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_549 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1281 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_183 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1466 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1831 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_550 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1282 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.02802193 0.00526361 0.00636186 0.9603526 ]\n",
      "  [0.4976419  0.00269494 0.4351522  0.06451096]\n",
      "  [0.99996424 0.         0.0000029  0.00003282]\n",
      "  ...\n",
      "  [0.40472353 0.14690514 0.18317144 0.2651999 ]\n",
      "  [0.4285126  0.17898619 0.22764404 0.16485713]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f33512be0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2f9e7b38>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f30458710>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f33512be0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_553 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1472 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1472 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_184 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1473 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1840 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_552 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1288 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_184 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1474 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1841 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_553 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1289 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.6860813  0.19987021 0.10325104 0.01079747]\n",
      "  [0.62869453 0.174714   0.16667762 0.02991384]\n",
      "  [0.8461147  0.06212968 0.07925498 0.01250069]\n",
      "  ...\n",
      "  [0.7915055  0.13619539 0.06078524 0.01151383]\n",
      "  [0.6406613  0.20422141 0.13750891 0.01760835]\n",
      "  [0.15905815 0.8409419  0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f3441ec50>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f33343b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3139ceb8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f3441ec50>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_556 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1480 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1480 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_185 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1481 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1850 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_555 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1295 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_185 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1482 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1851 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_556 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1296 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.29925182 0.22055435 0.23641866 0.24377511]\n",
      "  [0.39444    0.14819044 0.2748894  0.18248014]\n",
      "  [0.28807586 0.2234975  0.19716296 0.2912637 ]\n",
      "  ...\n",
      "  [0.46784815 0.19784148 0.13206631 0.20224407]\n",
      "  [0.3017894  0.19029193 0.26308027 0.2448384 ]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f33077b00>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3f9b39e8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f300edc18>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f33077b00>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_559 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1488 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1488 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_186 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1489 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1860 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_558 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1302 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_186 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1490 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1861 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_559 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1303 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.23544234 0.43219662 0.21292059 0.11944047]\n",
      "  [0.19450307 0.30143252 0.21640897 0.28765544]\n",
      "  [0.22186968 0.32458758 0.25307983 0.20046295]\n",
      "  ...\n",
      "  [0.1803732  0.2578854  0.26069227 0.3010491 ]\n",
      "  [0.17071906 0.30014881 0.19897334 0.33015883]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f32304ba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f31734fd0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2d307cf8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f32304ba8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_562 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1496 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1496 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_187 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1497 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1870 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_561 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1309 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_187 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1498 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1871 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_562 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1310 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.59625995 0.05776799 0.24602292 0.09994911]\n",
      "  [0.39587706 0.10047079 0.23726496 0.26638725]\n",
      "  [0.44097012 0.12434608 0.2654834  0.16920038]\n",
      "  ...\n",
      "  [0.49070215 0.11163411 0.18250632 0.21515737]\n",
      "  [0.37793955 0.16485956 0.2514129  0.20578805]\n",
      "  [0.         0.         1.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f32d83be0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f31049a90>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2eeb3d30>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f32d83be0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_565 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1504 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1504 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_188 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1505 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1880 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_564 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1316 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_188 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1506 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1881 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_565 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1317 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.48289976 0.13888775 0.11204202 0.26617044]\n",
      "  [0.12558669 0.15642537 0.38684192 0.33114603]\n",
      "  [0.20632958 0.14483128 0.22177397 0.42706513]\n",
      "  ...\n",
      "  [0.27836454 0.1745002  0.20349738 0.3436379 ]\n",
      "  [0.2828045  0.20783408 0.22466843 0.284693  ]\n",
      "  [0.9999752  0.         0.00002478 0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f3ca60a58>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f33659e10>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2dc12b70>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f3ca60a58>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_568 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1512 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1512 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_189 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1513 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1890 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_567 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1323 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_189 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1514 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1891 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_568 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1324 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.6811057  0.         0.3188943  0.        ]\n",
      "  [1.         0.         0.         0.        ]\n",
      "  [1.         0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.3786126  0.08886743 0.17503309 0.35748687]\n",
      "  [0.8410579  0.00702255 0.09559508 0.0563245 ]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f3eb2ac88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f3adeec88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2e837c50>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f3eb2ac88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_571 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1520 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1520 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_190 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1521 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1900 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_570 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1330 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_190 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1522 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1901 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_571 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1331 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.13451195 0.35230845 0.33924684 0.17393276]\n",
      "  [0.16870722 0.12909546 0.16740496 0.5347923 ]\n",
      "  [0.393984   0.12582265 0.14048086 0.33971247]\n",
      "  ...\n",
      "  [0.31744826 0.2352588  0.239296   0.20799693]\n",
      "  [0.1644684  0.21583258 0.24943855 0.3702605 ]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f2fc29b00>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2f37ba20>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2d98dc88>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f2fc29b00>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_574 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1528 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1528 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_191 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1529 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1910 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_573 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1337 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_191 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1530 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1911 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_574 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1338 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.467306   0.0190596  0.481334   0.03230046]\n",
      "  [0.5458852  0.02595073 0.40985927 0.01830481]\n",
      "  [0.732105   0.06586161 0.18604349 0.01598986]\n",
      "  ...\n",
      "  [0.8353537  0.00561523 0.10659314 0.05243796]\n",
      "  [0.36518973 0.01406251 0.5993664  0.02138131]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f3365ae10>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f31addd68>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2cf7eac8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f3365ae10>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_577 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1536 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1536 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_192 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1537 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1920 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_576 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1344 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_192 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1538 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1921 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_577 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1345 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  ...\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.25 0.25 0.25 0.25]\n",
      "  [0.   1.   0.   0.  ]]\n",
      "\n",
      " [[0.   0.   0.   1.  ]\n",
      "  [0.   0.   0.   1.  ]\n",
      "  [0.   0.   0.   1.  ]\n",
      "  ...\n",
      "  [0.   0.   1.   0.  ]\n",
      "  [0.   0.   1.   0.  ]\n",
      "  [0.   0.   1.   0.  ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f2c81ffd0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2ea80eb8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2be19ba8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f2c81ffd0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_580 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1544 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1544 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_193 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1545 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1930 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_579 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1351 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_193 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1546 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1931 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_580 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1352 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.15057641 0.05430153 0.30815938 0.48696274]\n",
      "  [0.4325111  0.23993693 0.01710517 0.31044683]\n",
      "  [0.03606991 0.02670993 0.20611195 0.73110825]\n",
      "  ...\n",
      "  [0.27568316 0.20231041 0.30583403 0.21617235]\n",
      "  [0.11492018 0.04119885 0.19058412 0.6532968 ]\n",
      "  [0.9929183  0.         0.00708163 0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f312929e8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2d363cf8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2be66be0>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f312929e8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_583 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1552 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1552 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_194 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1553 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_1940 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_582 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1358 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_194 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1554 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_1941 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_583 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1359 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.20645636 0.3070963  0.18710658 0.2993408 ]\n",
      "  [0.31281167 0.29605994 0.12978582 0.26134259]\n",
      "  [0.3164334  0.34411865 0.18436404 0.1550839 ]\n",
      "  ...\n",
      "  [0.26406908 0.29749942 0.14151637 0.2969151 ]\n",
      "  [0.48215234 0.15510811 0.07432584 0.28841373]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f322b5da0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2e9c6748>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2b650a90>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f2b650a90>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_588 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1563 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1564 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1564 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1955 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_780 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1368 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1565 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1565 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1956 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_781 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1369 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1566 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1566 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1957 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_782 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1370 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1567 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1567 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1958 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_783 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1371 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_391 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_391 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1959 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.53375393 0.03483359 0.20902507 0.22238745]\n",
      "  [0.5342318  0.03488833 0.2077351  0.22314483]\n",
      "  [0.5351146  0.03494138 0.20859899 0.22134502]\n",
      "  ...\n",
      "  [0.5352861  0.03481714 0.20870742 0.22118933]\n",
      "  [0.5356743  0.03495033 0.20842527 0.22095011]\n",
      "  [0.83117396 0.0006293  0.14550601 0.0226908 ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f2ee5ef60>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2d57be80>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f32c12c88>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f32c12c88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_591 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1571 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1572 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1572 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1965 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_784 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1375 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1573 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1573 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1966 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_785 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1376 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1574 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1574 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1967 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_786 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1377 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1575 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1575 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1968 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_787 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1378 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_393 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_393 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1969 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f2cdadc50>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2bce6ba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2f0cfa90>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f2f0cfa90>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_594 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1579 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1580 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1580 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1975 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_788 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1382 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1581 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1581 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1976 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_789 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1383 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1582 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1582 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1977 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_790 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1384 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1583 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1583 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1978 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_791 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1385 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_395 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_395 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1979 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f2c5b6cc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2b3b4be0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2ebbcb70>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f2ebbcb70>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_597 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1587 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1588 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1588 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1985 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_792 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1389 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1589 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1589 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1986 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_793 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1390 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1590 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1590 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1987 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_794 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1391 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1591 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1591 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1988 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_795 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1392 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_397 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_397 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1989 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f3c6deb38>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2c62abe0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f30f8dd30>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f30f8dd30>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_600 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1595 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1596 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1596 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_1995 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_796 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1396 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1597 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1597 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_1996 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_797 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1397 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1598 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1598 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_1997 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_798 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1398 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1599 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1599 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_1998 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_799 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1399 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_399 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_399 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_1999 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f2b2f1cf8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2a5a9be0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2caa0ef0>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f2caa0ef0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_603 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1603 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1604 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1604 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_2005 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_800 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1403 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1605 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1605 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_2006 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_801 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1404 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1606 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1606 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_2007 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_802 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1405 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1607 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1607 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_2008 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_803 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1406 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_401 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_401 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_2009 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f354d2b38>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f32bfaa58>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2b892cf8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f2b892cf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_606 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1611 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1612 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1612 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_2015 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_804 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1410 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1613 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1613 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_2016 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_805 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1411 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1614 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1614 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_2017 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_806 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1412 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1615 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1615 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_2018 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_807 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1413 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_403 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_403 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_2019 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f2a5c99b0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f28980c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2b1cbb70>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f2b1cbb70>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_609 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1619 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1620 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1620 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_2025 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_808 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1417 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1621 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1621 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_2026 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_809 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1418 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1622 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1622 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_2027 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_810 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1419 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1623 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1623 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_2028 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_811 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1420 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_405 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_405 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_2029 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f2fbbbbe0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2bbadb00>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2a5679e8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f2a5679e8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_612 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1627 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1628 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1628 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_2035 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_812 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1424 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1629 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1629 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_2036 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_813 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1425 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1630 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1630 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_2037 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_814 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1426 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1631 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1631 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_2038 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_815 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1427 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_407 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_407 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_2039 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f28d3c320>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2b985a20>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f29a10c18>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f29a10c18>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_615 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1635 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1636 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1636 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_2045 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_816 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1431 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1637 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1637 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_2046 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_817 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1432 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1638 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1638 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_2047 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_818 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1433 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1639 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1639 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_2048 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_819 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1434 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_409 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_409 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_2049 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1.         0.         0.         0.        ]\n",
      "  [1.         0.         0.         0.        ]\n",
      "  [1.         0.         0.         0.        ]\n",
      "  ...\n",
      "  [1.         0.         0.         0.        ]\n",
      "  [1.         0.         0.         0.        ]\n",
      "  [1.         0.00000001 0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f23ed1da0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2aa207b8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f29738b00>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f29738b00>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_618 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1643 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1644 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1644 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_2055 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_820 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1438 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1645 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1645 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_2056 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_821 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1439 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1646 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1646 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_2057 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_822 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1440 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1647 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1647 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_2058 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_823 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1441 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_411 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_411 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_2059 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.03275575 0.01794015 0.04960688 0.89969724]\n",
      "  [0.03251165 0.01772163 0.04932362 0.9004431 ]\n",
      "  [0.03168223 0.01785984 0.04926778 0.9011901 ]\n",
      "  ...\n",
      "  [0.03314372 0.0175981  0.05020452 0.89905363]\n",
      "  [0.03195265 0.01738325 0.04974878 0.9009153 ]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f2b960ba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f29e4ae48>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f28f0cc18>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f28f0cc18>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_621 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1651 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1652 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1652 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_2065 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_824 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1445 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1653 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1653 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_2066 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_825 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1446 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1654 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1654 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_2067 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_826 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1447 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1655 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1655 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_2068 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_827 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1448 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_413 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_413 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_2069 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Deep/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f2b4d46a0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f26fd6e10>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f28fdbba8>]\n",
      "flipChannels 2\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f28fdbba8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_624 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1659 (Conv2D)         (None, 25, 16, 621)       150       \n",
      "_________________________________________________________________\n",
      "conv2d_1660 (Conv2D)         (None, 25, 1, 621)        10025     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1660 (Ba (None, 25, 1, 621)        100       \n",
      "_________________________________________________________________\n",
      "activation_2075 (Activation) (None, 25, 1, 621)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_828 (MaxPoolin (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1452 (Dropout)       (None, 25, 1, 310)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1661 (Conv2D)         (None, 50, 1, 306)        6300      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1661 (Ba (None, 50, 1, 306)        200       \n",
      "_________________________________________________________________\n",
      "activation_2076 (Activation) (None, 50, 1, 306)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_829 (MaxPoolin (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1453 (Dropout)       (None, 50, 1, 153)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1662 (Conv2D)         (None, 100, 1, 149)       25100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1662 (Ba (None, 100, 1, 149)       400       \n",
      "_________________________________________________________________\n",
      "activation_2077 (Activation) (None, 100, 1, 149)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_830 (MaxPoolin (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1454 (Dropout)       (None, 100, 1, 74)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1663 (Conv2D)         (None, 200, 1, 70)        100200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1663 (Ba (None, 200, 1, 70)        800       \n",
      "_________________________________________________________________\n",
      "activation_2078 (Activation) (None, 200, 1, 70)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_831 (MaxPoolin (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1455 (Dropout)       (None, 200, 1, 35)        0         \n",
      "_________________________________________________________________\n",
      "flatten_415 (Flatten)        (None, 7000)              0         \n",
      "_________________________________________________________________\n",
      "dense_415 (Dense)            (None, 4)                 28004     \n",
      "_________________________________________________________________\n",
      "activation_2079 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 171,279\n",
      "Trainable params: 170,529\n",
      "Non-trainable params: 750\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f2a96eda0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2a313710>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f28727ac8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f2a313710>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_626 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1665 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1666 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1667 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_2082 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_626 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_2083 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1458 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_416 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_416 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_2084 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.02504744 0.7299447  0.23147646 0.01353138]\n",
      "  [0.02511141 0.73564094 0.2254862  0.01376139]\n",
      "  [0.0247419  0.7306073  0.23097678 0.01367399]\n",
      "  ...\n",
      "  [0.02507639 0.7297937  0.2311056  0.01402429]\n",
      "  [0.02484149 0.7346882  0.22729471 0.01317554]\n",
      "  [0.04091513 0.6003983  0.34173563 0.01695094]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f21d0bba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f28d56ef0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f265e8b38>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f28d56ef0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_629 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1673 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1674 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1675 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_2092 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_629 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_2093 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1465 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_418 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_418 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_2094 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         0.00000001 0.99999726 0.00000274]\n",
      "  [0.         0.00000002 0.9999969  0.00000306]\n",
      "  [0.         0.00000001 0.9999982  0.00000173]\n",
      "  ...\n",
      "  [0.         0.00000002 0.999997   0.00000296]\n",
      "  [0.         0.00000002 0.99999726 0.00000279]\n",
      "  [0.         0.00000001 0.999997   0.00000297]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f2ad4c9b0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f28cd9cf8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f26cd7ba8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f28cd9cf8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_632 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1681 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1682 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1683 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_2102 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_632 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_2103 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1472 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_420 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_420 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_2104 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00000002 0.         0.99998367 0.00001631]\n",
      "  [0.00000002 0.         0.99998415 0.00001581]\n",
      "  [0.00000002 0.         0.9999845  0.00001552]\n",
      "  ...\n",
      "  [0.00000002 0.         0.99998426 0.00001571]\n",
      "  [0.00000002 0.         0.9999851  0.00001493]\n",
      "  [0.00000002 0.         0.9999732  0.00002677]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f2a8dfb70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f299ab710>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f26723a20>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f299ab710>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_635 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1689 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1690 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1691 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_2112 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_635 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_2113 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1479 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_422 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_422 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_2114 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         0.9999994  0.00000058 0.00000001]\n",
      "  [0.         0.9999994  0.00000058 0.00000001]\n",
      "  [0.         0.9999994  0.00000058 0.00000001]\n",
      "  ...\n",
      "  [0.         0.9999994  0.00000061 0.00000002]\n",
      "  [0.         0.9999994  0.0000006  0.00000001]\n",
      "  [0.         0.9999995  0.00000048 0.00000002]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f27db1ef0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f293f5e80>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f26194c88>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f293f5e80>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_638 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1697 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1698 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1699 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_2122 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_638 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_2123 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1486 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_424 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_424 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_2124 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         0.23341098 0.7441318  0.02245727]\n",
      "  [0.         0.23341098 0.7441318  0.02245727]\n",
      "  [0.         0.23341098 0.7441318  0.02245727]\n",
      "  ...\n",
      "  [0.         0.21099314 0.77075106 0.01825581]\n",
      "  [0.         0.22815542 0.75474006 0.01710457]\n",
      "  [0.         0.22524579 0.7516158  0.02313834]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f29424cf8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f28557c18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f24e5bac8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f28557c18>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_641 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1705 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1706 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1707 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_2132 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_641 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_2133 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1493 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_426 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_426 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_2134 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.99998796 0.         0.         0.00001203]\n",
      "  [0.9999882  0.         0.         0.00001184]\n",
      "  [0.9999882  0.         0.         0.00001182]\n",
      "  ...\n",
      "  [0.99998677 0.         0.         0.00001324]\n",
      "  [0.9999827  0.         0.         0.00001729]\n",
      "  [0.99998724 0.         0.         0.00001281]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f253be748>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f27b61cc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f249e6e10>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f27b61cc0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_644 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1713 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1714 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1715 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_2142 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_644 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_2143 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1500 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_428 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_428 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_2144 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.11207075 0.         0.00003179 0.8878975 ]\n",
      "  [0.11212396 0.         0.00003126 0.8878448 ]\n",
      "  [0.11029965 0.         0.00003171 0.88966864]\n",
      "  ...\n",
      "  [0.11112502 0.         0.00002866 0.88884634]\n",
      "  [0.11397061 0.         0.00002939 0.8860001 ]\n",
      "  [0.11471952 0.         0.0000304  0.88525003]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f27777c18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2852ab38>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f23c72748>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f2852ab38>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_647 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1721 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1722 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1723 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_2152 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_647 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_2153 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1507 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_430 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_430 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_2154 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f28836cc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f27973be0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2341fef0>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f27973be0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_650 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1729 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1730 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1731 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_2162 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_650 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_2163 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1514 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_432 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_432 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_2164 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         1.         0.         0.        ]\n",
      "  [0.         1.         0.         0.        ]\n",
      "  [0.         1.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         1.         0.00000001 0.        ]\n",
      "  [0.         1.         0.         0.        ]\n",
      "  [0.         1.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f27157b00>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f203b8a58>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f23107cf8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f203b8a58>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_653 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1737 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1738 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1739 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_2172 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_653 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_2173 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1521 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_434 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_434 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_2174 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f27f809b0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f250ebc88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f233afb70>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f250ebc88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_656 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1745 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1746 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1747 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_2182 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_656 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_2183 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1528 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_436 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_436 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_2184 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00124045 0.9959181  0.00284143 0.0000001 ]\n",
      "  [0.0011291  0.99690527 0.00196556 0.0000001 ]\n",
      "  [0.00102459 0.996799   0.00217634 0.00000009]\n",
      "  ...\n",
      "  [0.00099655 0.9966685  0.0023348  0.00000009]\n",
      "  [0.00089586 0.9969512  0.00215281 0.00000007]\n",
      "  [0.         1.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f22051ba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f23dacb00>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f226e79e8>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f23dacb00>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_659 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1753 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1754 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1755 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_2192 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_659 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_2193 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1535 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_438 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_438 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_2194 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.00000003 0.8248379  0.17514037 0.00002169]\n",
      "  [0.00000003 0.77643836 0.22353512 0.00002656]\n",
      "  [0.00000003 0.74775267 0.25222155 0.00002575]\n",
      "  ...\n",
      "  [0.00000014 0.96513045 0.03483401 0.00003542]\n",
      "  [0.00000011 0.9682949  0.03166953 0.00003541]\n",
      "  [0.00000007 0.97400075 0.0259786  0.00002055]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/Shallow/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f271d9c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f22cefbe0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f222b1b70>]\n",
      "flipChannels 1\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f22cefbe0>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_662 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1761 (Conv2D)         (None, 40, 16, 613)       560       \n",
      "_________________________________________________________________\n",
      "conv2d_1762 (Conv2D)         (None, 40, 1, 613)        25600     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1763 (Ba (None, 40, 1, 613)        160       \n",
      "_________________________________________________________________\n",
      "activation_2202 (Activation) (None, 40, 1, 613)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_662 (Avera (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "activation_2203 (Activation) (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1542 (Dropout)       (None, 40, 1, 83)         0         \n",
      "_________________________________________________________________\n",
      "flatten_440 (Flatten)        (None, 3320)              0         \n",
      "_________________________________________________________________\n",
      "dense_440 (Dense)            (None, 4)                 13284     \n",
      "_________________________________________________________________\n",
      "activation_2204 (Activation) (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 39,604\n",
      "Trainable params: 39,524\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f263ccd30>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f244bac18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f22c2cf60>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f263ccd30>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_664 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1768 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1768 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_221 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1769 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_2210 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_663 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1547 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_221 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1770 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_2211 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_664 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1548 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.10691167 0.05994447 0.27697945 0.5561643 ]\n",
      "  [0.10699555 0.05989176 0.276684   0.55642873]\n",
      "  [0.10660689 0.05980913 0.27633402 0.55724996]\n",
      "  ...\n",
      "  [0.10675842 0.06007228 0.2771657  0.5560036 ]\n",
      "  [0.10666022 0.05987709 0.27714556 0.55631715]\n",
      "  [0.00083596 0.         0.9991641  0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-06_12-08-05-THREE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-06_12-08-05-THREE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11303\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11301\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f1fb8fb00>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f22368ac8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f209dbcf8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f1fb8fb00>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_667 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1776 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1776 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_222 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1777 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_2220 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_666 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1554 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_222 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1778 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_2221 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_667 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1555 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         1.         0.         0.        ]\n",
      "  [0.         1.         0.         0.        ]\n",
      "  [0.         0.9999423  0.         0.00005764]\n",
      "  ...\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         1.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-07_10-42-36-FOUR.2-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_10-42-36-FOUR.2\n",
      "sync baseline 0\n",
      "baseline stressor 15062\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25047\n",
      "stressor paced 11301\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f2434bc18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f22a4fb70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1fd7c748>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f2434bc18>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_670 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1784 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1784 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_223 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1785 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_2230 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_669 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1561 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_223 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1786 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_2231 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_670 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1562 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         0.         0.00016431 0.9998356 ]\n",
      "  [0.         0.         0.00003149 0.9999685 ]\n",
      "  [0.         0.         0.00000596 0.99999404]\n",
      "  ...\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-07_11-12-39-FIVE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_11-12-39-FIVE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25074\n",
      "stressor paced 11263\n",
      "paced stressor 25054\n",
      "stressor slowBreath 11275\n",
      "slowBreath stressor 25041\n",
      "stressor paced 11194\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f1ec1ac88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2116ebe0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f201a4ef0>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f1ec1ac88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_673 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1792 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1792 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_224 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1793 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_2240 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_672 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1568 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_224 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1794 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_2241 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_673 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1569 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-07_12-09-54-SIX-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-07_12-09-54-SIX\n",
      "sync baseline 0\n",
      "baseline stressor 15040\n",
      "stressor slowBreath 11326\n",
      "slowBreath stressor 25023\n",
      "stressor paced 11242\n",
      "paced stressor 25068\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25008\n",
      "stressor paced 11273\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f253edba8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1c280a90>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1ea92cf8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f253edba8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_676 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1800 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1800 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_225 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1801 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_2250 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_675 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1575 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_225 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1802 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_2251 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_676 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1576 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.00008329 0.9998977  0.00001898]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-10_10-55-19=ONE.2-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-10_10-55-19=ONE.2\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11309\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f19935d68>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1fcf8c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1e57db70>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f19935d68>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_679 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1808 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1808 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_226 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1809 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_2260 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_678 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1582 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_226 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1810 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_2261 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_679 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1583 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-14_11-09-00-SEVEN-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-09-00-SEVEN\n",
      "sync baseline 0\n",
      "baseline stressor 15027\n",
      "stressor slowBreath 11272\n",
      "slowBreath stressor 25044\n",
      "stressor paced 11272\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11268\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11236\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f21341c50>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f187c9b00>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1d9bc9e8>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f21341c50>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_682 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1816 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1816 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_227 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1817 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_2270 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_681 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1589 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_227 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1818 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_2271 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_682 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1590 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-14_11-43-46-EIGHT-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-14_11-43-46-EIGHT\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25084\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f1e0ccb00>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1b1f1a20>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1d3a9c18>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f1e0ccb00>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_685 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1824 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1824 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_228 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1825 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_2280 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_684 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1596 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_228 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1826 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_2281 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_685 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1597 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-23_16-49-310-VIR-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_16-49-310-VIR\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11269\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11256\n",
      "paced stressor 25036\n",
      "stressor slowBreath 11226\n",
      "slowBreath stressor 25068\n",
      "stressor paced 11291\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f2014ae10>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f2082ab70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1c621b00>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f2014ae10>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_688 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1832 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1832 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_229 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1833 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_2290 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_687 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1603 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_229 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1834 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_2291 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_688 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1604 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 1. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-23_18-14-52-ISH-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-23_18-14-52-ISH\n",
      "sync baseline 0\n",
      "baseline stressor 15029\n",
      "stressor slowBreath 11285\n",
      "slowBreath stressor 25058\n",
      "stressor paced 11273\n",
      "paced stressor 25070\n",
      "stressor slowBreath 11284\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11295\n",
      "uniform is 625\n",
      "224 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "x shape is (224, 1, 16, 625)\n",
      "y shape is (224, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f1c6ba710>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1d644cc0>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1deb5e10>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f1c6ba710>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_691 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1840 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1840 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_230 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1841 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_2300 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_690 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1610 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_230 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1842 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_2301 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_691 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1611 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-29_17-19-28-ELI-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-19-28-ELI\n",
      "sync baseline 0\n",
      "baseline stressor 15031\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11247\n",
      "paced stressor 25027\n",
      "stressor slowBreath 11301\n",
      "slowBreath stressor 25075\n",
      "stressor paced 11271\n",
      "uniform is 625\n",
      "223 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "x shape is (223, 1, 16, 625)\n",
      "y shape is (223, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f213c6c50>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1a0b5b70>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1b867748>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f213c6c50>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_694 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1848 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1848 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_231 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1849 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_2310 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_693 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1617 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_231 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1850 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_2311 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_694 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1618 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.06451948 0.43286425 0.12919949 0.3734167 ]\n",
      "  [0.06442288 0.43335542 0.12965496 0.37256676]\n",
      "  [0.06453144 0.43311152 0.12919897 0.37315807]\n",
      "  ...\n",
      "  [0.06441462 0.43242165 0.12941921 0.3737446 ]\n",
      "  [0.06453919 0.43298662 0.12894969 0.3735246 ]\n",
      "  [0.         1.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-02-29_17-51-57-BAHAR-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-02-29_17-51-57-BAHAR\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25083\n",
      "stressor paced 11305\n",
      "paced stressor 25055\n",
      "stressor slowBreath 11244\n",
      "slowBreath stressor 25071\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f1a15dc88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1f218c88>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1acb2c50>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f1a15dc88>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_697 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1856 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1856 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_232 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1857 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_2320 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_696 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1624 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_232 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1858 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_2321 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_697 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1625 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  ...\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]\n",
      "  [1. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  [0. 0. 0. 1.]\n",
      "  ...\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]\n",
      "  [0. 0. 1. 0.]]]\n",
      "model is /home/sean/pench/models-eegLib-high/EEGNet/OpenBCISession_2020-03-06_10-28-17-LUKE-2000ep.h5\n",
      "data is /home/sean/pench/pickled-avg/OpenBCISession_2020-03-06_10-28-17-LUKE\n",
      "sync baseline 0\n",
      "baseline stressor 15030\n",
      "stressor slowBreath 11302\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11241\n",
      "paced stressor 25015\n",
      "stressor slowBreath 11242\n",
      "slowBreath stressor 25066\n",
      "stressor paced 11302\n",
      "uniform is 625\n",
      "222 1\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 1, 16, 625)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f1df7ceb8>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f19c73e48>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1ab0dbe0>]\n",
      "flipChannels 0\n",
      "<tensorflow.python.keras.engine.training.Model object at 0x7f4f1df7ceb8>\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_700 (InputLayer)       (None, 1, 16, 625)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1864 (Conv2D)         (None, 8, 16, 625)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1864 (Ba (None, 8, 16, 625)        32        \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_233 (Depthw (None, 16, 1, 625)        256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1865 (Ba (None, 16, 1, 625)        64        \n",
      "_________________________________________________________________\n",
      "activation_2330 (Activation) (None, 16, 1, 625)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_699 (Avera (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1631 (Dropout)       (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "separable_conv2d_233 (Separa (None, 16, 1, 156)        512       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1866 (Ba (None, 16, 1, 156)        64        \n",
      "_________________________________________________________________\n",
      "activation_2331 (Activation) (None, 16, 1, 156)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_700 (Avera (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1632 (Dropout)       (None, 16, 1, 19)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 304)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4)                 1220      \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 4)                 0         \n",
      "=================================================================\n",
      "Total params: 2,660\n",
      "Trainable params: 2,580\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "None\n",
      "results [[[0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  ...\n",
      "  [0.         0.00033666 0.99966335 0.        ]\n",
      "  [0.         0.00073585 0.9992642  0.        ]\n",
      "  [1.         0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.        ]\n",
      "  ...\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.        ]]]\n",
      "model is /home/sean/pench/models-filt-double-lstm/OpenBCISession_2020-02-06_11-26-48-TWO-2000ep.h5\n",
      "data is /home/sean/pench/pickled-filt/OpenBCISession_2020-02-06_11-26-48-TWO\n",
      "sync baseline 0\n",
      "baseline stressor 15088\n",
      "stressor slowBreath 11243\n",
      "slowBreath stressor 25069\n",
      "stressor paced 11302\n",
      "paced stressor 25071\n",
      "stressor slowBreath 11303\n",
      "slowBreath stressor 25070\n",
      "stressor paced 11243\n",
      "uniform is 625\n",
      "222 625\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "x shape is (222, 625, 16)\n",
      "y shape is (222, 4)\n",
      "[<tensorflow.python.keras.engine.training.Model object at 0x7f4f1de56d30>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1cfb0c18>, <tensorflow.python.keras.engine.training.Model object at 0x7f4f1a698b00>]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unexpected keyword argument passed to optimizer: learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1e93937133d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     file =arr[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmaster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-765d0c806752>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0myhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    243\u001b[0m       \u001b[0moptimizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'optimizer_config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m       optimizer = optimizers.deserialize(\n\u001b[0;32m--> 245\u001b[0;31m           optimizer_config, custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;31m# Recover loss functions and metrics.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    795\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m       printable_module_name='optimizer')\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 list(custom_objects.items())))\n\u001b[1;32m    174\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m    147\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, lr, beta_1, beta_2, epsilon, decay, amsgrad, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m                \u001b[0mamsgrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                **kwargs):\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'iterations'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/py35/lib/python3.5/site-packages/tensorflow/python/keras/optimizers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         raise TypeError('Unexpected keyword argument '\n\u001b[0;32m---> 58\u001b[0;31m                         'passed to optimizer: ' + str(k))\n\u001b[0m\u001b[1;32m     59\u001b[0m       \u001b[0;31m# checks that clipnorm >= 0 and clipvalue >= 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Unexpected keyword argument passed to optimizer: learning_rate"
     ]
    }
   ],
   "source": [
    "master=[]\n",
    "\n",
    "for file in arr:\n",
    "#     file =arr[0]\n",
    "    master.append(predict(file))\n",
    "print(len(master))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tim={\n",
    "    0:'paced',\n",
    "    1:'slowBreath',\n",
    "    2:'stressor',\n",
    "    3:'baseline'\n",
    "}\n",
    "opp={\n",
    "    'paced':0,\n",
    "    'slowBreath':1,\n",
    "    'stressor':2,\n",
    "    'baseline':3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfusionMatrixPic():\n",
    "    f = open('confused.csv', 'r')\n",
    "    out=f.readline()[:-1]\n",
    "    arr=[[], [], [], []]\n",
    "    while len(out)!=0:\n",
    "        name=out.split(',')[1]\n",
    "        arr[0]=[int(x) for x in out.split(',')[3:]]\n",
    "        out=f.readline()[:-1]\n",
    "        arr[1]=[int(x) for x in out.split(',')[3:]]\n",
    "        out=f.readline()[:-1]\n",
    "        arr[2]=[int(x) for x in out.split(',')[3:]]\n",
    "        out=f.readline()[:-1]\n",
    "        arr[3]=[int(x) for x in out.split(',')[3:]]\n",
    "        out=f.readline()[:-1]\n",
    "#         print(arr)\n",
    "    #     arr = sklearn.metrics.confusion_matrix(argmax(res[2][1], axis=1), argmax(res[2][0], axis=1))\n",
    "        df=pd.DataFrame(arr)\n",
    "        su=df.sum()\n",
    "        print(su)\n",
    "        df = df.divide(su)\n",
    "        df = df.mul(100)\n",
    "        print(df)\n",
    "        plt.figure(figsize=(25,25), dpi=250)\n",
    "#         cmap = sns.light_palette(\"#2ecc71\", as_cmap=True)\n",
    "        cmap=sns.cubehelix_palette(8, as_cmap=True)\n",
    "\n",
    "        sn.set(font_scale=1.4) # for label size\n",
    "        \n",
    "        ax=sn.heatmap(df, annot=True, cmap=cmap, linewidths=3, linecolor='black', square=True, annot_kws={\"size\": 16}, xticklabels=False, yticklabels=False) # font size\n",
    "        for t in ax.texts: t.set_text(t.get_text() + \"%\")\n",
    "        plt.savefig('./confused-pics/' + name + '.png', transparent=True)\n",
    "        out=f.readline()[:-1]\n",
    "        \n",
    "#         print(len(out))\n",
    "        break\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getConfusionMatrix(res):\n",
    "    isFiltered=res[0].find('pickled-filt')!=-1\n",
    "#     print(res[0],res[0].find('pickled-filt') )\n",
    "    if len(res[1].split('/'))==6:\n",
    "        modelName=res[1].split('/')[4]\n",
    "    else:\n",
    "        modelName=res[1].split('/')[4]+'/'+res[1].split('/')[5]\n",
    "    cols=[modelName, res[1].split('/')[-1], isFiltered]\n",
    "    confused=sklearn.metrics.confusion_matrix(argmax(res[2][1], axis=1), argmax(res[2][0], axis=1))\n",
    "    cols=','.join(str(x) for x in cols)\n",
    "#     print(','.join(str(x) for x in list(confused[0]))+'\\n')\n",
    "    cols=cols+', '+','.join(str(x) for x in list(confused[0]))+'\\n'\n",
    "    cols=cols+',,,'+','.join(str(x) for x in confused[1])+'\\n'\n",
    "    cols=cols+',,,'+','.join(str(x) for x in confused[2])+'\\n'\n",
    "    cols=cols+',,,'+','.join(str(x) for x in confused[3])+'\\n'\n",
    "    return cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(res):\n",
    "    correct=0\n",
    "    wrong=0\n",
    "    for i in range(len(res[2][0])):\n",
    "        pred=argmax(res[2][0][i])\n",
    "        actual=argmax(res[2][1][i])\n",
    "        if pred==actual:\n",
    "            correct+=1\n",
    "        else:\n",
    "            wrong+=1\n",
    "    return [correct/(correct+wrong), correct, wrong]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def falsePred(res):\n",
    "    wrongs=[0, 0, 0, 0]\n",
    "    for i in range(len(res[2][0])):\n",
    "        pred=argmax(res[2][0][i])\n",
    "        actual=argmax(res[2][1][i])\n",
    "        if pred!=actual:\n",
    "            wrongs[pred]+=1\n",
    "    return wrongs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sdPred(res):\n",
    "    return np.std(res[2][0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uni(res):\n",
    "    return np.unique(res[2][0], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDist(res):\n",
    "    data=pickle.load(open(res[0], 'rb'))\n",
    "    clas=[0, 0, 0, 0]\n",
    "    for i in range(len(data)):\n",
    "        if data[i][20] in list(opp.keys()):\n",
    "            clas[opp[data[i][20]]]+=1\n",
    "    return clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cols: modelName, participant, isFiltered, Accuracy, correct, wrong, False paced, False slowBreath, False stressor, False baseline, SD paced, SD slowBreath, SD stressor, SD baseline, Predictions, Unique Predictions, Paced Samples, slowBreath Samples, Stressor Samples, Baseline Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllMetrics(res):\n",
    "    isFiltered=res[0].find('pickled-filt')!=-1\n",
    "#     print(res[0],res[0].find('pickled-filt') )\n",
    "    if len(res[1].split('/'))==6:\n",
    "        modelName=res[1].split('/')[4]\n",
    "    else:\n",
    "        modelName=res[1].split('/')[4]+'/'+res[1].split('/')[5]\n",
    "    cols=[modelName, res[1].split('/')[-1], isFiltered]\n",
    "    cols=cols+getAccuracy(res)\n",
    "    cols=cols+falsePred(res)\n",
    "    cols=cols+list(sdPred(res))\n",
    "    cols=cols+[len(res[2][0]), len(uni(res))]\n",
    "    cols=cols+getDist(res)\n",
    "    return ','.join(str(x) for x in cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b624e7d74f51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetAllMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "getAllMetrics(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = Pool(20)\n",
    "end=p.map(getAllMetrics, master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('validationCNN.csv', 'w')\n",
    "f.write('modelName, participant, isFiltered, Accuracy, correct, wrong, False paced, False slowBreath, False stressor, False baseline, SD paced, SD slowBreath, SD stressor, SD baseline, Predictions, Unique Predictions, Paced Samples, slowBreath Samples, Stressor Samples, Baseline Samples\\n')\n",
    "for elem in end:\n",
    "    f.write(elem + '\\n')\n",
    "#     f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p = Pool(20)\n",
    "end=p.map(getConfusionMatrix, master)\n",
    "\n",
    "f = open('confusedCNN.csv', 'w')\n",
    "# f.write('modelName, participant, isFiltered, Accuracy, correct, wrong, False paced, False slowBreath, False stressor, False baseline, SD paced, SD slowBreath, SD stressor, SD baseline, Predictions, Unique Predictions, Paced Samples, slowBreath Samples, Stressor Samples, Baseline Samples\\n')\n",
    "for elem in end:\n",
    "    f.write(elem + '\\n')\n",
    "#     f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication needed\n",
      "Go to the following url in your browser:\n",
      "https://accounts.google.com/o/oauth2/auth?access_type=offline&client_id=367116221053-7n0vf5akeru7on6o2fjinrecpdoe99eg.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&response_type=code&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&state=state\n",
      "\n",
      "Enter verification code: "
     ]
    }
   ],
   "source": [
    "!~/gdrive-linux-x64 upload --parent 1vhs7zre7sOnRuWLeVT_sL7SMQpfFnrkx ~/pench/validationCNN.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    40\n",
      "1    88\n",
      "2    70\n",
      "3    26\n",
      "dtype: int64\n",
      "      0          1          2          3\n",
      "0  85.0   3.409091   2.857143   7.692308\n",
      "1   0.0  86.363636   4.285714  11.538462\n",
      "2  15.0   6.818182  90.000000   3.846154\n",
      "3   0.0   3.409091   2.857143  76.923077\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 6250x6250 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "getConfusionMatrixPic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!~/gdrive-linux-x64 upload -r --parent 1vhs7zre7sOnRuWLeVT_sL7SMQpfFnrkx ~/pench/confused-pics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oldTF",
   "language": "python",
   "name": "oldtf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
