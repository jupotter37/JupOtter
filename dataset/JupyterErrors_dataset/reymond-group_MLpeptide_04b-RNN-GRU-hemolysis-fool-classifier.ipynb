{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 8 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=False)\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, matthews_corrcoef, f1_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "folder = \"/data/AIpep-clean/\"\n",
    "import matplotlib.pyplot as plt\n",
    "from vocabulary import Vocabulary\n",
    "from datasethem import Dataset, collate_fn\n",
    "from models import Classifier\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(folder + \"pickles/DAASP_RNN_dataset_with_hemolysis.plk\")\n",
    "df = df.query(\"isNotHemolytic==1 or isNotHemolytic==0\").copy()\n",
    "df_training = df[df[\"Set\"]==\"training\"]\n",
    "df_test = df[df[\"Set\"]==\"test\"]\n",
    "\n",
    "df_training_fool = df_training.copy()\n",
    "isNotHemolytic = df_training_fool.isNotHemolytic.tolist()\n",
    "random.shuffle(isNotHemolytic)\n",
    "df_training_fool[\"isNotHemolytic\"] = isNotHemolytic\n",
    "\n",
    "df_test_fool = df_test.copy()\n",
    "isNotHemolytic = df_test_fool.isNotHemolytic.tolist()\n",
    "random.shuffle(isNotHemolytic)\n",
    "df_test_fool[\"isNotHemolytic\"] = isNotHemolytic\n",
    "\n",
    "df_training = df_training_fool\n",
    "df_test = df_test_fool\n",
    "\n",
    "vocabulary = Vocabulary.get_vocabulary_from_sequences(df_training.Sequence.values)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\" \n",
    "else:\n",
    "    device = \"cpu\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def categoryFromOutput(output):\n",
    "    top_n, top_i = output.topk(1)\n",
    "    category_i = top_i[0].item()\n",
    "    return category_i\n",
    "\n",
    "def nan_equal(a,b):\n",
    "    try:\n",
    "        np.testing.assert_equal(a,b)\n",
    "    except AssertionError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def models_are_equal(model1, model2):\n",
    "    model1.vocabulary == model2.vocabulary\n",
    "    model1.hidden_size == model2.hidden_size\n",
    "    for a,b in zip(model1.model.parameters(), model2.model.parameters()):\n",
    "        if nan_equal(a.detach().numpy(), b.detach().numpy()) == True:\n",
    "            print(\"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, test_dataloader, training_dataloader, n_epoch, optimizer, filename):\n",
    "    \n",
    "    roc_training = []\n",
    "    roc_test = []\n",
    "    \n",
    "    for e in range(1, n_epoch + 1):\n",
    "        for i_batch, sample_batched in enumerate(training_dataloader):\n",
    "            seq_batched = sample_batched[0][0].to(model.device, non_blocking=True)\n",
    "            seq_lengths = sample_batched[0][1].to(model.device, non_blocking=True)\n",
    "            cat_batched = sample_batched[1].to(model.device, non_blocking=True)\n",
    "\n",
    "            output = model.evaluate(seq_batched, seq_lengths)\n",
    "\n",
    "            loss = criterion(output, cat_batched)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()  \n",
    "            torch.nn.utils.clip_grad_value_(model.model.parameters(), 2)\n",
    "            optimizer.step()\n",
    "\n",
    "        model.save(filename.format(e))\n",
    "        \n",
    "        def _evaluate_ROC(data_loader):\n",
    "            cat_list = []\n",
    "            out_list = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for i_batch, sample_batched in enumerate(data_loader):    \n",
    "                    seq_batched = sample_batched[0][0].to(model.device, non_blocking=True)\n",
    "                    seq_lengths = sample_batched[0][1].to(model.device, non_blocking=True)\n",
    "                    \n",
    "                    cat_list += sample_batched[1].to(\"cpu\", non_blocking=True)\n",
    "                    out_list += torch.exp(model.evaluate(seq_batched, seq_lengths))[: ,1].to(\"cpu\", non_blocking=True)\n",
    "\n",
    "                cat_list = torch.stack(cat_list)\n",
    "                out_list = torch.stack(out_list)\n",
    "\n",
    "                roc = roc_auc_score(cat_list.cpu().numpy().astype(int), out_list.cpu().numpy())\n",
    "            return roc\n",
    "        \n",
    "        roc_tr = _evaluate_ROC(training_dataloader)\n",
    "        roc_te = _evaluate_ROC(test_dataloader)\n",
    "        roc_training.append(roc_tr)\n",
    "        roc_test.append(roc_te)\n",
    "        print(\"epoch: \" + str(e))\n",
    "        print(\"roc auc training: \" + str(roc_tr))\n",
    "        print(\"roc auc test: \" + str(roc_te))\n",
    "        if roc_training == 1.0:\n",
    "            break\n",
    "        \n",
    "    return model, optimizer, roc_training, roc_test\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "batch_size = 20\n",
    "n_epoch = 150\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameters optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions of embedding 2, dimensions of hidden 50, number of layers 1\n",
      "epoch: 1\n",
      "roc auc training: 0.5017243140743399\n",
      "roc auc test: 0.5077110291814261\n",
      "epoch: 2\n",
      "roc auc training: 0.49823544522896807\n",
      "roc auc test: 0.5097352401198183\n",
      "epoch: 3\n",
      "roc auc training: 0.5064164944955136\n",
      "roc auc test: 0.5309479843641334\n",
      "epoch: 4\n",
      "roc auc training: 0.5038289367308441\n",
      "roc auc test: 0.520564903846154\n",
      "epoch: 5\n",
      "roc auc training: 0.5069659384812608\n",
      "roc auc test: 0.5245668570326996\n",
      "epoch: 6\n",
      "roc auc training: 0.5079984729167291\n",
      "roc auc test: 0.5273267944075397\n",
      "epoch: 7\n",
      "roc auc training: 0.5063396367721401\n",
      "roc auc test: 0.5179244371436853\n",
      "epoch: 8\n",
      "roc auc training: 0.5078162641203271\n",
      "roc auc test: 0.5277442264953136\n",
      "epoch: 9\n",
      "roc auc training: 0.5079935093303376\n",
      "roc auc test: 0.531278002470272\n",
      "epoch: 10\n",
      "roc auc training: 0.5088072082308588\n",
      "roc auc test: 0.5320803942409895\n",
      "epoch: 11\n",
      "roc auc training: 0.5090869375273045\n",
      "roc auc test: 0.5200600961538462\n",
      "epoch: 12\n",
      "roc auc training: 0.5090314998353146\n",
      "roc auc test: 0.5195208518189884\n",
      "epoch: 13\n",
      "roc auc training: 0.5105600095728132\n",
      "roc auc test: 0.528885584786206\n",
      "epoch: 14\n",
      "roc auc training: 0.5109863798818309\n",
      "roc auc test: 0.5254855541598222\n",
      "epoch: 15\n",
      "roc auc training: 0.5088827225863172\n",
      "roc auc test: 0.529297061919801\n",
      "epoch: 16\n",
      "roc auc training: 0.5119792484283077\n",
      "roc auc test: 0.5229762956243584\n",
      "epoch: 17\n",
      "roc auc training: 0.5099796887944027\n",
      "roc auc test: 0.5189752633104648\n",
      "epoch: 18\n",
      "roc auc training: 0.5098886422023378\n",
      "roc auc test: 0.5255881436005659\n",
      "epoch: 19\n",
      "roc auc training: 0.5113290754257908\n",
      "roc auc test: 0.5188823374949272\n",
      "epoch: 20\n",
      "roc auc training: 0.5086525619422081\n",
      "roc auc test: 0.5228091952925449\n",
      "epoch: 21\n",
      "roc auc training: 0.5097206391803488\n",
      "roc auc test: 0.5204801074366292\n",
      "epoch: 22\n",
      "roc auc training: 0.5092133689159994\n",
      "roc auc test: 0.5287348071585798\n",
      "epoch: 23\n",
      "roc auc training: 0.5108460710010969\n",
      "roc auc test: 0.5237139423076923\n",
      "epoch: 24\n",
      "roc auc training: 0.5110524727460463\n",
      "roc auc test: 0.5147834887587652\n",
      "epoch: 25\n",
      "roc auc training: 0.5098636604086195\n",
      "roc auc test: 0.5240367237764766\n",
      "epoch: 26\n",
      "roc auc training: 0.5156268696900802\n",
      "roc auc test: 0.5191525504832998\n",
      "epoch: 27\n",
      "roc auc training: 0.5111430526694374\n",
      "roc auc test: 0.523657641670064\n",
      "epoch: 28\n",
      "roc auc training: 0.5082891676897126\n",
      "roc auc test: 0.5157211538461539\n",
      "epoch: 29\n",
      "roc auc training: 0.5114951702327717\n",
      "roc auc test: 0.5131173760473611\n",
      "epoch: 30\n",
      "roc auc training: 0.5122658379702257\n",
      "roc auc test: 0.5157311704469327\n",
      "epoch: 31\n",
      "roc auc training: 0.5104875658122813\n",
      "roc auc test: 0.5240849177088605\n",
      "epoch: 32\n",
      "roc auc training: 0.5129896665744706\n",
      "roc auc test: 0.5282091346153845\n",
      "epoch: 33\n",
      "roc auc training: 0.5143321752533352\n",
      "roc auc test: 0.5186298076923076\n",
      "epoch: 34\n",
      "roc auc training: 0.5103988881236838\n",
      "roc auc test: 0.51515625\n",
      "epoch: 35\n",
      "roc auc training: 0.5129727221007875\n",
      "roc auc test: 0.5234684510580732\n",
      "epoch: 36\n",
      "roc auc training: 0.5128417223103872\n",
      "roc auc test: 0.5163280895657778\n",
      "epoch: 37\n",
      "roc auc training: 0.5112792170236529\n",
      "roc auc test: 0.5180229643598864\n",
      "epoch: 38\n",
      "roc auc training: 0.5115454481939496\n",
      "roc auc test: 0.5169951923076924\n",
      "epoch: 39\n",
      "roc auc training: 0.5124134495641345\n",
      "roc auc test: 0.5200600961538462\n",
      "epoch: 40\n",
      "roc auc training: 0.5133956518377557\n",
      "roc auc test: 0.5207340891768293\n",
      "epoch: 41\n",
      "roc auc training: 0.5119758760766935\n",
      "roc auc test: 0.5264274922660016\n",
      "epoch: 42\n",
      "roc auc training: 0.5117533065137635\n",
      "roc auc test: 0.5146148099954215\n",
      "epoch: 43\n",
      "roc auc training: 0.5119024470503769\n",
      "roc auc test: 0.5211691847996338\n",
      "epoch: 44\n",
      "roc auc training: 0.511924883331339\n",
      "roc auc test: 0.5093934257955168\n",
      "epoch: 45\n",
      "roc auc training: 0.5150953607797463\n",
      "roc auc test: 0.5319803346976338\n",
      "epoch: 46\n",
      "roc auc training: 0.5110006893382353\n",
      "roc auc test: 0.517860576923077\n",
      "epoch: 47\n",
      "roc auc training: 0.5149152618498667\n",
      "roc auc test: 0.5175694063163926\n",
      "epoch: 48\n",
      "roc auc training: 0.511884166510641\n",
      "roc auc test: 0.517368827906078\n",
      "epoch: 49\n",
      "roc auc training: 0.510328902203083\n",
      "roc auc test: 0.5220269071200748\n",
      "epoch: 50\n",
      "roc auc training: 0.5117687020460358\n",
      "roc auc test: 0.5226815963250072\n",
      "epoch: 51\n",
      "roc auc training: 0.5109439192692752\n",
      "roc auc test: 0.5187980769230769\n",
      "epoch: 52\n",
      "roc auc training: 0.5121380662933797\n",
      "roc auc test: 0.5299310938845821\n",
      "epoch: 53\n",
      "roc auc training: 0.5117578576841769\n",
      "roc auc test: 0.5227703302237464\n",
      "epoch: 54\n",
      "roc auc training: 0.5138161112275553\n",
      "roc auc test: 0.5144989951191501\n",
      "epoch: 55\n",
      "roc auc training: 0.5122408972667483\n",
      "roc auc test: 0.5158413461538461\n",
      "epoch: 56\n",
      "roc auc training: 0.5135469948849105\n",
      "roc auc test: 0.5230048076923077\n",
      "epoch: 57\n",
      "roc auc training: 0.5126582593896626\n",
      "roc auc test: 0.5139039494927589\n",
      "epoch: 58\n",
      "roc auc training: 0.5103528860135029\n",
      "roc auc test: 0.5196887215520756\n",
      "epoch: 59\n",
      "roc auc training: 0.5098882855894652\n",
      "roc auc test: 0.5223378876599436\n",
      "epoch: 60\n",
      "roc auc training: 0.5135105785433439\n",
      "roc auc test: 0.5193717027523812\n",
      "epoch: 61\n",
      "roc auc training: 0.5140426189621474\n",
      "roc auc test: 0.5138972157605698\n",
      "epoch: 62\n",
      "roc auc training: 0.5118692807849339\n",
      "roc auc test: 0.511523058106909\n",
      "epoch: 63\n",
      "roc auc training: 0.5126686303313872\n",
      "roc auc test: 0.5194755478993205\n",
      "epoch: 64\n",
      "roc auc training: 0.5133308060087143\n",
      "roc auc test: 0.5218202698822852\n",
      "epoch: 65\n",
      "roc auc training: 0.5120863758347375\n",
      "roc auc test: 0.5174584522410609\n",
      "epoch: 66\n",
      "roc auc training: 0.5098873963106656\n",
      "roc auc test: 0.5215625\n",
      "epoch: 67\n",
      "roc auc training: 0.5137895290280301\n",
      "roc auc test: 0.5138769260216288\n",
      "epoch: 68\n",
      "roc auc training: 0.5157099169943207\n",
      "roc auc test: 0.5128959709063068\n",
      "epoch: 69\n",
      "roc auc training: 0.5135143231604569\n",
      "roc auc test: 0.5184945927839985\n",
      "epoch: 70\n",
      "roc auc training: 0.5132758930442853\n",
      "roc auc test: 0.516846926784815\n",
      "epoch: 71\n",
      "roc auc training: 0.5143475960914653\n",
      "roc auc test: 0.5238375020983717\n",
      "epoch: 72\n",
      "roc auc training: 0.5137127878674406\n",
      "roc auc test: 0.51890625\n",
      "epoch: 73\n",
      "roc auc training: 0.5110928040941147\n",
      "roc auc test: 0.520048076923077\n",
      "epoch: 74\n",
      "roc auc training: 0.5127067340697747\n",
      "roc auc test: 0.518485576923077\n",
      "epoch: 75\n",
      "roc auc training: 0.5120694473555509\n",
      "roc auc test: 0.5138096488505884\n",
      "epoch: 76\n",
      "roc auc training: 0.5132259883622281\n",
      "roc auc test: 0.516244539399871\n",
      "epoch: 77\n",
      "roc auc training: 0.5156303388693382\n",
      "roc auc test: 0.5199038461538461\n",
      "epoch: 78\n",
      "roc auc training: 0.5157823557006118\n",
      "roc auc test: 0.5141319137762287\n",
      "epoch: 79\n",
      "roc auc training: 0.5146826436996818\n",
      "roc auc test: 0.519738730979041\n",
      "epoch: 80\n",
      "roc auc training: 0.5153257278597878\n",
      "roc auc test: 0.5214753351399314\n",
      "epoch: 81\n",
      "roc auc training: 0.5159249873541996\n",
      "roc auc test: 0.5138732343701289\n",
      "epoch: 82\n",
      "roc auc training: 0.513162618164413\n",
      "roc auc test: 0.5199519230769231\n",
      "epoch: 83\n",
      "roc auc training: 0.513233861342224\n",
      "roc auc test: 0.5277163461538461\n",
      "epoch: 84\n",
      "roc auc training: 0.5136743726023018\n",
      "roc auc test: 0.5145192307692308\n",
      "epoch: 85\n",
      "roc auc training: 0.5162054546589278\n",
      "roc auc test: 0.5185855775917887\n",
      "epoch: 86\n",
      "roc auc training: 0.5169102015151061\n",
      "roc auc test: 0.5163542371243599\n",
      "epoch: 87\n",
      "roc auc training: 0.5127566622979467\n",
      "roc auc test: 0.5159254807692308\n",
      "epoch: 88\n",
      "roc auc training: 0.5145511746639544\n",
      "roc auc test: 0.5108495858298918\n",
      "epoch: 89\n",
      "roc auc training: 0.5157924534419418\n",
      "roc auc test: 0.5146904009953106\n",
      "epoch: 90\n",
      "roc auc training: 0.5142168698715984\n",
      "roc auc test: 0.5126682692307692\n",
      "epoch: 91\n",
      "roc auc training: 0.5150547445255474\n",
      "roc auc test: 0.5160075781193794\n",
      "epoch: 92\n",
      "roc auc training: 0.5167985421403215\n",
      "roc auc test: 0.5139886849203885\n",
      "epoch: 93\n",
      "roc auc training: 0.516638220997894\n",
      "roc auc test: 0.5238439480469409\n",
      "epoch: 94\n",
      "roc auc training: 0.5171168047965962\n",
      "roc auc test: 0.5135216346153846\n",
      "epoch: 95\n",
      "roc auc training: 0.5178592796458059\n",
      "roc auc test: 0.5198925633708242\n",
      "epoch: 96\n",
      "roc auc training: 0.5154577779771204\n",
      "roc auc test: 0.5126629557338731\n",
      "epoch: 97\n",
      "roc auc training: 0.5143762912836483\n",
      "roc auc test: 0.5225186149063833\n",
      "epoch: 98\n",
      "roc auc training: 0.5125931473506834\n",
      "roc auc test: 0.5121781988707053\n",
      "epoch: 99\n",
      "roc auc training: 0.5131578619502192\n",
      "roc auc test: 0.5201330152533796\n",
      "epoch: 100\n",
      "roc auc training: 0.5147331097603577\n",
      "roc auc test: 0.5174897119341564\n",
      "epoch: 101\n",
      "roc auc training: 0.5170045716309475\n",
      "roc auc test: 0.5225544977097772\n",
      "epoch: 102\n",
      "roc auc training: 0.5146202334144667\n",
      "roc auc test: 0.5042548076923077\n",
      "epoch: 103\n",
      "roc auc training: 0.5165878903912888\n",
      "roc auc test: 0.5231060696899206\n",
      "epoch: 104\n",
      "roc auc training: 0.5156047931944414\n",
      "roc auc test: 0.5161811127978988\n",
      "epoch: 105\n",
      "roc auc training: 0.5147424498255397\n",
      "roc auc test: 0.519228473896541\n",
      "epoch: 106\n",
      "roc auc training: 0.5158287962187387\n",
      "roc auc test: 0.5131730769230769\n",
      "epoch: 107\n",
      "roc auc training: 0.515777466259861\n",
      "roc auc test: 0.5176093406067567\n",
      "epoch: 108\n",
      "roc auc training: 0.5166700305741817\n",
      "roc auc test: 0.5198491322718484\n",
      "epoch: 109\n",
      "roc auc training: 0.5145428446608001\n",
      "roc auc test: 0.5147596153846155\n",
      "epoch: 110\n",
      "roc auc training: 0.5159322050831202\n",
      "roc auc test: 0.5107556536127964\n",
      "epoch: 111\n",
      "roc auc training: 0.5177427433039552\n",
      "roc auc test: 0.5272836538461538\n",
      "epoch: 112\n",
      "roc auc training: 0.5172252968567231\n",
      "roc auc test: 0.5160063163939133\n",
      "epoch: 113\n",
      "roc auc training: 0.5152537342468282\n",
      "roc auc test: 0.519398009469514\n",
      "epoch: 114\n",
      "roc auc training: 0.5145258510063067\n",
      "roc auc test: 0.517298306057996\n",
      "epoch: 115\n",
      "roc auc training: 0.5143028363969809\n",
      "roc auc test: 0.5177686737804877\n",
      "epoch: 116\n",
      "roc auc training: 0.5201242783416608\n",
      "roc auc test: 0.5136268343815513\n",
      "epoch: 117\n",
      "roc auc training: 0.5163810540440104\n",
      "roc auc test: 0.5159134615384615\n",
      "epoch: 118\n",
      "roc auc training: 0.5158972043965473\n",
      "roc auc test: 0.5148798076923077\n",
      "epoch: 119\n",
      "roc auc training: 0.5140119871046301\n",
      "roc auc test: 0.5209615384615385\n",
      "epoch: 120\n",
      "roc auc training: 0.5170991699432066\n",
      "roc auc test: 0.5169230769230769\n",
      "epoch: 121\n",
      "roc auc training: 0.5169372317315581\n",
      "roc auc test: 0.509908536585366\n",
      "epoch: 122\n",
      "roc auc training: 0.5167609061973413\n",
      "roc auc test: 0.5155048076923077\n",
      "epoch: 123\n",
      "roc auc training: 0.517352091991688\n",
      "roc auc test: 0.5309691757657745\n",
      "epoch: 124\n",
      "roc auc training: 0.5172109774616368\n",
      "roc auc test: 0.5116472942073171\n",
      "epoch: 125\n",
      "roc auc training: 0.515507707670224\n",
      "roc auc test: 0.5119787045252884\n",
      "epoch: 126\n",
      "roc auc training: 0.5193839147426993\n",
      "roc auc test: 0.5123456790123456\n",
      "epoch: 127\n",
      "roc auc training: 0.5203778017762769\n",
      "roc auc test: 0.5130408653846154\n",
      "epoch: 128\n",
      "roc auc training: 0.5188090315275433\n",
      "roc auc test: 0.5105398210988273\n",
      "epoch: 129\n",
      "roc auc training: 0.5156459076196244\n",
      "roc auc test: 0.5099881924865659\n",
      "epoch: 130\n",
      "roc auc training: 0.5185948709491218\n",
      "roc auc test: 0.5143768435693902\n",
      "epoch: 131\n",
      "roc auc training: 0.5170911059875637\n",
      "roc auc test: 0.5154329092167769\n",
      "epoch: 132\n",
      "roc auc training: 0.5174878447715714\n",
      "roc auc test: 0.5250969902889226\n",
      "epoch: 133\n",
      "roc auc training: 0.5156652558542066\n",
      "roc auc test: 0.5095463680734998\n",
      "epoch: 134\n",
      "roc auc training: 0.5154321295143213\n",
      "roc auc test: 0.5145432692307693\n",
      "epoch: 135\n",
      "roc auc training: 0.5162089631900157\n",
      "roc auc test: 0.5111846555222727\n",
      "epoch: 136\n",
      "roc auc training: 0.5187222914072229\n",
      "roc auc test: 0.5058194173353575\n",
      "epoch: 137\n",
      "roc auc training: 0.5164785260153107\n",
      "roc auc test: 0.5161514664620255\n",
      "epoch: 138\n",
      "roc auc training: 0.5205865342427506\n",
      "roc auc test: 0.5161778846153846\n",
      "epoch: 139\n",
      "roc auc training: 0.5147443383138206\n",
      "roc auc test: 0.5181730769230769\n",
      "epoch: 140\n",
      "roc auc training: 0.5166282400614826\n",
      "roc auc test: 0.5135576923076923\n",
      "epoch: 141\n",
      "roc auc training: 0.5192004365604419\n",
      "roc auc test: 0.5144064357499225\n",
      "epoch: 142\n",
      "roc auc training: 0.5176824408468244\n",
      "roc auc test: 0.5152172341502205\n",
      "epoch: 143\n",
      "roc auc training: 0.5177844348748674\n",
      "roc auc test: 0.5082543784094171\n",
      "epoch: 144\n",
      "roc auc training: 0.5186418939824934\n",
      "roc auc test: 0.5136855201454684\n",
      "epoch: 145\n",
      "roc auc training: 0.5182590890158648\n",
      "roc auc test: 0.515264423076923\n",
      "epoch: 146\n",
      "roc auc training: 0.5191266384271099\n",
      "roc auc test: 0.5163497915612425\n",
      "epoch: 147\n",
      "roc auc training: 0.5170565593713852\n",
      "roc auc test: 0.5145686946929183\n",
      "epoch: 148\n",
      "roc auc training: 0.5177446053208886\n",
      "roc auc test: 0.5106009615384616\n",
      "epoch: 149\n",
      "roc auc training: 0.5240665318205965\n",
      "roc auc test: 0.5061841723838052\n",
      "epoch: 150\n",
      "roc auc training: 0.5234018620729216\n",
      "roc auc test: 0.5153121177965898\n",
      "maximum roc auc for test set 0.5320803942409895\n",
      "dimensions of embedding 2, dimensions of hidden 50, number of layers 2\n",
      "epoch: 1\n",
      "roc auc training: 0.4947662464692437\n",
      "roc auc test: 0.5334721025935496\n",
      "epoch: 2\n",
      "roc auc training: 0.5015057237445655\n",
      "roc auc test: 0.5215092353335247\n",
      "epoch: 3\n",
      "roc auc training: 0.5068975847219621\n",
      "roc auc test: 0.5221527297032776\n",
      "epoch: 4\n",
      "roc auc training: 0.5089778953899516\n",
      "roc auc test: 0.524772924920282\n",
      "epoch: 5\n",
      "roc auc training: 0.5128640079885165\n",
      "roc auc test: 0.5319646256536303\n",
      "epoch: 6\n",
      "roc auc training: 0.5135767334456719\n",
      "roc auc test: 0.513648056402439\n",
      "epoch: 7\n",
      "roc auc training: 0.5163350500543961\n",
      "roc auc test: 0.5127790124649725\n",
      "epoch: 8\n",
      "roc auc training: 0.5166959995007178\n",
      "roc auc test: 0.5141401091013493\n",
      "epoch: 9\n",
      "roc auc training: 0.5202456160478461\n",
      "roc auc test: 0.5109994172494172\n",
      "epoch: 10\n",
      "roc auc training: 0.5195202163867014\n",
      "roc auc test: 0.5109520711342442\n",
      "epoch: 11\n",
      "roc auc training: 0.5211818181818182\n",
      "roc auc test: 0.49714735862118353\n",
      "epoch: 12\n",
      "roc auc training: 0.5229778701138044\n",
      "roc auc test: 0.506747057134654\n",
      "epoch: 13\n",
      "roc auc training: 0.5214653934968483\n",
      "roc auc test: 0.505554350707246\n",
      "epoch: 14\n",
      "roc auc training: 0.5233475863171355\n",
      "roc auc test: 0.5000717772035601\n",
      "epoch: 15\n",
      "roc auc training: 0.5195993378804196\n",
      "roc auc test: 0.5088942307692308\n",
      "epoch: 16\n",
      "roc auc training: 0.5233370162438802\n",
      "roc auc test: 0.49843641832374497\n",
      "epoch: 17\n",
      "roc auc training: 0.5213504892118987\n",
      "roc auc test: 0.5000835501659068\n",
      "epoch: 18\n",
      "roc auc training: 0.5264511287942244\n",
      "roc auc test: 0.4868701887335428\n",
      "epoch: 19\n",
      "roc auc training: 0.5223747642003773\n",
      "roc auc test: 0.493920717523202\n",
      "epoch: 20\n",
      "roc auc training: 0.5249416656694986\n",
      "roc auc test: 0.49287436442195215\n",
      "epoch: 21\n",
      "roc auc training: 0.5276190618643053\n",
      "roc auc test: 0.4943492614279862\n",
      "epoch: 22\n",
      "roc auc training: 0.5255324877348331\n",
      "roc auc test: 0.48815676141257536\n",
      "epoch: 23\n",
      "roc auc training: 0.5263596080634089\n",
      "roc auc test: 0.5016988361165329\n",
      "epoch: 24\n",
      "roc auc training: 0.5263010150612331\n",
      "roc auc test: 0.4886208302357371\n",
      "epoch: 25\n",
      "roc auc training: 0.5282709604722587\n",
      "roc auc test: 0.4903732620063134\n",
      "epoch: 26\n",
      "roc auc training: 0.5290334729181372\n",
      "roc auc test: 0.4945432692307693\n",
      "epoch: 27\n",
      "roc auc training: 0.5264271694047402\n",
      "roc auc test: 0.484496031079882\n",
      "epoch: 28\n",
      "roc auc training: 0.5265653798256538\n",
      "roc auc test: 0.4937793090247871\n",
      "epoch: 29\n",
      "roc auc training: 0.5271493946562066\n",
      "roc auc test: 0.49060096153846156\n",
      "epoch: 30\n",
      "roc auc training: 0.5276452599388379\n",
      "roc auc test: 0.48904201358981714\n",
      "epoch: 31\n",
      "roc auc training: 0.5301281859518966\n",
      "roc auc test: 0.49186525026318306\n",
      "epoch: 32\n",
      "roc auc training: 0.5312864259028642\n",
      "roc auc test: 0.5001084363478638\n",
      "epoch: 33\n",
      "roc auc training: 0.5291994685102301\n",
      "roc auc test: 0.4787644787644787\n",
      "epoch: 34\n",
      "roc auc training: 0.5307028040365362\n",
      "roc auc test: 0.4861057692307692\n",
      "epoch: 35\n",
      "roc auc training: 0.5325601329615592\n",
      "roc auc test: 0.4795558646490323\n",
      "epoch: 36\n",
      "roc auc training: 0.5321036819674423\n",
      "roc auc test: 0.483201035996067\n",
      "epoch: 37\n",
      "roc auc training: 0.5302809134553004\n",
      "roc auc test: 0.47833281373654046\n",
      "epoch: 38\n",
      "roc auc training: 0.5296835184742794\n",
      "roc auc test: 0.4842082543945898\n",
      "epoch: 39\n",
      "roc auc training: 0.5325724941167086\n",
      "roc auc test: 0.4848275533536585\n",
      "epoch: 40\n",
      "roc auc training: 0.5330849403981776\n",
      "roc auc test: 0.4869826354411373\n",
      "epoch: 41\n",
      "roc auc training: 0.5310611521108564\n",
      "roc auc test: 0.48303316626298\n",
      "epoch: 42\n",
      "roc auc training: 0.5327841228234413\n",
      "roc auc test: 0.48004593741027846\n",
      "epoch: 43\n",
      "roc auc training: 0.5316743039826173\n",
      "roc auc test: 0.4923422552903662\n",
      "epoch: 44\n",
      "roc auc training: 0.5328609855176613\n",
      "roc auc test: 0.4810817307692308\n",
      "epoch: 45\n",
      "roc auc training: 0.5327943640062224\n",
      "roc auc test: 0.4822075076219512\n",
      "epoch: 46\n",
      "roc auc training: 0.5324820570430007\n",
      "roc auc test: 0.4901076764430802\n",
      "epoch: 47\n",
      "roc auc training: 0.5342610443670175\n",
      "roc auc test: 0.48588381663317065\n",
      "epoch: 48\n",
      "roc auc training: 0.5353031427493372\n",
      "roc auc test: 0.48222848743343216\n",
      "epoch: 49\n",
      "roc auc training: 0.5330312675528928\n",
      "roc auc test: 0.47655819084390516\n",
      "epoch: 50\n",
      "roc auc training: 0.5326156760147029\n",
      "roc auc test: 0.4855696927741042\n",
      "epoch: 51\n",
      "roc auc training: 0.5332343450287723\n",
      "roc auc test: 0.48262548262548266\n",
      "epoch: 52\n",
      "roc auc training: 0.5351366369396915\n",
      "roc auc test: 0.48077152610345897\n",
      "epoch: 53\n",
      "roc auc training: 0.5363900039619356\n",
      "roc auc test: 0.4796501120508928\n",
      "epoch: 54\n",
      "roc auc training: 0.5338270761265093\n",
      "roc auc test: 0.4818028846153846\n",
      "epoch: 55\n",
      "roc auc training: 0.5362478936528741\n",
      "roc auc test: 0.4745586205226321\n",
      "epoch: 56\n",
      "roc auc training: 0.5313137365037758\n",
      "roc auc test: 0.4847345719173956\n",
      "epoch: 57\n",
      "roc auc training: 0.5374547115010331\n",
      "roc auc test: 0.4880288461538462\n",
      "epoch: 58\n",
      "roc auc training: 0.5365133472374845\n",
      "roc auc test: 0.47683988898459184\n",
      "epoch: 59\n",
      "roc auc training: 0.5365656746877172\n",
      "roc auc test: 0.48020434227330777\n",
      "epoch: 60\n",
      "roc auc training: 0.5368628096206772\n",
      "roc auc test: 0.483204134366925\n",
      "epoch: 61\n",
      "roc auc training: 0.5413438335128236\n",
      "roc auc test: 0.47844291319743515\n",
      "epoch: 62\n",
      "roc auc training: 0.5365886538101479\n",
      "roc auc test: 0.47998752967697067\n",
      "epoch: 63\n",
      "roc auc training: 0.5381371580281662\n",
      "roc auc test: 0.47185096153846157\n",
      "epoch: 64\n",
      "roc auc training: 0.5373705207079655\n",
      "roc auc test: 0.47842873929830443\n",
      "epoch: 65\n",
      "roc auc training: 0.5358951901867434\n",
      "roc auc test: 0.47639702161497866\n",
      "epoch: 66\n",
      "roc auc training: 0.5376119112495135\n",
      "roc auc test: 0.4764331514977509\n",
      "epoch: 67\n",
      "roc auc training: 0.5398003746093663\n",
      "roc auc test: 0.4759346746924387\n",
      "epoch: 68\n",
      "roc auc training: 0.5396798093414702\n",
      "roc auc test: 0.48134615384615387\n",
      "epoch: 69\n",
      "roc auc training: 0.5387784331926021\n",
      "roc auc test: 0.4742307416867585\n",
      "epoch: 70\n",
      "roc auc training: 0.5408378372317284\n",
      "roc auc test: 0.4754481869613998\n",
      "epoch: 71\n",
      "roc auc training: 0.5403814930003916\n",
      "roc auc test: 0.47657014633214767\n",
      "epoch: 72\n",
      "roc auc training: 0.5414014807929213\n",
      "roc auc test: 0.4724854053019428\n",
      "epoch: 73\n",
      "roc auc training: 0.5407583719629155\n",
      "roc auc test: 0.4757945974601798\n",
      "epoch: 74\n",
      "roc auc training: 0.5403816211036919\n",
      "roc auc test: 0.47387309790410564\n",
      "epoch: 75\n",
      "roc auc training: 0.5438591452205882\n",
      "roc auc test: 0.46805288461538463\n",
      "epoch: 76\n",
      "roc auc training: 0.5439277452036217\n",
      "roc auc test: 0.47625374432312295\n",
      "epoch: 77\n",
      "roc auc training: 0.5408128415300546\n",
      "roc auc test: 0.4698057230356972\n",
      "epoch: 78\n",
      "roc auc training: 0.5432286832150592\n",
      "roc auc test: 0.4664690715438926\n",
      "epoch: 79\n",
      "roc auc training: 0.5432698177758841\n",
      "roc auc test: 0.4704829199589411\n",
      "epoch: 80\n",
      "roc auc training: 0.5447192473375613\n",
      "roc auc test: 0.4780361757105943\n",
      "epoch: 81\n",
      "roc auc training: 0.5444451098402052\n",
      "roc auc test: 0.4704038663986984\n",
      "epoch: 82\n",
      "roc auc training: 0.5466865028394992\n",
      "roc auc test: 0.4728306706185691\n",
      "epoch: 83\n",
      "roc auc training: 0.5423703226836741\n",
      "roc auc test: 0.47544818696139984\n",
      "epoch: 84\n",
      "roc auc training: 0.5453373275915872\n",
      "roc auc test: 0.48329696155783114\n",
      "epoch: 85\n",
      "roc auc training: 0.5450240041520695\n",
      "roc auc test: 0.47636633972037695\n",
      "epoch: 86\n",
      "roc auc training: 0.5433309878132766\n",
      "roc auc test: 0.47170673076923075\n",
      "epoch: 87\n",
      "roc auc training: 0.5448480901478177\n",
      "roc auc test: 0.47646722560975613\n",
      "epoch: 88\n",
      "roc auc training: 0.5456368969606191\n",
      "roc auc test: 0.4717139499748195\n",
      "epoch: 89\n",
      "roc auc training: 0.5487216305691835\n",
      "roc auc test: 0.47315283340128067\n",
      "epoch: 90\n",
      "roc auc training: 0.5470980244468776\n",
      "roc auc test: 0.46380036367116473\n",
      "epoch: 91\n",
      "roc auc training: 0.5460616848151251\n",
      "roc auc test: 0.47282234105763526\n",
      "epoch: 92\n",
      "roc auc training: 0.547422374719363\n",
      "roc auc test: 0.46968306116533004\n",
      "epoch: 93\n",
      "roc auc training: 0.5472317532935147\n",
      "roc auc test: 0.4718818197079067\n",
      "epoch: 94\n",
      "roc auc training: 0.5483704982819154\n",
      "roc auc test: 0.46734137238013196\n",
      "epoch: 95\n",
      "roc auc training: 0.5487690515798689\n",
      "roc auc test: 0.4607211538461538\n",
      "epoch: 96\n",
      "roc auc training: 0.5498032737049579\n",
      "roc auc test: 0.46665387659176477\n",
      "epoch: 97\n",
      "roc auc training: 0.5474739240556818\n",
      "roc auc test: 0.457627524164992\n",
      "epoch: 98\n",
      "roc auc training: 0.5498352666535312\n",
      "roc auc test: 0.4605769230769231\n",
      "epoch: 99\n",
      "roc auc training: 0.5485321148968327\n",
      "roc auc test: 0.4591826923076924\n",
      "epoch: 100\n",
      "roc auc training: 0.5504399097723348\n",
      "roc auc test: 0.46407865494250644\n",
      "epoch: 101\n",
      "roc auc training: 0.5506686011726697\n",
      "roc auc test: 0.46281249999999996\n",
      "epoch: 102\n",
      "roc auc training: 0.5510416900271355\n",
      "roc auc test: 0.4633173076923077\n",
      "epoch: 103\n",
      "roc auc training: 0.5497362490526904\n",
      "roc auc test: 0.46193884189980483\n",
      "epoch: 104\n",
      "roc auc training: 0.5502492823312575\n",
      "roc auc test: 0.46887019230769234\n",
      "epoch: 105\n",
      "roc auc training: 0.5523659739125008\n",
      "roc auc test: 0.47260748132057007\n",
      "epoch: 106\n",
      "roc auc training: 0.5504824779087719\n",
      "roc auc test: 0.4730329264490755\n",
      "epoch: 107\n",
      "roc auc training: 0.5502377958100029\n",
      "roc auc test: 0.46685445561099037\n",
      "epoch: 108\n",
      "roc auc training: 0.5504479777432092\n",
      "roc auc test: 0.46543144265146386\n",
      "epoch: 109\n",
      "roc auc training: 0.5512970978199387\n",
      "roc auc test: 0.4638480539101657\n",
      "epoch: 110\n",
      "roc auc training: 0.5495288023466267\n",
      "roc auc test: 0.46391826406626724\n",
      "epoch: 111\n",
      "roc auc training: 0.5521011295644604\n",
      "roc auc test: 0.4735294826381359\n",
      "epoch: 112\n",
      "roc auc training: 0.5542223363952203\n",
      "roc auc test: 0.4648317307692308\n",
      "epoch: 113\n",
      "roc auc training: 0.5548436001438618\n",
      "roc auc test: 0.46852442504616415\n",
      "epoch: 114\n",
      "roc auc training: 0.5538419906671888\n",
      "roc auc test: 0.4572103793177532\n",
      "epoch: 115\n",
      "roc auc training: 0.5562291407222915\n",
      "roc auc test: 0.46845862470862476\n",
      "epoch: 116\n",
      "roc auc training: 0.5527766335892155\n",
      "roc auc test: 0.46279535060975613\n",
      "epoch: 117\n",
      "roc auc training: 0.5562587957002126\n",
      "roc auc test: 0.46788092907784484\n",
      "epoch: 118\n",
      "roc auc training: 0.5557374557396983\n",
      "roc auc test: 0.4713942307692307\n",
      "epoch: 119\n",
      "roc auc training: 0.5539218619121695\n",
      "roc auc test: 0.46955562483512797\n",
      "epoch: 120\n",
      "roc auc training: 0.5539180598127951\n",
      "roc auc test: 0.4681853319161272\n",
      "epoch: 121\n",
      "roc auc training: 0.5566293379644879\n",
      "roc auc test: 0.46010695700136695\n",
      "epoch: 122\n",
      "roc auc training: 0.5563038470743089\n",
      "roc auc test: 0.4638853995555126\n",
      "epoch: 123\n",
      "roc auc training: 0.5558430985936532\n",
      "roc auc test: 0.46343028747184617\n",
      "epoch: 124\n",
      "roc auc training: 0.5573025132746894\n",
      "roc auc test: 0.4614795674227199\n",
      "epoch: 125\n",
      "roc auc training: 0.5565444138646245\n",
      "roc auc test: 0.4653125\n",
      "epoch: 126\n",
      "roc auc training: 0.556722641918838\n",
      "roc auc test: 0.46226528214105855\n",
      "epoch: 127\n",
      "roc auc training: 0.557674592772889\n",
      "roc auc test: 0.4566105769230769\n",
      "epoch: 128\n",
      "roc auc training: 0.5590945028195465\n",
      "roc auc test: 0.46111743479208545\n",
      "epoch: 129\n",
      "roc auc training: 0.5611675342028639\n",
      "roc auc test: 0.4612101009616537\n",
      "epoch: 130\n",
      "roc auc training: 0.5582300306414748\n",
      "roc auc test: 0.45942307692307693\n",
      "epoch: 131\n",
      "roc auc training: 0.5578856048821347\n",
      "roc auc test: 0.46630039278054897\n",
      "epoch: 132\n",
      "roc auc training: 0.5569083802002313\n",
      "roc auc test: 0.47222824646377015\n",
      "epoch: 133\n",
      "roc auc training: 0.5577671647153936\n",
      "roc auc test: 0.4604906592484232\n",
      "epoch: 134\n",
      "roc auc training: 0.5566615371953181\n",
      "roc auc test: 0.4607783778547383\n",
      "epoch: 135\n",
      "roc auc training: 0.5575400984120331\n",
      "roc auc test: 0.4588955880945545\n",
      "epoch: 136\n",
      "roc auc training: 0.5568236209165969\n",
      "roc auc test: 0.4602884615384616\n",
      "epoch: 137\n",
      "roc auc training: 0.5591457815572256\n",
      "roc auc test: 0.46770905777116956\n",
      "epoch: 138\n",
      "roc auc training: 0.5578018982405517\n",
      "roc auc test: 0.4582451923076923\n",
      "epoch: 139\n",
      "roc auc training: 0.5599484962705915\n",
      "roc auc test: 0.46387019230769233\n",
      "epoch: 140\n",
      "roc auc training: 0.5589593469118497\n",
      "roc auc test: 0.46384805391016565\n",
      "epoch: 141\n",
      "roc auc training: 0.5585724043715846\n",
      "roc auc test: 0.4626201923076923\n",
      "epoch: 142\n",
      "roc auc training: 0.5635935842226799\n",
      "roc auc test: 0.45863240501483393\n",
      "epoch: 143\n",
      "roc auc training: 0.5579854976993941\n",
      "roc auc test: 0.4710020097616997\n",
      "epoch: 144\n",
      "roc auc training: 0.5602146913811397\n",
      "roc auc test: 0.4699253517082974\n",
      "epoch: 145\n",
      "roc auc training: 0.5618393867712669\n",
      "roc auc test: 0.46060012890597024\n",
      "epoch: 146\n",
      "roc auc training: 0.5638394807464271\n",
      "roc auc test: 0.4628605769230769\n",
      "epoch: 147\n",
      "roc auc training: 0.5622833705854944\n",
      "roc auc test: 0.46814903846153844\n",
      "epoch: 148\n",
      "roc auc training: 0.5581218153839247\n",
      "roc auc test: 0.4531916431721246\n",
      "epoch: 149\n",
      "roc auc training: 0.5621198101513651\n",
      "roc auc test: 0.4725480769230769\n",
      "epoch: 150\n",
      "roc auc training: 0.5593089928694529\n",
      "roc auc test: 0.4666947115384615\n",
      "maximum roc auc for test set 0.5334721025935496\n",
      "dimensions of embedding 2, dimensions of hidden 50, number of layers 3\n",
      "epoch: 1\n",
      "roc auc training: 0.5062867423221646\n",
      "roc auc test: 0.5034931572399273\n",
      "epoch: 2\n",
      "roc auc training: 0.5099305472458219\n",
      "roc auc test: 0.5085096153846154\n",
      "epoch: 3\n",
      "roc auc training: 0.508282687836858\n",
      "roc auc test: 0.5083908238046358\n",
      "epoch: 4\n",
      "roc auc training: 0.5104627856886442\n",
      "roc auc test: 0.5085014029113408\n",
      "epoch: 5\n",
      "roc auc training: 0.512235902112783\n",
      "roc auc test: 0.5131298112664573\n",
      "epoch: 6\n",
      "roc auc training: 0.5128435243907303\n",
      "roc auc test: 0.5058173076923077\n",
      "epoch: 7\n",
      "roc auc training: 0.5133636363636364\n",
      "roc auc test: 0.5002033687434204\n",
      "epoch: 8\n",
      "roc auc training: 0.5115301153011531\n",
      "roc auc test: 0.4880288461538461\n",
      "epoch: 9\n",
      "roc auc training: 0.5177453105242287\n",
      "roc auc test: 0.5008052884615384\n",
      "epoch: 10\n",
      "roc auc training: 0.5169456244266284\n",
      "roc auc test: 0.5011778846153846\n",
      "epoch: 11\n",
      "roc auc training: 0.5184563340114077\n",
      "roc auc test: 0.48806925825559366\n",
      "epoch: 12\n",
      "roc auc training: 0.5184673438899018\n",
      "roc auc test: 0.49391434832317066\n",
      "epoch: 13\n",
      "roc auc training: 0.5176562765118624\n",
      "roc auc test: 0.5092037878055851\n",
      "epoch: 14\n",
      "roc auc training: 0.5191456264209644\n",
      "roc auc test: 0.48911379079337736\n",
      "epoch: 15\n",
      "roc auc training: 0.520220932409661\n",
      "roc auc test: 0.49696635410921125\n",
      "epoch: 16\n",
      "roc auc training: 0.5192507311035921\n",
      "roc auc test: 0.48552493061536983\n",
      "epoch: 17\n",
      "roc auc training: 0.5221695385106297\n",
      "roc auc test: 0.4755408653846154\n",
      "epoch: 18\n",
      "roc auc training: 0.5200647959476346\n",
      "roc auc test: 0.4850476030600254\n",
      "epoch: 19\n",
      "roc auc training: 0.5156251562515625\n",
      "roc auc test: 0.49114747822758165\n",
      "epoch: 20\n",
      "roc auc training: 0.522893071721981\n",
      "roc auc test: 0.47948246640089753\n",
      "epoch: 21\n",
      "roc auc training: 0.5181876053173563\n",
      "roc auc test: 0.47914407576086165\n",
      "epoch: 22\n",
      "roc auc training: 0.5229167653902846\n",
      "roc auc test: 0.4776373534137509\n",
      "epoch: 23\n",
      "roc auc training: 0.5201199046145336\n",
      "roc auc test: 0.48993951661485824\n",
      "epoch: 24\n",
      "roc auc training: 0.5213804180560717\n",
      "roc auc test: 0.4784047579078635\n",
      "epoch: 25\n",
      "roc auc training: 0.5208688904192992\n",
      "roc auc test: 0.4833369478782621\n",
      "epoch: 26\n",
      "roc auc training: 0.5250150129946501\n",
      "roc auc test: 0.48471153846153847\n",
      "epoch: 27\n",
      "roc auc training: 0.5213916413726365\n",
      "roc auc test: 0.47779978741907436\n",
      "epoch: 28\n",
      "roc auc training: 0.5199226339378129\n",
      "roc auc test: 0.4852634355739946\n",
      "epoch: 29\n",
      "roc auc training: 0.5247399308144886\n",
      "roc auc test: 0.48422853562736456\n",
      "epoch: 30\n",
      "roc auc training: 0.522400995044757\n",
      "roc auc test: 0.48423076923076924\n",
      "epoch: 31\n",
      "roc auc training: 0.5226025125264684\n",
      "roc auc test: 0.48005538182425816\n",
      "epoch: 32\n",
      "roc auc training: 0.5211558423411284\n",
      "roc auc test: 0.4828213226146042\n",
      "epoch: 33\n",
      "roc auc training: 0.521245853980179\n",
      "roc auc test: 0.4807710889941057\n",
      "epoch: 34\n",
      "roc auc training: 0.52143778167407\n",
      "roc auc test: 0.490602956807421\n",
      "epoch: 35\n",
      "roc auc training: 0.5234031091080955\n",
      "roc auc test: 0.4782036558522347\n",
      "epoch: 36\n",
      "roc auc training: 0.5257961696067599\n",
      "roc auc test: 0.4879414298018949\n",
      "epoch: 37\n",
      "roc auc training: 0.523616078564578\n",
      "roc auc test: 0.48313643292682923\n",
      "epoch: 38\n",
      "roc auc training: 0.5235498921035806\n",
      "roc auc test: 0.46725961538461536\n",
      "epoch: 39\n",
      "roc auc training: 0.5231954066030082\n",
      "roc auc test: 0.47540904600110845\n",
      "epoch: 40\n",
      "roc auc training: 0.5221483486897212\n",
      "roc auc test: 0.48681895949299986\n",
      "epoch: 41\n",
      "roc auc training: 0.5206493098182472\n",
      "roc auc test: 0.4751411618336683\n",
      "epoch: 42\n",
      "roc auc training: 0.5211324837461608\n",
      "roc auc test: 0.4794238683127572\n",
      "epoch: 43\n",
      "roc auc training: 0.5230141564098466\n",
      "roc auc test: 0.47456694420518714\n",
      "epoch: 44\n",
      "roc auc training: 0.5204606417773523\n",
      "roc auc test: 0.46883618312189734\n",
      "epoch: 45\n",
      "roc auc training: 0.5239081320601635\n",
      "roc auc test: 0.4692482365445937\n",
      "epoch: 46\n",
      "roc auc training: 0.5209277442879554\n",
      "roc auc test: 0.4826863297910792\n",
      "epoch: 47\n",
      "roc auc training: 0.5264334045806096\n",
      "roc auc test: 0.47983173076923075\n",
      "epoch: 48\n",
      "roc auc training: 0.5238868760667126\n",
      "roc auc test: 0.48058706443799615\n",
      "epoch: 49\n",
      "roc auc training: 0.5240691436320849\n",
      "roc auc test: 0.4755478993205091\n",
      "epoch: 50\n",
      "roc auc training: 0.5223748316441736\n",
      "roc auc test: 0.4712706786660619\n",
      "epoch: 51\n",
      "roc auc training: 0.5246645447169693\n",
      "roc auc test: 0.47365644260054196\n",
      "epoch: 52\n",
      "roc auc training: 0.5237971547314578\n",
      "roc auc test: 0.4691197378250079\n",
      "epoch: 53\n",
      "roc auc training: 0.524931131538761\n",
      "roc auc test: 0.4727268387004368\n",
      "epoch: 54\n",
      "roc auc training: 0.5251320049813201\n",
      "roc auc test: 0.47549066310975613\n",
      "epoch: 55\n",
      "roc auc training: 0.5217370168720833\n",
      "roc auc test: 0.4741091844512195\n",
      "epoch: 56\n",
      "roc auc training: 0.5256004235933504\n",
      "roc auc test: 0.47326299167384434\n",
      "epoch: 57\n",
      "roc auc training: 0.5199894798771489\n",
      "roc auc test: 0.46846588190257443\n",
      "epoch: 58\n",
      "roc auc training: 0.5232632893035216\n",
      "roc auc test: 0.4717619127557016\n",
      "epoch: 59\n",
      "roc auc training: 0.5263726018108571\n",
      "roc auc test: 0.4735844984292189\n",
      "epoch: 60\n",
      "roc auc training: 0.5263269369254882\n",
      "roc auc test: 0.4739903846153846\n",
      "epoch: 61\n",
      "roc auc training: 0.5255374734257569\n",
      "roc auc test: 0.4707331730769231\n",
      "epoch: 62\n",
      "roc auc training: 0.5257999107122816\n",
      "roc auc test: 0.476758476107858\n",
      "epoch: 63\n",
      "roc auc training: 0.5262687959376582\n",
      "roc auc test: 0.4830718812501506\n",
      "epoch: 64\n",
      "roc auc training: 0.5235236806630137\n",
      "roc auc test: 0.4758589338692698\n",
      "epoch: 65\n",
      "roc auc training: 0.5256547494285915\n",
      "roc auc test: 0.4716639288820176\n",
      "epoch: 66\n",
      "roc auc training: 0.5259326014119899\n",
      "roc auc test: 0.46842997302523215\n",
      "epoch: 67\n",
      "roc auc training: 0.5262235536416402\n",
      "roc auc test: 0.478951300031326\n",
      "epoch: 68\n",
      "roc auc training: 0.52531809660564\n",
      "roc auc test: 0.46504022343701507\n",
      "epoch: 69\n",
      "roc auc training: 0.5254808712475816\n",
      "roc auc test: 0.4755054338658763\n",
      "epoch: 70\n",
      "roc auc training: 0.5267031150095908\n",
      "roc auc test: 0.4811096849192319\n",
      "epoch: 71\n",
      "roc auc training: 0.5273136791512106\n",
      "roc auc test: 0.4754959299133466\n",
      "epoch: 72\n",
      "roc auc training: 0.526630385962811\n",
      "roc auc test: 0.47898116540545704\n",
      "epoch: 73\n",
      "roc auc training: 0.5272863766395395\n",
      "roc auc test: 0.4741330030487805\n",
      "epoch: 74\n",
      "roc auc training: 0.5252769634238763\n",
      "roc auc test: 0.4767368827906078\n",
      "epoch: 75\n",
      "roc auc training: 0.5280138742496617\n",
      "roc auc test: 0.47396634615384614\n",
      "epoch: 76\n",
      "roc auc training: 0.5271044804423551\n",
      "roc auc test: 0.46915865384615374\n",
      "epoch: 77\n",
      "roc auc training: 0.5308560649160105\n",
      "roc auc test: 0.46742128108587744\n",
      "epoch: 78\n",
      "roc auc training: 0.5278455649709055\n",
      "roc auc test: 0.47789262130347404\n",
      "epoch: 79\n",
      "roc auc training: 0.5266503478356339\n",
      "roc auc test: 0.4740161634571573\n",
      "epoch: 80\n",
      "roc auc training: 0.5283371260891697\n",
      "roc auc test: 0.46790865384615377\n",
      "epoch: 81\n",
      "roc auc training: 0.5316538530573172\n",
      "roc auc test: 0.47343309477336804\n",
      "epoch: 82\n",
      "roc auc training: 0.5312046028221938\n",
      "roc auc test: 0.4750961538461539\n",
      "epoch: 83\n",
      "roc auc training: 0.5284765649379018\n",
      "roc auc test: 0.47640922576323097\n",
      "epoch: 84\n",
      "roc auc training: 0.5284990326405792\n",
      "roc auc test: 0.4777729926308738\n",
      "epoch: 85\n",
      "roc auc training: 0.5284980686888043\n",
      "roc auc test: 0.4687642389505744\n",
      "epoch: 86\n",
      "roc auc training: 0.5289071959058853\n",
      "roc auc test: 0.4797109771269978\n",
      "epoch: 87\n",
      "roc auc training: 0.5299057604693254\n",
      "roc auc test: 0.47620522103658536\n",
      "epoch: 88\n",
      "roc auc training: 0.5303470371590263\n",
      "roc auc test: 0.46849321670401695\n",
      "epoch: 89\n",
      "roc auc training: 0.5279593454588967\n",
      "roc auc test: 0.4737534692315054\n",
      "epoch: 90\n",
      "roc auc training: 0.531144703467506\n",
      "roc auc test: 0.48141605595473963\n",
      "epoch: 91\n",
      "roc auc training: 0.5328684712199698\n",
      "roc auc test: 0.4738249265952114\n",
      "epoch: 92\n",
      "roc auc training: 0.5299537275832941\n",
      "roc auc test: 0.47793922745126394\n",
      "epoch: 93\n",
      "roc auc training: 0.5303413842601261\n",
      "roc auc test: 0.46694165327705706\n",
      "epoch: 94\n",
      "roc auc training: 0.5293827622792237\n",
      "roc auc test: 0.47591069330199764\n",
      "epoch: 95\n",
      "roc auc training: 0.5346214375322671\n",
      "roc auc test: 0.4767611181399346\n",
      "epoch: 96\n",
      "roc auc training: 0.5365444945292897\n",
      "roc auc test: 0.4703949735005636\n",
      "epoch: 97\n",
      "roc auc training: 0.5334269487611558\n",
      "roc auc test: 0.4787776295731707\n",
      "epoch: 98\n",
      "roc auc training: 0.5340278487895029\n",
      "roc auc test: 0.47707507971784713\n",
      "epoch: 99\n",
      "roc auc training: 0.5366952570264197\n",
      "roc auc test: 0.4816346153846154\n",
      "epoch: 100\n",
      "roc auc training: 0.534859621250477\n",
      "roc auc test: 0.48750000000000004\n",
      "epoch: 101\n",
      "roc auc training: 0.5349207259739968\n",
      "roc auc test: 0.47937500000000005\n",
      "epoch: 102\n",
      "roc auc training: 0.5322311676964364\n",
      "roc auc test: 0.47581108240022973\n",
      "epoch: 103\n",
      "roc auc training: 0.5333490387300068\n",
      "roc auc test: 0.48986786253867\n",
      "epoch: 104\n",
      "roc auc training: 0.53570056192672\n",
      "roc auc test: 0.48064903846153845\n",
      "epoch: 105\n",
      "roc auc training: 0.5350318391871525\n",
      "roc auc test: 0.47921988016519057\n",
      "epoch: 106\n",
      "roc auc training: 0.5360252979202431\n",
      "roc auc test: 0.48049113887623196\n",
      "epoch: 107\n",
      "roc auc training: 0.5348612948801328\n",
      "roc auc test: 0.47365644260054196\n",
      "epoch: 108\n",
      "roc auc training: 0.5379999201525087\n",
      "roc auc test: 0.47393913106339913\n",
      "epoch: 109\n",
      "roc auc training: 0.537256422854663\n",
      "roc auc test: 0.4833735169845551\n",
      "epoch: 110\n",
      "roc auc training: 0.5377970112079701\n",
      "roc auc test: 0.48355769230769224\n",
      "epoch: 111\n",
      "roc auc training: 0.5370267740123572\n",
      "roc auc test: 0.4821995192307692\n",
      "epoch: 112\n",
      "roc auc training: 0.5382669102015151\n",
      "roc auc test: 0.4772836538461538\n",
      "epoch: 113\n",
      "roc auc training: 0.5381341988751944\n",
      "roc auc test: 0.48744574210412717\n",
      "epoch: 114\n",
      "roc auc training: 0.5352405916495039\n",
      "roc auc test: 0.4785486462505096\n",
      "epoch: 115\n",
      "roc auc training: 0.5377941238765173\n",
      "roc auc test: 0.4862466725820763\n",
      "epoch: 116\n",
      "roc auc training: 0.5371415596211236\n",
      "roc auc test: 0.4907692307692308\n",
      "epoch: 117\n",
      "roc auc training: 0.5363231228353844\n",
      "roc auc test: 0.48641454231516346\n",
      "epoch: 118\n",
      "roc auc training: 0.5408795056745525\n",
      "roc auc test: 0.4866677806688787\n",
      "epoch: 119\n",
      "roc auc training: 0.5412437244862314\n",
      "roc auc test: 0.49094702510851584\n",
      "epoch: 120\n",
      "roc auc training: 0.5383001912951957\n",
      "roc auc test: 0.4958632101489244\n",
      "epoch: 121\n",
      "roc auc training: 0.5374311954050497\n",
      "roc auc test: 0.48471031963906325\n",
      "epoch: 122\n",
      "roc auc training: 0.5367500666552045\n",
      "roc auc test: 0.48442408690855887\n",
      "epoch: 123\n",
      "roc auc training: 0.541837431693989\n",
      "roc auc test: 0.4886778846153846\n",
      "epoch: 124\n",
      "roc auc training: 0.5407683823896358\n",
      "roc auc test: 0.492625722439387\n",
      "epoch: 125\n",
      "roc auc training: 0.5418673467352719\n",
      "roc auc test: 0.48763039525313423\n",
      "epoch: 126\n",
      "roc auc training: 0.5451164855555916\n",
      "roc auc test: 0.4908173076923077\n",
      "epoch: 127\n",
      "roc auc training: 0.5427895220129552\n",
      "roc auc test: 0.4885177956095328\n",
      "epoch: 128\n",
      "roc auc training: 0.5444925192881597\n",
      "roc auc test: 0.49418269230769235\n",
      "epoch: 129\n",
      "roc auc training: 0.5441570938534562\n",
      "roc auc test: 0.4891724022158805\n",
      "epoch: 130\n",
      "roc auc training: 0.5449141858578294\n",
      "roc auc test: 0.492798353909465\n",
      "epoch: 131\n",
      "roc auc training: 0.5471292003262244\n",
      "roc auc test: 0.4940646058658481\n",
      "epoch: 132\n",
      "roc auc training: 0.5445016972148716\n",
      "roc auc test: 0.4944951923076923\n",
      "epoch: 133\n",
      "roc auc training: 0.5430668414154654\n",
      "roc auc test: 0.49724611073533675\n",
      "epoch: 134\n",
      "roc auc training: 0.5460046311544948\n",
      "roc auc test: 0.491144364924456\n",
      "epoch: 135\n",
      "roc auc training: 0.5449616176745928\n",
      "roc auc test: 0.48888781524784997\n",
      "epoch: 136\n",
      "roc auc training: 0.5445771508914683\n",
      "roc auc test: 0.49319260705077234\n",
      "epoch: 137\n",
      "roc auc training: 0.5458135782177872\n",
      "roc auc test: 0.501120508927926\n",
      "epoch: 138\n",
      "roc auc training: 0.5476055677626444\n",
      "roc auc test: 0.49703829828053425\n",
      "epoch: 139\n",
      "roc auc training: 0.5474393059976285\n",
      "roc auc test: 0.48700685379380493\n",
      "epoch: 140\n",
      "roc auc training: 0.54955177296478\n",
      "roc auc test: 0.49097100649895686\n",
      "epoch: 141\n",
      "roc auc training: 0.5474988532567509\n",
      "roc auc test: 0.4954795079018681\n",
      "epoch: 142\n",
      "roc auc training: 0.5502081301705196\n",
      "roc auc test: 0.49526367538789895\n",
      "epoch: 143\n",
      "roc auc training: 0.5501968110613811\n",
      "roc auc test: 0.5025123200309208\n",
      "epoch: 144\n",
      "roc auc training: 0.548145703611457\n",
      "roc auc test: 0.48900453248279335\n",
      "epoch: 145\n",
      "roc auc training: 0.5515798688617811\n",
      "roc auc test: 0.5056266416058218\n",
      "epoch: 146\n",
      "roc auc training: 0.5506684141546527\n",
      "roc auc test: 0.49708106038855393\n",
      "epoch: 147\n",
      "roc auc training: 0.5552744258466329\n",
      "roc auc test: 0.49875586180495735\n",
      "epoch: 148\n",
      "roc auc training: 0.5502143653463889\n",
      "roc auc test: 0.491120267958264\n",
      "epoch: 149\n",
      "roc auc training: 0.5514492319669432\n",
      "roc auc test: 0.5012019230769231\n",
      "epoch: 150\n",
      "roc auc training: 0.5513853157034023\n",
      "roc auc test: 0.5034097207161619\n",
      "maximum roc auc for test set 0.5131298112664573\n",
      "dimensions of embedding 2, dimensions of hidden 100, number of layers 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuDNN error: CUDNN_STATUS_EXECUTION_FAILED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-503f1943194b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mtest_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"models/RNN-classifier-fool-hem/em{}_hi{}_la{}_ep{{}}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m                 \u001b[0mtraining_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"em{}_hi{}_la{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mroc_training\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"maximum roc auc for test set {max(roc_test)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2c172380901e>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(model, test_dataloader, training_dataloader, n_epoch, optimizer, filename)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mcat_batched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_batched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_batched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_batched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/AIpep/models.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, sequences, lengths)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aipep/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Code/AIpep/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sequences, lengths)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mall_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# we can now grab the last hidden state or the last output and give it to the output layer. for RNN and GRU the last output and the last hidden are the same,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aipep/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/aipep/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    728\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n\u001b[0;32m--> 730\u001b[0;31m                              self.num_layers, self.dropout, self.training, self.bidirectional)\n\u001b[0m\u001b[1;32m    731\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED"
     ]
    }
   ],
   "source": [
    "n_embeddings  = [2, 21, 42, 100]\n",
    "n_hiddens = [50, 100, 200, 300, 400]\n",
    "n_layerss = [1, 2,3]\n",
    "    \n",
    "if not os.path.exists(folder+\"pickles/fool_classifier_hyperparameter_optimization_results_hem_.pkl\"):\n",
    "    df_opt = df_training.copy()\n",
    "    # create an evaluation/training set only from the training set\n",
    "    # assign to training or evaluation set\n",
    "    df_opt[\"Set2\"] = \"test\"\n",
    "    training_ = df_opt.sample(frac=0.75, random_state=0)\n",
    "    df_opt.loc[training_.index, \"Set2\"] = \"training\"\n",
    "\n",
    "    df_training = df_opt[df_opt[\"Set2\"]==\"training\"]\n",
    "    df_test = df_opt[df_opt[\"Set2\"]==\"test\"]\n",
    "\n",
    "    training_dataset = Dataset(df_training, vocabulary)\n",
    "    test_dataset = Dataset(df_test, vocabulary)\n",
    "\n",
    "    training_dict = {}\n",
    "    for  n_embedding in n_embeddings:\n",
    "        for n_hidden in n_hiddens:\n",
    "            for n_layers in n_layerss:\n",
    "\n",
    "                if \"em{}_hi{}_la{}\".format(n_embedding, n_hidden, n_layers) in training_dict:\n",
    "                    continue\n",
    "\n",
    "                print(f\"dimensions of embedding {n_embedding}, dimensions of hidden {n_hidden}, number of layers {n_layers}\")\n",
    "                model = Classifier(n_embedding, n_hidden, n_layers, vocabulary)\n",
    "                model.to(device)\n",
    "                optimizer = optim.SGD(model.model.parameters(), lr = learning_rate, momentum=momentum)\n",
    "                training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, collate_fn = collate_fn, drop_last=True, pin_memory=True, num_workers=4)\n",
    "                test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn = collate_fn, drop_last=True, pin_memory=True, num_workers=4)\n",
    "                filename = folder+\"models/RNN-classifier-fool-hem/em{}_hi{}_la{}_ep{{}}\".format(n_embedding, n_hidden, n_layers)\n",
    "                model, optimizer, roc_training, roc_test = training(model, test_dataloader, training_dataloader, n_epoch, optimizer, filename)\n",
    "                training_dict[\"em{}_hi{}_la{}\".format(n_embedding, n_hidden, n_layers)] = [roc_training, roc_test]\n",
    "                print(f\"maximum roc auc for test set {max(roc_test)}\")\n",
    "\n",
    "    with open(folder+\"pickles/fool_classifier_hyperparameter_optimization_results_hem.pkl\",\"bw\") as fd:\n",
    "        pickle.dump(training_dict, fd)\n",
    "else:\n",
    "    with open(folder+\"pickles/fool_classifier_hyperparameter_optimization_results_hem.pkl\",'rb') as fd:\n",
    "        training_dict = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimized hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_test = 0\n",
    "for k,v in training_dict.items():\n",
    "    if max(v[1]) > max_test:\n",
    "        max_test = max(v[1])\n",
    "        best = k\n",
    "best = best.split(\"_\")\n",
    "n_embedding = int(best[0].replace(\"em\", \"\"))\n",
    "n_hidden = int(best[1].replace(\"hi\", \"\"))\n",
    "n_layers = int(best[2].replace(\"la\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 50 2\n"
     ]
    }
   ],
   "source": [
    "print(n_embedding, n_hidden, n_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimensions of embedding 2, dimensions of hidden 50, number of layers 2\n",
      "epoch: 1\n",
      "roc auc training: 0.5181590661835893\n",
      "roc auc test: 0.42510611765270145\n",
      "epoch: 2\n",
      "roc auc training: 0.5196150352826102\n",
      "roc auc test: 0.4363575461766676\n",
      "epoch: 3\n",
      "roc auc training: 0.5139518295253036\n",
      "roc auc test: 0.4342698909073548\n",
      "epoch: 4\n",
      "roc auc training: 0.5159258862055464\n",
      "roc auc test: 0.4297115384615385\n",
      "epoch: 5\n",
      "roc auc training: 0.5156325282406541\n",
      "roc auc test: 0.43245192307692304\n",
      "epoch: 6\n",
      "roc auc training: 0.5186273263912249\n",
      "roc auc test: 0.435113407981625\n",
      "epoch: 7\n",
      "roc auc training: 0.5184074862015559\n",
      "roc auc test: 0.4352862178949135\n",
      "epoch: 8\n",
      "roc auc training: 0.5174260695197169\n",
      "roc auc test: 0.43206935975609756\n",
      "epoch: 9\n",
      "roc auc training: 0.5207701429195531\n",
      "roc auc test: 0.4275402287824648\n",
      "epoch: 10\n",
      "roc auc training: 0.5193823367445847\n",
      "roc auc test: 0.42290865384615384\n",
      "epoch: 11\n",
      "roc auc training: 0.5224297877748125\n",
      "roc auc test: 0.4280123683447676\n",
      "epoch: 12\n",
      "roc auc training: 0.5187379604954537\n",
      "roc auc test: 0.4334156694405142\n",
      "epoch: 13\n",
      "roc auc training: 0.5209891408400144\n",
      "roc auc test: 0.43564593875152885\n",
      "epoch: 14\n",
      "roc auc training: 0.5214216624785608\n",
      "roc auc test: 0.4306609797826454\n",
      "epoch: 15\n",
      "roc auc training: 0.51931389852818\n",
      "roc auc test: 0.4390273148037123\n",
      "epoch: 16\n",
      "roc auc training: 0.519920701460211\n",
      "roc auc test: 0.4248536109303839\n",
      "epoch: 17\n",
      "roc auc training: 0.5249357153367868\n",
      "roc auc test: 0.43300794334386067\n",
      "epoch: 18\n",
      "roc auc training: 0.5239579902386442\n",
      "roc auc test: 0.4272524520971726\n",
      "epoch: 19\n",
      "roc auc training: 0.5242436480395676\n",
      "roc auc test: 0.43276868599866014\n",
      "epoch: 20\n",
      "roc auc training: 0.5228519195612432\n",
      "roc auc test: 0.4256145198170732\n",
      "epoch: 21\n",
      "roc auc training: 0.5217574232160507\n",
      "roc auc test: 0.4388474543754046\n",
      "epoch: 22\n",
      "roc auc training: 0.5226723464962053\n",
      "roc auc test: 0.43027410729274074\n",
      "epoch: 23\n",
      "roc auc training: 0.524511636951059\n",
      "roc auc test: 0.42958656330749356\n",
      "epoch: 24\n",
      "roc auc training: 0.524371108343711\n",
      "roc auc test: 0.4333413461538461\n",
      "epoch: 25\n",
      "roc auc training: 0.5206533965497031\n",
      "roc auc test: 0.42128380797784726\n",
      "epoch: 26\n",
      "roc auc training: 0.5266441097503768\n",
      "roc auc test: 0.4255257919854194\n",
      "epoch: 27\n",
      "roc auc training: 0.5253360793858828\n",
      "roc auc test: 0.41606852330366545\n",
      "epoch: 28\n",
      "roc auc training: 0.5219887421228498\n",
      "roc auc test: 0.43010432545731714\n",
      "epoch: 29\n",
      "roc auc training: 0.5225650627223367\n",
      "roc auc test: 0.43138144231457826\n",
      "epoch: 30\n",
      "roc auc training: 0.5246778652773203\n",
      "roc auc test: 0.4206575697258927\n",
      "epoch: 31\n",
      "roc auc training: 0.5264124885325675\n",
      "roc auc test: 0.4326682692307693\n",
      "epoch: 32\n",
      "roc auc training: 0.5234003054166542\n",
      "roc auc test: 0.4323140970427791\n",
      "epoch: 33\n",
      "roc auc training: 0.5258323336268023\n",
      "roc auc test: 0.4345703125\n",
      "epoch: 34\n",
      "roc auc training: 0.5257787111143257\n",
      "roc auc test: 0.4249399038461539\n",
      "epoch: 35\n",
      "roc auc training: 0.5257949225715861\n",
      "roc auc test: 0.4290270749898079\n",
      "epoch: 36\n",
      "roc auc training: 0.5246583036884478\n",
      "roc auc test: 0.4265163015976289\n",
      "epoch: 37\n",
      "roc auc training: 0.5269933389174744\n",
      "roc auc test: 0.43152113959567373\n",
      "epoch: 38\n",
      "roc auc training: 0.5282577833125779\n",
      "roc auc test: 0.4333189778926213\n",
      "epoch: 39\n",
      "roc auc training: 0.5288835823576968\n",
      "roc auc test: 0.42780409608574976\n",
      "epoch: 40\n",
      "roc auc training: 0.5293651625395495\n",
      "roc auc test: 0.4173481378450322\n",
      "epoch: 41\n",
      "roc auc training: 0.5298178173985881\n",
      "roc auc test: 0.4197462768891341\n",
      "epoch: 42\n",
      "roc auc training: 0.5287603722150587\n",
      "roc auc test: 0.4219165927240461\n",
      "epoch: 43\n",
      "roc auc training: 0.5283991761842353\n",
      "roc auc test: 0.4320966929662582\n",
      "epoch: 44\n",
      "roc auc training: 0.5305057145140666\n",
      "roc auc test: 0.4263767149390244\n",
      "epoch: 45\n",
      "roc auc training: 0.5272165426698026\n",
      "roc auc test: 0.43121521000506036\n",
      "epoch: 46\n",
      "roc auc training: 0.5297979054797219\n",
      "roc auc test: 0.4343295695972882\n",
      "epoch: 47\n",
      "roc auc training: 0.5317411052610586\n",
      "roc auc test: 0.4244921564375045\n",
      "epoch: 48\n",
      "roc auc training: 0.5305507359100156\n",
      "roc auc test: 0.4254680196653024\n",
      "epoch: 49\n",
      "roc auc training: 0.5325026923537154\n",
      "roc auc test: 0.42396700160675316\n",
      "epoch: 50\n",
      "roc auc training: 0.5325551002491576\n",
      "roc auc test: 0.42302884615384617\n",
      "epoch: 51\n",
      "roc auc training: 0.5319866578915879\n",
      "roc auc test: 0.4171451813570676\n",
      "epoch: 52\n",
      "roc auc training: 0.5322087915099958\n",
      "roc auc test: 0.4316600637742778\n",
      "epoch: 53\n",
      "roc auc training: 0.5331599123084866\n",
      "roc auc test: 0.4329600230221348\n",
      "epoch: 54\n",
      "roc auc training: 0.5347823050696967\n",
      "roc auc test: 0.428389423076923\n",
      "epoch: 55\n",
      "roc auc training: 0.5347350683392623\n",
      "roc auc test: 0.430304335343095\n",
      "epoch: 56\n",
      "roc auc training: 0.5321211320086494\n",
      "roc auc test: 0.4362989663650904\n",
      "epoch: 57\n",
      "roc auc training: 0.5311201246803069\n",
      "roc auc test: 0.426998240921468\n",
      "epoch: 58\n",
      "roc auc training: 0.536741074547614\n",
      "roc auc test: 0.4205136813832466\n",
      "epoch: 59\n",
      "roc auc training: 0.5369338578437238\n",
      "roc auc test: 0.42610134535600375\n",
      "epoch: 60\n",
      "roc auc training: 0.5372826105933144\n",
      "roc auc test: 0.4308307015025361\n",
      "epoch: 61\n",
      "roc auc training: 0.5377702013462992\n",
      "roc auc test: 0.42836538461538465\n",
      "epoch: 62\n",
      "roc auc training: 0.5360519253572988\n",
      "roc auc test: 0.430323622255958\n",
      "epoch: 63\n",
      "roc auc training: 0.5371794104742531\n",
      "roc auc test: 0.4281637449339313\n",
      "epoch: 64\n",
      "roc auc training: 0.5344446771169877\n",
      "roc auc test: 0.41737980769230776\n",
      "epoch: 65\n",
      "roc auc training: 0.5387952642592237\n",
      "roc auc test: 0.424606242149\n",
      "epoch: 66\n",
      "roc auc training: 0.5382862670017152\n",
      "roc auc test: 0.42892268028932223\n",
      "epoch: 67\n",
      "roc auc training: 0.5392772888972103\n",
      "roc auc test: 0.4306454729925596\n",
      "epoch: 68\n",
      "roc auc training: 0.5389917633919667\n",
      "roc auc test: 0.4226480251324972\n",
      "epoch: 69\n",
      "roc auc training: 0.5368982742960944\n",
      "roc auc test: 0.43085375551218097\n",
      "epoch: 70\n",
      "roc auc training: 0.5399291013521599\n",
      "roc auc test: 0.42818775995246583\n",
      "epoch: 71\n",
      "roc auc training: 0.5369272055687603\n",
      "roc auc test: 0.4280918007626082\n",
      "epoch: 72\n",
      "roc auc training: 0.5404705735505212\n",
      "roc auc test: 0.42764857881136953\n",
      "epoch: 73\n",
      "roc auc training: 0.540248060236787\n",
      "roc auc test: 0.43638147191118765\n",
      "epoch: 74\n",
      "roc auc training: 0.5384121594671134\n",
      "roc auc test: 0.4267265044997732\n",
      "epoch: 75\n",
      "roc auc training: 0.5403095791627109\n",
      "roc auc test: 0.42132904865824117\n",
      "epoch: 76\n",
      "roc auc training: 0.5432253635399114\n",
      "roc auc test: 0.4363237668377552\n",
      "epoch: 77\n",
      "roc auc training: 0.5412627646326276\n",
      "roc auc test: 0.43531019928535464\n",
      "epoch: 78\n",
      "roc auc training: 0.5426872174147378\n",
      "roc auc test: 0.43571788292285185\n",
      "epoch: 79\n",
      "roc auc training: 0.539654471494023\n",
      "roc auc test: 0.43487415063642454\n",
      "epoch: 80\n",
      "roc auc training: 0.5473906259751606\n",
      "roc auc test: 0.4340846013972629\n",
      "epoch: 81\n",
      "roc auc training: 0.5445809149347813\n",
      "roc auc test: 0.4272764334876136\n",
      "epoch: 82\n",
      "roc auc training: 0.5440099626400996\n",
      "roc auc test: 0.4351628176635423\n",
      "epoch: 83\n",
      "roc auc training: 0.5445253908831753\n",
      "roc auc test: 0.4346109675567039\n",
      "epoch: 84\n",
      "roc auc training: 0.5470942833413559\n",
      "roc auc test: 0.43408460139726296\n",
      "epoch: 85\n",
      "roc auc training: 0.5481505221336274\n",
      "roc auc test: 0.4349502397648136\n",
      "epoch: 86\n",
      "roc auc training: 0.5450727079822756\n",
      "roc auc test: 0.4443341163934029\n",
      "epoch: 87\n",
      "roc auc training: 0.54799582796858\n",
      "roc auc test: 0.43198631292320294\n",
      "epoch: 88\n",
      "roc auc training: 0.5436035698683144\n",
      "roc auc test: 0.44225162052097644\n",
      "epoch: 89\n",
      "roc auc training: 0.544805671168069\n",
      "roc auc test: 0.4377709428204693\n",
      "epoch: 90\n",
      "roc auc training: 0.5458672007302638\n",
      "roc auc test: 0.4348428063307154\n",
      "epoch: 91\n",
      "roc auc training: 0.5522366127023661\n",
      "roc auc test: 0.44394230769230775\n",
      "epoch: 92\n",
      "roc auc training: 0.546590119082326\n",
      "roc auc test: 0.4390226270512543\n",
      "epoch: 93\n",
      "roc auc training: 0.5449697858083045\n",
      "roc auc test: 0.4385826394870323\n",
      "epoch: 94\n",
      "roc auc training: 0.5494638956500032\n",
      "roc auc test: 0.43497445981918026\n",
      "epoch: 95\n",
      "roc auc training: 0.5507046121200775\n",
      "roc auc test: 0.4346072084259349\n",
      "epoch: 96\n",
      "roc auc training: 0.5463907502692354\n",
      "roc auc test: 0.4351201923076924\n",
      "epoch: 97\n",
      "roc auc training: 0.5502951361659435\n",
      "roc auc test: 0.4410657329911988\n",
      "epoch: 98\n",
      "roc auc training: 0.5491168944642077\n",
      "roc auc test: 0.4319230769230769\n",
      "epoch: 99\n",
      "roc auc training: 0.5512718511738343\n",
      "roc auc test: 0.4404326923076923\n",
      "epoch: 100\n",
      "roc auc training: 0.5528290964258267\n",
      "roc auc test: 0.4384277800426869\n",
      "epoch: 101\n",
      "roc auc training: 0.5483414178918267\n",
      "roc auc test: 0.4297944794839206\n",
      "epoch: 102\n",
      "roc auc training: 0.5506436719716007\n",
      "roc auc test: 0.43637066383225437\n",
      "epoch: 103\n",
      "roc auc training: 0.5551259423238004\n",
      "roc auc test: 0.43572115384615384\n",
      "epoch: 104\n",
      "roc auc training: 0.5504336948910966\n",
      "roc auc test: 0.43858888165979903\n",
      "epoch: 105\n",
      "roc auc training: 0.5503253023156143\n",
      "roc auc test: 0.439453125\n",
      "epoch: 106\n",
      "roc auc training: 0.5531212043366895\n",
      "roc auc test: 0.4423721053519362\n",
      "epoch: 107\n",
      "roc auc training: 0.5493597362696508\n",
      "roc auc test: 0.4359647657014633\n",
      "epoch: 108\n",
      "roc auc training: 0.550617071393638\n",
      "roc auc test: 0.43608959447468765\n",
      "epoch: 109\n",
      "roc auc training: 0.5564476139928586\n",
      "roc auc test: 0.4411057692307693\n",
      "epoch: 110\n",
      "roc auc training: 0.5551157557952651\n",
      "roc auc test: 0.4458714282304075\n",
      "epoch: 111\n",
      "roc auc training: 0.5515947209923817\n",
      "roc auc test: 0.43535816206623656\n",
      "epoch: 112\n",
      "roc auc training: 0.5556240039306549\n",
      "roc auc test: 0.4439180782850034\n",
      "epoch: 113\n",
      "roc auc training: 0.5521631067767541\n",
      "roc auc test: 0.4474112355249306\n",
      "epoch: 114\n",
      "roc auc training: 0.5544966841334726\n",
      "roc auc test: 0.44540832309212275\n",
      "epoch: 115\n",
      "roc auc training: 0.5543786368037049\n",
      "roc auc test: 0.4342755247114388\n",
      "epoch: 116\n",
      "roc auc training: 0.5556574442814225\n",
      "roc auc test: 0.44989088467349336\n",
      "epoch: 117\n",
      "roc auc training: 0.552257837740816\n",
      "roc auc test: 0.4298975978562542\n",
      "epoch: 118\n",
      "roc auc training: 0.5566285963926856\n",
      "roc auc test: 0.43897443311887036\n",
      "epoch: 119\n",
      "roc auc training: 0.5577876099573265\n",
      "roc auc test: 0.44140587616039817\n",
      "epoch: 120\n",
      "roc auc training: 0.5553605114231817\n",
      "roc auc test: 0.4394349984412096\n",
      "epoch: 121\n",
      "roc auc training: 0.5586829156311446\n",
      "roc auc test: 0.44138195042587813\n",
      "epoch: 122\n",
      "roc auc training: 0.5568011846356349\n",
      "roc auc test: 0.44111369577208087\n",
      "epoch: 123\n",
      "roc auc training: 0.5585462287104623\n",
      "roc auc test: 0.4390949179498301\n",
      "epoch: 124\n",
      "roc auc training: 0.5544267777005325\n",
      "roc auc test: 0.4414298018949182\n",
      "epoch: 125\n",
      "roc auc training: 0.5569399946102944\n",
      "roc auc test: 0.44037706957603606\n",
      "epoch: 126\n",
      "roc auc training: 0.5561311141304347\n",
      "roc auc test: 0.44322405813089044\n",
      "epoch: 127\n",
      "roc auc training: 0.5577464577965886\n",
      "roc auc test: 0.4423721053519361\n",
      "epoch: 128\n",
      "roc auc training: 0.5598307233184617\n",
      "roc auc test: 0.4392876936793658\n",
      "epoch: 129\n",
      "roc auc training: 0.5558335058398657\n",
      "roc auc test: 0.44902246305889093\n",
      "epoch: 130\n",
      "roc auc training: 0.5605298403046757\n",
      "roc auc test: 0.4388701923076923\n",
      "epoch: 131\n",
      "roc auc training: 0.5578869359523311\n",
      "roc auc test: 0.44394200401952344\n",
      "epoch: 132\n",
      "roc auc training: 0.5583386382075767\n",
      "roc auc test: 0.4430806775768016\n",
      "epoch: 133\n",
      "roc auc training: 0.5602923416274915\n",
      "roc auc test: 0.4444950718242643\n",
      "epoch: 134\n",
      "roc auc training: 0.5569736802706831\n",
      "roc auc test: 0.4477884615384615\n",
      "epoch: 135\n",
      "roc auc training: 0.5583237858032378\n",
      "roc auc test: 0.4471929655039134\n",
      "epoch: 136\n",
      "roc auc training: 0.5606915790839497\n",
      "roc auc test: 0.44533603219354684\n",
      "epoch: 137\n",
      "roc auc training: 0.5584046970286752\n",
      "roc auc test: 0.44661057692307693\n",
      "epoch: 138\n",
      "roc auc training: 0.561305623166698\n",
      "roc auc test: 0.4415506910792294\n",
      "epoch: 139\n",
      "roc auc training: 0.5623506487357937\n",
      "roc auc test: 0.44315211395956733\n",
      "epoch: 140\n",
      "roc auc training: 0.5627206234294604\n",
      "roc auc test: 0.446348104773609\n",
      "epoch: 141\n",
      "roc auc training: 0.5632594683814688\n",
      "roc auc test: 0.44008289356370034\n",
      "epoch: 142\n",
      "roc auc training: 0.5635127777333759\n",
      "roc auc test: 0.44241075701024024\n",
      "epoch: 143\n",
      "roc auc training: 0.5614000333898967\n",
      "roc auc test: 0.44315245478036175\n",
      "epoch: 144\n",
      "roc auc training: 0.5630458324600014\n",
      "roc auc test: 0.4467546728414218\n",
      "epoch: 145\n",
      "roc auc training: 0.5636891228909896\n",
      "roc auc test: 0.4423076923076923\n",
      "epoch: 146\n",
      "roc auc training: 0.5625740971357409\n",
      "roc auc test: 0.4406197035162684\n",
      "epoch: 147\n",
      "roc auc training: 0.5604308271202003\n",
      "roc auc test: 0.4472529317249814\n",
      "epoch: 148\n",
      "roc auc training: 0.5645041414038124\n",
      "roc auc test: 0.43750598143363\n",
      "epoch: 149\n",
      "roc auc training: 0.5657356948228883\n",
      "roc auc test: 0.4467818501650642\n",
      "epoch: 150\n",
      "roc auc training: 0.5639215442092154\n",
      "roc auc test: 0.45507086500875327\n",
      "maximum roc auc for test set 0.45507086500875327\n"
     ]
    }
   ],
   "source": [
    "training_dataset = Dataset(df_training, vocabulary)\n",
    "test_dataset = Dataset(df_test, vocabulary)\n",
    "\n",
    "print(f\"dimensions of embedding {n_embedding}, dimensions of hidden {n_hidden}, number of layers {n_layers}\")\n",
    "\n",
    "model = Classifier(n_embedding, n_hidden, n_layers, vocabulary)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.model.parameters(), lr = learning_rate, momentum=momentum)\n",
    "training_dataloader = torch.utils.data.DataLoader(training_dataset, batch_size=batch_size, shuffle=True, collate_fn = collate_fn, drop_last=True, pin_memory=True, num_workers=4)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, collate_fn = collate_fn, drop_last=True, pin_memory=True, num_workers=4)\n",
    "\n",
    "filename = folder + \"/models/RNN-classifier-fool/hem_em{}_hi{}_la{}_ep{{}}\".format(n_embedding, n_hidden, n_layers)\n",
    "model, optimizer, roc_training, roc_test = training(model, test_dataloader, training_dataloader, n_epoch, optimizer, filename)\n",
    "\n",
    "print(f\"maximum roc auc for test set {max(roc_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "roc_test = np.array(roc_test)\n",
    "epoch = np.argmax(roc_test) + 1\n",
    "print(epoch)\n",
    "training_dataset = Dataset(df_training, vocabulary)\n",
    "test_dataset = Dataset(df_test, vocabulary)\n",
    "\n",
    "filename = folder + \"models/RNN-classifier-fool/hem_em{}_hi{}_la{}_ep{}\".format(n_embedding, n_hidden, n_layers, epoch)\n",
    "\n",
    "model = Classifier.load_from_file(filename)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "training_dataloader_eval = torch.utils.data.DataLoader(training_dataset, batch_size=1, shuffle=False, collate_fn = collate_fn, drop_last=True, pin_memory=True, num_workers=4)\n",
    "test_dataloader_eval = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, collate_fn = collate_fn, drop_last=True, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_loader):\n",
    "    cat_list = []\n",
    "    out_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(data_loader):    \n",
    "            seq_batched = sample_batched[0][0].to(model.device, non_blocking=True)\n",
    "            seq_lengths = sample_batched[0][1].to(model.device, non_blocking=True)\n",
    "\n",
    "            cat_list += sample_batched[1].to(\"cpu\", non_blocking=True)\n",
    "            out_list += torch.exp(model.evaluate(seq_batched, seq_lengths))[: ,1].to(\"cpu\", non_blocking=True)\n",
    "\n",
    "        cat_list = torch.stack(cat_list)\n",
    "        out_list = torch.stack(out_list)\n",
    "    return cat_list.cpu().numpy().astype(int), out_list.cpu().numpy()\n",
    "\n",
    "def roc(y_true, y_score):\n",
    "    fpr, tpr, thresh = roc_curve(y_true, y_score)\n",
    "    roc = roc_auc_score(y_true, y_score)\n",
    "    return roc, fpr, tpr\n",
    "                \n",
    "def find_threshold(y_true, y_score, alpha = 0.049):\n",
    "    fpr, tpr, thresh = roc_curve(y_true, y_score)\n",
    "    for i, fp in enumerate(fpr):\n",
    "        if fp > alpha:\n",
    "            return thresh[i-1]\n",
    "        \n",
    "def calc_metrics(y_true, y_score, threshold = 0.5):\n",
    "    y_score = y_score > threshold\n",
    "    accuracy = accuracy_score(y_true, y_score)\n",
    "    f1 = f1_score(y_true, y_score)\n",
    "    mcc = matthews_corrcoef(y_true, y_score)\n",
    "    precision = precision_score(y_true, y_score)\n",
    "    recall = recall_score(y_true, y_score)\n",
    "    return accuracy, f1, mcc, precision, recall\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_score = predict(test_dataloader_eval)\n",
    "threshold = find_threshold(y_true, y_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49841443"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6078886310904872\n",
      "f1 score: 0.09625668449197859\n",
      "mcc: 0.012529783364402296\n",
      "precision: 0.4090909090909091\n",
      "recall: 0.05454545454545454\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1, mcc, precision, recall = calc_metrics(y_true, y_score, threshold)\n",
    "print(f\"accuracy: {accuracy}\\nf1 score: {f1}\\nmcc: {mcc}\\nprecision: {precision}\\nrecall: {recall}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy: 0.6078886310904872\n",
    "f1 score: 0.09625668449197859\n",
    "mcc: 0.012529783364402296\n",
    "precision: 0.4090909090909091\n",
    "recall: 0.05454545454545454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.6078886310904872\n",
      "f1 score: 0.09625668449197859\n",
      "mcc: 0.012529783364402296\n",
      "precision: 0.4090909090909091\n",
      "recall: 0.05454545454545454\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1, mcc, precision, recall = calc_metrics(y_true, y_score, 0.5)\n",
    "print(f\"accuracy: {accuracy}\\nf1 score: {f1}\\nmcc: {mcc}\\nprecision: {precision}\\nrecall: {recall}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy: 0.6078886310904872\n",
    "f1 score: 0.09625668449197859\n",
    "mcc: 0.012529783364402296\n",
    "precision: 0.4090909090909091\n",
    "recall: 0.05454545454545454"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_true, Y_score = predict(training_dataloader_eval) \n",
    "roc_training, fpr_training, tpr_training = roc(Y_true, Y_score)\n",
    "y_true, y_score = predict(test_dataloader_eval)\n",
    "roc_test, fpr_test, tpr_test = roc(y_true, y_score)    \n",
    "\n",
    "with open(\"/data/AIpep/auc_files/fool_classifier_hem.pkl\",\"bw\") as fd:\n",
    "        pickle.dump((fpr_test, tpr_test), fd)\n",
    "\n",
    "plt.figure()\n",
    "name = \"RNN fool-classifier\"\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "lw = 2\n",
    "plt.plot(fpr_training, tpr_training, color='blue',\n",
    "         lw=lw, label='Training Set ROC AUC = %0.2f' % roc_training)\n",
    "plt.plot(fpr_test, tpr_test, color='darkorange',\n",
    "         lw=lw, label='Test Set ROC AUC = %0.2f' % roc_test)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([-0.005, 1.0])\n",
    "plt.ylim([-0.005, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title(name)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(folder+\"plots/RNN-fool-classifier.svg\")\n",
    "plt.savefig(\"plots/RNN-fool-classifier.svg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
