{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_dir='/home/luca/Recommender Systems/recsys-challenge-2021-twitter/Utils/Preprocessing', parent_dir='/home/luca/Recommender Systems/recsys-challenge-2021-twitter/Utils', /home/luca/Recommender Systems/recsys-challenge-2021-twitter\n"
     ]
    }
   ],
   "source": [
    "# fix jupyter notebook python path\n",
    "import os,sys,inspect\n",
    "\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "root_dir = os.path.dirname(parent_dir)\n",
    "sys.path.insert(0, root_dir) \n",
    "\n",
    "print(f\"{current_dir=}, {parent_dir=}, {root_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import RootPath\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import itertools\n",
    "import sys\n",
    "import gzip\n",
    "import pickle\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Launch client to monitor status\n",
    "Very nice visualization of resource management at the dashboard!q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#from dask.distributed import Client,wait,LocalCluster\n",
    "\n",
    "#import psutil\n",
    "#dict(psutil.virtual_memory()._asdict())\n",
    "\n",
    "# i have only 8GB, so i try to leave some free space\n",
    "# each worker seem to need like 3 GB, to load one of the CSVs (1.4GB), keep in memory a dict ~500MB, and be able to still do things\n",
    "cluster = LocalCluster(\n",
    "   n_workers=1, threads_per_worker=8, memory_limit=\"6GB\"\n",
    ")\n",
    "client = Client(cluster) # use default n_threads and mem\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "client.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some extra functions that may be useful to investigate memory in workers\n",
    "# def collect():\n",
    "#     import gc\n",
    "#     gc.collect()\n",
    "#\n",
    "# def investigate_df(type_to_investigate: type = pd.DataFrame):\n",
    "#     return [sys.getsizeof(obj) for obj in gc.get_objects() if isinstance(obj, type_to_investigate)]\n",
    "#\n",
    "# def investigate():\n",
    "#     return sum([sys.getsizeof(obj) for obj in gc.get_objects()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load data with correct labels and type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# all_features = [\n",
    "#     \"raw_feature_tweet_text_token\",\n",
    "#     \"raw_feature_tweet_hashtags\",\n",
    "#     \"raw_feature_tweet_id\",\n",
    "#     \"raw_feature_tweet_media\",\n",
    "#     \"raw_feature_tweet_links\",\n",
    "#     \"raw_feature_tweet_domains\",\n",
    "#     \"raw_feature_tweet_type\",\n",
    "#     \"raw_feature_tweet_language\",\n",
    "#     \"raw_feature_tweet_timestamp\",\n",
    "#     \"raw_feature_creator_id\",\n",
    "#     \"raw_feature_creator_follower_count\",\n",
    "#     \"raw_feature_creator_following_count\",\n",
    "#     \"raw_feature_creator_is_verified\",\n",
    "#     \"raw_feature_creator_creation_timestamp\",\n",
    "#     \"raw_feature_engager_id\",\n",
    "#     \"raw_feature_engager_follower_count\",\n",
    "#     \"raw_feature_engager_following_count\",\n",
    "#     \"raw_feature_engager_is_verified\",\n",
    "#     \"raw_feature_engager_creation_timestamp\",\n",
    "#     \"raw_feature_engagement_creator_follows_engager\"\n",
    "#     ]\n",
    "\n",
    "all_features_dtype = {\n",
    "    \"raw_feature_tweet_text_token\": pd.StringDtype(),\n",
    "    \"raw_feature_tweet_hashtags\": pd.StringDtype(),\n",
    "    \"raw_feature_tweet_id\": pd.StringDtype(),\n",
    "    \"raw_feature_tweet_media\": pd.StringDtype(),\n",
    "    \"raw_feature_tweet_links\": pd.StringDtype(),\n",
    "    \"raw_feature_tweet_domains\": pd.StringDtype(),\n",
    "    \"raw_feature_tweet_type\": pd.StringDtype(),\n",
    "    \"raw_feature_tweet_language\": pd.StringDtype(),\n",
    "    \"tweet_timestamp\": pd.Int64Dtype(),\n",
    "    \"raw_feature_creator_id\": pd.StringDtype(),\n",
    "    \"creator_follower_count\": pd.UInt32Dtype(),\n",
    "    \"creator_following_count\": pd.UInt32Dtype(),\n",
    "    \"creator_is_verified\": pd.BooleanDtype(),\n",
    "    \"creator_creation_timestamp\": pd.Int64Dtype(),\n",
    "    \"raw_feature_engager_id\": pd.StringDtype(),\n",
    "    \"engager_follower_count\": pd.UInt32Dtype(),\n",
    "    \"engager_following_count\": pd.UInt32Dtype(),\n",
    "    \"engager_is_verified\": pd.BooleanDtype(),\n",
    "    \"engager_creation_timestamp\": pd.Int64Dtype(),\n",
    "    \"engagement_creator_follows_engager\": pd.BooleanDtype(),\n",
    "    \"engagement_reply_timestamp\": pd.Int64Dtype(),\n",
    "    \"engagement_retweet_timestamp\": pd.Int64Dtype(),\n",
    "    \"engagement_comment_timestamp\": pd.Int64Dtype(),\n",
    "    \"engagement_like_timestamp\": pd.Int64Dtype()\n",
    "}\n",
    "# all_labels = [\n",
    "#     \"engagement_reply_timestamp\",\n",
    "#     \"engagement_retweet_timestamp\",\n",
    "#     \"engagement_comment_timestamp\",\n",
    "#     \"engagement_like_timestamp\"\n",
    "# ]\n",
    "# all_labels_dtype = {\n",
    "#     \"engagement_reply_timestamp\": pd.Int32Dtype(),\n",
    "#     \"engagement_retweet_timestamp\": pd.Int32Dtype(),\n",
    "#     \"engagement_comment_timestamp\": pd.Int32Dtype(),\n",
    "#     \"engagement_like_timestamp\": pd.Int32Dtype()\n",
    "# }\n",
    "\n",
    "# mapped_features_dtype = {\n",
    "#     \"decoded_tweet_text_token\": pd.StringDtype(),\n",
    "#     \"mapped_tweet_hashtags\": 'O',\n",
    "#     \"mapped_tweet_id\": pd.UInt32Dtype(),\n",
    "#     \"number_of_photo\": pd.UInt8Dtype(),\n",
    "#     \"number_of_gif\": pd.UInt8Dtype(),\n",
    "#     \"number_of_video\": pd.UInt8Dtype(),\n",
    "#     \"mapped_tweet_links\": 'O',\n",
    "#     \"mapped_tweet_domains\": 'O',\n",
    "#     \"mapped_tweet_type\": pd.UInt8Dtype(),\n",
    "#     \"mapped_tweet_language\": pd.UInt8Dtype(),\n",
    "#     \"tweet_timestamp\": pd.UInt32Dtype(),\n",
    "#     \"mapped_creator_id\": pd.UInt32Dtype() ,\n",
    "#     \"creator_follower_count\": pd.UInt8Dtype(),\n",
    "#     \"creator_following_count\": pd.UInt8Dtype(),\n",
    "#     \"creator_is_verified\": pd.BooleanDtype(),\n",
    "#     \"creator_creation_timestamp\": pd.UInt32Dtype(),\n",
    "#     \"mapped_engager_id\": pd.UInt32Dtype(),\n",
    "#     \"engager_follower_count\": pd.UInt8Dtype(),\n",
    "#     \"engager_following_count\": pd.UInt8Dtype(),\n",
    "#     \"engager_is_verified\": pd.BooleanDtype(),\n",
    "#     \"engager_creation_timestamp\": pd.UInt32Dtype(),\n",
    "#     \"engagement_creator_follows_engager\": pd.BooleanDtype(),\n",
    "#     \"engagement_reply_timestamp\": pd.UInt32Dtype(),\n",
    "#     \"engagement_retweet_timestamp\": pd.UInt32Dtype(),\n",
    "#     \"engagement_comment_timestamp\": pd.UInt32Dtype(),\n",
    "#     \"engagement_like_timestamp\": pd.UInt32Dtype()\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "original_dataset_path = f\"{RootPath.get_dataset_path()}/part-*\"\n",
    "#original_dataset_path = f\"{RootPath.get_dataset_path()}/part-00000\"\n",
    "dataset_path = f\"{RootPath.get_dataset_path()}/Temp/full_dataset\"\n",
    "output_path = f\"{RootPath.get_dataset_path()}/Preprocessed/dataset.tsv\"\n",
    "temp_output_path = f\"{RootPath.get_dataset_path()}/Preprocessed/Temp/\"\n",
    "dict_path = f\"{RootPath.get_dataset_path()}/Preprocessed/Dictionary/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_dict_feature(series: dask.dataframe.Series, out_type: type) -> (dict,pd.DataFrame):\n",
    "    feature_name = series.name\n",
    "    feature_name_encode = feature_name + \"_encode\"\n",
    "\n",
    "    mapping = series.drop_duplicates().to_frame() #create a dataframe from a series\n",
    "    mapping[feature_name_encode] = 1\n",
    "    mapping[feature_name_encode] = mapping[feature_name_encode].cumsum()\n",
    "    mapping[feature_name_encode] = mapping[feature_name_encode].astype(out_type)\n",
    "    mapping, = dask.compute(mapping)\n",
    "\n",
    "    # define mapping dicts\n",
    "    direct_dict = dict(zip(mapping[feature_name], mapping[feature_name_encode]))\n",
    "\n",
    "    return direct_dict, mapping\n",
    "\n",
    "def create_dict_feature_to_split(series: dask.dataframe.Series, sep: str, out_type: type) -> (dict,pd.DataFrame):\n",
    "    feature_name = series.name\n",
    "    feature_name_encode = feature_name + \"_encode\"\n",
    "\n",
    "    #map partition internal function goes from series to dataframe\n",
    "    mapping = series\\\n",
    "        .map_partitions(lambda s: pd.DataFrame([hashtag for line in s.dropna() for hashtag in line.split(sep)], columns=[feature_name]),\n",
    "                       meta={feature_name:pd.StringDtype()})\\\n",
    "        .drop_duplicates()\n",
    "    mapping[feature_name_encode] = 1\n",
    "    mapping[feature_name_encode] = mapping[feature_name_encode].cumsum()\n",
    "    mapping[feature_name_encode] = mapping[feature_name_encode].astype(out_type)\n",
    "    mapping, = dask.compute(mapping)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # define mapping dicts\n",
    "    direct_dict = dict(zip(mapping[feature_name], mapping[feature_name_encode]))\n",
    "    # manage nans\n",
    "    #direct_dict[pd.NA] = None\n",
    "    #inverse_dict[None] = pd.NA\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    return direct_dict, mapping\n",
    "\n",
    "\n",
    "def map_column_single_value(series: dask.dataframe.Series, dictionary: dict, name_out:str, out_type: type) -> dask.dataframe.Series:\n",
    "    return series\\\n",
    "        .apply(lambda x: dictionary[x], # if x is not pd.NA else None, #Nans to be managed outside, manual entry in dict if you like\n",
    "               meta=pd.Series(dtype=out_type, name=name_out))\n",
    "\n",
    "\n",
    "def map_column_array(series: dask.dataframe.Series, dictionary: dict, sep: str, name_out:str, out_type: type, nan_symbol) -> dask.dataframe.Series:\n",
    "    return series\\\n",
    "        .apply(lambda x: np.array([dictionary[y] for y in x.split(sep)], dtype=out_type)\n",
    "                                    if x is not nan_symbol else np.array([]),\n",
    "               meta=pd.Series(dtype='O', name=name_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create intermediate parquet full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.28 ms, sys: 9.58 ms, total: 18.9 ms\n",
      "Wall time: 24.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read data\n",
    "df = dd.read_csv(original_dataset_path,\n",
    "                 sep='\\x01',\n",
    "                 names=all_features_dtype.keys(),\n",
    "                 dtype=all_features_dtype,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 4s, sys: 10.4 s, total: 2min 15s\n",
      "Wall time: 1min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Write to parquet\n",
    "df.to_parquet(dataset_path, write_index=False, compression=\"snappy\", engine=\"pyarrow\", overwrite=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_feature_tweet_text_token</th>\n",
       "      <th>raw_feature_tweet_hashtags</th>\n",
       "      <th>raw_feature_tweet_id</th>\n",
       "      <th>raw_feature_tweet_media</th>\n",
       "      <th>raw_feature_tweet_links</th>\n",
       "      <th>raw_feature_tweet_domains</th>\n",
       "      <th>raw_feature_tweet_type</th>\n",
       "      <th>raw_feature_tweet_language</th>\n",
       "      <th>tweet_timestamp</th>\n",
       "      <th>raw_feature_creator_id</th>\n",
       "      <th>creator_follower_count</th>\n",
       "      <th>creator_following_count</th>\n",
       "      <th>creator_is_verified</th>\n",
       "      <th>creator_creation_timestamp</th>\n",
       "      <th>raw_feature_engager_id</th>\n",
       "      <th>engager_follower_count</th>\n",
       "      <th>engager_following_count</th>\n",
       "      <th>engager_is_verified</th>\n",
       "      <th>engager_creation_timestamp</th>\n",
       "      <th>engagement_creator_follows_engager</th>\n",
       "      <th>engagement_reply_timestamp</th>\n",
       "      <th>engagement_retweet_timestamp</th>\n",
       "      <th>engagement_comment_timestamp</th>\n",
       "      <th>engagement_like_timestamp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=48</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>string</td>\n",
       "      <td>Int64</td>\n",
       "      <td>string</td>\n",
       "      <td>UInt32</td>\n",
       "      <td>UInt32</td>\n",
       "      <td>boolean</td>\n",
       "      <td>Int64</td>\n",
       "      <td>string</td>\n",
       "      <td>UInt32</td>\n",
       "      <td>UInt32</td>\n",
       "      <td>boolean</td>\n",
       "      <td>Int64</td>\n",
       "      <td>boolean</td>\n",
       "      <td>Int64</td>\n",
       "      <td>Int64</td>\n",
       "      <td>Int64</td>\n",
       "      <td>Int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: read-parquet, 48 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               raw_feature_tweet_text_token raw_feature_tweet_hashtags raw_feature_tweet_id raw_feature_tweet_media raw_feature_tweet_links raw_feature_tweet_domains raw_feature_tweet_type raw_feature_tweet_language tweet_timestamp raw_feature_creator_id creator_follower_count creator_following_count creator_is_verified creator_creation_timestamp raw_feature_engager_id engager_follower_count engager_following_count engager_is_verified engager_creation_timestamp engagement_creator_follows_engager engagement_reply_timestamp engagement_retweet_timestamp engagement_comment_timestamp engagement_like_timestamp\n",
       "npartitions=48                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     \n",
       "                                     string                     string               string                  string                  string                    string                 string                     string           Int64                 string                 UInt32                  UInt32             boolean                      Int64                 string                 UInt32                  UInt32             boolean                      Int64                            boolean                      Int64                        Int64                        Int64                     Int64\n",
       "                                        ...                        ...                  ...                     ...                     ...                       ...                    ...                        ...             ...                    ...                    ...                     ...                 ...                        ...                    ...                    ...                     ...                 ...                        ...                                ...                        ...                          ...                          ...                       ...\n",
       "...                                     ...                        ...                  ...                     ...                     ...                       ...                    ...                        ...             ...                    ...                    ...                     ...                 ...                        ...                    ...                    ...                     ...                 ...                        ...                                ...                        ...                          ...                          ...                       ...\n",
       "                                        ...                        ...                  ...                     ...                     ...                       ...                    ...                        ...             ...                    ...                    ...                     ...                 ...                        ...                    ...                    ...                     ...                 ...                        ...                                ...                        ...                          ...                          ...                       ...\n",
       "                                        ...                        ...                  ...                     ...                     ...                       ...                    ...                        ...             ...                    ...                    ...                     ...                 ...                        ...                    ...                    ...                     ...                 ...                        ...                                ...                        ...                          ...                          ...                       ...\n",
       "Dask Name: read-parquet, 48 tasks"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dd.read_parquet(dataset_path,\n",
    "                     engine='pyarrow')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                <NA>\n",
       "1    9EFF000CDB18B710CDDB43EE1D8C300B\n",
       "2    D56FA7843AF6F2BC53A2E192B542EA58\n",
       "3                                <NA>\n",
       "4                                <NA>\n",
       "5                                <NA>\n",
       "6                                <NA>\n",
       "7                                <NA>\n",
       "8                                <NA>\n",
       "9    F595B7DE8992A3D8C7948B4E81419D78\n",
       "Name: raw_feature_tweet_domains, dtype: string"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"raw_feature_tweet_domains\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Map creator_id, engager_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.3 ms, sys: 0 ns, total: 12.3 ms\n",
      "Wall time: 11.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load dataset\n",
    "df = dd.read_parquet(dataset_path,\n",
    "                     columns= [\n",
    "                         \"raw_feature_creator_id\",\n",
    "                         \"raw_feature_engager_id\"\n",
    "                     ],\n",
    "                     engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23 s, sys: 1.42 s, total: 24.4 s\n",
      "Wall time: 22.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create Dict\n",
    "dir_user_id, _ = create_dict_feature(df[\"raw_feature_creator_id\"].append(df[\"raw_feature_engager_id\"]).rename(\"raw_user_id\"), np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Map the feature\n",
    "out_creator_id = map_column_single_value(df[\"raw_feature_creator_id\"],\n",
    "                                         dir_user_id,\n",
    "                                         \"mapped_creator_id\",\n",
    "                                         np.uint32)\\\n",
    "    .to_frame()\n",
    "\n",
    "out_engager_id = map_column_single_value(df[\"raw_feature_engager_id\"],\n",
    "                                         dir_user_id,\n",
    "                                         \"mapped_engager_id\",\n",
    "                                         np.uint32)\\\n",
    "    .to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.3 s, sys: 1.59 s, total: 20.9 s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Write the output dataset\n",
    "out_creator_id.to_parquet(temp_output_path+\"mapped_creator_id\", write_index=False, compression=\"snappy\", engine=\"pyarrow\", overwrite=\"True\")\n",
    "out_engager_id.to_parquet(temp_output_path+\"mapped_engager_id\", write_index=False, compression=\"snappy\", engine=\"pyarrow\", overwrite=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.4 s, sys: 244 ms, total: 34.6 s\n",
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Write the dicts\n",
    "with gzip.GzipFile(dict_path + \"mapped_user_id\" + \"_dict\", 'wb') as file:\n",
    "    pickle.dump(dir_user_id, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mapped_engager_id    16\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_engager_id.min().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mapped_engager_id    5780065\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_engager_id.max().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean variables\n",
    "del dir_user_id, out_creator_id, out_engager_id, df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.7 ms, sys: 340 µs, total: 15 ms\n",
      "Wall time: 13.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load dataset\n",
    "df = dd.read_parquet(dataset_path,\n",
    "                     columns= [\n",
    "                             \"raw_feature_tweet_media\"\n",
    "                     ],\n",
    "                     engine='pyarrow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.1 ms, sys: 0 ns, total: 4.1 ms\n",
      "Wall time: 3.55 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create Dict\n",
    "media_dict = {\n",
    "    \"Photo\":0,\n",
    "    \"GIF\": 1,\n",
    "    \"Video\": 2\n",
    "}\n",
    "\n",
    "columns_types = {\n",
    "    \"number_of_photo\": np.uint8,\n",
    "    \"number_of_gif\": np.uint8,\n",
    "    \"number_of_video\": np.uint8,\n",
    "}\n",
    "\n",
    "# Map the feature\n",
    "\n",
    "#Function mapping each list of splitted strings into the 3 counting columns\n",
    "def count_media_types(vec: List[str]) -> List[int]:\n",
    "    ret = [0 for _ in range(3)]\n",
    "    for x in vec:\n",
    "        if x != \"\":\n",
    "            ret[media_dict[x]] +=1\n",
    "    return ret\n",
    "\n",
    "#Function responsible of mapping count_media_types and collecting result in a coherent pd.Dataframe\n",
    "def to_map_on_media_col(media_col: pd.Series) -> pd.DataFrame:\n",
    "    return pd.DataFrame(media_col.map(count_media_types).to_list(), columns=columns_types.keys())\n",
    "\n",
    "#Function mapping each big raw string into the list of splitted strings and calling next funcs\n",
    "out_media = df['raw_feature_tweet_media']\\\n",
    "    .fillna(\"\")\\\n",
    "    .map_partitions(lambda s: to_map_on_media_col(s.str.split(\"\\t\")),\n",
    "                    meta=columns_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.4 s, sys: 384 ms, total: 14.7 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Write the output dataset\n",
    "out_media.to_parquet(temp_output_path+\"counted_media\", write_index=False, compression=\"snappy\", engine=\"pyarrow\", overwrite=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_of_photo</th>\n",
       "      <th>number_of_gif</th>\n",
       "      <th>number_of_video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_of_photo  number_of_gif  number_of_video\n",
       "0                0              0                0\n",
       "1                0              0                0\n",
       "2                0              0                0\n",
       "3                0              0                0\n",
       "4                1              0                0\n",
       "5                0              0                0\n",
       "6                0              0                0\n",
       "7                0              0                0\n",
       "8                0              0                0\n",
       "9                0              0                0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_media.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean variables\n",
    "del out_media, media_dict, columns_types, df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 ms, sys: 0 ns, total: 11.2 ms\n",
      "Wall time: 10.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load dataset\n",
    "df = dd.read_parquet(dataset_path,\n",
    "                     columns= [\n",
    "                             \"raw_feature_tweet_links\"\n",
    "                     ],\n",
    "                     engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_feature_tweet_links</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=48</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: read-parquet, 48 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               raw_feature_tweet_links\n",
       "npartitions=48                        \n",
       "                                string\n",
       "                                   ...\n",
       "...                                ...\n",
       "                                   ...\n",
       "                                   ...\n",
       "Dask Name: read-parquet, 48 tasks"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.69 s, sys: 64.1 ms, total: 2.75 s\n",
      "Wall time: 1.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create Dict\n",
    "dict_links_id, mapping = create_dict_feature_to_split(df[\"raw_feature_tweet_links\"], '\\t', np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Map the feature\n",
    "out_links_id = map_column_array(df[\"raw_feature_tweet_links\"].fillna(\"\"), dict_links_id, '\\t', \"mapped_tweet_links\", np.uint32, \"\") \\\n",
    "    .to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.2 s, sys: 213 ms, total: 8.41 s\n",
      "Wall time: 7.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Write the output dataset\n",
    "out_links_id.to_parquet(temp_output_path+\"links\", write_index=False, compression=\"snappy\", engine=\"pyarrow\", overwrite=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mapped_tweet_links</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=48</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: to_frame, 240 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               mapped_tweet_links\n",
       "npartitions=48                   \n",
       "                           object\n",
       "                              ...\n",
       "...                           ...\n",
       "                              ...\n",
       "                              ...\n",
       "Dask Name: to_frame, 240 tasks"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_links_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mapped_tweet_links</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mapped_tweet_links\n",
       "0                 []\n",
       "1                [1]\n",
       "2                [2]\n",
       "3                 []\n",
       "4                 []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_links_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.76 s, sys: 8.29 ms, total: 2.77 s\n",
      "Wall time: 2.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Write the dicts\n",
    "with gzip.GzipFile(dict_path + \"mapped_tweet_links\" + \"_dict\", 'wb') as file:\n",
    "    pickle.dump(dict_links_id, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10799"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean variables\n",
    "del dict_links_id, out_links_id, mapping, df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.7 ms, sys: 106 µs, total: 11.8 ms\n",
      "Wall time: 11.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load dataset\n",
    "df = dd.read_parquet(dataset_path,\n",
    "                     columns= [\n",
    "                             \"raw_feature_tweet_domains\"\n",
    "                     ],\n",
    "                     engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.93 s, sys: 84.8 ms, total: 2.01 s\n",
      "Wall time: 1.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create Dict\n",
    "dict_domains_id, mapping = create_dict_feature_to_split(df[\"raw_feature_tweet_domains\"], '\\t', np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Map the feature\n",
    "out_domains_id = map_column_array(df[\"raw_feature_tweet_domains\"].fillna(\"\"), dict_domains_id, '\\t', \"mapped_domains\", np.uint32, \"\") \\\n",
    "    .to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 81.4 ms, total: 10.5 s\n",
      "Wall time: 9.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Write the output dataset\n",
    "out_domains_id.to_parquet(temp_output_path+\"domains\", write_index=False, compression=\"snappy\", engine=\"pyarrow\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mapped_domains</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=48</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: to_frame, 240 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               mapped_domains\n",
       "npartitions=48               \n",
       "                       object\n",
       "                          ...\n",
       "...                       ...\n",
       "                          ...\n",
       "                          ...\n",
       "Dask Name: to_frame, 240 tasks"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_domains_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mapped_domains</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  mapped_domains\n",
       "0             []\n",
       "1            [1]\n",
       "2            [2]\n",
       "3             []\n",
       "4             []"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_domains_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 224 ms, sys: 76 µs, total: 224 ms\n",
      "Wall time: 222 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Write the dicts\n",
    "with gzip.GzipFile(dict_path + \"raw_feature_tweet_domains\" + \"_dict\", 'wb') as file:\n",
    "    pickle.dump(dict_domains_id, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean variables\n",
    "del dict_domains_id, out_domains_id, mapping, df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.62 ms, sys: 10.2 ms, total: 11.8 ms\n",
      "Wall time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load dataset\n",
    "df = dd.read_parquet(dataset_path,\n",
    "                     columns= [\n",
    "                             \"raw_feature_tweet_hashtags\"\n",
    "                     ],\n",
    "                     engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.66 s, sys: 123 ms, total: 4.78 s\n",
      "Wall time: 3.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create Dict\n",
    "dict_hashtags_id, mapping = create_dict_feature_to_split(df[\"raw_feature_tweet_hashtags\"], '\\t', np.uint32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Map the feature\n",
    "out_hashtags_id = map_column_array(df[\"raw_feature_tweet_hashtags\"].fillna(\"\"), dict_hashtags_id, '\\t', \"mapped_tweet_hashtags\", np.uint32, \"\") \\\n",
    "    .to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 s, sys: 279 ms, total: 10.3 s\n",
      "Wall time: 9.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Write the output dataset\n",
    "out_hashtags_id.to_parquet(temp_output_path+\"hashtags\", write_index=False, compression=\"snappy\", engine=\"pyarrow\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mapped_tweet_hashtags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=48</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: to_frame, 240 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               mapped_tweet_hashtags\n",
       "npartitions=48                      \n",
       "                              object\n",
       "                                 ...\n",
       "...                              ...\n",
       "                                 ...\n",
       "                                 ...\n",
       "Dask Name: to_frame, 240 tasks"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_hashtags_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mapped_tweet_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[2, 3, 4, 5, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mapped_tweet_hashtags\n",
       "0                     []\n",
       "1                     []\n",
       "2                     []\n",
       "3                     []\n",
       "4                     []\n",
       "5                     []\n",
       "6                     []\n",
       "7                     []\n",
       "8                     []\n",
       "9                     []\n",
       "10                    []\n",
       "11                    []\n",
       "12                    []\n",
       "13                    []\n",
       "14                    []\n",
       "15                    []\n",
       "16                    []\n",
       "17                    []\n",
       "18                    []\n",
       "19                    []\n",
       "20                    []\n",
       "21                    []\n",
       "22                    []\n",
       "23                    []\n",
       "24                   [1]\n",
       "25                    []\n",
       "26                    []\n",
       "27                    []\n",
       "28                    []\n",
       "29                    []\n",
       "30                    []\n",
       "31       [2, 3, 4, 5, 6]\n",
       "32                    []\n",
       "33                    []\n",
       "34                    []\n",
       "35                    []\n",
       "36                    []\n",
       "37                   [7]\n",
       "38                    []\n",
       "39                    []"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_hashtags_id.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_feature_tweet_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>D79DBEE00CCE361AE78BBBB98713C300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4F3903BE060AB0BA12071617E7B00123\t4E3B51DC2EA6A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>B8E47183FFBA0200590572D127D16E75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           raw_feature_tweet_hashtags\n",
       "0                                                <NA>\n",
       "1                                                <NA>\n",
       "2                                                <NA>\n",
       "3                                                <NA>\n",
       "4                                                <NA>\n",
       "5                                                <NA>\n",
       "6                                                <NA>\n",
       "7                                                <NA>\n",
       "8                                                <NA>\n",
       "9                                                <NA>\n",
       "10                                               <NA>\n",
       "11                                               <NA>\n",
       "12                                               <NA>\n",
       "13                                               <NA>\n",
       "14                                               <NA>\n",
       "15                                               <NA>\n",
       "16                                               <NA>\n",
       "17                                               <NA>\n",
       "18                                               <NA>\n",
       "19                                               <NA>\n",
       "20                                               <NA>\n",
       "21                                               <NA>\n",
       "22                                               <NA>\n",
       "23                                               <NA>\n",
       "24                   D79DBEE00CCE361AE78BBBB98713C300\n",
       "25                                               <NA>\n",
       "26                                               <NA>\n",
       "27                                               <NA>\n",
       "28                                               <NA>\n",
       "29                                               <NA>\n",
       "30                                               <NA>\n",
       "31  4F3903BE060AB0BA12071617E7B00123\t4E3B51DC2EA6A...\n",
       "32                                               <NA>\n",
       "33                                               <NA>\n",
       "34                                               <NA>\n",
       "35                                               <NA>\n",
       "36                                               <NA>\n",
       "37                   B8E47183FFBA0200590572D127D16E75\n",
       "38                                               <NA>\n",
       "39                                               <NA>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.58 s, sys: 7.71 ms, total: 3.59 s\n",
      "Wall time: 3.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Write the dicts\n",
    "with gzip.GzipFile(dict_path + \"raw_feature_tweet_hashtags\" + \"_dict\", 'wb') as file:\n",
    "    pickle.dump(dict_hashtags_id, file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean variables\n",
    "del dict_hashtags_id, out_hashtags_id, mapping, df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load dataset\n",
    "df = dd.read_parquet(dataset_path,\n",
    "                     columns= [\n",
    "                             \"raw_feature_tweet_media\"\n",
    "                     ],\n",
    "                     engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Create Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Map the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Write the output dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Write the dicts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Clean variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%% do merging\n"
    }
   },
   "outputs": [],
   "source": [
    "# Read not mapped features from original dataset\n",
    "df = dd.read_parquet(dataset_path,\n",
    "                     columns= [\n",
    "                         \"tweet_timestamp\",\n",
    "                         \"creator_follower_count\",\n",
    "                         \"creator_following_count\",\n",
    "                         \"creator_is_verified\",\n",
    "                         \"creator_creation_timestamp\",\n",
    "                         \"engager_follower_count\",\n",
    "                         \"engager_following_count\",\n",
    "                         \"engager_is_verified\",\n",
    "                         \"engager_creation_timestamp\",\n",
    "                         \"engagement_creator_follows_engager\",\n",
    "                         \"engagement_reply_timestamp\",\n",
    "                         \"engagement_retweet_timestamp\",\n",
    "                         \"engagement_comment_timestamp\",\n",
    "                         \"engagement_like_timestamp\"\n",
    "                     ],\n",
    "                     engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare to load the datasets created previously\n",
    "df_list = []\n",
    "\n",
    "columns_dict = {\n",
    "    \"mapped_creator_id\": [\"mapped_creator_id\"],\n",
    "    \"counted_media\": [\n",
    "        \"number_of_photo\",\n",
    "        \"number_of_gif\",\n",
    "        \"number_of_video\"\n",
    "    ],\n",
    "    \"links\": [\"mapped_tweet_links\"],\n",
    "    \"domains\": [\"mapped_domains\"],\n",
    "    \"hashtags\": [\"mapped_hashtags\"]\n",
    "}\n",
    "\n",
    "for name, cols in columns_dict.items():\n",
    "    df_list.append(dd.read_parquet(temp_output_path + name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_timestamp</th>\n",
       "      <th>creator_follower_count</th>\n",
       "      <th>creator_following_count</th>\n",
       "      <th>creator_is_verified</th>\n",
       "      <th>creator_creation_timestamp</th>\n",
       "      <th>engager_follower_count</th>\n",
       "      <th>engager_following_count</th>\n",
       "      <th>engager_is_verified</th>\n",
       "      <th>engager_creation_timestamp</th>\n",
       "      <th>engagement_creator_follows_engager</th>\n",
       "      <th>engagement_reply_timestamp</th>\n",
       "      <th>engagement_retweet_timestamp</th>\n",
       "      <th>engagement_comment_timestamp</th>\n",
       "      <th>engagement_like_timestamp</th>\n",
       "      <th>number_of_photo</th>\n",
       "      <th>number_of_gif</th>\n",
       "      <th>number_of_video</th>\n",
       "      <th>mapped_tweet_links</th>\n",
       "      <th>mapped_domains</th>\n",
       "      <th>mapped_tweet_hashtags</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=48</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>Int64</td>\n",
       "      <td>UInt32</td>\n",
       "      <td>UInt32</td>\n",
       "      <td>boolean</td>\n",
       "      <td>Int64</td>\n",
       "      <td>UInt32</td>\n",
       "      <td>UInt32</td>\n",
       "      <td>boolean</td>\n",
       "      <td>Int64</td>\n",
       "      <td>boolean</td>\n",
       "      <td>Int64</td>\n",
       "      <td>Int64</td>\n",
       "      <td>Int64</td>\n",
       "      <td>Int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: assign, 816 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "               tweet_timestamp creator_follower_count creator_following_count creator_is_verified creator_creation_timestamp engager_follower_count engager_following_count engager_is_verified engager_creation_timestamp engagement_creator_follows_engager engagement_reply_timestamp engagement_retweet_timestamp engagement_comment_timestamp engagement_like_timestamp number_of_photo number_of_gif number_of_video mapped_tweet_links mapped_domains mapped_tweet_hashtags\n",
       "npartitions=48                                                                                                                                                                                                                                                                                                                                                                                                                                                                    \n",
       "                         Int64                 UInt32                  UInt32             boolean                      Int64                 UInt32                  UInt32             boolean                      Int64                            boolean                      Int64                        Int64                        Int64                     Int64           int64         int64           int64             object         object                object\n",
       "                           ...                    ...                     ...                 ...                        ...                    ...                     ...                 ...                        ...                                ...                        ...                          ...                          ...                       ...             ...           ...             ...                ...            ...                   ...\n",
       "...                        ...                    ...                     ...                 ...                        ...                    ...                     ...                 ...                        ...                                ...                        ...                          ...                          ...                       ...             ...           ...             ...                ...            ...                   ...\n",
       "                           ...                    ...                     ...                 ...                        ...                    ...                     ...                 ...                        ...                                ...                        ...                          ...                          ...                       ...             ...           ...             ...                ...            ...                   ...\n",
       "                           ...                    ...                     ...                 ...                        ...                    ...                     ...                 ...                        ...                                ...                        ...                          ...                          ...                       ...             ...           ...             ...                ...            ...                   ...\n",
       "Dask Name: assign, 816 tasks"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(1, len(df_list)):\n",
    "    cur_df = df_list[i]\n",
    "    for col in cur_df.columns:\n",
    "        df[col] = cur_df[col]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 182 ms, sys: 1.29 ms, total: 184 ms\n",
      "Wall time: 202 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_timestamp</th>\n",
       "      <th>creator_follower_count</th>\n",
       "      <th>creator_following_count</th>\n",
       "      <th>creator_is_verified</th>\n",
       "      <th>creator_creation_timestamp</th>\n",
       "      <th>engager_follower_count</th>\n",
       "      <th>engager_following_count</th>\n",
       "      <th>engager_is_verified</th>\n",
       "      <th>engager_creation_timestamp</th>\n",
       "      <th>engagement_creator_follows_engager</th>\n",
       "      <th>engagement_reply_timestamp</th>\n",
       "      <th>engagement_retweet_timestamp</th>\n",
       "      <th>engagement_comment_timestamp</th>\n",
       "      <th>engagement_like_timestamp</th>\n",
       "      <th>number_of_photo</th>\n",
       "      <th>number_of_gif</th>\n",
       "      <th>number_of_video</th>\n",
       "      <th>mapped_tweet_links</th>\n",
       "      <th>mapped_domains</th>\n",
       "      <th>mapped_tweet_hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1613237034</td>\n",
       "      <td>2473</td>\n",
       "      <td>662</td>\n",
       "      <td>False</td>\n",
       "      <td>1261859734</td>\n",
       "      <td>169</td>\n",
       "      <td>339</td>\n",
       "      <td>False</td>\n",
       "      <td>1520886748</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1613748600</td>\n",
       "      <td>4418640</td>\n",
       "      <td>228</td>\n",
       "      <td>True</td>\n",
       "      <td>1266804490</td>\n",
       "      <td>393</td>\n",
       "      <td>1190</td>\n",
       "      <td>False</td>\n",
       "      <td>1237570695</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1613386238</td>\n",
       "      <td>219715</td>\n",
       "      <td>3685</td>\n",
       "      <td>True</td>\n",
       "      <td>1202617218</td>\n",
       "      <td>629</td>\n",
       "      <td>1473</td>\n",
       "      <td>False</td>\n",
       "      <td>1263176351</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1613388292</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[2.0]</td>\n",
       "      <td>[2.0]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1613708640</td>\n",
       "      <td>2388283</td>\n",
       "      <td>13511</td>\n",
       "      <td>True</td>\n",
       "      <td>1251645191</td>\n",
       "      <td>123</td>\n",
       "      <td>200</td>\n",
       "      <td>False</td>\n",
       "      <td>1268276559</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1612586018</td>\n",
       "      <td>414</td>\n",
       "      <td>720</td>\n",
       "      <td>False</td>\n",
       "      <td>1578273274</td>\n",
       "      <td>134</td>\n",
       "      <td>379</td>\n",
       "      <td>False</td>\n",
       "      <td>1483862063</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1612587384</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1613047251</td>\n",
       "      <td>673</td>\n",
       "      <td>561</td>\n",
       "      <td>False</td>\n",
       "      <td>1318013852</td>\n",
       "      <td>2322</td>\n",
       "      <td>996</td>\n",
       "      <td>False</td>\n",
       "      <td>1385942383</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1613383429</td>\n",
       "      <td>9879</td>\n",
       "      <td>95</td>\n",
       "      <td>False</td>\n",
       "      <td>1551982041</td>\n",
       "      <td>61</td>\n",
       "      <td>1008</td>\n",
       "      <td>False</td>\n",
       "      <td>1573893335</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1614132656</td>\n",
       "      <td>209681</td>\n",
       "      <td>141</td>\n",
       "      <td>False</td>\n",
       "      <td>1516334262</td>\n",
       "      <td>35</td>\n",
       "      <td>106</td>\n",
       "      <td>False</td>\n",
       "      <td>1581377629</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1614134640</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1614179138</td>\n",
       "      <td>901</td>\n",
       "      <td>782</td>\n",
       "      <td>False</td>\n",
       "      <td>1401492344</td>\n",
       "      <td>9661</td>\n",
       "      <td>8573</td>\n",
       "      <td>False</td>\n",
       "      <td>1373060291</td>\n",
       "      <td>True</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1614172373</td>\n",
       "      <td>881</td>\n",
       "      <td>583</td>\n",
       "      <td>False</td>\n",
       "      <td>1254934130</td>\n",
       "      <td>355</td>\n",
       "      <td>650</td>\n",
       "      <td>False</td>\n",
       "      <td>1589197420</td>\n",
       "      <td>False</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1614175309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[3.0]</td>\n",
       "      <td>[3.0]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_timestamp  creator_follower_count  creator_following_count  \\\n",
       "0       1613237034                    2473                      662   \n",
       "1       1613748600                 4418640                      228   \n",
       "2       1613386238                  219715                     3685   \n",
       "3       1613708640                 2388283                    13511   \n",
       "4       1612586018                     414                      720   \n",
       "5       1613047251                     673                      561   \n",
       "6       1613383429                    9879                       95   \n",
       "7       1614132656                  209681                      141   \n",
       "8       1614179138                     901                      782   \n",
       "9       1614172373                     881                      583   \n",
       "\n",
       "   creator_is_verified  creator_creation_timestamp  engager_follower_count  \\\n",
       "0                False                  1261859734                     169   \n",
       "1                 True                  1266804490                     393   \n",
       "2                 True                  1202617218                     629   \n",
       "3                 True                  1251645191                     123   \n",
       "4                False                  1578273274                     134   \n",
       "5                False                  1318013852                    2322   \n",
       "6                False                  1551982041                      61   \n",
       "7                False                  1516334262                      35   \n",
       "8                False                  1401492344                    9661   \n",
       "9                False                  1254934130                     355   \n",
       "\n",
       "   engager_following_count  engager_is_verified  engager_creation_timestamp  \\\n",
       "0                      339                False                  1520886748   \n",
       "1                     1190                False                  1237570695   \n",
       "2                     1473                False                  1263176351   \n",
       "3                      200                False                  1268276559   \n",
       "4                      379                False                  1483862063   \n",
       "5                      996                False                  1385942383   \n",
       "6                     1008                False                  1573893335   \n",
       "7                      106                False                  1581377629   \n",
       "8                     8573                False                  1373060291   \n",
       "9                      650                False                  1589197420   \n",
       "\n",
       "   engagement_creator_follows_engager  engagement_reply_timestamp  \\\n",
       "0                               False                        <NA>   \n",
       "1                               False                        <NA>   \n",
       "2                               False                        <NA>   \n",
       "3                               False                        <NA>   \n",
       "4                                True                        <NA>   \n",
       "5                                True                        <NA>   \n",
       "6                               False                        <NA>   \n",
       "7                               False                        <NA>   \n",
       "8                                True                        <NA>   \n",
       "9                               False                        <NA>   \n",
       "\n",
       "   engagement_retweet_timestamp  engagement_comment_timestamp  \\\n",
       "0                          <NA>                          <NA>   \n",
       "1                          <NA>                          <NA>   \n",
       "2                          <NA>                          <NA>   \n",
       "3                          <NA>                          <NA>   \n",
       "4                          <NA>                          <NA>   \n",
       "5                          <NA>                          <NA>   \n",
       "6                          <NA>                          <NA>   \n",
       "7                          <NA>                          <NA>   \n",
       "8                          <NA>                          <NA>   \n",
       "9                          <NA>                          <NA>   \n",
       "\n",
       "   engagement_like_timestamp  number_of_photo  number_of_gif  number_of_video  \\\n",
       "0                       <NA>                0              0                0   \n",
       "1                       <NA>                0              0                0   \n",
       "2                 1613388292                0              0                0   \n",
       "3                       <NA>                0              0                0   \n",
       "4                 1612587384                1              0                0   \n",
       "5                       <NA>                0              0                0   \n",
       "6                       <NA>                0              0                0   \n",
       "7                 1614134640                0              0                0   \n",
       "8                       <NA>                0              0                0   \n",
       "9                 1614175309                0              0                0   \n",
       "\n",
       "  mapped_tweet_links mapped_domains mapped_tweet_hashtags  \n",
       "0                 []             []                    []  \n",
       "1              [1.0]          [1.0]                    []  \n",
       "2              [2.0]          [2.0]                    []  \n",
       "3                 []             []                    []  \n",
       "4                 []             []                    []  \n",
       "5                 []             []                    []  \n",
       "6                 []             []                    []  \n",
       "7                 []             []                    []  \n",
       "8                 []             []                    []  \n",
       "9              [3.0]          [3.0]                    []  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df.to_parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dask.config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop(\"raw_feature_tweet_text_token\", axis=1)\n",
    "del all_features_dtype[\"raw_feature_tweet_text_token\"]\n",
    "del all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#for k,t in {**all_features_dtype, **all_labels_dtype}.items():\n",
    "#    if t == 'int32':\n",
    "#        df[k] = df[k].fillna(0).astype(np.int32)\n",
    "#    elif t == 'bool':\n",
    "#        df[k] = df[k].astype(bool)\n",
    "#    elif t == 'string':\n",
    "#        df[k] = df[k].fillna(\"\").astype(str)\n",
    "#    else:\n",
    "#        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add ID column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['id']   = df.index.astype(np.uint32)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### They thought me a lesson...\n",
    "What was learnt from the dask API:\n",
    "* `map_partition` applies a function on each partition overall, so it is most indicated for functions that must be applied at a ~dataframe level\n",
    "* `apply` applies a function elementwise. If you see repo source, apply = map_partition + apply on each df\n",
    "* `reset_index` is a partition-wise operation, so indices will be repeated on different partitions :)\n",
    "* `compute` synchronous return of a result, no data persisted on cluster, full result returned. *\"This turns a lazy Dask collection into its in-memory equivalent. For example a Dask array turns into a NumPy array and a Dask dataframe turns into a Pandas dataframe. The entire dataset must fit into memory before calling this operation.\"*\n",
    "* `persist` asynchronous return of result, result persisted on cluster, full result available on request (ie. available a read away)\n",
    "* `meta`: meta is the worst nightamre in dask. Required for many operations such as map_partitions and apply, you will never get them right at the first shot.\n",
    "    * SO let's try to be precise from this [gold]: https://docs.dask.org/en/latest/dataframe-design.html#metadata\n",
    "    * IF you apply a map_partition/apply, and expect to produce a dataframe THEN:\n",
    "        * ONE ROW DATAFRAME EXAMPLE`ddf.map_partitions(foo, meta=pd.DataFrame({'a': 1, 'b': 2}))` since a whole dataframe (many columns possible) is expected to be produced from foo from working on each partition\n",
    "        * DICT `{'a':int, 'b':int}` to be shorter, order must match Dataframe\n",
    "    * ELIF you apply a map_partition/apply, and expect to produce a series THEN:\n",
    "        * EMPTY SERIES `meta=pd.Series(dtype='int', name='the_custom_name_for_your_input')`\n",
    "        * SINGLE TUPLE `('the_custom_name_for_your_input', int)`\n",
    "    * ELSE you expect a single scalar:\n",
    "        * SINGLE DTYPE `meta=int`\n",
    "    * note that each dtype can be substituted with a string 'f8'~float8, 'O'~generic object ...\n",
    "* `gc.collect()` are crucial to avoid OOMs :)\n",
    "    * 2 types of OOM experienced:\n",
    "        * dask backend crashes and computation halts\n",
    "        * frozen computer, blue screens of death\n",
    "    * PyCharm is heavy on RAM, close browser tabs/using lightweight browser can help \\[true experience,sad\\]\n",
    "more info at https://distributed.dask.org/en/latest/memory.html, https://docs.dask.org/en/latest/dataframe-best-practices.html\n",
    "\n",
    "Empirical concepts seen by visual inspection of graph computations happening\n",
    "* `drop duplicates` is the unavoidable, long bottleneck, that however can benefit by an incredible amount of workers in parallel\n",
    "* `cumsum` trick for computing unique increasing array is super fast\n",
    "* translation to dictionary happens rather fast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's prepare some functions to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_dict_feature(series: dask.dataframe.Series) -> (dict,dict):\n",
    "    feature_name = series.name\n",
    "    feature_name_encode = feature_name + \"_encode\"\n",
    "\n",
    "    mapping = series.drop_duplicates().to_frame() #create a dataframe from a series\n",
    "    mapping[feature_name_encode] = 1\n",
    "    mapping[feature_name_encode] = mapping[feature_name_encode].cumsum()\n",
    "    mapping, = dask.compute(mapping)\n",
    "    #_ = wait(mapping)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # define mapping dicts\n",
    "    direct_dict = dict(zip(mapping[feature_name], mapping[feature_name_encode]))\n",
    "    inverse_dict = dict(zip(mapping[feature_name_encode], mapping[feature_name]))\n",
    "    # manage nans\n",
    "    #direct_dict[pd.NA] = None\n",
    "    #inverse_dict[None] = pd.NA\n",
    "\n",
    "    del mapping\n",
    "    gc.collect()\n",
    "    return direct_dict, inverse_dict\n",
    "\n",
    "def create_dict_feature_to_split(series: dask.dataframe.Series, sep: str) -> (dict,dict):\n",
    "    feature_name = series.name\n",
    "    feature_name_encode = feature_name + \"_encode\"\n",
    "\n",
    "    #map partition internal function goes from series to dataframe\n",
    "    mapping = series\\\n",
    "        .map_partitions(lambda s: pd.DataFrame([hashtag for line in s.dropna() for hashtag in line.split(sep)], columns=[feature_name]),\n",
    "                       meta={feature_name:pd.StringDtype()})\\\n",
    "        .drop_duplicates()\n",
    "    mapping[feature_name_encode] = 1\n",
    "    mapping[feature_name_encode] = mapping[feature_name_encode].cumsum()\n",
    "    mapping, = dask.compute(mapping)\n",
    "    #_ = wait(mapping)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    # define mapping dicts\n",
    "    direct_dict = dict(zip(mapping[feature_name], mapping[feature_name_encode]))\n",
    "    inverse_dict = dict(zip(mapping[feature_name_encode], mapping[feature_name]))\n",
    "    # manage nans\n",
    "    #direct_dict[pd.NA] = None\n",
    "    #inverse_dict[None] = pd.NA\n",
    "\n",
    "    del mapping\n",
    "    gc.collect()\n",
    "\n",
    "    return direct_dict, inverse_dict\n",
    "\n",
    "\n",
    "def map_column_single_value(series: dask.dataframe.Series, dictionary: dict, out_type: type = np.uint32) -> dask.dataframe.Series:\n",
    "    feature_name = series.name\n",
    "    feature_name_mapped = \"mapped_\" + feature_name\n",
    "\n",
    "    return series\\\n",
    "        .apply(lambda x: dictionary[x],\n",
    "               meta=pd.Series(dtype=out_type, name=feature_name_mapped))\n",
    "\n",
    "\n",
    "def map_column_array(series: dask.dataframe.Series, dictionary: dict, sep: str, out_type: type = np.uint32) -> dask.dataframe.Series:\n",
    "    feature_name = series.name\n",
    "    feature_name_mapped = \"mapped_\" + feature_name\n",
    "\n",
    "    return df[feature_name]\\\n",
    "        .apply(lambda x: np.array([dictionary[y] for y in x.split(sep)], dtype=out_type)\n",
    "                                    if x is not pd.NA else None,\n",
    "           meta=pd.Series(dtype='O', name=feature_name_mapped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dir1, inv1 = create_dict_feature(df[\"raw_feature_tweet_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "dir2, inv2 = create_dict_feature_to_split(df[\"raw_feature_tweet_hashtags\"], '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing size of dictionaries in Megabytes\n",
    "print('dir1 size:',sys.getsizeof(dir1)/(10**6))\n",
    "print('inv1 size:',sys.getsizeof(inv1)/(10**6))\n",
    "print('dir2 size:',sys.getsizeof(dir2)/(10**6))\n",
    "print('inv2 size:',sys.getsizeof(inv2)/(10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dir_language, inv_language = create_dict_feature(df[\"raw_feature_tweet_language\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing size of dictionaries in Megabytes\n",
    "print('dir_language size:',sys.getsizeof(dir_language)/(10**6))\n",
    "print('inv_language size:',sys.getsizeof(inv_language)/(10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dir_links, inv_links =  create_dict_feature_to_split(df[\"raw_feature_tweet_links\"], '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing size of dictionaries in Megabytes\n",
    "print('dir_links size:',sys.getsizeof(dir_links)/(10**6))\n",
    "print('inv_links size:',sys.getsizeof(inv_links)/(10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dir_domains, inv_domains = create_dict_feature_to_split(df[\"raw_feature_tweet_domains\"], '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dir_domains size:',sys.getsizeof(dir_domains)/(10**6))\n",
    "print('inv_domains size:',sys.getsizeof(inv_domains)/(10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dir_creator_id, inv_creator_id =  create_dict_feature(df[\"raw_feature_creator_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dir_creator_id size:',sys.getsizeof(dir_creator_id)/(10**6))\n",
    "print('inv_creator_id size:',sys.getsizeof(inv_creator_id)/(10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "dir_engager_id, inv_engager_id = create_dict_feature(df[\"raw_feature_engager_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('dir_engager_id size:',sys.getsizeof(dir_engager_id)/(10**6))\n",
    "print('inv_engager_id size:',sys.getsizeof(inv_engager_id)/(10**6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in itertools.islice(dir_engager_id.items(), 5):\n",
    "    print(x)\n",
    "for x in itertools.islice(dir_creator_id.items(), 5):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"mapped_tweet_id\"] = map_column_single_value(df[\"raw_feature_tweet_id\"], dir1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df[\"mapped_hashtags\"] = map_column_array(df[\"raw_feature_tweet_hashtags\"], dir2, '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mapped_language\"] = map_column_single_value(df[\"raw_feature_tweet_language\"], dir_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mapped_links\"] = map_column_array(df[\"raw_feature_tweet_links\"], dir_links, '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: Mapping the creator id and engager id together makes the .head() function stall. I have no idea why. If run individually, the .head() works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mapped_creator_id\"] =  map_column_single_value(df[\"raw_feature_creator_id\"], dir_creator_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"mapped_engager_id\"] =  map_column_single_value(df[\"raw_feature_engager_id\"], dir_engager_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delle volte da il seguente errore, delle altre si pianta e basta. Fondamentalmente sembra che il problema sia la \"computazione\" effettiva sulle due features\n",
    "# Runnate singolarmete funzionano, se runno sia il mapper_creator che il mapped_engager, si pianta.\n",
    "# distributed.nanny - WARNING - Worker exceeded 95% memory budget. Restarting\n",
    "# distributed.nanny - WARNING - Restarting worker\n",
    "df[\"mapped_engager_id\"].head(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\n",
    "    \"raw_feature_tweet_id\", \"raw_feature_tweet_hashtags\", \"raw_feature_tweet_language\", \"raw_feature_tweet_links\",\n",
    "   # \"mapped_tweet_id\", \n",
    "   # \"mapped_hashtags\", \n",
    "    \"mapped_engager_id\",\n",
    "    \"mapped_creator_id\"]].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Generate Media columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#df[\"raw_feature_tweet_media\"].unique().compute()\n",
    "\n",
    "media_dict = {\n",
    "    \"Photo\":0,\n",
    "    \"GIF\": 1,\n",
    "    \"Video\": 2\n",
    "}\n",
    "\n",
    "def count_media_types(vec):\n",
    "    ret = [0 for _ in range(3)]\n",
    "    for x in vec:\n",
    "        if x != \"\":\n",
    "            ret[media_dict[x]] +=1\n",
    "    return ret\n",
    "\n",
    "def to_map_on_media_col(media_col: pd.Series) -> pd.DataFrame:\n",
    "    return pd.DataFrame(media_col.map(count_media_types).to_list(), columns=media_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['raw_feature_tweet_media'].fillna(\"\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "temp = df['raw_feature_tweet_media']\\\n",
    "    .fillna(\"\")\\\n",
    "    .map_partitions(lambda s: to_map_on_media_col(s.str.split(\"\\t\")),\n",
    "                    meta={k:'uint8' for k in media_dict.keys()})\n",
    "temp.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['generated_feature_n_photo'] = temp['Photo']\n",
    "df['generated_feature_n_gif'] = temp['GIF']\n",
    "df['generated_feature_n_video'] = temp['Video']\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dict mapping on column of single values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# dataset to dataset\n",
    "mapping = df['raw_feature_tweet_id']\\\n",
    "    .drop_duplicates().to_frame() #create a dataframe from a series\n",
    "mapping['tweet_encode'] = 1\n",
    "mapping['tweet_encode'] = mapping['tweet_encode'].cumsum()\n",
    "mapping, = dask.compute(mapping)\n",
    "_ = wait(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# define mapping dicts\n",
    "direct_dict = dict(zip(mapping[\"raw_feature_tweet_id\"], mapping[\"tweet_encode\"]))\n",
    "# save RAM\n",
    "# inverse_dict = dict(zip(mapping[\"tweet_encode\"], mapping[\"raw_feature_tweet_id\"]))\n",
    "# # manage nans #NO MORE NEEDED\n",
    "# direct_dict[pd.NA] = None\n",
    "# inverse_dict[None] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print results\n",
    "print(f\"{mapping.shape=}, {len(direct_dict)=}\")\n",
    "print(\"\\ndirect_dict contains:\")\n",
    "for x in itertools.islice(direct_dict.items(), 5):\n",
    "    print(x)\n",
    "# print(\"\\ninverse_dict contains:\")\n",
    "# for x in itertools.islice(inverse_dict.items(), 5):\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sys.getsizeof(mapping) / 1024**2\n",
    "#nice 500MB mapping :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(direct_dict) / 1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#time needed to compute graph, not to execute computations\n",
    "\n",
    "df['mapped_tweet_id'] = df['raw_feature_tweet_id']\\\n",
    "     .apply(lambda x: direct_dict[x],\n",
    "            meta=pd.Series(dtype='uint32', name='mapped_tweet_id'))\n",
    "\n",
    "#df['mapped_tweet_id'] = df['raw_feature_tweet_id']\\\n",
    "#    .map_partitions(lambda x: x.map(direct_dict),\n",
    "#           meta=pd.Series(dtype=pd.UInt32Dtype(), name='mapped_tweet_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#only head now, don't waste time mapping on whole dataset\n",
    "df[['raw_feature_tweet_id', 'mapped_tweet_id']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Dict mapping on columns containing a list of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#doing it here creates connectivity exceptions\n",
    "client.restart()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df.npartitions)\n",
    "#df = df.repartition(partition_size='100MB')\n",
    "#print(df.npartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#map partition internal function goes from series to dataframe\n",
    "mapping = df['raw_feature_tweet_hashtags']\\\n",
    "    .fillna(\"\")\\\n",
    "    .map_partitions(lambda s: pd.DataFrame([hashtag for line in s for hashtag in line.split('\\t')], columns=['hashtag']),\n",
    "                   meta={'hashtag':pd.StringDtype()})\\\n",
    "    .drop_duplicates(split_out = 16)\n",
    "\n",
    "mapping['hashtag_encode'] = 1\n",
    "mapping['hashtag_encode'] = mapping['hashtag_encode'].cumsum()\n",
    "mapping, = dask.compute(mapping)\n",
    "_ = wait(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# define mapping dicts\n",
    "direct_dict = dict(zip(mapping[\"hashtag\"], mapping[\"hashtag_encode\"]))\n",
    "# inverse_dict = dict(zip(mapping[\"hashtag_encode\"], mapping[\"hashtag\"]))\n",
    "# # manage nans\n",
    "# direct_dict[pd.NA] = None\n",
    "# inverse_dict[None] = pd.NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print results\n",
    "print(f\"{mapping.shape=}, {len(direct_dict)=}\")\n",
    "print(\"\\ndirect_dict contains:\")\n",
    "for x in itertools.islice(direct_dict.items(), 5):\n",
    "    print(x)\n",
    "# print(\"\\ninverse_dict contains:\")\n",
    "# for x in itertools.islice(inverse_dict.items(), 5):\n",
    "#     print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#del mapping\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['mapped_hashtag'] = df['raw_feature_tweet_hashtags']\\\n",
    "    .fillna(\"\")\\\n",
    "    .apply(lambda x: np.array([direct_dict[y] for y in x.split('\\t')], dtype=np.int32)\n",
    "                                    if x != \"\" else None,\n",
    "           meta=pd.Series(dtype='O', name='mapped_hashtag'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#only head now, don't waste time mapping on whole dataset\n",
    "df[['raw_feature_tweet_hashtags', 'mapped_hashtag']].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#client.restart()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# here 'official' things stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "assert(False) #do not execute automatically after :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%time\n"
    }
   },
   "outputs": [],
   "source": [
    "mapping = df[['raw_feature_tweet_hashtags']]\\\n",
    "    .apply(lambda x: x.split('\\t', expand=True).stack().rename(\"test\"),\n",
    "           axis=1,\n",
    "           meta={'test':'O'})\\\n",
    "    .drop_duplicates(split_out=16)\n",
    "mapping['hashtag_encode'] = 1\n",
    "mapping['hashtag_encode'] = mapping['hashtag_encode'].cumsum()\n",
    "mapping,shape = dask.compute(mapping, mapping.shape)\n",
    "_ = wait(mapping)\n",
    "_ = wait(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "mapping = df['raw_feature_tweet_hashtags'].map_partitions(lambda s: pd.DataFrame(s.dropna().str.split('\\t', expand=True).stack().rename('test')), meta={'test':'O'}).drop_duplicates(split_out=16)\n",
    "mapping , count = dd.compute(mapping, mapping.shape)\n",
    "_ = wait(mapping)\n",
    "_ = wait(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['mapped_tweet_hashtags'] = df['raw_feature_tweet_hashtags']\\\n",
    "    .map_partitions(lambda s: s.map(lambda x: np.array([direct_dict[y] for y in x.split('\\t')], dtype=np.int32)\n",
    "                                    if x is not pd.NA else None),\n",
    "                    meta={'raw_feature_tweet_hashtags': 'O'})['raw_feature_tweet_hashtags']\n",
    "df[['raw_feature_tweet_hashtags', 'mapped_tweet_hashtags']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_dict_feature_to_split(series, sep):\n",
    "    series = series.dropna()\\\n",
    "        .str.split(sep, expand=True)\\\n",
    "        .stack().reset_index(drop=True, level=1)\n",
    "\n",
    "\n",
    "    d.map_partitions(\n",
    "    lambda df: df.drop('var2', axis=1).join(\n",
    "        df.var2.str.split(',', expand=True).stack().reset_index(drop=True, level=1).rename('var2')))\n",
    "\n",
    "    \n",
    "data = pd.DataFrame([y for x in data.dropna() for y in x.split('\\t')])\n",
    "data = data[data.columns[0]]\n",
    "dictionary = pd.DataFrame(data.unique()).to_dict()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def map_column_single_value(series, dictionary):\n",
    "    mapped_series = series.map(dictionary).astype(np.int32)\n",
    "    return mapped_series\n",
    "\n",
    "\n",
    "def map_column_array(series, dictionary):\n",
    "    mapped_series = series.map(\n",
    "        lambda x: np.array([dictionary[y] for y in x.split('\\t')], dtype=np.int32) if x is not pd.NA else None)\n",
    "    return mapped_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "      test\n0  a\\tb\\tc\n1  a\\td\\te\n2     c\\tb\n3     a\\td",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>test</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>a\\tb\\tc</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a\\td\\te</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>c\\tb</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a\\td</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "d = {c:i for i,c in enumerate(string.ascii_lowercase)}\n",
    "test_df = pd.DataFrame([\"a\\tb\\tc\", \"a\\td\\te\", \"c\\tb\", \"a\\td\"], columns=[\"test\"])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-19-a11fde3939fb>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtest_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'test'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'\\t'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Recommender Systems/recsys-challenge-2021-twitter/venv/lib/python3.9/site-packages/pandas/core/series.py\u001B[0m in \u001B[0;36mapply\u001B[0;34m(self, func, convert_dtype, args, **kwds)\u001B[0m\n\u001B[1;32m   4136\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4137\u001B[0m                 \u001B[0mvalues\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mobject\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_values\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 4138\u001B[0;31m                 \u001B[0mmapped\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_infer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalues\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mconvert\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mconvert_dtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   4139\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   4140\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmapped\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmapped\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mSeries\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/lib.pyx\u001B[0m in \u001B[0;36mpandas._libs.lib.map_infer\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32m<ipython-input-19-a11fde3939fb>\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(x)\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtest_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'test'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0marray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmap\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0md\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'\\t'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "test_df['test'].apply(lambda x: np.array(list(map(d, x.split('\\t')))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df['test'].apply(lambda x: x.split('\\t', expand=True)).stack()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_df['test'].str.split('\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_df['test'].str.split('\\t',expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_df['test'].str.split('\\t',expand=True).stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "d = {\"1\":\"uno\", 2:\"due\", 3:\"lezzo\"}\n",
    "for x in itertools.islice(d.items(), 2):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chr(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a':[[1,2,3], [4,5]]})\n",
    "df['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['a'].dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['a'].astype(pd.arrays.IntegerArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'a':[1,2,3,4,5,6,7,8], 'b':[8,7,6,5,4,3,2,1], 'c':[1,3,5,7,2,4,6,8]})\n",
    "df = dd.from_pandas(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (recsys-challenge-2021-twitter)",
   "language": "python",
   "name": "pycharm-cc02c472"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}