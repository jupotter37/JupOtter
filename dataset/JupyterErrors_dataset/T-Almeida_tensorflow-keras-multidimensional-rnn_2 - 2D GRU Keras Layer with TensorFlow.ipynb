{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-94c031128d7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import initializers, regularizers, activations\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from utils import f1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a 2D-GRU Cell that takes 3 recurrent states plus the input data interaction\n",
    "\n",
    "Detailed article: https://arxiv.org/pdf/1604.04378.pdf\n",
    "\n",
    "#### <center>Input</center>\n",
    "$$S^{M,N}$$\n",
    "$$S_{ij} = Scalar\\ or\\ Vector$$\n",
    "\n",
    "#### <center>Recurrent function to compute the hidden state at position i,j</center>\n",
    "\n",
    "$$\\vec{h}_{ij}=f(\\vec{h}_{i-1,j},\\vec{h}_{i,j-1}, \\vec{h}_{i-1,j-1}, \\vec{s}_{ij})$$\n",
    "\n",
    "#### <center>Implementation of f to compute $\\vec{h}_{ij}$</center>\n",
    "\n",
    "$$\\underset{(H*3+I) \\times 1}{\\vec{q}}=[ \\underset{1 \\times H}{\\vec{h}^{T}_{(i-1,j)}}; \\underset{1 \\times H}{\\vec{h}^{T}_{(i,j-1)}}; \\underset{1 \\times H}{\\vec{h}^{T}_{(i-1,j-1)}}; \\underset{1 \\times I}{\\vec{s}^{T}_{ij}}]^T$$\n",
    "$$\\underset{H \\times 1}{\\vec{r}_{l}}= \\sigma\\left (\\underset{H\\times(H*3+I)}{W^{(rl)}}\\cdot\\underset{(H*3+I) \\times 1}{\\vec{q}}+\\underset{H \\times 1}{\\vec{b^{(rl)}}}\\right )$$\n",
    "$$\\underset{H \\times 1}{\\vec{r}_{t}}= \\sigma\\left (\\underset{H\\times(H*3+I)}{W^{(rt)}}\\cdot\\underset{(H*3+I) \\times 1}{\\vec{q}}+\\underset{H \\times 1}{\\vec{b^{(rt)}}}\\right )$$\n",
    "$$\\underset{H \\times 1}{\\vec{r}_{d}}= \\sigma\\left (\\underset{H\\times(H*3+I)}{W^{(rd)}}\\cdot\\underset{(H*3+I) \\times 1}{\\vec{q}}+\\underset{H \\times 1}{\\vec{b^{(rd)}}}\\right )$$\n",
    "\n",
    "$$\\underset{(H*3) \\times 1}{\\vec{r}}=[ \\underset{1 \\times H}{\\vec{r}^T_{l}}; \\underset{1 \\times H}{\\vec{r}^T_{t}}; \\underset{1 \\times H}{\\vec{r}^T_{d}} ]^T$$\n",
    "\n",
    "$$\\underset{H \\times 1}{\\vec{z'}_{i}}= \\underset{H\\times(H*3+I)}{W^{(zi)}}\\cdot\\underset{(H*3+I) \\times 1}{\\vec{q}}+\\underset{H \\times 1}{\\vec{b^{(zi)}}}$$\n",
    "$$\\underset{H \\times 1}{\\vec{z'}_{l}}= \\underset{H\\times(H*3+I)}{W^{(zl)}}\\cdot\\underset{(H*3+I) \\times 1}{\\vec{q}}+\\underset{H \\times 1}{\\vec{b^{(zl)}}}$$\n",
    "$$\\underset{H \\times 1}{\\vec{z'}_{t}}= \\underset{H\\times(H*3+I)}{W^{(zt)}}\\cdot\\underset{(H*3+I) \\times 1}{\\vec{q}}+\\underset{H \\times 1}{\\vec{b^{(zt)}}}$$\n",
    "$$\\underset{H \\times 1}{\\vec{z'}_{d}}= \\underset{H\\times(H*3+I)}{W^{(zd)}}\\cdot\\underset{(H*3+I) \\times 1}{\\vec{q}}+\\underset{H \\times 1}{\\vec{b^{(zd)}}}$$\n",
    "\n",
    "$$[\\underset{H \\times 1}{\\vec{z}_{i}}; \\underset{H \\times 1}{\\vec{z}_{l}}; \\underset{H \\times 1}{\\vec{z}_{t}}; \\underset{H \\times 1}{\\vec{z}_{d}}] = SoftMaxByRow\\left([\\underset{H \\times 1}{\\vec{z'}_{i}}; \\underset{H \\times 1}{\\vec{z'}_{l}}; \\underset{H \\times 1}{\\vec{z'}_{t}}; \\underset{H \\times 1}{\\vec{z'}_{d}}]\\right)$$\n",
    "\n",
    "$$\\underset{H \\times 1}{\\vec{h'}_{ij}}=\\theta\\left( \\underset{H\\times I}{W^{(i)}}\\cdot\\underset{I\\times 1}{\\vec{s}_{ij}} + \\underset{H \\times H*3}{U}\\cdot\\left( \\underset{(H*3) \\times 1}{\\vec{r}} \\otimes \\left [ \\underset{1 \\times H}{\\vec{h}^{T}_{(i-1,j)}}; \\underset{1 \\times H}{\\vec{h}^{T}_{(i,j-1)}}; \\underset{1 \\times H}{\\vec{h}^{T}_{(i-1,j-1)}} \\right]^T \\right) + \\underset{H \\times 1}{\\vec{b^{(i)}}} \\right)$$\n",
    "\n",
    "$$\\underset{H \\times 1}{\\vec{h}_{ij}}=\\underset{H \\times 1}{\\vec{z}_{l}}\\otimes \\underset{H \\times 1}{\\vec{h}_{(i,j-1)}} + \\underset{H \\times 1}{\\vec{z}_{t}}\\otimes \\underset{H \\times 1}{\\vec{h}_{(i-1,j)}} + \\underset{H \\times 1}{\\vec{z}_{d}}\\otimes \\underset{H \\times 1}{\\vec{h}_{(i-1,j-1)}} + \\underset{H \\times 1}{\\vec{z}_{i}}\\otimes \\underset{H \\times 1}{\\vec{h'}_{(i,j)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "K.clear_session()\n",
    "\n",
    "# First, let's define a 2D RNN Cell, as a layer subclass.\n",
    "# NOTE: the weights and the forward passage are done with the BATCH dimension,\n",
    "# which means that the previous equations must account for this new dimension\n",
    "class MultiDimensinalGRUCell(tf.keras.layers.Layer):\n",
    "    def __init__(self, \n",
    "                 units,\n",
    "                 activation=None,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 recurrent_initializer='orthogonal',\n",
    "                 bias_initializer='zeros',\n",
    "                 kernel_regularizer=None,\n",
    "                 recurrent_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 **kwargs):\n",
    "        \n",
    "        self.units = units\n",
    "        self.state_size = units\n",
    "        \n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.recurrent_initializer = initializers.get(recurrent_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer) # TODO add to the weights\n",
    "        self.recurrent_regularizer = regularizers.get(recurrent_regularizer) # TODO add to the weights\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer) # TODO add to the weights\n",
    "        \n",
    "        self.activation = activations.get(activation)\n",
    "        \n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        #input shape [BATCH, S]\n",
    "        recurrent_space_plus_feature_dim = self.state_size*3 + input_shape[-1]\n",
    "        \n",
    "        # Trainnable weights for the reset GATES\n",
    "        self.w_rl = self.add_weight(shape=(recurrent_space_plus_feature_dim, self.state_size),\n",
    "                                      initializer=self.recurrent_initializer,\n",
    "                                      name='recurrent_left_reset_weight')\n",
    "        self.b_rl = self.add_weight(shape=(self.state_size,),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      name='recurrent_left_reset_bias')\n",
    "        \n",
    "        self.w_rt = self.add_weight(shape=(recurrent_space_plus_feature_dim, self.state_size),\n",
    "                                      initializer=self.recurrent_initializer,\n",
    "                                      name='recurrent_top_reset_weight')\n",
    "        self.b_rt = self.add_weight(shape=(self.state_size,),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      name='recurrent_top_reset_bias')\n",
    "        \n",
    "        self.w_rd = self.add_weight(shape=(recurrent_space_plus_feature_dim, self.state_size),\n",
    "                                      initializer=self.recurrent_initializer,\n",
    "                                      name='recurrent_diagonal_reset_weight')\n",
    "        self.b_rd = self.add_weight(shape=(self.state_size,),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      name='recurrent_diagonal_reset_bias')\n",
    "        \n",
    "        # Trainnable weights for the feature (Z) GATES\n",
    "        self.w_zi = self.add_weight(shape=(recurrent_space_plus_feature_dim, self.state_size),\n",
    "                                      initializer=self.recurrent_initializer,\n",
    "                                      name='recurrent_input_feature_weight')\n",
    "        self.b_zi = self.add_weight(shape=(self.state_size,),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      name='recurrent_input_feature_bias')\n",
    "        \n",
    "        self.w_zl = self.add_weight(shape=(recurrent_space_plus_feature_dim, self.state_size),\n",
    "                                      initializer=self.recurrent_initializer,\n",
    "                                      name='recurrent_left_feature_weight')\n",
    "        self.b_zl = self.add_weight(shape=(self.state_size,),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      name='recurrent_left_feature_bias')\n",
    "        \n",
    "        self.w_zt = self.add_weight(shape=(recurrent_space_plus_feature_dim, self.state_size),\n",
    "                                      initializer=self.recurrent_initializer,\n",
    "                                      name='recurrent_top_feature_weight')\n",
    "        self.b_zt = self.add_weight(shape=(self.state_size,),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      name='recurrent_top_feature_bias')\n",
    "        \n",
    "        self.w_zd = self.add_weight(shape=(recurrent_space_plus_feature_dim, self.state_size),\n",
    "                                      initializer=self.recurrent_initializer,\n",
    "                                      name='recurrent_diagonal_feature_weight')\n",
    "        self.b_zd = self.add_weight(shape=(self.state_size,),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      name='recurrent_diagonal_feature_bias')\n",
    "        \n",
    "        # projection weigts U\n",
    "        self.u = self.add_weight(shape=(self.state_size*3, self.state_size),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      name='U_weights')\n",
    "        \n",
    "        self.w_i = self.add_weight(shape=(input_shape[-1], self.state_size),\n",
    "                                      initializer=self.recurrent_initializer,\n",
    "                                      name='input_feature_weight')\n",
    "        self.b_i = self.add_weight(shape=(self.state_size,),\n",
    "                                      initializer=self.bias_initializer,\n",
    "                                      name='input_feature_bias')\n",
    "        \n",
    "        super().build(input_shape)\n",
    "\n",
    "    def call(self, x, states):\n",
    "        \n",
    "        # states: [BATCH, 3 (left, top, diagonal)]\n",
    "        \n",
    "        left_state = states[0] #(BATCH, RECURRENT_DIM)\n",
    "        top_state = states[1] #(BATCH, RECURRENT_DIM)\n",
    "        diagonal_state = states[2] #(BATCH, RECURRENT_DIM)\n",
    "        \n",
    "        q_vec = tf.concat([left_state, top_state, diagonal_state, x], axis=1) # [BATCH, 3*RECURRENT_DIM + INPUT_DIM]\n",
    "        \n",
    "                     # [BATCH, RECURRENT_DIM]  [1, RECURRENT_DIM]\n",
    "        reset_left = K.bias_add(K.dot(q_vec, self.w_rl), self.b_rl)\n",
    "        reset_left = sigmoid(reset_left) # [BATCH, RECURRENT_DIM]\n",
    "        \n",
    "        reset_top = K.bias_add(K.dot(q_vec, self.w_rt), self.b_rt)\n",
    "        reset_top = sigmoid(reset_top) # [BATCH, RECURRENT_DIM]\n",
    "        \n",
    "        reset_diagonal = K.bias_add(K.dot(q_vec, self.w_rd), self.b_rd)\n",
    "        reset_diagonal = sigmoid(reset_diagonal) # [BATCH, RECURRENT_DIM]\n",
    "\n",
    "        reset = tf.concat([reset_left, reset_top, reset_diagonal], axis=1) # [BATCH, 3*RECURRENT_DIM]\n",
    "        \n",
    "        _z_input = K.bias_add(K.dot(q_vec, self.w_zi), self.b_zi) # [BATCH, RECURRENT_DIM]\n",
    "        _z_left = K.bias_add(K.dot(q_vec, self.w_zl), self.b_zl) # [BATCH, RECURRENT_DIM]\n",
    "        _z_top = K.bias_add(K.dot(q_vec, self.w_zt), self.b_zt) # [BATCH, RECURRENT_DIM]\n",
    "        _z_diagonal = K.bias_add(K.dot(q_vec, self.w_zd), self.b_zd) # [BATCH, RECURRENT_DIM]\n",
    "        \n",
    "        _z_input = tf.expand_dims(_z_input, axis=-1)\n",
    "        _z_left = tf.expand_dims(_z_left, axis=-1)\n",
    "        _z_top = tf.expand_dims(_z_top, axis=-1)\n",
    "        _z_diagonal = tf.expand_dims(_z_diagonal, axis=-1)\n",
    "        \n",
    "        _z = tf.concat([_z_input, _z_left, _z_top, _z_diagonal], axis=-1)\n",
    "        _z = K.softmax(_z, axis=-1)\n",
    "        \n",
    "        # each will have dims # [BATCH, RECURRENT_DIM]\n",
    "        z = tf.split(_z, num_or_size_splits=4, axis=-1) \n",
    "        z_input = K.squeeze(z[0], axis=-1)\n",
    "        z_left = K.squeeze(z[1], axis=-1)\n",
    "        z_top = K.squeeze(z[2], axis=-1)\n",
    "        z_diagonal = K.squeeze(z[3], axis=-1)\n",
    "        \n",
    "        # compute candite hidden space\n",
    "        _states = tf.concat([left_state, top_state, diagonal_state], axis=1) # [BATCH, 3*RECURRENT_DIM]\n",
    "        reset_states = reset * _states # reset the hidden states # [BATCH, 3*RECURRENT_DIM]\n",
    "        _h_reset_states = K.dot(reset_states, self.u) # [BATCH, RECURRENT_DIM]\n",
    "        _h = K.bias_add(K.dot(x, self.w_i), self.b_i) # [BATCH, RECURRENT_DIM]\n",
    "        _h = _h + _h_reset_states\n",
    "        _h = self.activation(_h)\n",
    "\n",
    "        h = z_left * left_state + z_top * top_state + z_diagonal * diagonal_state + z_input * _h\n",
    "\n",
    "        # OUTPUT [BATCH, Features]\n",
    "        return h#tf.random.normal((K.shape(x)[0], self.state_size))\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.state_size)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multidimensional RNN (2D), implements the multidimensional recurrency in tensorflow\n",
    "\n",
    "It's written in tensorflow 2.0, but a conversion for tensorflow 1.X should be straitforward with the tf.while_loop and tf.cond "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "class MultiDimensionalRNN(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 cell,\n",
    "                 inital_state=None,\n",
    "                 **kwargs):\n",
    "\n",
    "        # outter layer keep track of the inner layer\n",
    "        self.cell = cell\n",
    "        self.inital_state = inital_state\n",
    "\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.rows = int(input_shape[1])\n",
    "        self.columns = int(input_shape[2])\n",
    "        if len(input_shape)==3:\n",
    "            self.features = 1\n",
    "        else:\n",
    "            self.features = int(input_shape[3])\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "    # Base LOOP\n",
    "    @tf.function\n",
    "    def dynamic_tf_loop(self, input_data):\n",
    "\n",
    "        input_shape = K.shape(input_data)\n",
    "        print(\"[DYNAMIC LOOP] input shape\",input_shape)\n",
    "\n",
    "        if self.inital_state is None:\n",
    "            initial_state = tf.zeros((input_shape[1],self.cell.state_size)) # default state\n",
    "        else:\n",
    "            initial_state = self.inital_state\n",
    "\n",
    "        input_flat = tf.TensorArray(dtype=tf.float32, size=self.rows*self.columns)\n",
    "\n",
    "        input_flat = input_flat.unstack(input_data) # 1D data representation\n",
    "\n",
    "        # each entry (2D matrix entry) of the TensorArray is compised by a vector [BATCH, FEATURES]\n",
    "\n",
    "        ######\n",
    "        # find the recursive states base on the one dimentional index\n",
    "        ######\n",
    "        def get_back_state(index, states, columns):\n",
    "            if 0>=index%columns: # out of the matrix/terminal case\n",
    "                return initial_state\n",
    "            else:\n",
    "                return states.read(index-1)\n",
    "\n",
    "        def get_up_state(index, states, columns):\n",
    "            if index<columns: # out of the matrix/terminal case\n",
    "                return initial_state\n",
    "            else:\n",
    "                return states.read(index-columns)\n",
    "\n",
    "        def get_diagonal_state(index, states, columns):\n",
    "            if 0>=index%columns or index<columns: # out of the matrix/terminal case\n",
    "                return initial_state\n",
    "            else:\n",
    "                return states.read(index-columns-1)\n",
    "        ######\n",
    "        # END\n",
    "        ######\n",
    "\n",
    "        # flat matrix with all the hidden states\n",
    "        # clear_after_read must be False, since some entries (e.g. diagonal) could read up on 3 times the same state value\n",
    "        states = tf.TensorArray(dtype=tf.float32, size=self.rows*self.columns, clear_after_read = False)\n",
    "\n",
    "        # sequential loop -> recursive loop\n",
    "        print(\"Loop Iterations\",self.rows*self.columns)\n",
    "        for i in tf.range(self.rows*self.columns):\n",
    "\n",
    "            states = states.write(i,\n",
    "                                  self.cell(input_flat.read(i),\n",
    "                                                 [get_back_state(i, states, self.columns),\n",
    "                                                 get_up_state(i, states, self.columns),\n",
    "                                                 get_diagonal_state(i, states, self.columns)])\n",
    "                                 )\n",
    "\n",
    "\n",
    "        return states.stack()\n",
    "    \n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        input_shape = K.shape(x)\n",
    "        batch = input_shape[0]\n",
    "\n",
    "        input_data = K.reshape(x, [batch, -1, self.features])\n",
    "        input_data = tf.transpose(input_data, (1, 0, 2))\n",
    "\n",
    "        states = self.dynamic_tf_loop(input_data)\n",
    "\n",
    "        # return the last computed states, i.e. h_{M,N}\n",
    "        return tf.reshape(states[-1], self.compute_output_shape(input_shape))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.cell.state_size)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 3 2 1 3]\n",
      " [2 1 1 4 2 1]\n",
      " [3 2 2 1 3 3]\n",
      " [4 4 0 4 3 1]\n",
      " [0 4 4 0 3 3]]\n",
      "[DYNAMIC LOOP] input shape Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
      "Loop Iterations 30\n",
      "[DYNAMIC LOOP] input shape Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
      "Loop Iterations 30\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "multi_dimensional_rnn (Multi (None, 4)                 480       \n",
      "=================================================================\n",
      "Total params: 480\n",
      "Trainable params: 480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "\n",
    "samples = np.random.randint(0,5,size=(10,5,6,2),dtype=np.int32)\n",
    "print(samples[0,:,:,0])\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(MultiDimensionalRNN(MultiDimensinalGRUCell(4, activation='tanh'), input_shape=(5,6,2)))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11600827,  0.08719105, -0.9175204 ,  0.3317431 ],\n",
       "       [ 0.09044574,  0.02689793, -0.89777946,  0.34646532],\n",
       "       [ 0.08953112,  0.03760115, -0.8939328 ,  0.3576638 ],\n",
       "       [ 0.11472344,  0.10193343, -0.8590306 ,  0.35245255],\n",
       "       [ 0.1352495 ,  0.04094839, -0.83062124,  0.4225371 ],\n",
       "       [ 0.12522927,  0.14861901, -0.86151654,  0.3836741 ],\n",
       "       [ 0.10181195,  0.13453832, -0.87949765,  0.39124557],\n",
       "       [ 0.10965315, -0.02972251, -0.9107307 ,  0.35705563],\n",
       "       [ 0.12083595,  0.13359556, -0.83007824,  0.41804466],\n",
       "       [ 0.12485104,  0.06513244, -0.9355093 ,  0.42319936]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small simillarity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_stsb_csv(csv_file):\n",
    "    _data = []\n",
    "\n",
    "    with open(csv_file, \"r\", encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            _l = line.split(\"\\t\")[4:7]\n",
    "            #_l[1] = _l[1][1:-1]\n",
    "            #_l[2] = _l[2][1:-1]\n",
    "            _data.append(_l)\n",
    "            \n",
    "\n",
    "    _data = pd.DataFrame(_data, columns=[\"similarity\", \"sentenceA\", \"sentenceB\"])\n",
    "    _data[\"similarity\"] = pd.to_numeric(_data[\"similarity\"]) \n",
    "    \n",
    "    return _data\n",
    "\n",
    "# read STS_B dataset\n",
    "# download at: http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark\n",
    "\n",
    "train = read_stsb_csv(\"/backup/Semantic_Similarity/stsbenchmark/sts-train.csv\")\n",
    "dev = read_stsb_csv(\"/backup/Semantic_Similarity/stsbenchmark/sts-dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 58\n",
      "Avg length: 10.418126638156988\n"
     ]
    }
   ],
   "source": [
    "# prepare tokenizer\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tk = Tokenizer()\n",
    "\n",
    "tk.fit_on_texts(train[\"sentenceA\"])\n",
    "tk.fit_on_texts(train[\"sentenceB\"])\n",
    "\n",
    "tk.fit_on_texts(dev[\"sentenceA\"])\n",
    "tk.fit_on_texts(dev[\"sentenceB\"])\n",
    "\n",
    "all_sentences = []\n",
    "\n",
    "all_sentences.extend(tk.texts_to_sequences(train[\"sentenceA\"].values.tolist()))\n",
    "all_sentences.extend(tk.texts_to_sequences(train[\"sentenceB\"].values.tolist()))\n",
    "all_sentences.extend(tk.texts_to_sequences(dev[\"sentenceA\"].values.tolist()))\n",
    "all_sentences.extend(tk.texts_to_sequences(dev[\"sentenceB\"].values.tolist()))\n",
    "\n",
    "_stats = list(map(lambda x:len(x),all_sentences))\n",
    "\n",
    "print(\"Max length:\",max(_stats))\n",
    "print(\"Avg length:\",np.average(_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coverage 0.9108079748163693\n"
     ]
    }
   ],
   "source": [
    "# load embeddings\n",
    "embeddings = {}\n",
    "with open(\"/backup/pre-trained_embeddings/glove/glove.6B.50d.txt\", \"r\", encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        _l = line.split(\" \")\n",
    "        embeddings[_l[0]] = _l[1:]\n",
    "        \n",
    "emb_voc = set(embeddings.keys())\n",
    "emb_text = set(tk.word_index.keys())\n",
    "\n",
    "print(\"coverage\",len(emb_text&emb_voc)/len(emb_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove tokens without embeddings\n",
    "\n",
    "miss_tokens = emb_text - (emb_text&emb_voc)\n",
    "\n",
    "for token in miss_tokens:\n",
    "    del tk.word_index[token]\n",
    "\n",
    "#rebuild tokenizer index (hacking the tokenizer, not the clean solution)\n",
    "tk.word_index = { d[0]:i+1 for i,d in  enumerate(tk.word_index.items())}\n",
    "tk.index_word = { i:w for w,i in  tk.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coverage 1.0\n",
      "Max length: 55\n",
      "Avg length: 10.238860532487239\n"
     ]
    }
   ],
   "source": [
    "emb_text = set(tk.word_index.keys())\n",
    "\n",
    "print(\"coverage\",len(emb_text&emb_voc)/len(emb_text))\n",
    "\n",
    "all_sentences = []\n",
    "\n",
    "all_sentences.extend(tk.texts_to_sequences(train[\"sentenceA\"].values.tolist()))\n",
    "all_sentences.extend(tk.texts_to_sequences(train[\"sentenceB\"].values.tolist()))\n",
    "all_sentences.extend(tk.texts_to_sequences(dev[\"sentenceA\"].values.tolist()))\n",
    "all_sentences.extend(tk.texts_to_sequences(dev[\"sentenceB\"].values.tolist()))\n",
    "\n",
    "_stats = list(map(lambda x:len(x),all_sentences))\n",
    "\n",
    "print(\"Max length:\",max(_stats))\n",
    "print(\"Avg length:\",np.average(_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build embedding matrix\n",
    "EMB_SIZE = 50\n",
    "VOCAB_SIZE = len(emb_text)+1\n",
    "emb_matrix = np.empty((VOCAB_SIZE, EMB_SIZE))\n",
    "emb_matrix[0,:] = 0.04 * np.random.random((50,)) - 0.02\n",
    "\n",
    "[0.04 * np.random.random((50,)) - 0.02] # 0 index random init between [-0.02,0.02[\n",
    "for w,i in tk.word_index.items():\n",
    "    emb_matrix[i,:] = np.array(embeddings[w])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# auxiliar input layer\n",
    "class SimilarityLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        self.dot_layer = Dot(axes=-1, normalize=True)\n",
    "        super().__init__(**kwargs)\n",
    "            \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.sentence_size = int(input_shape[0][1])\n",
    "        emb_dim = int(input_shape[0][2])\n",
    "        \n",
    "        self.a = self.add_weight(shape=(emb_dim,1),\n",
    "                                 initializer=\"glorot_uniform\")\n",
    "        \n",
    "        self.b = self.add_weight(shape=(emb_dim,1),\n",
    "                                 initializer=\"glorot_uniform\")\n",
    "\n",
    "        super().build(input_shape)\n",
    "        \n",
    "    @tf.function\n",
    "    def call(self, x):\n",
    "        inputA = x[0] # embedding format\n",
    "        inputB = x[1] # embedding format\n",
    "        \n",
    "        dot = K.expand_dims(self.dot_layer(x), axis=-1)\n",
    "        # TODO the code here will be broken if the matrix is not square!!! TODO IZ FIX\n",
    "        #print(dot)\n",
    "        _a = K.dot(inputA, self.a)\n",
    "        _a = K.expand_dims(_a, axis=-2)\n",
    "        _a = K.repeat_elements(_a, self.sentence_size, axis=-2)\n",
    "        #print(_a)\n",
    "        _b = K.dot(inputB, self.b)\n",
    "        _b = K.expand_dims(_b, axis=-2)\n",
    "        _b = K.repeat_elements(_b, self.sentence_size, axis=-2)\n",
    "        #print(_b)\n",
    "        \n",
    "        return K.concatenate([dot, _a, _b],axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "from tensorflow.keras.layers import InputLayer, Embedding, Dot, Dense, Conv2D, GlobalMaxPool2D, MaxPool2D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "S_LENGTH = 25\n",
    "\n",
    "def model_cnn(categorical=True):\n",
    "    inputA = Input(shape=(S_LENGTH,), name=\"inputA\")\n",
    "    inputB = Input(shape=(S_LENGTH,), name=\"inputB\")\n",
    "\n",
    "    emb = Embedding(VOCAB_SIZE, EMB_SIZE, embeddings_initializer=tf.keras.initializers.Constant(emb_matrix), trainable=False)\n",
    "\n",
    "    sim = SimilarityLayer()\n",
    "    cnn_1 = Conv2D(32, kernel_size=(3,3), activation = \"relu\")\n",
    "    pool_1 = MaxPool2D()\n",
    "    flat_1 = Flatten()\n",
    "    if categorical:\n",
    "        dense = Dense(6, activation=\"softmax\")\n",
    "    else:\n",
    "        dense = Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    embA = emb(inputA)\n",
    "    embB = emb(inputB)\n",
    "    dot = sim([embA,embB])\n",
    "    cnn = cnn_1(dot)\n",
    "    pool = pool_1(cnn)\n",
    "    flat = flat_1(pool)\n",
    "    out_sim = dense(flat)\n",
    "\n",
    "    return Model(inputs=[inputA,inputB], outputs=[out_sim])\n",
    "\n",
    "def model_cnn_global_max(categorical=True):\n",
    "    inputA = Input(shape=(S_LENGTH,), name=\"inputA\")\n",
    "    inputB = Input(shape=(S_LENGTH,), name=\"inputB\")\n",
    "\n",
    "    emb = Embedding(VOCAB_SIZE, EMB_SIZE, embeddings_initializer=tf.keras.initializers.Constant(emb_matrix), trainable=False)\n",
    "\n",
    "    sim = SimilarityLayer()\n",
    "    cnn_1 = Conv2D(32, kernel_size=(3,3), activation = \"relu\")\n",
    "    pool_1 = GlobalMaxPool2D()\n",
    "\n",
    "    if categorical:\n",
    "        dense = Dense(6, activation=\"softmax\")\n",
    "    else:\n",
    "        dense = Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    embA = emb(inputA)\n",
    "    embB = emb(inputB)\n",
    "    dot = sim([embA,embB])\n",
    "    cnn = cnn_1(dot)\n",
    "    pool = pool_1(cnn)\n",
    "    out_sim = dense(pool)\n",
    "\n",
    "    return Model(inputs=[inputA,inputB], outputs=[out_sim])\n",
    "\n",
    "def model_small_cnn(categorical=True):\n",
    "    inputA = Input(shape=(S_LENGTH,), name=\"inputA\")\n",
    "    inputB = Input(shape=(S_LENGTH,), name=\"inputB\")\n",
    "\n",
    "    emb = Embedding(VOCAB_SIZE, EMB_SIZE, embeddings_initializer=tf.keras.initializers.Constant(emb_matrix), trainable=False)\n",
    "\n",
    "    sim = SimilarityLayer()\n",
    "    cnn_1 = Conv2D(8, kernel_size=(3,3), activation = \"relu\")\n",
    "    pool_1 = MaxPool2D()\n",
    "    flat_1 = Flatten()\n",
    "    if categorical:\n",
    "        dense = Dense(6, activation=\"softmax\")\n",
    "    else:\n",
    "        dense = Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    embA = emb(inputA)\n",
    "    embB = emb(inputB)\n",
    "    dot = sim([embA,embB])\n",
    "    cnn = cnn_1(dot)\n",
    "    pool = pool_1(cnn)\n",
    "    flat = flat_1(pool)\n",
    "    out_sim = dense(flat)\n",
    "\n",
    "    return Model(inputs=[inputA,inputB], outputs=[out_sim])\n",
    "\n",
    "def model_2D_gru(categorical=True):\n",
    "    inputA = Input(shape=(S_LENGTH,), name=\"inputA\")\n",
    "    inputB = Input(shape=(S_LENGTH,), name=\"inputB\")\n",
    "\n",
    "    emb = Embedding(VOCAB_SIZE, EMB_SIZE, embeddings_initializer=tf.keras.initializers.Constant(emb_matrix), trainable=False)\n",
    "\n",
    "    sim = SimilarityLayer()\n",
    "\n",
    "    gru_2d = MultiDimensionalRNN(MultiDimensinalGRUCell(6, activation='tanh'))\n",
    "    if categorical:\n",
    "        dense = Dense(6, activation=\"softmax\")\n",
    "    else:\n",
    "        dense = Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    embA = emb(inputA)\n",
    "    embB = emb(inputB)\n",
    "    dot = sim([embA,embB])\n",
    "    h = gru_2d(dot)\n",
    "    out_sim = dense(h)\n",
    "\n",
    "    return Model(inputs=[inputA,inputB], outputs=[out_sim])\n",
    "\n",
    "def model_2D_gru_cnn(categorical=True):\n",
    "    inputA = Input(shape=(S_LENGTH,), name=\"inputA\")\n",
    "    inputB = Input(shape=(S_LENGTH,), name=\"inputB\")\n",
    "\n",
    "    emb = Embedding(VOCAB_SIZE, EMB_SIZE, embeddings_initializer=tf.keras.initializers.Constant(emb_matrix), trainable=False)\n",
    "\n",
    "    sim = SimilarityLayer()\n",
    "    \n",
    "    cnn_1 = Conv2D(4, kernel_size=(3,3), activation = \"relu\")\n",
    "    pool_1 = MaxPool2D()\n",
    "    cnn_2 = Conv2D(8, kernel_size=(3,3), activation = \"relu\")\n",
    "    pool_2 = MaxPool2D()\n",
    "    gru_2d = MultiDimensionalRNN(MultiDimensinalGRUCell(6, activation='tanh'))\n",
    "    if categorical:\n",
    "        dense = Dense(6, activation=\"softmax\")\n",
    "    else:\n",
    "        dense = Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "    embA = emb(inputA)\n",
    "    embB = emb(inputB)\n",
    "    dot = sim([embA,embB])\n",
    "    x = cnn_1(dot)\n",
    "    x = pool_1(x)\n",
    "    x = cnn_2(x)\n",
    "    x = pool_2(x)\n",
    "    h = gru_2d(x)\n",
    "    out_sim = dense(h)\n",
    "\n",
    "    return Model(inputs=[inputA,inputB], outputs=[out_sim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_sim = lambda x: (x - np.min(x))/(np.max(x)-np.min(x))\n",
    "binary_normalize_sim = lambda x: x.apply(lambda y:1 if y>0 else 0)\n",
    "categorical_normalize_sim = lambda x: tf.keras.utils.to_categorical(np.round(x))\n",
    "dumb_convertion = lambda y: [ np.array(x, dtype=np.int32) for x in y]\n",
    "\n",
    "x_train_a = dumb_convertion(tk.texts_to_sequences(train[\"sentenceA\"].values.tolist()))\n",
    "x_train_a = pad_sequences(x_train_a, maxlen=S_LENGTH, padding='post', truncating='post', value=0.0)\n",
    "x_train_b = dumb_convertion(tk.texts_to_sequences(train[\"sentenceB\"].values.tolist()))\n",
    "x_train_b = pad_sequences(x_train_b, maxlen=S_LENGTH, padding='post', truncating='post', value=0.0)\n",
    "y_train = categorical_normalize_sim(train[\"similarity\"].values)\n",
    "\n",
    "x_dev_a = dumb_convertion(tk.texts_to_sequences(dev[\"sentenceA\"].values.tolist()))\n",
    "x_dev_a = pad_sequences(x_dev_a, maxlen=S_LENGTH, padding='post', truncating='post', value=0.0)\n",
    "x_dev_b = dumb_convertion(tk.texts_to_sequences(dev[\"sentenceB\"].values.tolist()))\n",
    "x_dev_b = pad_sequences(x_dev_b, maxlen=S_LENGTH, padding='post', truncating='post', value=0.0)\n",
    "y_dev = categorical_normalize_sim(dev[\"similarity\"].values)\n",
    "\n",
    "def data_generator(x_a, x_b, y, batch_size = 32):\n",
    "    assert len(x_a) == len(x_b)\n",
    "    assert len(x_a) == len(y)\n",
    "    \n",
    "    steps = len(x_a)//batch_size\n",
    "    \n",
    "    while True:\n",
    "        for i in range(0, len(x_a), steps):\n",
    "            yield [np.array(x_a[i:i+batch_size]), np.array(x_b[i:i+batch_size])], y[i:i+batch_size]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " model_cnn\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputA (InputLayer)             [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inputB (InputLayer)             [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 25, 50)       651050      inputA[0][0]                     \n",
      "                                                                 inputB[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "similarity_layer (SimilarityLay (None, 25, 25, 3)    100         embedding[0][0]                  \n",
      "                                                                 embedding[1][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 23, 23, 32)   896         similarity_layer[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 11, 11, 32)   0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3872)         0           max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 6)            23238       flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 675,284\n",
      "Trainable params: 24,234\n",
      "Non-trainable params: 651,050\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "179/179 [==============================] - 8s 46ms/step - loss: 1.6783 - accuracy: 0.2995 - f1: 0.0371 - val_loss: 1.8313 - val_accuracy: 0.2337 - val_f1: 0.0222\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 7s 42ms/step - loss: 1.4497 - accuracy: 0.4313 - f1: 0.1678 - val_loss: 1.9996 - val_accuracy: 0.2322 - val_f1: 0.0970\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 7s 41ms/step - loss: 1.3036 - accuracy: 0.5099 - f1: 0.2853 - val_loss: 2.2711 - val_accuracy: 0.2377 - val_f1: 0.1176\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 7s 41ms/step - loss: 1.1124 - accuracy: 0.6051 - f1: 0.4306 - val_loss: 2.6139 - val_accuracy: 0.2037 - val_f1: 0.1480\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 7s 42ms/step - loss: 1.0236 - accuracy: 0.6431 - f1: 0.5140 - val_loss: 2.5180 - val_accuracy: 0.2322 - val_f1: 0.1357\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 7s 40ms/step - loss: 0.8894 - accuracy: 0.6987 - f1: 0.6037 - val_loss: 2.8318 - val_accuracy: 0.2445 - val_f1: 0.1927\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 7s 41ms/step - loss: 0.8112 - accuracy: 0.7421 - f1: 0.6448 - val_loss: 3.5562 - val_accuracy: 0.2180 - val_f1: 0.1861\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 7s 41ms/step - loss: 0.7422 - accuracy: 0.7713 - f1: 0.6908 - val_loss: 3.3297 - val_accuracy: 0.2180 - val_f1: 0.1767\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 7s 41ms/step - loss: 0.6449 - accuracy: 0.8012 - f1: 0.7437 - val_loss: 3.4435 - val_accuracy: 0.2329 - val_f1: 0.1918\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 7s 41ms/step - loss: 0.6152 - accuracy: 0.8105 - f1: 0.7679 - val_loss: 3.9103 - val_accuracy: 0.2405 - val_f1: 0.2094\n",
      "\n",
      " model_cnn_global_max\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputA (InputLayer)             [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inputB (InputLayer)             [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 25, 50)       651050      inputA[0][0]                     \n",
      "                                                                 inputB[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "similarity_layer_1 (SimilarityL (None, 25, 25, 3)    100         embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 23, 23, 32)   896         similarity_layer_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 32)           0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            198         global_max_pooling2d[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 652,244\n",
      "Trainable params: 1,194\n",
      "Non-trainable params: 651,050\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "179/179 [==============================] - 8s 43ms/step - loss: 1.7668 - accuracy: 0.2482 - f1: 0.0014 - val_loss: 1.7903 - val_accuracy: 0.1894 - val_f1: 0.0000e+00\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 7s 39ms/step - loss: 1.6719 - accuracy: 0.3030 - f1: 0.0000e+00 - val_loss: 1.7727 - val_accuracy: 0.2193 - val_f1: 0.0000e+00\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 7s 39ms/step - loss: 1.6568 - accuracy: 0.3089 - f1: 0.0020 - val_loss: 1.7491 - val_accuracy: 0.2166 - val_f1: 0.0000e+00\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 7s 39ms/step - loss: 1.6152 - accuracy: 0.3407 - f1: 0.0071 - val_loss: 1.7888 - val_accuracy: 0.2180 - val_f1: 0.0040\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 7s 38ms/step - loss: 1.5976 - accuracy: 0.3543 - f1: 0.0168 - val_loss: 1.7913 - val_accuracy: 0.2220 - val_f1: 0.0088\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 7s 38ms/step - loss: 1.5621 - accuracy: 0.3638 - f1: 0.0454 - val_loss: 1.7288 - val_accuracy: 0.2425 - val_f1: 0.0200\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 7s 39ms/step - loss: 1.5387 - accuracy: 0.3792 - f1: 0.0607 - val_loss: 1.7823 - val_accuracy: 0.2296 - val_f1: 0.0343\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 7s 39ms/step - loss: 1.5228 - accuracy: 0.3875 - f1: 0.0711 - val_loss: 1.7596 - val_accuracy: 0.2486 - val_f1: 0.0268\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 7s 41ms/step - loss: 1.4853 - accuracy: 0.4063 - f1: 0.1003 - val_loss: 1.7774 - val_accuracy: 0.2500 - val_f1: 0.0392\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 8s 42ms/step - loss: 1.4809 - accuracy: 0.4080 - f1: 0.1052 - val_loss: 1.7315 - val_accuracy: 0.2704 - val_f1: 0.0617\n",
      "\n",
      " model_small_cnn\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputA (InputLayer)             [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inputB (InputLayer)             [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 25, 50)       651050      inputA[0][0]                     \n",
      "                                                                 inputB[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "similarity_layer_2 (SimilarityL (None, 25, 25, 3)    100         embedding_2[0][0]                \n",
      "                                                                 embedding_2[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 23, 23, 8)    224         similarity_layer_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 11, 11, 8)    0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 968)          0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 6)            5814        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 657,188\n",
      "Trainable params: 6,138\n",
      "Non-trainable params: 651,050\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/179 [==============================] - 8s 44ms/step - loss: 1.6962 - accuracy: 0.2917 - f1: 0.0225 - val_loss: 1.7979 - val_accuracy: 0.2241 - val_f1: 0.0234\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 7s 37ms/step - loss: 1.5543 - accuracy: 0.3545 - f1: 0.1044 - val_loss: 1.8559 - val_accuracy: 0.2404 - val_f1: 0.0778\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 7s 38ms/step - loss: 1.4897 - accuracy: 0.3804 - f1: 0.1421 - val_loss: 1.9855 - val_accuracy: 0.2384 - val_f1: 0.1081\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 7s 39ms/step - loss: 1.3708 - accuracy: 0.4493 - f1: 0.2262 - val_loss: 2.1212 - val_accuracy: 0.2153 - val_f1: 0.0957\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 7s 38ms/step - loss: 1.3349 - accuracy: 0.4772 - f1: 0.2476 - val_loss: 2.1609 - val_accuracy: 0.2049 - val_f1: 0.1065\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 7s 38ms/step - loss: 1.2480 - accuracy: 0.5110 - f1: 0.3071 - val_loss: 2.2767 - val_accuracy: 0.2302 - val_f1: 0.1439\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 7s 38ms/step - loss: 1.2041 - accuracy: 0.5359 - f1: 0.3482 - val_loss: 2.7128 - val_accuracy: 0.2241 - val_f1: 0.1553\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 7s 38ms/step - loss: 1.1722 - accuracy: 0.5648 - f1: 0.3781 - val_loss: 2.4857 - val_accuracy: 0.1948 - val_f1: 0.1217\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 7s 38ms/step - loss: 1.0955 - accuracy: 0.6002 - f1: 0.4388 - val_loss: 2.5460 - val_accuracy: 0.2193 - val_f1: 0.1480\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 7s 38ms/step - loss: 1.0979 - accuracy: 0.5874 - f1: 0.4483 - val_loss: 2.9060 - val_accuracy: 0.2214 - val_f1: 0.1622\n",
      "\n",
      " model_2D_gru_cnn\n",
      "[DYNAMIC LOOP] input shape Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
      "Loop Iterations 16\n",
      "[DYNAMIC LOOP] input shape Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
      "Loop Iterations 16\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputA (InputLayer)             [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inputB (InputLayer)             [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 25, 50)       651050      inputA[0][0]                     \n",
      "                                                                 inputB[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "similarity_layer_3 (SimilarityL (None, 25, 25, 3)    100         embedding_3[0][0]                \n",
      "                                                                 embedding_3[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 23, 23, 4)    112         similarity_layer_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 11, 11, 4)    0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 9, 9, 8)      296         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 8)      0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multi_dimensional_rnn (MultiDim (None, 6)            1296        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 6)            42          multi_dimensional_rnn[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 652,896\n",
      "Trainable params: 1,846\n",
      "Non-trainable params: 651,050\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "[DYNAMIC LOOP] input shape Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
      "Loop Iterations 16\n",
      " 32/179 [====>.........................] - ETA: 32s - loss: 1.8072 - accuracy: 0.1582 - f1: 0.0000e+00[DYNAMIC LOOP] input shape Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
      "Loop Iterations 16\n",
      "178/179 [============================>.] - ETA: 0s - loss: 1.7776 - accuracy: 0.2446 - f1: 0.0000e+00- ETA: 6s - lo[DYNAMIC LOOP] input shape Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
      "Loop Iterations 16\n",
      "179/179 [==============================] - 25s 141ms/step - loss: 1.7773 - accuracy: 0.2448 - f1: 0.0000e+00 - val_loss: 1.7720 - val_accuracy: 0.1982 - val_f1: 0.0000e+00\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 18s 100ms/step - loss: 1.7115 - accuracy: 0.2637 - f1: 6.7716e-04 - val_loss: 1.7729 - val_accuracy: 0.2138 - val_f1: 0.0000e+00\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 18s 99ms/step - loss: 1.6930 - accuracy: 0.2791 - f1: 0.0030 - val_loss: 1.7930 - val_accuracy: 0.1996 - val_f1: 0.0015\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 18s 100ms/step - loss: 1.6375 - accuracy: 0.3113 - f1: 0.0212 - val_loss: 1.8525 - val_accuracy: 0.1982 - val_f1: 0.0116\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 18s 100ms/step - loss: 1.6177 - accuracy: 0.3365 - f1: 0.0629 - val_loss: 1.8487 - val_accuracy: 0.2063 - val_f1: 0.0327\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 18s 99ms/step - loss: 1.5841 - accuracy: 0.3437 - f1: 0.1005 - val_loss: 1.8178 - val_accuracy: 0.2240 - val_f1: 0.0534\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 18s 99ms/step - loss: 1.5554 - accuracy: 0.3665 - f1: 0.1173 - val_loss: 1.9311 - val_accuracy: 0.2105 - val_f1: 0.0863\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 18s 100ms/step - loss: 1.5523 - accuracy: 0.3668 - f1: 0.1282 - val_loss: 1.9290 - val_accuracy: 0.1839 - val_f1: 0.0483\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 18s 99ms/step - loss: 1.4974 - accuracy: 0.3938 - f1: 0.1769 - val_loss: 1.9255 - val_accuracy: 0.2015 - val_f1: 0.0617\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 18s 100ms/step - loss: 1.5040 - accuracy: 0.3889 - f1: 0.1796 - val_loss: 1.9484 - val_accuracy: 0.2071 - val_f1: 0.0927\n",
      "\n",
      " model_2D_gru\n",
      "[DYNAMIC LOOP] input shape Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
      "Loop Iterations 625\n",
      "[DYNAMIC LOOP] input shape Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
      "Loop Iterations 625\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputA (InputLayer)             [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inputB (InputLayer)             [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 25, 50)       651050      inputA[0][0]                     \n",
      "                                                                 inputB[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "similarity_layer_4 (SimilarityL (None, 25, 25, 3)    100         embedding_4[0][0]                \n",
      "                                                                 embedding_4[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "multi_dimensional_rnn_1 (MultiD (None, 6)            1056        similarity_layer_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 6)            42          multi_dimensional_rnn_1[0][0]    \n",
      "==================================================================================================\n",
      "Total params: 652,248\n",
      "Trainable params: 1,198\n",
      "Non-trainable params: 651,050\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DYNAMIC LOOP] input shape Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
      "Loop Iterations 625\n",
      " 32/179 [====>.........................] - ETA: 4:07 - loss: 1.7808 - accuracy: 0.1650 - f1: 0.0000e+00[DYNAMIC LOOP] input shape Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
      "Loop Iterations 625\n",
      "178/179 [============================>.] - ETA: 1s - loss: 1.7528 - accuracy: 0.2384 - f1: 0.0000e+00[DYNAMIC LOOP] input shape Tensor(\"Shape:0\", shape=(3,), dtype=int32)\n",
      "Loop Iterations 625\n",
      "179/179 [==============================] - 313s 2s/step - loss: 1.7523 - accuracy: 0.2387 - f1: 0.0000e+00 - val_loss: 1.7805 - val_accuracy: 0.1921 - val_f1: 0.0000e+00\n",
      "Epoch 2/10\n",
      "179/179 [==============================] - 303s 2s/step - loss: 1.7131 - accuracy: 0.2757 - f1: 0.0000e+00 - val_loss: 1.7662 - val_accuracy: 0.2022 - val_f1: 0.0000e+00\n",
      "Epoch 3/10\n",
      "179/179 [==============================] - 306s 2s/step - loss: 1.7157 - accuracy: 0.2699 - f1: 0.0000e+00 - val_loss: 1.7544 - val_accuracy: 0.2016 - val_f1: 0.0000e+00\n",
      "Epoch 4/10\n",
      "179/179 [==============================] - 305s 2s/step - loss: 1.6935 - accuracy: 0.2716 - f1: 0.0000e+00 - val_loss: 1.7926 - val_accuracy: 0.1887 - val_f1: 0.0000e+00\n",
      "Epoch 5/10\n",
      "179/179 [==============================] - 301s 2s/step - loss: 1.6999 - accuracy: 0.2718 - f1: 0.0000e+00 - val_loss: 1.7900 - val_accuracy: 0.1967 - val_f1: 0.0000e+00\n",
      "Epoch 6/10\n",
      "179/179 [==============================] - 303s 2s/step - loss: 1.6850 - accuracy: 0.2833 - f1: 0.0000e+00 - val_loss: 1.7448 - val_accuracy: 0.2247 - val_f1: 0.0000e+00\n",
      "Epoch 7/10\n",
      "179/179 [==============================] - 306s 2s/step - loss: 1.6821 - accuracy: 0.2847 - f1: 0.0010 - val_loss: 1.8019 - val_accuracy: 0.2003 - val_f1: 0.0000e+00\n",
      "Epoch 8/10\n",
      "179/179 [==============================] - 305s 2s/step - loss: 1.6853 - accuracy: 0.2801 - f1: 0.0017 - val_loss: 1.7900 - val_accuracy: 0.2023 - val_f1: 0.0000e+00\n",
      "Epoch 9/10\n",
      "179/179 [==============================] - 301s 2s/step - loss: 1.6617 - accuracy: 0.2930 - f1: 0.0027 - val_loss: 1.7941 - val_accuracy: 0.1981 - val_f1: 0.0013\n",
      "Epoch 10/10\n",
      "179/179 [==============================] - 303s 2s/step - loss: 1.6772 - accuracy: 0.2817 - f1: 0.0044 - val_loss: 1.7633 - val_accuracy: 0.2234 - val_f1: 0.0026\n"
     ]
    }
   ],
   "source": [
    "for model in [model_cnn, model_cnn_global_max, model_small_cnn, model_2D_gru_cnn, model_2D_gru]:\n",
    "    print(\"\\n\", model.__name__)\n",
    "    model = model()\n",
    "    model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\", metrics=[\"accuracy\", f1])\n",
    "    model.summary()\n",
    "    BATCH = 32\n",
    "\n",
    "    model.fit_generator(data_generator(x_train_a, x_train_b, y_train, batch_size=BATCH),\n",
    "                        steps_per_epoch= len(x_train_a)//BATCH,\n",
    "                        epochs = 10,\n",
    "                        validation_data=data_generator(x_dev_a, x_dev_b, y_dev, batch_size=BATCH), \n",
    "                        validation_steps= len(x_dev_a)//BATCH)\n",
    "    del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow 2.0",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
