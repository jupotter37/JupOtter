{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyMC4 â€” Hiding `yield` from the Model Specification API\n",
    "\n",
    "Please refer to the `README.org` for context and discussion. In this notebook I will outline my proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last run: 2019-07-10 14:13:35.934874\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(\"Last run:\", datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import __future__\n",
    "import ast\n",
    "import functools\n",
    "import inspect\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow_probability import distributions as tfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AST Helper Functions\n",
    "\n",
    "Based on http://code.activestate.com/recipes/578353-code-to-source-and-back/.\n",
    "\n",
    "The main thing to take away from this cell block is that `uncompile` takes a Python object and returns its source code (along with a bunch of other things, but we're less interested in those), and `recompile` takes either:\n",
    "\n",
    "1. the output of `uncompile`, or\n",
    "2. a modified AST, and `compile`s (the Python built-in) it down to bytecode.\n",
    "    \n",
    "The output of `uncompile` can then be `exec`'ed or `eval`'ed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PyCF_MASK = sum(v for k, v in vars(__future__).items() if k.startswith(\"CO_FUTURE\"))\n",
    "\n",
    "\n",
    "def uncompile(c):\n",
    "    \"\"\"uncompile(codeobj) -> [source, filename, mode, flags, firstlineno, privateprefix].\"\"\"\n",
    "    if c.co_flags & inspect.CO_NESTED or c.co_freevars:\n",
    "        raise NotImplementedError(\"Nested functions not supported\")\n",
    "    if c.co_name == \"<lambda>\":\n",
    "        raise NotImplementedError(\"Lambda functions not supported\")\n",
    "    if c.co_filename == \"<string>\":\n",
    "        raise NotImplementedError(\"Code without source file not supported\")\n",
    "\n",
    "    filename = inspect.getfile(c)\n",
    "\n",
    "    try:\n",
    "        lines, firstlineno = inspect.getsourcelines(c)\n",
    "    except IOError:\n",
    "        raise RuntimeError(\"Source code not available\")\n",
    "\n",
    "    source = \"\".join(lines)\n",
    "\n",
    "    # __X is mangled to _ClassName__X in methods. Find this prefix:\n",
    "    privateprefix = None\n",
    "    for name in c.co_names:\n",
    "        m = re.match(\"^(_[A-Za-z][A-Za-z0-9_]*)__.*$\", name)\n",
    "        if m:\n",
    "            privateprefix = m.group(1)\n",
    "            break\n",
    "\n",
    "    return [source, filename, \"exec\", c.co_flags & PyCF_MASK, firstlineno, privateprefix]\n",
    "\n",
    "\n",
    "def recompile(source, filename, mode, flags=0, firstlineno=1, privateprefix=None):\n",
    "    \"\"\"Recompile output of uncompile back to a code object. source may also be preparsed AST.\"\"\"\n",
    "    if isinstance(source, ast.AST):\n",
    "        a = source\n",
    "    else:\n",
    "        a = parse_snippet(source, filename, mode, flags, firstlineno)\n",
    "\n",
    "    node = a.body[0]\n",
    "\n",
    "    if not isinstance(node, ast.FunctionDef):\n",
    "        raise RuntimeError(\"Expecting function AST node\")\n",
    "\n",
    "    c0 = compile(a, filename, mode, flags, True)\n",
    "\n",
    "    return c0\n",
    "\n",
    "\n",
    "def parse_snippet(source, filename, mode, flags, firstlineno, privateprefix_ignored=None):\n",
    "    \"\"\"Like ast.parse, but accepts indented code snippet with a line number offset.\"\"\"\n",
    "    args = filename, mode, flags | ast.PyCF_ONLY_AST, True\n",
    "    prefix = \"\\n\"\n",
    "    try:\n",
    "        a = compile(prefix + source, *args)\n",
    "    except IndentationError:\n",
    "        # Already indented? Wrap with dummy compound statement\n",
    "        prefix = \"with 0:\\n\"\n",
    "        a = compile(prefix + source, *args)\n",
    "        # Peel wrapper\n",
    "        a.body = a.body[0].body\n",
    "    ast.increment_lineno(a, firstlineno - 2)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyMC4 Backend\n",
    "\n",
    "Now, let's talk about what the backends need to look like.\n",
    "\n",
    "First, a helper class to traverse and transform the AST of the user-defined model specification function. Half the magic is in this class: please read the docstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionToGenerator(ast.NodeTransformer):\n",
    "    \"\"\"\n",
    "    This subclass traverses the AST of the user-written, decorated,\n",
    "    model specification and transforms it into a generator for the\n",
    "    model. Subclassing in this way is the idiomatic way to transform\n",
    "    an AST.\n",
    "\n",
    "    Specifically:\n",
    "    \n",
    "    1. Add `yield` keywords to all assignments\n",
    "       E.g. `x = tfd.Normal(0, 1)` -> `x = yield tfd.Normal(0, 1)`\n",
    "    2. Rename the model specification function to\n",
    "       `_pm_compiled_model_generator`. This is done out an abundance\n",
    "       of caution more than anything.\n",
    "    3. Remove the @Model decorator. Otherwise, we risk running into\n",
    "       an infinite recursion.\n",
    "    \"\"\"\n",
    "    def visit_Assign(self, node):\n",
    "        # TODO: AugAssign and AnnAssign nodes, for completeness.\n",
    "        # https://greentreesnakes.readthedocs.io/en/latest/nodes.html#AugAssign\n",
    "        # https://greentreesnakes.readthedocs.io/en/latest/nodes.html#AnnAssign\n",
    "        new_node = node\n",
    "        new_node.value = ast.Yield(value=new_node.value)\n",
    "\n",
    "        # Tie up loose ends in the AST.\n",
    "        # FIXME: I may be cargo-culting what I've read in docs and tutorials.\n",
    "        ast.copy_location(new_node, node)\n",
    "        ast.fix_missing_locations(new_node)\n",
    "        self.generic_visit(node)\n",
    "        return new_node\n",
    "    \n",
    "    def visit_FunctionDef(self, node):\n",
    "        new_node = node\n",
    "        new_node.name = \"_pm_compiled_model_generator\"\n",
    "        new_node.decorator_list = []\n",
    "\n",
    "        # FIXME: Some more cargo-culting.\n",
    "        ast.copy_location(new_node, node)\n",
    "        ast.fix_missing_locations(new_node)\n",
    "        self.generic_visit(node)\n",
    "        return new_node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for the `pm.Model` decorator. Instead of a function, our decorator [will be a class](https://realpython.com/primer-on-python-decorators/#classes-as-decorators). This allows us to have a stateful decorator, where we can store model-related things (e.g. the AST and the generator) and even define user-facing functions such as `sample` or `observe`. The other half of the magic is in this class: please read the comments and docstrings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    \"\"\" pm.Model decorator. \"\"\"\n",
    "\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "\n",
    "        # Introspect wrapped function, instead of the decorator class.\n",
    "        functools.update_wrapper(self, func)\n",
    "\n",
    "        # Uncompile wrapped function\n",
    "        uncompiled = uncompile(func.__code__)\n",
    "\n",
    "        # Parse AST and modify it\n",
    "        tree = parse_snippet(*uncompiled)\n",
    "        tree = FunctionToGenerator().visit(tree)\n",
    "        uncompiled[0] = tree\n",
    "\n",
    "        # Recompile wrapped function\n",
    "        self.recompiled = recompile(*uncompiled)    \n",
    "        \n",
    "        # Execute recompiled code (defines `_pm_compiled_model_generator`)\n",
    "        # in the locals() namespace and assign it to an attribute.\n",
    "        # Refer to http://lucumr.pocoo.org/2011/2/1/exec-in-python/\n",
    "        # FIXME: Need to understand locals() and namespaces more.\n",
    "        exec(self.recompiled, None, locals())\n",
    "        self.model_generator = locals()[\"_pm_compiled_model_generator\"]\n",
    "\n",
    "    \"\"\"\n",
    "    The following three functions aren't necessary for the rest of the notebook.\n",
    "    I just want to point out that this would be natural places to define these functions.\n",
    "    Refer to the \"User-Facing API\" section (below) for why.\n",
    "    \"\"\"\n",
    "        \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        # Could be something like what we have already:\n",
    "        # https://github.com/pymc-devs/pymc4/blob/master/pymc4/coroutine_model.py#L63\n",
    "        raise NotImplementedError(\"Evaluate model, as in `coroutine_model.py`.\")\n",
    "\n",
    "    def sample(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"George isn't sure how sampling works.\")\n",
    "\n",
    "    def observe(self, *args, **kwargs):\n",
    "        raise NotImplementedError(\"George isn't sure how observing works, either.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-Facing Model Specification API\n",
    "\n",
    "And now all users need to see is this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@Model\n",
    "def linear_regression(x):\n",
    "    scale = tfd.HalfCauchy(0, 1)\n",
    "    coefs = tfd.Normal(tf.zeros(x.shape[1]), 1)\n",
    "    predictions = tfd.Normal(tf.linalg.matvec(x, coefs), scale)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What else can we do in the `Model` decorator?\n",
    "\n",
    "1. If we define `__call__`, then users can run `predictions = linear_regression(tf.zeros([3, 10]))`. I am unsure what we would want this to return. Note that this will **not** be as straightfoward as\n",
    "\n",
    "    ```python\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)\n",
    "    ```\n",
    "   since (currently) `self.func` is the user-defined function that crashes (just as in @ferrine's example). More bluntly, users will be writing a function that, without the `@Model` decorator, crashes. On the other hand, if we _don't_ implement `__call__`, users will write a function and get back a `Model` object that _cannot be called_, as you would expect a function to be. Tricky situation; food for thought; feedback needed!\n",
    "\n",
    "2. If we define `sample`, then users can sample from their model via `linear_regression.sample()`.\n",
    "\n",
    "3. If we define `observe`, then users can provide observations to their model via `linear_regression.observe()` (as suggested by @ferrine and @rpgoldman)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Evaluate model, as in `coroutine_model.py`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d88b8ca2a8e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# All three statements will raise NotImplementedErrors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlinear_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlinear_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-594696e1f854>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# Could be something like what we have already:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# https://github.com/pymc-devs/pymc4/blob/master/pymc4/coroutine_model.py#L63\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Evaluate model, as in `coroutine_model.py`.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Evaluate model, as in `coroutine_model.py`."
     ]
    }
   ],
   "source": [
    "# All three statements will raise NotImplementedErrors.\n",
    "\n",
    "predictions = linear_regression(tf.zeros([3, 10]))\n",
    "linear_regression.sample()\n",
    "linear_regression.observe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyMC4 Core Engine\n",
    "\n",
    "We can get the generator in exactly the same way that @ferrine's notebook requires:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _pm_compiled_model_generator at 0x107a5c5c8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression.model_generator(tf.zeros([3, 10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success!!\n",
    "\n",
    "In fact, to demonstrate that it's actually the generator we need (and that there aren't subtle bugs along the way), we can interact with the generator in exactly the same way as in @ferrine's notebook.\n",
    "\n",
    "I've omitted the \"One level deeper\" section in the notebook: that is, recursively interacting with the generator. I haven't tested it out, but I expect that it would also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://gist.github.com/ferrine/59a63c738e03911eacba515b5be904ad\n",
    "\n",
    "def interact(gen, state):\n",
    "    control_flow = gen()\n",
    "    return_value = None\n",
    "    while True:\n",
    "        try:\n",
    "            dist = control_flow.send(return_value)\n",
    "            if dist.name in state[\"dists\"]:\n",
    "                control_flow.throw(RuntimeError(\n",
    "                    \"We found duplicate names in your cool model: {}, \"\n",
    "                    \"so far we have other variables in the model, {}\".format(\n",
    "                        preds_dist.name, set(state[\"dists\"].keys()), \n",
    "                    )\n",
    "                ))\n",
    "            if dist.name in state[\"samples\"]:\n",
    "                return_value = state[\"samples\"][dist.name]\n",
    "            else:\n",
    "                return_value = dist.sample()\n",
    "                state[\"samples\"][dist.name] = return_value\n",
    "            state[\"dists\"][dist.name] = dist\n",
    "        except StopIteration as e:\n",
    "            if e.args:\n",
    "                return_value = e.args[0]\n",
    "            else:\n",
    "                return_value = None\n",
    "            break\n",
    "    return return_value, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, state = interact(lambda: linear_regression.model_generator(tf.zeros([3, 10])),\n",
    "                        state=dict(dists=dict(), samples=dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Normal_1/sample/Reshape:0' shape=(3,) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dists': {'HalfCauchy/': <tfp.distributions.HalfCauchy 'HalfCauchy/' batch_shape=[] event_shape=[] dtype=float32>,\n",
       "  'Normal/': <tfp.distributions.Normal 'Normal/' batch_shape=[10] event_shape=[] dtype=float32>,\n",
       "  'Normal_1/': <tfp.distributions.Normal 'Normal_1/' batch_shape=[3] event_shape=[] dtype=float32>},\n",
       " 'samples': {'HalfCauchy/': <tf.Tensor 'HalfCauchy/sample/Reshape:0' shape=() dtype=float32>,\n",
       "  'Normal/': <tf.Tensor 'Normal/sample/Reshape:0' shape=(10,) dtype=float32>,\n",
       "  'Normal_1/': <tf.Tensor 'Normal_1/sample/Reshape:0' shape=(3,) dtype=float32>}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and Next Steps\n",
    "\n",
    "Please refer to the `README.org`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.7 :: Anaconda, Inc.\n",
      "jupyter==1.0.0\n",
      "tensorflow==1.14.0\n",
      "tensorflow-probability==0.7.0\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!cat requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
