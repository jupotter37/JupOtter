{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import sys\n",
    "\n",
    "# module_path = os.path.abspath(os.path.join('../../src'))\n",
    "# print(\"adding following folder to path: \",module_path)\n",
    "# if module_path not in sys.path:\n",
    "#     sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy import linspace\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import datetime\n",
    "from scipy import stats\n",
    "import time\n",
    "import copy\n",
    "\n",
    "\n",
    "import csv \n",
    "from pathlib import Path\n",
    "from os import listdir\n",
    "import pickle\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "from datetime import datetime,timedelta\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import NullFormatter\n",
    "from matplotlib.colors import ListedColormap,Normalize\n",
    "import matplotlib.pylab as pl\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "from pytz import timezone\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nna.pre_process_func import read_queue\n",
    "from nna.fileUtils import read_file_properties\n",
    "from nna.labeling_utils import load_labels\n",
    "from nna.visUtils import get_cycle,createTimeIndex,file2TableDict,reverseTableDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DIR_PARENT = \"/home/data/nna/stinchcomb/NUI_DATA/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "linestyle_str = [\n",
    "     ('solid', 'solid'),      # Same as (0, ()) or '-'\n",
    "     ('dotted', 'dotted'),    # Same as (0, (1, 1)) or '.'\n",
    "     ('dashed', 'dashed'),    # Same as '--'\n",
    "     ('dashdot', 'dashdot'),  # Same as '-.\n",
    "     ('densely dotted',        (0, (1, 1))),\n",
    "     ('densely dashed',        (0, (5, 1))),\n",
    "    ('densely dashdotted',    (0, (3, 1, 1, 1))),\n",
    "     ('densely dashdotdotted', (0, (3, 1, 1, 1, 1, 1)))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFlder = \"/home/enis/projects/nna/data/\"\n",
    "resultsFlder = \"/home/enis/projects/nna/results/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2name={}\n",
    "id2name[\"_CABLE\"]=\"Cable\"\n",
    "id2name[\"_RUNNINGWATER\"]=\"Running Water\"\n",
    "id2name[\"_INSECT\"]=\"Insect\"\n",
    "id2name[\"_RAIN\"]=\"Rain\"\n",
    "id2name[\"_WATERBIRD\"]=\"Water Bird\"\n",
    "id2name[\"_WIND\"]=\"Wind\"\n",
    "id2name[\"_SONGBIRD\"]=\"Songbird\"\n",
    "id2name[\"_AIRCRAFT\"]=\"Aircraft\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties_df=pd.read_pickle(\"../../data/stinchcomb_dataV1.pkl\")\n",
    "file_properties_df=pd.read_pickle(\"../../data/prudhoeAndAnwr4photoExp_dataV1.pkl\")\n",
    "\n",
    "#important to keep them in order\n",
    "file_properties_df.sort_values(by=['timestamp'],inplace=True)\n",
    "\n",
    "# delete older than 2016\n",
    "fromtime=datetime(2016, 1, 1, 0)\n",
    "file_properties_df=file_properties_df[file_properties_df.timestamp>=fromtime]\n",
    "all_areas=sorted(pd.unique(file_properties_df.site_id.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# file_properties_df=pd.read_pickle(\"../../data/stinchcomb_dataV1.pkl\")\n",
    "# file_properties_df2=pd.read_pickle(\"../../data/realdata_v2No_stinchcomb.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asd=pd.concat([file_properties_df,file_properties_df2])\n",
    "# asd.sort_values(by=['timestamp'],inplace=True)\n",
    "\n",
    "# asd.to_pickle(\"../../data/allFields_dataV3.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls ../../data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties_df[file_properties_df.site_id==\"47\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMS\n",
    "# FREQS to reduce results \n",
    "# freq=\"30min\"\n",
    "freq=\"2H\"\n",
    "# freq=\"270min\"\n",
    "# freq=\"135min\"\n",
    "# freq=\"continous\"\n",
    "\n",
    "\n",
    "\n",
    "# possible places to pick\n",
    "# sorted(pd.unique(file_properties_df.site_id.values))\n",
    "# areas to be visualized\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# globalindex,all_start,all_end=createTimeIndex(selected_areas,file_properties_df,freq)\n",
    "\n",
    "# selected_tag_name=\"_SONGBIRD\"\n",
    "\n",
    "\n",
    "\n",
    "# weather_cols=[]\n",
    "\n",
    "visFilePath=\"/home/enis/projects/nna/results/vis/PrudhoeAnwrV1/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\" Duration of selected data period:\",(all_end-all_start).days,\"days\")\n",
    "# print(\" Starts: {} \\n Ends:   {}\".format(all_start,all_end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globalindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties_df[file_properties_df.site_id==\"31\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_properties_df[file_properties_df.site_id==selected_area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 0\n",
      "77 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/11/2019/S4A10276_20190707_190000.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/11/2019/S4A10276_20190815_051602.flac')]\n",
      "12 1\n",
      "68 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/12/2019/S4A10274_20190707_000000.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/12/2019/S4A10274_20190905_190000.flac')]\n",
      "13 2\n",
      "69 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/13/2019/S4A10298_20190708_004602.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/13/2019/S4A10298_20190823_000000.flac')]\n",
      "14 3\n",
      "79 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/14/2019/S4A10361_20190707_000000.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/14/2019/S4A10361_20190824_004602.flac')]\n",
      "15 4\n",
      "65 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/15/2019/S4A10283_20190707_011602.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/15/2019/S4A10283_20190904_000000.flac')]\n",
      "16 5\n",
      "18 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/16/2019/S4A10261_20190707_011602.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/16/2019/S4A10261_20190720_224602.flac')]\n",
      "17 6\n",
      "44 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/17/2019/S4A10307_20190707_093000.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/17/2019/S4A10307_20190808_131602.flac')]\n",
      "18 7\n",
      "18 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/18/2019/S4A10280_20190805_043000.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/18/2019/S4A10280_20190904_054602.flac')]\n",
      "19 8\n",
      "30 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/19/2019/S4A10258_20190707_043000.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/19/2019/S4A10258_20190803_100000.flac')]\n",
      "20 9\n",
      "52 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/20/2019/S4A10257_20190707_043000.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/20/2019/S4A10257_20190906_004602.flac')]\n",
      "21 10\n",
      "38 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/21/2019/S4A10227_20190707_093000.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/21/2019/S4A10227_20190818_174602.flac')]\n",
      "22 11\n",
      "34 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/22/2019/S4A10275_20190708_011602.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/22/2019/S4A10275_20190905_104602.flac')]\n",
      "23 12\n",
      "39 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/23/2019/S4A10292_20190708_000000.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/23/2019/S4A10292_20190809_181602.flac')]\n",
      "24 13\n",
      "32 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/24/2019/S4A10301_20190708_104602.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/24/2019/S4A10301_20190908_040000.flac')]\n",
      "25 14\n",
      "40 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/25/2019/S4A10295_20190709_004602.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/25/2019/S4A10295_20190820_171602.flac')]\n",
      "26 15\n",
      "43 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/26/2019/S4A10255_20190804_173000.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/26/2019/S4A10255_20190804_173000.flac')]\n",
      "27 16\n",
      "23 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/27/2019/S4A10339_20190706_151602.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/27/2019/S4A10339_20190904_201602.flac')]\n",
      "28 17\n",
      "29 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/28/2019/S4A10259_20190706_104602.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/28/2019/S4A10259_20190810_103000.flac')]\n",
      "29 18\n",
      "25 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/29/2019/S4A10288_20190708_104602.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/29/2019/S4A10288_20190816_144602.flac')]\n",
      "30 19\n",
      "28 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/30/2019/S4A10264_20190708_011602.flac')]\n",
      "[PosixPath('/tank/data/nna/real/prudhoe/30/2019/S4A10264_20190820_113000.flac')]\n",
      "31 20\n",
      "15 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/anwr/31/2019/S4A10297_20190711_081602.flac')]\n",
      "[PosixPath('/tank/data/nna/real/anwr/31/2019/S4A10297_20190903_140000.flac')]\n",
      "32 21\n",
      "19 number of files do not have results\n",
      "[PosixPath('/tank/data/nna/real/anwr/32/2019/S4A10266_20190711_174602.flac')]\n",
      "[PosixPath('/tank/data/nna/real/anwr/32/2019/S4A10266_20190903_233000.flac')]\n",
      "33 22\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/enis/projects/nna/data/clipping_results/33_1.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-33fcd0b82414>\u001b[0m in \u001b[0;36mVisPredsWClipping\u001b[0;34m(selected_area, file_properties_df, freq, model_tag_names, my_cmaps)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mglobalcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_tag_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#selected_areas+weather_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0mgathered_results_perTag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadClipping2Dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclippingResultsPath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected_areas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselected_tag_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     df_dict_clipping,no_result_paths = file2TableDict(selected_areas,globalcolumns,globalindex,globalcolumns,\n",
      "\u001b[0;32m<ipython-input-28-392572cc8ad6>\u001b[0m in \u001b[0;36mloadClipping2Dict\u001b[0;34m(clippingResultsPath, selected_areas, selected_tag_name)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mto_be_deleted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mfileName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclippingResultsPath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0marea\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_1.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mresultsDict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileName\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mresultsDict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresultsDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mgathered_results_perTag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_tag_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultsDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/enis/conda/envs/speechEnv/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/enis/projects/nna/data/clipping_results/33_1.pkl'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_path=\"/scratch/enis/data/nna/real/\"\n",
    "model_tag_names=[\"CABLE\",\"RUNNINGWATER\",\"INSECT\", \"RAIN\", \"WATERBIRD\", \"WIND\", \"SONGBIRD\", \"AIRCRAFT\"]\n",
    "def main():\n",
    "    cmap = pl.cm.tab10\n",
    "    aCmap = cmap\n",
    "    my_cmaps = addNormalDistAlpha(aCmap)\n",
    "    for selected_area in all_areas:\n",
    "        print(selected_area,all_areas.index(selected_area))\n",
    "        VisPredsWClipping(selected_area, file_properties_df, freq,model_tag_names, my_cmaps)\n",
    "main()\n",
    "# try:\n",
    "#     main()\n",
    "#     !conda run -n speechEnv python /home/enis/projects/nna/src/slack_message.py -m \"continous figures ready \"\n",
    "# except Exception as ex:\n",
    "#     print(ex)\n",
    "#     !conda run -n speechEnv python /home/enis/projects/nna/src/slack_message.py -m \"continous figures failed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def VisPredsWClipping(selected_area,file_properties_df,freq,model_tag_names,my_cmaps):\n",
    "    selected_areas=[selected_area,]\n",
    "    # file length based time index\n",
    "    if freq==\"continous\":\n",
    "        fileTimeIndexSeries = getTimeIndexPerFile(selected_area,file_properties_df,freq)\n",
    "        globalindex = fileTimeIndexSeries\n",
    "    #fixed freq based  time index\n",
    "    else:\n",
    "        globalindex,all_start,all_end = createTimeIndex(selected_areas,file_properties_df,freq)\n",
    "\n",
    "    selected_tag_name=[\"_\"+i for i in model_tag_names]\n",
    "    globalcolumns=selected_tag_name #selected_areas+weather_cols\n",
    "\n",
    "    df_dict,no_result_paths = file2TableDict(selected_areas,selected_tag_name,globalindex,\n",
    "                                             globalcolumns,file_properties_df,freq,dataFreq=\"10S\",\n",
    "                                             result_path=result_path,prob2binaryFlag=False)\n",
    "    if len(no_result_paths)!=0:\n",
    "        print(\"{} number of files do not have results\".format(len(no_result_paths)))\n",
    "        print(no_result_paths[:1])\n",
    "        print(no_result_paths[-1:])\n",
    "        return None\n",
    "    \n",
    "    regionName=file_properties_df[file_properties_df.site_id==selected_area][:1].region[0]\n",
    "\n",
    "    # we are not using this for visualizations\n",
    "    # df_dict_reverse=reverseTableDict(selected_areas,df_dict,model_tag_names)\n",
    "    df_count,df_sums = df_dict[selected_area]\n",
    "\n",
    "    df_freq=df_sums/df_count\n",
    "    # del df_freq['UMIAT']\n",
    "    df_freq=df_freq*100\n",
    "    \n",
    "    ########     LOAD Clipping     #########\n",
    "    clippingResultsPath=dataFlder+\"clipping_results/\"\n",
    "    selected_tag_name=\"Clipping\"\n",
    "#     model_tag_names=[selected_tag_name]\n",
    "    globalcolumns=[selected_tag_name] #selected_areas+weather_cols\n",
    "\n",
    "    gathered_results_perTag = loadClipping2Dict(clippingResultsPath,selected_areas,selected_tag_name)\n",
    "\n",
    "    df_dict_clipping,no_result_paths = file2TableDict(selected_areas,globalcolumns,globalindex,globalcolumns,\n",
    "                                    file_properties_df,freq,dataFreq=\"10S\",dataThreshold=0.01,channel=2,\n",
    "                                    gathered_results_perTag=gathered_results_perTag,result_path=None)\n",
    "\n",
    "    df_count_clipping,df_sums_clipping = df_dict_clipping[selected_area]\n",
    "    df_freq_clipping = df_sums_clipping / df_count_clipping\n",
    "    df_freq_clipping = df_freq_clipping * 100\n",
    "\n",
    "    ### add Clipping data to predictions \n",
    "\n",
    "    df_freq = pd.concat([df_freq, df_freq_clipping], axis=1, sort=False)\n",
    "    if len(no_result_paths)!=0:\n",
    "        print(\"{} number of files do not have results\".format(len(no_result_paths)))\n",
    "\n",
    "    ### Divide data into months\n",
    "\n",
    "    cord_list=[(i,(0,0)) for i in df_freq.columns]\n",
    "    \n",
    "    monthsTime=pd.unique(df_freq.index.strftime(\"%Y-%m-01\"))\n",
    "    monthsTime=[pd.Timestamp(i) for i in monthsTime]\n",
    "    \n",
    "    monthsTimeStr=[\"{}-{}\".format(month.year,month.month) for month in monthsTime]\n",
    "    months=[df_freq.loc[month:month] for month in monthsTimeStr]\n",
    "    ##### align all months\n",
    "    for i,month in enumerate(months):\n",
    "        months[i]=month.rename(index=lambda x: x.replace(month=7,year=2019))\n",
    "\n",
    "    uniqueYears=np.unique([month.year for month in monthsTime])\n",
    "    for year in uniqueYears:\n",
    "        monthsInAYear=[months[i] for i,month in enumerate(monthsTime) if month.year==year]\n",
    "        monthsTimeInAYear=[monthsTime[i] for i,month in enumerate(monthsTime) if month.year==year]\n",
    "        createFigure(selected_area,monthsInAYear,monthsTimeInAYear,my_cmaps,cord_list,visFilePath,regionName,year,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTimeIndexPerFile(selected_area,file_properties_df,freq,timeDifference=5):\n",
    "    #TODO add sensitivity\n",
    "    rowiterator=file_properties_df[file_properties_df.site_id==selected_area].iterrows()\n",
    "    # use first item as initialization, ahead of for loop\n",
    "    n=next(rowiterator)\n",
    "    start=n[1].timestamp\n",
    "    beginning=start\n",
    "    end=n[1].timestampEnd\n",
    "    fileTimeIndex=[]\n",
    "    IsHead=False\n",
    "#     print(start)\n",
    "    for row in rowiterator:\n",
    "        # if end of previous file not equal to start of the second one\n",
    "        if (row[1].timestamp-end)>timedelta(minutes=timeDifference):\n",
    "            # add previous one to list and make new one the beginning of continous recording\n",
    "            fileTimeIndex.append(beginning)\n",
    "            beginning=row[1].timestamp\n",
    "            IsHead=True\n",
    "    #             pass\n",
    "#             print(\"noteq\",row[1].timestamp-end)\n",
    "    #         print(row[1].timestamp,end)\n",
    "        # if they are equal, they should be in the same bin, so keep going\n",
    "        else:\n",
    "            IsHead=False\n",
    "    #             pass\n",
    "    #         print(\"equal\",row[1].timestampEnd-start)\n",
    "    #         fileTimeIndex.append(start)\n",
    "    #         print(row[1].timestampEnd,start)\n",
    "        start=row[1].timestamp\n",
    "        end=row[1].timestampEnd\n",
    "    # If last one is a head add to the list\n",
    "#     print(IsHead)\n",
    "    if IsHead:\n",
    "        fileTimeIndex.append(beginning)\n",
    "    # add end since last bin border should be bigger than all data\n",
    "    fileTimeIndex.append(end)\n",
    "    fileTimeIndexSeries=pd.Series(fileTimeIndex)\n",
    "    return fileTimeIndexSeries\n",
    "\n",
    "\n",
    "# 10191019101019101910101910191\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNormalDistAlpha(aCmap):\n",
    "    # Choose colormap\n",
    "    # cmap = pl.cm.tab10\n",
    "    cmap=aCmap\n",
    "    # Get the colormap colors\n",
    "    my_cmap = aCmap(np.arange(aCmap.N))\n",
    "    my_cmaps=[]\n",
    "    for clr in my_cmap:\n",
    "        r,g,b,_=clr\n",
    "        cdict = {'red':   [[0.0,  r, r],\n",
    "                       [1.0,  r, r]],\n",
    "             'green': [[0.0,  g,  g],\n",
    "                       [1.0,  g, g]],\n",
    "             'blue':  [[0.0,  b, b],\n",
    "                       [1.0,  b, b]],\n",
    "             'alpha':  [[0,  0.9, 0.9],\n",
    "                       [1,  0.1, 0.1]]}\n",
    "\n",
    "        newcmp = LinearSegmentedColormap('testCmap', segmentdata=cdict, N=100)\n",
    "        my_cmaps.append(newcmp)\n",
    "    return my_cmaps\n",
    "\n",
    "def loadClipping2Dict(clippingResultsPath,selected_areas,selected_tag_name):\n",
    "    gathered_results_perTag={selected_tag_name:{}}\n",
    "    gathered_results={}\n",
    "    selected_areas_files={}\n",
    "    for i,area in enumerate(selected_areas):\n",
    "        to_be_deleted=[]\n",
    "        fileName=(clippingResultsPath+area+\"_1.pkl\")\n",
    "        resultsDict=np.load(fileName,allow_pickle=True)\n",
    "        resultsDict=resultsDict[()]\n",
    "        gathered_results_perTag[selected_tag_name].update(resultsDict)\n",
    "    return gathered_results_perTag\n",
    "\n",
    "\n",
    "# def loadClipping(clippingInfoFile):\n",
    "    \n",
    "#     clippingInfo=np.load(clippingInfoFile,allow_pickle=True)\n",
    "#     clippingInfo = clippingInfo[()]\n",
    "#     clippingInfo2={}\n",
    "#     clippingInfoArray=[]\n",
    "#     cc=0\n",
    "#     for clipFile,clipping in clippingInfo.items():\n",
    "#         locID=Path(clipFile).stem.split(\"_\")[:2]\n",
    "#         locID = tuple(locID)\n",
    "#         clippingInfo2[locID] = clipping\n",
    "#         if clipping.shape==(1,2):\n",
    "#             clipping = clipping[0]\n",
    "#         elif clipping.shape==(2,2):\n",
    "#             clipping = clipping[0]\n",
    "#         elif clipping.shape==(2,):\n",
    "#             pass\n",
    "#         else:\n",
    "#             print(\"ERROR\",clipping)\n",
    "#         clippingInfoArray.append(clipping)\n",
    "#         clippingInfo2[locID] = clipping\n",
    "\n",
    "#     clippingInfoArray = np.concatenate(clippingInfoArray).reshape(-1,2)\n",
    "#     return clippingInfo2,clippingInfoArray\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def createFigure(selected_area,months,monthsTime,my_cmaps,cord_list,visFilePath,regionName,year):\n",
    "#     plt.rcParams[\"axes.prop_cycle\"] = get_cycle(\"tab10\",N=8)\n",
    "    vmin,vmax=0,100\n",
    "    normalize = Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(80,len(months)*9),nrows=len(months),sharex=True, sharey=True,gridspec_kw={'hspace': 0})\n",
    "    ax = np.array(ax).reshape(-1) # subplot returns single element for single row\n",
    "\n",
    "    markers = itertools.cycle((',', '+', '.', 'o', '*')) \n",
    "\n",
    "    weather_colors=[\"firebrick\",\"darkorange\",\"green\",\"seagreen\",\"lightpink\"]\n",
    "\n",
    "    for monthi,month in enumerate(months):\n",
    "        # for col in df_freq.columns:\n",
    "        for i,(col,(lat,long)) in enumerate(cord_list):\n",
    "#             if col in weather_cols:\n",
    "#                 index=weather_cols.index(col)\n",
    "#                 ax[monthi].plot_date(month.index.to_pydatetime(), month[col],linestyle=\"-\",marker=\" \",color=weather_colors[index])\n",
    "#             else:\n",
    "#             ax[monthi].plot_date(month.index.to_pydatetime(), month[col],linestyle=\"-\",marker=\" \")\n",
    "            if col==\"Clipping\":\n",
    "                continue\n",
    "            #convert dates to numbers first\n",
    "            inxval = mdates.date2num(month[col].index.to_pydatetime())\n",
    "            points = np.array([inxval, month[col].values]).T.reshape(-1,1,2)\n",
    "            segments = np.concatenate([points[:-1],points[1:]], axis=1)\n",
    "            lc = LineCollection(segments, cmap=my_cmaps[i],norm=normalize, linewidth=3,)\n",
    "            # set color to date values\n",
    "            lc.set_array(month[\"Clipping\"])\n",
    "            # note that you could also set the colors according to y values\n",
    "            # lc.set_array(s.values)\n",
    "            # add collection to axes\n",
    "            ax[monthi].add_collection(lc)\n",
    "#             break\n",
    "\n",
    "    # add legend and set names of the lines\n",
    "    ax[0].legend( labels=[id2name.get(x[0],x[0][1:]) for x in cord_list],loc='upper left', \n",
    "                borderpad=0.2, labelspacing=0.2, fontsize=28, \n",
    "                frameon=True) # frameon=False to remove frame.\n",
    "\n",
    "    # set colours of the lines on the legend\n",
    "    leg = ax[0].get_legend()\n",
    "    for i,(col,(lat,long)) in enumerate(cord_list):\n",
    "        if col==\"Clipping\":\n",
    "            continue\n",
    "        leg.legendHandles[i].set_color(my_cmaps[i](vmin)[:-1])\n",
    "\n",
    "\n",
    "    ax[-1].set_xlabel('Day Number', fontsize=32)\n",
    "\n",
    "#     uniqueYears=pd.unique([month.year for month in monthsTime])\n",
    "#     uniqueYears.size\n",
    "\n",
    "    for i,an_ax in enumerate(ax):    \n",
    "        an_ax.set_ylabel('{}'.format(monthsTime[i].strftime(\"%Y-%B\")),fontsize=48) #, fontweight='black')\n",
    "\n",
    "        locator=mdates.DayLocator()\n",
    "        an_ax.xaxis.set_minor_locator(locator)\n",
    "        an_ax.xaxis.set_minor_formatter(mdates.DateFormatter('%d\\n'))\n",
    "\n",
    "        an_ax.xaxis.grid(True, which=\"minor\")\n",
    "        an_ax.xaxis.grid(True, which=\"major\")\n",
    "\n",
    "\n",
    "        an_ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "        an_ax.xaxis.set_major_formatter(mdates.DateFormatter('%d\\n'))\n",
    "        \n",
    "\n",
    "        an_ax.yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:.0f}'))\n",
    "        an_ax.yaxis.grid()\n",
    "        an_ax.tick_params(labelsize=22,which=\"minor\")\n",
    "        an_ax.tick_params(labelsize=25,which=\"major\")\n",
    "        \n",
    "        # TODO figure out why we need to autoscale_view\n",
    "        an_ax.autoscale_view()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.margins(x=0)\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "\n",
    "\n",
    "    fig.suptitle('Site {}, Normalized Bi-270min Frequency [%]'.format(selected_area),fontsize=48)\n",
    "#     plt.show()\n",
    "\n",
    "    figDir= Path(visFilePath) / (\"Freq-\"+freq) / regionName \n",
    "    figDir.mkdir(parents=True,exist_ok=True)\n",
    "    figPath= figDir / (\"_\".join([selected_area,str(year)]) +'.'+\"png\")\n",
    "    \n",
    "    fig.savefig(figPath)\n",
    "#     fig.show()\n",
    "#     fig.savefig(\"test\" +'.png')\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechEnv",
   "language": "python",
   "name": "speechenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
