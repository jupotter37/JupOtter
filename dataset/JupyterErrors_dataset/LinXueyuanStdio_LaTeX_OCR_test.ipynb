{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T08:08:28.455589Z",
     "start_time": "2019-05-27T08:08:26.845986Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "# With square kernels and equal stride\n",
    "m = nn.Conv2d(16, 33, 3, stride=2)\n",
    "# non-square kernels and unequal stride and with padding\n",
    "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
    "# non-square kernels and unequal stride and with padding and dilation\n",
    "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\n",
    "input = autograd.Variable(torch.randn(20, 16, 50, 100))\n",
    "output = m(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T08:31:08.562449Z",
     "start_time": "2019-05-27T08:31:08.526430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 16, 50, 100])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(20, 3, 50, 100).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:20:41.022408Z",
     "start_time": "2019-05-27T13:20:38.020225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 512, 14, 14])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = autograd.Variable(torch.randn(20, 3, 128, 128))\n",
    "def getWH(img_w, img_h):\n",
    "    img_w, img_h = np.ceil(img_w / 2), np.ceil(img_h / 2)\n",
    "    img_w, img_h = np.ceil(img_w / 2), np.ceil(img_h / 2)\n",
    "    img_w, img_h = np.ceil(img_w / 2), np.ceil(img_h / 2)\n",
    "    img_w, img_h = np.ceil(img_w - 2), np.ceil(img_h - 2)\n",
    "    return int(img_w), int(img_h)\n",
    "print(getWH(input.shape[2], input.shape[3]))\n",
    "model = nn.Sequential(\n",
    "    # conv + max pool -> /2\n",
    "    # 64 个 3*3 filters, strike = (1, 1), output_img.shape = ceil(L/S) = ceil(input/strike) = (H, W)\n",
    "    nn.Conv2d(in_channels=3, out_channels=64,  kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # conv + max pool -> /2\n",
    "    nn.Conv2d(in_channels=64, out_channels=128,  kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # regular conv -> id\n",
    "    nn.Conv2d(in_channels=128, out_channels=256,  kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=256, out_channels=256,  kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=(2, 1), stride=(2, 1)),\n",
    "    nn.Conv2d(in_channels=256, out_channels=512,  kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=(1, 2), stride=(1, 2)),\n",
    "\n",
    "    # conv\n",
    "    nn.Conv2d(in_channels=512, out_channels=512,  kernel_size=3, stride=1, padding=0),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "model(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:24:56.639211Z",
     "start_time": "2019-05-27T13:24:53.861484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 512, 15, 14])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = nn.Sequential(\n",
    "    # conv + max pool -> /2\n",
    "    # 64 个 3*3 filters, strike = (1, 1), output_img.shape = ceil(L/S) = ceil(input/strike) = (H, W)\n",
    "    nn.Conv2d(in_channels=3, out_channels=64,  kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # conv + max pool -> /2\n",
    "    nn.Conv2d(in_channels=64, out_channels=128,  kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    # regular conv -> id\n",
    "    nn.Conv2d(in_channels=128, out_channels=256,  kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(in_channels=256, out_channels=256,  kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Conv2d(in_channels=256, out_channels=512,  kernel_size=3, stride=1, padding=1),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    nn.Conv2d(in_channels=512, out_channels=512,  kernel_size=(2, 4), stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "\n",
    "    # conv\n",
    "    nn.Conv2d(in_channels=512, out_channels=512,  kernel_size=3, stride=1, padding=0),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "model2(input).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T11:07:57.977836Z",
     "start_time": "2019-05-27T11:07:57.921158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "        [ 0.9616,  0.9616,  0.9616,  ...,  0.2743,  0.2743,  0.2743],\n",
      "        [ 0.5276,  0.5276,  0.5276,  ..., -0.8495, -0.8495, -0.8495],\n",
      "        ...,\n",
      "        [-0.2470, -0.2470, -0.2470,  ...,  0.9690,  0.9690,  0.9690],\n",
      "        [ 0.8641,  0.8641,  0.8641,  ...,  0.5033,  0.5033,  0.5033],\n",
      "        [ 0.7210,  0.7210,  0.7210,  ..., -0.6929, -0.6929, -0.6929]]) torch.Size([100, 200])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "constant_pad_nd(): argument 'pad' must be tuple of ints, but found element of type list at pos 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-440521cb4480>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0madd_timing_signal_nd_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-440521cb4480>\u001b[0m in \u001b[0;36madd_timing_signal_nd_torch\u001b[0;34m(x, min_timescale, max_timescale)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprepad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_timescales\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mpostpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_timescales\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mprepad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostpad\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyworks/env35/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mpad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   2667\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Padding length too large'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'constant'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2669\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_pad_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2670\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Padding mode \"{}\"\" doesn\\'t take in value argument'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: constant_pad_nd(): argument 'pad' must be tuple of ints, but found element of type list at pos 1"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from torch.nn.functional import pad\n",
    "def add_timing_signal_nd_torch(x, min_timescale=1.0, max_timescale=1.0e4):\n",
    "    static_shape = x.shape\n",
    "    num_dims = len(static_shape) - 2\n",
    "    channels = static_shape[1]\n",
    "    num_timescales = channels // (num_dims * 2)\n",
    "    log_timescale_increment = (\n",
    "        math.log(float(max_timescale) / float(min_timescale)) /\n",
    "        (float(num_timescales) - 1))\n",
    "    inv_timescales = min_timescale * torch.exp(torch.linspace(0, num_timescales).float() * -log_timescale_increment)\n",
    "    for dim in range(num_dims):\n",
    "        length = static_shape[dim + 2]\n",
    "        position = torch.linspace(0, length).float()\n",
    "        scaled_time = position.unsqueeze(1) * inv_timescales.unsqueeze(0)\n",
    "        signal = torch.cat([torch.sin(scaled_time), torch.cos(scaled_time)], dim=1)\n",
    "        print(signal, signal.shape)\n",
    "        prepad = dim * 2 * num_timescales\n",
    "        postpad = channels - (dim + 2) * 2 * num_timescales\n",
    "        signal = pad(signal, [[0, 0], [prepad, postpad]])\n",
    "        for _ in range(2 + dim):\n",
    "            signal = signal.unsqueeze(0)\n",
    "        for _ in range(num_dims - 1 - dim):\n",
    "            signal = signal.unsqueeze(-2)\n",
    "        x += signal\n",
    "    return x\n",
    "add_timing_signal_nd_torch(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:35:26.752908Z",
     "start_time": "2019-05-27T10:35:26.585220Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'add_timing_signal_nd_torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-5741f8bda0a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0madd_timing_signal_nd_torch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'add_timing_signal_nd_torch' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:53:43.640334Z",
     "start_time": "2019-05-27T10:53:43.632805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.Tensor([1,2,3,4,5])\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T10:54:02.375247Z",
     "start_time": "2019-05-27T10:54:02.368443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{log_timescale_increment} = \\frac{log(\\frac{\\text{max_timescale}}{\\text{min_timescale}})}{\\text{num_timescales} - 1}\n",
    "$$\n",
    "$$\n",
    "\\text{inv_timescales} = \\text{min_timescale} * e^{range(\\text{num_timescales}) * -\\text{log_timescale_increment}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:13:19.428082Z",
     "start_time": "2019-05-27T13:13:19.243415Z"
    }
   },
   "outputs": [],
   "source": [
    "x = autograd.Variable(torch.randn(20, 512, 14, 14))\n",
    "min_timescale=1.0\n",
    "max_timescale=1.0e4\n",
    "static_shape = x.shape # [20, 512, 14, 14]\n",
    "num_dims = len(static_shape) - 2 # 2\n",
    "channels = static_shape[1] # 512\n",
    "num_timescales = channels // (num_dims * 2) # 128\n",
    "log_timescale_increment = (\n",
    "    math.log(float(max_timescale) / float(min_timescale)) /\n",
    "    (float(num_timescales) - 1)\n",
    ") # 0.1\n",
    "inv_timescales = min_timescale * torch.exp(torch.arange(num_timescales).float() * (-log_timescale_increment)) # len == 128\n",
    "for dim in range(num_dims): # dim == 0; 1\n",
    "    length = static_shape[dim + 2] # 14\n",
    "    position = torch.arange(length).float() # len == 14\n",
    "    scaled_time = inv_timescales.unsqueeze(1) * position.unsqueeze(0) # inv = [128, 1]， pos = [1, 14], scaled_time = [128, 14]\n",
    "    signal = torch.cat([torch.sin(scaled_time), torch.cos(scaled_time)], dim=0) # [256， 14]\n",
    "    \n",
    "    prepad = dim * 2 * num_timescales # 0; 256\n",
    "    postpad = channels - (dim + 1) * 2 * num_timescales # 256; 0\n",
    "    \n",
    "    signal = pad(signal, (0, 0, prepad, postpad)) # [512, 14]\n",
    "    \n",
    "    signal = signal.unsqueeze(0)\n",
    "    for _ in range(dim):\n",
    "        signal = signal.unsqueeze(2) # [512, 14]\n",
    "    for _ in range(num_dims - 1 - dim):\n",
    "        signal = signal.unsqueeze(-1)\n",
    "    x += signal # [1, 512, 14, 1]; [1, 512, 1, 14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T13:16:29.898791Z",
     "start_time": "2019-05-27T13:16:29.892776Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 512, 14, 14])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-27T12:26:26.866517Z",
     "start_time": "2019-05-27T12:26:26.861785Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 80):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # create constant 'pe' matrix with values dependant on \n",
    "        # pos and i\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = \\\n",
    "                math.sin(pos / (10000 ** ((2 * i)/d_model)))\n",
    "                pe[pos, i + 1] = \\\n",
    "                math.cos(pos / (10000 ** ((2 * (i + 1))/d_model)))\n",
    "                \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    " \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # make embeddings relatively larger\n",
    "        x = x * math.sqrt(self.d_model)\n",
    "        #add constant to embedding\n",
    "        seq_len = x.size(1)\n",
    "        x = x + Variable(self.pe[:,:seq_len], \\\n",
    "        requires_grad=False).cuda()\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 612.5,
   "position": {
    "height": "40px",
    "left": "900px",
    "right": "20px",
    "top": "2px",
    "width": "597px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
