{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triage all errors caught during experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/duncan/miniconda3/envs/recsys/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (13,14,20,21,36,37,45,47,48,49,54) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "TIME_FORMAT = \"%Y%m%d_%H%M%S\"\n",
    "\n",
    "df = pd.read_csv(\"/Users/duncan/research/active_projects/reczilla/results/results.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg_name</th>\n",
       "      <th>alg_seed</th>\n",
       "      <th>cutoff_list</th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>exception</th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>hyperparameters_source</th>\n",
       "      <th>num_samples</th>\n",
       "      <th>original_split_path</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>...</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_5</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_50</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_6</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_7</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_8</th>\n",
       "      <th>test_metric_USERS_IN_GT_cut_9</th>\n",
       "      <th>time</th>\n",
       "      <th>time_on_test</th>\n",
       "      <th>time_on_train</th>\n",
       "      <th>time_on_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>MFBPR_Wrapper</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...</td>\n",
       "      <td>AnimeReader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dl-mfbpr-3</td>\n",
       "      <td>default</td>\n",
       "      <td>1</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220728_021855</td>\n",
       "      <td>220.014045</td>\n",
       "      <td>3965.576081</td>\n",
       "      <td>219.375607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>MFBPR_Wrapper</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...</td>\n",
       "      <td>LastFMReader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dl-mfbpr-13</td>\n",
       "      <td>default</td>\n",
       "      <td>1</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220728_031404</td>\n",
       "      <td>6.587432</td>\n",
       "      <td>57.875386</td>\n",
       "      <td>6.502233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>SpectralCF_RecommenderWrapper</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...</td>\n",
       "      <td>Movielens100KReader</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dl-spectralcf-17</td>\n",
       "      <td>default</td>\n",
       "      <td>1</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20220727_223357</td>\n",
       "      <td>2.762477</td>\n",
       "      <td>47.346239</td>\n",
       "      <td>3.302866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>INeuRec_RecommenderWrapper</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...</td>\n",
       "      <td>BookCrossingReader</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"/h...</td>\n",
       "      <td>dl-ineurec-4</td>\n",
       "      <td>default</td>\n",
       "      <td>1</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20220727_214622</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3835</th>\n",
       "      <td>SpectralCF_RecommenderWrapper</td>\n",
       "      <td>0</td>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...</td>\n",
       "      <td>CiaoDVDReader</td>\n",
       "      <td>Traceback (most recent call last):\\n  File \"/h...</td>\n",
       "      <td>dl-spectralcf-5</td>\n",
       "      <td>default</td>\n",
       "      <td>1</td>\n",
       "      <td>gs://reczilla-results/dataset-splits/splits-v5...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20220727_221159</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 392 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           alg_name  alg_seed  \\\n",
       "377                   MFBPR_Wrapper         0   \n",
       "2631                  MFBPR_Wrapper         0   \n",
       "2732  SpectralCF_RecommenderWrapper         0   \n",
       "3834     INeuRec_RecommenderWrapper         0   \n",
       "3835  SpectralCF_RecommenderWrapper         0   \n",
       "\n",
       "                                            cutoff_list         dataset_name  \\\n",
       "377   [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...          AnimeReader   \n",
       "2631  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...         LastFMReader   \n",
       "2732  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...  Movielens100KReader   \n",
       "3834  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...   BookCrossingReader   \n",
       "3835  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20, 30, 40...        CiaoDVDReader   \n",
       "\n",
       "                                              exception   experiment_name  \\\n",
       "377                                                 NaN        dl-mfbpr-3   \n",
       "2631                                                NaN       dl-mfbpr-13   \n",
       "2732                                                NaN  dl-spectralcf-17   \n",
       "3834  Traceback (most recent call last):\\n  File \"/h...      dl-ineurec-4   \n",
       "3835  Traceback (most recent call last):\\n  File \"/h...   dl-spectralcf-5   \n",
       "\n",
       "     hyperparameters_source  num_samples  \\\n",
       "377                 default            1   \n",
       "2631                default            1   \n",
       "2732                default            1   \n",
       "3834                default            1   \n",
       "3835                default            1   \n",
       "\n",
       "                                    original_split_path  param_alpha  ...  \\\n",
       "377   gs://reczilla-results/dataset-splits/splits-v5...          NaN  ...   \n",
       "2631  gs://reczilla-results/dataset-splits/splits-v5...          NaN  ...   \n",
       "2732  gs://reczilla-results/dataset-splits/splits-v5...          NaN  ...   \n",
       "3834  gs://reczilla-results/dataset-splits/splits-v5...          NaN  ...   \n",
       "3835  gs://reczilla-results/dataset-splits/splits-v5...          NaN  ...   \n",
       "\n",
       "      test_metric_USERS_IN_GT_cut_5  test_metric_USERS_IN_GT_cut_50  \\\n",
       "377                             1.0                             1.0   \n",
       "2631                            1.0                             1.0   \n",
       "2732                            1.0                             1.0   \n",
       "3834                            NaN                             NaN   \n",
       "3835                            NaN                             NaN   \n",
       "\n",
       "      test_metric_USERS_IN_GT_cut_6 test_metric_USERS_IN_GT_cut_7  \\\n",
       "377                             1.0                           1.0   \n",
       "2631                            1.0                           1.0   \n",
       "2732                            1.0                           1.0   \n",
       "3834                            NaN                           NaN   \n",
       "3835                            NaN                           NaN   \n",
       "\n",
       "     test_metric_USERS_IN_GT_cut_8  test_metric_USERS_IN_GT_cut_9  \\\n",
       "377                            1.0                            1.0   \n",
       "2631                           1.0                            1.0   \n",
       "2732                           1.0                            1.0   \n",
       "3834                           NaN                            NaN   \n",
       "3835                           NaN                            NaN   \n",
       "\n",
       "                 time  time_on_test  time_on_train  time_on_val  \n",
       "377   20220728_021855    220.014045    3965.576081   219.375607  \n",
       "2631  20220728_031404      6.587432      57.875386     6.502233  \n",
       "2732  20220727_223357      2.762477      47.346239     3.302866  \n",
       "3834  20220727_214622           NaN            NaN          NaN  \n",
       "3835  20220727_221159           NaN            NaN          NaN  \n",
       "\n",
       "[5 rows x 392 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# slice by experiment name\n",
    "# df_expt = df.loc[df[\"experiment_name\"].str.startswith(\"neurips-\"), :]\n",
    "df_expt = df.loc[df[\"experiment_name\"].str.startswith(\"dl-\"), :]\n",
    "\n",
    "df_expt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for exceptions\n",
    "exception_list = list(df_expt[\"exception\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at specific DL models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "ALG = INeuRec_RecommenderWrapper\n",
      "                          dataset_name  time_on_val\n",
      "170731           AmazonAllBeautyReader     0.481514\n",
      "175106      AmazonAllElectronicsReader     0.435075\n",
      "67113      AmazonAlternativeRockReader     0.402303\n",
      "97950   AmazonAppstoreforAndroidReader     0.059709\n",
      "139909               AmazonBluesReader     0.097119\n",
      "119006           AmazonClassicalReader     0.561739\n",
      "77938            AmazonComputersReader     0.152204\n",
      "94529              AmazonCountryReader     0.212135\n",
      "192624               AmazonDavisReader     0.095836\n",
      "17521            AmazonGiftCardsReader     0.459439\n",
      "49253               AmazonGospelReader     0.198941\n",
      "181986     AmazonHomeImprovementReader     0.169921\n",
      "90235      AmazonHomeImprovementReader     0.164313\n",
      "83150                    CiaoDVDReader          NaN\n",
      "80852                  FilmTrustReader     4.166487\n",
      "74483                     FrappeReader     2.316315\n",
      "157700                   Jester2Reader          NaN\n",
      "92380           MarketBiasAmazonReader          NaN\n",
      "66027         MarketBiasModClothReader    20.170253\n",
      "130920             Movielens100KReader     2.789000\n",
      "61211        MovielensHetrec2011Reader     6.709796\n",
      "70248                   WikilensReader     0.862087\n",
      "84754                YahooMoviesReader          NaN\n",
      "num rows = 53\n",
      "num datasets with results = 22\n",
      "num exceptions = 30\n",
      "num OOM exceptions = 0\n",
      "num Memory exceptions = 23\n",
      "num memory exceptions = 0\n",
      "--------------------------\n",
      "ALG = UNeuRec_RecommenderWrapper\n",
      "                       dataset_name  time_on_val\n",
      "90436   AmazonAlternativeRockReader     0.440821\n",
      "87095   AmazonHomeImprovementReader     0.170672\n",
      "22333                 CiaoDVDReader          NaN\n",
      "107524              FilmTrustReader     4.290219\n",
      "71661                  FrappeReader     2.390963\n",
      "82786                 Jester2Reader   175.502680\n",
      "29685        MarketBiasAmazonReader          NaN\n",
      "155563     MarketBiasModClothReader    21.089923\n",
      "57288           Movielens100KReader     2.871564\n",
      "179650    MovielensHetrec2011Reader     7.075677\n",
      "22330                WikilensReader     0.879906\n",
      "157897            YahooMoviesReader          NaN\n",
      "num rows = 29\n",
      "num datasets with results = 12\n",
      "num exceptions = 17\n",
      "num OOM exceptions = 0\n",
      "num Memory exceptions = 11\n",
      "num memory exceptions = 0\n",
      "--------------------------\n",
      "ALG = Mult_VAE_RecommenderWrapper\n",
      "                       dataset_name  time_on_val\n",
      "139605  AmazonHomeImprovementReader     0.132047\n",
      "42255                   AnimeReader   226.149273\n",
      "102361                CiaoDVDReader    15.649208\n",
      "162146              FilmTrustReader     4.253825\n",
      "149348                 FrappeReader     2.382640\n",
      "num rows = 5\n",
      "num datasets with results = 5\n",
      "num exceptions = 0\n",
      "num OOM exceptions = 0\n",
      "num Memory exceptions = 0\n",
      "num memory exceptions = 0\n",
      "--------------------------\n",
      "ALG = SpectralCF_RecommenderWrapper\n",
      "                       dataset_name  time_on_val\n",
      "56455   AmazonHomeImprovementReader     1.062672\n",
      "151984              FilmTrustReader     4.466660\n",
      "64300                  FrappeReader     3.950579\n",
      "190953     MarketBiasModClothReader    24.726192\n",
      "2732            Movielens100KReader     3.302866\n",
      "63759     MovielensHetrec2011Reader    17.127283\n",
      "11024                WikilensReader     2.730987\n",
      "num rows = 24\n",
      "num datasets with results = 7\n",
      "num exceptions = 17\n",
      "num OOM exceptions = 0\n",
      "num Memory exceptions = 11\n",
      "num memory exceptions = 0\n",
      "--------------------------\n",
      "ALG = DELF_EF_RecommenderWrapper\n",
      "                       dataset_name  time_on_val\n",
      "11023   AmazonHomeImprovementReader     1.702677\n",
      "8453                    AnimeReader          NaN\n",
      "118579           BookCrossingReader          NaN\n",
      "64198                 CiaoDVDReader          NaN\n",
      "100719              FilmTrustReader    33.754794\n",
      "62037                  FrappeReader    43.730225\n",
      "98675                 Jester2Reader          NaN\n",
      "112316                 LastFMReader  1661.055753\n",
      "34318        MarketBiasAmazonReader          NaN\n",
      "139544     MarketBiasModClothReader   187.953642\n",
      "147958         MovieTweetingsReader          NaN\n",
      "58609           Movielens100KReader    16.084570\n",
      "138811           Movielens10MReader          NaN\n",
      "134722    MovielensHetrec2011Reader   701.400677\n",
      "21236                 RecipesReader          NaN\n",
      "17125                WikilensReader    22.104050\n",
      "num rows = 23\n",
      "num datasets with results = 16\n",
      "num exceptions = 7\n",
      "num OOM exceptions = 1\n",
      "num Memory exceptions = 6\n",
      "num memory exceptions = 0\n",
      "--------------------------\n",
      "ALG = DELF_MLP_RecommenderWrapper\n",
      "                       dataset_name  time_on_val\n",
      "44224   AmazonHomeImprovementReader     1.520039\n",
      "51469                   AnimeReader          NaN\n",
      "35142            BookCrossingReader          NaN\n",
      "142874                CiaoDVDReader          NaN\n",
      "194296              FilmTrustReader    30.609841\n",
      "55663                  FrappeReader    43.485284\n",
      "95567                 Jester2Reader          NaN\n",
      "21397                  LastFMReader  1610.107929\n",
      "91219        MarketBiasAmazonReader          NaN\n",
      "168021     MarketBiasModClothReader   241.202054\n",
      "141142         MovieTweetingsReader          NaN\n",
      "141575          Movielens100KReader    16.079308\n",
      "145536           Movielens10MReader          NaN\n",
      "55964     MovielensHetrec2011Reader   717.579814\n",
      "141141                RecipesReader          NaN\n",
      "27069                WikilensReader    21.042845\n",
      "29155             YahooMoviesReader          NaN\n",
      "num rows = 24\n",
      "num datasets with results = 17\n",
      "num exceptions = 7\n",
      "num OOM exceptions = 1\n",
      "num Memory exceptions = 6\n",
      "num memory exceptions = 0\n",
      "--------------------------\n",
      "ALG = MFBPR_Wrapper\n",
      "                       dataset_name  time_on_val\n",
      "115965  AmazonHomeImprovementReader     0.178485\n",
      "184046         AmazonMoviesTVReader  1880.313857\n",
      "377                     AnimeReader   219.375607\n",
      "191931           BookCrossingReader   168.360014\n",
      "4238                  CiaoDVDReader    14.824103\n",
      "113772                 DatingReader   691.100680\n",
      "43216                EpinionsReader   134.011441\n",
      "80329               FilmTrustReader     4.037266\n",
      "188283                 FrappeReader     2.473753\n",
      "50039      GoogleLocalReviewsReader          NaN\n",
      "152087                GowallaReader  1785.951204\n",
      "99398                 Jester2Reader   173.768671\n",
      "2631                   LastFMReader     6.502233\n",
      "123639       MarketBiasAmazonReader    60.691031\n",
      "61846      MarketBiasModClothReader    20.511984\n",
      "133973         MovieTweetingsReader   107.996329\n",
      "100556          Movielens100KReader     2.887722\n",
      "112420           Movielens10MReader   240.713531\n",
      "38125     MovielensHetrec2011Reader     6.742418\n",
      "154321                RecipesReader   223.432766\n",
      "48560                WikilensReader     0.891786\n",
      "96191             YahooMoviesReader    26.079794\n",
      "187740             YahooMusicReader          NaN\n",
      "num rows = 23\n",
      "num datasets with results = 23\n",
      "num exceptions = 0\n",
      "num OOM exceptions = 0\n",
      "num Memory exceptions = 0\n",
      "num memory exceptions = 0\n"
     ]
    }
   ],
   "source": [
    "alg_list = [\n",
    "    \"INeuRec_RecommenderWrapper\",\n",
    "    \"UNeuRec_RecommenderWrapper\",\n",
    "    \"Mult_VAE_RecommenderWrapper\",\n",
    "    \"SpectralCF_RecommenderWrapper\",\n",
    "    \"DELF_EF_RecommenderWrapper\",\n",
    "    \"DELF_MLP_RecommenderWrapper\",\n",
    "    \"MFBPR_Wrapper\",\n",
    "]\n",
    "\n",
    "for alg_name in alg_list:\n",
    "\n",
    "    print(\"--------------------------\")\n",
    "    print(f\"ALG = {alg_name}\")\n",
    "\n",
    "    df_alg = df_expt.loc[df_expt[\"alg_name\"] == alg_name, :]\n",
    "    dl_excepts = exception_list = list(df_alg[\"exception\"].unique())\n",
    "\n",
    "    good_rows = df_alg.loc[df_alg[\"exception\"].isna(), :]\n",
    "\n",
    "    print(good_rows.loc[:, [\"dataset_name\", \"time_on_val\"]].sort_values(\"dataset_name\"))\n",
    "    # num results by dataset\n",
    "    num_datasets = len(good_rows[\"dataset_name\"].unique())\n",
    "\n",
    "    print(f\"num rows = {len(df_alg)}\")\n",
    "    print(f\"num datasets with results = {num_datasets}\")\n",
    "    print(f\"num exceptions = {np.sum(~df_alg['exception'].isna())}\")\n",
    "    print(f\"num OOM exceptions = {np.sum(df_alg['exception'].str.contains('OOM'))}\")\n",
    "    print(f\"num Memory exceptions = {np.sum(df_alg['exception'].str.contains('Memory'))}\")\n",
    "    print(f\"num memory exceptions = {np.sum(df_alg['exception'].str.contains('memory'))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_alg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze all caught exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_es = [e for e in exception_list if \"MemoryError\" in str(e)]\n",
    "oom_es = [e for e in exception_list if \"OOM when allocating\" in str(e)]\n",
    "non_memory_es = [e for e in exception_list if \"MemoryError\" not in str(e) and \"OOM when allocating\" not in str(e)]\n",
    "tfidf_es = [e for e in exception_list if \"TF_IDF\" in str(e)]\n",
    "ials_es = [e for e in exception_list if \"IALSRecommender\" in str(e)]\n",
    "rp3_es = [e for e in exception_list if \"RP3betaRecommender\" in str(e)]\n",
    "NMFRecommender_es = [e for e in exception_list if \"NMFRecommender\" in str(e)]\n",
    "MultiVAE_es = [e for e in exception_list if \"MultiVAE_RecommenderWrapper\" in str(e)]\n",
    "ease_r_es = [e for e in exception_list if \"EASE_R_\" in str(e)]\n",
    "delf_es = [e for e in exception_list if \"DELF\" in str(e)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-955e98486d8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# len(non_memory_es)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_es\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# len(non_memory_es)\n",
    "print(memory_es[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total num exceptions: 0\n",
      "--- total num memory exceptions: 0\n",
      "algs: Series([], Name: alg_name, dtype: int64)\n",
      "datasets: Series([], Name: dataset_name, dtype: int64)\n",
      "--- total num OOM (tensor?) exceptions: 0\n",
      "algs: Series([], Name: alg_name, dtype: int64)\n",
      "datasets: Series([], Name: dataset_name, dtype: int64)\n",
      "--- total num exceptions because of TF-IDF exceptions: 0\n",
      "algs: Series([], Name: alg_name, dtype: int64)\n",
      "datasets: Series([], Name: dataset_name, dtype: int64)\n",
      "--- total num exceptions because  cd doesn't handle k-l: 0\n",
      "algs: Series([], Name: alg_name, dtype: int64)\n",
      "datasets: Series([], Name: dataset_name, dtype: int64)\n",
      "--- total num exceptions because of NMFRecommender: 0\n",
      "algs: Series([], Name: alg_name, dtype: int64)\n",
      "datasets: Series([], Name: dataset_name, dtype: int64)\n",
      "--- total num exceptions because of IALSRecommender: 0\n",
      "algs: Series([], Name: alg_name, dtype: int64)\n",
      "datasets: Series([], Name: dataset_name, dtype: int64)\n",
      "--- total num exceptions because of RP3betaRecommender: 0\n",
      "algs: Series([], Name: alg_name, dtype: int64)\n",
      "datasets: Series([], Name: dataset_name, dtype: int64)\n",
      "--- total num exceptions because of MultiVAE_RecommenderWrapper: 0\n",
      "algs: Series([], Name: alg_name, dtype: int64)\n",
      "datasets: Series([], Name: dataset_name, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# how many exceptions? and how many memory errors\n",
    "print(f\"total num exceptions: {sum(~df_expt['exception'].isna())}\")\n",
    "print(f\"--- total num memory exceptions: {sum(df_expt['exception'].astype(str).str.contains('MemoryError'))}\")\n",
    "\n",
    "x = df_expt['exception'].astype(str).str.contains('MemoryError')\n",
    "\n",
    "# alg_datsets = df_expt[x].apply(lambda row: row[\"alg_name\"] + \"---\" + row[\"dataset_name\"], axis=1)\n",
    "\n",
    "print(\"algs: \" + str(df_expt.loc[x, \"alg_name\"].value_counts()))\n",
    "print(\"datasets: \" + str(df_expt.loc[x, \"dataset_name\"].value_counts()))\n",
    "\n",
    "print(f\"--- total num OOM (tensor?) exceptions: {sum(df_expt['exception'].astype(str).str.contains('OOM when allocating'))}\")\n",
    "\n",
    "x = df_expt['exception'].astype(str).str.contains('OOM when allocating')\n",
    "\n",
    "print(\"algs: \" + str(df_expt.loc[x, \"alg_name\"].value_counts()))\n",
    "print(\"datasets: \" + str(df_expt.loc[x, \"dataset_name\"].value_counts()))\n",
    "\n",
    "print(f\"--- total num exceptions because of TF-IDF exceptions: {sum(df_expt['exception'].astype(str).str.contains('TF_IDF'))}\")\n",
    "\n",
    "\n",
    "x = df_expt['exception'].astype(str).str.contains('TF_IDF')\n",
    "\n",
    "print(\"algs: \" + str(df_expt.loc[x, \"alg_name\"].value_counts()))\n",
    "print(\"datasets: \" + str(df_expt.loc[x, \"dataset_name\"].value_counts()))\n",
    "\n",
    "\n",
    "print(f\"--- total num exceptions because  cd doesn't handle k-l: {sum(df_expt['exception'].astype(str).str.contains(' does not handle beta_loss = '))}\")\n",
    "\n",
    "x = df_expt['exception'].astype(str).str.contains(' does not handle beta_loss = ')\n",
    "\n",
    "print(\"algs: \" + str(df_expt.loc[x, \"alg_name\"].value_counts()))\n",
    "print(\"datasets: \" + str(df_expt.loc[x, \"dataset_name\"].value_counts()))\n",
    "\n",
    "\n",
    "\n",
    "print(f\"--- total num exceptions because of NMFRecommender: {sum(df_expt['exception'].astype(str).str.contains('NMFRecommender'))}\")\n",
    "\n",
    "\n",
    "x = df_expt['exception'].astype(str).str.contains('NMFRecommender')\n",
    "\n",
    "print(\"algs: \" + str(df_expt.loc[x, \"alg_name\"].value_counts()))\n",
    "print(\"datasets: \" + str(df_expt.loc[x, \"dataset_name\"].value_counts()))\n",
    "\n",
    "\n",
    "print(f\"--- total num exceptions because of IALSRecommender: {sum(df_expt['exception'].astype(str).str.contains('IALSRecommender'))}\")\n",
    "\n",
    "x = df_expt['exception'].astype(str).str.contains('IALSRecommender')\n",
    "\n",
    "print(\"algs: \" + str(df_expt.loc[x, \"alg_name\"].value_counts()))\n",
    "print(\"datasets: \" + str(df_expt.loc[x, \"dataset_name\"].value_counts()))\n",
    "\n",
    "print(f\"--- total num exceptions because of RP3betaRecommender: {sum(df_expt['exception'].astype(str).str.contains('RP3betaRecommender'))}\")\n",
    "\n",
    "x = df_expt['exception'].astype(str).str.contains('RP3betaRecommender')\n",
    "print(\"algs: \" + str(df_expt.loc[x, \"alg_name\"].value_counts()))\n",
    "print(\"datasets: \" + str(df_expt.loc[x, \"dataset_name\"].value_counts()))\n",
    "\n",
    "\n",
    "print(f\"--- total num exceptions because of MultiVAE_RecommenderWrapper: {sum(df_expt['exception'].astype(str).str.contains('MultiVAE_RecommenderWrapper'))}\")\n",
    "\n",
    "x = df_expt['exception'].astype(str).str.contains('MultiVAE_RecommenderWrapper')\n",
    "\n",
    "print(\"algs: \" + str(df_expt.loc[x, \"alg_name\"].value_counts()))\n",
    "print(\"datasets: \" + str(df_expt.loc[x, \"dataset_name\"].value_counts()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(NMFRecommender_es)\n",
    "# print(NMFRecommender_es[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[119829,1,11200] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n",
      "\t [[{{node predict/GatherV2}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/SearchAbstractClass.py\", line 402, in _objective_function\n",
      "    result_dict, result_string, recommender_instance, train_time, evaluation_time = self._evaluate_on_validation(current_fit_parameters_dict)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/RandomSearch.py\", line 50, in _evaluate_on_validation\n",
      "    current_fit_parameters\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/SearchAbstractClass.py\", line 293, in _evaluate_on_validation\n",
      "    recommender_instance, train_time = self._fit_model(current_fit_parameters)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/SearchAbstractClass.py\", line 283, in _fit_model\n",
      "    **current_fit_parameters)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Conferences/IJCAI/DELF_our_interface/DELFWrapper.py\", line 135, in fit\n",
      "    **earlystopping_kwargs)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Base/Incremental_Training_Early_Stopping.py\", line 177, in _train_with_early_stopping\n",
      "    self._run_epoch(epochs_current)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Conferences/IJCAI/DELF_our_interface/DELFWrapper.py\", line 177, in _run_epoch\n",
      "    self.rating_matrix: self.train_arr})\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[119829,1,11200] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n",
      "\t [[node predict/GatherV2 (defined at /home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Conferences/IJCAI/DELF_original/Model/NMF_attention_EF.py:134) ]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\n",
      "\n",
      "Caused by op 'predict/GatherV2', defined at:\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Experiment_handler/run_experiment.py\", line 109, in <module>\n",
      "    run(args)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Experiment_handler/run_experiment.py\", line 41, in run\n",
      "    time_limit=args.time_limit,\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Experiment_handler/Experiment.py\", line 469, in run_experiment\n",
      "    p.start()\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/multiprocessing/context.py\", line 223, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/multiprocessing/popen_fork.py\", line 73, in _launch\n",
      "    code = process_obj._bootstrap()\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/RandomSearch.py\", line 165, in search\n",
      "    hyperparams, hyperparameters_source=f\"random_{i_sample}\"\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/SearchAbstractClass.py\", line 402, in _objective_function\n",
      "    result_dict, result_string, recommender_instance, train_time, evaluation_time = self._evaluate_on_validation(current_fit_parameters_dict)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/RandomSearch.py\", line 50, in _evaluate_on_validation\n",
      "    current_fit_parameters\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/SearchAbstractClass.py\", line 293, in _evaluate_on_validation\n",
      "    recommender_instance, train_time = self._fit_model(current_fit_parameters)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/ParameterTuning/SearchAbstractClass.py\", line 283, in _fit_model\n",
      "    **current_fit_parameters)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Conferences/IJCAI/DELF_our_interface/DELFWrapper.py\", line 114, in fit\n",
      "    self.model = NMF.Model(self.input_user, self.input_item, self.output, self.num_users, self.num_items, self.rating_matrix, self.layers, self.batch_len)\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Conferences/IJCAI/DELF_original/Model/NMF_attention_EF.py\", line 59, in __init__\n",
      "    self.predict\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Conferences/IJCAI/DELF_original/Model/NMF_attention_EF.py\", line 40, in decorator\n",
      "    setattr(self, attribute, function(self))\n",
      "  File \"/home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Conferences/IJCAI/DELF_original/Model/NMF_attention_EF.py\", line 134, in predict\n",
      "    user_ratings = tf.reduce_sum(tf.gather(self.rating_matrix, self.input_user), axis=1)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 3273, in gather\n",
      "    return gen_array_ops.gather_v2(params, indices, axis, name=name)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3748, in gather_v2\n",
      "    \"GatherV2\", params=params, indices=indices, axis=axis, name=name)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"/home/shared/miniconda3/envs/reczilla/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[119829,1,11200] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n",
      "\t [[node predict/GatherV2 (defined at /home/shared/reczilla/RecSys2019_DeepLearning_Evaluation/Conferences/IJCAI/DELF_original/Model/NMF_attention_EF.py:134) ]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(delf_es[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_expt['exception'].astype(str).str.contains('EASE_R') & df_expt['exception'].astype(str).str.contains('sim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9a49d437ec7d70416a2164b1de0841ecb25c4cf254d34094d737b88836beceb4"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('recsys')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
