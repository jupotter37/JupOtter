{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Billboard 200 archive\n",
    "\n",
    "> There are some significant flaws in the files resulting from these scripts that make the data fairly unusable. Since titles and artists mix quotes and include commas, columns are not parsed correctly. This could possible be fixed in the script, or after the fact, but I don't have it in me to figure it out.\n",
    "\n",
    "The API archive goes back to April 1967.\n",
    "\n",
    "This notebook builds a year's worth of Billboard 200 charts at a time (but could be changed to pull other charts by adjusting the `chart_type` field. The idea is to build an archive one year at a time. This allows me to fix a single year if it is a problem. And there were issues with timeouts on other charts.\n",
    "\n",
    "A little about the [Billboard 200](https://en.wikipedia.org/wiki/Billboard_200): The chart grew from a weekly top 10 list in 1956 to become a top 200 in May 1967, and acquired its present title in March 1992. ... On April 1, 1967, the chart was expanded to 175 positions, then finally to 200 positions on May 13, 1967.\n",
    "\n",
    "There is a rate limit on requests to the billboard site. I've had it time out after 10 requests, but I've also had it time out after one if I've run other requests recently.\n",
    "\n",
    "For each chart, we have `chart.previousDate` to work with, which allows us to walk back in time. The loop works like this:\n",
    "\n",
    "- Open our file\n",
    "- check for the oldest date, start new if not results already\n",
    "- Find the next oldest chart\n",
    "- Start a loop and counter and write the results of that week's chart\n",
    "- Set the chart date to the next oldest date\n",
    "- Check if that is in our current year. Break if not.\n",
    "- Wait a time interval and loop again if counter is not maxed\n",
    "\n",
    "This doesn't completely solve the rate limit, but does pretty well at 10 seconds a week.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import billboard\n",
    "from datetime import datetime, timedelta, date\n",
    "import os\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/billboard-200-2020.csv\n"
     ]
    }
   ],
   "source": [
    "# chart type from api\n",
    "chart_type = 'billboard-200'\n",
    "\n",
    "# year we are working on\n",
    "output_year = \"2020\"\n",
    "\n",
    "# output path\n",
    "outfilename = \"../data/billboard-200-\" + output_year + \".csv\"\n",
    "\n",
    "print(outfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File has data\n"
     ]
    }
   ],
   "source": [
    "# headers\n",
    "header = 'date,title,artist,current,previous,peak,weeks,new\\n'\n",
    "\n",
    "# set exists flag\n",
    "file_exists = os.path.exists(outfilename)\n",
    "\n",
    "# checks if file exists and writes if not\n",
    "if file_exists != True:\n",
    "    with open(outfilename, 'a') as outputfile:\n",
    "        outputfile.write(header)\n",
    "        print(\"File created with header\")\n",
    "# checks if file empty and writes header if not\n",
    "else:\n",
    "    file_empty = os.stat(outfilename).st_size == 0\n",
    "    if file_empty:\n",
    "        with open(outfilename, 'a') as outputfile:\n",
    "            outputfile.write(header)\n",
    "            print(\"Added header\")\n",
    "    else:\n",
    "        print(\"File has data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chart loop\n",
    "\n",
    "This loop checks the most recent date of the current year's file. If it is new, it starts with the last chart in December and then through older charts. If there are charts already, it picks up where it left off.\n",
    "\n",
    "Beyond `output_year` above, there are two settings to help control rate limiting:\n",
    "\n",
    "- counter: How many loops it will do before stopping.\n",
    "- timer_interval: How long to wait before getting the next chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new year\n",
      "Beginning date: 2020-12-26\n",
      "2020-12-26: 'Evermore' by Taylor Swift\n",
      "2020-12-19: 'Wonder' by Shawn Mendes\n",
      "2020-12-12: 'El Ultimo Tour del Mundo' by Bad Bunny\n",
      "2020-12-05: 'BE' by BTS\n",
      "2020-11-28: 'Power Up' by AC/DC\n",
      "2020-11-21: 'Positions' by Ariana Grande\n",
      "2020-11-14: 'Positions' by Ariana Grande\n",
      "2020-11-07: 'What You See Is What You Get' by Luke Combs\n",
      "2020-10-31: 'Folklore' by Taylor Swift\n",
      "2020-10-24: 'Shoot For The Stars Aim For The Moon' by Pop Smoke\n",
      "2020-10-17: 'Savage Mode II' by 21 Savage & Metro Boomin\n",
      "2020-10-10: 'Tickets To My Downfall' by Machine Gun Kelly\n",
      "2020-10-03: 'Folklore' by Taylor Swift\n",
      "2020-09-26: 'Top' by YoungBoy Never Broke Again\n",
      "2020-09-19: 'Detroit 2' by Big Sean\n",
      "2020-09-12: 'Folklore' by Taylor Swift\n",
      "2020-09-05: 'Folklore' by Taylor Swift\n",
      "2020-08-29: 'Folklore' by Taylor Swift\n",
      "2020-08-22: 'Folklore' by Taylor Swift\n",
      "2020-08-15: 'Folklore' by Taylor Swift\n",
      "2020-08-08: 'Folklore' by Taylor Swift\n",
      "2020-08-01: 'Legends Never Die' by Juice WRLD\n",
      "2020-07-25: 'Legends Never Die' by Juice WRLD\n",
      "2020-07-18: 'Shoot For The Stars Aim For The Moon' by Pop Smoke\n",
      "2020-07-11: 'My Turn' by Lil Baby\n",
      "2020-07-04: 'My Turn' by Lil Baby\n",
      "2020-06-27: 'My Turn' by Lil Baby\n",
      "2020-06-20: 'My Turn' by Lil Baby\n",
      "2020-06-13: 'Chromatica' by Lady Gaga\n",
      "2020-06-06: 'Wunna' by Gunna\n",
      "2020-05-30: 'High Off Life' by Future\n",
      "2020-05-23: 'Good Intentions' by NAV\n",
      "2020-05-16: 'Here And Now' by Kenny Chesney\n",
      "2020-05-09: '38 Baby 2' by YoungBoy Never Broke Again\n",
      "2020-05-02: 'BLAME IT ON BABY' by DaBaby\n",
      "2020-04-25: 'After Hours' by The Weeknd\n",
      "2020-04-18: 'After Hours' by The Weeknd\n",
      "2020-04-11: 'After Hours' by The Weeknd\n",
      "2020-04-04: 'After Hours' by The Weeknd\n",
      "2020-03-28: 'Eternal Atake' by Lil Uzi Vert\n",
      "2020-03-21: 'Eternal Atake' by Lil Uzi Vert\n",
      "2020-03-14: 'My Turn' by Lil Baby\n",
      "2020-03-07: 'MAP OF THE SOUL : 7' by BTS\n",
      "2020-02-29: 'Changes' by Justin Bieber\n",
      "2020-02-22: 'Please Excuse Me For Being Antisocial' by Roddy Ricch\n",
      "2020-02-15: 'Funeral' by Lil Wayne\n",
      "2020-02-08: 'Please Excuse Me For Being Antisocial' by Roddy Ricch\n",
      "2020-02-01: 'Music To Be Murdered By' by Eminem\n",
      "2020-01-25: 'Rare' by Selena Gomez\n",
      "2020-01-18: 'Please Excuse Me For Being Antisocial' by Roddy Ricch\n",
      "2020-01-11: 'JACKBOYS' by JACKBOYS\n",
      "2020-01-04: 'Fine Line' by Harry Styles\n",
      "Year is over\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# set the counter\n",
    "counter = 53\n",
    "\n",
    "# set the time intervval\n",
    "timer_interval = 10\n",
    "\n",
    "# read in file\n",
    "chart_file = pd.read_csv(outfilename)\n",
    "\n",
    "# find most oldest week in output\n",
    "oldest_date = chart_file.date.min()\n",
    "\n",
    "# if oldest_date isnull, then use begin_chart date\n",
    "if pd.isnull(oldest_date):\n",
    "    begin_chart_date = output_year + \"-12-25\"\n",
    "    chart = billboard.ChartData(chart_type, date=begin_chart_date)\n",
    "    print(\"Starting new year\")\n",
    "    print(\"Beginning date: \" + chart.date)\n",
    "# else, use next previous date\n",
    "else:\n",
    "    chart = billboard.ChartData(chart_type, date=oldest_date)\n",
    "    chart = billboard.ChartData(chart_type, str(chart.previousDate))\n",
    "    print(\"Picking up after: \" + oldest_date)\n",
    "    print(\"Beginning date: \" + chart.date)\n",
    "\n",
    "with open(outfilename, 'a') as outputfile:\n",
    "    start_time = time.time()\n",
    "    for i in range (1,counter+1):\n",
    "        for position in range (0,200):\n",
    "            song = chart[position]\n",
    "            line_out = str(chart.date) + ',' + '\"' + song.title + '\"' + ',' \\\n",
    "            + '\"' + song.artist + '\"' + ','  + str(song.rank) + ',' \\\n",
    "            + str(song.lastPos) + ',' + str(song.peakPos) + ',' \\\n",
    "            + str(song.weeks) + ',' + str(song.isNew) + '\\n'\n",
    "            with open(outfilename, 'a') as outputfile:\n",
    "                outputfile.write(line_out)\n",
    "        print(chart.date + \": \" + str(chart[0]))\n",
    "        chart = billboard.ChartData(chart_type, str(chart.previousDate))\n",
    "        # check if year is over\n",
    "        if chart.date[:4] != output_year:\n",
    "            print(\"Year is over\")\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(timer_interval)\n",
    "    print('done')\n",
    "outputfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some testing\n",
    "\n",
    "This checks the lengh of the last file processed. Should be 10400 or maybe 10600 if there was a chart on both the first and last day of the year or perhaps a leap year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 8 fields in line 8459, saw 9\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-8e4b227f55d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read in the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mchart_peek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# check the length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchart_peek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/data/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2036\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2037\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2038\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 8 fields in line 8459, saw 9\n"
     ]
    }
   ],
   "source": [
    "# read in the file\n",
    "chart_peek = pd.read_csv(outfilename)\n",
    "\n",
    "# check the length\n",
    "len(chart_peek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
