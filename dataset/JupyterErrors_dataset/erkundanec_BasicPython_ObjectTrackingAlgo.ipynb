{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCV Object Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In last week’s blog post we got our feet wet by implementing a simple object tracking algorithm called “centroid tracking”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today, we are going to take the next step and look at eight separate object tracking algorithms built right into OpenCV!\n",
    "\n",
    "You see, while our centroid tracker worked well, it required us to run an actual object detector on each frame of the input video. For the vast majority of circumstances, having to run the detection phase on each and every frame is undesirable and potentially computationally limiting.\n",
    "\n",
    "Instead, we would like to apply object detection only once and then have the object tracker be able to handle every subsequent frame, leading to a faster, more efficient object tracking pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question is — can OpenCV help us achieve such object tracking?\n",
    "\n",
    "The answer is undoubtedly a resounding “Yes”.\n",
    "\n",
    "To learn how to apply object tracking using OpenCV’s built-in object trackers, just keep reading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of today’s blog post, we are going to briefly review the eight object tracking algorithms built-in to OpenCV.\n",
    "\n",
    "From there I’ll demonstrate how we can use each of these object trackers in real-time.\n",
    "\n",
    "Finally, we’ll review the results of each of OpenCV’s object trackers, noting which ones worked under what situations and which ones didn’t.\n",
    "\n",
    "Let’s go ahead and get started tracking objects with OpenCV!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 OpenCV Object Tracking Implementations\n",
    "\n",
    "You might be surprised to know that OpenCV includes eight (yes, eight!) separate object tracking implementations that you can use in your own computer vision applications.\n",
    "\n",
    "I’ve included a brief highlight of each object tracker below:\n",
    "\n",
    "- **BOOSTING Tracker**: Based on the same algorithm used to power the machine learning behind Haar cascades (AdaBoost), but like Haar cascades, is over a decade old. This tracker is slow and doesn’t work very well. Interesting only for legacy reasons and comparing other algorithms. (minimum OpenCV 3.0.0)\n",
    "- **MIL Tracker**: Better accuracy than BOOSTING tracker but does a poor job of reporting failure. (minimum OpenCV 3.0.0)\n",
    "- **KCF Tracker**: Kernelized Correlation Filters. Faster than BOOSTING and MIL. Similar to MIL and KCF, does not handle full occlusion well. (minimum OpenCV 3.1.0)\n",
    "- **CSRT Tracker**: Discriminative Correlation Filter (with Channel and Spatial Reliability). Tends to be more accurate than KCF but slightly slower. (minimum OpenCV 3.4.2)\n",
    "- **MedianFlow Tracker**: Does a nice job reporting failures; however, if there is too large of a jump in motion, such as fast moving objects, or objects that change quickly in their appearance, the model will fail. (minimum OpenCV 3.0.0)\n",
    "- **TLD Tracker**: I’m not sure if there is a problem with the OpenCV implementation of the TLD tracker or the actual algorithm itself, but the TLD tracker was incredibly prone to false-positives. I do not recommend using this OpenCV object tracker. (minimum OpenCV 3.0.0)\n",
    "- **MOSSE Tracker**: Very, very fast. Not as accurate as CSRT or KCF but a good choice if you need pure speed. (minimum OpenCV 3.4.1)\n",
    "- **GOTURN Tracker**: The only deep learning-based object detector included in OpenCV. It requires additional model files to run (will not be covered in this post). My initial experiments showed it was a bit of a pain to use even though it reportedly handles viewing changes well (my initial experiments didn’t confirm this though). I’ll try to cover it in a future post, but in the meantime, take a look at Satya’s writeup. (minimum OpenCV 3.2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### My personal suggestion is to:\n",
    "\n",
    "- Use CSRT when you need higher object tracking accuracy and can tolerate slower FPS throughput\n",
    "- Use KCF when you need faster FPS throughput but can handle slightly lower object tracking accuracy\n",
    "- Use MOSSE when you need pure speed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Satya Mallick also provides some additional information on these object trackers in his article as well.\n",
    "\n",
    "Object Trackers have been in active development in OpenCV 3. Here is a brief summary of which versions of OpenCV the trackers appear in:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you’ve had a brief overview of each of the object trackers, let’s get down to business!\n",
    "\n",
    "Object Tracking with OpenCV\n",
    "To perform object tracking using OpenCV, open up a new file, name it opencv_object_tracker.py , and insert the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from imutils.video import VideoStream\n",
    "from imutils.video import FPS\n",
    "import argparse\n",
    "import imutils\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('major=', '4', 'minor=', '0')\n"
     ]
    }
   ],
   "source": [
    "# extract the OpenCV version info\n",
    "(major, minor) = cv2.__version__.split(\".\")[:2]\n",
    "print('major=', major,'minor=',minor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'TrackerKCF_create'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ed20a72b6469>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# grab the appropriate object tracker using our dictionary of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# OpenCV object tracker objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtracker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackerKCF_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'TrackerKCF_create'"
     ]
    }
   ],
   "source": [
    "# initialize the bounding box coordinates of the object we are going\n",
    "# to track\n",
    "initBB = None\n",
    "# initialize the FPS throughput estimator\n",
    "fps = None\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "# initialize the first frame in the video stream\n",
    "firstFrame = None\n",
    "\n",
    "# OPENCV_OBJECT_TRACKERS = {\n",
    "#     \"csrt\": cv2.TrackerCSRT_create,\n",
    "#     \"kcf\": cv2.TrackerKCF_create,\n",
    "#     \"boosting\": cv2.TrackerBoosting_create,\n",
    "#     \"mil\": cv2.TrackerMIL_create,\n",
    "#     \"tld\": cv2.TrackerTLD_create,\n",
    "#     \"medianflow\": cv2.TrackerMedianFlow_create,\n",
    "#     \"mosse\": cv2.TrackerMOSSE_create\n",
    "# }\n",
    " \n",
    "# grab the appropriate object tracker using our dictionary of\n",
    "# OpenCV object tracker objects\n",
    "tracker = cv2.TrackerKCF_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over frames from the video stream\n",
    "while True:\n",
    "    # grab the current frame and initialize the occupied/unoccupied\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # check to see if we have reached the end of the stream\n",
    "    if frame is None:\n",
    "        break\n",
    "\n",
    "    # resize the frame (so we can process it faster) and grab the\n",
    "    # frame dimensions\n",
    "    frame = imutils.resize(frame, width=500)\n",
    "    (H, W) = frame.shape[:2]\n",
    "\n",
    "    # check to see if we are currently tracking an object\n",
    "    if initBB is not None:\n",
    "        # grab the new bounding box coordinates of the object\n",
    "        (success, box) = tracker.update(frame)\n",
    "\n",
    "        # check to see if the tracking was a success\n",
    "        if success:\n",
    "            (x, y, w, h) = [int(v) for v in box]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h),(0, 255, 0), 2)\n",
    "\n",
    "        # update the FPS counter\n",
    "        fps.update()\n",
    "        fps.stop()\n",
    "\n",
    "        # initialize the set of information we'll be displaying on\n",
    "        # the frame\n",
    "        info = [(\"Tracker\", args[\"tracker\"]),\n",
    "                (\"Success\", \"Yes\" if success else \"No\"),(\"FPS\", \"{:.2f}\".format(fps.fps())),]\n",
    "\n",
    "        # loop over the info tuples and draw them on our frame\n",
    "        for (i, (k, v)) in enumerate(info):\n",
    "            text = \"{}: {}\".format(k, v)\n",
    "            cv2.putText(frame, text, (10, H - ((i * 20) + 20)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
    "        \n",
    "    # show the output frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    # if the 's' key is selected, we are going to \"select\" a bounding\n",
    "    # box to track\n",
    "    if key == ord(\"s\"):\n",
    "        # select the bounding box of the object we want to track (make\n",
    "        # sure you press ENTER or SPACE after selecting the ROI)\n",
    "        initBB = cv2.selectROI(\"Frame\", frame, fromCenter=False,\n",
    "                               showCrosshair=True)\n",
    "        # start OpenCV object tracker using the supplied bounding box\n",
    "        # coordinates, then start the FPS throughput estimator as well\n",
    "        tracker.init(frame, initBB)\n",
    "        fps = FPS().start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
