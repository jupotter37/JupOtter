{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.sparse as sparse\n",
    "import sparseprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "\n",
    "def _gen_indx_seqs(\n",
    "    fan_in: int, num_out: int, num_in: int, fan_out_const: bool\n",
    ") -> torch.LongTensor:\n",
    "    \"\"\"\n",
    "    Generates indices required by the condensed layer (LinearCondensed) for\n",
    "    drawing recombination vectors from the input vector v.\n",
    "\n",
    "    Args:\n",
    "        fan_in: Number of recombination vectors, corresponding to the number of\n",
    "            columns in the weight matrix of LinearCondensed.\n",
    "        num_out: Length of recombination vectors, corresponding to the number of\n",
    "            rows in the weight matrix of LinearCondensed.\n",
    "        num_in: Length of the input vector(s).\n",
    "        fan_out_const: If True, nearly constant fan-out will be ensured. Nearly,\n",
    "            and not exactly, because in some cases the number of connections is\n",
    "            not evenly divisible by the number of neurons.\n",
    "\n",
    "    Returns:\n",
    "        A 2d array of indices of the same shape as the weight matrix in\n",
    "            LinearCondensed, namely (num_out, fan_in).\n",
    "    \"\"\"\n",
    "\n",
    "    indx_seqs = np.zeros((num_out, fan_in))\n",
    "\n",
    "    # indices of input vector\n",
    "    v_inds = np.arange(num_in)\n",
    "\n",
    "    # initializing an array of probabilities for every index of v\n",
    "    # (initially uniform)\n",
    "    probs = 1 / num_in * np.ones(num_in)\n",
    "\n",
    "    for row_nr in range(num_out):\n",
    "        chosen_inds = np.random.choice(\n",
    "            v_inds, size=fan_in, replace=False, p=probs / sum(probs)\n",
    "        )\n",
    "        chosen_inds.sort()\n",
    "        # update probabs only if want to control fan_out\n",
    "        if fan_out_const:\n",
    "            probs[chosen_inds] /= 100 * num_in\n",
    "\n",
    "        indx_seqs[row_nr, :] = chosen_inds\n",
    "\n",
    "    return torch.LongTensor(indx_seqs.astype(int))\n",
    "\n",
    "\n",
    "class LinearCondensed(nn.Module):\n",
    "    r\"\"\"Applies a special condensed matmul\n",
    "    transformation to the incoming data.\n",
    "\n",
    "    This module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n",
    "\n",
    "    Args:\n",
    "        in_features: Length of each input vector.\n",
    "        out_features: Length of layer output.\n",
    "        fan_in: The number of rows in the weight matrix.\n",
    "        bias: If set to ``False``, the layer will not learn an additive bias.\n",
    "            Default: ``True``.\n",
    "\n",
    "    Shape:\n",
    "        - Input: :math:`(*, H_{in})` where :math:`*` means any number of\n",
    "          dimensions including none and :math:`H_{in} = \\text{in\\_features}`.\n",
    "        - Output: :math:`(*, H_{out})` where all but the last dimension\n",
    "          are the same shape as the input and\n",
    "          :math:`H_{out} = \\text{out\\_features}`.\n",
    "\n",
    "    Attributes:\n",
    "        weight: the learnable weights of the module of shape\n",
    "            :math:`(\\text{out\\_features}, \\text{fan\\in})`. The values are\n",
    "            initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n",
    "            :math:`k = \\frac{1}{\\text{fan\\in}}`\n",
    "        bias:   the learnable bias of the module of shape\n",
    "                :math:`(\\text{out\\_features})`.If :attr:`bias` is ``True``, the\n",
    "                values are initialized from\n",
    "                :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n",
    "                :math:`k = \\frac{1}{\\text{in\\_features}}`\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        >>> m = nn.LinearCondensed(20, 10, 5, False)\n",
    "        >>> input = torch.randn(64, 784)\n",
    "        >>> output = m(input)\n",
    "        >>> print(output.size())\n",
    "        torch.Size([64, 10])\n",
    "    \"\"\"\n",
    "    __constants__ = [\"in_features\", \"out_features\"]\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    fan_in: int\n",
    "    weight: torch.Tensor\n",
    "    indx_seqs: torch.Tensor\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features: int,\n",
    "        out_features: int,\n",
    "        fan_in: int,\n",
    "        fan_out_const: bool,\n",
    "        bias: bool = True,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "    ) -> None:\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        super(LinearCondensed, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.fan_in = fan_in\n",
    "        self.weight = Parameter(\n",
    "            torch.empty((out_features, fan_in), **factory_kwargs)\n",
    "        )\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.empty(out_features, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "        # ===== INDICES FOR RECOMBS =====\n",
    "        self.indx_seqs = _gen_indx_seqs(\n",
    "            fan_in=fan_in,\n",
    "            num_out=out_features,\n",
    "            num_in=in_features,\n",
    "            fan_out_const=fan_out_const,\n",
    "        )\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        # Setting a=sqrt(5) in kaiming_uniform is the same as initializing with\n",
    "        # uniform(-1/sqrt(fan_in), 1/sqrt(fan_in)). For details, see\n",
    "        # https://github.com/pytorch/pytorch/issues/57109\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if self.bias is not None:\n",
    "            dense_fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(dense_fan_in) if dense_fan_in > 0 else 0\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, input: torch.Tensor) -> torch.Tensor:\n",
    "        output = (\n",
    "            torch.sum(self.weight * input[:, self.indx_seqs], axis=2)\n",
    "            + self.bias\n",
    "        )\n",
    "        return output\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return (\n",
    "            \"in_features={}, out_features={}, fan_in={}, fan_out_const={}, \"\n",
    "            \"bias={}\"\n",
    "        ).format(\n",
    "            self.in_features,\n",
    "            self.out_features,\n",
    "            self.fan_in,\n",
    "            self.fan_out_const,\n",
    "            self.bias is not None,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CondensedLinear(nn.Module):\n",
    "    \n",
    "#     def __init__(self, dense_weight, mask, bias=None):\n",
    "#         self.dense_weight = dense_weight\n",
    "#         self.mask = mask\n",
    "#         self.bias = bias\n",
    "#         self.sparse_weight = torch.sparse.mo\n",
    "        \n",
    "#     def forward(self,  input: torch.Tensor) -> torch.Tensor:\n",
    "#         return torch.sum(self.sparse_weight * input) + self.bias\n",
    "            \n",
    "        \n",
    "\n",
    "# import copy\n",
    "# class SparseLinear(nn.Module):\n",
    "    \n",
    "#     def __init__(self, linear_layer, bs):   \n",
    "#         super().__init__()\n",
    "#         self.weights = linear_layer.weight.T.to_sparse_coo()\n",
    "#         # self.weights = copy.deepcopy(linear_layer.weight.T.to_sparse_coo())\n",
    "#         self.bias = nn.Parameter(linear_layer.bias.expand(size=(bs, *linear_layer.bias.shape)))\n",
    "#         # self.bias = linear_layer.bias\n",
    "\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return self.bias + torch.mm(x, self.weights)\n",
    "\n",
    "\n",
    "class SparseLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, linear_layer, bs):   \n",
    "        super().__init__()\n",
    "        self.weight = linear_layer.weight.to_sparse_coo()\n",
    "        # self.weights = copy.deepcopy(linear_layer.weight.T.to_sparse_coo())\n",
    "        self.bias = nn.Parameter(linear_layer.bias.expand(size=(bs, *linear_layer.bias.shape)))\n",
    "        # self.bias = linear_layer.bias\n",
    "\n",
    "    def forward(self, x):\n",
    "        # return self.bias + torch.mm(self.weight, x.T).T\n",
    "        return self.bias + torch.mm(self.weight, x).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f6e2ff30100>\n",
      "Dense\n",
      "  935.75 us\n",
      "  1 measurement, 100 runs , 4 threads\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f6e2ff30820>\n",
      "Sparse Linear\n",
      "  30.26 ms\n",
      "  1 measurement, 100 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "dense = nn.Linear(1024,1000)\n",
    "condensed = LinearCondensed(1024, 1000, fan_in=100, fan_out_const=False)\n",
    "\n",
    "def forward_pass(input, layer):\n",
    "    layer(input)\n",
    "    return\n",
    "    \n",
    "input = torch.rand(size=(128, 1024))\n",
    "layer = dense\n",
    "t_dense = benchmark.Timer(\n",
    "    stmt=\"layer(input)\",\n",
    "    globals={\"input\": input, \"layer\": layer},\n",
    "    num_threads=4,\n",
    "    label=\"Dense\",\n",
    ")\n",
    "\n",
    "input = torch.rand(size=(128, 1024))\n",
    "layer = condensed\n",
    "\n",
    "jit_lc = torch.jit.trace(condensed, input)\n",
    "torch.jit.optimize_for_inference(jit_lc)\n",
    "t_sparse = benchmark.Timer(\n",
    "    stmt=\"layer(input)\",\n",
    "    globals={\"input\": input, \"layer\": jit_lc},\n",
    "    num_threads=4,\n",
    "    label=\"Sparse Linear\",\n",
    ")\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(t_dense.timeit(100))\n",
    "    print(t_sparse.timeit(100))\n",
    "    \n",
    "\n",
    "\n",
    "# input = torch.rand(size=(64, 1024))\n",
    "# layer = accel_linear\n",
    "# t_accel = benchmark.Timer(\n",
    "#     stmt=\"layer(input)\",\n",
    "#     globals={\"input\": input, \"layer\": layer},\n",
    "#     num_threads=4,\n",
    "#     label=\"Accelerated Linear\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1024, out_features=1000, bias=True)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dense_linear = nn.Linear(1024, 1000)\n",
    "sparse_linear = nn.Linear(1024, 1000)\n",
    "dense_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1023999)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.count_nonzero(sparse_linear.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 1024])\n",
      "torch.Size([1000, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(10240)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity=0.99\n",
    "idx = torch.randperm(n=sparse_linear.weight.numel())\n",
    "non_zero_idx = idx[int(len(idx)*(1-0.99)):]\n",
    "with torch.no_grad():\n",
    "    \n",
    "    w = sparse_linear.weight\n",
    "    w  = w.flatten()\n",
    "    print(sparse_linear.weight.shape)\n",
    "    w[non_zero_idx]=0\n",
    "    w = w.reshape(dense_linear.weight.shape)\n",
    "    print(sparse_linear.weight.shape)\n",
    "\n",
    "\n",
    "\n",
    "sparse_linear.weight.count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_linear = accel_linear = sparseprop.modules.SparseLinear(dense_weight=sparse_linear.weight, bias=sparse_linear.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    sparse_linear = SparseLinear(sparse_linear, bs = 64)\n",
    "    sparse_linear.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_linear.weight.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Unsupported value kind: Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/user/condensed-sparsity/notebooks/sparse_ops.ipynb Cell 10\u001b[0m in \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d696b652f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d6f7261696e65227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d696b652f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/home/user/condensed-sparsity/notebooks/sparse_ops.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# sparse_linear = SparseLinear(sparse_linear, bs = 64)\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d696b652f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d6f7261696e65227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d696b652f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/home/user/condensed-sparsity/notebooks/sparse_ops.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d696b652f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d6f7261696e65227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d696b652f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/home/user/condensed-sparsity/notebooks/sparse_ops.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     sparse_linear_module \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace(sparse_linear, torch\u001b[39m.\u001b[39;49mrand(size\u001b[39m=\u001b[39;49m(\u001b[39m64\u001b[39;49m, \u001b[39m1024\u001b[39;49m))\u001b[39m.\u001b[39;49mT)\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torch/jit/_trace.py:759\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[39mreturn\u001b[39;00m func\n\u001b[1;32m    758\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(func, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[0;32m--> 759\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    760\u001b[0m         func,\n\u001b[1;32m    761\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mforward\u001b[39;49m\u001b[39m\"\u001b[39;49m: example_inputs},\n\u001b[1;32m    762\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    763\u001b[0m         check_trace,\n\u001b[1;32m    764\u001b[0m         wrap_check_inputs(check_inputs),\n\u001b[1;32m    765\u001b[0m         check_tolerance,\n\u001b[1;32m    766\u001b[0m         strict,\n\u001b[1;32m    767\u001b[0m         _force_outplace,\n\u001b[1;32m    768\u001b[0m         _module_class,\n\u001b[1;32m    769\u001b[0m     )\n\u001b[1;32m    771\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    772\u001b[0m     \u001b[39mhasattr\u001b[39m(func, \u001b[39m\"\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    773\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule)\n\u001b[1;32m    774\u001b[0m     \u001b[39mand\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    775\u001b[0m ):\n\u001b[1;32m    776\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    777\u001b[0m         func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m,\n\u001b[1;32m    778\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m: example_inputs},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    785\u001b[0m         _module_class,\n\u001b[1;32m    786\u001b[0m     )\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torch/jit/_trace.py:976\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    972\u001b[0m     argument_names \u001b[39m=\u001b[39m get_callable_argument_names(func)\n\u001b[1;32m    974\u001b[0m example_inputs \u001b[39m=\u001b[39m make_tuple(example_inputs)\n\u001b[0;32m--> 976\u001b[0m module\u001b[39m.\u001b[39;49m_c\u001b[39m.\u001b[39;49m_create_method_from_trace(\n\u001b[1;32m    977\u001b[0m     method_name,\n\u001b[1;32m    978\u001b[0m     func,\n\u001b[1;32m    979\u001b[0m     example_inputs,\n\u001b[1;32m    980\u001b[0m     var_lookup_fn,\n\u001b[1;32m    981\u001b[0m     strict,\n\u001b[1;32m    982\u001b[0m     _force_outplace,\n\u001b[1;32m    983\u001b[0m     argument_names,\n\u001b[1;32m    984\u001b[0m )\n\u001b[1;32m    985\u001b[0m check_trace_method \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_c\u001b[39m.\u001b[39m_get_method(method_name)\n\u001b[1;32m    987\u001b[0m \u001b[39m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/build/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1182\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         recording_scopes \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1183\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1184\u001b[0m     \u001b[39mif\u001b[39;00m recording_scopes:\n",
      "\u001b[1;32m/home/user/condensed-sparsity/notebooks/sparse_ops.ipynb Cell 10\u001b[0m in \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d696b652f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d6f7261696e65227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d696b652f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/home/user/condensed-sparsity/notebooks/sparse_ops.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d696b652f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d6f7261696e65227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d696b652f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/home/user/condensed-sparsity/notebooks/sparse_ops.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39m# return self.bias + torch.mm(self.weight, x.T).T\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://dev-container%2B7b22686f737450617468223a222f686f6d652f6d696b652f636f6e64656e7365642d7370617273697479222c226c6f63616c446f636b6572223a66616c73652c2273657474696e6773223a7b22686f7374223a227373683a2f2f6d6f7261696e65227d2c22636f6e66696746696c65223a7b22246d6964223a312c2270617468223a222f686f6d652f6d696b652f636f6e64656e7365642d73706172736974792f2e646576636f6e7461696e65722f646576636f6e7461696e65722e6a736f6e222c22736368656d65223a227673636f64652d66696c65486f7374227d7d/home/user/condensed-sparsity/notebooks/sparse_ops.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39;49mmm(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, x)\u001b[39m.\u001b[39mT\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unsupported value kind: Tensor"
     ]
    }
   ],
   "source": [
    "# sparse_linear = SparseLinear(sparse_linear, bs = 64)\n",
    "\n",
    "with torch.no_grad():\n",
    "    sparse_linear_module = torch.jit.trace(sparse_linear, torch.rand(size=(64, 1024)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "def forward_pass(input, layer):\n",
    "    layer(input)\n",
    "    return\n",
    "    \n",
    "input = torch.rand(size=(64, 1024))\n",
    "layer = dense_linear\n",
    "t_dense = benchmark.Timer(\n",
    "    stmt=\"layer(input)\",\n",
    "    globals={\"input\": input, \"layer\": layer},\n",
    "    num_threads=4,\n",
    "    label=\"Dense\",\n",
    ")\n",
    "\n",
    "input = torch.rand(size=(64, 1024)).T\n",
    "layer = sparse_linear\n",
    "t_sparse = benchmark.Timer(\n",
    "    stmt=\"layer(input)\",\n",
    "    globals={\"input\": input, \"layer\": layer},\n",
    "    num_threads=4,\n",
    "    label=\"Sparse Linear\",\n",
    ")\n",
    "\n",
    "\n",
    "input = torch.rand(size=(64, 1024))\n",
    "layer = accel_linear\n",
    "t_accel = benchmark.Timer(\n",
    "    stmt=\"layer(input)\",\n",
    "    globals={\"input\": input, \"layer\": layer},\n",
    "    num_threads=4,\n",
    "    label=\"Accelerated Linear\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f03526d5300>\n",
      "Dense\n",
      "  1.05 ms\n",
      "  1 measurement, 100 runs , 4 threads\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f0350447550>\n",
      "Sparse Linear\n",
      "  1.66 ms\n",
      "  1 measurement, 100 runs , 4 threads\n",
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7f03526d5300>\n",
      "Accelerated Linear\n",
      "  449.00 us\n",
      "  1 measurement, 100 runs , 4 threads\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(t_dense.timeit(100))\n",
    "    print(t_sparse.timeit(100))\n",
    "    print(t_accel.timeit(100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparseLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, linear_layer, bs):   \n",
    "        super().__init__()\n",
    "        self.weights = linear_layer.weight.to_sparse_coo()\n",
    "        # self.weights = copy.deepcopy(linear_layer.weight.T.to_sparse_coo())\n",
    "        self.bias = nn.Parameter(linear_layer.bias.expand(size=(bs, *linear_layer.bias.shape)))\n",
    "        # self.bias = linear_layer.bias\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # return self.bias + torch.mm(x, self.weights)\n",
    "        return self.bias + torch.mm(self.weights, x.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1000])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(sparse_linear.weight @ x.T).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1000])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x @ sparse_linear.weight.T).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 64])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.t().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 1000])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl.weights.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(size=(64,1024))\n",
    "with torch.no_grad():\n",
    "    sl =SparseLinear(sparse_linear, bs=64)\n",
    "    print(sl(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.076035\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "input = torch.rand(size=(64, 1024))\n",
    "\n",
    "with torch.no_grad():\n",
    "    start = datetime.now()\n",
    "    for _ in range(100):\n",
    "        dense_linear(input)\n",
    "    end = datetime.now() - start\n",
    "    print(end)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.093300\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "input = torch.rand(size=(64, 1024))\n",
    "\n",
    "with torch.no_grad():\n",
    "    start = datetime.now()\n",
    "    for _ in range(100):\n",
    "        sparse_linear(input)\n",
    "    end = datetime.now() - start\n",
    "    print(end)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.038281\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "input = torch.rand(size=(64, 1024))\n",
    "\n",
    "with torch.no_grad():\n",
    "    start = datetime.now()\n",
    "    for _ in range(100):\n",
    "        accel_linear(input)\n",
    "    end = datetime.now() - start\n",
    "    print(end)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "class SparseLinear(nn.Module):\n",
    "    \n",
    "    def __init__(self, linear_layer, bs):   \n",
    "        super().__init__()\n",
    "        self.weights = linear_layer.weight.T.to_sparse_coo()\n",
    "        # self.weights = copy.deepcopy(linear_layer.weight.T.to_sparse_coo())\n",
    "        self.bias = nn.Parameter(linear_layer.bias.expand(size=(bs, *linear_layer.bias.shape)))\n",
    "        # self.bias = linear_layer.bias\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.bias + torch.mm(x, self.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0738, -0.0234,  0.0346,  ..., -0.0094,  0.0154, -0.0011],\n",
       "        [-0.1085,  0.0009,  0.0709,  ..., -0.0308,  0.0147,  0.0152],\n",
       "        [-0.0445,  0.0006,  0.0638,  ..., -0.0376,  0.0010, -0.0057],\n",
       "        ...,\n",
       "        [-0.1035,  0.0213,  0.0500,  ...,  0.0013,  0.0042,  0.0554],\n",
       "        [-0.0812,  0.0079,  0.0342,  ..., -0.0241, -0.0153,  0.0018],\n",
       "        [-0.0975,  0.0019,  0.0885,  ..., -0.0015, -0.0043,  0.0365]],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sl.bias  + (input_sparse @ sl.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00.544879\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand(size=(64, 1024))\n",
    "input_sparse = input.to_sparse_coo()\n",
    "with torch.no_grad():\n",
    "    sl = SparseLinear(sparse_linear, bs=64)\n",
    "    start = datetime.now()\n",
    "    for _ in range(100):\n",
    "        out = sl(input_sparse)\n",
    "    end = datetime.now() - start\n",
    "    print(end)\n",
    "out.shape\n",
    "print(type(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    input.to_sparse_coo() @ sparse_linear.weight.T.to_sparse_coo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.tensor(\n",
    "        [\n",
    "            [\n",
    "                1,2,3\n",
    "            ],\n",
    "            [\n",
    "                4,5,6,\n",
    "            ],\n",
    "        ]\n",
    "    )\n",
    "w.shape\n",
    "x = torch.tensor([[1,2],[3,4],[5,6],])\n",
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "816b48dc46e0e4033a4b7ddacb526e2f216437e7413cf9fdf092ed7be3b64e38"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
