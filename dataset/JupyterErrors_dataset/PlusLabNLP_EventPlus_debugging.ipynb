{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import nltk\n",
    "from itertools import combinations\n",
    "from predpatt import load_conllu\n",
    "from predpatt import PredPatt\n",
    "from predpatt import PredPattOpts\n",
    "\n",
    "#from factslab.datastructures import ConstituencyTree, DependencyTree\n",
    "from factslab.pytorch.temporalmodule import TemporalModel, TemporalTrainer\n",
    "options = PredPattOpts(resolve_relcl=True, borrow_arg_for_relcl=True, resolve_conj=False, cut=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import allennlp\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from allennlp.commands.elmo import ElmoEmbedder\n",
    "import pickle\n",
    "from torch.distributions.binomial import Binomial\n",
    "from torch.nn import MSELoss, L1Loss, SmoothL1Loss, CrossEntropyLoss\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "#from torchviz import make_dot, make_dot_from_trace\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm import tqdm_notebook as tqdm_n\n",
    "\n",
    "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependency structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import DependencyGraph\n",
    "import re\n",
    "\n",
    "def html_ify(s):\n",
    "    '''\n",
    "        Takes care of &quot &lsqb &rsqb &#39\n",
    "    '''\n",
    "    html_string = re.sub(r'\\)', r'&rcrb;', s)\n",
    "    html_string = re.sub(r'\\(', r'&lcrb;', html_string)\n",
    "    return html_string\n",
    "\n",
    "def get_structs(file_path):\n",
    "    files = [file_path]\n",
    "    structures = {}\n",
    "    for file in files:\n",
    "        with open(file, 'r') as f:\n",
    "            filename = file.split(\"/\")[-1]\n",
    "            iden = 0\n",
    "            a = \"\"\n",
    "            words = []\n",
    "            for line in f:\n",
    "                if line != \"\\n\":\n",
    "                    a += line\n",
    "                    words.append(line.split(\"\\t\")[1])\n",
    "                else:\n",
    "                    iden += 1\n",
    "                    a = html_ify(a)\n",
    "                    structure = DependencyGraph(a, top_relation_label='root')\n",
    "                    sent = \" \".join(words)\n",
    "                    sent = html_ify(sent)\n",
    "                    sent_id = filename + \" sent_\" + str(iden)\n",
    "                    structures[sent_id] = structure\n",
    "                    a = \"\"\n",
    "                    words = []\n",
    "    return structures\n",
    "\n",
    "structures = get_structs('../input_data/sample_document.txt.output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_struct_dicts(structures):\n",
    "    '''\n",
    "    Input: A dictionary of DependencyGraph objects with key as the sentence id:\n",
    "            Key example: sample_corpus_document.txt.output sent_1'\n",
    "            \n",
    "    Output: A dictionary of sentences with key as the sentence id:\n",
    "\n",
    "    '''\n",
    "    struct_dict = {}\n",
    "    for key in structures:\n",
    "        N = len(structures[key].nodes)\n",
    "        struct_dict[key] = [structures[key].nodes[i]['word']for i in range(1, N)]\n",
    "        \n",
    "    return struct_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct_dict = extract_struct_dicts(structures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample_document.txt.output sent_1': ['Before',\n",
       "  'the',\n",
       "  'arrival',\n",
       "  'of',\n",
       "  'Keep',\n",
       "  ',',\n",
       "  'which',\n",
       "  'Google',\n",
       "  'launched',\n",
       "  'this',\n",
       "  'week',\n",
       "  ',',\n",
       "  'there',\n",
       "  'was',\n",
       "  'no',\n",
       "  'default',\n",
       "  'note-taking',\n",
       "  'app',\n",
       "  'for',\n",
       "  'Android',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_2': ['It',\n",
       "  'was',\n",
       "  'a',\n",
       "  'glaring',\n",
       "  'hole',\n",
       "  ',',\n",
       "  'considering',\n",
       "  'that',\n",
       "  'Apple',\n",
       "  \"'s\",\n",
       "  'iPhone',\n",
       "  'has',\n",
       "  'built-in',\n",
       "  'Notes',\n",
       "  'and',\n",
       "  'Reminders',\n",
       "  'apps',\n",
       "  'that',\n",
       "  'can',\n",
       "  'be',\n",
       "  'powered',\n",
       "  'by',\n",
       "  'Siri',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_3': ['Instead',\n",
       "  'of',\n",
       "  'settling',\n",
       "  'for',\n",
       "  'a',\n",
       "  'bare',\n",
       "  'bones',\n",
       "  'app',\n",
       "  'to',\n",
       "  'fill',\n",
       "  'the',\n",
       "  'void',\n",
       "  ',',\n",
       "  'the',\n",
       "  'search',\n",
       "  'giant',\n",
       "  'took',\n",
       "  'things',\n",
       "  'one',\n",
       "  'step',\n",
       "  'further',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_4': ['Keep',\n",
       "  'is',\n",
       "  \"n't\",\n",
       "  'simply',\n",
       "  'just',\n",
       "  'a',\n",
       "  'place',\n",
       "  'to',\n",
       "  'bank',\n",
       "  'whatever',\n",
       "  'random',\n",
       "  'half-thoughts',\n",
       "  'come',\n",
       "  'to',\n",
       "  'mind',\n",
       "  ':',\n",
       "  'Users',\n",
       "  'can',\n",
       "  'construct',\n",
       "  'to-do',\n",
       "  'lists',\n",
       "  ',',\n",
       "  'stash',\n",
       "  'photos',\n",
       "  ',',\n",
       "  'and',\n",
       "  'color',\n",
       "  'code',\n",
       "  'your',\n",
       "  'notes',\n",
       "  '--',\n",
       "  'all',\n",
       "  'in',\n",
       "  'one',\n",
       "  'well-designed',\n",
       "  'and',\n",
       "  'easy-to-use',\n",
       "  'interface',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_5': ['The',\n",
       "  'second',\n",
       "  'you',\n",
       "  'log',\n",
       "  'anything',\n",
       "  'into',\n",
       "  'your',\n",
       "  'phone',\n",
       "  ',',\n",
       "  'it',\n",
       "  'is',\n",
       "  'also',\n",
       "  'accessible',\n",
       "  'from',\n",
       "  'a',\n",
       "  'PC',\n",
       "  'Web',\n",
       "  'browser',\n",
       "  'via',\n",
       "  'Google',\n",
       "  'Drive',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_6': ['Alternatively',\n",
       "  ',',\n",
       "  'you',\n",
       "  'can',\n",
       "  'save',\n",
       "  'things',\n",
       "  'while',\n",
       "  'working',\n",
       "  'on',\n",
       "  'your',\n",
       "  'computer',\n",
       "  ',',\n",
       "  'and',\n",
       "  'it',\n",
       "  'will',\n",
       "  'instantly',\n",
       "  'appear',\n",
       "  'on',\n",
       "  'your',\n",
       "  'phone',\n",
       "  ',',\n",
       "  'ready',\n",
       "  'for',\n",
       "  'use',\n",
       "  'while',\n",
       "  'on',\n",
       "  'the',\n",
       "  'go',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_7': ['The',\n",
       "  'design',\n",
       "  'may',\n",
       "  'not',\n",
       "  'be',\n",
       "  'as',\n",
       "  'progressive',\n",
       "  'as',\n",
       "  'the',\n",
       "  'to-do',\n",
       "  'app',\n",
       "  'Clear',\n",
       "  ',',\n",
       "  'but',\n",
       "  'Keep',\n",
       "  'makes',\n",
       "  'up',\n",
       "  'for',\n",
       "  'that',\n",
       "  'in',\n",
       "  'its',\n",
       "  'simplicity',\n",
       "  'and',\n",
       "  'efficiency',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_8': ['Everything',\n",
       "  'in',\n",
       "  'Keep',\n",
       "  'is',\n",
       "  'presented',\n",
       "  'like',\n",
       "  'a',\n",
       "  'Microsoft',\n",
       "  '&lcrb;',\n",
       "  'MSFT',\n",
       "  ',',\n",
       "  'Fortune',\n",
       "  '500',\n",
       "  '&rcrb;',\n",
       "  'Windows',\n",
       "  'Phone-esque',\n",
       "  'stream',\n",
       "  'of',\n",
       "  'tiles',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_9': ['Swiping',\n",
       "  'left',\n",
       "  'or',\n",
       "  'right',\n",
       "  'will',\n",
       "  'archive',\n",
       "  'those',\n",
       "  'notes',\n",
       "  'you',\n",
       "  'no',\n",
       "  'longer',\n",
       "  'need',\n",
       "  '&lcrb;',\n",
       "  'but',\n",
       "  'do',\n",
       "  \"n't\",\n",
       "  'want',\n",
       "  'to',\n",
       "  'erase',\n",
       "  'entirely',\n",
       "  '&rcrb;',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_10': ['At',\n",
       "  'the',\n",
       "  'top',\n",
       "  'of',\n",
       "  'the',\n",
       "  'app',\n",
       "  'is',\n",
       "  'a',\n",
       "  'text',\n",
       "  'entry',\n",
       "  'field',\n",
       "  'that',\n",
       "  'serves',\n",
       "  'as',\n",
       "  'your',\n",
       "  'main',\n",
       "  'point',\n",
       "  'of',\n",
       "  'entry',\n",
       "  'for',\n",
       "  'all',\n",
       "  'new',\n",
       "  'notes',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_11': ['And',\n",
       "  'when',\n",
       "  'viewing',\n",
       "  'any',\n",
       "  'specific',\n",
       "  'note',\n",
       "  ',',\n",
       "  'tapping',\n",
       "  'any',\n",
       "  'part',\n",
       "  'of',\n",
       "  'that',\n",
       "  'note',\n",
       "  '&lcrb;',\n",
       "  'title',\n",
       "  ',',\n",
       "  'body',\n",
       "  ',',\n",
       "  'etc.',\n",
       "  '&rcrb;',\n",
       "  'will',\n",
       "  'allow',\n",
       "  'you',\n",
       "  'to',\n",
       "  'edit',\n",
       "  'it',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_12': ['The',\n",
       "  'entire',\n",
       "  'experience',\n",
       "  'is',\n",
       "  'frictionless',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_13': ['That',\n",
       "  'said',\n",
       "  ',',\n",
       "  'it',\n",
       "  \"'s\",\n",
       "  'not',\n",
       "  'going',\n",
       "  'to',\n",
       "  'conquer',\n",
       "  'the',\n",
       "  'world',\n",
       "  'quite',\n",
       "  'yet',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_14': ['Organization',\n",
       "  'options',\n",
       "  'are',\n",
       "  'limited',\n",
       "  '--',\n",
       "  'color',\n",
       "  'coding',\n",
       "  'is',\n",
       "  'your',\n",
       "  'only',\n",
       "  'choice',\n",
       "  ',',\n",
       "  'and',\n",
       "  'you',\n",
       "  'ca',\n",
       "  \"n't\",\n",
       "  're-order',\n",
       "  'your',\n",
       "  'notes',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_15': ['Sharing',\n",
       "  'with',\n",
       "  'others',\n",
       "  'is',\n",
       "  'mostly',\n",
       "  'limited',\n",
       "  'to',\n",
       "  'email',\n",
       "  'and',\n",
       "  'Google',\n",
       "  '+',\n",
       "  ',',\n",
       "  'and',\n",
       "  'the',\n",
       "  'desktop',\n",
       "  'features',\n",
       "  'are',\n",
       "  'pretty',\n",
       "  'bare',\n",
       "  'bones',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_16': ['But',\n",
       "  'that',\n",
       "  \"'s\",\n",
       "  'more',\n",
       "  'a',\n",
       "  'function',\n",
       "  'of',\n",
       "  'it',\n",
       "  'being',\n",
       "  'new',\n",
       "  ',',\n",
       "  'rather',\n",
       "  'than',\n",
       "  'poorly',\n",
       "  'thought',\n",
       "  'out',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_17': ['Like',\n",
       "  'most',\n",
       "  'things',\n",
       "  'Google',\n",
       "  ',',\n",
       "  'expect',\n",
       "  'the',\n",
       "  'company',\n",
       "  'to',\n",
       "  'flesh',\n",
       "  'out',\n",
       "  'Keep',\n",
       "  'over',\n",
       "  'time',\n",
       "  'and',\n",
       "  'really',\n",
       "  'turn',\n",
       "  'it',\n",
       "  'into',\n",
       "  'our',\n",
       "  'personal',\n",
       "  'internet',\n",
       "  'junk',\n",
       "  'drawer',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_18': ['It',\n",
       "  \"'s\",\n",
       "  'easy',\n",
       "  'to',\n",
       "  'foresee',\n",
       "  'the',\n",
       "  'day',\n",
       "  'the',\n",
       "  'when',\n",
       "  'users',\n",
       "  'will',\n",
       "  'be',\n",
       "  'able',\n",
       "  'to',\n",
       "  'send',\n",
       "  'anything',\n",
       "  'from',\n",
       "  'their',\n",
       "  'Web',\n",
       "  'browser',\n",
       "  'or',\n",
       "  'Maps',\n",
       "  'directly',\n",
       "  'to',\n",
       "  'Keep',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_19': ['The',\n",
       "  'prospect',\n",
       "  'of',\n",
       "  'Keep',\n",
       "  'incorporating',\n",
       "  'features',\n",
       "  'of',\n",
       "  'services',\n",
       "  'such',\n",
       "  'as',\n",
       "  'Pinterest',\n",
       "  'or',\n",
       "  'Pocket',\n",
       "  ',',\n",
       "  'or',\n",
       "  'even',\n",
       "  'making',\n",
       "  'it',\n",
       "  'easy',\n",
       "  'to',\n",
       "  'catalog',\n",
       "  'streaming',\n",
       "  'media',\n",
       "  ',',\n",
       "  'could',\n",
       "  'turn',\n",
       "  'it',\n",
       "  'into',\n",
       "  'something',\n",
       "  'big',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_20': ['That',\n",
       "  'should',\n",
       "  'scare',\n",
       "  'Evernote',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_21': ['Keep',\n",
       "  'is',\n",
       "  'not',\n",
       "  'the',\n",
       "  'reinvention',\n",
       "  'of',\n",
       "  'the',\n",
       "  'wheel',\n",
       "  'in',\n",
       "  'any',\n",
       "  'aspect',\n",
       "  '--',\n",
       "  'there',\n",
       "  'are',\n",
       "  'a',\n",
       "  'plethora',\n",
       "  'of',\n",
       "  'third-party',\n",
       "  'apps',\n",
       "  'already',\n",
       "  'available',\n",
       "  'for',\n",
       "  'Android',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_22': ['But',\n",
       "  'it',\n",
       "  'is',\n",
       "  'a',\n",
       "  'well-exectuted',\n",
       "  'refinement',\n",
       "  '.'],\n",
       " 'sample_document.txt.output sent_23': ['In',\n",
       "  'filling',\n",
       "  'a',\n",
       "  'minor',\n",
       "  ',',\n",
       "  'but',\n",
       "  'important',\n",
       "  'gap',\n",
       "  'in',\n",
       "  'its',\n",
       "  'mobile',\n",
       "  'ecosystem',\n",
       "  ',',\n",
       "  'Google',\n",
       "  'gives',\n",
       "  'the',\n",
       "  'competition',\n",
       "  'one',\n",
       "  'less',\n",
       "  'claim',\n",
       "  'of',\n",
       "  'superiority',\n",
       "  'over',\n",
       "  'Android',\n",
       "  '.']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Before', 'the', 'arrival', 'of', 'Keep', ',', 'which', 'Google', 'launched', 'this', 'week', ',', 'there', 'was', 'no', 'default', 'note-taking', 'app', 'for', 'Android', '.']\n"
     ]
    }
   ],
   "source": [
    "print(struct_dict['sample_document.txt.output sent_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_in_tree(idx, dep_obj):\n",
    "    '''\n",
    "    Input: Index of the word in a linear sequence of words\n",
    "    \n",
    "    Output: Depth of that word in the dependency tree\n",
    "    \n",
    "    '''\n",
    "    nodes = dep_obj.nodes\n",
    "    depth = 0\n",
    "    i = idx+1\n",
    "    while nodes[i]['rel'] != 'root':\n",
    "        i = nodes[i]['head']\n",
    "        depth+=1\n",
    "        \n",
    "    return depth\n",
    "            \n",
    "    \n",
    "def find_pivot_predicate(fname, sentid_num, predp_object, structures):\n",
    "    '''\n",
    "    Find the pivot-predicate of a given sentence's id\n",
    "    \n",
    "    Heuristic/Algo:  Follow the root predicate until you find a predicate which doesn't have\n",
    "                any xcomp, ccomp or csubj dependencies.\n",
    "                \n",
    "    '''\n",
    "    #preds = filter_preds([(sentid_num, x) for x in predp_object.instances])\n",
    "    preds = [(sentid_num, x) for x in predp_object.instances]\n",
    "    tokens = [y.root.position for x, y in preds]\n",
    "    \n",
    "    if tokens:\n",
    "        tokens_covered = set()\n",
    "        \n",
    "        struct_id = fname + \" sent_\" + str(sentid_num)\n",
    "        dep_object = structures[struct_id]\n",
    "        pred_heights = sorted([(x, depth_in_tree(x,dep_object)) for x in tokens], key=lambda x:x[1])\n",
    "        tokens_reverse = [x for x,y in pred_heights][::-1]\n",
    "        \n",
    "        root_idx = tokens.index(pred_heights[0][0])\n",
    "        root_predicate = preds[root_idx]\n",
    "        deps = dep_object.nodes[tokens[root_idx]+1]['deps']\n",
    "        \n",
    "        tokens_covered.add(tokens[root_idx])\n",
    "        tokens_reverse.pop()\n",
    "        \n",
    "        while ('ccomp' in deps) or ('xcomp' in deps) or ('csubj') in deps:\n",
    "            variables = ['ccomp', 'xcomp', 'csubj']\n",
    "            for var in variables:\n",
    "                if var in deps:\n",
    "                    tok_idx = deps[var][0]-1\n",
    "                    if tok_idx in tokens:\n",
    "                        root_idx = tokens.index(tok_idx)\n",
    "                        tokens_covered.add(tokens[root_idx])\n",
    "                        tokens_reverse.pop()\n",
    "                    else:\n",
    "                        if tokens_reverse:\n",
    "                            root_idx = tokens.index(tokens_reverse[-1])\n",
    "                            tokens_covered.add(tokens[root_idx])\n",
    "                            tokens_reverse.pop()\n",
    "                        else:\n",
    "                            return root_predicate\n",
    "                    break\n",
    "                    \n",
    "            deps = dep_object.nodes[tokens[root_idx]+1]['deps']\n",
    "            root_predicate = preds[root_idx]\n",
    "            \n",
    "        return root_predicate \n",
    "\n",
    "    return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_preds(pred_tuples):\n",
    "    '''\n",
    "    Input: a list of tuples of (sent_id_num, predicate object)\n",
    "    \n",
    "    Output: filter tuples only with specific pos tags predicates\n",
    "    \n",
    "    '''\n",
    "    ans = []\n",
    "    pos_tags = set([\"ADJ\", \"NOUN\", \"NUM\", \"DET\", \"PROPN\", \"PRON\", \"VERB\", \"AUX\"])\n",
    "    for sent_id, pred_obj in pred_tuples:\n",
    "        if pred_obj.root.tag not in pos_tags:\n",
    "            #print(pred_obj.root.tag)\n",
    "            #print(\"not in pos tags\")\n",
    "            continue\n",
    "        elif pred_obj.root.tag not in [\"VERB\", \"AUX\"]:\n",
    "            gov_rels = [tok.gov_rel for tok in pred_obj.tokens]\n",
    "            if 'cop' in gov_rels:\n",
    "                ans.append((sent_id, pred_obj))\n",
    "            elif pred_obj.root.tag == 'ADJ':\n",
    "                ans.append((sent_id, pred_obj))\n",
    "        else:\n",
    "            ans.append((sent_id, pred_obj))\n",
    "    return ans\n",
    "\n",
    "def predicate_info(predicate):\n",
    "    '''\n",
    "    Input: predicate object\n",
    "    Output: pred_text, token, root_token\n",
    "    \n",
    "    Note: If predicate is copular: pred_text is only upto first 5 words\n",
    "    '''      \n",
    "    copula_bool = False\n",
    "    \n",
    "    #Extend predicate to start from the copula\n",
    "    if predicate.root.tag not in [\"VERB\", \"AUX\"]:\n",
    "        all_pred = predicate.tokens\n",
    "        gov_rels = [tok.gov_rel for tok in all_pred]\n",
    "        if 'cop' in gov_rels:\n",
    "            copula_bool = True\n",
    "            cop_pos = gov_rels.index('cop')\n",
    "            pred = [x.text for x in all_pred[cop_pos:]]\n",
    "            pred_token = [x.position for x in all_pred[cop_pos:]]\n",
    "            def_pred_token = predicate.root.position  #needed for it_happen set\n",
    "            cop_bool = True  \n",
    "            #print(predicate, idx)\n",
    "            \n",
    "        elif predicate.root.tag == \"ADJ\":\n",
    "            pred_token = [predicate.root.position]\n",
    "            pred = [predicate.root.text]\n",
    "            def_pred_token = predicate.root.position\n",
    "        else: ## Different from protocol as we are considering all predicates\n",
    "            pred_token = [predicate.root.position]\n",
    "            pred = [predicate.root.text]\n",
    "            def_pred_token = predicate.root.position\n",
    "            \n",
    "    #Else keep the root        \n",
    "    else:\n",
    "        pred_token = [predicate.root.position]\n",
    "        pred = [predicate.root.text]\n",
    "        def_pred_token = predicate.root.position \n",
    "\n",
    "    #Stringify pred and pred_tokens:\n",
    "    #pred_token = \"_\".join(map(str, pred_token))\n",
    "\n",
    "    if len(pred)>5:\n",
    "        pred = pred[:5]\n",
    "        pred = \" \".join(pred) + \"...\"\n",
    "    else:\n",
    "        pred = \" \".join(pred)\n",
    "    \n",
    "    return pred, pred_token, def_pred_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_pred_double(pred_comb, raw_sentence, fname, sentid_num, sentid_num_next):\n",
    "    '''\n",
    "    Extract turk_parse dict from input predicate combination \n",
    "    \n",
    "    INputs:\n",
    "    1. pred_all : one list of all predicates in both sentences\n",
    "    2. raw_sentence: a dict of two sentences, with key: sent_id_num\n",
    "    3. sentid_num: 1st sentence in adjacent sentence\n",
    "    4. sentid_num_next: 2nd sentence in adjacent sentence\n",
    "    \n",
    "    '''\n",
    "    token_dict = {}\n",
    "    pred1_obj, pred2_obj = [y for x,y in pred_comb]\n",
    "    sent_id1, sent_id2 = [x for x,y in pred_comb]\n",
    "    \n",
    "    pred1_text, pred1_token, pred1_root_token = predicate_info(pred1_obj)\n",
    "    pred2_text, pred2_token, pred2_root_token = predicate_info(pred2_obj)\n",
    "\n",
    "    token_dict['pred1_token'] = \"_\".join(map(str, pred1_token))\n",
    "    token_dict['pred1_text'] = pred1_text\n",
    "    token_dict['pred2_token'] = \"_\".join(map(str, pred2_token))\n",
    "    token_dict['pred2_text'] = pred2_text\n",
    "    token_dict['sentence_id_1'] = fname + \" \" + sent_id1\n",
    "    token_dict['sentence_id_2'] = fname + \" \" + sent_id2\n",
    "    token_dict['pred1_root_token'] = pred1_root_token\n",
    "    token_dict['pred2_root_token'] = pred2_root_token\n",
    "      \n",
    "    pred_sentence = raw_sentence[sentid_num] + raw_sentence[sentid_num_next]\n",
    "    token_dict['sentence'] = \" \".join(pred_sentence)\n",
    "        \n",
    "    return token_dict, pred1_token, pred2_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dataframe(file_path):\n",
    "    '''\n",
    "    Input: Input document file path which contains conllu format \n",
    "            sentences separated by '\\n'\n",
    "    \n",
    "    Output: A dataframe after processing the file through PredPatt and exracting\n",
    "             roots and spans of each predicate. \n",
    "             Each row in the dataframe corresponds to an event-pair\n",
    "    '''\n",
    "    \n",
    "    with open(file_path) as infile:\n",
    "        data = infile.read()\n",
    "        parsed = [(PredPatt(ud_parse, opts=options), sent_id) for sent_id, ud_parse in load_conllu(data)]\n",
    "        print(\"Number of sentences in the document: {}\".format(len(parsed)))\n",
    "\n",
    "    fname = file_path.split(\"/\")[-1]\n",
    "    \n",
    "    total_preds = 0\n",
    "    global_tuples = []\n",
    "    sent_total=0\n",
    "    struct_dict\n",
    "    \n",
    "    total_sents_doc = len(parsed)\n",
    "    for i, parse_sen in enumerate(parsed):\n",
    "        pred_object = parse_sen[0] \n",
    "        total_preds += len(pred_object.instances)\n",
    "        sentid_num = parse_sen[1].split(\"_\")[-1]\n",
    "        #print(sentid_num)\n",
    "        \n",
    "        ## Concatenate adjacent sentences\n",
    "        if i < total_sents_doc-1:\n",
    "            parse_sen_next = parsed[i+1]\n",
    "            pred_object_next = parse_sen_next[0]\n",
    "            sentid_num_next = parse_sen_next[1].split(\"_\")[-1]\n",
    "\n",
    "            raw_sentence =  {sentid_num : [token.text for token in pred_object.tokens] ,\n",
    "                            sentid_num_next: [token.text for token in pred_object_next.tokens]}\n",
    "\n",
    "            preds_curr = [(sentid_num,pred) for pred in pred_object.instances]\n",
    "            preds_next = [(sentid_num_next,pred) for pred in pred_object_next.instances]\n",
    "\n",
    "            #Curr_sent combinations (all possible)\n",
    "            pred_combs_curr = combinations(preds_curr,2)\n",
    "            for pred_comb in pred_combs_curr:      \n",
    "                #token dict from all predicates in the antecedent sentence:\n",
    "                token_dict, pred_token1, pred_token2 = dict_pred_double(pred_comb, raw_sentence, \n",
    "                                                                              fname, sentid_num, \n",
    "                                                                                sentid_num_next)\n",
    "                global_tuples.append((token_dict, pred_token1, pred_token2))\n",
    "                sent_total+=1\n",
    "\n",
    "            #Combinations of Pivot predicate of curr_sent with predicates of next_sent:\n",
    "            pivot_curr_pred = find_pivot_predicate(fname, sentid_num, pred_object, structures)\n",
    "            print(\"Pivot predicate: {}\".format(pivot_curr_pred))\n",
    "            if pivot_curr_pred:\n",
    "                for tupl in preds_next:\n",
    "                    pred_comb = [pivot_curr_pred, tupl]\n",
    "                    token_dict, pred_token1, pred_token2 = dict_pred_double(pred_comb, raw_sentence, \n",
    "                                                                                  fname, sentid_num, \n",
    "                                                                                    sentid_num_next)\n",
    "                    global_tuples.append((token_dict, pred_token1, pred_token2))\n",
    "                    sent_total+=1\n",
    "       \n",
    "    ## Create a dataframe from the global tuples dictionary\n",
    "    dcts = [dct for dct, pred1_span, pred2_span in global_tuples]\n",
    "    pred1_spans = [pred1_span for dct, pred1_span, pred2_span in global_tuples]\n",
    "    pred2_spans = [pred2_span for dct, pred1_span, pred2_span in global_tuples]\n",
    "                    \n",
    "    df = pd.DataFrame(dcts)\n",
    "    df['pred1_span'] = np.array(pred1_spans)\n",
    "    df['pred2_span'] = np.array(pred2_spans)\n",
    "    \n",
    "    return df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences in the document: 23\n",
      "Pivot predicate: ('1', Predicate(was/13))\n",
      "Pivot predicate: ('2', Predicate(hole/4))\n",
      "Pivot predicate: ('3', Predicate(took/16))\n",
      "Pivot predicate: ('4', Predicate(construct/18))\n",
      "Pivot predicate: ('5', Predicate(accessible/12))\n",
      "Pivot predicate: ('6', Predicate(save/4))\n",
      "Pivot predicate: ('7', Predicate(progressive/6))\n",
      "Pivot predicate: ('8', Predicate(presented/4))\n",
      "Pivot predicate: ('9', Predicate(Swiping/0))\n",
      "Pivot predicate: ('10', Predicate(is/6))\n",
      "Pivot predicate: ('11', Predicate(edit/24))\n",
      "Pivot predicate: ('12', Predicate(frictionless/4))\n",
      "Pivot predicate: ('13', Predicate(said/1))\n",
      "Pivot predicate: ('14', Predicate(limited/3))\n",
      "Pivot predicate: ('15', Predicate(email/7))\n",
      "Pivot predicate: ('16', Predicate(function/5))\n",
      "Pivot predicate: ('17', Predicate(expect/5))\n",
      "Pivot predicate: ('18', Predicate(foresee/4))\n",
      "Pivot predicate: ('19', Predicate(turn/25))\n",
      "Pivot predicate: ('20', Predicate(scare/2))\n",
      "Pivot predicate: ('21', Predicate(are/13))\n",
      "Pivot predicate: ('22', Predicate(refinement/5))\n"
     ]
    }
   ],
   "source": [
    "df = extract_dataframe(\"../input_data/sample_document.txt.output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred1_root_token</th>\n",
       "      <th>pred1_text</th>\n",
       "      <th>pred1_token</th>\n",
       "      <th>pred2_root_token</th>\n",
       "      <th>pred2_text</th>\n",
       "      <th>pred2_token</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_id_1</th>\n",
       "      <th>sentence_id_2</th>\n",
       "      <th>pred1_span</th>\n",
       "      <th>pred2_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Keep</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>launched</td>\n",
       "      <td>8</td>\n",
       "      <td>Before the arrival of Keep , which Google laun...</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Keep</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>was</td>\n",
       "      <td>13</td>\n",
       "      <td>Before the arrival of Keep , which Google laun...</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>launched</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>was</td>\n",
       "      <td>13</td>\n",
       "      <td>Before the arrival of Keep , which Google laun...</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>was</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>was a glaring hole</td>\n",
       "      <td>1_2_3_4</td>\n",
       "      <td>Before the arrival of Keep , which Google laun...</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>sample_document.txt.output 2</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>was</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>considering</td>\n",
       "      <td>6</td>\n",
       "      <td>Before the arrival of Keep , which Google laun...</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>sample_document.txt.output 2</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred1_root_token pred1_text pred1_token  pred2_root_token  \\\n",
       "0                 4       Keep           4                 8   \n",
       "1                 4       Keep           4                13   \n",
       "2                 8   launched           8                13   \n",
       "3                13        was          13                 4   \n",
       "4                13        was          13                 6   \n",
       "\n",
       "           pred2_text pred2_token  \\\n",
       "0            launched           8   \n",
       "1                 was          13   \n",
       "2                 was          13   \n",
       "3  was a glaring hole     1_2_3_4   \n",
       "4         considering           6   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  Before the arrival of Keep , which Google laun...   \n",
       "1  Before the arrival of Keep , which Google laun...   \n",
       "2  Before the arrival of Keep , which Google laun...   \n",
       "3  Before the arrival of Keep , which Google laun...   \n",
       "4  Before the arrival of Keep , which Google laun...   \n",
       "\n",
       "                  sentence_id_1                 sentence_id_2 pred1_span  \\\n",
       "0  sample_document.txt.output 1  sample_document.txt.output 1        [4]   \n",
       "1  sample_document.txt.output 1  sample_document.txt.output 1        [4]   \n",
       "2  sample_document.txt.output 1  sample_document.txt.output 1        [8]   \n",
       "3  sample_document.txt.output 1  sample_document.txt.output 2       [13]   \n",
       "4  sample_document.txt.output 1  sample_document.txt.output 2       [13]   \n",
       "\n",
       "     pred2_span  \n",
       "0           [8]  \n",
       "1          [13]  \n",
       "2          [13]  \n",
       "3  [1, 2, 3, 4]  \n",
       "4           [6]  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_data = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Pred2 token positions in the combined sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_pred2_root(row, struct_dict):\n",
    "    if row.sentence_id_1 == row.sentence_id_2:\n",
    "        return row.pred2_root_token\n",
    "    else:\n",
    "        sent_str, num = row.sentence_id_1.split(\" \")\n",
    "        sent_name = sent_str + \" \" + \"sent_\" + num\n",
    "        \n",
    "        return len(struct_dict[sent_name]) + row.pred2_root_token \n",
    "    \n",
    "def correct_pred2_tokens(row, struct_dict):\n",
    "    if row.sentence_id_1 == row.sentence_id_2:\n",
    "        return row.pred2_token\n",
    "    else:\n",
    "        sent_str, num = row.sentence_id_1.split(\" \")\n",
    "        sent_name = sent_str + \" \" + \"sent_\" + num\n",
    "        \n",
    "        curr_posns = [int(x) for x in row.pred2_token.split(\"_\")]\n",
    "        new_posns = [len(struct_dict[sent_name]) + x for x in curr_posns]\n",
    "        \n",
    "        return \"_\".join([str(x) for x in new_posns])\n",
    "    \n",
    "df['pred2_token_mod'] = df.apply(lambda row: correct_pred2_tokens(row, struct_dict), axis=1)\n",
    "df['pred2_root_token_mod'] = df.apply(lambda row: correct_pred2_root(row, struct_dict), axis=1)\n",
    "\n",
    "#Convert tokens into list of numbers\n",
    "df['pred1_token_span'] = df['pred1_token'].map(lambda x: [int(y) for y in x.split(\"_\")])\n",
    "df['pred2_token_span'] = df['pred2_token_mod'].map(lambda x: [int(y) for y in x.split(\"_\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred1_root_token</th>\n",
       "      <th>pred1_text</th>\n",
       "      <th>pred1_token</th>\n",
       "      <th>pred2_root_token</th>\n",
       "      <th>pred2_text</th>\n",
       "      <th>pred2_token</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_id_1</th>\n",
       "      <th>sentence_id_2</th>\n",
       "      <th>pred1_span</th>\n",
       "      <th>pred2_span</th>\n",
       "      <th>pred2_token_mod</th>\n",
       "      <th>pred2_root_token_mod</th>\n",
       "      <th>pred1_token_span</th>\n",
       "      <th>pred2_token_span</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Keep</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>launched</td>\n",
       "      <td>8</td>\n",
       "      <td>Before the arrival of Keep , which Google laun...</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[8]</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Keep</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>was</td>\n",
       "      <td>13</td>\n",
       "      <td>Before the arrival of Keep , which Google laun...</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[13]</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>[4]</td>\n",
       "      <td>[13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>launched</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>was</td>\n",
       "      <td>13</td>\n",
       "      <td>Before the arrival of Keep , which Google laun...</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[13]</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>[8]</td>\n",
       "      <td>[13]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>was</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>was a glaring hole</td>\n",
       "      <td>1_2_3_4</td>\n",
       "      <td>Before the arrival of Keep , which Google laun...</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>sample_document.txt.output 2</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[1, 2, 3, 4]</td>\n",
       "      <td>22_23_24_25</td>\n",
       "      <td>25</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[22, 23, 24, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>was</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>considering</td>\n",
       "      <td>6</td>\n",
       "      <td>Before the arrival of Keep , which Google laun...</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>sample_document.txt.output 2</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[6]</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>[13]</td>\n",
       "      <td>[27]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred1_root_token pred1_text pred1_token  pred2_root_token  \\\n",
       "0                 4       Keep           4                 8   \n",
       "1                 4       Keep           4                13   \n",
       "2                 8   launched           8                13   \n",
       "3                13        was          13                 4   \n",
       "4                13        was          13                 6   \n",
       "\n",
       "           pred2_text pred2_token  \\\n",
       "0            launched           8   \n",
       "1                 was          13   \n",
       "2                 was          13   \n",
       "3  was a glaring hole     1_2_3_4   \n",
       "4         considering           6   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  Before the arrival of Keep , which Google laun...   \n",
       "1  Before the arrival of Keep , which Google laun...   \n",
       "2  Before the arrival of Keep , which Google laun...   \n",
       "3  Before the arrival of Keep , which Google laun...   \n",
       "4  Before the arrival of Keep , which Google laun...   \n",
       "\n",
       "                  sentence_id_1                 sentence_id_2 pred1_span  \\\n",
       "0  sample_document.txt.output 1  sample_document.txt.output 1        [4]   \n",
       "1  sample_document.txt.output 1  sample_document.txt.output 1        [4]   \n",
       "2  sample_document.txt.output 1  sample_document.txt.output 1        [8]   \n",
       "3  sample_document.txt.output 1  sample_document.txt.output 2       [13]   \n",
       "4  sample_document.txt.output 1  sample_document.txt.output 2       [13]   \n",
       "\n",
       "     pred2_span pred2_token_mod  pred2_root_token_mod pred1_token_span  \\\n",
       "0           [8]               8                     8              [4]   \n",
       "1          [13]              13                    13              [4]   \n",
       "2          [13]              13                    13              [8]   \n",
       "3  [1, 2, 3, 4]     22_23_24_25                    25             [13]   \n",
       "4           [6]              27                    27             [13]   \n",
       "\n",
       "   pred2_token_span  \n",
       "0               [8]  \n",
       "1              [13]  \n",
       "2              [13]  \n",
       "3  [22, 23, 24, 25]  \n",
       "4              [27]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_X(data):\n",
    "    sents = data.sentence.values\n",
    "    structures = [x.split() for x in sents]\n",
    "    root_idxs = data[['pred1_root_token', 'pred2_root_token_mod']].values\n",
    "    span_idxs = data[['pred1_token_span', 'pred2_token_span']].values\n",
    "\n",
    "    X_data = list(zip(structures, span_idxs, root_idxs))\n",
    "    print(\"Data size: {}\".format(len(X_data)))\n",
    "    \n",
    "    return X_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data size: 139\n"
     ]
    }
   ],
   "source": [
    "X = extract_X(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract X data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['Before', 'the', 'arrival', 'of', 'Keep', ',', 'which', 'Google', 'launched', 'this', 'week', ',', 'there', 'was', 'no', 'default', 'note-taking', 'app', 'for', 'Android', '.', 'It', 'was', 'a', 'glaring', 'hole', ',', 'considering', 'that', 'Apple', \"'s\", 'iPhone', 'has', 'built-in', 'Notes', 'and', 'Reminders', 'apps', 'that', 'can', 'be', 'powered', 'by', 'Siri', '.'], array([list([13]), list([22, 23, 24, 25])], dtype=object), array([13, 25]))\n"
     ]
    }
   ],
   "source": [
    "print(X[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "squashed = True\n",
    "baseline=False\n",
    "loss_confidence = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_device_num = 1\n",
    "cuda_device_str = \"cuda:1\"\n",
    "\n",
    "model_path = \"../model/\"\n",
    "def str2bool(v):\n",
    "    return v.lower() in (\"yes\", \"true\", \"t\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eventatt: param, Duratt: param, Relatt: param, Dropout: 0.5, Activation: relu, Binomial: True, concat_fine2dur: False, concat_dur2fine:False, fine_to_dur: False, dur_to_fine: False \n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ElmoEmbedder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4b1454b2f7c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                             \u001b[0membedding_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                             \u001b[0mduration_distr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbino_bool\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                             \u001b[0melmo_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElmoEmbedder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcuda_device_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                             \u001b[0mmlp_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                             \u001b[0mmlp_activation\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mactiv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ElmoEmbedder' is not defined"
     ]
    }
   ],
   "source": [
    "file_path = \"model_param_param_param_1_0_128_128_0_0_0_0_0.0_0.5_relu_1.pth\"\n",
    "\n",
    "tokens = file_path.split(\"_\")\n",
    "eventatt = tokens[1]\n",
    "duratt = tokens[2]\n",
    "relatt = tokens[3]\n",
    "concat_fine_to_dur = str2bool(tokens[-8])\n",
    "concat_dur_to_fine = str2bool(tokens[-7])\n",
    "fine_2_dur = str2bool(tokens[-6])\n",
    "dur_2_fine = str2bool(tokens[-5])\n",
    "weight = float(tokens[-4])\n",
    "drop = float(tokens[-3])\n",
    "activ = tokens[-2]\n",
    "bino_bool = str2bool(tokens[-1].split(\".\")[0])\n",
    "#coarse_size = int(tokens[-1].split(\".\")[0])\n",
    "\n",
    "print(\"Eventatt: {}, Duratt: {}, Relatt: {}, Dropout: {}, Activation: {}, Binomial: {}, concat_fine2dur: {}, concat_dur2fine:{}, fine_to_dur: {}, dur_to_fine: {} \\n\".format(\n",
    "                                                                                                                        eventatt,\n",
    "                                                                                                                        duratt,\n",
    "                                                                                                                        relatt,\n",
    "                                                                                                                        drop,\n",
    "                                                                                                                        activ,\n",
    "                                                                                                                        bino_bool,\n",
    "                                                                                                                        concat_fine_to_dur,\n",
    "                                                                                                                        concat_dur_to_fine,\n",
    "                                                                                                                        fine_2_dur,\n",
    "                                                                                                       dur_2_fine))\n",
    "device = torch.device(cuda_device_str if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "best_model = TemporalModel(\n",
    "                            embedding_size=1024, \n",
    "                            duration_distr = bino_bool,\n",
    "                            elmo_class = ElmoEmbedder(options_file, weight_file, cuda_device=cuda_device_num),\n",
    "                            mlp_dropout = drop,\n",
    "                            mlp_activation= activ,\n",
    "                            tune_embed_size=256,\n",
    "                            event_attention=eventatt, \n",
    "                            dur_attention = duratt, \n",
    "                            rel_attention = relatt, \n",
    "                            concat_fine_to_dur  =concat_fine_to_dur,                      \n",
    "                            concat_dur_to_fine = concat_dur_to_fine,\n",
    "                            fine_to_dur = fine_2_dur,\n",
    "                            dur_to_fine = dur_2_fine,\n",
    "                            fine_squash = True,\n",
    "                            baseline=False,\n",
    "                            dur_MLP_sizes = [128], fine_MLP_sizes = [128],\n",
    "                            dur_output_size = 11, fine_output_size = 4,\n",
    "                            device= device)\n",
    "\n",
    "best_model.load_state_dict(torch.load(model_path + file_path))\n",
    "best_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fine_dur_only(data_x, model, predict_batch_size = 80):\n",
    "    '''\n",
    "    Predict duration and coarse-grained relations\n",
    "    '''\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():  \n",
    "        bidx_i = 0\n",
    "        bidx_j = predict_batch_size\n",
    "        total_obs = len(data_x)\n",
    "        p1_dur_yhat = torch.zeros(total_obs, 11).to(model.device)\n",
    "        p2_dur_yhat = torch.zeros(total_obs, 11).to(model.device)\n",
    "        # coarse_yhat = torch.zeros(total_obs, 13).to(model.device)\n",
    "        # coarser_yhat = torch.zeros(total_obs, 7).to(model.device)\n",
    "        fine_yhat = torch.zeros(total_obs, 4).to(model.device)\n",
    "        rel_yhat = torch.zeros(total_obs, 1280).to(model.device)\n",
    "\n",
    "        while bidx_j < total_obs:\n",
    "            words = [p for p,q,r in data_x[bidx_i:bidx_j]]\n",
    "            spans = [q for p,q,r in data_x[bidx_i:bidx_j]]\n",
    "            roots = [r for p,q,r in data_x[bidx_i:bidx_j]]\n",
    "            predicts = model(words,spans, roots) \n",
    "            # print(predicts[0].size())\n",
    "            # print(p1_dur_yhat[bidx_i:bidx_j].size())\n",
    "            # print(\"\\n\")\n",
    "            p1_dur_yhat[bidx_i:bidx_j] = predicts[0]\n",
    "            p2_dur_yhat[bidx_i:bidx_j] = predicts[1]\n",
    "            # coarse_yhat[bidx_i:bidx_j] = predicts[3]\n",
    "            # coarser_yhat[bidx_i:bidx_j] = predicts[4]\n",
    "            fine_yhat[bidx_i:bidx_j] = predicts[2]\n",
    "            rel_yhat[bidx_i:bidx_j] = predicts[3]\n",
    "            \n",
    "            bidx_i = bidx_j\n",
    "            bidx_j = bidx_i + predict_batch_size\n",
    "\n",
    "            if bidx_j >= total_obs:\n",
    "                words = [p for p,q,r in data_x[bidx_i:bidx_j]]\n",
    "                spans = [q for p,q,r in data_x[bidx_i:bidx_j]]\n",
    "                roots = [r for p,q,r in data_x[bidx_i:bidx_j]]\n",
    "                predicts = model(words,spans, roots) \n",
    "                p1_dur_yhat[bidx_i:bidx_j] = predicts[0]\n",
    "                p2_dur_yhat[bidx_i:bidx_j] = predicts[1]\n",
    "                # coarse_yhat[bidx_i:bidx_j] = predicts[3]\n",
    "                # coarser_yhat[bidx_i:bidx_j] = predicts[4]\n",
    "                fine_yhat[bidx_i:bidx_j] = predicts[2]\n",
    "                rel_yhat[bidx_i:bidx_j] = predicts[3]\n",
    "\n",
    "        p1_dur_yhat = F.softmax(p1_dur_yhat, dim=1)\n",
    "        p2_dur_yhat = F.softmax(p2_dur_yhat, dim=1)\n",
    "        # coarse_yhat = F.softmax(coarse_yhat, dim=1)\n",
    "        # coarser_yhat = F.softmax(coarser_yhat, dim=1)\n",
    "\n",
    "        _ , p1_dur_yhat =  p1_dur_yhat.max(1)\n",
    "        _ , p2_dur_yhat =  p2_dur_yhat.max(1)\n",
    "        # _ , coarse_yhat =  coarse_yhat.max(1)\n",
    "        # _ , coarser_yhat =  coarser_yhat.max(1)\n",
    "\n",
    "    return p1_dur_yhat.detach(), p2_dur_yhat.detach(), fine_yhat.detach(), rel_yhat.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidvash/anaconda3/envs/allennlp/lib/python3.6/site-packages/allennlp/nn/util.py:149: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  index_range = sequence_lengths.new_tensor(torch.arange(0, len(sequence_lengths)))\n"
     ]
    }
   ],
   "source": [
    "p1_dur_yhat,p2_dur_yhat,fine_yhat,rel_yhat = predict_fine_dur_only(X, best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a prediction dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred1_duration'] = p1_dur_yhat.cpu().numpy()\n",
    "df['pred2_duration'] = p2_dur_yhat.cpu().numpy()\n",
    "df['b1'] = [b1 for b1,d1,b2,d2 in fine_yhat.cpu().numpy()]\n",
    "df['d1'] = [d1 for b1,d1,b2,d2 in fine_yhat.cpu().numpy()]\n",
    "df['e1'] = df['b1'] + df['d1']\n",
    "\n",
    "df['b2'] = [b2 for b1,d1,b2,d2 in fine_yhat.cpu().numpy()]\n",
    "df['d2'] = [d2 for b1,d1,b2,d2 in fine_yhat.cpu().numpy()]\n",
    "df['e2'] = df['b2'] + df['d2']\n",
    "\n",
    "df = df.drop(['d1', 'd2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sent_pred_id1'] = df['sentence_id_1'] + \" \" + df['pred1_root_token'].map(lambda x: str(x))\n",
    "df['sent_pred_id2'] = df['sentence_id_2'] + \" \" + df['pred2_root_token'].map(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred1_root_token</th>\n",
       "      <th>pred1_text</th>\n",
       "      <th>pred1_token</th>\n",
       "      <th>pred2_root_token</th>\n",
       "      <th>pred2_text</th>\n",
       "      <th>pred2_token</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentence_id_1</th>\n",
       "      <th>sentence_id_2</th>\n",
       "      <th>pred1_span</th>\n",
       "      <th>...</th>\n",
       "      <th>beg1</th>\n",
       "      <th>dur1</th>\n",
       "      <th>beg2</th>\n",
       "      <th>dur2</th>\n",
       "      <th>sent_pred_id1</th>\n",
       "      <th>sent_pred_id2</th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>e1</th>\n",
       "      <th>e2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Keep</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>launched</td>\n",
       "      <td>8</td>\n",
       "      <td>Before the arrival of Keep , which Google laun...</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.138038</td>\n",
       "      <td>0.835664</td>\n",
       "      <td>sample_document.txt.output 1 4</td>\n",
       "      <td>sample_document.txt.output 1 8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138038</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.973703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Keep</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>was</td>\n",
       "      <td>13</td>\n",
       "      <td>Before the arrival of Keep , which Google laun...</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772453</td>\n",
       "      <td>0.051323</td>\n",
       "      <td>0.948677</td>\n",
       "      <td>sample_document.txt.output 1 4</td>\n",
       "      <td>sample_document.txt.output 1 13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051323</td>\n",
       "      <td>0.772453</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>launched</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>was</td>\n",
       "      <td>13</td>\n",
       "      <td>Before the arrival of Keep , which Google laun...</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>[8]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683801</td>\n",
       "      <td>0.350981</td>\n",
       "      <td>0.649019</td>\n",
       "      <td>sample_document.txt.output 1 8</td>\n",
       "      <td>sample_document.txt.output 1 13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350981</td>\n",
       "      <td>0.683801</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>was</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>was a glaring hole</td>\n",
       "      <td>1_2_3_4</td>\n",
       "      <td>Before the arrival of Keep , which Google laun...</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>sample_document.txt.output 2</td>\n",
       "      <td>[13]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713067</td>\n",
       "      <td>0.182615</td>\n",
       "      <td>0.817385</td>\n",
       "      <td>sample_document.txt.output 1 13</td>\n",
       "      <td>sample_document.txt.output 2 4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182615</td>\n",
       "      <td>0.713067</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>was</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>considering</td>\n",
       "      <td>6</td>\n",
       "      <td>Before the arrival of Keep , which Google laun...</td>\n",
       "      <td>sample_document.txt.output 1</td>\n",
       "      <td>sample_document.txt.output 2</td>\n",
       "      <td>[13]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772952</td>\n",
       "      <td>0.370259</td>\n",
       "      <td>0.629741</td>\n",
       "      <td>sample_document.txt.output 1 13</td>\n",
       "      <td>sample_document.txt.output 2 6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370259</td>\n",
       "      <td>0.772952</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred1_root_token pred1_text pred1_token  pred2_root_token  \\\n",
       "0                 4       Keep           4                 8   \n",
       "1                 4       Keep           4                13   \n",
       "2                 8   launched           8                13   \n",
       "3                13        was          13                 4   \n",
       "4                13        was          13                 6   \n",
       "\n",
       "           pred2_text pred2_token  \\\n",
       "0            launched           8   \n",
       "1                 was          13   \n",
       "2                 was          13   \n",
       "3  was a glaring hole     1_2_3_4   \n",
       "4         considering           6   \n",
       "\n",
       "                                            sentence  \\\n",
       "0  Before the arrival of Keep , which Google laun...   \n",
       "1  Before the arrival of Keep , which Google laun...   \n",
       "2  Before the arrival of Keep , which Google laun...   \n",
       "3  Before the arrival of Keep , which Google laun...   \n",
       "4  Before the arrival of Keep , which Google laun...   \n",
       "\n",
       "                  sentence_id_1                 sentence_id_2 pred1_span  \\\n",
       "0  sample_document.txt.output 1  sample_document.txt.output 1        [4]   \n",
       "1  sample_document.txt.output 1  sample_document.txt.output 1        [4]   \n",
       "2  sample_document.txt.output 1  sample_document.txt.output 1        [8]   \n",
       "3  sample_document.txt.output 1  sample_document.txt.output 2       [13]   \n",
       "4  sample_document.txt.output 1  sample_document.txt.output 2       [13]   \n",
       "\n",
       "     ...    beg1      dur1      beg2      dur2  \\\n",
       "0    ...     0.0  1.000000  0.138038  0.835664   \n",
       "1    ...     0.0  0.772453  0.051323  0.948677   \n",
       "2    ...     0.0  0.683801  0.350981  0.649019   \n",
       "3    ...     0.0  0.713067  0.182615  0.817385   \n",
       "4    ...     0.0  0.772952  0.370259  0.629741   \n",
       "\n",
       "                     sent_pred_id1                    sent_pred_id2   b1  \\\n",
       "0   sample_document.txt.output 1 4   sample_document.txt.output 1 8  0.0   \n",
       "1   sample_document.txt.output 1 4  sample_document.txt.output 1 13  0.0   \n",
       "2   sample_document.txt.output 1 8  sample_document.txt.output 1 13  0.0   \n",
       "3  sample_document.txt.output 1 13   sample_document.txt.output 2 4  0.0   \n",
       "4  sample_document.txt.output 1 13   sample_document.txt.output 2 6  0.0   \n",
       "\n",
       "         b2        e1        e2  \n",
       "0  0.138038  1.000000  0.973703  \n",
       "1  0.051323  0.772453  1.000000  \n",
       "2  0.350981  0.683801  1.000000  \n",
       "3  0.182615  0.713067  1.000000  \n",
       "4  0.370259  0.772952  1.000000  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimelineModel(torch.nn.Module):\n",
    "    '''\n",
    "     A class to extract a simple timeline model from a\n",
    "     given document's predicate-pair data\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 data = None,\n",
    "                 num_preds = None, \n",
    "                 mlp_activation='relu',\n",
    "                 mlp_dropout=0.0,\n",
    "                 optimizer_class = torch.optim.Adam,\n",
    "                  dur_output_size = 11, fine_output_size = 4,\n",
    "                device=device,\n",
    "                **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.linear_maps = nn.ModuleDict()\n",
    "        self.mlp_activation = mlp_activation\n",
    "        self.mlp_dropout =  nn.Dropout(mlp_dropout) \n",
    "        self.dur_output_size = dur_output_size\n",
    "        \n",
    "        ## Parameters\n",
    "            # Hidden predicate representations\n",
    "        self.pred_tensor = torch.nn.Parameter(torch.randn(num_preds,2), requires_grad=True)\n",
    "            # Binomial parameter\n",
    "        self.k = torch.nn.Parameter(torch.randn(1), requires_grad=True)\n",
    "        \n",
    "        self.params = nn.ParameterList()\n",
    "        self.params.extend([self.pred_tensor, self.k])\n",
    "        \n",
    "        self._optimizer_class = optimizer_class\n",
    "        \n",
    "        ## Losses Initialization\n",
    "        self.fine_loss = L1Loss().to(self.device)\n",
    "        self.duration_loss = CrossEntropyLoss().to(self.device)\n",
    "\n",
    "        \n",
    "    def _init_MLP(self, input_size, hidden_sizes, output_size, param=None):\n",
    "        '''\n",
    "        Initialise MLP or regression parameters\n",
    "        '''\n",
    "        self.linear_maps[param] = nn.ModuleList()\n",
    "\n",
    "        for h in hidden_sizes:\n",
    "            linmap = torch.nn.Linear(input_size, h)\n",
    "            linmap = linmap.to(self.device)\n",
    "            self.linear_maps[param].append(linmap)\n",
    "            input_size = h\n",
    "\n",
    "        linmap = torch.nn.Linear(input_size, output_size)\n",
    "        linmap = linmap.to(self.device)\n",
    "        self.linear_maps[param].append(linmap)\n",
    "        \n",
    "    def forward(self, local_data, **kwargs):\n",
    "        '''\n",
    "        INput: dataframe with cols:\n",
    "                b1, e1, b2, e2, pred1_dict_idx, pred2_dict_idx\n",
    "                \n",
    "        Output: \n",
    "        '''\n",
    "        t_sq = self.pred_tensor**2 \n",
    "        num_preds= t_sq.size()[0]\n",
    "        anchored_tensor = torch.zeros(num_preds,2).to(self.device)\n",
    "        \n",
    "        anchored_tensor[:,0] = t_sq[:,0] - t_sq[:,0].min()\n",
    "        anchored_tensor[:,1] = t_sq[:,1]\n",
    "        \n",
    "        #Predicted fine-grained values for the given document\n",
    "        b1 = anchored_tensor[local_data.pred1_dict_idx.values][:,0]\n",
    "        dur1 = anchored_tensor[local_data.pred1_dict_idx.values][:,1]\n",
    "        b2 = anchored_tensor[local_data.pred2_dict_idx.values][:,0]\n",
    "        dur2 = anchored_tensor[local_data.pred2_dict_idx.values][:,1]\n",
    "        \n",
    "        batch_size = b1.size()[0]\n",
    "        #print(batch_size)\n",
    "                \n",
    "        pred1_dur = self._binomial_dist(dur1)\n",
    "        pred2_dur = self._binomial_dist(dur2)\n",
    "        \n",
    "        yhat = (b1, dur1, b2, dur2, pred1_dur, pred2_dur,\n",
    "                anchored_tensor)\n",
    "        \n",
    "        return yhat\n",
    "    \n",
    "    def fit(self, local_data, epochs=5000, **kwargs):\n",
    "        losses = [10000]\n",
    "        \n",
    "        print(\"#### Model Parameters ####\")\n",
    "        for name,param in self.named_parameters():     \n",
    "            if param.requires_grad:\n",
    "                print(name, param.shape) \n",
    "        print(\"##########################\") \n",
    "        parameters = [p for p in self.parameters() if p.requires_grad]\n",
    "        optimizer = self._optimizer_class(parameters)\n",
    "        \n",
    "        #Actual ground truth values\n",
    "        b1_lst = local_data.b1.values\n",
    "        e1_lst = local_data.e1.values\n",
    "        b2_lst = local_data.b2.values\n",
    "        e2_lst = local_data.e2.values\n",
    "        durations = [local_data.pred1_duration.values,\n",
    "                     local_data.pred2_duration.values]\n",
    "\n",
    "        \n",
    "        #pbar = tqdm_n(total = total_obs//self.train_batch_size)\n",
    "        \n",
    "        for epoch in tqdm_n(range(epochs)):\n",
    "            preds = self(local_data)\n",
    "            #zero_grad\n",
    "            optimizer.zero_grad()\n",
    "            curr_loss = self._custom_loss(preds,\n",
    "                                         b1_lst,\n",
    "                                         e1_lst,\n",
    "                                         b2_lst,\n",
    "                                         e2_lst,\n",
    "                                         durations)\n",
    "            \n",
    "            curr_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if epoch==0:\n",
    "                print(\"Epoch: {}, Loss: {}\".format(epoch+1, curr_loss))\n",
    "            \n",
    "            #print(\"Epoch: {}, Loss: {}\".format(epoch+1, curr_loss))\n",
    "               \n",
    "            ## Stop training when loss converges\n",
    "            if abs(curr_loss.detach() - losses[-1]) < 0.00001:\n",
    "                #print(\"Epoch: {}, Converging-Loss: {}\".format(epoch+1, curr_loss))\n",
    "                break\n",
    "                \n",
    "            #pbar.update(1)\n",
    "                \n",
    "            losses.append(curr_loss.detach())\n",
    "        #pbar.close()\n",
    "        print(\"Epoch: {}, Converging-Loss: {}\".format(epoch+1, curr_loss))\n",
    "                \n",
    "        return self.predict(preds)\n",
    "        \n",
    "    def _custom_loss(self, preds, b1_lst, e1_lst, b2_lst,\n",
    "                            e2_lst,durations):\n",
    "        ## Predictions\n",
    "        b1_pred, dur1_pred, b2_pred, dur2_pred = preds[0], preds[1], preds[2], preds[3]\n",
    "        out_p1_d, out_p2_d, anchored_tensor = preds[4], preds[5], preds[6]\n",
    "#         out_coarse, out_coarser = preds[7], preds[8]\n",
    "        \n",
    "        ## Ground truth values:\n",
    "        b1_act, e1_act, b2_act, e2_act = self._lsts_to_tensors(b1_lst, e1_lst, b2_lst, e2_lst,\n",
    "                                        param=\"float\")\n",
    "        ## Store actual_y into tensors\n",
    "        pred1_durs, pred2_durs = durations\n",
    "\n",
    "        pred1_durs, pred2_durs = self._lsts_to_tensors(pred1_durs,pred2_durs)\n",
    "        \n",
    "        ## Duration Losses\n",
    "        L5_p1 = self.duration_loss(out_p1_d, pred1_durs)\n",
    "        L5_p2 = self.duration_loss(out_p2_d, pred2_durs)\n",
    "        #print(\"L5_p1 {},  L5_p2: {}\".format(L5_p1, L5_p2))\n",
    "        \n",
    "        ## Coarse Loss\n",
    "        #L7 = self.coarse_loss(out_coarse, time_ml_coarse)\n",
    "        #print(\"L7: {}\".format(L7))\n",
    "        \n",
    "        ## Coarser Loss\n",
    "        #L8 = self.coarser_loss(out_coarser, time_ml_coarser)\n",
    "        #print(\"L8: {}\".format(L8))\n",
    "        \n",
    "        ## Normalize predicted fine-grained values:\n",
    "        num_pairs = b1_pred.size()[0]\n",
    "        t = torch.zeros(num_pairs,4).to(self.device)\n",
    "        t[:,0] = b1_pred\n",
    "        t[:,1] = b1_pred + dur1_pred\n",
    "        t[:,2] = b2_pred\n",
    "        t[:,3] = b2_pred + dur2_pred\n",
    "        \n",
    "    \n",
    "        t_min, _ = torch.min(t,dim=1)\n",
    "        t_min = t_min.unsqueeze(1).repeat(1,4)  #add extra dimension\n",
    "        t_adj = t - t_min\n",
    "        t_adj_max, _ = torch.max(t_adj,dim=1)\n",
    "        t_adj_max = t_adj_max.unsqueeze(1).repeat(1,4)\n",
    "        t_normalized = t_adj/t_adj_max\n",
    "        \n",
    "        ## Fine-grained Losses\n",
    "        l1 = self.fine_loss(t_normalized[:,0]-t_normalized[:,2], b1_act-b2_act)\n",
    "        l2 = self.fine_loss(t_normalized[:,1]-t_normalized[:,2], e1_act-b2_act)\n",
    "        l3 = self.fine_loss(t_normalized[:,3]-t_normalized[:,0], e2_act-b1_act)\n",
    "        l4 = self.fine_loss(t_normalized[:,1]-t_normalized[:,3], e1_act-e2_act)\n",
    "        \n",
    "        L1to4 = sum([l1, l2, l3, l4])/4 \n",
    "           \n",
    "        #L5_p1, L5_p2 = 0,0 \n",
    "        \n",
    "        #print(\"L1to4: {}\".format(L1to4))\n",
    "        \n",
    "        dur = (L5_p1+L5_p2)/2\n",
    "        fine = L1to4\n",
    "        beta=2.0\n",
    "        \n",
    "        total_loss = (sum([dur, beta*fine])/2)\n",
    "        \n",
    "        return total_loss\n",
    "            \n",
    "    def _lsts_to_tensors(self, *args, param=None):\n",
    "        '''\n",
    "        Input: list1, list2,......\n",
    "\n",
    "        Output: [Tensor(list1), tensor(list2),....]\n",
    "\n",
    "        '''\n",
    "        if param==\"float\":\n",
    "            return [torch.from_numpy(np.array(arg)).float().to(self.device) for arg in args]\n",
    "        else:\n",
    "            return [torch.from_numpy(np.array(arg, dtype=\"int64\")).to(self.device) for arg in args]\n",
    "        \n",
    "    def predict(self, preds):\n",
    "        b1_pred, dur1_pred, b2_pred, dur2_pred = preds[0], preds[1], preds[2], preds[3]\n",
    "        pred_timeline =  preds[6]\n",
    "        \n",
    "        ## Normalize predicted values:\n",
    "        num_pairs = b1_pred.size()[0]\n",
    "        t = torch.zeros(num_pairs,4).to(self.device)\n",
    "        t[:,0] = b1_pred\n",
    "        t[:,1] = b1_pred + dur1_pred\n",
    "        t[:,2] = b2_pred\n",
    "        t[:,3] = b2_pred + dur2_pred\n",
    "        \n",
    "        t_min, _ = torch.min(t,dim=1)\n",
    "        t_min = t_min.unsqueeze(1).repeat(1,4)  #add extra dimension\n",
    "        t_adj = t - t_min\n",
    "        t_adj_max, _ = torch.max(t_adj,dim=1)\n",
    "        t_adj_max = t_adj_max.unsqueeze(1).repeat(1,4)\n",
    "        t_normalized = t_adj/t_adj_max\n",
    "        t_normalized = t_normalized.detach().cpu().numpy()\n",
    "        \n",
    "        return t_normalized[:,0],t_normalized[:,1], t_normalized[:,2], t_normalized[:,3], pred_timeline.detach().cpu().numpy()\n",
    "    \n",
    "    def _binomial_dist(self, pred_dur):\n",
    "        '''\n",
    "        *** Vectorized implementation ***\n",
    "        Input: A tensor with dimension: batch_size x 1\n",
    "        Output: A tensor with dimension: batch_size x 11 \n",
    "        Binomial Prob distribution for a given duration value \n",
    "        '''\n",
    "        pred_dur = torch.sigmoid((self.k)*(torch.log(pred_dur)))\n",
    "    \n",
    "        bin_class = Binomial(total_count=self.dur_output_size-1, probs=pred_dur)\n",
    "        durations = torch.tensor(range(self.dur_output_size), dtype=torch.float).to(self.device)\n",
    "        \n",
    "        return self._log_prob_vectorized(bin_class, durations)\n",
    "        \n",
    "    def _log_prob_vectorized(self, bin_class, value):\n",
    "        '''\n",
    "        1. bin_class: Pytorch Binomial distribution class \n",
    "        2. Value is a tensor with size: [total_count+1]\n",
    "        '''\n",
    "        batch_size = bin_class.total_count.size()[0]\n",
    "\n",
    "        value = value.repeat(batch_size,1)\n",
    "        #print(value.size())\n",
    "\n",
    "        bin_class.logits = bin_class.logits.repeat(11,1).permute(1,0)\n",
    "        #print(bin_class.logits.size())\n",
    "\n",
    "        bin_class.total_count = bin_class.total_count.repeat(11,1).permute(1,0)\n",
    "        #print(bin_class.total_count.size())\n",
    "\n",
    "        log_factorial_n = torch.lgamma(bin_class.total_count + 1)\n",
    "        log_factorial_k = torch.lgamma(value + 1)\n",
    "        log_factorial_nmk = torch.lgamma(bin_class.total_count - value + 1)\n",
    "        max_val = (-bin_class.logits).clamp(min=0.0)\n",
    "        # Note that: torch.log1p(-bin_class.probs)) = max_val - torch.log1p((bin_class.logits + 2 * max_val).exp()))\n",
    "\n",
    "        return (log_factorial_n - log_factorial_k - log_factorial_nmk +\n",
    "                value * bin_class.logits + bin_class.total_count * max_val -\n",
    "                bin_class.total_count * torch.log1p((bin_class.logits + 2 * max_val).exp()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_preds(data):\n",
    "    '''\n",
    "    Extracts a dict of predicates for a given docid data\n",
    "    Key: pred_sent_id\n",
    "    Value: predicate-index\n",
    "    '''\n",
    "    cols = ['sent_pred_id1', 'sent_pred_id2', 'b1', 'e1', 'b2', 'e2', \n",
    "            'pred1_duration', 'pred2_duration', \n",
    "            'pred1_text', 'pred2_text']\n",
    "    \n",
    "    local_data = data[cols]\n",
    "    preds_arr = local_data[['sent_pred_id1', 'sent_pred_id2']].values\n",
    "    uniq_preds = np.unique(preds_arr.flatten())\n",
    "    \n",
    "    pred_dict = {}\n",
    "    idx=0\n",
    "    for pred in uniq_preds:\n",
    "        pred_dict[pred]=idx\n",
    "        idx+=1\n",
    "        \n",
    "    local_data['pred1_dict_idx'] = local_data['sent_pred_id1'].map(lambda x: pred_dict[x])\n",
    "    local_data['pred2_dict_idx'] = local_data['sent_pred_id2'].map(lambda x: pred_dict[x])\n",
    "        \n",
    "    return pred_dict, idx, local_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sidvash/anaconda3/envs/allennlp/lib/python3.6/site-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/sidvash/anaconda3/envs/allennlp/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "pred_dict, num_preds, local_data = extract_preds(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_pred_id1</th>\n",
       "      <th>sent_pred_id2</th>\n",
       "      <th>b1</th>\n",
       "      <th>e1</th>\n",
       "      <th>b2</th>\n",
       "      <th>e2</th>\n",
       "      <th>pred1_duration</th>\n",
       "      <th>pred2_duration</th>\n",
       "      <th>pred1_text</th>\n",
       "      <th>pred2_text</th>\n",
       "      <th>pred1_dict_idx</th>\n",
       "      <th>pred2_dict_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_document.txt.output 1 4</td>\n",
       "      <td>sample_document.txt.output 1 8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.138038</td>\n",
       "      <td>0.973703</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Keep</td>\n",
       "      <td>launched</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_document.txt.output 1 4</td>\n",
       "      <td>sample_document.txt.output 1 13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772453</td>\n",
       "      <td>0.051323</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Keep</td>\n",
       "      <td>was</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_document.txt.output 1 8</td>\n",
       "      <td>sample_document.txt.output 1 13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683801</td>\n",
       "      <td>0.350981</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>launched</td>\n",
       "      <td>was</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_document.txt.output 1 13</td>\n",
       "      <td>sample_document.txt.output 2 4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713067</td>\n",
       "      <td>0.182615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>was</td>\n",
       "      <td>was a glaring hole</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_document.txt.output 1 13</td>\n",
       "      <td>sample_document.txt.output 2 6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.772952</td>\n",
       "      <td>0.370259</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>was</td>\n",
       "      <td>considering</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sample_document.txt.output 1 13</td>\n",
       "      <td>sample_document.txt.output 2 11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.700707</td>\n",
       "      <td>0.054357</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>was</td>\n",
       "      <td>has</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sample_document.txt.output 1 13</td>\n",
       "      <td>sample_document.txt.output 2 20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.721205</td>\n",
       "      <td>0.134588</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>was</td>\n",
       "      <td>powered</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sample_document.txt.output 2 4</td>\n",
       "      <td>sample_document.txt.output 2 6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.929649</td>\n",
       "      <td>0.360196</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>was a glaring hole</td>\n",
       "      <td>considering</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sample_document.txt.output 2 4</td>\n",
       "      <td>sample_document.txt.output 2 11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.792010</td>\n",
       "      <td>0.049051</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>was a glaring hole</td>\n",
       "      <td>has</td>\n",
       "      <td>37</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sample_document.txt.output 2 4</td>\n",
       "      <td>sample_document.txt.output 2 20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.859625</td>\n",
       "      <td>0.156823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>was a glaring hole</td>\n",
       "      <td>powered</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sample_document.txt.output 2 6</td>\n",
       "      <td>sample_document.txt.output 2 11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683936</td>\n",
       "      <td>0.056403</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>considering</td>\n",
       "      <td>has</td>\n",
       "      <td>38</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sample_document.txt.output 2 6</td>\n",
       "      <td>sample_document.txt.output 2 20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683903</td>\n",
       "      <td>0.176831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>considering</td>\n",
       "      <td>powered</td>\n",
       "      <td>38</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sample_document.txt.output 2 11</td>\n",
       "      <td>sample_document.txt.output 2 20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.950263</td>\n",
       "      <td>0.214235</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>has</td>\n",
       "      <td>powered</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sample_document.txt.output 2 4</td>\n",
       "      <td>sample_document.txt.output 3 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.957735</td>\n",
       "      <td>0.501102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>was a glaring hole</td>\n",
       "      <td>settling</td>\n",
       "      <td>37</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sample_document.txt.output 2 4</td>\n",
       "      <td>sample_document.txt.output 3 9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.855897</td>\n",
       "      <td>0.438598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>was a glaring hole</td>\n",
       "      <td>fill</td>\n",
       "      <td>37</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sample_document.txt.output 2 4</td>\n",
       "      <td>sample_document.txt.output 3 16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.877559</td>\n",
       "      <td>0.517376</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>was a glaring hole</td>\n",
       "      <td>took</td>\n",
       "      <td>37</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sample_document.txt.output 3 2</td>\n",
       "      <td>sample_document.txt.output 3 9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684059</td>\n",
       "      <td>0.511311</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>settling</td>\n",
       "      <td>fill</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sample_document.txt.output 3 2</td>\n",
       "      <td>sample_document.txt.output 3 16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684026</td>\n",
       "      <td>0.581059</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>settling</td>\n",
       "      <td>took</td>\n",
       "      <td>46</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sample_document.txt.output 3 9</td>\n",
       "      <td>sample_document.txt.output 3 16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.685237</td>\n",
       "      <td>0.499833</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>fill</td>\n",
       "      <td>took</td>\n",
       "      <td>47</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sample_document.txt.output 3 16</td>\n",
       "      <td>sample_document.txt.output 4 6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683977</td>\n",
       "      <td>0.403055</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>took</td>\n",
       "      <td>is n't simply just a...</td>\n",
       "      <td>45</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sample_document.txt.output 3 16</td>\n",
       "      <td>sample_document.txt.output 4 18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684035</td>\n",
       "      <td>0.416919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>took</td>\n",
       "      <td>construct</td>\n",
       "      <td>45</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sample_document.txt.output 3 16</td>\n",
       "      <td>sample_document.txt.output 4 27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684504</td>\n",
       "      <td>0.576316</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>took</td>\n",
       "      <td>code</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sample_document.txt.output 3 16</td>\n",
       "      <td>sample_document.txt.output 4 34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683937</td>\n",
       "      <td>0.183423</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>took</td>\n",
       "      <td>well-designed</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sample_document.txt.output 3 16</td>\n",
       "      <td>sample_document.txt.output 4 37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684063</td>\n",
       "      <td>0.461289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>took</td>\n",
       "      <td>interface</td>\n",
       "      <td>45</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sample_document.txt.output 4 6</td>\n",
       "      <td>sample_document.txt.output 4 18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.932618</td>\n",
       "      <td>0.292017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>is n't simply just a...</td>\n",
       "      <td>construct</td>\n",
       "      <td>52</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>sample_document.txt.output 4 6</td>\n",
       "      <td>sample_document.txt.output 4 27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.886415</td>\n",
       "      <td>0.471430</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>is n't simply just a...</td>\n",
       "      <td>code</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sample_document.txt.output 4 6</td>\n",
       "      <td>sample_document.txt.output 4 34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.849277</td>\n",
       "      <td>0.097245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>is n't simply just a...</td>\n",
       "      <td>well-designed</td>\n",
       "      <td>52</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sample_document.txt.output 4 6</td>\n",
       "      <td>sample_document.txt.output 4 37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.881371</td>\n",
       "      <td>0.309839</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>is n't simply just a...</td>\n",
       "      <td>interface</td>\n",
       "      <td>52</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sample_document.txt.output 4 18</td>\n",
       "      <td>sample_document.txt.output 4 27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679819</td>\n",
       "      <td>0.556183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>construct</td>\n",
       "      <td>code</td>\n",
       "      <td>48</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sample_document.txt.output 4 18</td>\n",
       "      <td>sample_document.txt.output 4 34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.686048</td>\n",
       "      <td>0.182905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>construct</td>\n",
       "      <td>well-designed</td>\n",
       "      <td>48</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>sample_document.txt.output 18 2</td>\n",
       "      <td>sample_document.txt.output 18 14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.886620</td>\n",
       "      <td>0.285617</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>'s easy</td>\n",
       "      <td>send</td>\n",
       "      <td>27</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>sample_document.txt.output 18 2</td>\n",
       "      <td>sample_document.txt.output 18 24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.690941</td>\n",
       "      <td>0.272183</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>'s easy</td>\n",
       "      <td>Keep</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>sample_document.txt.output 18 4</td>\n",
       "      <td>sample_document.txt.output 18 12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683848</td>\n",
       "      <td>0.455291</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>foresee</td>\n",
       "      <td>be able</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>sample_document.txt.output 18 4</td>\n",
       "      <td>sample_document.txt.output 18 14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.691825</td>\n",
       "      <td>0.426123</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>foresee</td>\n",
       "      <td>send</td>\n",
       "      <td>29</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>sample_document.txt.output 18 4</td>\n",
       "      <td>sample_document.txt.output 18 24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683773</td>\n",
       "      <td>0.476206</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>foresee</td>\n",
       "      <td>Keep</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>sample_document.txt.output 18 12</td>\n",
       "      <td>sample_document.txt.output 18 14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.817707</td>\n",
       "      <td>0.304178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>be able</td>\n",
       "      <td>send</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>sample_document.txt.output 18 12</td>\n",
       "      <td>sample_document.txt.output 18 24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.687430</td>\n",
       "      <td>0.350424</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>be able</td>\n",
       "      <td>Keep</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>sample_document.txt.output 18 14</td>\n",
       "      <td>sample_document.txt.output 18 24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684110</td>\n",
       "      <td>0.500412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>send</td>\n",
       "      <td>Keep</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>sample_document.txt.output 18 4</td>\n",
       "      <td>sample_document.txt.output 19 3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683717</td>\n",
       "      <td>0.465342</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>foresee</td>\n",
       "      <td>Keep</td>\n",
       "      <td>29</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>sample_document.txt.output 18 4</td>\n",
       "      <td>sample_document.txt.output 19 4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.690885</td>\n",
       "      <td>0.122334</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>foresee</td>\n",
       "      <td>incorporating</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>sample_document.txt.output 18 4</td>\n",
       "      <td>sample_document.txt.output 19 16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684330</td>\n",
       "      <td>0.271550</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>foresee</td>\n",
       "      <td>making</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>sample_document.txt.output 18 4</td>\n",
       "      <td>sample_document.txt.output 19 18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684165</td>\n",
       "      <td>0.181679</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>foresee</td>\n",
       "      <td>easy</td>\n",
       "      <td>29</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>sample_document.txt.output 18 4</td>\n",
       "      <td>sample_document.txt.output 19 25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684009</td>\n",
       "      <td>0.589851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>foresee</td>\n",
       "      <td>turn</td>\n",
       "      <td>29</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>sample_document.txt.output 19 3</td>\n",
       "      <td>sample_document.txt.output 19 4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.961707</td>\n",
       "      <td>0.042199</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Keep</td>\n",
       "      <td>incorporating</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>sample_document.txt.output 19 3</td>\n",
       "      <td>sample_document.txt.output 19 16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.830668</td>\n",
       "      <td>0.153271</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Keep</td>\n",
       "      <td>making</td>\n",
       "      <td>33</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>sample_document.txt.output 19 3</td>\n",
       "      <td>sample_document.txt.output 19 18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.797513</td>\n",
       "      <td>0.089905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Keep</td>\n",
       "      <td>easy</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>sample_document.txt.output 19 3</td>\n",
       "      <td>sample_document.txt.output 19 25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.710761</td>\n",
       "      <td>0.509415</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Keep</td>\n",
       "      <td>turn</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>sample_document.txt.output 19 4</td>\n",
       "      <td>sample_document.txt.output 19 16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.698823</td>\n",
       "      <td>0.281376</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>incorporating</td>\n",
       "      <td>making</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>sample_document.txt.output 19 4</td>\n",
       "      <td>sample_document.txt.output 19 18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693564</td>\n",
       "      <td>0.231722</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>incorporating</td>\n",
       "      <td>easy</td>\n",
       "      <td>34</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>sample_document.txt.output 19 4</td>\n",
       "      <td>sample_document.txt.output 19 25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682601</td>\n",
       "      <td>0.583054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>incorporating</td>\n",
       "      <td>turn</td>\n",
       "      <td>34</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>sample_document.txt.output 19 16</td>\n",
       "      <td>sample_document.txt.output 19 18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.742853</td>\n",
       "      <td>0.144564</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>making</td>\n",
       "      <td>easy</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>sample_document.txt.output 19 16</td>\n",
       "      <td>sample_document.txt.output 19 25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.683171</td>\n",
       "      <td>0.551186</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>making</td>\n",
       "      <td>turn</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>sample_document.txt.output 19 18</td>\n",
       "      <td>sample_document.txt.output 19 25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707977</td>\n",
       "      <td>0.493468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>easy</td>\n",
       "      <td>turn</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>sample_document.txt.output 19 25</td>\n",
       "      <td>sample_document.txt.output 20 2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.686516</td>\n",
       "      <td>0.268540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>turn</td>\n",
       "      <td>scare</td>\n",
       "      <td>32</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>sample_document.txt.output 20 2</td>\n",
       "      <td>sample_document.txt.output 21 4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684645</td>\n",
       "      <td>0.174202</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>scare</td>\n",
       "      <td>is not the reinvention of</td>\n",
       "      <td>39</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>sample_document.txt.output 20 2</td>\n",
       "      <td>sample_document.txt.output 21 13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684328</td>\n",
       "      <td>0.006619</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>scare</td>\n",
       "      <td>are</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>sample_document.txt.output 21 4</td>\n",
       "      <td>sample_document.txt.output 21 13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.840664</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>is not the reinvention of</td>\n",
       "      <td>are</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>sample_document.txt.output 21 13</td>\n",
       "      <td>sample_document.txt.output 22 5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.946635</td>\n",
       "      <td>0.293871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>are</td>\n",
       "      <td>is a well-exectuted refinement</td>\n",
       "      <td>40</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>sample_document.txt.output 22 5</td>\n",
       "      <td>sample_document.txt.output 23 1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.997454</td>\n",
       "      <td>0.246350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>is a well-exectuted refinement</td>\n",
       "      <td>filling</td>\n",
       "      <td>42</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>sample_document.txt.output 22 5</td>\n",
       "      <td>sample_document.txt.output 23 14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.832637</td>\n",
       "      <td>0.470791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>is a well-exectuted refinement</td>\n",
       "      <td>gives</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        sent_pred_id1                     sent_pred_id2   b1  \\\n",
       "0      sample_document.txt.output 1 4    sample_document.txt.output 1 8  0.0   \n",
       "1      sample_document.txt.output 1 4   sample_document.txt.output 1 13  0.0   \n",
       "2      sample_document.txt.output 1 8   sample_document.txt.output 1 13  0.0   \n",
       "3     sample_document.txt.output 1 13    sample_document.txt.output 2 4  0.0   \n",
       "4     sample_document.txt.output 1 13    sample_document.txt.output 2 6  0.0   \n",
       "5     sample_document.txt.output 1 13   sample_document.txt.output 2 11  0.0   \n",
       "6     sample_document.txt.output 1 13   sample_document.txt.output 2 20  0.0   \n",
       "7      sample_document.txt.output 2 4    sample_document.txt.output 2 6  0.0   \n",
       "8      sample_document.txt.output 2 4   sample_document.txt.output 2 11  0.0   \n",
       "9      sample_document.txt.output 2 4   sample_document.txt.output 2 20  0.0   \n",
       "10     sample_document.txt.output 2 6   sample_document.txt.output 2 11  0.0   \n",
       "11     sample_document.txt.output 2 6   sample_document.txt.output 2 20  0.0   \n",
       "12    sample_document.txt.output 2 11   sample_document.txt.output 2 20  0.0   \n",
       "13     sample_document.txt.output 2 4    sample_document.txt.output 3 2  0.0   \n",
       "14     sample_document.txt.output 2 4    sample_document.txt.output 3 9  0.0   \n",
       "15     sample_document.txt.output 2 4   sample_document.txt.output 3 16  0.0   \n",
       "16     sample_document.txt.output 3 2    sample_document.txt.output 3 9  0.0   \n",
       "17     sample_document.txt.output 3 2   sample_document.txt.output 3 16  0.0   \n",
       "18     sample_document.txt.output 3 9   sample_document.txt.output 3 16  0.0   \n",
       "19    sample_document.txt.output 3 16    sample_document.txt.output 4 6  0.0   \n",
       "20    sample_document.txt.output 3 16   sample_document.txt.output 4 18  0.0   \n",
       "21    sample_document.txt.output 3 16   sample_document.txt.output 4 27  0.0   \n",
       "22    sample_document.txt.output 3 16   sample_document.txt.output 4 34  0.0   \n",
       "23    sample_document.txt.output 3 16   sample_document.txt.output 4 37  0.0   \n",
       "24     sample_document.txt.output 4 6   sample_document.txt.output 4 18  0.0   \n",
       "25     sample_document.txt.output 4 6   sample_document.txt.output 4 27  0.0   \n",
       "26     sample_document.txt.output 4 6   sample_document.txt.output 4 34  0.0   \n",
       "27     sample_document.txt.output 4 6   sample_document.txt.output 4 37  0.0   \n",
       "28    sample_document.txt.output 4 18   sample_document.txt.output 4 27  0.0   \n",
       "29    sample_document.txt.output 4 18   sample_document.txt.output 4 34  0.0   \n",
       "..                                ...                               ...  ...   \n",
       "109   sample_document.txt.output 18 2  sample_document.txt.output 18 14  0.0   \n",
       "110   sample_document.txt.output 18 2  sample_document.txt.output 18 24  0.0   \n",
       "111   sample_document.txt.output 18 4  sample_document.txt.output 18 12  0.0   \n",
       "112   sample_document.txt.output 18 4  sample_document.txt.output 18 14  0.0   \n",
       "113   sample_document.txt.output 18 4  sample_document.txt.output 18 24  0.0   \n",
       "114  sample_document.txt.output 18 12  sample_document.txt.output 18 14  0.0   \n",
       "115  sample_document.txt.output 18 12  sample_document.txt.output 18 24  0.0   \n",
       "116  sample_document.txt.output 18 14  sample_document.txt.output 18 24  0.0   \n",
       "117   sample_document.txt.output 18 4   sample_document.txt.output 19 3  0.0   \n",
       "118   sample_document.txt.output 18 4   sample_document.txt.output 19 4  0.0   \n",
       "119   sample_document.txt.output 18 4  sample_document.txt.output 19 16  0.0   \n",
       "120   sample_document.txt.output 18 4  sample_document.txt.output 19 18  0.0   \n",
       "121   sample_document.txt.output 18 4  sample_document.txt.output 19 25  0.0   \n",
       "122   sample_document.txt.output 19 3   sample_document.txt.output 19 4  0.0   \n",
       "123   sample_document.txt.output 19 3  sample_document.txt.output 19 16  0.0   \n",
       "124   sample_document.txt.output 19 3  sample_document.txt.output 19 18  0.0   \n",
       "125   sample_document.txt.output 19 3  sample_document.txt.output 19 25  0.0   \n",
       "126   sample_document.txt.output 19 4  sample_document.txt.output 19 16  0.0   \n",
       "127   sample_document.txt.output 19 4  sample_document.txt.output 19 18  0.0   \n",
       "128   sample_document.txt.output 19 4  sample_document.txt.output 19 25  0.0   \n",
       "129  sample_document.txt.output 19 16  sample_document.txt.output 19 18  0.0   \n",
       "130  sample_document.txt.output 19 16  sample_document.txt.output 19 25  0.0   \n",
       "131  sample_document.txt.output 19 18  sample_document.txt.output 19 25  0.0   \n",
       "132  sample_document.txt.output 19 25   sample_document.txt.output 20 2  0.0   \n",
       "133   sample_document.txt.output 20 2   sample_document.txt.output 21 4  0.0   \n",
       "134   sample_document.txt.output 20 2  sample_document.txt.output 21 13  0.0   \n",
       "135   sample_document.txt.output 21 4  sample_document.txt.output 21 13  0.0   \n",
       "136  sample_document.txt.output 21 13   sample_document.txt.output 22 5  0.0   \n",
       "137   sample_document.txt.output 22 5   sample_document.txt.output 23 1  0.0   \n",
       "138   sample_document.txt.output 22 5  sample_document.txt.output 23 14  0.0   \n",
       "\n",
       "           e1        b2        e2  pred1_duration  pred2_duration  \\\n",
       "0    1.000000  0.138038  0.973703               4               3   \n",
       "1    0.772453  0.051323  1.000000               4               3   \n",
       "2    0.683801  0.350981  1.000000               3               3   \n",
       "3    0.713067  0.182615  1.000000               3               4   \n",
       "4    0.772952  0.370259  1.000000               3               3   \n",
       "5    0.700707  0.054357  1.000000               3               5   \n",
       "6    0.721205  0.134588  1.000000               3               4   \n",
       "7    0.929649  0.360196  1.000000               4               2   \n",
       "8    0.792010  0.049051  1.000000               4               5   \n",
       "9    0.859625  0.156823  1.000000               4               4   \n",
       "10   0.683936  0.056403  1.000000               2               5   \n",
       "11   0.683903  0.176831  1.000000               2               4   \n",
       "12   0.950263  0.214235  1.000000               5               4   \n",
       "13   0.957735  0.501102  1.000000               4               3   \n",
       "14   0.855897  0.438598  1.000000               4               3   \n",
       "15   0.877559  0.517376  1.000000               4               3   \n",
       "16   0.684059  0.511311  1.000000               3               3   \n",
       "17   0.684026  0.581059  1.000000               3               3   \n",
       "18   0.685237  0.499833  1.000000               3               3   \n",
       "19   0.683977  0.403055  1.000000               3               4   \n",
       "20   0.684035  0.416919  1.000000               3               4   \n",
       "21   0.684504  0.576316  1.000000               3               3   \n",
       "22   0.683937  0.183423  1.000000               3               4   \n",
       "23   0.684063  0.461289  1.000000               3               4   \n",
       "24   0.932618  0.292017  1.000000               5               4   \n",
       "25   0.886415  0.471430  1.000000               5               3   \n",
       "26   0.849277  0.097245  1.000000               5               4   \n",
       "27   0.881371  0.309839  1.000000               5               4   \n",
       "28   0.679819  0.556183  1.000000               4               3   \n",
       "29   0.686048  0.182905  1.000000               4               4   \n",
       "..        ...       ...       ...             ...             ...   \n",
       "109  0.886620  0.285617  1.000000               3               2   \n",
       "110  0.690941  0.272183  1.000000               3               4   \n",
       "111  0.683848  0.455291  1.000000               3               3   \n",
       "112  0.691825  0.426123  1.000000               3               2   \n",
       "113  0.683773  0.476206  1.000000               3               4   \n",
       "114  0.817707  0.304178  1.000000               3               2   \n",
       "115  0.687430  0.350424  1.000000               3               4   \n",
       "116  0.684110  0.500412  1.000000               2               4   \n",
       "117  0.683717  0.465342  1.000000               3               4   \n",
       "118  0.690885  0.122334  1.000000               3               4   \n",
       "119  0.684330  0.271550  1.000000               3               4   \n",
       "120  0.684165  0.181679  1.000000               3               4   \n",
       "121  0.684009  0.589851  1.000000               3               3   \n",
       "122  0.961707  0.042199  1.000000               4               4   \n",
       "123  0.830668  0.153271  1.000000               4               4   \n",
       "124  0.797513  0.089905  1.000000               4               4   \n",
       "125  0.710761  0.509415  1.000000               4               3   \n",
       "126  0.698823  0.281376  1.000000               4               4   \n",
       "127  0.693564  0.231722  1.000000               4               4   \n",
       "128  0.682601  0.583054  1.000000               4               3   \n",
       "129  0.742853  0.144564  1.000000               4               4   \n",
       "130  0.683171  0.551186  1.000000               4               3   \n",
       "131  0.707977  0.493468  1.000000               4               3   \n",
       "132  0.686516  0.268540  1.000000               3               4   \n",
       "133  0.684645  0.174202  1.000000               4               5   \n",
       "134  0.684328  0.006619  1.000000               4               5   \n",
       "135  0.840664  0.008757  1.000000               5               5   \n",
       "136  0.946635  0.293871  1.000000               5               4   \n",
       "137  0.997454  0.246350  1.000000               4               4   \n",
       "138  0.832637  0.470791  1.000000               4               4   \n",
       "\n",
       "                         pred1_text                      pred2_text  \\\n",
       "0                              Keep                        launched   \n",
       "1                              Keep                             was   \n",
       "2                          launched                             was   \n",
       "3                               was              was a glaring hole   \n",
       "4                               was                     considering   \n",
       "5                               was                             has   \n",
       "6                               was                         powered   \n",
       "7                was a glaring hole                     considering   \n",
       "8                was a glaring hole                             has   \n",
       "9                was a glaring hole                         powered   \n",
       "10                      considering                             has   \n",
       "11                      considering                         powered   \n",
       "12                              has                         powered   \n",
       "13               was a glaring hole                        settling   \n",
       "14               was a glaring hole                            fill   \n",
       "15               was a glaring hole                            took   \n",
       "16                         settling                            fill   \n",
       "17                         settling                            took   \n",
       "18                             fill                            took   \n",
       "19                             took         is n't simply just a...   \n",
       "20                             took                       construct   \n",
       "21                             took                            code   \n",
       "22                             took                   well-designed   \n",
       "23                             took                       interface   \n",
       "24          is n't simply just a...                       construct   \n",
       "25          is n't simply just a...                            code   \n",
       "26          is n't simply just a...                   well-designed   \n",
       "27          is n't simply just a...                       interface   \n",
       "28                        construct                            code   \n",
       "29                        construct                   well-designed   \n",
       "..                              ...                             ...   \n",
       "109                         's easy                            send   \n",
       "110                         's easy                            Keep   \n",
       "111                         foresee                         be able   \n",
       "112                         foresee                            send   \n",
       "113                         foresee                            Keep   \n",
       "114                         be able                            send   \n",
       "115                         be able                            Keep   \n",
       "116                            send                            Keep   \n",
       "117                         foresee                            Keep   \n",
       "118                         foresee                   incorporating   \n",
       "119                         foresee                          making   \n",
       "120                         foresee                            easy   \n",
       "121                         foresee                            turn   \n",
       "122                            Keep                   incorporating   \n",
       "123                            Keep                          making   \n",
       "124                            Keep                            easy   \n",
       "125                            Keep                            turn   \n",
       "126                   incorporating                          making   \n",
       "127                   incorporating                            easy   \n",
       "128                   incorporating                            turn   \n",
       "129                          making                            easy   \n",
       "130                          making                            turn   \n",
       "131                            easy                            turn   \n",
       "132                            turn                           scare   \n",
       "133                           scare       is not the reinvention of   \n",
       "134                           scare                             are   \n",
       "135       is not the reinvention of                             are   \n",
       "136                             are  is a well-exectuted refinement   \n",
       "137  is a well-exectuted refinement                         filling   \n",
       "138  is a well-exectuted refinement                           gives   \n",
       "\n",
       "     pred1_dict_idx  pred2_dict_idx  \n",
       "0                 1               2  \n",
       "1                 1               0  \n",
       "2                 2               0  \n",
       "3                 0              37  \n",
       "4                 0              38  \n",
       "5                 0              35  \n",
       "6                 0              36  \n",
       "7                37              38  \n",
       "8                37              35  \n",
       "9                37              36  \n",
       "10               38              35  \n",
       "11               38              36  \n",
       "12               35              36  \n",
       "13               37              46  \n",
       "14               37              47  \n",
       "15               37              45  \n",
       "16               46              47  \n",
       "17               46              45  \n",
       "18               47              45  \n",
       "19               45              52  \n",
       "20               45              48  \n",
       "21               45              49  \n",
       "22               45              50  \n",
       "23               45              51  \n",
       "24               52              48  \n",
       "25               52              49  \n",
       "26               52              50  \n",
       "27               52              51  \n",
       "28               48              49  \n",
       "29               48              50  \n",
       "..              ...             ...  \n",
       "109              27              26  \n",
       "110              27              28  \n",
       "111              29              25  \n",
       "112              29              26  \n",
       "113              29              28  \n",
       "114              25              26  \n",
       "115              25              28  \n",
       "116              26              28  \n",
       "117              29              33  \n",
       "118              29              34  \n",
       "119              29              30  \n",
       "120              29              31  \n",
       "121              29              32  \n",
       "122              33              34  \n",
       "123              33              30  \n",
       "124              33              31  \n",
       "125              33              32  \n",
       "126              34              30  \n",
       "127              34              31  \n",
       "128              34              32  \n",
       "129              30              31  \n",
       "130              30              32  \n",
       "131              31              32  \n",
       "132              32              39  \n",
       "133              39              41  \n",
       "134              39              40  \n",
       "135              41              40  \n",
       "136              40              42  \n",
       "137              42              43  \n",
       "138              42              44  \n",
       "\n",
       "[139 rows x 12 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#### Model Parameters ####\n",
      "pred_tensor torch.Size([65, 2])\n",
      "k torch.Size([1])\n",
      "##########################\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10e4e6da7a5432686dffba95669b47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 9.886517524719238\n",
      "\n",
      "Epoch: 4630, Converging-Loss: 0.8108711242675781\n"
     ]
    }
   ],
   "source": [
    "## Run Timeline Model on current docid's data\n",
    "model = TimelineModel(data = local_data,\n",
    "         num_preds = num_preds,\n",
    "        device=torch.device(type=\"cpu\"))\n",
    "\n",
    "pred_b1, pred_e1, pred_b2, pred_e2, pred_timeline  = model.fit(local_data, epochs=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pred_text(lst, data):\n",
    "    '''\n",
    "    Input: A list of sent_pred tokens\n",
    "    Output: A list of predicate text\n",
    "    '''\n",
    "    ans = []\n",
    "    for sent_pred in lst:\n",
    "        try:\n",
    "            pred_text = data[(data.sent_pred_id1==sent_pred)]['pred1_text'].values[0]\n",
    "            ans.append(pred_text)\n",
    "        except:\n",
    "            pred_text = data[(data.sent_pred_id2==sent_pred)]['pred2_text'].values[0]\n",
    "            ans.append(pred_text)\n",
    "            \n",
    "    return ans\n",
    "\n",
    "preds_arr = local_data[['sent_pred_id1', 'sent_pred_id2']].values\n",
    "uniq_preds = np.unique(preds_arr.flatten())\n",
    "#print(uniq_preds)\n",
    "\n",
    "preds_text = extract_pred_text(uniq_preds, local_data)\n",
    "\n",
    "ans_df = pd.DataFrame(data=pred_timeline, \n",
    "                     columns=['start_pt', 'duration'])\n",
    "ans_df['sent_pred_id'] = uniq_preds\n",
    "ans_df['pred_text'] = preds_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_pt</th>\n",
       "      <th>duration</th>\n",
       "      <th>sent_pred_id</th>\n",
       "      <th>pred_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.119858e-01</td>\n",
       "      <td>1.695792</td>\n",
       "      <td>sample_document.txt.output 1 13</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.022708e-02</td>\n",
       "      <td>1.381148</td>\n",
       "      <td>sample_document.txt.output 1 4</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.514682</td>\n",
       "      <td>sample_document.txt.output 1 8</td>\n",
       "      <td>launched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.955912e+00</td>\n",
       "      <td>1.827200</td>\n",
       "      <td>sample_document.txt.output 10 12</td>\n",
       "      <td>serves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.002516e+00</td>\n",
       "      <td>2.072986</td>\n",
       "      <td>sample_document.txt.output 10 6</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.090870e+00</td>\n",
       "      <td>2.587976</td>\n",
       "      <td>sample_document.txt.output 11 2</td>\n",
       "      <td>viewing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.979735e+00</td>\n",
       "      <td>1.893597</td>\n",
       "      <td>sample_document.txt.output 11 21</td>\n",
       "      <td>allow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.718867e+00</td>\n",
       "      <td>2.573961</td>\n",
       "      <td>sample_document.txt.output 11 24</td>\n",
       "      <td>edit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.845518e+00</td>\n",
       "      <td>2.494445</td>\n",
       "      <td>sample_document.txt.output 11 7</td>\n",
       "      <td>tapping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.690800e+00</td>\n",
       "      <td>1.434886</td>\n",
       "      <td>sample_document.txt.output 12 4</td>\n",
       "      <td>is frictionless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.116409e-33</td>\n",
       "      <td>3.287474</td>\n",
       "      <td>sample_document.txt.output 13 1</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.954245e+00</td>\n",
       "      <td>1.505532</td>\n",
       "      <td>sample_document.txt.output 13 6</td>\n",
       "      <td>going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.122333e+00</td>\n",
       "      <td>1.147960</td>\n",
       "      <td>sample_document.txt.output 13 8</td>\n",
       "      <td>conquer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.266660e+00</td>\n",
       "      <td>1.950531</td>\n",
       "      <td>sample_document.txt.output 14 10</td>\n",
       "      <td>is only choice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.685147e+00</td>\n",
       "      <td>2.423265</td>\n",
       "      <td>sample_document.txt.output 14 16</td>\n",
       "      <td>re-order</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7.760270e-01</td>\n",
       "      <td>1.361552</td>\n",
       "      <td>sample_document.txt.output 14 3</td>\n",
       "      <td>limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.129252e-01</td>\n",
       "      <td>1.225690</td>\n",
       "      <td>sample_document.txt.output 15 10</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.750909e-01</td>\n",
       "      <td>1.331804</td>\n",
       "      <td>sample_document.txt.output 15 19</td>\n",
       "      <td>are pretty bare bones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8.632225e-01</td>\n",
       "      <td>1.214902</td>\n",
       "      <td>sample_document.txt.output 15 5</td>\n",
       "      <td>limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6.714599e-01</td>\n",
       "      <td>1.543488</td>\n",
       "      <td>sample_document.txt.output 15 7</td>\n",
       "      <td>email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.111757e+00</td>\n",
       "      <td>1.583894</td>\n",
       "      <td>sample_document.txt.output 16 14</td>\n",
       "      <td>thought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.125117e+00</td>\n",
       "      <td>1.100012</td>\n",
       "      <td>sample_document.txt.output 16 5</td>\n",
       "      <td>'s more a function of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.137137e+00</td>\n",
       "      <td>1.163098</td>\n",
       "      <td>sample_document.txt.output 16 9</td>\n",
       "      <td>being new</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.513792e+00</td>\n",
       "      <td>1.582096</td>\n",
       "      <td>sample_document.txt.output 17 16</td>\n",
       "      <td>turn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.882577</td>\n",
       "      <td>sample_document.txt.output 17 5</td>\n",
       "      <td>expect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.359368e+00</td>\n",
       "      <td>1.419168</td>\n",
       "      <td>sample_document.txt.output 18 12</td>\n",
       "      <td>be able</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.463834e+00</td>\n",
       "      <td>1.628252</td>\n",
       "      <td>sample_document.txt.output 18 14</td>\n",
       "      <td>send</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>8.117424e-01</td>\n",
       "      <td>1.586106</td>\n",
       "      <td>sample_document.txt.output 18 2</td>\n",
       "      <td>'s easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.076740e+00</td>\n",
       "      <td>1.326546</td>\n",
       "      <td>sample_document.txt.output 18 24</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8.707098e-01</td>\n",
       "      <td>1.537090</td>\n",
       "      <td>sample_document.txt.output 18 4</td>\n",
       "      <td>foresee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>1.547921e+00</td>\n",
       "      <td>1.406543</td>\n",
       "      <td>sample_document.txt.output 19 16</td>\n",
       "      <td>making</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.687923e+00</td>\n",
       "      <td>1.428888</td>\n",
       "      <td>sample_document.txt.output 19 18</td>\n",
       "      <td>easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.187676e+00</td>\n",
       "      <td>1.525699</td>\n",
       "      <td>sample_document.txt.output 19 25</td>\n",
       "      <td>turn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.293131e+00</td>\n",
       "      <td>1.380952</td>\n",
       "      <td>sample_document.txt.output 19 3</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.256287e+00</td>\n",
       "      <td>1.365266</td>\n",
       "      <td>sample_document.txt.output 19 4</td>\n",
       "      <td>incorporating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6.775539e-01</td>\n",
       "      <td>1.182213</td>\n",
       "      <td>sample_document.txt.output 2 11</td>\n",
       "      <td>has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>7.740075e-01</td>\n",
       "      <td>1.374936</td>\n",
       "      <td>sample_document.txt.output 2 20</td>\n",
       "      <td>powered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5.187451e-01</td>\n",
       "      <td>1.155471</td>\n",
       "      <td>sample_document.txt.output 2 4</td>\n",
       "      <td>was a glaring hole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4.294924e-01</td>\n",
       "      <td>1.877270</td>\n",
       "      <td>sample_document.txt.output 2 6</td>\n",
       "      <td>considering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2.663382e+00</td>\n",
       "      <td>1.231701</td>\n",
       "      <td>sample_document.txt.output 20 2</td>\n",
       "      <td>scare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        start_pt  duration                      sent_pred_id  \\\n",
       "0   1.119858e-01  1.695792   sample_document.txt.output 1 13   \n",
       "1   2.022708e-02  1.381148    sample_document.txt.output 1 4   \n",
       "2   0.000000e+00  1.514682    sample_document.txt.output 1 8   \n",
       "3   3.955912e+00  1.827200  sample_document.txt.output 10 12   \n",
       "4   3.002516e+00  2.072986   sample_document.txt.output 10 6   \n",
       "5   3.090870e+00  2.587976   sample_document.txt.output 11 2   \n",
       "6   4.979735e+00  1.893597  sample_document.txt.output 11 21   \n",
       "7   5.718867e+00  2.573961  sample_document.txt.output 11 24   \n",
       "8   3.845518e+00  2.494445   sample_document.txt.output 11 7   \n",
       "9   1.690800e+00  1.434886   sample_document.txt.output 12 4   \n",
       "10  1.116409e-33  3.287474   sample_document.txt.output 13 1   \n",
       "11  1.954245e+00  1.505532   sample_document.txt.output 13 6   \n",
       "12  2.122333e+00  1.147960   sample_document.txt.output 13 8   \n",
       "13  1.266660e+00  1.950531  sample_document.txt.output 14 10   \n",
       "14  2.685147e+00  2.423265  sample_document.txt.output 14 16   \n",
       "15  7.760270e-01  1.361552   sample_document.txt.output 14 3   \n",
       "16  9.129252e-01  1.225690  sample_document.txt.output 15 10   \n",
       "17  9.750909e-01  1.331804  sample_document.txt.output 15 19   \n",
       "18  8.632225e-01  1.214902   sample_document.txt.output 15 5   \n",
       "19  6.714599e-01  1.543488   sample_document.txt.output 15 7   \n",
       "20  1.111757e+00  1.583894  sample_document.txt.output 16 14   \n",
       "21  1.125117e+00  1.100012   sample_document.txt.output 16 5   \n",
       "22  1.137137e+00  1.163098   sample_document.txt.output 16 9   \n",
       "23  1.513792e+00  1.582096  sample_document.txt.output 17 16   \n",
       "24  0.000000e+00  1.882577   sample_document.txt.output 17 5   \n",
       "25  1.359368e+00  1.419168  sample_document.txt.output 18 12   \n",
       "26  1.463834e+00  1.628252  sample_document.txt.output 18 14   \n",
       "27  8.117424e-01  1.586106   sample_document.txt.output 18 2   \n",
       "28  2.076740e+00  1.326546  sample_document.txt.output 18 24   \n",
       "29  8.707098e-01  1.537090   sample_document.txt.output 18 4   \n",
       "30  1.547921e+00  1.406543  sample_document.txt.output 19 16   \n",
       "31  1.687923e+00  1.428888  sample_document.txt.output 19 18   \n",
       "32  2.187676e+00  1.525699  sample_document.txt.output 19 25   \n",
       "33  1.293131e+00  1.380952   sample_document.txt.output 19 3   \n",
       "34  1.256287e+00  1.365266   sample_document.txt.output 19 4   \n",
       "35  6.775539e-01  1.182213   sample_document.txt.output 2 11   \n",
       "36  7.740075e-01  1.374936   sample_document.txt.output 2 20   \n",
       "37  5.187451e-01  1.155471    sample_document.txt.output 2 4   \n",
       "38  4.294924e-01  1.877270    sample_document.txt.output 2 6   \n",
       "39  2.663382e+00  1.231701   sample_document.txt.output 20 2   \n",
       "\n",
       "                pred_text  \n",
       "0                     was  \n",
       "1                    Keep  \n",
       "2                launched  \n",
       "3                  serves  \n",
       "4                      is  \n",
       "5                 viewing  \n",
       "6                   allow  \n",
       "7                    edit  \n",
       "8                 tapping  \n",
       "9         is frictionless  \n",
       "10                   said  \n",
       "11                  going  \n",
       "12                conquer  \n",
       "13         is only choice  \n",
       "14               re-order  \n",
       "15                limited  \n",
       "16                      +  \n",
       "17  are pretty bare bones  \n",
       "18                limited  \n",
       "19                  email  \n",
       "20                thought  \n",
       "21  's more a function of  \n",
       "22              being new  \n",
       "23                   turn  \n",
       "24                 expect  \n",
       "25                be able  \n",
       "26                   send  \n",
       "27                's easy  \n",
       "28                   Keep  \n",
       "29                foresee  \n",
       "30                 making  \n",
       "31                   easy  \n",
       "32                   turn  \n",
       "33                   Keep  \n",
       "34          incorporating  \n",
       "35                    has  \n",
       "36                powered  \n",
       "37     was a glaring hole  \n",
       "38            considering  \n",
       "39                  scare  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ans_df.to_json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
