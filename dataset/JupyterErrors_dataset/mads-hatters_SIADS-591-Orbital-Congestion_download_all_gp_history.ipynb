{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import urllib\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import gzip\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurables\n",
    "\n",
    "# local paths\n",
    "csv_store_path = \"../../../siads591 data/space_track_raw/csv/\"\n",
    "log_file_path = \"../../../siads591 data/space_track_raw/logs.pkl\"\n",
    "temp_directory = \"../../../siads591 data/space_track_raw/tmp/\"\n",
    "cookie_path = \"../../../siads591 data/space_track_raw/cookie.pkl\"\n",
    "space_track_credentials = \"./space-track-credentials.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up default and initial variables\n",
    "columns = ['GP_ID', 'EPOCH', 'NORAD_CAT_ID', 'MEAN_MOTION', 'ECCENTRICITY', 'INCLINATION', 'RA_OF_ASC_NODE', 'ARG_OF_PERICENTER', 'MEAN_ANOMALY', 'REV_AT_EPOCH', 'BSTAR', 'MEAN_MOTION_DOT', 'MEAN_MOTION_DDOT', 'SEMIMAJOR_AXIS', 'PERIOD', 'APOAPSIS', 'PERIAPSIS']\n",
    "dtypes = {\n",
    "    'GP_ID':np.uint32,\n",
    "    'NORAD_CAT_ID':np.uint32,\n",
    "    'REV_AT_EPOCH':np.uint32,\n",
    "    'INCLINATION':np.float64,\n",
    "    'RA_OF_ASC_NODE':np.float64,\n",
    "    'ARG_OF_PERICENTER':np.float64,\n",
    "    'MEAN_ANOMALY':np.float64,\n",
    "    'SEMIMAJOR_AXIS':np.float64,\n",
    "    'PERIOD':np.float64,\n",
    "    'APOAPSIS':np.float64,\n",
    "    'PERIAPSIS':np.float64,\n",
    "    'MEAN_MOTION':np.float64,\n",
    "    'ECCENTRICITY':np.float64,\n",
    "    'BSTAR':np.float64,\n",
    "    'MEAN_MOTION_DOT':np.float64,\n",
    "    'MEAN_MOTION_DDOT':np.float64,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log file helpers\n",
    "\n",
    "def save_logs():\n",
    "    logs.to_pickle(log_file_path)\n",
    "    \n",
    "def log(log_type,url=None,error=None,input_str=None,output_str=None):\n",
    "    global logs\n",
    "    new_log = {'created_on':np.datetime64('now'), 'type':log_type, 'url':url, 'input':input_str, 'error':error, 'output':output_str}\n",
    "    logs = logs.append(new_log,ignore_index=True)\n",
    "    save_logs()\n",
    "    \n",
    "try:\n",
    "    logs = pd.read_pickle(log_file_path)\n",
    "except:\n",
    "    logs = pd.DataFrame(columns = [\"created_on\",\"type\",\"url\",\"error\",\"input_str\",\"output_str\"])\n",
    "    logs = logs.astype({'created_on': 'datetime64[ns]'})\n",
    "    log('log_created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_gp_id():\n",
    "    try:\n",
    "        return max([int(f[:-7].split(\"-\")[1]) for f in os.listdir(f'{csv_store_path}/') if f.endswith(\".csv.gz\")])+1\n",
    "    except:\n",
    "        return 1\n",
    "\n",
    "def get_space_track_api_count(unit=\"m\"):\n",
    "    return len(logs[(logs.created_on > (np.datetime64('now') - np.timedelta64(1,unit))) & (logs.type==\"fetch_init\")])\n",
    "\n",
    "def space_track_login():\n",
    "    with open(space_track_credentials) as json_file:\n",
    "        credentials = json.load(json_file)\n",
    "    url = \"https://www.space-track.org/ajaxauth/login\"\n",
    "    x = requests.post(url, data = credentials)\n",
    "    if x.status_code == 200:\n",
    "        log(\"login\", output_str=f'{credentials[\"identity\"]} - success')\n",
    "        return x.cookies\n",
    "    else:\n",
    "        log(\"login\", error=x.status_code)\n",
    "        print(\"Login failed with code:\",x.status_code)\n",
    "        return None\n",
    "    \n",
    "def generate_url():\n",
    "    gp_id = get_latest_gp_id()\n",
    "    end_gp_id = gp_id + 5000000 # sometimes gotta fix this number\n",
    "    return (gp_id, f'https://www.space-track.org/basicspacedata/query/class/gp_history/GP_ID/{gp_id}--{end_gp_id}/orderby/GP_ID asc/limit/100000/format/csv/emptyresult/show')\n",
    "\n",
    "def give_me_a_cookie_please():\n",
    "    # returns an existing cookie if there is one, otherwise, get a new one.\n",
    "    # return None if can't :(\n",
    "    try:\n",
    "        auth_cookie = pickle.load(open(cookie_path, \"rb\"))\n",
    "    except:\n",
    "        auth_cookie = None\n",
    "    if type(auth_cookie) == requests.cookies.RequestsCookieJar:\n",
    "        auth_cookie.clear_expired_cookies()\n",
    "    else:\n",
    "        auth_cookie = None\n",
    "    # log in if needed\n",
    "    if auth_cookie == None or len(auth_cookie) == 0:\n",
    "        auth_cookie = space_track_login()\n",
    "        pickle.dump(auth_cookie, open(cookie_path, \"wb\"))\n",
    "    # stop if can't log in\n",
    "    if auth_cookie == None:\n",
    "        log(\"skip\", error = f'Cannot log in')\n",
    "        return None\n",
    "    return auth_cookie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you proceed:\n",
    "* Create the `space-track-credentials.json` file from template with your own credentials\n",
    "* Make sure all the directories and file paths are created and correct\n",
    "* Manually test the fetch cell to make sure things are working first\n",
    "* If using automatic process, set an appropriate intervalTime\n",
    "* This will probably mess up if your task time is longer than your interval time, don't use the automatic process if so\n",
    "* If you don't know what to do or are unsure, ask Tim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "This exception is to stop the cells below from running when you do \"Run All Cells\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d2dbe78a8e07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This exception is to stop the cells below from running when you do \"Run All Cells\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: This exception is to stop the cells below from running when you do \"Run All Cells\""
     ]
    }
   ],
   "source": [
    "raise Exception('This exception is to stop the cells below from running when you do \"Run All Cells\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have commented this out for now since it's never really necessary to use given my internet speed.  Please feel\n",
    "# free to use it for autorunning the tasks.  Look at the /playground/tim_autorun-notebook/skeleton_autorun_below.ipynb\n",
    "# if you want the skeleton autorun code.\n",
    "\n",
    "\n",
    "# %%html\n",
    "# <script>\n",
    "#     var intervalTime = 300000; // 5 minutes in ms\n",
    "#     if (typeof autorun_toggle === 'undefined') {\n",
    "#         var autorun_toggle = null;\n",
    "#     }\n",
    "#     function toggle_autorun() {\n",
    "#         var btn = document.getElementById(\"autorun_button\");\n",
    "#         setTimeout(function(){ // add a delay so the selected cell is correctly set here\n",
    "#             if (autorun_toggle == null) {\n",
    "#                 var start_index = IPython.notebook.get_selected_index()+1;\n",
    "#                 var end_index = IPython.notebook.get_cells().length;\n",
    "#                 console.log(\"start autorun, start: \" + start_index + \" end: \" + end_index);\n",
    "#                 IPython.notebook.execute_cell_range(start_index, end_index);\n",
    "#                 //$('div.input').hide(200);\n",
    "#                 autorun_toggle = setInterval(function(){\n",
    "#                     console.log(\"Run cells below\");\n",
    "#                     //IPython.notebook.execute_cells_below();\n",
    "#                     IPython.notebook.execute_cell_range(start_index, end_index);\n",
    "#                 }, intervalTime);\n",
    "#             } else {\n",
    "#                 window.clearInterval(autorun_toggle);\n",
    "#                 console.log(\"clear autorun\");\n",
    "#                 autorun_toggle = null;\n",
    "#                 //$('div.input').show(200);\n",
    "#             }\n",
    "#         }, 100);\n",
    "#     }\n",
    "# </script>\n",
    "# <button id=\"autorun_button\" onclick=\"toggle_autorun()\">Toggle autorun cells below</button>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:08,  8.19s/it, No more results.  Last GP_ID: 170814691]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time used to execute cells: 8.195576899 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(position=0, leave=True)\n",
    "start_time = timeit.default_timer()\n",
    "log('run_cell',output_str=f'Last run local time: {datetime.now()}')\n",
    "# print(f'Last run local time: {datetime.now()}')\n",
    "\n",
    "last_fetched_gp_id = -1\n",
    "while True:\n",
    "    # check API limit\n",
    "    if get_space_track_api_count(\"m\") >= 25 or get_space_track_api_count(\"h\") >= 275:\n",
    "        log(\"skip\", error = f'Request limit exceeded: 1m({get_space_track_api_count(\"m\")}) 1h({get_space_track_api_count(\"h\")})')\n",
    "        break\n",
    "\n",
    "    # check if already up to date\n",
    "    current_gp_id = get_latest_gp_id()\n",
    "    if last_fetched_gp_id == current_gp_id:\n",
    "        log(\"up_to_date\",output_str=(last_fetched_gp_id))\n",
    "        break\n",
    "    \n",
    "    auth_cookie = give_me_a_cookie_please()\n",
    "\n",
    "    start_gp, url = generate_url()\n",
    "    pbar.set_postfix_str(f\"downloading gp id starting {start_gp}\")\n",
    "    r = requests.get(url, allow_redirects=True, cookies=auth_cookie)\n",
    "    \n",
    "    if r.content == b'NO RESULTS RETURNED':\n",
    "        log(\"no_more_results\",output_str=(last_fetched_gp_id))\n",
    "        pbar.set_postfix_str(f\"No more results.  Last GP_ID: {current_gp_id}\")\n",
    "        break\n",
    "    \n",
    "    # save gzip'ed version of CSV to save space\n",
    "    pbar.set_postfix_str(f\"processing gp id starting {start_gp}\")\n",
    "    dlname = f'{temp_directory}{start_gp}.csv.gz'\n",
    "    gzip.open(dlname, 'wb').write(r.content)\n",
    "    \n",
    "    log(\"fetch_complete\", url=url, input_str=start_gp, output_str=dlname)\n",
    "    \n",
    "    df = pd.read_csv(dlname, usecols=columns, parse_dates=['EPOCH'], infer_datetime_format=True, index_col='GP_ID', dtype=dtypes, compression='gzip')\n",
    "\n",
    "    end_gp = max(df.index)\n",
    "    \n",
    "    fname = f'{csv_store_path}{str(start_gp).zfill(9)}-{str(end_gp).zfill(9)}.csv.gz'\n",
    "    shutil.move(dlname, fname)\n",
    "    log(\"csv_move_complete\", url=url, input_str=dlname, output_str=fname)\n",
    "    # note that the CSV file may include a partial downloaded file as its last file_id\n",
    "    \n",
    "    pbar.set_postfix_str(f\"completed {start_gp}-{end_gp}\")\n",
    "\n",
    "    pbar.update(1)\n",
    "    \n",
    "    last_fetched_gp_id = current_gp_id\n",
    "\n",
    "    \n",
    "pbar.close()\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(f\"Time used to execute cells: {elapsed} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
