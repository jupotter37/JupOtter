{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# TEST Extracting researchers based on affiliations and publications history\n",
    "The purpose of this notebook is to demonstrate how to extract researchers data using the Dimensions API. \n",
    "\n",
    "Specifically, we will look at a concrete use case. We want to find out about all researchers based on these two criteria: \n",
    "\n",
    "1. they are or have been **affiliated** to a specific **GRID** organization \n",
    "2. they have **published** within a chosen **time frame** \n",
    "\n",
    "For the purpose of this exercise, we will are going to use [grid.258806.1](https://grid.ac/institutes/grid.258806.1) and the time frame **2013-2018**. Feel free though to change the parameters below as you want, eg by [choosing another GRID organization](https://grid.ac/institutes).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# sample org: grid.258806.1\n",
    "GRIDID = \"grid.420434.5\" #@param {type:\"string\"}\n",
    "START_YEAR = 2016 #@param {type:\"slider\", min:1900, max:2020, step: 1}\n",
    "END_YEAR = 2016 #@param {type:\"slider\", min:1900, max:2020, step: 1}\n",
    "\n",
    "if START_YEAR < END_YEAR: START_YEAR = END_YEAR\n",
    "YEARS = f\"[{START_YEAR}:{END_YEAR}]\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Before we start, let's also load some useful libraries and login with the Dimensions API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mDimcli - Dimensions API Client (v0.7.4.2)\u001b[0m\n",
      "\u001b[2mConnected to: https://app.dimensions.ai - DSL v1.27\u001b[0m\n",
      "\u001b[2mMethod: dsl.ini file\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# @markdown Click the 'play' button on the left (or shift+enter) after entering your API credentials\n",
    "\n",
    "username = \"\" #@param {type: \"string\"}\n",
    "password = \"\" #@param {type: \"string\"}\n",
    "endpoint = \"https://app.dimensions.ai\"\n",
    "\n",
    "!pip install dimcli -U --quiet\n",
    "\n",
    "# import all libraries and login\n",
    "import dimcli\n",
    "from dimcli.shortcuts import *\n",
    "dimcli.login(username, password, endpoint)\n",
    "dsl = dimcli.Dsl()\n",
    "\n",
    "\n",
    "import json \n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import numpy as np\n",
    "from tqdm import tnrange, tqdm_notebook as bar\n",
    "from time import sleep\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Background: understanding the data model\n",
    "\n",
    "In order to process researchers affiliation data in the context of publications, we should first take the time to understand how this data is structured in Dimensions. \n",
    "\n",
    "The JSON results of any query with shape  `search publications where .... return publications` are composed by a list of publications. If we open up one single publication record we will immediately see that authors are stored in a nested object `authors` that contains a list of dictionaries. Each element in this dictionary represents **one single publication author** and includes other information e.g. name, surname, ID, the organizations he/she is affiliated with etc..\n",
    "\n",
    "For example, in order to extract the second author of the tenth publication from our results we would do the following: `results.publications[10]['authors'][1]`: \n",
    "\n",
    "```\n",
    "# author info\n",
    "...\n",
    "    {'first_name': 'Noboru',\n",
    "     'last_name': 'Sebe',\n",
    "     'orcid': '',\n",
    "     'current_organization_id': 'grid.258806.1',\n",
    "     'researcher_id': 'ur.010647607673.28',\n",
    "     'affiliations': [{'id': 'grid.258806.1',\n",
    "       'name': 'Kyushu Institute of Technology',\n",
    "       'city': 'Kitakyushu',\n",
    "       'city_id': 1859307,\n",
    "       'country': 'Japan',\n",
    "       'country_code': 'JP',\n",
    "       'state': None,\n",
    "       'state_code': None}]}\n",
    " ...\n",
    "```\n",
    "\n",
    "\n",
    "Here's a object model diagram summing up how data is structured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://api-sample-data.dimensions.ai/diagrams/data_model_researchers_publications1.v2.jpg\" width=\"800\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://api-sample-data.dimensions.ai/diagrams/data_model_researchers_publications1.v2.jpg\", width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "There are a few important things to keep in mind: \n",
    "\n",
    "* **Publication Authors VS Researchers**. In Dimensions, publication authors don't necessarily have a `researcher` ID (eg because they haven't been disambiguated yet). So a publication may have N authors (stored in JSON  within the `authors` key), but only a subset of these include a `researcher_id` link. PS see also the [searching for researchers](https://docs.dimensions.ai/dsl/language.html#searching-for-researchers-authors) section of the API docs for more info on this topic.\n",
    "* **Time of the affiliation**. Researchers can be affiliated to a specific GRID organization either *at the time of speaking* (now), **or** *at the time of writing* (i.e. when the article was published). The DSL uses different properties to express this fact: `current_research_org` or simply `research_orgs`. For the sake of this exercise, we will look at both.\n",
    "* **Denormalized fields**. Both the [Publication](https://docs.dimensions.ai/dsl/data-sources.html#publications) and [Researcher](https://docs.dimensions.ai/dsl/data-sources.html#researchers) sources include a `research_orgs` field - both are 'denormalized' shortcut versions of the data you'd find via the `authors` structure in publications. However they don't have the same meaning: for publications, the field contains the sum of all authors' research organizations, while for researchers, that's the sum of all research organizations a single individual has been affiliated to throught his career (as far as Dimensions knows, of course!). \n",
    "\n",
    "So, in the real world we often have scenarios like the following one:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://api-sample-data.dimensions.ai/diagrams/data_model_researchers_publications2.v2.jpg\" width=\"1000\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://api-sample-data.dimensions.ai/diagrams/data_model_researchers_publications2.v2.jpg\", width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Methodology: two options available\n",
    "\n",
    "It turns out that there are two possible ways to extract these data, depending on whether we start our queries from Publications or from Researchers. \n",
    "\n",
    "1. **Starting from the Publication source**, we can first filter publications based on our constraints (eg year range [2013-2018] and research_orgs=\"grid.258806.1\" - but it could be any other query parameters); second, we would loop over all of these publications so to extract all relevant reasearchers using the `affiliation` data. \n",
    "2. **Starting from the Researcher source**, we would first filter researchers based on our constraints (eg with research_orgs=\"grid.258806.1\"); second, we would search for publications linked to these researchers, which have been published in the time frame [2013-2018]; lastly, we extract all relevant reasearchers using the `affiliation` data. \n",
    "\n",
    "As we will find out later, both approaches are perfectly valid and return the same results. \n",
    "\n",
    "The first apporach is generally quicker as it has only two steps (the second one has threed). \n",
    "\n",
    "In real world situations though, deciding which approach is best depends on the specific query filters being used and on the impact these filters have on the overall performance/speed of the data extraction. There is no fixed rule and a bit of trial & error can go a long way in helping you optimize your data extraction algorithm!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Approach 1. From publications to researchers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Starting from the _publications_ source, the steps are as follows:\n",
    "\n",
    "1. Filtering publications for year range [2013-2018] and research_orgs=\"grid.258806.1\"\n",
    "    * i.e. `search publications where year in [2013:2018] and research_orgs=\"grid.258806.1\" return publications`\n",
    "2. Looping over publications' authors and extracting relevant researchers\n",
    "    * if `['current_organization_id'] == \"grid.258806.1\"`\n",
    "        * => **that gives us the affiliations at the time of speaking**\n",
    "    * or if `['affiliation']['id'] == \"grid.258806.1\"` \n",
    "        * => **that gives us the affiliations at the time of publishing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "First off, we can to get all publications based on our search criteria by using a `loop` query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration with limit=500 skip=0 ...\n",
      "0-28 / 28 (0.54s)\n",
      "===\n",
      "Records extracted: 28\n"
     ]
    }
   ],
   "source": [
    "pubs = dsl.query_iterative(f\"\"\"search publications \n",
    "                                where year in {YEARS} and research_orgs=\"{GRIDID}\" \n",
    "                            return publications[id+title+doi+year+type+authors+journal+issue+volume]\"\"\",\n",
    "                          limit = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Researchers affiliated to the GRID-ID **at the time of writing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "First we want to know how many researchers linked to these publications were affiliated to the GRID organization *when the publication was created* (note: they may be at at a different institution right now). \n",
    "\n",
    "The affiliation data in publications represent exactly that: we can thus loop over them (for each publication/researcher) and keep only the ones matching our GRID ID. \n",
    "\n",
    "**TIP** affiliations can be extracted easily thanks one of the 'dataframe' transformation methods in [Dimcli](https://github.com/digital-science/dimcli): `as_dataframe_authors_affiliations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "Researchers with affiliation to grid.420434.5 at time of writing: 1 \n",
      "===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aff_name</th>\n",
       "      <th>aff_id</th>\n",
       "      <th>aff_city</th>\n",
       "      <th>aff_city_id</th>\n",
       "      <th>aff_country</th>\n",
       "      <th>aff_country_code</th>\n",
       "      <th>aff_state</th>\n",
       "      <th>aff_state_code</th>\n",
       "      <th>researcher_id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States Department of the Navy</td>\n",
       "      <td>grid.420434.5</td>\n",
       "      <td>Arlington</td>\n",
       "      <td>4.74471e+06</td>\n",
       "      <td>United States</td>\n",
       "      <td>US</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>US-VA</td>\n",
       "      <td></td>\n",
       "      <td>David A.</td>\n",
       "      <td>Lankford</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               aff_name         aff_id   aff_city  \\\n",
       "2  United States Department of the Navy  grid.420434.5  Arlington   \n",
       "\n",
       "   aff_city_id    aff_country aff_country_code aff_state aff_state_code  \\\n",
       "2  4.74471e+06  United States               US  Virginia          US-VA   \n",
       "\n",
       "  researcher_id first_name last_name  \n",
       "2                 David A.  Lankford  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract affiliations from a publications list\n",
    "affiliations = pubs.as_dataframe_authors_affiliations()\n",
    "# select only affiliations for GRIDID\n",
    "authors_historical = affiliations[affiliations['aff_id'] == GRIDID].copy()\n",
    "# remove duplicates by eliminating publication-specific data\n",
    "authors_historical.drop(columns=['pub_id'], inplace=True)\n",
    "authors_historical.drop_duplicates('researcher_id', inplace=True)\n",
    "print(f\"===\\nResearchers with affiliation to {GRIDID} at time of writing:\", authors_historical.researcher_id.nunique(), \"\\n===\")\n",
    "# preview the data\n",
    "authors_historical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Note:\n",
    "* The first 'publication-affiliations' dataframe we get may contain duplicate records - eg if an author has more than one publication it'll be listed twice. That's why we have an extra step where we drop the `pub_id` column and  simply count unique researchers, based on their researcher ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Researchers affiliated to the GRIDID **at the time of speaking** ie now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "This can be achieved simply by taking into consideration a different field, called `current_organization_id`, available at the outer level of the JSON author structure (see the data model section above) - outside the `affiliations` list. \n",
    "\n",
    "Luckily Dimcli includes another handy method for umpacking authors into a dataframe: `as_dataframe_authors` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'current_organization_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/Envs/jupyterlab/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'current_organization_id'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-e1570f26d390>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mauthors_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpubs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dataframe_authors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mauthors_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauthors_current\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauthors_current\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'current_organization_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGRIDID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mauthors_current\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pub_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mauthors_current\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'researcher_id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"===\\nResearchers with affiliation to {GRIDID} at the time of speaking:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthors_current\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresearcher_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/jupyterlab/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/jupyterlab/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'current_organization_id'"
     ]
    }
   ],
   "source": [
    "authors_current = pubs.as_dataframe_authors()\n",
    "authors_current = authors_current[authors_current['current_organization_id'] == GRIDID].copy()\n",
    "authors_current.drop(columns=['pub_id'], inplace=True)\n",
    "authors_current.drop_duplicates('researcher_id', inplace=True)\n",
    "print(f\"===\\nResearchers with affiliation to {GRIDID} at the time of speaking:\", authors_current.researcher_id.nunique(), \"\\n===\")\n",
    "authors_current"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Approach 2. From researchers to publications\n",
    "\n",
    "Using this approach, we start our search from the 'researchers' database (instead of the 'publications' database). \n",
    "\n",
    "There are 3 main steps:\n",
    "\n",
    "1. Filtering researchers with research_orgs=GRID-ID (note: this gives us affiliated researches *at any point in time*)\n",
    "    * `search researchers where research_orgs=\"grid.258806.1\" return researchers`\n",
    "2. Searching for publications linked to these researchers and linked to GRID-ID, which have been published in the time frame `[2013-2018]`\n",
    "    * `search publications where researchers.id in {LIST OF IDS} and year in [2013:2018] and research_orgs=\"grid.258806.1\" return publications`\n",
    "    * NOTE: this a variation of the Approach-1 query above: we have just added the researchers IDs filter (thus reducing the search space)\n",
    "3. Extracting relevant researchers from publications, using the same exact steps as in approach 1 above.\n",
    "    * if `['current_organization_id'] == \"grid.258806.1\"`\n",
    "        * => **that gives us the affiliations at the time of speaking**\n",
    "    * or if `['affiliation']['id'] == \"grid.258806.1\"` \n",
    "        * => **that gives us the affiliations at the time of publishing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "q = f\"\"\"search researchers where research_orgs=\"{GRIDID}\" \n",
    "        return researchers[basics]\"\"\"\n",
    "researchers_json = dsl.query_iterative(q)\n",
    "researchers = researchers_json.as_dataframe()\n",
    "researchers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Now we need to select only the researchers who have **published in the time frame [2013:2018]**. So for each researcher ID we must extract the full publication history in order to verify their relevance. \n",
    "\n",
    "The most efficient way to do this is to use a query that **extracts the publication history for several researchers at the same time** (so to avoid overruning our API quota), then, as a second step, producing a clean list of relevant researchers from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "researchers_ids = list(researchers['id'])\n",
    "# no of researchers IDs per query: so to ensure we never hit the 1000 records limit per query\n",
    "CHUNKS_SIZE = 300 \n",
    "\n",
    "q = \"\"\"search publications \n",
    "                where researchers.id in {}\n",
    "                and year in {}\n",
    "                and research_orgs=\"{}\"\n",
    "            return publications[id+title+doi+year+type+authors+journal+issue+volume] limit 1000\"\"\"\n",
    "\n",
    "\n",
    "for chunk in chunks_of(researchers_ids, size=CHUNKS_SIZE):\n",
    "    data = dsl.query(q.format(json.dumps(chunk), YEARS, GRIDID))\n",
    "    try:\n",
    "        results += data.publications\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"---\\nFound\", len(results), \"publications for the given criteria (including duplicates)\")\n",
    "\n",
    "# simulate a DSL payload using Dimcli\n",
    "pubs_v2 = dimcli.DslDataset.from_publications_list(results)\n",
    "\n",
    "# transform to a dataframe to remove duplicates quickly\n",
    "pubs_v2_df = pubs_v2.as_dataframe()\n",
    "pubs_v2_df.drop_duplicates(\"id\", inplace=True)\n",
    "print(\"Final result:\", len(pubs_v2_df), \"unique publications\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Researchers affiliated to the GRID-ID **at the time of writing**\n",
    "This step is basically the same as in approach 1 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# extract affiliations from a publications list\n",
    "affiliations_v2 = pubs_v2.as_dataframe_authors_affiliations()\n",
    "# select only affiliations for GRIDID\n",
    "authors_historical_v2 = affiliations_v2[affiliations_v2['aff_id'] == GRIDID].copy()\n",
    "# remove duplicates by eliminating publication-specific data\n",
    "authors_historical_v2.drop(columns=['pub_id'], inplace=True)\n",
    "authors_historical_v2.drop_duplicates('researcher_id', inplace=True)\n",
    "print(f\"===\\nResearchers with affiliation to {GRIDID} at time of writing:\", authors_historical_v2.researcher_id.nunique(), \"\\n===\")\n",
    "# preview the data\n",
    "authors_historical_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Researchers affiliated to the GRIDID **at the time of speaking** ie now\n",
    "\n",
    "Also here, the procedure is exactly the same as in approach 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "authors_current_v2 = pubs_v2.as_dataframe_authors()\n",
    "authors_current_v2 = authors_current_v2[authors_current_v2['current_organization_id'] == GRIDID].copy()\n",
    "authors_current_v2.drop(columns=['pub_id'], inplace=True)\n",
    "authors_current_v2.drop_duplicates('researcher_id', inplace=True)\n",
    "print(f\"===\\nResearchers with affiliation to {GRIDID} at the time of speaking:\", authors_current_v2.researcher_id.nunique(), \"\\n===\")\n",
    "authors_current_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "As anticipated above, **both approaches are equally valid** and in fact they return the same (or very similar) number of results. Let's compare them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# create summary table \n",
    "data = [['1', len(authors_current), len(authors_historical),\n",
    "         \"\"\"search publications where year in [2013:2018] and research_orgs=\"grid.258806.1\" return publication\"\"\", \n",
    "         ], \n",
    "        ['2', len(authors_current_v2), len(authors_historical_v2),\n",
    "         \"\"\"search researchers where research_orgs=\"grid.258806.1\" return researchers --- then --- search publications where researchers.id in {IDS} and year in [2013:2018] and research_orgs={GRIDID} return publications\"\"\",\n",
    "        ]] \n",
    "   \n",
    "pd.DataFrame(data, columns = ['Method', 'Authors (current)', 'Authors (historical)',  'Query']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "#### Why are the total counts different? \n",
    "\n",
    "In some cases you might encounter small differences in the total number of records returned by the two approaches (eg one method returns 1-2 extra records than the other one). \n",
    "\n",
    "This is usually due to a synchronization delay between Dimensions databases (e.g. publications and researchers). The differences are negligible in most cases, but in general it's enough to run same extraction again after a day or two for the problem to disappear.  \n",
    "\n",
    "#### So which method should I choose?  \n",
    "\n",
    "It depends on which/how many filters are being used in order to identify a suitable results set for your research question. \n",
    "\n",
    "* The first approach is generally quicker as it has only two steps, as opposed to the second method that has three. \n",
    "* However if your initial `publications` query returns lots of results (eg for a large institution or big time frame), it may be quicker to try out method 2 instead. \n",
    "* The second approach can be handy if one wants to pre-filter researchers using one of the [ther available properties](https://docs.dimensions.ai/dsl/data-sources.html#researchers) (e.g. `last_grant_year`)\n",
    "\n",
    "So, in general, deciding which approach is best depends on the specific query filters being used and on the impact these filters have on the overall performance/speed of the data extraction. \n",
    "\n",
    "There is no fixed rule and a bit of trial & error can go a long way in helping you optimize your data extraction algorithm!"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "0.14.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
