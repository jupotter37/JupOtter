{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Pacakges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from MDNet.utils import Options, overlap_ratio\n",
    "from MDNet.models.mdnet import MDNet, BCELoss\n",
    "from MDNet.models.extractor import SampleGenerator, RegionExtractor\n",
    "from MDNet.models.regressor import BBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_samples(model, image, samples, opts, out_layer='conv3'):\n",
    "    model.eval()\n",
    "    extractor = RegionExtractor(image, samples, opts.img_size, opts.padding, opts.batch_test)\n",
    "\n",
    "    for i, regions in enumerate(extractor):\n",
    "        if opts.use_gpu:\n",
    "            regions = regions.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            feat = model(regions, out_layer=out_layer)\n",
    "\n",
    "        feats = torch.cat((feats, feat.detach().clone()), 0) if i else feat.detach().clone()\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDNet Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer,\n",
    "          pos_feats, neg_feats, maxiter, opts,\n",
    "          in_layer='fc4'):\n",
    "    model.train()\n",
    "\n",
    "    batch_pos = opts.batch_pos\n",
    "    batch_neg = opts.batch_neg\n",
    "    batch_test = opts.batch_test\n",
    "    batch_neg_cand = max(opts.batch_neg_cand, batch_neg)\n",
    "\n",
    "    pos_idx = np.random.permutation(pos_feats.size(0))\n",
    "    neg_idx = np.random.permutation(neg_feats.size(0))\n",
    "\n",
    "    while len(pos_idx) < batch_pos * maxiter:\n",
    "        pos_idx = np.concatenate([pos_idx, np.random.permutation(pos_feats.size(0))])\n",
    "\n",
    "    while len(neg_idx) < batch_neg_cand * maxiter:\n",
    "        neg_idx = np.concatenate([neg_idx, np.random.permutation(neg_feats.size(0))])\n",
    "\n",
    "    pos_pointer = 0\n",
    "    neg_pointer = 0\n",
    "\n",
    "    for _ in range(maxiter):\n",
    "\n",
    "        # select pos idx\n",
    "        pos_next = pos_pointer + batch_pos\n",
    "        pos_cur_idx = pos_idx[pos_pointer:pos_next]\n",
    "        pos_cur_idx = pos_feats.new(pos_cur_idx).long()\n",
    "        pos_pointer = pos_next\n",
    "\n",
    "        # select neg idx\n",
    "        neg_next = neg_pointer + batch_neg_cand\n",
    "        neg_cur_idx = neg_idx[neg_pointer:neg_next]\n",
    "        neg_cur_idx = neg_feats.new(neg_cur_idx).long()\n",
    "        neg_pointer = neg_next\n",
    "\n",
    "        # create batch\n",
    "        batch_pos_feats = pos_feats[pos_cur_idx]\n",
    "        batch_neg_feats = neg_feats[neg_cur_idx]\n",
    "\n",
    "        # hard negative mining\n",
    "        if batch_neg_cand > batch_neg:\n",
    "            model.eval()\n",
    "\n",
    "            for start in range(0, batch_neg_cand, batch_test):\n",
    "                end = min(start + batch_test, batch_neg_cand)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    score = model(batch_neg_feats[start:end], in_layer=in_layer)\n",
    "\n",
    "                if start == 0:\n",
    "                    neg_cand_score = score.detach()[:, 1].clone()\n",
    "                else:\n",
    "                    neg_cand_score = torch.cat((neg_cand_score, score.detach()[:, 1].clone()), 0)\n",
    "\n",
    "            _, top_idx = neg_cand_score.topk(batch_neg)\n",
    "            batch_neg_feats = batch_neg_feats[top_idx]\n",
    "            model.train()\n",
    "\n",
    "        # forward\n",
    "        pos_score = model(batch_pos_feats, in_layer=in_layer)\n",
    "        neg_score = model(batch_neg_feats, in_layer=in_layer)\n",
    "\n",
    "        # optimize\n",
    "        loss = criterion(pos_score, neg_score)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), opts.grad_clip)\n",
    "\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function for MDNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(images, init_bbox, ground_truths, opts):\n",
    "    device = ('cuda' if opts.use_gpu else 'cpu')\n",
    "\n",
    "    model = MDNet(opts.model_path).to(device)\n",
    "\n",
    "    criterion = BCELoss()\n",
    "\n",
    "    # Set learnable parameters\n",
    "    for k, p in model.params.items():\n",
    "        p.requires_grad = any([k.startswith(l) for l in opts.ft_layers])\n",
    "\n",
    "    # Set optimizer states\n",
    "    def set_optimizer(lr_base, lr_mult, momentum=0.9, w_decay=0.0005):\n",
    "        param_list = []\n",
    "\n",
    "        for k, p in filter(lambda kp: kp[1].requires_grad, model.params.items()):\n",
    "            lr = lr_base\n",
    "            for l, m in lr_mult.items():\n",
    "                if k.startswith(l):\n",
    "                    lr = lr_base * m\n",
    "            param_list.append({'params': [p], 'lr': lr})\n",
    "\n",
    "        return optim.SGD(param_list, lr=lr, momentum=momentum, weight_decay=w_decay)\n",
    "\n",
    "    init_optimizer = set_optimizer(opts.lr_init, opts.lr_mult)\n",
    "    update_optimizer = set_optimizer(opts.lr_update, opts.lr_mult)\n",
    "\n",
    "    # Load first image\n",
    "    image = Image.open(images[0]).convert('RGB')\n",
    "\n",
    "    # Draw pos/neg samples\n",
    "    pos_examples = SampleGenerator('gaussian', image.size, opts.trans_pos, opts.scale_pos)(\n",
    "        init_bbox, opts.n_pos_init, opts.overlap_pos_init)\n",
    "\n",
    "    neg_examples = np.concatenate([\n",
    "        SampleGenerator('uniform', image.size, opts.trans_neg_init, opts.scale_neg_init)(\n",
    "            init_bbox, int(opts.n_neg_init * 0.5), opts.overlap_neg_init),\n",
    "        SampleGenerator('whole', image.size)(\n",
    "            init_bbox, int(opts.n_neg_init * 0.5), opts.overlap_neg_init)])\n",
    "    neg_examples = np.random.permutation(neg_examples)\n",
    "\n",
    "    # Extract pos/neg features\n",
    "    pos_feats = forward_samples(model, image, pos_examples, opts)\n",
    "    neg_feats = forward_samples(model, image, neg_examples, opts)\n",
    "\n",
    "    # Initial training\n",
    "    train(model, criterion, init_optimizer, pos_feats, neg_feats, opts.maxiter_init, opts)\n",
    "    del init_optimizer, neg_feats\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Train bbox regressor\n",
    "    bbreg_examples = SampleGenerator('uniform', image.size, opts.trans_bbreg, opts.scale_bbreg, opts.aspect_bbreg)\\\n",
    "        (init_bbox, opts.n_bbreg, opts.overlap_bbreg)\n",
    "\n",
    "    bbreg_feats = forward_samples(model, image, bbreg_examples, opts)\n",
    "    bbreg = BBRegressor(image.size)\n",
    "    bbreg.train(bbreg_feats, bbreg_examples, init_bbox)\n",
    "    del bbreg_feats\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Init sample generators for update\n",
    "    sample_generator = SampleGenerator('gaussian', image.size, opts.trans, opts.scale)\n",
    "    pos_generator = SampleGenerator('gaussian', image.size, opts.trans_pos, opts.scale_pos)\n",
    "    neg_generator = SampleGenerator('uniform', image.size, opts.trans_neg, opts.scale_neg)\n",
    "\n",
    "    # Init pos/neg features for update\n",
    "    neg_examples = neg_generator(init_bbox, opts.n_neg_update, opts.overlap_neg_init)\n",
    "    neg_feats = forward_samples(model, image, neg_examples, opts)\n",
    "    pos_feats_all = [pos_feats]\n",
    "    neg_feats_all = [neg_feats]\n",
    "\n",
    "    # Main loop\n",
    "    for i, image in enumerate(images[1:], 1):\n",
    "        image = Image.open(image).convert('RGB')\n",
    "\n",
    "        # Estimate target bbox\n",
    "        samples = sample_generator(init_bbox, opts.n_samples)\n",
    "        sample_scores = forward_samples(model, image, samples, opts, out_layer='fc6')\n",
    "\n",
    "        top_scores, top_idx = sample_scores[:, 1].topk(5)\n",
    "        top_idx = top_idx.cpu()\n",
    "        target_score = top_scores.mean()\n",
    "        init_bbox = samples[top_idx]\n",
    "        if top_idx.shape[0] > 1:\n",
    "            init_bbox = init_bbox.mean(axis=0)\n",
    "        success = target_score > 0\n",
    "\n",
    "        # Expand search area at failure\n",
    "        sample_generator.trans = opts.trans if success else min(sample_generator.trans * 1.1, opts.trans_limit)\n",
    "\n",
    "        # Bbox regression\n",
    "        if success:\n",
    "            bbreg_samples = samples[top_idx]\n",
    "\n",
    "            if top_idx.shape[0] == 1:\n",
    "                bbreg_samples = bbreg_samples[None, :]\n",
    "\n",
    "            bbreg_feats = forward_samples(model, image, bbreg_samples, opts)\n",
    "            bbreg_samples = bbreg.predict(bbreg_feats, bbreg_samples)\n",
    "            bbreg_bbox = bbreg_samples.mean(axis=0)\n",
    "\n",
    "        else:\n",
    "            bbreg_bbox = init_bbox\n",
    "\n",
    "        yield init_bbox, bbreg_bbox, overlap_ratio(ground_truths[i], bbreg_bbox)[0], target_score\n",
    "\n",
    "        # Data collect\n",
    "        if success:\n",
    "            pos_examples = pos_generator(init_bbox, opts.n_pos_update, opts.overlap_pos_update)\n",
    "            pos_feats = forward_samples(model, image, pos_examples, opts)\n",
    "            pos_feats_all.append(pos_feats)\n",
    "\n",
    "            if len(pos_feats_all) > opts.n_frames_long:\n",
    "                del pos_feats_all[0]\n",
    "\n",
    "            neg_examples = neg_generator(init_bbox, opts.n_neg_update, opts.overlap_neg_update)\n",
    "            neg_feats = forward_samples(model, image, neg_examples, opts)\n",
    "            neg_feats_all.append(neg_feats)\n",
    "\n",
    "            if len(neg_feats_all) > opts.n_frames_short:\n",
    "                del neg_feats_all[0]\n",
    "\n",
    "        # Short term update\n",
    "        if not success:\n",
    "            nframes = min(opts.n_frames_short, len(pos_feats_all))\n",
    "            pos_data = torch.cat(pos_feats_all[-nframes:], 0)\n",
    "            neg_data = torch.cat(neg_feats_all, 0)\n",
    "            train(model, criterion, update_optimizer, pos_data, neg_data, opts.maxiter_update, opts)\n",
    "\n",
    "        # Long term update\n",
    "        elif i % opts.long_interval == 0:\n",
    "            pos_data = torch.cat(pos_feats_all, 0)\n",
    "            neg_data = torch.cat(neg_feats_all, 0)\n",
    "            train(model, criterion, update_optimizer, pos_data, neg_data, opts.maxiter_update, opts)\n",
    "\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Refresh image output in IPython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fafcbd6be70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 4. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a51b1604db58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Run tracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3d13bf9c0cc6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(images, init_bbox, ground_truths, opts)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mbbreg_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbreg_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mbbreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mbbreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbreg_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbreg_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_bbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mbbreg_feats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/c/Users/maybe/Documents/Workspace/Deeplearning-Practice/6-Tracking/MDNet/models/regressor.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, bbox, gt)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/lib/python3.7/site-packages/sklearn/linear_model/ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \"\"\"\n\u001b[0;32m--> 747\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/lib/python3.7/site-packages/sklearn/linear_model/ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    545\u001b[0m                          \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_accept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                          \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                          multi_output=True, y_numeric=True)\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         if ((sample_weight is not None) and\n",
      "\u001b[0;32m~/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 539\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "options.use_gpu = False\n",
    "dataset = Path('../data/OTB/DragonBaby')\n",
    "\n",
    "images = list(sorted(dataset.joinpath('img').glob('*.jpg')))\n",
    "ground_truths = pd.read_csv(str(dataset.joinpath('groundtruth_rect.txt')), header=None).values\n",
    "\n",
    "iou, success = 0, 0\n",
    "\n",
    "# Run tracker\n",
    "for i, (result, (x, y, w, h), overlap, score) in \\\n",
    "        enumerate(main(images, ground_truths[0], ground_truths, options), 1):\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    image = np.asarray(Image.open(images[i]).convert('RGB'))\n",
    "\n",
    "    gx, gy, gw, gh = ground_truths[i]\n",
    "    cv2.rectangle(image, (int(gx), int(gy)), (int(gx+gw), int(gy+gh)), (0, 255, 0), 2)\n",
    "    cv2.rectangle(image, (int(x), int(y)), (int(x+w), int(y+h)), (255, 0, 0), 2)\n",
    "\n",
    "    iou += overlap\n",
    "    success += overlap > .5\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.pause(.1)\n",
    "    plt.title(f'#{i}/{len(images)-1}, Overlap {overlap:.3f}, Score {score:.3f}')\n",
    "    plt.draw()\n",
    "\n",
    "iou /= len(images) - 1\n",
    "print(f'Mean IOU: {iou:.3f}, Success: {success} / {len(images)-1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
