{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   }
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nAuthor: Eric McCullough\\nFile: composite_frame \\nTrello: Goal 1 \\n'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Author: Eric McCullough\n",
    "File: composite_frame \n",
    "Trello: Goal 1 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Composite_Frame(object):\n",
    "    '''\n",
    "    The Composite_Frame class takes a pandas data frame containing network flow\n",
    "    information and splits into a list of frames, each representing the telemtry\n",
    "    of the network at a given time interval. \n",
    "    Dataset used: BoT IoT Dataset (10 best features CSV) \n",
    "    '''\n",
    "\n",
    "    def __init__(self, frame: pd.DataFrame, interval: int, max_frames: int = -1):\n",
    "        '''\n",
    "        Instance variables:\n",
    "            @self.items -> The list of dataframes derived from the parent frame\n",
    "            @self._interval -> The time interval to split the parent frame on\n",
    "            @self.max_frames -> The maximum number of time frames to include in\n",
    "                the composite frame. Default is set to 10,000\n",
    "        '''\n",
    "        if max_frames < 0:\n",
    "            self.max_frames = 10000\n",
    "        else:\n",
    "            self.max_frames = max_frames\n",
    "\n",
    "        self.items: List[pd.DataFrame] = self._split_frame(frame, interval)\n",
    "        self._interval = interval\n",
    "\n",
    "    def _insert_row(self, row_number: int, df: pd.DataFrame, row_value):\n",
    "        '''\n",
    "        Borrowed this function from the following Geeks for Geeks \n",
    "        article: https://www.geeksforgeeks.org/insert-row-at-given-position-in-pandas-dataframe/\n",
    "        '''\n",
    "        # Split old dataframe\n",
    "        df1 = df[0:row_number]\n",
    "        df2 = df[row_number:]\n",
    "\n",
    "        # Add new row to first subframe\n",
    "        df1.loc[row_number] = row_value\n",
    "\n",
    "        # Create new dataframe from two subframes\n",
    "        df_result = pd.concat([df1, df2])\n",
    "        df_result.index = [*range(df_result.shape[0])]\n",
    "\n",
    "        return df_result\n",
    "\n",
    "    def _split_flow(self, df: pd.DataFrame, index: int, interval: int, min_stime: int, max_ltime: int):\n",
    "        # Insert a copy of the new row at the appropriate place in the df\n",
    "        row = df.iloc[index]\n",
    "        try:    # Attempt to acquire insert index\n",
    "            insert_index = df[df.stime > max_ltime].index[0]\n",
    "        except:  # Attempt failed, insert index should be end of dataframe\n",
    "            insert_index = -1\n",
    "\n",
    "        if insert_index >= 0:\n",
    "            df = self._insert_row(int(insert_index), df, row)\n",
    "        else:\n",
    "            insert_index = df.shape[0]\n",
    "            df.loc[insert_index] = row\n",
    "\n",
    "        # Calculate percent of the flow which is in the current window\n",
    "        percent_in_frame = (max_ltime-row.stime)/(row.ltime-row.stime)\n",
    "\n",
    "        # Adjust values for the original flow\n",
    "        df.at[index, 'ltime'] = max_ltime\n",
    "        df.at[index, 'TnBPSrcIP'] = row.TnBPSrcIP*percent_in_frame\n",
    "\n",
    "        # Adjust values for the new flowl\n",
    "        df.at[insert_index, 'stime'] = max_ltime\n",
    "        df.at[insert_index, 'TnBPSrcIP'] = row.TnBPSrcIP * \\\n",
    "            (1.-percent_in_frame)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _process_flow(self, current_stime, min_stime, current_ltime, max_ltime, current_frame, traffic, index, interval):\n",
    "        if current_stime >= min_stime and current_ltime < max_ltime:\n",
    "            current_frame.append(traffic.iloc[index])\n",
    "\n",
    "        elif current_stime >= min_stime and current_stime < max_ltime and \\\n",
    "                current_ltime >= max_ltime:\n",
    "            traffic = self._split_flow(\n",
    "                traffic, index, interval, min_stime, max_ltime)\n",
    "            current_frame.append(traffic.iloc[index])\n",
    "\n",
    "        return traffic, current_frame\n",
    "\n",
    "    def _split_frame(self, df: pd.DataFrame, interval: int):\n",
    "        # Order the data frame by start time\n",
    "        traffic = df.sort_values(by=['stime']).reset_index()\n",
    "        traffic = traffic.filter(['saddr', 'stime', 'ltime', 'TnBPSrcIP'])\n",
    "\n",
    "        # Variables for tracking the progress of the function\n",
    "        progress = 0.\n",
    "\n",
    "        # Loop Variables\n",
    "        index = 0\n",
    "        time_frames = []                    # list to hold subframes\n",
    "        current_frame = []                  # Current data frame being populated\n",
    "        # Starting point of current time frame\n",
    "        min_stime = traffic.iloc[0].stime\n",
    "        max_ltime = min_stime + interval    # ending point of current time frame\n",
    "\n",
    "        # Main loop\n",
    "        while not traffic.empty:\n",
    "            # Find start and end time of current flow\n",
    "            current_stime, current_ltime = traffic.iloc[index].stime, traffic.iloc[index].ltime\n",
    "\n",
    "            if current_stime < max_ltime:\n",
    "                traffic, current_frame = self._process_flow(current_stime, min_stime, current_ltime,\n",
    "                                                            max_ltime, current_frame, traffic, index, interval)\n",
    "\n",
    "            else:\n",
    "                # Update loop variables\n",
    "                current_frame = pd.DataFrame(current_frame)\n",
    "                current_frame = current_frame.filter(['saddr', 'TnBPSrcIP']).groupby(\n",
    "                    'saddr').sum().reset_index()\n",
    "                time_frames.append(current_frame)\n",
    "\n",
    "                # If the upper limit of frames to add has been reached, break the loop\n",
    "                if len(time_frames) >= self.max_frames:\n",
    "                    break\n",
    "\n",
    "                current_frame = []\n",
    "                min_stime = traffic.iloc[index].stime\n",
    "                max_ltime = min_stime + interval\n",
    "\n",
    "                traffic, current_frame = self._process_flow(current_stime, min_stime, current_ltime,\n",
    "                                                            max_ltime, current_frame, traffic, index, interval)\n",
    "\n",
    "            # If sufficient progress has been made, update the user via print\n",
    "            percent_done = (index+1) / traffic.shape[0]\n",
    "            if percent_done - progress >= 0.05:\n",
    "                progress = percent_done\n",
    "                print('Progress: {:.2f}%'.format(percent_done * 100))\n",
    "\n",
    "            traffic = traffic.drop(index, axis=0)\n",
    "\n",
    "            if traffic.empty:\n",
    "                continue\n",
    "            elif traffic.index.values[0] != 0:\n",
    "                traffic.index = range(len(traffic.index))\n",
    "\n",
    "        current_frame = pd.DataFrame(current_frame)\n",
    "        time_frames.append(current_frame)\n",
    "        current_frame = current_frame.filter(['saddr', 'TnBPSrcIP']).groupby(\n",
    "            'saddr').sum().reset_index()\n",
    "\n",
    "        return time_frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/SGF.EDUBEAR.NET/eam96/Net_Sentinel/All features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1669b71ca162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcsv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'All features'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mli\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcsv_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     flow_df = pd.read_csv(file, usecols=['pkSeqID', 'stime', 'proto', 'saddr', \n\u001b[1;32m      5\u001b[0m                                          \u001b[0;34m'sport'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'daddr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dport'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'attack'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/eric/lib/python3.7/pathlib.py\u001b[0m in \u001b[0;36miterdir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'..'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m                 \u001b[0;31m# Yielding a path object for these makes little sense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/SGF.EDUBEAR.NET/eam96/Net_Sentinel/All features'"
     ]
    }
   ],
   "source": [
    "csv_path = Path.cwd() / 'All features'\n",
    "li = []\n",
    "for file in csv_path.iterdir():\n",
    "    flow_df = pd.read_csv(file, usecols=['pkSeqID', 'stime', 'proto', 'saddr', \n",
    "                                         'sport', 'daddr', 'dport', 'attack', \n",
    "                                         'category', 'subcategory', 'TnBPSrcIP', \n",
    "                                         'ltime'],\n",
    "\n",
    "                          dtype={'pkSeqID': np.int, 'stime': np.float, 'proto': str,\n",
    "                                 'saddr': str, 'sport': str, 'daddr': str, 'dport': str,\n",
    "                                 'attack': bool, 'category': str, 'subcategory': str, \n",
    "                                 'TnBPSrcIP': np.int64, 'ltime': np.float}\n",
    "                            )\n",
    "\n",
    "    li.append(flow_df)\n",
    "\n",
    "df = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b95571faa2de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclean_traffic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclean_traffic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_traffic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclean_traffic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproto\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tcp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "clean_traffic = df[df.attack == False]\n",
    "clean_traffic = clean_traffic[clean_traffic.proto == 'tcp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_composite = Composite_Frame(clean_traffic, 60)"
   ]
  }
 ]
}