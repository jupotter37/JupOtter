{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "import bs4\n",
    "\n",
    "ROOTDIR = os.path.normpath(\"N:\\_archive\\\\test\\\\trans\\soundgasmNET\")\n",
    "df = pd.read_csv(os.path.join(ROOTDIR, \"sgasm_rip_db.csv\"), sep=\";\", encoding=\"utf-8\", index_col=0)\n",
    "df_grp = df.groupby(\"sgasm_user\")\n",
    "\n",
    "url = \"https://soundgasm.net/u/belle_in_the_woods/F4M-The-Take-FdomJOIcountdownteasingwhispers\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing timeits of filtering downloaded urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 7.66 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000 loops, best of 3: 527 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit url in df_grp.get_group(\"belle_in_the_woods\")[\"URLsg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 2.24 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit url in df[df[\"sgasm_user\"] == \"belle_in_the_woods\"][\"URLsg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def t():\n",
    "    df.query(\"sgasm_user == 'belle_in_the_woods'\")[\"URLsg\"].isin([url]).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 2.65 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 39.70 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 9.47 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit url in df[\"URLsg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s_for = [\"https://soundgasm.net/u/belle_in_the_woods/F4M-The-Take-FdomJOIcountdownteasingwhispers\",\n",
    "       \"https://soundgasm.net/u/belle_in_the_woods/F4F-Should-I-Call-intimateerotic-poetry\",\n",
    "       \"https://soundgasm.net/u/belle_in_the_woods/F4M-In-Darkness-FsubErotic-Poetry\",\n",
    "       \"https://soundgasm.net/u/belle_in_the_woods/F4M-Cum-Lust-cock-worshiperotic-poetry\",\n",
    "       \"https://soundgasm.net/u/belle_in_the_woods/F4M-The-Take-FdomJOIcountdownteasingwhispers\",\n",
    "        \"https://soundgasm.net/u/belle_in_the_woods/F4A-Ill-Be-Home-For-Christmas-singinga-capellaChristmas-song\",\n",
    "         \"https://soundgasm.net/u/belle_in_the_woods/F4M-An-Early-Morning-Quickie-GFEvanillakissingmuffled-orgasmgigglesa-little-dirty-talkshort-but-sweet\",\n",
    "         \"https://soundgasm.net/u/belle_in_the_woods/F4M-Turning-Fs-into-As-into-Fsublegal-teenteacherstudentmasturbationblowjobspankingroughanalchokingback-to-school-challenge\",\n",
    "         \"https://soundgasm.net/u/belle_in_the_woods/F4M-Cum-For-Your-Good-Girl-Fsub-a-little-switching-light-Fdomgreedy-for-youbeggingdirty-talkwhisperspossible-ASMRcum-for-merelaxingsoundscape\",\n",
    "         \"http:///spungfsgs.netz/UNIQUE/aknfksd\"]\n",
    "\n",
    "def filter_alrdy_downloaded(df, dl_dict, currentusr=None):\n",
    "    # OLD when passing 2pair tuples, unpack tuples in dl_list into two lists\n",
    "    # url_list, title = zip(*dl_list)\n",
    "    # filter dupes\n",
    "    unique_urls = set(dl_dict)\n",
    "    if currentusr:\n",
    "        try:\n",
    "            duplicate = unique_urls.intersection(df_grp.get_group(currentusr)[\"URLsg\"].values)\n",
    "        except KeyError:\n",
    "            logger.info(\"User '{}' not yet in databas!\".format(currentusr))\n",
    "            duplicate = set()\n",
    "    else:\n",
    "        # timeit 1000: 0.19\n",
    "        duplicate = unique_urls.intersection(df[\"URLsg\"].values)\n",
    "\n",
    "    # set.symmetric_difference()\n",
    "    # Return a new set with elements in either the set or other but not both.\n",
    "    # -> duplicates will get removed from unique_urls\n",
    "    result = list(unique_urls.symmetric_difference(duplicate))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.58 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000 loops, best of 3: 700 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit filter_alrdy_downloaded(df, s_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 303.96 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000 loops, best of 3: 501 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit filter_alrdy_downloaded(df, s_for, currentusr=\"belle_in_the_woods\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "\n",
    "\n",
    "conn = sqlite3.connect(\"N:\\\\_archive\\\\test/trans\\\\soundgasmNET\\\\gwarip_db.sqlite\")\n",
    "c = conn.cursor()\n",
    "c.execute(\"SELECT url_sg FROM Downloads\")\n",
    "url_tupes = c.fetchall()\n",
    "urls = [tupe[0] for tupe in url_tupes]\n",
    "urls_set = set(urls)\n",
    "conn.close()\n",
    "\n",
    "def filter_alrdy_downloaded(df, urls, dled, currentusr=None):\n",
    "    # OLD when passing 2pair tuples, unpack tuples in dl_list into two lists\n",
    "    # url_list, title = zip(*dl_list)\n",
    "    # filter dupes\n",
    "    unique_urls = set(urls)\n",
    "    # using grped df is slightly faster than checking all urls:\n",
    "    # df: 1000 loops, best of 3: 705 µs per loop; grped_df: 1000 loops, best of 3: 488 µs per loop\n",
    "    if currentusr:\n",
    "        try:\n",
    "            c.execute(\"SELECT url_sg FROM Downloads WHERE sgasm_user = ?\", (currentusr,))\n",
    "            usr_urls = [tup[0] for tup in c.fetchall()]\n",
    "            duplicate = unique_urls.intersection(usr_urls)\n",
    "        except KeyError:\n",
    "            print(\"error\")\n",
    "            duplicate = set()\n",
    "    else:\n",
    "        # timeit 1000: 0.19\n",
    "        duplicate = unique_urls.intersection(dled)\n",
    "\n",
    "    dup_titles = \"\\n\".join(duplicate)\n",
    "\n",
    "    # set.symmetric_difference()\n",
    "    # Return a new set with elements in either the set or other but not both.\n",
    "    # -> duplicates will get removed from unique_urls\n",
    "    result = list(unique_urls.symmetric_difference(duplicate))\n",
    "    # str.contains accepts regex patter, join url strings with | -> htt..m4a|htt...m4a etc\n",
    "    # returns Series/array of boolean values, .any() True if any element is True\n",
    "    # timeit 1000: 1.129\n",
    "    # mask = df[\"URL\"].str.contains('|'.join(url_list))\n",
    "    # isin also works\n",
    "    # timeit 1000: 0.29\n",
    "    # mask = df[\"URL\"].isin(unique_urls)\n",
    "    # print(df[\"URL\"][mask])\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 6.72 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000 loops, best of 3: 449 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit urls_set = set(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 304 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit filter_alrdy_downloaded(0, s_for, urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a set instead of a list to hold the downloaded urls is ~80 times faster!!\n",
    "And we only need to do the conversion to a set (that almost takes as long as searching for the url in the list) once at startup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 loops, best of 3: 7.47 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit filter_alrdy_downloaded(0, s_for, urls_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's_for' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c197c91ed5f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timeit filter_alrdy_downloaded(0, s_for, urls_set, currentusr=\"belle_in_the_woods\")'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python3.5\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python3.5\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32mc:\\python3.5\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python3.5\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0mworst_tuning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworst_tuning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\python3.5\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 's_for' is not defined"
     ]
    }
   ],
   "source": [
    "%timeit filter_alrdy_downloaded(0, s_for, urls_set, currentusr=\"belle_in_the_woods\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"N:\\\\_archive\\\\test/trans\\\\soundgasmNET\\\\gwarip_db.sqlite\")\n",
    "c = conn.cursor()\n",
    "\n",
    "def filter_dled_sql(c, url):\n",
    "    # the second argument we pass to replace ? must be a tuple -> () + , at the end -> tuple\n",
    "    c.execute(\"SELECT url_sg FROM Downloads WHERE url_sg = ?\", (url,))\n",
    "    res = c.fetchone()\n",
    "    if res:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "def filter_urls_sql(c, urls):\n",
    "    new_dl = []\n",
    "    for url in urls:\n",
    "        if not filter_dled_sql(c, url):\n",
    "            new_dl.append(url)\n",
    "    return new_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing them one after the other instead of all at once is SO MUCH SLOWER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 217 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit filter_urls_sql(c, s_for)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing sqlite functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "same conn:  [(2, 'milton')]\n",
      "other conn:  []\n",
      "same conn:  [(2, 'milton'), (3, 'max')]\n",
      "other conn:  [(2, 'milton'), (3, 'max')]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.remove(\"test_res/t-temp.db\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "conn = sqlite3.connect(\"test_res/t-temp.db\")\n",
    "# we can call execute on conn directly (it creates cursor obj and returns it)\n",
    "c = conn.execute(\"CREATE TABLE test (id INT, name TEXT)\")\n",
    "c.execute(\"INSERT INTO test VALUES (2, 'milton')\")\n",
    "# we didnt call commit so no changes should be commited \n",
    "# If you don’t call this method, anything you did since the last call to commit() is not visible from other database connections.\n",
    "# but they would be readable from the same conn\n",
    "c.execute(\"SELECT * FROM test\")\n",
    "print(\"same conn: \", c.fetchall())\n",
    "\n",
    "conn2 = sqlite3.connect(\"test_res/t-temp.db\")\n",
    "c2 = conn2.execute(\"SELECT * FROM test\")\n",
    "print(\"other conn: \", c2.fetchall())\n",
    "\n",
    "# executescript calls to commit first then execs script\n",
    "c.executescript(\"INSERT INTO test VALUES (3, 'max')\")\n",
    "\n",
    "c.execute(\"SELECT * FROM test\")\n",
    "print(\"same conn: \", c.fetchall())\n",
    "\n",
    "conn2 = sqlite3.connect(\"test_res/t-temp.db\")\n",
    "c2 = conn2.execute(\"SELECT * FROM test\")\n",
    "print(\"other conn: \", c2.fetchall())\n",
    "\n",
    "conn.close()\n",
    "conn2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'Joe')]\n",
      "couldn't add Joe twice\n",
      "with:  [(1, 'Joe')]\n",
      "couldn't add Joe twice\n",
      "without with:  [(1, 'Joe'), (2, 'does this get rolled back')]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    os.remove(\"test_res/t-temp.db\")\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "con = sqlite3.connect(\"test_res/t-temp.db\")\n",
    "con.execute(\"create table person (id integer primary key, firstname varchar unique)\")\n",
    "\n",
    "# Successful, con.commit() is called automatically afterwards\n",
    "with con:\n",
    "    con.execute(\"insert into person(firstname) values (?)\", (\"Joe\",))\n",
    "\n",
    "con2 = sqlite3.connect(\"test_res/t-temp.db\")\n",
    "c2 = con2.execute(\"SELECT * FROM person\")\n",
    "print(c2.fetchall())\n",
    "\n",
    "c = con.execute(\"INSERT INTO person(firstname) VALUES ('does this get rolled back')\")\n",
    "\n",
    "# con.rollback() is called after the with block finishes with an exception, the\n",
    "# exception is still raised and must be caught\n",
    "try:\n",
    "    with con:\n",
    "        con.execute(\"insert into person(firstname) values (?)\", (\"Joe\",))\n",
    "except sqlite3.IntegrityError:\n",
    "    print(\"couldn't add Joe twice\")\n",
    "c.execute(\"SELECT * FROM person\")\n",
    "print(\"with: \", c.fetchall())\n",
    "   \n",
    "c = con.execute(\"INSERT INTO person(firstname) VALUES ('does this get rolled back')\")    \n",
    "\n",
    "# without with\n",
    "try:\n",
    "    con.execute(\"insert into person(firstname) values (?)\", (\"Joe\",))  # <- 1-tuple\n",
    "except sqlite3.IntegrityError:\n",
    "    print(\"couldn't add Joe twice\")\n",
    "c.execute(\"SELECT * FROM person\")\n",
    "print(\"without with: \", c.fetchall())\n",
    "\n",
    "\n",
    "# with DOESNT CLOSE CONNECTION!!!!\n",
    "con.close()\n",
    "con2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "def clean_name(some_var):\n",
    "    return ''.join(char for char in some_var if char.isalnum())\n",
    "\n",
    "def set_missing_values_df_sql(cursor, audiodl_obj):\n",
    "    # parameters with ? etc. only work with values not table/col names\n",
    "    cursor.execute(\"SELECT * FROM Downloads WHERE url = ?\", (audiodl_obj.url_to_file,))\n",
    "#     row_cont = cursor.fetchone()\n",
    "#     print(row_cont)\n",
    "    # executescript doesnt work with parameters\n",
    "    # use format instead and put ' around the inserted vals -> UNSAFE sql injections\n",
    "    cursor.executescript(\"\"\"\n",
    "    UPDATE Downloads \n",
    "    SET url_sg = CASE WHEN url_sg IS NULL THEN '{}' ELSE url_sg END, \n",
    "        local_filename = CASE WHEN local_filename IS NULL THEN '{}' ELSE local_filename END WHERE url = '{}'\n",
    "    \"\"\".format(audiodl_obj.page_url, audiodl_obj.filename_local, audiodl_obj.url_to_file))\n",
    "    \n",
    "\n",
    "def set_missing_values_df(cursor, audiodl_obj):\n",
    "    # parameters with ? etc. only work with values not table/col names\n",
    "    cursor.execute(\"SELECT * FROM Downloads WHERE url = ?\", (audiodl_obj.url_to_file,))\n",
    "    # get row\n",
    "    row_cont = cursor.fetchone()\n",
    "    # get indexes of None elements\n",
    "    null_ind = (i for i, e in enumerate(row_cont) if e is None)\n",
    "    # get table cols\n",
    "    c.execute(\"PRAGMA table_info('Downloads')\")\n",
    "    col_name = [colinfo[1] for colinfo in c.fetchall()]\n",
    "    # get names of col where val is None\n",
    "    null_cols = [col_name[i] for i in null_ind]\n",
    "    \n",
    "    set_helper = ((\"reddit_title\", \"title\"), (\"reddit_url\", \"permalink\"), (\"reddit_user\", \"r_user\"),\n",
    "                       (\"created_utc\", \"created_utc\"), (\"reddit_id\", \"id\"), (\"subreddit_name\", \"subreddit\"),\n",
    "                       (\"r_post_url\", \"r_post_url\"))\n",
    "\n",
    "    \n",
    "    upd_cols = []\n",
    "    upd_vals = []\n",
    "    if \"url_sg\" in null_cols:\n",
    "        upd_cols.append(\"url_sg = ?\")\n",
    "        upd_vals.append(audiodl_obj.page_url)\n",
    "    if \"local_filename\" in null_cols:\n",
    "        upd_cols.append(\"local_filename = ?\")\n",
    "        upd_vals.append(audiodl_obj.filename_local)\n",
    "    if audiodl_obj.reddit_info:\n",
    "        for col, key in set_helper:\n",
    "            if col in null_cols:\n",
    "                upd_cols.append(\"{} = ?\".format(col))\n",
    "                upd_vals.append(audiodl_obj.reddit_info[key])\n",
    "    if upd_cols:\n",
    "        # append url since upd_vals need to include all the param substitutions for ?\n",
    "        upd_vals.append(audiodl_obj.url_to_file)\n",
    "        print(null_cols)\n",
    "        # would work in SQLite version 3.15.0 (2016-10-14), but this is 3.8.11, users would have to update as well so not a good idea\n",
    "        # print(\"UPDATE Downloads SET ({}) = ({}) WHERE url = ?\".format(\",\".join(upd_cols), \",\".join(\"?\"*len(upd_cols))))\n",
    "        \n",
    "        # join only inserts the string to join on inbetween the elements of the iterable (none at the end)\n",
    "        # format to -> e.g UPDATE Downloads SET url_sg = ?,local_filename = ? WHERE url = ?\n",
    "        c.execute(\"UPDATE Downloads SET {} WHERE url = ?\".format(\",\".join(upd_cols)), upd_vals)\n",
    "    cursor.connection.commit()\n",
    "    \n",
    "    \n",
    "def set_missing_values_df_sqlrow(cursor, audiodl_obj):\n",
    "    # Row provides both index-based and case-insensitive name-based access to columns with almost no memory overhead\n",
    "    cursor.connection.row_factory = sqlite3.Row\n",
    "    # we need to create new cursor after changing row_factory\n",
    "    new_c = cursor.connection.cursor()\n",
    "    # reset row_factory to default so we get normal tuples when fetching (should we generate a new cursor)\n",
    "    # new_c will always fetch Row obj and cursor will fetch tuples\n",
    "    cursor.connection.row_factory = None\n",
    "    new_c.execute(\"SELECT * FROM Downloads WHERE url = ?\", (audiodl_obj.url_to_file,))\n",
    "    # get row\n",
    "    row_cont = new_c.fetchone()\n",
    "    \n",
    "    set_helper = ((\"reddit_title\", \"title\"), (\"reddit_url\", \"permalink\"), (\"reddit_user\", \"r_user\"),\n",
    "                       (\"created_utc\", \"created_utc\"), (\"reddit_id\", \"id\"), (\"subreddit_name\", \"subreddit\"),\n",
    "                       (\"r_post_url\", \"r_post_url\"))\n",
    "\n",
    "    \n",
    "    upd_cols = []\n",
    "    upd_vals = []\n",
    "    if row_cont[\"url_sg\"] is None:\n",
    "        upd_cols.append(\"url_sg = ?\")\n",
    "        upd_vals.append(audiodl_obj.page_url)\n",
    "    if row_cont[\"local_filename\"] is None:\n",
    "        upd_cols.append(\"local_filename = ?\")\n",
    "        upd_vals.append(audiodl_obj.filename_local)\n",
    "    if audiodl_obj.reddit_info:\n",
    "        for col, key in set_helper:\n",
    "            if row_cont[col] is None:\n",
    "                upd_cols.append(\"{} = ?\".format(col))\n",
    "                upd_vals.append(audiodl_obj.reddit_info[key])\n",
    "    if upd_cols:\n",
    "        # append url since upd_vals need to include all the param substitutions for ?\n",
    "        upd_vals.append(audiodl_obj.url_to_file)\n",
    "        # would work in SQLite version 3.15.0 (2016-10-14), but this is 3.8.11, users would have to update as well so not a good idea\n",
    "        # print(\"UPDATE Downloads SET ({}) = ({}) WHERE url = ?\".format(\",\".join(upd_cols), \",\".join(\"?\"*len(upd_cols))))\n",
    "        \n",
    "        # join only inserts the string to join on inbetween the elements of the iterable (none at the end)\n",
    "        # format to -> e.g UPDATE Downloads SET url_sg = ?,local_filename = ? WHERE url = ?\n",
    "        c.execute(\"UPDATE Downloads SET {} WHERE url = ?\".format(\",\".join(upd_cols)), upd_vals)\n",
    "    cursor.connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('https://soundgasm.net/u/belle_in_the_woods/F4A-Take-Care-Beach-House-cover-singingbadly-playing-ukuele', '[F4A] Take Care - Beach House cover [singing][badly playing ukuele].m4a')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# append pardir to syspath so we can import gwaripper (not the one in site-packages)\n",
    "sys.path.append('../')\n",
    "import gwaripper.gwaripper as gw\n",
    "\n",
    "try:\n",
    "    conn = sqlite3.connect(\"N:\\\\_archive\\\\test/trans\\\\soundgasmNET\\\\_dev\\\\gwarip_db.sqlite\")\n",
    "    c = conn.cursor()\n",
    "    a = gw.AudioDownload(\"https://soundgasm.net/u/Testing1231234/testest\", \"sgasm\")\n",
    "    a.url_to_file = \"https://soundgasm.net/sounds/176d98d189da48bbdeb6356841367172be06aa64.m4a\"\n",
    "    a.filename_local = \"testname123333\"\n",
    "#     c.execute(\"SELECT * FROM Downloads WHERE url = ?\", (a.url_to_file,))\n",
    "#     pre = c.fetchone();print(pre)\n",
    "    #c.execute(\"UPDATE Downloads SET url_sg = NULL, local_filename = NULL WHERE url = ?\", (a.url_to_file,))\n",
    "    #set_missing_values_df_sql(c, a)  # executescript keeps commiting my changes\n",
    "    #set_missing_values_df(c, a)\n",
    "    #set_missing_values_df_sqlrow(c,a)\n",
    "    c.execute(\"SELECT url_sg, local_filename FROM Downloads WHERE url = ?\", (a.url_to_file,))\n",
    "    print(c.fetchone())\n",
    "finally:  # prevent from commiting, whether success or an exception gets raised\n",
    "    conn.rollback()\n",
    "    c.execute(\"REPLACE INTO Downloads VALUES (359, '07.05.2017', '02:39:37', NULL, '[F4A] Take Care - Beach House cover [singing][badly playing ukuele].m4a', '[F4A] Take Care - Beach House cover [singing][badly playing ukuele]', 'https://soundgasm.net/sounds/176d98d189da48bbdeb6356841367172be06aa64.m4a', 'https://soundgasm.net/u/belle_in_the_woods/F4A-Take-Care-Beach-House-cover-singingbadly-playing-ukuele', NULL, NULL, NULL, NULL, NULL, 'Belle_in_the_woods', 'belle_in_the_woods', NULL)\")\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"N:\\\\_archive\\\\test/trans\\\\soundgasmNET\\\\_dev\\\\gwarip_db.sqlite\")\n",
    "c = conn.cursor()\n",
    "a = gw.AudioDownload(\"https://soundgasm.net/u/Testing1231234/testest\", \"sgasm\")\n",
    "a.url_to_file = \"https://soundgasm.net/sounds/176d98d189da48bbdeb6356841367172be06aa64.m4a\"\n",
    "a.filename_local = \"testname123333\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using only sql (with CASE WHEN..) is slowest by far!!! Using sqlite3.Row for dict-like access is fastest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 52.47 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1 loop, best of 3: 7.78 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit set_missing_values_df_sql(c, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 314 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit set_missing_values_df(c, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.52 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 182 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit set_missing_values_df_sqlrow(c, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "('https://soundgasm.net/u/belle_in_the_woods/F4A-Take-Care-Beach-House-cover-singingbadly-playing-ukuele', '[F4A] Take Care - Beach House cover [singing][badly playing ukuele].m4a')\n",
      "<sqlite3.Row object at 0x0112EA50>\n",
      "('https://soundgasm.net/u/belle_in_the_woods/F4A-Take-Care-Beach-House-cover-singingbadly-playing-ukuele', '[F4A] Take Care - Beach House cover [singing][badly playing ukuele].m4a')\n",
      "('https://soundgasm.net/u/belle_in_the_woods/F4A-Take-Care-Beach-House-cover-singingbadly-playing-ukuele', '[F4A] Take Care - Beach House cover [singing][badly playing ukuele].m4a')\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"N:\\\\_archive\\\\test/trans\\\\soundgasmNET\\\\_dev\\\\gwarip_db.sqlite\")\n",
    "c = conn.cursor()\n",
    "print(c.connection.row_factory)  # default for row_factory is None\n",
    "c.execute(\"SELECT url_sg, local_filename FROM Downloads WHERE url = 'https://soundgasm.net/sounds/176d98d189da48bbdeb6356841367172be06aa64.m4a'\")\n",
    "print(c.fetchone())\n",
    "# since this is weird and not that pracitcal ill pass the connection or connection+cursor to my fucntions\n",
    "c.connection.row_factory = sqlite3.Row\n",
    "c_rf = c.connection.cursor()\n",
    "c_rf.execute(\"SELECT url_sg, local_filename FROM Downloads WHERE url = 'https://soundgasm.net/sounds/176d98d189da48bbdeb6356841367172be06aa64.m4a'\")\n",
    "print(c_rf.fetchone())\n",
    "# if the line below is missing we get a cursor from conn that returns Row obj when fetching data\n",
    "c.connection.row_factory = None\n",
    "c.execute(\"SELECT url_sg, local_filename FROM Downloads WHERE url = 'https://soundgasm.net/sounds/176d98d189da48bbdeb6356841367172be06aa64.m4a'\")\n",
    "print(c.fetchone())\n",
    "ct = c.connection.cursor()\n",
    "ct.execute(\"SELECT url_sg, local_filename FROM Downloads WHERE url = 'https://soundgasm.net/sounds/176d98d189da48bbdeb6356841367172be06aa64.m4a'\")\n",
    "print(ct.fetchone())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing timeit for checking if one url is in db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "con = sqlite3.connect(\"N:\\_archive\\\\test\\\\trans\\soundgasmNET\\gwarip_db.sqlite\")\n",
    "def check_direct_url_for_dl(db_con, direct_url):\n",
    "    c = db_con.execute(\"SELECT url_file FROM Downloads\")\n",
    "    # converting to set would take just as long (for ~10k entries) as searching for it in list\n",
    "    # returned as list of 1-tuples, use generator to unpack, so when we find direct_url b4\n",
    "    # the last row we dont have to generate the remaining tuples and we only use it once\n",
    "    file_urls = (tup[0] for tup in c.fetchall())\n",
    "    if direct_url in file_urls:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def check_direct_url_for_dl_l(db_con, direct_url):\n",
    "    c = db_con.execute(\"SELECT url_file FROM Downloads\")\n",
    "    # converting to set would take just as long (for ~10k entries) as searching for it in list\n",
    "    # returned as list of 1-tuples, use generator to unpack, so when we find direct_url b4\n",
    "    # the last row we dont have to generate the remaining tuples and we only use it once\n",
    "    file_urls =  [tup[0] for tup in c.fetchall()]\n",
    "    if direct_url in file_urls:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 42.4 ms per loop\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %timeit check_direct_url_for_dl(con, \"https://soundgasm.net/sounds/92f9569c1ab0c0f21f709d84dce5325aad9aad4b.m4a\")\n",
    "finally:\n",
    "    con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 44.5 ms per loop\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    %timeit check_direct_url_for_dl_l(con, \"https://soundgasm.net/sounds/92f9569c1ab0c0f21f709d84dce5325aad9aad4b.m4a\")\n",
    "finally:\n",
    "    con.close()\n",
    "# -> generator not MINIMALLY faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing checking if url contained with dict, vs writing them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "supported_hosts = {\n",
    "                \"sgasm\": \"soundgasm.net\",\n",
    "                \"chirb.it\": \"chirb.it/\",\n",
    "                \"eraudica\": \"eraudica.com/\"\n",
    "            }\n",
    "\n",
    "def check_p_url():\n",
    "    found_urls = []\n",
    "    for url in [\"https://chiasasrb.it/u/Testing1231234/testest\", \"https://chirb.it/u/Testing1231234/testest\"]:\n",
    "        sub_url = url\n",
    "        # TODO Refactor only selftext search makes sense in sep func, url check mb with loop and dict, then /gwa remove in _set_eraudica..\n",
    "        if \"soundgasm.net\" in sub_url:\n",
    "            found_urls.append((\"sgasm\", sub_url))\n",
    "        elif \"chirb.it/\" in sub_url:\n",
    "            found_urls.append((\"chirb.it\", sub_url))\n",
    "        elif \"eraudica.com/\" in sub_url:\n",
    "            found_urls.append((\"eraudica\", sub_url))\n",
    "        \n",
    "def check_p_url_dict(supported_hosts):\n",
    "    found_urls = []\n",
    "    for url in [\"https://chiasasrb.it/u/Testing1231234/testest\", \"https://chirb.it/u/Testing1231234/testest\"]:\n",
    "        sub_url = url\n",
    "    \n",
    "        for host, search_for in supported_hosts.items():\n",
    "            if search_for in sub_url:\n",
    "                found_urls.append((host, sub_url))\n",
    "                continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000 loops, best of 3: 1.58 µs per loop\n",
      "100000 loops, best of 3: 2.7 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit check_p_url()\n",
    "%timeit check_p_url_dict(supported_hosts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> Dict method takes almost twice as long but absolute difference is only 500ns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing timeits of searching for parts of html (splits vs regex vs bs4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.19 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000000 loops, best of 3: 1.63 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit url.split(\"/u/\", 1)[1].split(\"/\", 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 loops, best of 3: 3.28 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit re.search(\"/u/(.+)/\", url).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usr = re.compile(\"/u/(.+)/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 loops, best of 3: 3.92 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit re.search(usr, url).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sgasm_inf_split(url):\n",
    "    site = urllib.request.urlopen(url)\n",
    "    html = site.read().decode('utf-8')\n",
    "    site.close()\n",
    "    nhtml = html.split(\"aria-label=\\\"title\\\">\")\n",
    "    title = nhtml[1].split(\"</div>\", 1)[0]\n",
    "    descript = nhtml[1].split(\"<div class=\\\"jp-description\\\">\\n          <p style=\\\"white-space: pre-wrap;\\\">\")[1].split(\"</p>\\r\\n\", 1)[0]\n",
    "    urlm4a = nhtml[1].split(\"m4a: \\\"\")[1].split(\"\\\"\\r\\n\", 1)[0]\n",
    "    \n",
    "\n",
    "def sgasm_re(url):\n",
    "    site = urllib.request.urlopen(url)\n",
    "    html = site.read().decode('utf-8')\n",
    "    site.close()\n",
    "    \n",
    "    title = re.search(\"class=\\\"jp-title\\\" aria-label=\\\"title\\\">(.+)<\\/div>\", html).group(1)\n",
    "    descript = re.search(\"class=\\\"jp-description\\\">\\s+<p.+\\\">(.+)</p>\", html).group(1)\n",
    "    urlm4a = re.search(\"m4a: \\\"(.+)\\\"\", html).group(1)\n",
    "    \n",
    "    \n",
    "t_re = re.compile(\"class=\\\"jp-title\\\" aria-label=\\\"title\\\">(.+)<\\/div>\")\n",
    "d_re = re.compile(\"class=\\\"jp-description\\\">\\s+<p.+\\\">(.+)</p>\")\n",
    "url_re = re.compile(\"m4a: \\\"(.+)\\\"\")\n",
    "\n",
    "\n",
    "def sgasm_re_comp(url):\n",
    "    site = urllib.request.urlopen(url)\n",
    "    html = site.read().decode('utf-8')\n",
    "    site.close()\n",
    "    \n",
    "    title = re.search(t_re, html).group(1)\n",
    "    descript = re.search(d_re, html).group(1)\n",
    "    urlm4a = re.search(url_re, html).group(1)\n",
    "    \n",
    "def sgasm_bs4(url):\n",
    "    site = urllib.request.urlopen(url)\n",
    "    html = site.read().decode('utf-8')\n",
    "    site.close()\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    title = soup.select_one(\"div.jp-title\").text\n",
    "    descr = soup.select_one(\"div.jp-description > p\").text\n",
    "    urlm4a = re.search(\"m4a: \\\"(.+)\\\"\", html).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 427 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit sgasm_inf_split(\"file:///N:/_archive/test/trans/soundgasmNET/_dev/_sgasm-repo/tests/test_res/soundgasm.net_file-site.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 8.02 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000 loops, best of 3: 436 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit sgasm_re(\"file:///N:/_archive/test/trans/soundgasmNET/_dev/_sgasm-repo/tests/test_res/soundgasm.net_file-site.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 417 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit sgasm_re_comp(\"file:///N:/_archive/test/trans/soundgasmNET/_dev/_sgasm-repo/tests/test_res/soundgasm.net_file-site.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 5.71 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit sgasm_bs4(\"file:///N:/_archive/test/trans/soundgasmNET/_dev/_sgasm-repo/tests/test_res/soundgasm.net_file-site.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rip_usr_links(sgasm_usr_url):\n",
    "    site = urllib.request.urlopen(sgasm_usr_url)\n",
    "    html = site.read().decode('utf-8')\n",
    "    site.close()\n",
    "    # links zu den einzelnen posts isolieren\n",
    "    nhtml = html.split(\"<div class=\\\"sound-details\\\"><a href=\\\"\")\n",
    "    del nhtml[0]\n",
    "    user_files = []\n",
    "    for splits in nhtml:\n",
    "        # teil str in form von https://soundgasm.net/u/USERNAME/link-to-post> an \">\" und schreibt\n",
    "        # den ersten teil in die variable url\n",
    "        url = splits.split(\"\\\">\", 1)[0]\n",
    "        # url in die liste anfuegen\n",
    "        user_files.append(url)\n",
    "    return user_files\n",
    "\n",
    "\n",
    "def rip_usr_links_re(sgasm_usr_url):\n",
    "    site = urllib.request.urlopen(sgasm_usr_url)\n",
    "    html = site.read().decode('utf-8')\n",
    "    site.close()\n",
    "    # links zu den einzelnen posts isolieren\n",
    "    \n",
    "    # .+ match one or more of any char except newline, .+? -> ?: match as few as possible\n",
    "    # findall returns list of strings or list of groups -> more than 1 grp -> tuples \n",
    "    # matched = re.findall(\"<div class=\\\"sound-details\\\"><a href=\\\"(.+?)\\\">(.+?)<\\/a>\", html)\n",
    "    urls = re.findall(\"<div class=\\\"sound-details\\\"><a href=\\\"(.+?)\\\">\", html)\n",
    "    # unpack list of tuples\n",
    "    # url, titles = zip(*matched)\n",
    "    #print(url)\n",
    "    return urls\n",
    "\n",
    "\n",
    "def rip_usr_links_bs4(u_url):\n",
    "    site = urllib.request.urlopen(u_url)\n",
    "    html = site.read().decode('utf-8')\n",
    "    site.close()\n",
    "    soup = bs4.BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    anchs = soup.select(\"div.sound-details > a\")\n",
    "    urls = [a[\"href\"] for a in anchs]\n",
    "    return urls\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 874 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit rip_usr_links(\"file:///N:/_archive/test/trans/soundgasmNET/_dev/_sgasm-repo/tests/test_res/soundgasm.net_user-site.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 loops, best of 3: 1.49 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit rip_usr_links_re(\"file:///N:/_archive/test/trans/soundgasmNET/_dev/_sgasm-repo/tests/test_res/soundgasm.net_user-site.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 84.3 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit rip_usr_links_bs4(\"file:///N:/_archive/test/trans/soundgasmNET/_dev/_sgasm-repo/tests/test_res/soundgasm.net_user-site.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
