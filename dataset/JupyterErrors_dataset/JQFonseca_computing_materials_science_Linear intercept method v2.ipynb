{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring grain size using the linear intercept method\n",
    "\n",
    "In the image analysis session, we used labelling and other `skimage` functions to measure the size of particles. However, this method isn't very useful to measure the grain size in metals, where the only feature visible in the image is the grain boundaries. \n",
    "\n",
    "There are a number of standard methods for measuring grain size, but one of the most widely used ones is the mean linear intercept method. You will have come across it in the \"Microstructures of Materials\" module, taught by Dr Phil Frankel. Here is a slide to jog your memory.\n",
    "\n",
    "![Slide from lecture notes](https://dl.dropboxusercontent.com/s/4z63vq80i29wms1/Linear_intercept.png)\n",
    "\n",
    "In this notebook, you can see how Python can be used to implement this method for measuring grain size. The notebook takes through a possible image analysis workflow that can be used to measure grain size. This workflow makes extensive use of ready-made functions in the `skimage` package. At the end of the notebook, the workflow is brought together into two functions that can be easily reused. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by importing the usual modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we need to import some modules and functions from `skimage`. Their usefulness will become apparent as we work through the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from skimage.morphology import remove_small_objects,skeletonize,closing,disk,square,dilation\n",
    "from skimage.filters import sobel,threshold_otsu\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a good grain boundary image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we read in the image. The file loaded below can be downloaded from [here](https://dl.dropboxusercontent.com/u/11tdx1q3ozvf1rn/steel_sample.png).\n",
    "https://www.dropbox.com/s/11tdx1q3ozvf1rn/steel_sample.png?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: '/home/joao/Dropbox (Research Group)/Teaching/UG year 1/Core skills/computing_materials_science/5-Other_useful_notebooks/steel_sample.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-526d605fdaa3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'steel_sample.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/skimage/io/manage_plugins.py\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m                                (plugin, kind))\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/skimage/io/_plugins/imageio_plugin.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimageio_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(uri, format, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;31m# Get reader and read first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/imageio/core/functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[0;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Create request object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mrequest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# Get format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# Parse what was given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;31m# Set extension\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.7/site-packages/imageio/core/request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    258\u001b[0m                 \u001b[0;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No such file: '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                 \u001b[0;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/home/joao/Dropbox (Research Group)/Teaching/UG year 1/Core skills/computing_materials_science/5-Other_useful_notebooks/steel_sample.png'"
     ]
    }
   ],
   "source": [
    "image=io.imread('steel_sample.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a colour image, which we can check by looking at the shape of the `image` array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us the image is 968 pixels high, 1292 pixels wide and has 3 intensity channels, which correspond to **R**ed, **G**reen and **B**lue (RGB). In order to work with this image, we first need to flatten it into a greyscale image using the rgb2gray function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image=rgb2gray(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has converted the array into a simple 2D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(gray_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image is now in greyscale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imshow(gray_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the linear intercept method, we want to determine the number of interceptions with grain boundaries and regularly spaced lines. The first step is to get a good image of the grain boundaries. We could use thresholding to do this, but because the intensity of the image changes throughout (different grains have different intensities because of the orientation) this can be tricky. Instead we will use a filter to detect edges: the [sobel filter](https://en.wikipedia.org/wiki/Sobel_operator). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_image=sobel(gray_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This produces a map of the instensity gradient of the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(edge_image, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good start but since we will be after interceptions we need to convert this into an image where the grain boundaries are one pixel thin. To do this we will first threshold to get a representative binary image. First we plot a histogram to see what the distribution of gradients looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(edge_image.flatten(),bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there is a peak below 0.005 and almost all the values are less than 0.2. To get a good starting point for a threshold value, we can use Otsu's method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh=threshold_otsu(edge_image)\n",
    "print(thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which we can then test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_edge=edge_image>0.068\n",
    "fig1,ax1=plt.subplots(1,2, figsize=(12,4))\n",
    "ax1[0].imshow(gray_image,cmap='viridis')\n",
    "ax1[1].imshow(thresh_edge, cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty good, but we should keep in mind that it _might require adjustment for different images_.\n",
    "\n",
    "Another problem is that, because the grain boundaries are not one pixel thin, the each have two edges. This can be seen clearly if we plot a small 200 pixel wide region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(thresh_edge[200:400,:200], cmap='viridis',interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the two edges into one boundary, we carry out a [`closing` operation](http://scikit-image.org/docs/dev/auto_examples/applications/plot_morphology.html#closing), which closes off any holes in the binary image. The closing function requires an approximate shape of the wholes it needs to fill. These can be generated with the functions `disk` or `square`. To make a disk with a 3 pixel radius:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape=disk(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then use this shape with the `closing` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_edge=closing(thresh_edge,shape)\n",
    "plt.imshow(closed_edge[200:400,:200], cmap='viridis',interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which seems to do a good job. \n",
    "\n",
    "The other issue we have is that our image is full of pits, particles and other small objects we would ignore if doing the method manually, but would look like grain boundaries to an algorithm. To do this, we need to remove the small objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_edge=remove_small_objects(closed_edge,min_size=300)\n",
    "plt.imshow(clean_edge, cmap='viridis',interpolation='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not perfect, but it's pretty good. We could probably do better, but for now we carry on with this result.. \n",
    "\n",
    "Because we are interested in intercepts, we would like the boundaries to be one pixel thin. There is a function for that, called `skeletonize`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thin_boundaries=skeletonize(clean_edge)\n",
    "plt.imshow(thin_boundaries, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should check this still looks like our image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1,ax1=plt.subplots(1,2)\n",
    "ax1[0].imshow(gray_image[200:400,:200],cmap='gray')\n",
    "ax1[1].imshow(thin_boundaries[200:400,:200], cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty good although we can certainly get better by adjusting the threshold value we used. For now, though we will use this grain boundary image to find our intercepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting intercepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use both horizontal and vertical lines to get our intercepts. This is straight forward since these are just rows and columns of the image array. The spacing between the lines will be called the step_size. We can plot the lines using `axvline` and `axhline`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gray_image,cmap='gray')\n",
    "step_size=200\n",
    "rows=range(step_size,np.shape(image)[0],step_size) # the rows for the stepsize above\n",
    "cols=range(step_size,np.shape(image)[1],step_size) # the columns for the stepsize above\n",
    "\n",
    "#plot all rows and columns\n",
    "for row in rows:\n",
    "    plt.axhline(row,color='b')\n",
    "for col in cols:\n",
    "    plt.axvline(col,color='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have created an image of pixel-wide grain boundaries, finding intercepts is relatively easy. We just loop through the rows and columns and find out where in each there is a value of '1':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through the rows\n",
    "row_intercepts_list=[]\n",
    "for row in rows:\n",
    "    line=thin_boundaries[row,:]\n",
    "    row_intercepts=np.where(line==1)[0] #find where there is a grain boundary\n",
    "    row_intercepts_list.append(row_intercepts)\n",
    "\n",
    "#loop through the columns\n",
    "col_intercepts_list=[]\n",
    "for col in cols:\n",
    "    line=thin_boundaries[:,col]\n",
    "    col_intercepts=np.where(line==1)[0]#find where there is a grain boundary\n",
    "    col_intercepts_list.append(col_intercepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have lists of all the row and columns intercepts, for a step size of 200. We should check these are correct by plotting them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image,cmap='gray')\n",
    "\n",
    "for row,points in zip(rows, row_intercepts_list):\n",
    "    plt.axhline(row,color='b')\n",
    "    yvals=np.ones(np.shape(points))*row\n",
    "    xvals=points\n",
    "    plt.plot(xvals,yvals,'yo',alpha=0.7)\n",
    "    \n",
    "for col,points in zip(cols,col_intercepts_list):\n",
    "    plt.axvline(col,color='b')\n",
    "    xvals=np.ones(np.shape(points))*col\n",
    "    yvals=points\n",
    "    plt.plot(xvals,yvals,'go',alpha=0.7)\n",
    "    \n",
    "plt.xlim(0,np.shape(image)[1])\n",
    "plt.ylim(0,np.shape(image)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that this works pretty well. However, there are some regions where there seem to be far too many intercepts, very close together. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(gray_image,cmap='gray')\n",
    "for row,points in zip(rows, row_intercepts_list):\n",
    "    plt.axhline(row,color='b')\n",
    "    yvals=np.ones(np.shape(points))*row\n",
    "    xvals=points\n",
    "    plt.plot(xvals,yvals,'yo',alpha=0.7)   \n",
    "for col,points in zip(cols,col_intercepts_list):\n",
    "    plt.axvline(col,color='b')\n",
    "    xvals=np.ones(np.shape(points))*col\n",
    "    yvals=points\n",
    "    plt.plot(xvals,yvals,'go',alpha=0.7)\n",
    "    \n",
    "plt.ylim(190,210)\n",
    "plt.xlim(950,975)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an artefact, as can be seen by plotting the boundary image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(thin_boundaries,cmap='viridis')\n",
    "for row,points in zip(rows, row_intercepts_list):\n",
    "    plt.axhline(row,color='b')\n",
    "    yvals=np.ones(np.shape(points))*row\n",
    "    xvals=points\n",
    "    plt.plot(xvals,yvals,'yo',alpha=0.7)   \n",
    "for col,points in zip(cols,col_intercepts_list):\n",
    "    plt.axvline(col,color='b')\n",
    "    xvals=np.ones(np.shape(points))*col\n",
    "    yvals=points\n",
    "    plt.plot(xvals,yvals,'go',alpha=0.7)\n",
    "    \n",
    "plt.ylim(190,210)\n",
    "plt.xlim(950,975)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To remove these artifacts we filter the intercepts by their distance. The distances between the intercepts can determined by the difference in their values, using `ediff1d`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_distances_list=[]\n",
    "for row_intercepts in row_intercepts_list:\n",
    "    row_distances=np.ediff1d(row_intercepts,to_end=step_size)\n",
    "    row_distances_list.append(row_distances)\n",
    "col_distances_list=[]\n",
    "for col_intercepts in col_intercepts_list:\n",
    "    col_distances=np.ediff1d(col_intercepts,to_end=step_size)\n",
    "    col_distances_list.append(col_distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The row we are interested in is the first row. If we print the distances in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(row_distances_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can see that there are a number of points that are only one pixel apart. These must be filtered out. In the next cell we filter and plot at the same time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image,cmap='gray',origin='bottom')\n",
    " \n",
    "for row,points,distances in zip(rows,row_intercepts_list,row_distances_list):\n",
    "    plt.axhline(row,color='r')\n",
    "    points=points[np.where(distances>1)[0]]\n",
    "    yvals=np.ones(np.shape(points))*row\n",
    "    xvals=points\n",
    "    plt.plot(xvals,yvals,'yo',alpha=0.7)\n",
    "    \n",
    "for col,points,distances in zip(cols,col_intercepts_list,col_distances_list):\n",
    "    plt.axvline(col,color='r')\n",
    "    points=points[np.where(distances>1)[0]]\n",
    "    xvals=np.ones(np.shape(points))*col\n",
    "    yvals=points\n",
    "    plt.plot(xvals,yvals,'bo',alpha=0.7)\n",
    "    \n",
    "plt.ylim(190,210)\n",
    "plt.xlim(950,975)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the filtering removes adjoining points. We will probably need to chose the threshold and this minimum distance parameter carefully. We will return to this later.\n",
    "\n",
    "To measure grain size, all we need now is to count the number of intercepts and divide the length of each row/column by that number:\n",
    "\n",
    "$$ \\text{Grain size} = \\dfrac{\\text{length of line}}{\\text{number of intercepts}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_row_list=[]\n",
    "count_col_list=[]\n",
    "\n",
    "#count number of points in each row and column\n",
    "for row,points,distances in zip(rows,row_intercepts_list,row_distances_list):\n",
    "    points=np.size(points[np.where(distances>1)[0]])\n",
    "    count_row_list.append(points)\n",
    "for col,points,distances in zip(cols,col_intercepts_list,col_distances_list):\n",
    "    points=np.size(points[np.where(distances>1)[0]])\n",
    "    count_col_list.append(points)\n",
    "\n",
    "# Divide length of lines by counts\n",
    "x_dist=np.shape(gray_image)[1]/np.mean(count_row_list)\n",
    "y_dist=np.shape(gray_image)[0]/np.mean(count_col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_dist)\n",
    "print(y_dist)\n",
    "print(np.mean([x_dist,y_dist]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These numbers are in units of pixels, and the final step is to convert them into SI units using a calibrated image. But we leave that as an exercise for you.\n",
    "\n",
    "What we will do instead is collate the steps above into 2 functions that can be rapidly reused."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we collect all the steps above to define 2 functions: one that produces the pixel thin grain boundary image and another that measures grain size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundaries(fname, thresh_offset=0.04, small_objects=250, show_figure=True ):\n",
    "    '''Uses edge filtering and thresholding to give clean grain boundaries\n",
    "    \n",
    "    Keywords:\n",
    "    thresh_offset -- threshold offset\n",
    "    small_objects -- size of window used to remove small objects in pixels\n",
    "    figure -- show the thresholded and original image\n",
    "    '''\n",
    "    \n",
    "    # read image in and threshold\n",
    "    image=io.imread(fname)\n",
    "    image=rgb2gray(image)\n",
    "    edge=sobel(image)\n",
    "    edge=edge>thresh_offset\n",
    "    edge=closing(edge,disk(3))\n",
    "    edge=remove_small_objects(edge,min_size=small_objects)\n",
    "    thin_boundaries=skeletonize(edge)\n",
    "    \n",
    "    if (show_figure):\n",
    "        # compare original and thresholded\n",
    "        f,ax=plt.subplots(1,2,figsize=(16,9))\n",
    "        ax[0].imshow(image,cmap='gray',origin='bottom')\n",
    "        # we use dilation here for visualization purposes only\n",
    "        ax[1].imshow(dilation(thin_boundaries,square(3)),cmap='gray',origin='bottom') \n",
    "    \n",
    "    return thin_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_grain(edge_image, step_size=100, min_distance=0, image_file=None):\n",
    "    ''' Measure grain size by the linear intercept method. \n",
    "    Inputs:\n",
    "    thresh_image -- binary image of grain boundaries (from thresh_and_clean)\n",
    "\n",
    "    Keywords:\n",
    "    step_size -- distance in pixels between intercept lines\n",
    "    min_distance -- minimum distance allowed between intercepts in pixels\n",
    "    image_file -- filename of image to be used to display intercepts\n",
    "    '''\n",
    "        \n",
    "    #find intercepts and distances\n",
    "    rows=range(step_size,np.shape(edge_image)[0],step_size) # the rows \n",
    "    cols=range(step_size,np.shape(edge_image)[1],step_size) # the columns \n",
    "\n",
    "    row_intercepts_list=[]\n",
    "    col_intercepts_list=[]\n",
    "    row_counts_list=[]\n",
    "    col_counts_list=[]\n",
    "    \n",
    "    for row in rows:\n",
    "        line=edge_image[row,:]\n",
    "        row_intercepts=np.where(line==1)[0]\n",
    "        row_distances=np.ediff1d(row_intercepts,to_end=step_size)\n",
    "        row_intercepts_filtered=row_intercepts[np.where(row_distances>min_distance)[0]]\n",
    "        row_counts=np.size(row_intercepts_filtered)\n",
    "        row_intercepts_list.append(row_intercepts_filtered)\n",
    "        row_counts_list.append(row_counts)\n",
    "        \n",
    "    for col in cols:\n",
    "        line=edge_image[:,col]\n",
    "        col_intercepts=np.where(line==1)[0]\n",
    "        col_distances=np.ediff1d(col_intercepts,to_end=step_size)\n",
    "        col_intercepts_filtered=col_intercepts[np.where(col_distances>min_distance)[0]]\n",
    "        col_counts=np.size(col_intercepts_filtered)\n",
    "        col_intercepts_list.append(col_intercepts_filtered)\n",
    "        col_counts_list.append(col_counts)\n",
    "    \n",
    "    \n",
    "    #calculate mean distances\n",
    "    x_size=np.shape(edge_image)[1]/np.mean(col_counts_list)\n",
    "    y_size=np.shape(edge_image)[0]/np.mean(col_counts_list)\n",
    "\n",
    "    #plot image and measured intercepts\n",
    "    if (image_file):\n",
    "        \n",
    "        original_image=io.imread(image_file)\n",
    "        io.imshow(original_image)\n",
    "\n",
    "        for row,points in zip(rows,row_intercepts_list):\n",
    "            plt.axhline(row,color='y')\n",
    "            yvals=np.ones(np.shape(points))*row\n",
    "            plt.plot(points,yvals,'go',alpha=0.7)\n",
    "\n",
    "        for col,points in zip(cols,col_intercepts_list):\n",
    "            plt.axvline(col,color='y')\n",
    "            xvals=np.ones(np.shape(points))*col\n",
    "            plt.plot(xvals,points,'bo',alpha=0.7)\n",
    "\n",
    "        plt.xlim(0,np.shape(edge_image)[1])\n",
    "        plt.ylim(0,np.shape(edge_image)[0])\n",
    "\n",
    "        print('X distance from intercepts: {:2.2f} pixels'.format(x_size))\n",
    "        print('Y distance from intercepts: {:2.2f} pixels'.format(y_size))\n",
    "\n",
    "    return [x_size,y_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now call the functions and do the analysis in one step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_image=get_boundaries('steel_sample.png',thresh_offset=0.05,small_objects=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances=measure_grain(edge_image, step_size=100, min_distance=4,image_file='steel_sample.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean value is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean grain size = {:2.2f} pixels.'.format(np.mean(distances)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions can also be run silently. This is very useful if you want to run several images or test the effect of some of the optional parameters. For example, let's try a few different thresholds and minimum distances:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds_list=np.linspace(0.01,0.07,28)\n",
    "min_distances_list=[1,5,10,20,30]\n",
    "min_dist_list=[]\n",
    "for dist in min_distances_list:\n",
    "    distances_list=[]\n",
    "    for thresh in thresholds_list:\n",
    "        edge_image=get_boundaries('steel_sample.png',thresh_offset=thresh, \n",
    "                                  small_objects=200, show_figure=False)\n",
    "        distances=measure_grain(edge_image, step_size=100, min_distance=dist)\n",
    "        distances_list.append(np.mean(distances))\n",
    "    min_dist_list.append(distances_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dist in min_dist_list:\n",
    "    plt.plot(thresholds_list,dist,'-o')\n",
    "plt.legend(min_distances_list, title='Min distance')\n",
    "plt.ylabel('Grain size (pixels)')\n",
    "plt.xlabel('Threshold value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this we seen that the distance parameter can be very important and that something happens at threshold values below 0.02. We can investigate further. Here is what happens at 0.015:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edge_image=get_boundaries('steel_sample.png',thresh_offset=0.015,small_objects=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly our algorithm creates boundaries that aren't there. Which disappear at larger offsets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "edge_image=get_boundaries('steel_sample.png',thresh_offset=0.03,small_objects=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course the best way to check parameters is by inspection. We can plot the intercepts and see if we are happy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances=measure_grain(edge_image, step_size=200, min_distance=10,image_file='steel_sample.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances=measure_grain(edge_image, step_size=200, min_distance=30,image_file='steel_sample.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these it is clear that at `min_distance = 30`, many grain boundaries are missed. \n",
    "\n",
    "In the end it is still somewhat subjective, and different people will chose different offsets/distances. The same is true of doing this manually. However, this calculation is now reproducible, unlike counting intercepts on a print-out. And much faster!\n",
    "\n",
    "From this analysis, a good choice would be a threshold of 0.035  and a distance of 5. This gives us a grain size of:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_image=get_boundaries('steel_sample.png',thresh_offset=0.035,small_objects=200,show_figure=False)\n",
    "distances=measure_grain(edge_image, step_size=100, min_distance=5)\n",
    "print('Mean grain size = {:2.2f} pixels.'.format(np.mean(distances)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
