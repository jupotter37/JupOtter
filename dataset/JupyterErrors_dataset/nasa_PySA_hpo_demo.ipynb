{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T01:23:01.214029Z",
     "start_time": "2023-02-14T01:23:01.204521Z"
    }
   },
   "source": [
    "Authors: David E. Bernal Neira (david.e.bernalneira)<br>\n",
    "\n",
    "Copyright Â© 2023, United States Government, as represented by the Administrator\n",
    "of the National Aeronautics and Space Administration. All rights reserved.\n",
    "\n",
    "The *PySA*, a powerful tool for solving optimization problems is licensed under\n",
    "the Apache License, Version 2.0 (the \"License\"); you may not use this file\n",
    "except in compliance with the License. You may obtain a copy of the License at\n",
    "http://www.apache.org/licenses/LICENSE-2.0. \n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed\n",
    "under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR\n",
    "CONDITIONS OF ANY KIND, either express or implied. See the License for the\n",
    "specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySA Hyperparameter optimization via Hyperopt\n",
    "This tutorial explains how to perform a hyperparameter optimization to find good parameters when addressing a challenging problem for PySA.\n",
    "The problem at hard is a Wishart instance. This kind of problems can be automatically generated, have a predetermined known (or <em>planted</em>) solution, and can be really challenging for QUBO solvers such as PySA. For more details see the following *[paper](\n",
    "https://doi.org/10.1103/PhysRevE.101.052102)*.\n",
    "\n",
    "This tutorial shows how to:\n",
    "- Import automatically created problem from the generator **[Chook](https://github.com/dilinanp/chook)**\n",
    "- Parameterize PySA minimum and maximum temperature automatically based on the coefficients of the problem\n",
    "- Perform a Hyperparameter optimization via **[Hyperopt](https://hyperopt.github.io/hyperopt/)** for PySA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages\n",
    "\n",
    "Here we assume that you have PySA installed. Moreover, we will make use of the libraries **[numpy](https://numpy.org/)** and **[scipy](https://scipy.org/)** for the matrices processing.\n",
    "Finally, for Hyperparameter optimization, we will use the library **[Hyperopt](https://hyperopt.github.io/hyperopt/)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T01:23:10.969718Z",
     "start_time": "2023-02-14T01:23:10.565360Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pysa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Import PySA\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpysa\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msa\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Solver\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Import Numpy and Scipy for the processing of (sparse) matrices\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pysa'"
     ]
    }
   ],
   "source": [
    "# Import PySA\n",
    "from pysa.sa import Solver\n",
    "\n",
    "# Import Numpy and Scipy for the processing of (sparse) matrices\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "\n",
    "# Import Hyperopt for the optimization of the hyperparameters\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from hyperopt.fmin import generate_trials_to_calculate\n",
    "\n",
    "# Import Matplotlib for the plotting of the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Wishart problem and loading it from the library Chook\n",
    "We will solve an instance of a Wishart problem. The problem is defined as follows:\n",
    "$$\n",
    "\\min_{x\\in \\{-1,1\\}^N} x^\\top W x,\n",
    "$$\n",
    "where $W$ is derived such that the optimal solution to the problem above, $x^*$, is the solution of the nullspace of a system of linear equations, i.e., $Ax = 0$, with $A \\in \\mathbb{R}^{M\\times N}$.\n",
    "The complexity of this problem can be controlled by the ratio of the rows and columns of $A$ in a parameter known as $\\alpha$, i.e., $\\alpha = N/M$.\n",
    "\n",
    "More details of this problem can be found in the following *[paper](\n",
    "https://doi.org/10.1103/PhysRevE.101.052102)*.\n",
    "\n",
    "One can create instances of the Wishart problem parameterized by $N$ and $\\alpha$, which is one of the functions of the library **[Chook](https://github.com/dilinanp/chook)**. Besides generating planted Wishart files, it also provides generators for Tile planting (2D/3D), Deceptive cluster loops (DCL), Equation planting (k-regular k-XORSAT), k-local planting, and more to come!\n",
    "\n",
    "For the sake of this example we will generate a single instance of the Wishart Problem of size $N=50$ and $\\alpha=0.5$. Chook will create a text file with the data of the $W$ matrix and another file with the optimal objective function value, also known as the <em>ground state energy</em>.\n",
    "\n",
    "The code below assumes that you have both files available in the same directory as this notebook. To create them, check the usage of **[Chook](https://github.com/dilinanp/chook)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T01:23:10.972727Z",
     "start_time": "2023-02-14T01:23:10.972715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get the matrix for the Ising model from the file\n",
    "instance_filename = 'wishart_planting_N_50_alpha_0.50_inst_1.txt'\n",
    "\n",
    "# Load the matrix\n",
    "file_array = np.loadtxt(instance_filename, unpack=True)\n",
    "rows = file_array[0, :].astype(int)\n",
    "cols = file_array[1, :].astype(int)\n",
    "vals = file_array[2, :]\n",
    "\n",
    "# Create a sparse matrix representing the W in the Wishart model\n",
    "ising = csr_matrix((vals, (rows, cols)), shape = (50, 50))\n",
    "ising = (ising + ising.T) / 2. # Note that this is the symmetric form of the Ising problem\n",
    "ising = ising.A\n",
    "\n",
    "# Get the ground state energy (first line of gs_energies.txt)\n",
    "gs_filename = 'gs_energies.txt'\n",
    "gs_dict = {}\n",
    "with open(gs_filename) as f:\n",
    "    line = f.readline().strip().split('\\t')\n",
    "    gs_energy = float(line[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ising problem\n",
    "As specified, PySA is an Ising solver. In this sense, it attempts to find the solution to a problem of the form:\n",
    "$$\n",
    "\\min_{\\sigma \\in \\{ -1,+1 \\}^N} H(\\sigma) =\\min_{\\sigma \\in \\{ -1,+1 \\}^N} \\sum_{(ij) \\in E(G)} J_{ij}\\sigma_i\\sigma_j + \\sum_{i \\in V(G)}h_i\\sigma_i + c_I\n",
    "$$\n",
    "where we optimize over spins $\\sigma \\in \\{ -1,+1 \\}^N$, on a constrained graph $G(V,E)$, where the quadratic coefficients are $J_{ij}$ and the linear coefficients are $h_i$. We also include an arbitrary offset of the Ising model $c_I$.\n",
    "\n",
    "We consider that the problem is already specified and will obviate the notation $(ij) \\in E(G)$ and $i \\in V(G)$ where it's apparent, mainly in sums indices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying the temperatures for PySA\n",
    "PySA receives several parameters, including the number of replicas and sweeps to be executed. Besides, minimum and maximum temperatures are also used to define the different replicas for PySA through a geometric series, where each value is assigned to a replica.\n",
    "Determining the optimal temperatures is challenging; their values decide the solver's performance, and the optimal values depend on the problem to be solved.\n",
    "\n",
    "There is a way of determining these temperatures by parameterizing them using the nonzero coefficients in the Ising model $J$ and $h$.\n",
    "\n",
    "In the cold limit, the temperature should reflect a small chance of having a single flip in the variable values, as we want to avoid being stuck between small energy tweaks.\n",
    "Given a Metropolis update, the probability of changing a single variable value / exciting a single spin becomes\n",
    "$$\n",
    "p^{cold} = \\sum_{i \\in N} \\exp \\left( -\\frac{\\Delta E^{min}_i}{T^{cold}} \\right) .\n",
    "$$\n",
    "Computing the minimum energy change $\\Delta E^{min}_i$ that each spin can experiment with a single flip would require solving a combinatorial problem.\n",
    "$$\n",
    "\\Delta E^{min}_i = \\min_{\\delta\\sigma \\in \\{ -1,0,1 \\}^{N}, |\\delta\\sigma|_0 = 1} \\sum_{j \\mid (ij) \\in E(G)} 2J_{ij} \\sigma_i\\delta\\sigma_j + 2\\sum_{j \\in V(G)}h_j\\delta\\sigma_j ,\n",
    "$$\n",
    "hence an approximate solution is taken. Here the change of energy is given by two times the minimum effective field felt by each spin:\n",
    "$$\n",
    "\\Delta E^{min}_i \\sim \\Delta E^{cold}_i = 2 \\min \\left[ \\min_{j \\mid J_{ij} \\neq 0}|J_{ij}|, |h_i| \\mid h_i \\neq 0 \\right].\n",
    "$$\n",
    "This allows us to approximate the probability at the cold limit as\n",
    "$$\n",
    "p^{cold} = N^{min gap}\\exp \\left( -\\frac{\\Delta E^{cold}}{T^{cold}} \\right),\n",
    "$$\n",
    "where the $\\Delta E^{cold}$ becomes\n",
    "$$\n",
    "\\Delta E^{cold} = \\min_i \\Delta E^{cold}_i,\n",
    "$$\n",
    "and a correction for scaling the minimum energy can be given by the number of spins that reflect that minimum effective field, e.g.,\n",
    "$$\n",
    "N^{min gap} = \\sum_{i \\mid E^{cold}_i = E^{cold}} 1.\n",
    "$$\n",
    "\n",
    "The cold transition probability usually takes as a small value, e.g., $p_{cold}=0.01$ (1%).\n",
    "\n",
    "For the hot limit, we want to find a temperature where all variable value flips have a large chance of happening, as we want to make large steps at that limit to enhance exploration.\n",
    "We use a temperature that would assure the most unlikely of the transitions to happen by overcoming the maximum energy difference.\n",
    "Using a Metropolis update for this transition, we obtain that it is bounded by the probability\n",
    "$$\n",
    "p^{hot} = \\exp \\left( -\\frac{\\Delta E^{max}}{T^{hot}} \\right) .\n",
    "$$\n",
    "\n",
    "The maximum energy difference can also be computed through a combinatorial problem, although here, we take an approximation as the worst case of the effective field\n",
    "$$\n",
    "\\Delta E^{max} \\sim \\Delta E^{hot} = 2 \\max_i \\left[ \\sum_{j}|J_{ij}| + |h_i| \\right].\n",
    "$$\n",
    "\n",
    "The hot transition probability usually takes as a large value, e.g., $p^{hot}=0.5$ (50%).\n",
    "\n",
    "We present a function to compute these $\\Delta E$ to compute the temperatures later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T01:23:10.973546Z",
     "start_time": "2023-02-14T01:23:10.973535Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_delta_e_ising(J, h, scaling_correction = True):\n",
    "    \"\"\"\n",
    "    This function computes the hot and cold deltas of Energy for a given Ising problem.\n",
    "    For the cold delta, it provides a count of the number of variables with the minimum mean field energy.\n",
    "    This assume the symmetric matrix form for J, and h represented as a vector\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    J : np.ndarray\n",
    "        The J matrix of the Ising problem\n",
    "    h : np.ndarray\n",
    "        The h vector of the Ising problem\n",
    "    scaling_correction : bool, optional\n",
    "        Whether to apply the scaling correction to the delta_e_cold, by default True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    delta_e_hot : float\n",
    "        The delta of Energy at the hot temperature limit\n",
    "    delta_e_cold : float\n",
    "        The delta of Energy at the cold temperature limit\n",
    "    count_min_i : int\n",
    "        The number of variables with the minimum mean field energy\n",
    "    \"\"\"\n",
    "    max_mean_field = np.max(np.sum(np.abs(J), axis = 1) + np.abs(h))\n",
    "    delta_e_hot = 2 * max_mean_field\n",
    "\n",
    "    min_mean_field = np.minimum(np.min(np.abs(J[J != 0]), initial=np.inf), np.min(np.abs(h[h != 0]), initial=np.inf))\n",
    "    min_mean_field_ji = np.where(abs(J) != 0, abs(J), np.inf).min(axis=1)\n",
    "    min_mean_field_hi = np.where(abs(h) != 0, abs(h), min_mean_field_ji)\n",
    "    if scaling_correction:\n",
    "        count_min_i = np.sum(np.minimum(min_mean_field_ji, min_mean_field_hi) == min_mean_field)\n",
    "    else:\n",
    "        count_min_i = 1\n",
    "    delta_e_cold = 2 * min_mean_field\n",
    "\n",
    "    return delta_e_hot, delta_e_cold, count_min_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Unconstrained Binary Optimization\n",
    "Although PySA can handle Quadratic Unconstrained Binary Optimization (QUBO) problems natively using the argument `problem_type='qubo'`, for the $\\Delta E$ computation, we instead transform the coefficients of the QUBO problem into an Ising model and then call the function previously designed.\n",
    "This transformation is based on the problem definition::\n",
    "$$\n",
    "\\min_{x \\in \\{0,1 \\}^N} \\sum_{(ij) \\in E(G)} Q_{ij}x_i x_j + \\sum_{i \\in V(G)}Q_{ii}x_i + c_Q = \\min_{x \\in \\{0,1 \\}^n}  x^\\top Q x + c_Q\n",
    "$$\n",
    "where we optimize over binary variables $x \\in \\{ 0,1 \\}^N$, on a constrained graph $G(V,E)$ defined by an adjacency matrix $Q$. We also include an arbitrary offset  $c_Q$.\n",
    "\n",
    "The transformation is a linear mapping of $x \\in \\{ 0,1 \\}^n \\to \\sigma \\in \\{ -1,1 \\}^N$ by setting $\\sigma_i = 2x_i - 1$. The remaining coefficient mappings follow from this definition and are implemented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T01:23:10.975039Z",
     "start_time": "2023-02-14T01:23:10.975023Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_delta_e_qubo(Q):\n",
    "    \"\"\"\n",
    "    This function computes the hot and cold deltas of Energy for a given QUBO problem.\n",
    "    It transform the problem into a Ising problem and then use the get_delta_e_ising function.\n",
    "    This assume the symmetric matrix form for Q\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    Q : np.ndarray\n",
    "        The Q matrix of the QUBO problem\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    delta_e_hot : float\n",
    "        The delta of Energy at the hot temperature limit\n",
    "    delta_e_cold : float\n",
    "        The delta of Energy at the cold temperature limit\n",
    "    count_min_i : int\n",
    "        The number of variables with the minimum mean field energy\n",
    "    \"\"\"\n",
    "    J = (Q - np.diag(np.diag(Q.A))) / 4.\n",
    "    h = np.ones(Q.shape[0]) @ Q / 2.\n",
    "    return get_delta_e_ising(J, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature computation for Wishart problem\n",
    "With these functions, the range for the temperature is defined as $T \\in \\left[ -\\frac{\\Delta E^{cold}}{\\log(p^{cold}/N^{mingap})} ,  -\\frac{\\Delta E^{hot}}{\\log(p^{hot})} \\right]$.\n",
    "We evaluate those temperatures using the functions above to provide them to PySA as parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T01:23:10.976100Z",
     "start_time": "2023-02-14T01:23:10.976089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define transition probabilities (in percentages)\n",
    "phot = 50.\n",
    "pcold = 1.\n",
    "\n",
    "delta_e_hot, delta_e_cold, count_min_i = get_delta_e_ising(ising, np.zeros(ising.shape[0]))\n",
    "max_temp = - delta_e_hot / np.log(phot / 100.)\n",
    "min_temp = - delta_e_cold / np.log(pcold / 100. / count_min_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time To Solution performance metric\n",
    "The performance metrics when evaluating PySA might be contradictory. On one hand you would like to obtain a large probability of finding a right solution (the definition of right comes from what you define as success). On the other hand, the time it takes to solve these cases should be as small as possible.\n",
    "This is why we are interested in a metric that combines both, and that is why we settle on the Time To Solution (TTS) which is defined as\n",
    "$$\n",
    "TTS = t\\frac{\\log{1-s}}{\\log{1-p}},\n",
    "$$\n",
    "where $t$ is the mean runtime, $s$ is a success factor, usually takes as $s = 99\\%$, and $p$ is the success probability, usually accounted as the observed/empirical success probability.\n",
    "\n",
    "One usually reads this as the time to solution within 99\\% probability.\n",
    "\n",
    "We provide a function to compute this $TTS_{99\\%}$ given the runtime of the algorithm, the observed energies returned by PySA, the ground state energy, a tolerance for determining what we call success (in this case a relative difference with the ground state), the s value, and a value to place when not a single observation satisfied the success threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T01:23:10.977269Z",
     "start_time": "2023-02-14T01:23:10.977257Z"
    }
   },
   "outputs": [],
   "source": [
    "def tts_objective_fcn(energies, mean_runtime, gs_energy, s=0.99, opt_gap=0.05, fail_value=1e10):\n",
    "    \"\"\"\n",
    "    This function computes the time-to-solution for a given set of energies given a mean-runtime and the ground state energy.\n",
    "    It is based on the following paper:\n",
    "    https://arxiv.org/pdf/1905.10876.pdf\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    energies : np.ndarray\n",
    "        The energies of the samples\n",
    "    mean_runtime : float\n",
    "        The mean runtime of the samples\n",
    "    gs_energy : float\n",
    "        The ground state energy of the problem\n",
    "    s : float, optional\n",
    "        The success probability, by default 0.99\n",
    "    opt_gap : float, optional\n",
    "        The optimality gap, by default 0.05\n",
    "    fail_value : float, optional\n",
    "        The value to return if the success probability is 0, by default 1e10\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The time-to-solution value\n",
    "    \"\"\"\n",
    "    p_succ = np.mean(energies <= gs_energy * (1. -  opt_gap))\n",
    "    print(\"Probability of success:\", p_succ)\n",
    "\n",
    "    if p_succ == 0.:\n",
    "        return fail_value\n",
    "    elif p_succ >= s:\n",
    "        return mean_runtime\n",
    "    else:\n",
    "        tts = mean_runtime *  np.log(1 - s) / np.log(1 - p_succ)\n",
    "        print(\"Time-to-solution:\", tts, \"seconds\")\n",
    "        return tts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the PySA run\n",
    "These functions now allow us to run PySA. We created a wrapper function such that we can compute the $TTS_{99\\%}$ directly from the outputs and interface it with the hyperparameter optimization library Hyperopt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T01:23:10.978443Z",
     "start_time": "2023-02-14T01:23:10.978431Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_pysa(ising_model, fixed_params, tuned_params, gs_energy):\n",
    "    \"\"\"\n",
    "    This function runs PySA with the given parameters and returns the time-to-solution value.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ising_model : np.ndarray\n",
    "        The Ising matrix of the problem\n",
    "    fixed_params : dict\n",
    "        The fixed parameters for PySA\n",
    "    tuned_params : dict\n",
    "        The tuned parameters for PySA\n",
    "    gs_energy : float\n",
    "        The ground state energy of the problem\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        The result of the PySA run\n",
    "\n",
    "    Note: Fixed_params, tuned_params, and kwargs keys need to match the pysa arguments, e.g., \n",
    "        num_sweeps: int, \n",
    "        num_reads: int = 1,\n",
    "        num_replicas: int = None,\n",
    "        temps: np.ndarray = None,\n",
    "        min_temp: float = 0.3,\n",
    "        max_temp: float = 1.5,\n",
    "        update_strategy: str = 'random',\n",
    "        initialize_strategy: str = 'random',\n",
    "        init_energies: List[float] = None,\n",
    "        recompute_energy: bool = False,\n",
    "        sort_output_temps: bool = False,\n",
    "        return_dataframe: bool = True,\n",
    "        parallel: bool = True,\n",
    "        use_pt: bool = True,\n",
    "        send_background: bool = False,\n",
    "        verbose: bool = False\n",
    "    \"\"\"\n",
    "    # Combine fixed and tuned parameters\n",
    "    joint_params = fixed_params\n",
    "    joint_params.update(tuned_params)\n",
    "\n",
    "    # Fix types of num_sweeps and num_replicas\n",
    "    joint_params['num_sweeps'] = int(joint_params['num_sweeps'])\n",
    "    joint_params['num_replicas'] = int(joint_params['num_replicas']) \n",
    "\n",
    "    solver = Solver(problem=ising_model, problem_type='ising', float_type='float32')\n",
    "    result = solver.metropolis_update(**joint_params)\n",
    "    energies =  2 * result['best_energy'][1:] # Note: energy is 1/2 * state @ ising @ state\n",
    "    mean_runtime = 1e-6 * result['runtime (us)'][1:].mean()\n",
    "    print(tuned_params)\n",
    "    tts = tts_objective_fcn(energies, mean_runtime, gs_energy)\n",
    "\n",
    "    return {\n",
    "        'loss': tts,\n",
    "        'status': STATUS_OK,\n",
    "        'num_sweeps': joint_params['num_sweeps'],\n",
    "        'num_replicas': joint_params['num_replicas'],\n",
    "        # -- store other results like this\n",
    "        'result': result,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing PySA\n",
    "We can fix certain parameters and allow others to be (later) modified. Moreover, we provide the ground state energy for the internal computation of $TTS$ within our wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T01:23:10.979309Z",
     "start_time": "2023-02-14T01:23:10.979297Z"
    }
   },
   "outputs": [],
   "source": [
    "fixed_params = {'min_temp' : min_temp,\n",
    "                'max_temp' : max_temp,\n",
    "                'num_reads' : 1001,\n",
    "                'update_strategy' : 'random',\n",
    "                'recompute_energy' : True,\n",
    "                'sort_output_temps' : True,\n",
    "                'parallel' : True,\n",
    "                'use_pt' : True,\n",
    "                'verbose' : False}\n",
    "\n",
    "tuned_params = {'num_sweeps' : 100,\n",
    "                'num_replicas' : 4}\n",
    "\n",
    "run_pysa(ising_model=ising, fixed_params=fixed_params, tuned_params=tuned_params, gs_energy=gs_energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimization\n",
    "As it can be seen, fixing the values of certain parameters yields an $TTS_{99\\%}$, which we wish to optimize. Therefore, we use Hyperopt, and its algorithm of the tree of Parzen to perform this hyperparameter optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T01:23:10.980472Z",
     "start_time": "2023-02-14T01:23:10.980447Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameter search space\n",
    "tuned_params_space = {\n",
    "    'num_sweeps': hp.qloguniform('num_sweeps', 0, 4, 1), # loguniform between 1 and 1000\n",
    "    'num_replicas': hp.quniform('num_replicas', 1, 16, 1), # uniform between 1 and 16\n",
    "    }\n",
    "\n",
    "#define the hyperopt objective function\n",
    "objective = lambda tuned_params : run_pysa(ising, fixed_params, tuned_params, gs_energy)\n",
    "trials = Trials()\n",
    "best_params = fmin(fn = objective,\n",
    "                space=tuned_params_space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=50,\n",
    "                trials=trials)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing the hyperparameter optimization, we report the best found values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T01:23:10.981548Z",
     "start_time": "2023-02-14T01:23:10.981537Z"
    }
   },
   "outputs": [],
   "source": [
    "best_hyperparams = trials.argmin\n",
    "best_tts = trials.best_trial['result']['loss']\n",
    "best_iter = trials.best_trial['tid']\n",
    "print(\"Best hyperparameters:\", best_hyperparams)\n",
    "print(\"Best time-to-solution:\", best_tts, \"seconds\")\n",
    "print(\"Best iteration:\", best_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we present a plot of the advance of the hyperparameter optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T01:23:10.982451Z",
     "start_time": "2023-02-14T01:23:10.982439Z"
    }
   },
   "outputs": [],
   "source": [
    "losses = np.array(trials.losses())\n",
    "f, ax = plt.subplots()\n",
    "ax.plot(\n",
    "    np.ma.masked_where(losses > 1e9, losses),\n",
    "    label='TTS')\n",
    "ax.axhline(y=best_tts, color='r', linestyle='--', label='Best TTS')\n",
    "ax.set_xlabel('Hyperopt iteration')\n",
    "ax.set_ylabel('TTS_99 (s)')\n",
    "ax.legend()\n",
    "ax.title.set_text('TTS_99 vs. Hyperopt iteration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretty plots\n",
    "For a more advanced plots, you would need to import Pandas and Plotly. Then a contour plot of the experiments will be shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-14T01:23:10.983243Z",
     "start_time": "2023-02-14T01:23:10.983231Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "trials_df = pd.DataFrame(trials.results)\n",
    "trials_df[\"trial_number\"] = trials_df.index\n",
    "filter = (\n",
    "    (trials_df['loss'] < 5e10)\n",
    ")\n",
    "# plotly express does not support contour plots so we will use `graph_objects` instead. `go.Contour\n",
    "# automatically interpolates \"z\" values for our loss.\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "    go.Contour(\n",
    "        z=np.log10(trials_df.loc[filter, \"loss\"]),\n",
    "        x=trials_df.loc[filter, \"num_sweeps\"],\n",
    "        y=trials_df.loc[filter, \"num_replicas\"],\n",
    "        contours=dict(\n",
    "            showlabels=True,  # show labels on contours\n",
    "            # label font properties\n",
    "            labelfont=dict(size=12, color=\"white\",),\n",
    "        ),\n",
    "        colorbar=dict(title=\"log10(TTS (s))\", titleside=\"right\",),\n",
    "        connectgaps=True,\n",
    "        hoverinfo='skip',\n",
    "        hoverongaps=False,\n",
    "    ),\n",
    "    go.Contour(\n",
    "        name='Explored values',\n",
    "        z=trials_df.loc[filter, \"loss\"],\n",
    "        x=trials_df.loc[filter, \"num_sweeps\"],\n",
    "        y=trials_df.loc[filter, \"num_replicas\"],\n",
    "        connectgaps=False,\n",
    "        showscale=False,\n",
    "        colorbar=None,\n",
    "        colorscale='greys',\n",
    "        hoverongaps=False,\n",
    "        showlegend=False,\n",
    "        hovertemplate=\"TTS: %{z:.2r} s<br>sweeps: %{x}<br>replicas: %{y}<extra></extra>\",\n",
    "    ),\n",
    "    ]\n",
    ")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"sweeps\",\n",
    "    yaxis_title=\"replicas\",\n",
    "    title={\n",
    "        \"text\": \"TTS vs. sweeps and replicas | pcold == 1, phot == 50\",\n",
    "        \"xanchor\": \"center\",\n",
    "        \"yanchor\": \"top\",\n",
    "        \"x\": 0.5,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "8694fad53f786df7df254898a614e8419731754eee6a41d86dba2cf3f9f559d8"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
