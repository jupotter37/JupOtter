{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from time import time\n",
    "from os.path import join as join_path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import multiprocessing\n",
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "import logging # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from utils import clean_text, EpochSaver\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "cord_data_dir = 'data'\n",
    "cord_data_path = join_path(cord_data_dir, 'cord-19-data.csv')\n",
    "w2v_saved_models_dir = 'models-word2vec'\n",
    "saved_models_prefix = 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cord_data = pd.read_csv(cord_data_path)\n",
    "cord_data_eng = cord_data[cord_data['language'] == 'en']\n",
    "eng_texts = cord_data_eng['body_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6bc95ddf70f47f8a193edbdae28c8e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=35708), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of CORD-19 sentences: 7097680\n"
     ]
    }
   ],
   "source": [
    "cord_num_sentences = 0\n",
    "for text in tqdm(eng_texts):\n",
    "    sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    cord_num_sentences += len(sentences)\n",
    "print(f'Total number of CORD-19 sentences: {cord_num_sentences}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CORDDataIteratorWord2Vec():\n",
    "    def __init__(self, texts: np.ndarray):\n",
    "        self.texts = texts\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for text in self.texts:\n",
    "            sentences = nltk.tokenize.sent_tokenize(text)\n",
    "            cleaned_sentences = [clean_text(sent) for sent in sentences]\n",
    "            for sentence in cleaned_sentences:\n",
    "                yield sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cord_sentences = CORDDataIteratorWord2Vec(eng_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn word embeddings using Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpochSaver(CallbackAny2Vec):\n",
    "    '''Callback to save model after each epoch.'''\n",
    "\n",
    "    def __init__(self, output_dir: str, prefix: str, start_epoch: int = 1):\n",
    "        self.output_dir = output_dir\n",
    "        self.prefix = prefix\n",
    "        self.epoch = start_epoch\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        output_path = join_path(self.output_dir, f'{self.prefix}_epoch_{self.epoch}.model')\n",
    "        model.save(output_path)\n",
    "        self.epoch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup initial model\n",
    "w2v_model = Word2Vec(\n",
    "    min_count=20,\n",
    "    window=2,\n",
    "    size=300,\n",
    "    negative=5,\n",
    "    workers=cores-1,\n",
    "    callbacks=[EpochSaver(w2v_saved_models_dir, saved_models_prefix)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0392a23da74940ba244cbe85bcc2a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7097680), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 07:48:01: collecting all words and their counts\n",
      "INFO - 07:48:01: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 07:48:22: PROGRESS: at sentence #70976, processed 1013256 words, keeping 51891 word types\n",
      "INFO - 07:48:40: PROGRESS: at sentence #141952, processed 2029040 words, keeping 84651 word types\n",
      "INFO - 07:48:59: PROGRESS: at sentence #212928, processed 3054106 words, keeping 115992 word types\n",
      "INFO - 07:49:17: PROGRESS: at sentence #283904, processed 4068911 words, keeping 142369 word types\n",
      "INFO - 07:49:36: PROGRESS: at sentence #354880, processed 5105447 words, keeping 164500 word types\n",
      "INFO - 07:49:55: PROGRESS: at sentence #425856, processed 6124854 words, keeping 185561 word types\n",
      "INFO - 07:50:13: PROGRESS: at sentence #496832, processed 7156844 words, keeping 206875 word types\n",
      "INFO - 07:50:31: PROGRESS: at sentence #567808, processed 8149173 words, keeping 233078 word types\n",
      "INFO - 07:50:50: PROGRESS: at sentence #638784, processed 9174245 words, keeping 253535 word types\n",
      "INFO - 07:51:09: PROGRESS: at sentence #709760, processed 10216020 words, keeping 274898 word types\n",
      "INFO - 07:51:27: PROGRESS: at sentence #780736, processed 11238609 words, keeping 294666 word types\n",
      "INFO - 07:51:49: PROGRESS: at sentence #851712, processed 12245580 words, keeping 316227 word types\n",
      "INFO - 07:52:03: PROGRESS: at sentence #922688, processed 13240249 words, keeping 335029 word types\n",
      "INFO - 07:52:22: PROGRESS: at sentence #993664, processed 14262830 words, keeping 353733 word types\n",
      "INFO - 07:52:40: PROGRESS: at sentence #1064640, processed 15278108 words, keeping 373005 word types\n",
      "INFO - 07:52:59: PROGRESS: at sentence #1135616, processed 16311924 words, keeping 391304 word types\n",
      "INFO - 07:53:17: PROGRESS: at sentence #1206592, processed 17332005 words, keeping 409010 word types\n",
      "INFO - 07:53:36: PROGRESS: at sentence #1277568, processed 18365516 words, keeping 426725 word types\n",
      "INFO - 07:53:54: PROGRESS: at sentence #1348544, processed 19357132 words, keeping 444969 word types\n",
      "INFO - 07:54:12: PROGRESS: at sentence #1419520, processed 20388633 words, keeping 461649 word types\n",
      "INFO - 07:54:31: PROGRESS: at sentence #1490496, processed 21431108 words, keeping 479407 word types\n",
      "INFO - 07:54:49: PROGRESS: at sentence #1561472, processed 22458197 words, keeping 496617 word types\n",
      "INFO - 07:55:07: PROGRESS: at sentence #1632448, processed 23466901 words, keeping 514238 word types\n",
      "INFO - 07:55:26: PROGRESS: at sentence #1703424, processed 24499209 words, keeping 533721 word types\n",
      "INFO - 07:55:44: PROGRESS: at sentence #1774400, processed 25505790 words, keeping 551156 word types\n",
      "INFO - 07:56:02: PROGRESS: at sentence #1845376, processed 26528511 words, keeping 567701 word types\n",
      "INFO - 07:56:21: PROGRESS: at sentence #1916352, processed 27583151 words, keeping 585474 word types\n",
      "INFO - 07:56:40: PROGRESS: at sentence #1987328, processed 28613004 words, keeping 602106 word types\n",
      "INFO - 07:56:58: PROGRESS: at sentence #2058304, processed 29629498 words, keeping 619329 word types\n",
      "INFO - 07:57:16: PROGRESS: at sentence #2129280, processed 30599943 words, keeping 639410 word types\n",
      "INFO - 07:57:34: PROGRESS: at sentence #2200256, processed 31511971 words, keeping 654439 word types\n",
      "INFO - 07:57:52: PROGRESS: at sentence #2271232, processed 32462806 words, keeping 673163 word types\n",
      "INFO - 07:58:10: PROGRESS: at sentence #2342208, processed 33493936 words, keeping 686526 word types\n",
      "INFO - 07:58:28: PROGRESS: at sentence #2413184, processed 34504722 words, keeping 700335 word types\n",
      "INFO - 07:58:47: PROGRESS: at sentence #2484160, processed 35508408 words, keeping 721634 word types\n",
      "INFO - 07:59:05: PROGRESS: at sentence #2555136, processed 36518559 words, keeping 734308 word types\n",
      "INFO - 07:59:23: PROGRESS: at sentence #2626112, processed 37523985 words, keeping 745615 word types\n",
      "INFO - 07:59:41: PROGRESS: at sentence #2697088, processed 38539566 words, keeping 756433 word types\n",
      "INFO - 07:59:59: PROGRESS: at sentence #2768064, processed 39539481 words, keeping 767982 word types\n",
      "INFO - 08:00:18: PROGRESS: at sentence #2839040, processed 40574833 words, keeping 779924 word types\n",
      "INFO - 08:00:35: PROGRESS: at sentence #2910016, processed 41492662 words, keeping 805644 word types\n",
      "INFO - 08:00:52: PROGRESS: at sentence #2980992, processed 42415368 words, keeping 829093 word types\n",
      "INFO - 08:01:10: PROGRESS: at sentence #3051968, processed 43386680 words, keeping 849092 word types\n",
      "INFO - 08:01:28: PROGRESS: at sentence #3122944, processed 44317041 words, keeping 906644 word types\n",
      "INFO - 08:01:48: PROGRESS: at sentence #3193920, processed 45227819 words, keeping 930769 word types\n",
      "INFO - 08:02:05: PROGRESS: at sentence #3264896, processed 46130813 words, keeping 949697 word types\n",
      "INFO - 08:02:23: PROGRESS: at sentence #3335872, processed 47084527 words, keeping 973679 word types\n",
      "INFO - 08:02:40: PROGRESS: at sentence #3406848, processed 47998100 words, keeping 992495 word types\n",
      "INFO - 08:02:58: PROGRESS: at sentence #3477824, processed 48953589 words, keeping 1008676 word types\n",
      "INFO - 08:03:16: PROGRESS: at sentence #3548800, processed 49928546 words, keeping 1021366 word types\n",
      "INFO - 08:03:33: PROGRESS: at sentence #3619776, processed 50822270 words, keeping 1032193 word types\n",
      "INFO - 08:03:49: PROGRESS: at sentence #3690752, processed 51671382 words, keeping 1039488 word types\n",
      "INFO - 08:04:07: PROGRESS: at sentence #3761728, processed 52628540 words, keeping 1048076 word types\n",
      "INFO - 08:04:24: PROGRESS: at sentence #3832704, processed 53535437 words, keeping 1054998 word types\n",
      "INFO - 08:04:42: PROGRESS: at sentence #3903680, processed 54493816 words, keeping 1061699 word types\n",
      "INFO - 08:04:59: PROGRESS: at sentence #3974656, processed 55427230 words, keeping 1069936 word types\n",
      "INFO - 08:05:17: PROGRESS: at sentence #4045632, processed 56372701 words, keeping 1078316 word types\n",
      "INFO - 08:05:35: PROGRESS: at sentence #4116608, processed 57272531 words, keeping 1082244 word types\n",
      "INFO - 08:05:52: PROGRESS: at sentence #4187584, processed 58191977 words, keeping 1089543 word types\n",
      "INFO - 08:06:10: PROGRESS: at sentence #4258560, processed 59038691 words, keeping 1095837 word types\n",
      "INFO - 08:06:26: PROGRESS: at sentence #4329536, processed 59883182 words, keeping 1099737 word types\n",
      "INFO - 08:06:43: PROGRESS: at sentence #4400512, processed 60752925 words, keeping 1105272 word types\n",
      "INFO - 08:07:00: PROGRESS: at sentence #4471488, processed 61587295 words, keeping 1108209 word types\n",
      "INFO - 08:07:17: PROGRESS: at sentence #4542464, processed 62489651 words, keeping 1112378 word types\n",
      "INFO - 08:07:35: PROGRESS: at sentence #4613440, processed 63476364 words, keeping 1130982 word types\n",
      "INFO - 08:07:52: PROGRESS: at sentence #4684416, processed 64390756 words, keeping 1146553 word types\n",
      "INFO - 08:08:10: PROGRESS: at sentence #4755392, processed 65337550 words, keeping 1158605 word types\n",
      "INFO - 08:08:27: PROGRESS: at sentence #4826368, processed 66291706 words, keeping 1172434 word types\n",
      "INFO - 08:08:45: PROGRESS: at sentence #4897344, processed 67099674 words, keeping 1179689 word types\n",
      "INFO - 08:09:02: PROGRESS: at sentence #4968320, processed 67931384 words, keeping 1187561 word types\n",
      "INFO - 08:09:19: PROGRESS: at sentence #5039296, processed 68774596 words, keeping 1196120 word types\n",
      "INFO - 08:09:37: PROGRESS: at sentence #5110272, processed 69709397 words, keeping 1205705 word types\n",
      "INFO - 08:09:55: PROGRESS: at sentence #5181248, processed 70675445 words, keeping 1215113 word types\n",
      "INFO - 08:10:13: PROGRESS: at sentence #5252224, processed 71624446 words, keeping 1224916 word types\n",
      "INFO - 08:10:31: PROGRESS: at sentence #5323200, processed 72583699 words, keeping 1234948 word types\n",
      "INFO - 08:10:49: PROGRESS: at sentence #5394176, processed 73549101 words, keeping 1244472 word types\n",
      "INFO - 08:11:07: PROGRESS: at sentence #5465152, processed 74492805 words, keeping 1254332 word types\n",
      "INFO - 08:11:25: PROGRESS: at sentence #5536128, processed 75447304 words, keeping 1263990 word types\n",
      "INFO - 08:11:43: PROGRESS: at sentence #5607104, processed 76398857 words, keeping 1274284 word types\n",
      "INFO - 08:12:02: PROGRESS: at sentence #5678080, processed 77349140 words, keeping 1284365 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 08:12:20: PROGRESS: at sentence #5749056, processed 78309142 words, keeping 1293451 word types\n",
      "INFO - 08:12:39: PROGRESS: at sentence #5820032, processed 79280301 words, keeping 1302643 word types\n",
      "INFO - 08:12:58: PROGRESS: at sentence #5891008, processed 80236804 words, keeping 1311421 word types\n",
      "INFO - 08:13:17: PROGRESS: at sentence #5961984, processed 81191278 words, keeping 1320204 word types\n",
      "INFO - 08:13:36: PROGRESS: at sentence #6032960, processed 82148730 words, keeping 1328579 word types\n",
      "INFO - 08:13:54: PROGRESS: at sentence #6103936, processed 83102084 words, keeping 1339290 word types\n",
      "INFO - 08:14:13: PROGRESS: at sentence #6174912, processed 84058376 words, keeping 1348821 word types\n",
      "INFO - 08:14:31: PROGRESS: at sentence #6245888, processed 85011177 words, keeping 1357663 word types\n",
      "INFO - 08:14:49: PROGRESS: at sentence #6316864, processed 85969150 words, keeping 1367554 word types\n",
      "INFO - 08:15:07: PROGRESS: at sentence #6387840, processed 86933176 words, keeping 1376239 word types\n",
      "INFO - 08:15:25: PROGRESS: at sentence #6458816, processed 87894180 words, keeping 1385072 word types\n",
      "INFO - 08:15:43: PROGRESS: at sentence #6529792, processed 88866448 words, keeping 1393313 word types\n",
      "INFO - 08:16:01: PROGRESS: at sentence #6600768, processed 89823308 words, keeping 1401495 word types\n",
      "INFO - 08:16:20: PROGRESS: at sentence #6671744, processed 90780832 words, keeping 1410122 word types\n",
      "INFO - 08:16:39: PROGRESS: at sentence #6742720, processed 91729366 words, keeping 1419134 word types\n",
      "INFO - 08:16:58: PROGRESS: at sentence #6813696, processed 92677735 words, keeping 1427475 word types\n",
      "INFO - 08:17:17: PROGRESS: at sentence #6884672, processed 93640282 words, keeping 1436793 word types\n",
      "INFO - 08:17:35: PROGRESS: at sentence #6955648, processed 94583671 words, keeping 1444954 word types\n",
      "INFO - 08:17:54: PROGRESS: at sentence #7026624, processed 95529312 words, keeping 1453372 word types\n",
      "INFO - 08:18:12: PROGRESS: at sentence #7097600, processed 96496828 words, keeping 1463241 word types\n",
      "INFO - 08:18:12: collected 1463257 word types from a corpus of 96497880 raw words and 7097680 sentences\n",
      "INFO - 08:18:12: Loading a fresh vocabulary\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 08:18:13: effective_min_count=20 retains 93856 unique words (6% of original 1463257, drops 1369401)\n",
      "INFO - 08:18:13: effective_min_count=20 leaves 93320129 word corpus (96% of original 96497880, drops 3177751)\n",
      "INFO - 08:18:14: deleting the raw counts dictionary of 1463257 items\n",
      "INFO - 08:18:14: sample=0.001 downsamples 17 most-common words\n",
      "INFO - 08:18:14: downsampling leaves estimated 90805423 word corpus (97.3% of prior 93320129)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cannot sort vocabulary after model weights already initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ead31db4fe12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcord_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcord_num_sentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_per\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcord_num_sentences\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Time to build vocab: {round((time() - t) / 60, 2)} mins'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonavin/anaconda3/lib/python3.7/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, sentences, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    939\u001b[0m         report_values = self.vocabulary.prepare_vocab(\n\u001b[1;32m    940\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_raw_vocab\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m             trim_rule=trim_rule, **kwargs)\n\u001b[0m\u001b[1;32m    942\u001b[0m         \u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'memory'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_retained_words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonavin/anaconda3/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mprepare_vocab\u001b[0;34m(self, hs, negative, wv, update, keep_raw_vocab, trim_rule, min_count, sample, dry_run)\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msorted_vocab\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1757\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1759\u001b[0m             \u001b[0;31m# add info about each word's Huffman encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jonavin/anaconda3/lib/python3.7/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36msort_vocab\u001b[0;34m(self, wv)\u001b[0m\n\u001b[1;32m   1602\u001b[0m         \u001b[0;34m\"\"\"Sort the vocabulary so the most frequent words have the lowest indexes.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1604\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot sort vocabulary after model weights already initialized.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1605\u001b[0m         \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1606\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot sort vocabulary after model weights already initialized."
     ]
    }
   ],
   "source": [
    "# Build vocabulary\n",
    "t = time()\n",
    "w2v_model.build_vocab(tqdm(cord_sentences, total=cord_num_sentences), progress_per=int(cord_num_sentences / 100))\n",
    "print(f'Time to build vocab: {round((time() - t) / 60, 2)} mins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 08:35:20: training model with 15 workers on 93856 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2\n",
      "INFO - 08:35:22: EPOCH 1 - PROGRESS: at 0.06% examples, 50206 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:35:52: EPOCH 1 - PROGRESS: at 1.59% examples, 48588 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:36:22: EPOCH 1 - PROGRESS: at 3.18% examples, 49548 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:36:52: EPOCH 1 - PROGRESS: at 4.75% examples, 49824 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:37:22: EPOCH 1 - PROGRESS: at 6.37% examples, 50213 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:37:52: EPOCH 1 - PROGRESS: at 7.97% examples, 50201 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:38:22: EPOCH 1 - PROGRESS: at 9.50% examples, 49999 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:38:52: EPOCH 1 - PROGRESS: at 11.04% examples, 49920 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:39:22: EPOCH 1 - PROGRESS: at 12.57% examples, 49631 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:39:52: EPOCH 1 - PROGRESS: at 14.11% examples, 49554 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:40:23: EPOCH 1 - PROGRESS: at 15.64% examples, 49440 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:40:53: EPOCH 1 - PROGRESS: at 17.18% examples, 49420 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:41:23: EPOCH 1 - PROGRESS: at 18.75% examples, 49409 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:41:53: EPOCH 1 - PROGRESS: at 20.30% examples, 49444 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:42:23: EPOCH 1 - PROGRESS: at 21.86% examples, 49507 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:42:53: EPOCH 1 - PROGRESS: at 23.41% examples, 49472 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:43:24: EPOCH 1 - PROGRESS: at 24.90% examples, 49286 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:43:54: EPOCH 1 - PROGRESS: at 26.53% examples, 49445 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:44:24: EPOCH 1 - PROGRESS: at 28.10% examples, 49487 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:44:54: EPOCH 1 - PROGRESS: at 29.71% examples, 49478 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:45:24: EPOCH 1 - PROGRESS: at 31.35% examples, 49386 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:45:54: EPOCH 1 - PROGRESS: at 32.90% examples, 49334 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:46:24: EPOCH 1 - PROGRESS: at 34.50% examples, 49391 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:46:54: EPOCH 1 - PROGRESS: at 36.11% examples, 49444 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:47:24: EPOCH 1 - PROGRESS: at 37.71% examples, 49472 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:47:54: EPOCH 1 - PROGRESS: at 39.30% examples, 49528 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:48:25: EPOCH 1 - PROGRESS: at 40.94% examples, 49450 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:48:56: EPOCH 1 - PROGRESS: at 42.63% examples, 49450 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:49:26: EPOCH 1 - PROGRESS: at 44.31% examples, 49334 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:49:56: EPOCH 1 - PROGRESS: at 46.01% examples, 49295 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:50:26: EPOCH 1 - PROGRESS: at 47.68% examples, 49244 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:50:56: EPOCH 1 - PROGRESS: at 49.37% examples, 49262 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:51:26: EPOCH 1 - PROGRESS: at 51.04% examples, 49271 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:51:56: EPOCH 1 - PROGRESS: at 52.73% examples, 49224 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:52:26: EPOCH 1 - PROGRESS: at 54.45% examples, 49261 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:52:56: EPOCH 1 - PROGRESS: at 56.13% examples, 49294 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:53:26: EPOCH 1 - PROGRESS: at 57.80% examples, 49285 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:53:57: EPOCH 1 - PROGRESS: at 59.57% examples, 49289 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:54:27: EPOCH 1 - PROGRESS: at 61.31% examples, 49238 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:54:57: EPOCH 1 - PROGRESS: at 63.07% examples, 49203 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:55:28: EPOCH 1 - PROGRESS: at 64.67% examples, 49119 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:55:58: EPOCH 1 - PROGRESS: at 66.40% examples, 49166 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:56:28: EPOCH 1 - PROGRESS: at 68.01% examples, 49138 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:56:58: EPOCH 1 - PROGRESS: at 69.71% examples, 49017 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:57:28: EPOCH 1 - PROGRESS: at 71.38% examples, 48921 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:57:59: EPOCH 1 - PROGRESS: at 73.01% examples, 48916 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:58:29: EPOCH 1 - PROGRESS: at 74.64% examples, 48912 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:58:59: EPOCH 1 - PROGRESS: at 76.23% examples, 48897 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:59:29: EPOCH 1 - PROGRESS: at 77.86% examples, 48882 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 08:59:59: EPOCH 1 - PROGRESS: at 79.49% examples, 48879 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:00:29: EPOCH 1 - PROGRESS: at 81.11% examples, 48873 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:00:59: EPOCH 1 - PROGRESS: at 82.74% examples, 48878 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:01:29: EPOCH 1 - PROGRESS: at 84.38% examples, 48887 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:02:00: EPOCH 1 - PROGRESS: at 85.96% examples, 48852 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:02:30: EPOCH 1 - PROGRESS: at 87.59% examples, 48842 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:03:00: EPOCH 1 - PROGRESS: at 89.17% examples, 48825 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:03:30: EPOCH 1 - PROGRESS: at 90.78% examples, 48823 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:04:00: EPOCH 1 - PROGRESS: at 92.37% examples, 48808 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:04:30: EPOCH 1 - PROGRESS: at 94.00% examples, 48814 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:05:00: EPOCH 1 - PROGRESS: at 95.69% examples, 48837 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:05:30: EPOCH 1 - PROGRESS: at 97.34% examples, 48847 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:06:01: EPOCH 1 - PROGRESS: at 99.01% examples, 48857 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:06:19: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 09:06:19: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 09:06:19: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 09:06:19: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 09:06:19: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 09:06:19: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 09:06:19: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 09:06:19: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 09:06:19: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 09:06:19: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 09:06:19: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 09:06:19: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 09:06:19: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 09:06:19: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 09:06:19: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 09:06:19: EPOCH - 1 : training on 96497880 raw words (90805423 effective words) took 1858.1s, 48870 effective words/s\n",
      "INFO - 09:06:19: saving Word2Vec object under models-word2vec-new/model_epoch_16.model, separately None\n",
      "INFO - 09:06:19: storing np array 'vectors' to models-word2vec-new/model_epoch_16.model.wv.vectors.npy\n",
      "INFO - 09:06:19: not storing attribute vectors_norm\n",
      "INFO - 09:06:19: storing np array 'syn1neg' to models-word2vec-new/model_epoch_16.model.trainables.syn1neg.npy\n",
      "INFO - 09:06:19: not storing attribute cum_table\n",
      "INFO - 09:06:19: saved models-word2vec-new/model_epoch_16.model\n",
      "INFO - 09:06:20: EPOCH 2 - PROGRESS: at 0.06% examples, 47647 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:06:51: EPOCH 2 - PROGRESS: at 1.60% examples, 48550 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:07:21: EPOCH 2 - PROGRESS: at 3.16% examples, 49154 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:07:51: EPOCH 2 - PROGRESS: at 4.73% examples, 49601 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 09:08:21: EPOCH 2 - PROGRESS: at 6.31% examples, 49678 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:08:51: EPOCH 2 - PROGRESS: at 7.90% examples, 49782 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:09:21: EPOCH 2 - PROGRESS: at 9.44% examples, 49731 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:09:51: EPOCH 2 - PROGRESS: at 11.01% examples, 49764 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:10:21: EPOCH 2 - PROGRESS: at 12.60% examples, 49733 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:10:51: EPOCH 2 - PROGRESS: at 14.13% examples, 49606 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:11:21: EPOCH 2 - PROGRESS: at 15.69% examples, 49601 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:11:52: EPOCH 2 - PROGRESS: at 17.27% examples, 49679 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:12:22: EPOCH 2 - PROGRESS: at 18.87% examples, 49743 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:12:52: EPOCH 2 - PROGRESS: at 20.45% examples, 49807 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:13:22: EPOCH 2 - PROGRESS: at 22.02% examples, 49874 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:13:52: EPOCH 2 - PROGRESS: at 23.56% examples, 49798 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:14:22: EPOCH 2 - PROGRESS: at 25.13% examples, 49766 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:14:52: EPOCH 2 - PROGRESS: at 26.70% examples, 49820 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:15:22: EPOCH 2 - PROGRESS: at 28.27% examples, 49836 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:15:52: EPOCH 2 - PROGRESS: at 29.84% examples, 49755 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:16:23: EPOCH 2 - PROGRESS: at 31.48% examples, 49526 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 09:16:53: EPOCH 2 - PROGRESS: at 33.10% examples, 49600 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:17:23: EPOCH 2 - PROGRESS: at 34.59% examples, 49484 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:17:53: EPOCH 2 - PROGRESS: at 36.03% examples, 49289 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:18:24: EPOCH 2 - PROGRESS: at 37.56% examples, 49243 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:18:54: EPOCH 2 - PROGRESS: at 39.08% examples, 49207 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:19:25: EPOCH 2 - PROGRESS: at 40.56% examples, 48997 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 09:19:55: EPOCH 2 - PROGRESS: at 42.25% examples, 48962 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:20:25: EPOCH 2 - PROGRESS: at 43.90% examples, 48889 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:20:55: EPOCH 2 - PROGRESS: at 45.61% examples, 48832 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:21:26: EPOCH 2 - PROGRESS: at 47.28% examples, 48830 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:21:56: EPOCH 2 - PROGRESS: at 48.99% examples, 48853 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:22:26: EPOCH 2 - PROGRESS: at 50.63% examples, 48808 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:22:56: EPOCH 2 - PROGRESS: at 52.38% examples, 48836 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:23:27: EPOCH 2 - PROGRESS: at 54.05% examples, 48835 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:23:57: EPOCH 2 - PROGRESS: at 55.68% examples, 48841 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:24:27: EPOCH 2 - PROGRESS: at 57.32% examples, 48813 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 09:24:57: EPOCH 2 - PROGRESS: at 59.02% examples, 48821 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:25:28: EPOCH 2 - PROGRESS: at 60.69% examples, 48724 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:25:58: EPOCH 2 - PROGRESS: at 62.42% examples, 48678 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:26:28: EPOCH 2 - PROGRESS: at 64.09% examples, 48653 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:26:58: EPOCH 2 - PROGRESS: at 65.70% examples, 48627 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:27:30: EPOCH 2 - PROGRESS: at 67.33% examples, 48533 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:28:00: EPOCH 2 - PROGRESS: at 69.21% examples, 48583 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:28:31: EPOCH 2 - PROGRESS: at 70.94% examples, 48519 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:29:01: EPOCH 2 - PROGRESS: at 72.57% examples, 48516 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:29:31: EPOCH 2 - PROGRESS: at 74.19% examples, 48516 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:30:01: EPOCH 2 - PROGRESS: at 75.79% examples, 48511 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:30:31: EPOCH 2 - PROGRESS: at 77.43% examples, 48514 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:31:01: EPOCH 2 - PROGRESS: at 79.02% examples, 48492 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:31:31: EPOCH 2 - PROGRESS: at 80.62% examples, 48481 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:32:01: EPOCH 2 - PROGRESS: at 82.23% examples, 48482 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:32:31: EPOCH 2 - PROGRESS: at 83.84% examples, 48480 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:33:01: EPOCH 2 - PROGRESS: at 85.39% examples, 48447 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:33:32: EPOCH 2 - PROGRESS: at 86.96% examples, 48416 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:34:02: EPOCH 2 - PROGRESS: at 88.54% examples, 48393 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:34:32: EPOCH 2 - PROGRESS: at 90.12% examples, 48382 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:35:02: EPOCH 2 - PROGRESS: at 91.71% examples, 48382 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:35:32: EPOCH 2 - PROGRESS: at 93.32% examples, 48389 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:36:02: EPOCH 2 - PROGRESS: at 94.94% examples, 48382 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:36:32: EPOCH 2 - PROGRESS: at 96.62% examples, 48412 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:37:02: EPOCH 2 - PROGRESS: at 98.27% examples, 48419 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:37:32: EPOCH 2 - PROGRESS: at 99.91% examples, 48432 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:37:34: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 09:37:34: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 09:37:34: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 09:37:34: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 09:37:34: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 09:37:34: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 09:37:34: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 09:37:34: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 09:37:34: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 09:37:34: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 09:37:34: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 09:37:34: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 09:37:34: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 09:37:34: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 09:37:34: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 09:37:34: EPOCH - 2 : training on 96497880 raw words (90803484 effective words) took 1874.8s, 48433 effective words/s\n",
      "INFO - 09:37:34: saving Word2Vec object under models-word2vec-new/model_epoch_17.model, separately None\n",
      "INFO - 09:37:34: storing np array 'vectors' to models-word2vec-new/model_epoch_17.model.wv.vectors.npy\n",
      "INFO - 09:37:34: not storing attribute vectors_norm\n",
      "INFO - 09:37:34: storing np array 'syn1neg' to models-word2vec-new/model_epoch_17.model.trainables.syn1neg.npy\n",
      "INFO - 09:37:34: not storing attribute cum_table\n",
      "INFO - 09:37:34: saved models-word2vec-new/model_epoch_17.model\n",
      "INFO - 09:37:36: EPOCH 3 - PROGRESS: at 0.06% examples, 48837 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:38:06: EPOCH 3 - PROGRESS: at 1.55% examples, 47422 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:38:36: EPOCH 3 - PROGRESS: at 3.17% examples, 49310 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:39:06: EPOCH 3 - PROGRESS: at 4.76% examples, 49911 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:39:36: EPOCH 3 - PROGRESS: at 6.37% examples, 50216 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:40:06: EPOCH 3 - PROGRESS: at 7.98% examples, 50267 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:40:36: EPOCH 3 - PROGRESS: at 9.59% examples, 50513 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:41:06: EPOCH 3 - PROGRESS: at 11.20% examples, 50689 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:41:36: EPOCH 3 - PROGRESS: at 12.87% examples, 50813 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 09:42:07: EPOCH 3 - PROGRESS: at 14.48% examples, 50815 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:42:37: EPOCH 3 - PROGRESS: at 16.11% examples, 50960 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:43:07: EPOCH 3 - PROGRESS: at 17.74% examples, 51047 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:43:37: EPOCH 3 - PROGRESS: at 19.38% examples, 51069 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:44:07: EPOCH 3 - PROGRESS: at 20.99% examples, 51156 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:44:37: EPOCH 3 - PROGRESS: at 22.62% examples, 51187 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:45:07: EPOCH 3 - PROGRESS: at 24.23% examples, 51167 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:45:37: EPOCH 3 - PROGRESS: at 25.84% examples, 51157 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:46:07: EPOCH 3 - PROGRESS: at 27.42% examples, 51185 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:46:38: EPOCH 3 - PROGRESS: at 29.05% examples, 51196 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:47:08: EPOCH 3 - PROGRESS: at 30.74% examples, 51094 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:47:38: EPOCH 3 - PROGRESS: at 32.39% examples, 50996 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:48:08: EPOCH 3 - PROGRESS: at 33.95% examples, 50932 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:48:38: EPOCH 3 - PROGRESS: at 35.56% examples, 50899 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:49:08: EPOCH 3 - PROGRESS: at 37.19% examples, 50928 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:49:38: EPOCH 3 - PROGRESS: at 38.83% examples, 50975 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:50:09: EPOCH 3 - PROGRESS: at 40.33% examples, 50777 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:50:39: EPOCH 3 - PROGRESS: at 42.10% examples, 50707 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:51:09: EPOCH 3 - PROGRESS: at 43.69% examples, 50523 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:51:40: EPOCH 3 - PROGRESS: at 45.36% examples, 50397 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:52:10: EPOCH 3 - PROGRESS: at 46.97% examples, 50260 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:52:40: EPOCH 3 - PROGRESS: at 48.64% examples, 50197 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:53:10: EPOCH 3 - PROGRESS: at 50.29% examples, 50154 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:53:40: EPOCH 3 - PROGRESS: at 51.98% examples, 50037 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:54:10: EPOCH 3 - PROGRESS: at 53.61% examples, 49996 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:54:40: EPOCH 3 - PROGRESS: at 55.33% examples, 50035 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:55:11: EPOCH 3 - PROGRESS: at 57.04% examples, 50064 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:55:41: EPOCH 3 - PROGRESS: at 58.73% examples, 50059 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:56:11: EPOCH 3 - PROGRESS: at 60.43% examples, 49939 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:56:41: EPOCH 3 - PROGRESS: at 62.31% examples, 49963 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:57:11: EPOCH 3 - PROGRESS: at 64.08% examples, 49969 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:57:41: EPOCH 3 - PROGRESS: at 65.74% examples, 49950 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:58:14: EPOCH 3 - PROGRESS: at 67.33% examples, 49767 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:58:44: EPOCH 3 - PROGRESS: at 69.12% examples, 49737 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:59:14: EPOCH 3 - PROGRESS: at 70.79% examples, 49615 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 09:59:44: EPOCH 3 - PROGRESS: at 72.43% examples, 49568 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:00:14: EPOCH 3 - PROGRESS: at 74.06% examples, 49552 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:00:45: EPOCH 3 - PROGRESS: at 75.65% examples, 49510 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:01:15: EPOCH 3 - PROGRESS: at 77.26% examples, 49483 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:01:45: EPOCH 3 - PROGRESS: at 78.92% examples, 49473 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:02:15: EPOCH 3 - PROGRESS: at 80.55% examples, 49462 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:02:45: EPOCH 3 - PROGRESS: at 82.14% examples, 49436 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:03:15: EPOCH 3 - PROGRESS: at 83.72% examples, 49390 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:03:47: EPOCH 3 - PROGRESS: at 85.25% examples, 49278 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:04:17: EPOCH 3 - PROGRESS: at 86.99% examples, 49331 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:04:47: EPOCH 3 - PROGRESS: at 88.57% examples, 49292 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:05:17: EPOCH 3 - PROGRESS: at 90.17% examples, 49275 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:05:47: EPOCH 3 - PROGRESS: at 91.77% examples, 49262 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:06:18: EPOCH 3 - PROGRESS: at 93.33% examples, 49223 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:06:48: EPOCH 3 - PROGRESS: at 94.92% examples, 49190 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:07:18: EPOCH 3 - PROGRESS: at 96.54% examples, 49175 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:07:48: EPOCH 3 - PROGRESS: at 98.18% examples, 49169 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:08:18: EPOCH 3 - PROGRESS: at 99.79% examples, 49151 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:08:22: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 10:08:22: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 10:08:22: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 10:08:22: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 10:08:22: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 10:08:22: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 10:08:22: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 10:08:22: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 10:08:22: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 10:08:22: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:08:22: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:08:22: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:08:22: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:08:22: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:08:22: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:08:22: EPOCH - 3 : training on 96497880 raw words (90806922 effective words) took 1847.5s, 49151 effective words/s\n",
      "INFO - 10:08:22: saving Word2Vec object under models-word2vec-new/model_epoch_18.model, separately None\n",
      "INFO - 10:08:22: storing np array 'vectors' to models-word2vec-new/model_epoch_18.model.wv.vectors.npy\n",
      "INFO - 10:08:22: not storing attribute vectors_norm\n",
      "INFO - 10:08:22: storing np array 'syn1neg' to models-word2vec-new/model_epoch_18.model.trainables.syn1neg.npy\n",
      "INFO - 10:08:22: not storing attribute cum_table\n",
      "INFO - 10:08:22: saved models-word2vec-new/model_epoch_18.model\n",
      "INFO - 10:08:23: EPOCH 4 - PROGRESS: at 0.05% examples, 47244 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:08:54: EPOCH 4 - PROGRESS: at 1.50% examples, 45926 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:09:24: EPOCH 4 - PROGRESS: at 3.05% examples, 47718 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:09:54: EPOCH 4 - PROGRESS: at 4.56% examples, 47872 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:10:24: EPOCH 4 - PROGRESS: at 6.07% examples, 47893 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:10:54: EPOCH 4 - PROGRESS: at 7.58% examples, 47758 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:11:24: EPOCH 4 - PROGRESS: at 9.09% examples, 47849 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:11:54: EPOCH 4 - PROGRESS: at 10.60% examples, 47896 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:12:25: EPOCH 4 - PROGRESS: at 11.71% examples, 46185 words/s, in_qsize 17, out_qsize 0\n",
      "INFO - 10:12:56: EPOCH 4 - PROGRESS: at 13.75% examples, 48073 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:13:26: EPOCH 4 - PROGRESS: at 15.34% examples, 48294 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:13:56: EPOCH 4 - PROGRESS: at 16.91% examples, 48481 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:26: EPOCH 4 - PROGRESS: at 18.48% examples, 48571 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:14:56: EPOCH 4 - PROGRESS: at 20.08% examples, 48755 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:15:26: EPOCH 4 - PROGRESS: at 21.65% examples, 48878 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:15:56: EPOCH 4 - PROGRESS: at 23.25% examples, 48983 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:16:26: EPOCH 4 - PROGRESS: at 24.83% examples, 49065 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:16:57: EPOCH 4 - PROGRESS: at 26.40% examples, 49105 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:17:27: EPOCH 4 - PROGRESS: at 28.00% examples, 49231 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:17:57: EPOCH 4 - PROGRESS: at 29.60% examples, 49235 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:18:27: EPOCH 4 - PROGRESS: at 31.26% examples, 49186 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:18:57: EPOCH 4 - PROGRESS: at 32.85% examples, 49185 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:19:27: EPOCH 4 - PROGRESS: at 34.45% examples, 49258 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:19:57: EPOCH 4 - PROGRESS: at 36.04% examples, 49269 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:20:27: EPOCH 4 - PROGRESS: at 37.64% examples, 49320 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:20:57: EPOCH 4 - PROGRESS: at 39.23% examples, 49377 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:21:28: EPOCH 4 - PROGRESS: at 40.84% examples, 49279 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:21:58: EPOCH 4 - PROGRESS: at 42.57% examples, 49310 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:22:29: EPOCH 4 - PROGRESS: at 44.24% examples, 49200 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:22:59: EPOCH 4 - PROGRESS: at 45.93% examples, 49142 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:23:29: EPOCH 4 - PROGRESS: at 47.56% examples, 49068 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:23:59: EPOCH 4 - PROGRESS: at 49.18% examples, 49023 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:24:29: EPOCH 4 - PROGRESS: at 50.83% examples, 48995 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:24:59: EPOCH 4 - PROGRESS: at 52.50% examples, 48953 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:25:29: EPOCH 4 - PROGRESS: at 54.17% examples, 48976 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:26:00: EPOCH 4 - PROGRESS: at 55.83% examples, 48971 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:26:30: EPOCH 4 - PROGRESS: at 57.43% examples, 48928 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:27:00: EPOCH 4 - PROGRESS: at 59.15% examples, 48928 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:27:31: EPOCH 4 - PROGRESS: at 60.85% examples, 48848 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:28:01: EPOCH 4 - PROGRESS: at 62.63% examples, 48832 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:28:31: EPOCH 4 - PROGRESS: at 64.30% examples, 48801 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:29:01: EPOCH 4 - PROGRESS: at 65.93% examples, 48790 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:29:31: EPOCH 4 - PROGRESS: at 67.56% examples, 48773 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:30:01: EPOCH 4 - PROGRESS: at 69.22% examples, 48677 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:30:31: EPOCH 4 - PROGRESS: at 70.91% examples, 48592 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:31:01: EPOCH 4 - PROGRESS: at 72.57% examples, 48600 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:31:32: EPOCH 4 - PROGRESS: at 74.24% examples, 48623 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:32:02: EPOCH 4 - PROGRESS: at 75.86% examples, 48630 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:32:32: EPOCH 4 - PROGRESS: at 77.48% examples, 48621 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:33:02: EPOCH 4 - PROGRESS: at 79.09% examples, 48613 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:33:32: EPOCH 4 - PROGRESS: at 80.71% examples, 48612 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:34:02: EPOCH 4 - PROGRESS: at 82.27% examples, 48578 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:34:32: EPOCH 4 - PROGRESS: at 83.89% examples, 48579 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:35:02: EPOCH 4 - PROGRESS: at 85.47% examples, 48554 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:35:32: EPOCH 4 - PROGRESS: at 87.04% examples, 48529 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:36:03: EPOCH 4 - PROGRESS: at 88.64% examples, 48517 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:36:33: EPOCH 4 - PROGRESS: at 90.26% examples, 48527 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:37:03: EPOCH 4 - PROGRESS: at 91.84% examples, 48510 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:37:33: EPOCH 4 - PROGRESS: at 93.41% examples, 48496 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:38:03: EPOCH 4 - PROGRESS: at 94.99% examples, 48474 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:38:33: EPOCH 4 - PROGRESS: at 96.61% examples, 48469 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:39:03: EPOCH 4 - PROGRESS: at 98.22% examples, 48459 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:39:33: EPOCH 4 - PROGRESS: at 99.82% examples, 48447 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:39:37: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 10:39:37: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 10:39:37: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 10:39:37: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 10:39:37: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 10:39:37: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 10:39:37: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 10:39:37: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 10:39:37: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 10:39:37: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 10:39:37: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 10:39:37: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 10:39:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 10:39:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 10:39:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 10:39:37: EPOCH - 4 : training on 96497880 raw words (90805406 effective words) took 1874.3s, 48447 effective words/s\n",
      "INFO - 10:39:37: saving Word2Vec object under models-word2vec-new/model_epoch_19.model, separately None\n",
      "INFO - 10:39:37: storing np array 'vectors' to models-word2vec-new/model_epoch_19.model.wv.vectors.npy\n",
      "INFO - 10:39:37: not storing attribute vectors_norm\n",
      "INFO - 10:39:37: storing np array 'syn1neg' to models-word2vec-new/model_epoch_19.model.trainables.syn1neg.npy\n",
      "INFO - 10:39:37: not storing attribute cum_table\n",
      "INFO - 10:39:37: saved models-word2vec-new/model_epoch_19.model\n",
      "INFO - 10:39:38: EPOCH 5 - PROGRESS: at 0.06% examples, 47181 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:40:08: EPOCH 5 - PROGRESS: at 1.54% examples, 46884 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:40:38: EPOCH 5 - PROGRESS: at 3.06% examples, 47755 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:41:08: EPOCH 5 - PROGRESS: at 4.60% examples, 48267 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:41:39: EPOCH 5 - PROGRESS: at 6.15% examples, 48499 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:42:09: EPOCH 5 - PROGRESS: at 7.67% examples, 48314 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:42:39: EPOCH 5 - PROGRESS: at 9.19% examples, 48407 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:43:09: EPOCH 5 - PROGRESS: at 10.71% examples, 48473 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:43:39: EPOCH 5 - PROGRESS: at 12.31% examples, 48618 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:44:09: EPOCH 5 - PROGRESS: at 13.87% examples, 48705 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:44:39: EPOCH 5 - PROGRESS: at 15.42% examples, 48752 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:45:09: EPOCH 5 - PROGRESS: at 16.97% examples, 48832 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:45:39: EPOCH 5 - PROGRESS: at 18.57% examples, 48967 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:46:10: EPOCH 5 - PROGRESS: at 20.14% examples, 49056 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:46:40: EPOCH 5 - PROGRESS: at 21.69% examples, 49106 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:47:10: EPOCH 5 - PROGRESS: at 23.27% examples, 49169 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:47:40: EPOCH 5 - PROGRESS: at 24.81% examples, 49151 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:48:10: EPOCH 5 - PROGRESS: at 26.37% examples, 49174 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:48:40: EPOCH 5 - PROGRESS: at 27.94% examples, 49255 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:49:10: EPOCH 5 - PROGRESS: at 29.50% examples, 49204 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 10:49:40: EPOCH 5 - PROGRESS: at 31.13% examples, 49095 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:50:10: EPOCH 5 - PROGRESS: at 32.73% examples, 49082 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:50:41: EPOCH 5 - PROGRESS: at 34.27% examples, 49094 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:51:11: EPOCH 5 - PROGRESS: at 35.87% examples, 49129 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:51:41: EPOCH 5 - PROGRESS: at 37.49% examples, 49200 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:52:11: EPOCH 5 - PROGRESS: at 39.14% examples, 49322 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:52:41: EPOCH 5 - PROGRESS: at 40.76% examples, 49298 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:53:11: EPOCH 5 - PROGRESS: at 42.46% examples, 49302 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:53:42: EPOCH 5 - PROGRESS: at 44.16% examples, 49227 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:54:12: EPOCH 5 - PROGRESS: at 45.84% examples, 49159 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:54:42: EPOCH 5 - PROGRESS: at 47.48% examples, 49090 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:55:12: EPOCH 5 - PROGRESS: at 49.19% examples, 49124 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:55:42: EPOCH 5 - PROGRESS: at 50.86% examples, 49118 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:56:12: EPOCH 5 - PROGRESS: at 52.59% examples, 49147 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:56:42: EPOCH 5 - PROGRESS: at 54.29% examples, 49171 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:57:12: EPOCH 5 - PROGRESS: at 55.97% examples, 49181 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:57:42: EPOCH 5 - PROGRESS: at 57.66% examples, 49207 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:58:12: EPOCH 5 - PROGRESS: at 59.37% examples, 49194 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:58:43: EPOCH 5 - PROGRESS: at 61.11% examples, 49144 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 10:59:13: EPOCH 5 - PROGRESS: at 62.85% examples, 49105 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 10:59:43: EPOCH 5 - PROGRESS: at 64.54% examples, 49100 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:00:13: EPOCH 5 - PROGRESS: at 66.18% examples, 49091 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:00:43: EPOCH 5 - PROGRESS: at 67.81% examples, 49079 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:01:13: EPOCH 5 - PROGRESS: at 69.53% examples, 48984 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:01:43: EPOCH 5 - PROGRESS: at 71.25% examples, 48898 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:02:13: EPOCH 5 - PROGRESS: at 72.88% examples, 48917 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:02:43: EPOCH 5 - PROGRESS: at 74.53% examples, 48926 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:03:13: EPOCH 5 - PROGRESS: at 76.12% examples, 48910 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:03:43: EPOCH 5 - PROGRESS: at 77.87% examples, 48966 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:04:14: EPOCH 5 - PROGRESS: at 79.51% examples, 48970 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:04:44: EPOCH 5 - PROGRESS: at 81.18% examples, 48991 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:05:14: EPOCH 5 - PROGRESS: at 82.83% examples, 49007 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:05:44: EPOCH 5 - PROGRESS: at 84.47% examples, 49011 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:06:14: EPOCH 5 - PROGRESS: at 86.05% examples, 48976 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:06:44: EPOCH 5 - PROGRESS: at 87.66% examples, 48960 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:14: EPOCH 5 - PROGRESS: at 89.27% examples, 48955 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:07:44: EPOCH 5 - PROGRESS: at 90.86% examples, 48931 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:08:14: EPOCH 5 - PROGRESS: at 92.28% examples, 48834 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:08:45: EPOCH 5 - PROGRESS: at 93.80% examples, 48779 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:09:15: EPOCH 5 - PROGRESS: at 95.45% examples, 48789 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:09:45: EPOCH 5 - PROGRESS: at 97.09% examples, 48784 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:10:16: EPOCH 5 - PROGRESS: at 98.62% examples, 48709 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 11:10:40: worker thread finished; awaiting finish of 14 more threads\n",
      "INFO - 11:10:40: worker thread finished; awaiting finish of 13 more threads\n",
      "INFO - 11:10:40: worker thread finished; awaiting finish of 12 more threads\n",
      "INFO - 11:10:40: worker thread finished; awaiting finish of 11 more threads\n",
      "INFO - 11:10:40: worker thread finished; awaiting finish of 10 more threads\n",
      "INFO - 11:10:40: worker thread finished; awaiting finish of 9 more threads\n",
      "INFO - 11:10:40: worker thread finished; awaiting finish of 8 more threads\n",
      "INFO - 11:10:40: worker thread finished; awaiting finish of 7 more threads\n",
      "INFO - 11:10:40: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 11:10:40: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 11:10:40: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 11:10:40: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 11:10:40: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 11:10:40: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 11:10:40: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 11:10:40: EPOCH - 5 : training on 96497880 raw words (90805489 effective words) took 1862.7s, 48750 effective words/s\n",
      "INFO - 11:10:40: saving Word2Vec object under models-word2vec-new/model_epoch_20.model, separately None\n",
      "INFO - 11:10:40: storing np array 'vectors' to models-word2vec-new/model_epoch_20.model.wv.vectors.npy\n",
      "INFO - 11:10:40: not storing attribute vectors_norm\n",
      "INFO - 11:10:40: storing np array 'syn1neg' to models-word2vec-new/model_epoch_20.model.trainables.syn1neg.npy\n",
      "INFO - 11:10:40: not storing attribute cum_table\n",
      "INFO - 11:10:40: saved models-word2vec-new/model_epoch_20.model\n",
      "INFO - 11:10:40: training on a 482489400 raw words (454026724 effective words) took 9319.7s, 48717 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 155.33 mins\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "t = time()\n",
    "w2v_model.train(\n",
    "    cord_sentences,\n",
    "    total_examples=w2v_model.corpus_count,\n",
    "    epochs=20,\n",
    "    report_delay=30\n",
    ")\n",
    "print(f'Time to train the model: {round((time() - t) / 60, 2)} mins')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
