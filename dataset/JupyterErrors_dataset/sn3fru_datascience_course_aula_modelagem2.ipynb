{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NEW YORK TAXI FARE\n",
    "\n",
    "<img src='img/taxi_fare.PNG' width=2000>\n",
    "\n",
    "Nesta aula, vamos trabalhar com dados de corridas de taxi em Nova York através de um dataSet consagrado em estudos que vão desde a Caursera e Google Coud até o Kaggle. O objetivo será identificar a série de dados do _fare amount_ (valor da corrida de taxi) como variável taarget, e construir séries de dados que possam explicar estes valores. Para isso, teremos que manipular os dados existentes conforme descrito abaixo, com o intuito de obter uma regressão explicativa para os valores cobrados por este serviço de transporte.\n",
    "\n",
    "### Descrições de arquivo\n",
    "\n",
    "- train.csv - Recursos de entrada e valores de fare_amount de destino para o conjunto de treinamento (cerca de 55 milhões de linhas).\n",
    "- test.csv - Recursos de entrada para o conjunto de testes (cerca de 10 mil linhas).\n",
    "- sample_submission.csv - um arquivo de envio de amostra no formato correto (keys key e fare_amount). Este arquivo 'prevê' fare_amount para $ 11.35 para todas as linhas, que é a média de fare_amount do conjunto de treinamento.\n",
    "\n",
    "#### Para baixar os arquivos acesse o link [clicando aqui](https://www.kaggle.com/c/new-york-city-taxi-fare-prediction/data)\n",
    "\n",
    "### Campos de dados\n",
    "\n",
    "1.Variável de Identidade\n",
    "\n",
    "- key - string única que identifica cada linha nos conjuntos de treinamento e teste.\n",
    "\n",
    "2.Variáveis Explicativas\n",
    "\n",
    "- pickup_datetime - valor do registro de data e hora indicando quando o taxi começou.\n",
    "- pickup_longitude - flutua pela coordenada de longitude de onde o taxi começou.\n",
    "- pickup_latitude - flutua para a coordenada de latitude de onde o táxi começou.\n",
    "- dropoff_longitude - flutua pela coordenada de longitude de onde o passeio de táxi terminou.\n",
    "- dropoff_latitude - flutua para a coordenada de latitude de onde o passeio de táxi terminou.\n",
    "- passenger_count - número inteiro indicando o número de passageiros no trajeto de táxi.\n",
    "\n",
    "3.Variável Alvo\n",
    "\n",
    "- fare_amount - valor em dólar flutuante do custo do táxi. Este valor é apenas no conjunto de treinamento; isso é o que você está prevendo no conjunto de testes e é necessário em seu envio CSV.\n",
    "\n",
    "Para esta DataSet, faremos algumas operações que tem por objetivo explicar o preço da corrida de taxi, separado em seções:\n",
    "\n",
    "- Claning Data\n",
    "- Análise Exploratória de Dados\n",
    "- Modelagem Estatística\n",
    "- Regressão Lienar\n",
    "- Avançado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wordcloud'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f7feff0c7a8e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstatsmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordcloud'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as sm\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from sklearn import preprocessing\n",
    "from datetime import datetime\n",
    "import ast\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lendo e verificando os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/train.csv\", nrows = 1000000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendendo a explicabilidade do DataSet (benchmark)\n",
    "\n",
    "Rodar uma regressão linear no início da análise exploratória de dados nos permite entender o quão explicativas são as variáveis independentes iniciais, que servirá como referência ao final da nossa análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rodando uma regressão inicial para servir de benchmark para a análise\n",
    "\n",
    "formula = 'fare_amount ~ pickup_longitude + pickup_latitude + dropoff_longitude + dropoff_latitude + passenger_count'\n",
    "\n",
    "result = sm.ols(formula, data=df).fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos verificar que não existe relação nenhuma contida nas variáveis independentes que possam explicar as taxas de corridas de taxi cobradas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLEANING DATA\n",
    "\n",
    "Para melhor entendimento no processamento das colunas do DataSet, precisamos entender os valores que estão contidos em cada coluna e como faremos para confiar nos dados, ou seja, para estarmos seguros de que os números nas colunas são coerentes e estão dentro de um intervalo esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contagem de valores nulos\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminando os valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropando 10 observações com dados nulos\n",
    "df = df.drop(df[df.isnull().any(1)].index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando a variável alvo fare_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fare_amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(df['fare_amount']<0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descobrimos que existem 38 valores negativos de _fare amount_ - como não podemos ter taxas de cobrança de corrida de taxi negativa, vamos eliminar estas linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropando 38 colunas com taxa de corrida negativa\n",
    "df = df.drop(df[df['fare_amount']<0].index, axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fare_amount'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fare_amount'].sort_values(ascending=False).nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando a variável passenger_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['passenger_count'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['passenger_count'].sort_values(ascending=False).nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['passenger_count']>6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descobrimos que temos uma observação com 208 passageiros - vamos eliminar esta linha e ficar com um máximo de 6 passageiros por corrida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropando uma linha com 608 passageiros\n",
    "df = df.drop(df[df['passenger_count']==208].index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['passenger_count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando as variáveis de latitude\n",
    "\n",
    "A latitude é um ângulo (definido abaixo) que varia de 0 ° no equador a 90 ° (norte ou sul) nos pólos. Linhas de latitude constante, ou paralelos, correm de leste a oeste como círculos paralelos ao equador. A latitude é usada junto com a longitude para especificar a localização precisa dos recursos na superfície da Terra.\n",
    "\n",
    "Isso significa de não podemos ter valores de latitude menores que -90 e maiores que 90.\n",
    "\n",
    "### pickup_latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pickup_latitude'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['pickup_latitude']<-90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['pickup_latitude']>90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebemos que temos 3 observações com valores menores que -90 e 9 observações com valores maiores que 90 - vamos eliminar estas 12 linhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropando 12 linhas com valores fora do experado para pickup_latitude\n",
    "df = df.drop(((df[df['pickup_latitude']<-90])|(df[df['pickup_latitude']>90])).index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['pickup_latitude']<-90) & (df['pickup_latitude']>90)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropoff_latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['dropoff_latitude']<-90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['dropoff_latitude']>90]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebemos que temos uma observação com valor menos que -90 e 7 observações com valores maiores que 90 - vamos eliminar estas 8 linhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropando 8 linhas com valores fora do experado para pickup_latitude\n",
    "df = df.drop(((df[df['dropoff_latitude']<-90])|(df[df['dropoff_latitude']>90])).index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['dropoff_latitude']<-90) & (df['dropoff_latitude']>90)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando as variáveis de longitude\n",
    "\n",
    "Longitude, algumas vezes representada pela letra grega λ (lambda), descreve a localização de um lugar na Terra medido em graus, de zero a 180 para leste ou para oeste, a partir do Meridiano de Greenwich.\n",
    "\n",
    "Isso significa de não podemos ter valores de longitude menores que -180 e maiores que 180. \n",
    "\n",
    "### pickup_longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pickup_longitude'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['pickup_longitude']<-180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['pickup_longitude']>180]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebemos que temos 11 valores menores que -180 e nenhum valor maiores que 180 - vamos eliminar estas 11 linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropando 11 linhas com valores fora do experado para pickup_latitude\n",
    "df = df.drop(((df[df['pickup_longitude']<-180])|(df[df['pickup_longitude']>180])).index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['pickup_longitude']<-180) & (df['pickup_longitude']>180)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dropoff_longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['dropoff_longitude']<-180]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['dropoff_longitude']>180]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Percebemos que temos 9 observações com valor menores que -180 e nenhuma observação com valores maiores que 180 - vamos eliminar estas 9 linhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropando 11 linhas com valores fora do experado para pickup_latitude\n",
    "df = df.drop(((df[df['dropoff_longitude']<-180])|(df[df['dropoff_longitude']>180])).index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['dropoff_longitude']<-180) & (df['dropoff_longitude']>180)].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANÁLISE EXPLORATÓRIA DE DADOS - EDA (Exploratory Data Analysis)\n",
    "\n",
    "Para a Análise exploratória de dados, devemos ter algumas considerações para orientar o trabalho de modelagem dos dados:\n",
    "\n",
    "- Como o número de passageiros afeta o preço da corrida de taxi? \n",
    "- Como a data de pickup afeta o preço da corrida de taxi? \n",
    "- Como o horário de pickup afeta o preço da corrida de taxi? \n",
    "- Como o dia do mês e da semana de pickup afeta o preço da corrida de taxi?  \n",
    "- Como a distância viajada afeta o preço da corrida de taxi?\n",
    "\n",
    "Agora está claro que temos que trabalhar com as variáveis de pickup_datetime e distância para explicar o preço da corridda. A partir daí, entendemos que teremos que fazer transformações matemáticas \n",
    "\n",
    "### 1. Distância\n",
    "\n",
    "Inicialmente, teremos que explorar as variáveis de latitude e longitude com o objetivo de obter algum valor para distância percorrida durante a corrida.\n",
    "\n",
    "### 2. Dados da data e horário do pickup\n",
    "\n",
    "Em seguida vamos fazer o split da variável pickup_datetime para obtenção dos valores de início da corrida de taxi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. DISTÂNCIA\n",
    "\n",
    "<img src='img/haversine.PNG' width=200>\n",
    "\n",
    "Utilizando so dados de latitude e longitude para o pickup e dropoff, vamos calcular a distância e chegar a nossas conclusões sobre como pickup_location afeta a tarifa, através da criação de uma nova coluna que armazene a distância entre o pickup e o drop.\n",
    "\n",
    "Podemos calcular a distância em uma esfera quando as latitudes e longitudes são dadas pela fórmula de Haversine\n",
    "\n",
    "haversine (θ) = sin² (θ / 2)\n",
    "\n",
    "Esta fórmula está baseada nos valores conhecidos de latitude representados por φ e de longitude representados por λ, e do raio da Terra representado por R (raio médio = 6,371km) considerando as coordenadas inicial e final representadas por 1 e 2 neste caso.\n",
    "\n",
    "a = sin² ((φ2 - φ1) / 2) + cos φ1. cos φ2. sin² ((λ2 - λ1) / 2)\n",
    "\n",
    "c = 2 * atan² (√a, √ (1 − a))\n",
    "\n",
    "d = R ⋅ c\n",
    "\n",
    "d = distância Haversine\n",
    "\n",
    "Consulte esta página para mais informações e exemplos sobre a fórmula de Haversine\n",
    "\n",
    "\n",
    "## [Fórmula de Haversine](https://en.wikipedia.org/wiki/Haversine_formula)\n",
    "\n",
    "_Da Wikipédia, a enciclopédia livre_\n",
    "\n",
    "A fórmula de Haversine determina a distância do grande círculo entre dois pontos em uma esfera, dadas as suas longitudes e latitudes. Importante na navegação, é um caso especial de uma fórmula mais geral em trigonometria esférica, a lei de haversines, que relaciona os lados e ângulos dos triângulos esféricos.\n",
    "\n",
    "A primeira tabela de haversines em inglês foi publicada por James Andrew em 1805, mas Florian Cajori credita um uso anterior por José de Mendoza y Ríos em 1801. O termo haversine foi cunhado em 1835 por James Inman.\n",
    "\n",
    "Esses nomes decorrem do fato de que eles são costumeiramente escritos em termos da função haversina, dada por haversin (θ) = sin² (θ / 2). As fórmulas poderiam igualmente ser escritas em termos de qualquer múltiplo do haversine, como a antiga função versine (duas vezes o haversine). Antes do advento dos computadores, a eliminação da divisão e multiplicação por fatores de dois provou ser conveniente o bastante para incluir tabelas de valores e logaritmos haversinos nos textos de navegação e trigonométricos do século XIX e início do século XX. Atualmente, a forma haversina também é conveniente, pois não tem coeficiente na frente da função sin²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, long1, lat2, long2):\n",
    "    data = [df]\n",
    "    for i in data:\n",
    "        R = 6371  #radius of earth in kilometers\n",
    "        #R = 3959 #radius of earth in miles\n",
    "        phi1 = np.radians(i[lat1])\n",
    "        phi2 = np.radians(i[lat2])\n",
    "    \n",
    "        delta_phi = np.radians(i[lat2]-i[lat1])\n",
    "        delta_lambda = np.radians(i[long2]-i[long1])\n",
    "    \n",
    "        #a = sin²((φ2 - φ1)/2) + cos φ1 . cos φ2 . sin²((λ2 - λ1)/2)\n",
    "        a = np.sin(delta_phi / 2.0) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2.0) ** 2\n",
    "    \n",
    "        #c = 2 * atan2( √a, √(1−a) )\n",
    "        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    \n",
    "        #d = R*c\n",
    "        d = (R * c) #in kilometers\n",
    "        i['H_Distance'] = d\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "haversine_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['H_Distance'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DADOS DA DATA E HORÁRIO DO PICKUP \n",
    "\n",
    "Vamos fazer o split da variável pickup_datetime para a criação de novas colunas dentro do nosso DataSet que incluem:\n",
    "\n",
    "- ano\n",
    "- mês\n",
    "- dia do mês\n",
    "- dia da semana\n",
    "- hora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esta célula é lenta pra rodar\n",
    "df['key'] = pd.to_datetime(df['key'])\n",
    "df['pickup_datetime']  = pd.to_datetime(df['pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have calculated the distance, we shall create columns for the following -\n",
    "\n",
    "- year\n",
    "- month\n",
    "- date\n",
    "- hour\n",
    "- day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [df]\n",
    "for i in data:\n",
    "    i['Year'] = i['pickup_datetime'].dt.year\n",
    "    i['Month'] = i['pickup_datetime'].dt.month\n",
    "    i['Date'] = i['pickup_datetime'].dt.day\n",
    "    i['Day_of_Week'] = i['pickup_datetime'].dt.dayofweek\n",
    "    i['Hour'] = i['pickup_datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando a variável passenger_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.hist(df['passenger_count'], bins=15)\n",
    "plt.xlabel('No. of Passengers')\n",
    "plt.ylabel('Frequency')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(x=df['passenger_count'], y=df['fare_amount'], s=1.5)\n",
    "plt.xlabel('No. of Passengers')\n",
    "plt.ylabel('Fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dos 2 gráficos acima, podemos ver que os passageiros solteiros são os viajantes mais frequentes, e a tarifa mais alta também parece vir de táxis que transportam apenas 1 passageiro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando a variável Date (dia do mês do pickup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.hist(df['Date'], bins=100)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(x=df['Date'], y=df['fare_amount'], s=1.5)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando a variável Hour (hora do pickup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.hist(df['Hour'], bins=100)\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(x=df['Hour'], y=df['fare_amount'], s=1.5)\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos entender a influência da frequência das corridas de taxi, sendo que os valores de mínimo estão às 5AM e os valores de máximo estão às 7PM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando a variável Day of Week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.hist(df['Day_of_Week'], bins=100)\n",
    "plt.xlabel('Day_of_Week')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(x=df['Day_of_Week'], y=df['fare_amount'], s=1.5)\n",
    "plt.xlabel('Day_of_Week')\n",
    "plt.ylabel('Fare')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável retorna o dia da semana de tal forma que assume-se que a semana começa na segunda-feira, que é denotada por 0 e termina no domingo, que é denotada por 6. Esse método está disponível em ambos os valores Series com data e hora (usando o acessador dt) ou DatetimeIndex.\n",
    "\n",
    "As tarifas mais altas parecem estar no domingo e na segunda-feira, e as mais baixas na quarta e na sexta-feira. Talvez as pessoas viajem longas distâncias no domingo e segunda-feira (visitando a família e voltando para casa) e, portanto, as altas tarifas. Isto pode indicar que as pessoas acabam por ficar em casa em uma sexta-feira depois de uma semana de trabalho."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando a variável H_Distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.hist(df['H_Distance'], bins=100)\n",
    "plt.xlabel('H_Distance')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.scatter(df['H_Distance'], y=df['fare_amount'], s=1.5)\n",
    "plt.xlabel('H_Distance')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em primeiro lugar, vamos verificar a frequência das distâncias que calculamos usando a fórmula de Haversine com a criação de intervalos (0-10 kms, 10-20 kms e assim por diante) para a verificação da frequência dos dados e eventuais outlires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_0 = df.loc[(df['H_Distance'] == 0), ['H_Distance']]\n",
    "bins_1 = df.loc[(df['H_Distance'] > 0) & (df['H_Distance'] <= 10),['H_Distance']]\n",
    "bins_2 = df.loc[(df['H_Distance'] > 10) & (df['H_Distance'] <= 50),['H_Distance']]\n",
    "bins_3 = df.loc[(df['H_Distance'] > 50) & (df['H_Distance'] <= 100),['H_Distance']]\n",
    "bins_4 = df.loc[(df['H_Distance'] > 100) & (df['H_Distance'] <= 200),['H_Distance']]\n",
    "bins_5 = df.loc[(df['H_Distance'] > 200) & (df['H_Distance'] <= 300),['H_Distance']]\n",
    "bins_6 = df.loc[(df['H_Distance'] > 300),['H_Distance']]\n",
    "\n",
    "bins_0['bins'] = '0'\n",
    "bins_1['bins'] = '0-10'\n",
    "bins_2['bins'] = '11-50'\n",
    "bins_3['bins'] = '51-100'\n",
    "bins_4['bins'] = '100-200'\n",
    "bins_5['bins'] = '201-300'\n",
    "bins_6['bins'] = '>300'\n",
    "\n",
    "dist_bins = pd.concat([bins_0,bins_1,bins_2,bins_3,bins_4,bins_5,bins_6])\n",
    "#len(dist_bins)\n",
    "dist_bins.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_bins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_bins['bins'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem valores maiores que 100 kms,porém em Nova York precisamos explorar por que as pessoas pegam táxis para viajar mais de 100 quilômetros. Como a frequência do número de bins de 100 a 200 kms é bastante alto, a ideia será mantê-los. Esses outliers podem ser causados por erros de digitação ou valores ausentes na latitude ou longitude. Seguindo a análise exploratória e modelagem estatística, devemos pensar em remover campos dos seguintes:\n",
    "\n",
    "- A latitude de pickup e a longitude de pickup são 0, mas a latitude e a longitude de dropoff não são 0, mas a tarifa é 0\n",
    "- Vice-versa do ponto 1.\n",
    "- A latitude de pickup e a longitude de pickup são 0, mas a latitude e longitude de dropoff não são 0, mas a tarifa é NÃO 0. Aqui teremos que imputar os valores de distância a serem calculados de acordo com fórmula de cobrança dos taxímetros.\n",
    "\n",
    "## A latitude de pickup e a longitude de pickup são 0, mas a latitude e a longitude de dropoff não são 0, mas a tarifa é 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickup latitude and longitude = 0\n",
    "df.loc[((df['pickup_latitude']==0) & (df['pickup_longitude']==0))&((df['dropoff_latitude']!=0) & (df['dropoff_longitude']!=0)) & (df['fare_amount']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.loc[((df['pickup_latitude']==0) & (df['pickup_longitude']==0))&\\\n",
    "                    ((df['dropoff_latitude']!=0) & (df['dropoff_longitude']!=0)) & (df['fare_amount']==0)].index, axis=0)\n",
    "\n",
    "# 1 row dropped\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropoff latitude and longitude = 0\n",
    "df.loc[((df['pickup_latitude']!=0) & (df['pickup_longitude']!=0))&((df['dropoff_latitude']==0) & (df['dropoff_longitude']==0)) & (df['fare_amount']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.loc[((df['pickup_latitude']!=0) & (df['pickup_longitude']!=0))&\\\n",
    "                    ((df['dropoff_latitude']==0) & (df['dropoff_longitude']==0)) & (df['fare_amount']==0)].index, axis=0)\n",
    "\n",
    "# 3 rows dropped\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valores de distância maiores do que 200Km\n",
    "\n",
    "Verificando os campos H_Distance que são maiores que 200 kms, pois dificilmente as pessoas podem viajar mais de 200 kms no máximo em NYC em um taxi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_distance = df.loc[(df['H_Distance']>200)&(df['fare_amount']!=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_distance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_distance.fare_amount.hist(bins=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_distance.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver no DF acima, as distâncias anormalmente altas se devem ao fato de as coordenadas de pickup ou dropoff estarem incorretas ou 0. No entanto, como todos esses valores têm tarifas, descartá-las não é a melhor estratégia, pois elas contêm dados cruciais. Em vez disso, vamos substituir os valores iniciais de distância por valores de distância calculados usando a tarifa usando a fórmula de cobrança de carridas de taxi abaixo.\n",
    "\n",
    "#### distance = (fare_amount - 2.5)/1.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_distance['H_Distance'] = high_distance.apply(lambda row: (row['fare_amount'] - 2.50)/1.56, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando a substituição dos dadso de distância calculados de acordo com a fórmula \n",
    "high_distance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sincronizando os dados com os valores calculados no DataFrame original \n",
    "df.update(high_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificando os valores com H_Distance iguais a zero\n",
    "\n",
    "Agora vamos verificar as linhas onde os valores de distância são 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['H_Distance']==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['H_Distance']==0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver algumas linhas com distância = 0. Isso pode ser devido a 2 motivos\n",
    "\n",
    "- O táxi esperou o tempo todo e o passageiro acabou cancelado. É por isso que as coordenadas de coleta e queda são as mesmas e talvez o passageiro tenha sido cobrado pelo tempo de espera.\n",
    "\n",
    "- As coordenadas de coleta de dropoff não foram inseridas. Em outras palavras, esses valores estão faltando.\n",
    "\n",
    "28667 linhas são muitas linhas para serem excluídas. Precisamos imputar esses valores ausentes. Podemos adotar a estratégia de imputar os valores de distância perdidos com a tarifa e o preço médio por quilômetro dos táxis de Nova York.\n",
    "\n",
    "UVerificando as fórmulas de calculo de tarifa temos:\n",
    "\n",
    "#### Preço base de USD 2,5 + USD 1,56 / km -> das 06:00 h às 20:00 h de segunda a sexta\n",
    "\n",
    "#### Preço base de USD 3.0 + USD 1,56 / km -> das 20:00 h às 06:00 h de segunda a sexta e sáb e dom\n",
    "\n",
    "No entanto, antes de prosseguirmos com as etapas acima, vamos verificar os cenários a seguir para imputar o valor da tarifa ausente e a H_Distance nos dados\n",
    "\n",
    "1. Tarifa e Distância são ambas 0. \n",
    "2. A tarifa não é 0 e é menor que o valor base, mas a distância é 0.\n",
    "3. A tarifa é 0, mas a distância não é 0.\n",
    "4. A tarifa não é 0, mas a distância é 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tarifa e Distância são ambas 0. \n",
    "\n",
    "De acordo com a tabela acima, nós as excluiremos, pois elas não nos fornecem nenhuma informação com relação aos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['H_Distance']==0)&(df['fare_amount']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[(df['H_Distance']==0)&(df['fare_amount']==0)].index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 linhas excluidas\n",
    "df[(df['H_Distance']==0)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A tarifa não é 0 e é menor que o valor base, mas a distância é 0.\n",
    "\n",
    "A ideia inicial é excluir essas linhas, pois o mínimo é de US $ 2,50 e essas tarifas são valores incorretos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entre 6AM e 8PM em dias de semana Mon-Fri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rush_hour = df.loc[(((df['Hour']>=6)&(df['Hour']<=20)) & ((df['Day_of_Week']>=1) & (df['Day_of_Week']<=5)) & (df['H_Distance']==0) & (df['fare_amount'] < 2.5))]\n",
    "rush_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos excluir estas duas linhas pois estão abaixo do limite inicial\n",
    "df=df.drop(rush_hour.index, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entre 8PM e 6AM em dias de semana Mon-Fri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_rush_hour = df.loc[(((df['Hour']<6)|(df['Hour']>20)) & ((df['Day_of_Week']>=1)&(df['Day_of_Week']<=5)) & (df['H_Distance']==0) & (df['fare_amount'] < 3.0))]\n",
    "#print(Counter(non_work_hours['Hour']))\n",
    "#print(Counter(non_work_hours['Day of Week']))\n",
    "non_rush_hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_rush_hour.fare_amount.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos manter esses valores uma vez que, como o fare_amount não é <2,5 (que é a tarifa básica), esses valores parecem legítimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saturday and Sunday all hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekends = df.loc[((df['Day_of_Week']==0) | (df['Day_of_Week']==6)) & (df['H_Distance']==0) & (df['fare_amount'] < 3.0)]\n",
    "weekends.head()\n",
    "#Counter(weekends['Day of Week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekends.fare_amount.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos manter esses valores também pois novamente o fare_amount não é <2,5 (que é a tarifa básica), de novo esses valores parecem legítimos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A tarifa é 0, mas a distância não é 0.\n",
    "\n",
    "Esses valores precisam ser imputados.\n",
    "\n",
    "devemos calcular a tarifa correspondente baseado da distância. Devemos utilizar a seguinte fórmula (para simplificar em relação a horas de não pressa e fins de semana)\n",
    "\n",
    "#### tarifa = 2.5 + 1.56 (H_Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_3 = df.loc[(df['H_Distance']!=0) & (df['fare_amount']==0)]\n",
    "scenario_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_3.fare_amount.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_3['fare_amount'] = scenario_3.apply(lambda row: ((row['H_Distance'] * 1.56) + 2.50), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_3['fare_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(scenario_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. A tarifa não é 0, mas a distância é 0.\n",
    "\n",
    "Esses valores precisam ser imputados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_4 = df.loc[(df['H_Distance']==0) & (df['fare_amount']!=0)]\n",
    "scenario_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levando em consideração a fórmula básica:\n",
    "\n",
    "- Preço base de USD 2,5 + USD 1,56 / km -> das 06: 00h às 20: 00h, de segunda a sexta-feira;\n",
    "\n",
    "- Preço base de USD 3,0 + USD 1,56 / km -> 20:00 h às 06:00 h de segunda a sexta e sáb e dom\n",
    "\n",
    "Devemos adotar cálculos de distância como:\n",
    "\n",
    "- distância = (tarifa - 2,5) / 1,56 -> 6:00 às 20:00 seg - sex (hora do rush)\n",
    "\n",
    "- distância = (tarifa - 3.0) / 1.56 -> das 8h às 6h seg-sex e sáb e dom (hora do rush)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rush Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rush_hour_4 = scenario_4.loc[(((scenario_4['Hour']>=6)&(scenario_4['Hour']<=20)) & ((scenario_4['Day_of_Week']>=1) & (scenario_4['Day_of_Week']<=5)))]\n",
    "rush_hour_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rush_hour_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rush_hour_4['H_Distance'] = rush_hour_4.apply(lambda row: (row['fare_amount'] - 2.5) / 1.56, axis=1)\n",
    "rush_hour_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(rush_hour_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Rush Hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_4.shape[0] - rush_hour_4.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_rush_hour_4 = scenario_4.drop(rush_hour_4.index, axis=0)\n",
    "non_rush_hour_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_rush_hour_4['H_Distance'] = non_rush_hour_4.apply(lambda row: (row['fare_amount'] - 3.0) / 1.56, axis=1)\n",
    "non_rush_hour_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(non_rush_hour_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELAGEM ESTATÍSTICA\n",
    "\n",
    "Agora vamos criar uma cópia do DataFrame original e entender como podemos explicar os valores de taxa de corrida de taxi com os dados criados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando os dados\n",
    "\n",
    "Vamos aplicar o StandardScaler() para termos todos os dados com a mesma ordem de grandeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.drop(columns=['key','pickup_datetime', 'pickup_longitude','pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pd.DataFrame(scaled_data,columns=['fare_amount', 'passenger_count', 'H_Distance', 'Year', 'Month', 'Date','Day_of_Week', 'Hour'])\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'fare_amount ~ passenger_count + H_Distance + Year + Month + Date + Day_of_Week + Hour'\n",
    "\n",
    "result = sm.ols(formula, data=df_scaled).fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização dos dados e estratégias de transformação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df_copy.corr()\n",
    "ax = sns.heatmap(\n",
    "    corr, \n",
    "    vmin=-1, vmax=1, center=0,\n",
    "    cmap=sns.diverging_palette(20, 220, n=200),\n",
    "    square=True\n",
    ")\n",
    "ax.set_xticklabels(\n",
    "    ax.get_xticklabels(),\n",
    "    rotation=45,\n",
    "    horizontalalignment='right'\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df_copy.sample(n=10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos visualizar que existe uma relação linear significativa entre a taxa da corrida e a distância percorrida (talvez impulsionada pela inserção de valores de acrodo com a fóormula de cálculo do preço). Além disso, também podemos observar que ambas as variávais tem assimeria positiva presente nos gráficos de distribuição. Portanto a melhor estratégia é transformar ambas as variáveis com o LOG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'np.log1p(fare_amount) ~ passenger_count + np.log1p(H_Distance) + Year + Month + Date + Day_of_Week + Hour'\n",
    "\n",
    "result = sm.ols(formula, data=df_copy).fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AVANÇADO\n",
    "\n",
    "Vamos aplicar as análises e modelagens para os dados de teste e verificar a qualidade de predição do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import layers\n",
    "from keras import models\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.metrics import mean_squared_logarithmic_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./data/test.csv\", nrows = 1000000)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.passenger_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.pickup_latitude.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dropoff_latitude.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.pickup_longitude.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.dropoff_longitude.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo das distâncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_test(lat1, long1, lat2, long2):\n",
    "    data = [test]\n",
    "    for i in data:\n",
    "        R = 6371  #radius of earth in kilometers\n",
    "        #R = 3959 #radius of earth in miles\n",
    "        phi1 = np.radians(i[lat1])\n",
    "        phi2 = np.radians(i[lat2])\n",
    "    \n",
    "        delta_phi = np.radians(i[lat2]-i[lat1])\n",
    "        delta_lambda = np.radians(i[long2]-i[long1])\n",
    "    \n",
    "        #a = sin²((φ2 - φ1)/2) + cos φ1 . cos φ2 . sin²((λ2 - λ1)/2)\n",
    "        a = np.sin(delta_phi / 2.0) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2.0) ** 2\n",
    "    \n",
    "        #c = 2 * atan2( √a, √(1−a) )\n",
    "        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "    \n",
    "        #d = R*c\n",
    "        d = (R * c) #in kilometers\n",
    "        i['H_Distance'] = d\n",
    "    return d\n",
    "\n",
    "haversine_test('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude').head(10)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.H_Distance.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.H_Distance.value_counts().nlargest(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformação das variáveis Date and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['key'] = pd.to_datetime(test['key'])\n",
    "test['pickup_datetime']  = pd.to_datetime(test['pickup_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [test]\n",
    "for i in data:\n",
    "    i['Year'] = i['pickup_datetime'].dt.year\n",
    "    i['Month'] = i['pickup_datetime'].dt.month\n",
    "    i['Date'] = i['pickup_datetime'].dt.day\n",
    "    i['Day_of_Week'] = i['pickup_datetime'].dt.dayofweek\n",
    "    i['Hour'] = i['pickup_datetime'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excluíndo as colunas que não interessam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(columns=['key','pickup_datetime', 'pickup_longitude','pickup_latitude', 'dropoff_longitude', 'dropoff_latitude'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazendo as predições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_copy['fare_amount'] = np.log1p(df_copy['fare_amount'])\n",
    "df_copy['H_Distance'] = np.log1p(df_copy['H_Distance'])\n",
    "\n",
    "test['H_Distance'] = np.log1p(test['H_Distance'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_copy.drop(['fare_amount'],axis=1)\n",
    "y_train = df_copy.fare_amount\n",
    "\n",
    "x_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model_lr = LinearRegression()\n",
    "model_lr.fit(x_train,y_train)\n",
    "y_pred_lr = model_lr.predict(x_test)\n",
    "y_pred_lr = np.exp(y_pred_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission['fare_amount'] = y_pred_lr\n",
    "submission.to_csv('submission_lr.csv', index=False)\n",
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ml_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_metrics import rmse\n",
    "\n",
    "y_pred_lr_train = model_lr.predict(x_train)\n",
    "\n",
    "rmse(y_train, y_pred_lr_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "\n",
    "params = {\n",
    "        'boosting_type':'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'nthread': -1,\n",
    "        'verbose': 0,\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': -1,\n",
    "        'subsample': 0.8,\n",
    "        'subsample_freq': 1,\n",
    "        'colsample_bytree': 0.6,\n",
    "        'reg_aplha': 1,\n",
    "        'reg_lambda': 0.001,\n",
    "        'metric': 'rmse',\n",
    "        'min_split_gain': 0.5,\n",
    "        'min_child_weight': 1,\n",
    "        'min_child_samples': 10,\n",
    "        'scale_pos_weight':1     \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_y = np.zeros(x_test.shape[0])\n",
    "pred_test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = lgbm.Dataset(x_train, y_train, silent=True)\n",
    "train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbm.train(params, train_set = train_set, num_boost_round=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_y = model.predict(x_test, num_iteration = model.best_iteration)\n",
    "pred_test_y = np.exp(pred_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['fare_amount'] = pred_test_y\n",
    "submission.to_csv('submission_LGB.csv', index=False)\n",
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lgbm_train = model.predict(x_train)\n",
    "\n",
    "rmse(y_train, y_pred_lgbm_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb \n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dtest = xgb.DMatrix(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters for xgboost\n",
    "params = {'max_depth':7,\n",
    "          'eta':1,\n",
    "          'silent':1,\n",
    "          'objective':'reg:linear',\n",
    "          'eval_metric':'rmse',\n",
    "          'learning_rate':0.05\n",
    "         }\n",
    "num_rounds = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = xgb.train(params, dtrain, num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgb = xb.predict(dtest)\n",
    "y_pred_xgb = np.exp(y_pred_xgb)\n",
    "print(y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['fare_amount'] = y_pred_xgb\n",
    "submission.to_csv('submission_XGB.csv', index=False)\n",
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xb_train = xb.predict(dtrain)\n",
    "rmse(y_train, y_pred_xb_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O melhor _Score_ no kaggle foi de 3.98717 com LGBM, porém ficou muito próximo do XGBOOST (4.07935), porém sem a aplicação da função LOG.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
