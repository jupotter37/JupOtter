{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 삼성전자 첨기연 시각 심화\n",
    "\n",
    "- **Instructor**: Jongwoo Lim / Jiun Bae\n",
    "- **Email**: [jlim@hanyang.ac.kr](mailto:jlim@hanyang.ac.kr) / [jiun.maydev@gmail.com](mailto:jiun.maydev@gmail.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from MDNet.models.mdnet import MDNet, BCELoss, Precision\n",
    "from MDNet.models.extractor import SampleGenerator, RegionDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Download OTB-50, 100 dataset from [CVLab](http://cvlab.hanyang.ac.kr/tracker_benchmark/datasets.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, root: str, options):\n",
    "        self.sequences, self.images, self.ground_truths = map(list, zip(*[(\n",
    "            str(seq.stem),\n",
    "            list(map(str, sorted(seq.glob('img/*.jpg')))),\n",
    "            pd.read_csv(str(seq.joinpath('groundtruth_rect.txt')), header=None, sep=r'\\,|\\t|\\ ', engine='python').values,\n",
    "        ) for seq in filter(lambda p: p.is_dir(), Path(root).iterdir())]))\n",
    "        \n",
    "        # assertion\n",
    "        for i, _ in enumerate(self.sequences):\n",
    "            if len(self.images[i]) != np.size(self.ground_truths[i], 0):\n",
    "                self.images[i] = self.images[i][:self.ground_truths[i].shape[0]]\n",
    "        \n",
    "        self.regions = [RegionDataset(i, g, options) for i, g in zip(self.images, self.ground_truths)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.regions[idx]\n",
    "    \n",
    "    def __iter__(self):\n",
    "        yield from self.regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Environments\n",
    "\n",
    "Download pre-trained imagenet-vgg weights from [link](http://www.vlfeat.org/matconvnet/models/imagenet-vgg-m.mat)\n",
    "\n",
    "```\n",
    "wget \"http://www.vlfeat.org/matconvnet/models/imagenet-vgg-m.mat\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = yaml.safe_load(open('MDNet/options.yaml','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset('../data/OTB', opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MDNet(opts['init_model_path'], len(dataset)).to(device)\n",
    "model.set_learnable_params(opts['ft_layers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = BCELoss()\n",
    "evaluator = Precision()\n",
    "optimizer = model.optimizer(opts['lr'], opts['lr_mult'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  0 (Domain  0), Loss 0.634, Precision 0.406\n",
      "Batch  0: Mean Precision: 0.406\n",
      "Iter  0 (Domain  0), Loss 0.562, Precision 0.344\n",
      "Batch  1: Mean Precision: 0.344\n",
      "Iter  0 (Domain  0), Loss 0.532, Precision 0.344\n",
      "Batch  2: Mean Precision: 0.344\n",
      "Iter  0 (Domain  0), Loss 0.569, Precision 0.438\n",
      "Batch  3: Mean Precision: 0.438\n",
      "Iter  0 (Domain  0), Loss 0.469, Precision 0.469\n",
      "Batch  4: Mean Precision: 0.469\n",
      "Iter  0 (Domain  0), Loss 0.346, Precision 0.719\n",
      "Batch  5: Mean Precision: 0.719\n",
      "Iter  0 (Domain  0), Loss 0.322, Precision 0.750\n",
      "Batch  6: Mean Precision: 0.750\n",
      "Iter  0 (Domain  0), Loss 0.231, Precision 0.844\n",
      "Batch  7: Mean Precision: 0.844\n",
      "Iter  0 (Domain  0), Loss 0.232, Precision 0.812\n",
      "Batch  8: Mean Precision: 0.812\n",
      "Iter  0 (Domain  0), Loss 0.175, Precision 0.781\n",
      "Batch  9: Mean Precision: 0.781\n",
      "Iter  0 (Domain  0), Loss 0.117, Precision 0.906\n",
      "Batch 10: Mean Precision: 0.906\n",
      "Iter  0 (Domain  0), Loss 0.105, Precision 0.969\n",
      "Batch 11: Mean Precision: 0.969\n",
      "Iter  0 (Domain  0), Loss 0.114, Precision 0.969\n",
      "Batch 12: Mean Precision: 0.969\n",
      "Iter  0 (Domain  0), Loss 0.084, Precision 0.969\n",
      "Batch 13: Mean Precision: 0.969\n",
      "Iter  0 (Domain  0), Loss 0.106, Precision 0.906\n",
      "Batch 14: Mean Precision: 0.906\n",
      "Iter  0 (Domain  0), Loss 0.095, Precision 0.938\n",
      "Batch 15: Mean Precision: 0.938\n",
      "Iter  0 (Domain  0), Loss 0.138, Precision 0.938\n",
      "Batch 16: Mean Precision: 0.938\n",
      "Iter  0 (Domain  0), Loss 0.109, Precision 0.938\n",
      "Batch 17: Mean Precision: 0.938\n",
      "Iter  0 (Domain  0), Loss 0.066, Precision 0.938\n",
      "Batch 18: Mean Precision: 0.938\n",
      "Iter  0 (Domain  0), Loss 0.045, Precision 0.969\n",
      "Batch 19: Mean Precision: 0.969\n",
      "Iter  0 (Domain  0), Loss 0.071, Precision 0.969\n",
      "Batch 20: Mean Precision: 0.969\n",
      "Iter  0 (Domain  0), Loss 0.091, Precision 0.938\n",
      "Batch 21: Mean Precision: 0.938\n",
      "Iter  0 (Domain  0), Loss 0.070, Precision 0.969\n",
      "Batch 22: Mean Precision: 0.969\n",
      "Iter  0 (Domain  0), Loss 0.016, Precision 0.969\n",
      "Batch 23: Mean Precision: 0.969\n",
      "Iter  0 (Domain  0), Loss 0.021, Precision 0.969\n",
      "Batch 24: Mean Precision: 0.969\n",
      "Iter  0 (Domain  0), Loss 0.071, Precision 0.969\n",
      "Batch 25: Mean Precision: 0.969\n",
      "Iter  0 (Domain  0), Loss 0.099, Precision 0.969\n",
      "Batch 26: Mean Precision: 0.969\n",
      "Iter  0 (Domain  0), Loss 0.011, Precision 1.000\n",
      "Batch 27: Mean Precision: 1.000\n",
      "Iter  0 (Domain  0), Loss 0.018, Precision 1.000\n",
      "Batch 28: Mean Precision: 1.000\n",
      "Iter  0 (Domain  0), Loss 0.122, Precision 0.938\n",
      "Batch 29: Mean Precision: 0.938\n",
      "Iter  0 (Domain  0), Loss 0.113, Precision 0.938\n",
      "Batch 30: Mean Precision: 0.938\n",
      "Iter  0 (Domain  0), Loss 0.022, Precision 0.969\n",
      "Batch 31: Mean Precision: 0.969\n"
     ]
    }
   ],
   "source": [
    "for b in range(opts['n_cycles']):\n",
    "    model.train()\n",
    "    \n",
    "    prec = np.zeros(len(dataset))\n",
    "    permute = np.random.permutation(len(dataset))\n",
    "\n",
    "    for i, j in enumerate(permute):\n",
    "        pos, neg = dataset[j].next()\n",
    "        \n",
    "        pos_loss = model(pos.to(device), j)\n",
    "        neg_loss = model(neg.to(device), j)\n",
    "        \n",
    "        loss = criterion(pos_loss, neg_loss)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        if 'grad_clip' in opts:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), opts['grad_clip'])\n",
    "        optimizer.step()\n",
    "        \n",
    "        prec[j] = evaluator(pos_loss, neg_loss)\n",
    "        \n",
    "        if not i % 10:\n",
    "            print(f'Iter {i:2d} (Domain {j:2d}), Loss {loss.item():.3f}, Precision {prec[j]:.3f}')\n",
    "\n",
    "    print(f'Batch {b:2d}: Mean Precision: {prec.mean():.3f}')\n",
    "    \n",
    "    torch.save({\n",
    "        'shared_layers': model.cpu().layers.state_dict()\n",
    "    }, opts['model_path'])\n",
    "    \n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "from MDNet.utils import Options, overlap_ratio\n",
    "from MDNet.models.extractor import RegionExtractor\n",
    "from MDNet.models.regressor import BBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_samples(model, image, samples, opts, out_layer='conv3'):\n",
    "    model.eval()\n",
    "    extractor = RegionExtractor(image, samples, opts.img_size, opts.padding, opts.batch_test)\n",
    "\n",
    "    for i, regions in enumerate(extractor):\n",
    "        if opts.use_gpu:\n",
    "            regions = regions.cuda()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            feat = model(regions, out_layer=out_layer)\n",
    "\n",
    "        feats = torch.cat((feats, feat.detach().clone()), 0) if i else feat.detach().clone()\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer,\n",
    "          pos_feats, neg_feats, maxiter, opts,\n",
    "          in_layer='fc4'):\n",
    "    model.train()\n",
    "\n",
    "    batch_pos = opts.batch_pos\n",
    "    batch_neg = opts.batch_neg\n",
    "    batch_test = opts.batch_test\n",
    "    batch_neg_cand = max(opts.batch_neg_cand, batch_neg)\n",
    "\n",
    "    pos_idx = np.random.permutation(pos_feats.size(0))\n",
    "    neg_idx = np.random.permutation(neg_feats.size(0))\n",
    "\n",
    "    while len(pos_idx) < batch_pos * maxiter:\n",
    "        pos_idx = np.concatenate([pos_idx, np.random.permutation(pos_feats.size(0))])\n",
    "\n",
    "    while len(neg_idx) < batch_neg_cand * maxiter:\n",
    "        neg_idx = np.concatenate([neg_idx, np.random.permutation(neg_feats.size(0))])\n",
    "\n",
    "    pos_pointer = 0\n",
    "    neg_pointer = 0\n",
    "\n",
    "    for _ in range(maxiter):\n",
    "\n",
    "        # select pos idx\n",
    "        pos_next = pos_pointer + batch_pos\n",
    "        pos_cur_idx = pos_idx[pos_pointer:pos_next]\n",
    "        pos_cur_idx = pos_feats.new(pos_cur_idx).long()\n",
    "        pos_pointer = pos_next\n",
    "\n",
    "        # select neg idx\n",
    "        neg_next = neg_pointer + batch_neg_cand\n",
    "        neg_cur_idx = neg_idx[neg_pointer:neg_next]\n",
    "        neg_cur_idx = neg_feats.new(neg_cur_idx).long()\n",
    "        neg_pointer = neg_next\n",
    "\n",
    "        # create batch\n",
    "        batch_pos_feats = pos_feats[pos_cur_idx]\n",
    "        batch_neg_feats = neg_feats[neg_cur_idx]\n",
    "\n",
    "        # hard negative mining\n",
    "        if batch_neg_cand > batch_neg:\n",
    "            model.eval()\n",
    "\n",
    "            for start in range(0, batch_neg_cand, batch_test):\n",
    "                end = min(start + batch_test, batch_neg_cand)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    score = model(batch_neg_feats[start:end], in_layer=in_layer)\n",
    "\n",
    "                if start == 0:\n",
    "                    neg_cand_score = score.detach()[:, 1].clone()\n",
    "                else:\n",
    "                    neg_cand_score = torch.cat((neg_cand_score, score.detach()[:, 1].clone()), 0)\n",
    "\n",
    "            _, top_idx = neg_cand_score.topk(batch_neg)\n",
    "            batch_neg_feats = batch_neg_feats[top_idx]\n",
    "            model.train()\n",
    "\n",
    "        # forward\n",
    "        pos_score = model(batch_pos_feats, in_layer=in_layer)\n",
    "        neg_score = model(batch_neg_feats, in_layer=in_layer)\n",
    "\n",
    "        # optimize\n",
    "        loss = criterion(pos_score, neg_score)\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), opts.grad_clip)\n",
    "\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(images, init_bbox, ground_truths, opts):\n",
    "    device = ('cuda' if opts.use_gpu else 'cpu')\n",
    "\n",
    "    model = MDNet(opts.model_path).to(device)\n",
    "\n",
    "    criterion = BCELoss()\n",
    "\n",
    "    # Set learnable parameters\n",
    "    for k, p in model.params.items():\n",
    "        p.requires_grad = any([k.startswith(l) for l in opts.ft_layers])\n",
    "\n",
    "    # Set optimizer states\n",
    "    def set_optimizer(lr_base, lr_mult, momentum=0.9, w_decay=0.0005):\n",
    "        param_list = []\n",
    "\n",
    "        for k, p in filter(lambda kp: kp[1].requires_grad, model.params.items()):\n",
    "            lr = lr_base\n",
    "            for l, m in lr_mult.items():\n",
    "                if k.startswith(l):\n",
    "                    lr = lr_base * m\n",
    "            param_list.append({'params': [p], 'lr': lr})\n",
    "\n",
    "        return optim.SGD(param_list, lr=lr, momentum=momentum, weight_decay=w_decay)\n",
    "\n",
    "    init_optimizer = set_optimizer(opts.lr_init, opts.lr_mult)\n",
    "    update_optimizer = set_optimizer(opts.lr_update, opts.lr_mult)\n",
    "\n",
    "    # Load first image\n",
    "    image = Image.open(images[0]).convert('RGB')\n",
    "\n",
    "    # Draw pos/neg samples\n",
    "    pos_examples = SampleGenerator('gaussian', image.size, opts.trans_pos, opts.scale_pos)(\n",
    "        init_bbox, opts.n_pos_init, opts.overlap_pos_init)\n",
    "\n",
    "    neg_examples = np.concatenate([\n",
    "        SampleGenerator('uniform', image.size, opts.trans_neg_init, opts.scale_neg_init)(\n",
    "            init_bbox, int(opts.n_neg_init * 0.5), opts.overlap_neg_init),\n",
    "        SampleGenerator('whole', image.size)(\n",
    "            init_bbox, int(opts.n_neg_init * 0.5), opts.overlap_neg_init)])\n",
    "    neg_examples = np.random.permutation(neg_examples)\n",
    "\n",
    "    # Extract pos/neg features\n",
    "    pos_feats = forward_samples(model, image, pos_examples, opts)\n",
    "    neg_feats = forward_samples(model, image, neg_examples, opts)\n",
    "\n",
    "    # Initial training\n",
    "    train(model, criterion, init_optimizer, pos_feats, neg_feats, opts.maxiter_init, opts)\n",
    "    del init_optimizer, neg_feats\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Train bbox regressor\n",
    "    bbreg_examples = SampleGenerator('uniform', image.size, opts.trans_bbreg, opts.scale_bbreg, opts.aspect_bbreg)\\\n",
    "        (init_bbox, opts.n_bbreg, opts.overlap_bbreg)\n",
    "\n",
    "    bbreg_feats = forward_samples(model, image, bbreg_examples, opts)\n",
    "    bbreg = BBRegressor(image.size)\n",
    "    bbreg.train(bbreg_feats, bbreg_examples, init_bbox)\n",
    "    del bbreg_feats\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Init sample generators for update\n",
    "    sample_generator = SampleGenerator('gaussian', image.size, opts.trans, opts.scale)\n",
    "    pos_generator = SampleGenerator('gaussian', image.size, opts.trans_pos, opts.scale_pos)\n",
    "    neg_generator = SampleGenerator('uniform', image.size, opts.trans_neg, opts.scale_neg)\n",
    "\n",
    "    # Init pos/neg features for update\n",
    "    neg_examples = neg_generator(init_bbox, opts.n_neg_update, opts.overlap_neg_init)\n",
    "    neg_feats = forward_samples(model, image, neg_examples, opts)\n",
    "    pos_feats_all = [pos_feats]\n",
    "    neg_feats_all = [neg_feats]\n",
    "\n",
    "    # Main loop\n",
    "    for i, image in enumerate(images[1:], 1):\n",
    "        image = Image.open(image).convert('RGB')\n",
    "\n",
    "        # Estimate target bbox\n",
    "        samples = sample_generator(init_bbox, opts.n_samples)\n",
    "        sample_scores = forward_samples(model, image, samples, opts, out_layer='fc6')\n",
    "\n",
    "        top_scores, top_idx = sample_scores[:, 1].topk(5)\n",
    "        top_idx = top_idx.cpu()\n",
    "        target_score = top_scores.mean()\n",
    "        init_bbox = samples[top_idx]\n",
    "        if top_idx.shape[0] > 1:\n",
    "            init_bbox = init_bbox.mean(axis=0)\n",
    "        success = target_score > 0\n",
    "\n",
    "        # Expand search area at failure\n",
    "        sample_generator.trans = opts.trans if success else min(sample_generator.trans * 1.1, opts.trans_limit)\n",
    "\n",
    "        # Bbox regression\n",
    "        if success:\n",
    "            bbreg_samples = samples[top_idx]\n",
    "\n",
    "            if top_idx.shape[0] == 1:\n",
    "                bbreg_samples = bbreg_samples[None, :]\n",
    "\n",
    "            bbreg_feats = forward_samples(model, image, bbreg_samples, opts)\n",
    "            bbreg_samples = bbreg.predict(bbreg_feats, bbreg_samples)\n",
    "            bbreg_bbox = bbreg_samples.mean(axis=0)\n",
    "\n",
    "        else:\n",
    "            bbreg_bbox = init_bbox\n",
    "\n",
    "        yield init_bbox, bbreg_bbox, overlap_ratio(ground_truths[i], bbreg_bbox)[0], target_score\n",
    "\n",
    "        # Data collect\n",
    "        if success:\n",
    "            pos_examples = pos_generator(init_bbox, opts.n_pos_update, opts.overlap_pos_update)\n",
    "            pos_feats = forward_samples(model, image, pos_examples, opts)\n",
    "            pos_feats_all.append(pos_feats)\n",
    "\n",
    "            if len(pos_feats_all) > opts.n_frames_long:\n",
    "                del pos_feats_all[0]\n",
    "\n",
    "            neg_examples = neg_generator(init_bbox, opts.n_neg_update, opts.overlap_neg_update)\n",
    "            neg_feats = forward_samples(model, image, neg_examples, opts)\n",
    "            neg_feats_all.append(neg_feats)\n",
    "\n",
    "            if len(neg_feats_all) > opts.n_frames_short:\n",
    "                del neg_feats_all[0]\n",
    "\n",
    "        # Short term update\n",
    "        if not success:\n",
    "            nframes = min(opts.n_frames_short, len(pos_feats_all))\n",
    "            pos_data = torch.cat(pos_feats_all[-nframes:], 0)\n",
    "            neg_data = torch.cat(neg_feats_all, 0)\n",
    "            train(model, criterion, update_optimizer, pos_data, neg_data, opts.maxiter_update, opts)\n",
    "\n",
    "        # Long term update\n",
    "        elif i % opts.long_interval == 0:\n",
    "            pos_data = torch.cat(pos_feats_all, 0)\n",
    "            neg_data = torch.cat(neg_feats_all, 0)\n",
    "            train(model, criterion, update_optimizer, pos_data, neg_data, opts.maxiter_update, opts)\n",
    "\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional)\n",
    "\n",
    "Refresh image output in IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 4. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8901b86bad9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Run tracker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverlap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-3d13bf9c0cc6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(images, init_bbox, ground_truths, opts)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mbbreg_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbreg_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mbbreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBBRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mbbreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbreg_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbreg_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_bbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mbbreg_feats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/c/Users/maybe/Documents/Workspace/Deeplearning-Practice/6-Tracking/MDNet/models/regressor.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, bbox, gt)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/lib/python3.7/site-packages/sklearn/linear_model/ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    745\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \"\"\"\n\u001b[0;32m--> 747\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/lib/python3.7/site-packages/sklearn/linear_model/ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    545\u001b[0m                          \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_accept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                          \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                          multi_output=True, y_numeric=True)\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         if ((sample_weight is not None) and\n",
      "\u001b[0;32m~/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m~/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 539\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "options.use_gpu = False\n",
    "options.model_path = '../data/mdnet_otb.pth'\n",
    "dataset = Path('../data/OTB/DragonBaby')\n",
    "\n",
    "images = list(sorted(dataset.joinpath('img').glob('*.jpg')))\n",
    "ground_truths = pd.read_csv(str(dataset.joinpath('groundtruth_rect.txt')), header=None).values\n",
    "\n",
    "iou, success = 0, 0\n",
    "\n",
    "# Run tracker\n",
    "for i, (result, (x, y, w, h), overlap, score) in \\\n",
    "        enumerate(main(images, ground_truths[0], ground_truths, options), 1):\n",
    "    \n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    image = np.asarray(Image.open(images[i]).convert('RGB'))\n",
    "\n",
    "    gx, gy, gw, gh = ground_truths[i]\n",
    "    cv2.rectangle(image, (int(gx), int(gy)), (int(gx+gw), int(gy+gh)), (0, 255, 0), 2)\n",
    "    cv2.rectangle(image, (int(x), int(y)), (int(x+w), int(y+h)), (255, 0, 0), 2)\n",
    "\n",
    "    iou += overlap\n",
    "    success += overlap > .5\n",
    "    \n",
    "    plt.imshow(image)\n",
    "    plt.pause(.1)\n",
    "    plt.title(f'#{i}/{len(images)-1}, Overlap {overlap:.3f}, Score {score:.3f}')\n",
    "    plt.draw()\n",
    "\n",
    "iou /= len(images) - 1\n",
    "print(f'Mean IOU: {iou:.3f}, Success: {success} / {len(images)-1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
