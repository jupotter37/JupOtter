{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import sys\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import joblib\n",
    "import imodelsx.util\n",
    "import sasc.viz\n",
    "from copy import deepcopy\n",
    "from numpy.linalg import norm\n",
    "from sasc.config import CACHE_DIR, RESULTS_DIR\n",
    "\n",
    "\n",
    "num_top_test_ngrams = 75\n",
    "from sasc.modules.fmri_module import convert_module_num_to_voxel_num, add_stability_score\n",
    "tqdm.pandas()\n",
    "\n",
    "r_opt = pd.read_pickle(join(RESULTS_DIR, 'results_fmri_full_1500_opt.pkl'))\n",
    "r_llama = pd.read_pickle(join(RESULTS_DIR, 'results_fmri_full_1500_llama.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add stability scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ngram_scores_dict_opt = {}\n",
    "# ngram_scores_dict_llama = {}\n",
    "# stability_scores = {}\n",
    "# for subject in [\"UTS01\", \"UTS02\", \"UTS03\"]:\n",
    "#     ngram_scores_dict_opt[subject] = joblib.load(\n",
    "#         join(CACHE_DIR, \"cache_ngrams\", f\"fmri_{subject}.pkl\")\n",
    "#     )\n",
    "#     ngram_scores_dict_llama[subject] = joblib.load(\n",
    "#         join(CACHE_DIR, \"cache_ngrams\", f\"fmri_{subject}_llama.pkl\")\n",
    "#     )\n",
    "\n",
    "#     mat1 = ngram_scores_dict_opt[subject].T\n",
    "#     mat2 = ngram_scores_dict_llama[subject].T\n",
    "\n",
    "#     # calculate correlations between rows of the mats\n",
    "#     corrs = np.zeros(500)\n",
    "#     for i in tqdm(range(mat1.shape[0])):\n",
    "#         corrs[i] = np.corrcoef(mat1[i], mat2[i])[0, 1]\n",
    "#     stability_scores[subject] = deepcopy(corrs)\n",
    "# joblib.dump(stability_scores, join(RESULTS_DIR, \"fmri_stability_scores.jbl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=300)\n",
    "STABILITY_SCORES_DICT = joblib.load(join(RESULTS_DIR, \"fmri_stability_scores.jbl\"))\n",
    "for i, subject in enumerate([\"UTS01\", \"UTS02\", \"UTS03\"]):\n",
    "    plt.hist(STABILITY_SCORES_DICT[subject], label=subject, alpha=0.7)\n",
    "    plt.axvline(np.mean(STABILITY_SCORES_DICT[subject]), linewidth=3, color=f\"C{i}\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Stability score (correlation of ngram scores)\")\n",
    "plt.ylabel(\"Number of voxels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export gsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1500/1500 [00:13<00:00, 110.78it/s]\n",
      "100%|██████████| 1500/1500 [00:00<00:00, 154977.24it/s]\n"
     ]
    }
   ],
   "source": [
    "def clean_df(df):\n",
    "    # df = df.sort_values(by=['top_score_synthetic'], ascending=False)\n",
    "    # df['pid'] = df['subject'] + ' ' + df['module_num'].astype(str)\n",
    "    # df = df.set_index('pid')\n",
    "    df[\"voxel_num\"] = df.progress_apply(\n",
    "        lambda row: convert_module_num_to_voxel_num(row[\"module_num\"], row[\"subject\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    df[\"stability_score\"] = df.progress_apply(\n",
    "        lambda row: add_stability_score(row[\"module_num\"], row[\"subject\"]),\n",
    "        axis=1,\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "r = clean_df(r_opt)\n",
    "for k in [\n",
    "    \"top_score_synthetic\",\n",
    "    \"fmri_test_corr\",\n",
    "    \"top_ngrams_module_correct\",\n",
    "    \"top_score_normalized\",\n",
    "    'top_explanation_init_strs',\n",
    "    'explanation_init_strs',\n",
    "]:\n",
    "    r[k + \"_llama\"] = r_llama[k]\n",
    "\n",
    "# overlapping ngrams\n",
    "# r.apply(\n",
    "#     lambda row: len(\n",
    "#         set(row[\"top_ngrams_module_correct\"].tolist()).intersection(\n",
    "#             row[\"top_ngrams_module_correct_llama\"].tolist()\n",
    "#         )\n",
    "#     ),\n",
    "#     axis=1,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    # fmri stuff\n",
    "    'subject': 'Subject',\n",
    "    'module_num': 'Voxel',\n",
    "    'roi_func': 'ROI (functional)',\n",
    "    'roi_anat': 'ROI (anatomical)',\n",
    "    'fmri_test_corr': 'Enc. correlation',\n",
    "    'fmri_test_corr_llama': 'Enc. correlation (llama)',\n",
    "    \n",
    "    # scores\n",
    "    'top_score_normalized': 'Explanation score',\n",
    "    'top_score_normalized_llama': 'Explanation score (llama)',\n",
    "    'stability_score': 'Stability score',\n",
    "    'frac_top_ngrams_module_correct': 'Fraction of matching ngrams (module, top-75)',\n",
    "    'rankcorr_expl_test': 'Correlation (test) when predicting with only explanation',\n",
    "    # 'frac_top_ngrams_test_correct': 'Fraction of matching ngrams (test, top-75)',\n",
    "            \n",
    "    # explanation\n",
    "    'top_explanation_init_strs': 'Explanation',\n",
    "    'top_explanation_init_strs_llama': 'Explanation (llama)',\n",
    "        \n",
    "    # ngrams matching the explanation (used 75 ngrams)\n",
    "    'top_ngrams_module_correct': 'Matching top ngrams (out of top-75)',\n",
    "    'top_ngrams_module_correct_llama': 'Matching top ngrams (llama, out of top-75)',\n",
    "    # 'top_ngrams_test_correct': 'Matching ngrams (test, top-75)',\n",
    "\n",
    "    # all ngrams\n",
    "    'top_ngrams_module_25': 'All top ngrams (top-25)',\n",
    "    # 'top_ngrams_test_25': 'Top ngrams (test, top-25)',\n",
    "\n",
    "    # alternative explanations\n",
    "    'explanation_init_strs': 'Explanation candidates',\n",
    "    'explanation_init_strs_llama': 'Explanation candidates (llama)',\n",
    "}\n",
    "\n",
    "tab = (\n",
    "    r\n",
    "    .sort_values(by=['top_score_synthetic'], ascending=False)\n",
    "    # .sort_values(by=['rankcorr_expl_test'], ascending=False)\n",
    "    .filter(columns.keys())\n",
    "    .rename(columns=columns)\n",
    "    .round(3)\n",
    ")\n",
    "with pd.option_context('display.max_colwidth', None, 'display.max_rows', 200):\n",
    "    # display(\n",
    "        # tab.head(3)\n",
    "    # )\n",
    "    tab_join_lists = tab.applymap(lambda x: ' __ '.join(x) if isinstance(x, np.ndarray) or isinstance(x, list) else x)\n",
    "    tab_join_lists.to_csv('../results/results_fmri.csv', index=False, float_format='%.3f')\n",
    "r[columns.keys()].to_pickle('../results/fmri_results_merged.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at relationships between things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    \"Corr (test)\",\n",
    "    \"Expl score\",\n",
    "    \"Frac matching ngrams\",\n",
    "    \"Expl corr (test)\",\n",
    "]\n",
    "# sns.pairplot(\n",
    "#     r_opt[cols],\n",
    "#     kind=\"reg\",\n",
    "#     diag_kind=\"kde\",\n",
    "#     plot_kws={\"scatter_kws\": {\"alpha\": 0.1}},\n",
    "#     markers=\".\",\n",
    "#     height=2,\n",
    "#     aspect=1.5,\n",
    "#     corner=True,\n",
    "# )\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "left = r_opt\n",
    "right = r_llama\n",
    "suffixes = (\"\", \"_llama\")\n",
    "\n",
    "# merge the two dataframes\n",
    "df = left.merge(right, left_index=True, right_index=True, suffixes=suffixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'text-davinci-003'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# sns.heatmap(df.corr())\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m corrs \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mcorr()\n\u001b[1;32m      3\u001b[0m \u001b[39m# hide the upper triangle\u001b[39;00m\n\u001b[1;32m      4\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros_like(corrs, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n",
      "File \u001b[0;32m~/imodelsx/.venv/lib/python3.11/site-packages/pandas/core/frame.py:10054\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  10052\u001b[0m cols \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m  10053\u001b[0m idx \u001b[39m=\u001b[39m cols\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m> 10054\u001b[0m mat \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mto_numpy(dtype\u001b[39m=\u001b[39;49m\u001b[39mfloat\u001b[39;49m, na_value\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mnan, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m  10056\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpearson\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m  10057\u001b[0m     correl \u001b[39m=\u001b[39m libalgos\u001b[39m.\u001b[39mnancorr(mat, minp\u001b[39m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m~/imodelsx/.venv/lib/python3.11/site-packages/pandas/core/frame.py:1838\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1836\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1837\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 1838\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1839\u001b[0m \u001b[39mif\u001b[39;00m result\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m dtype:\n\u001b[1;32m   1840\u001b[0m     result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(result, dtype\u001b[39m=\u001b[39mdtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/imodelsx/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:1732\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1730\u001b[0m         arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mwriteable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1731\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1732\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[1;32m   1733\u001b[0m     \u001b[39m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1734\u001b[0m     \u001b[39m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1736\u001b[0m \u001b[39mif\u001b[39;00m na_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/imodelsx/.venv/lib/python3.11/site-packages/pandas/core/internals/managers.py:1794\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1792\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1793\u001b[0m         arr \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1794\u001b[0m     result[rl\u001b[39m.\u001b[39;49mindexer] \u001b[39m=\u001b[39m arr\n\u001b[1;32m   1795\u001b[0m     itemmask[rl\u001b[39m.\u001b[39mindexer] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1797\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m itemmask\u001b[39m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'text-davinci-003'"
     ]
    }
   ],
   "source": [
    "# sns.heatmap(df.corr())\n",
    "corrs = df.corr()\n",
    "# hide the upper triangle\n",
    "mask = np.zeros_like(corrs, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "corrs[mask] = 0\n",
    "plt.figure(figsize=(8, 8), dpi=300)\n",
    "sasc.viz.imshow_diverging(corrs)\n",
    "plt.yticks(ticks=range(len(corrs.columns)), labels=corrs.columns, rotation=0)\n",
    "plt.xticks(ticks=range(len(corrs.columns)), labels=corrs.columns, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overarching stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = r[['top_score_normalized', 'rankcorr_expl_test']]\n",
    "# rt = rt.sort_values('fmri_test_corr', ascending=False)\n",
    "print(rt.mean())\n",
    "print(rt.std() / np.sqrt(rt.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = joblib.load(join(SAVE_DIR_FMRI, 'stories', 'running_words.jbl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearmans = []\n",
    "pearsons = []\n",
    "cvs = []\n",
    "# test different prediction mappings\n",
    "for i in tqdm(range(r.shape[0])):\n",
    "    row = r.iloc[i]\n",
    "    resp = dsets[row[\"subject\"]][\"resp\"][:, row[\"module_num\"]]\n",
    "    neg_dists = np.array(row[\"neg_dists_expl_test\"])\n",
    "    neg_dists[np.isnan(neg_dists)] = np.nanmean(neg_dists)\n",
    "\n",
    "    # stack neg_dists with delays\n",
    "    neg_dists_arr = np.stack(\n",
    "        [\n",
    "            np.concatenate((neg_dists[i:], np.ones(i) * np.nanmean(neg_dists)))\n",
    "            for i in range(3)\n",
    "        ]\n",
    "    ).T\n",
    "    # print(neg_dists_arr.shape, resp.shape)\n",
    "    neg_dists = np.mean(neg_dists_arr, axis=1)\n",
    "    \n",
    "    spearmans.append(\n",
    "        scipy.stats.spearmanr(\n",
    "            neg_dists, resp, nan_policy=\"omit\", alternative=\"greater\"\n",
    "        ).statistic\n",
    "    )\n",
    "    # pearson correlation\n",
    "    pearsons.append(scipy.stats.pearsonr(neg_dists, resp)[0])\n",
    "\n",
    "    # m = RidgeCV(alphas=10, scoring='r2')\n",
    "    # m.fit(neg_dists_arr, resp)\n",
    "    # neg_dists = m.predict(neg_dists_arr)\n",
    "    # cvs.append(m.best_score_)\n",
    "    cvs.append(0)\n",
    "    # cvs.append(scipy.stats.pearsonr(neg_dists, resp)[0])\n",
    "    # cvs = \n",
    "print(\"means\", np.mean(spearmans), np.mean(pearsons), np.mean(cvs))\n",
    "r['rankcorr_expl_test'] = spearmans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9ff692d44ea03fd8a03facee7621117bbbb82def09bacaacf0a2cbc238b7b91"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
