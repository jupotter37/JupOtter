{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pyDOE import *\n",
    "import xarray as xr\n",
    "import copy\n",
    "import netCDF4\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download latest version of params file from google drive\n",
    "* requires 'publishing' the google drive spreadsheet\n",
    "* file > publish to web\n",
    "* then it can be set up to continuously publish the spreadsheet to a stable url (with some latency, maybe 1-2 minutes)\n",
    "* note that the first tab must be the sheet where the relevant information is located"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vQs413GtLXtHVDCqEPgAwn4BbDjoWmV7uFqOAWH4mgpxXoVfN6ijnJdhyRgLkV-n2eU-sSQush4CzYU/pub?output=csv'\n",
    "cmd = 'curl -L '+data_url+' > params.csv' # need to add -L option to force redirects\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a class for organizing parameter information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamInfo(object):\n",
    "    \"\"\"\n",
    "    Stores parameter information.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name, loc, minval=None, maxval=None, defval=None, value=None):\n",
    "        self._name = name # parameter name\n",
    "        self._min = minval # minimum value\n",
    "        self._max = maxval # maximum value\n",
    "        self._default = defval # default value\n",
    "        self._value = value # actual value to be used in a given ensemble member\n",
    "        self._location = loc # location of parameter (params file or namelist)\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "\n",
    "    @property\n",
    "    def min(self):\n",
    "        return self._min\n",
    "\n",
    "    @property\n",
    "    def max(self):\n",
    "        return self._max\n",
    "    \n",
    "    @property\n",
    "    def default(self):\n",
    "        return self._default\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        return self._value\n",
    "    \n",
    "    @property\n",
    "    def location(self):\n",
    "        return self._location\n",
    "    \n",
    "    @name.setter\n",
    "    def name(self, new_name):\n",
    "        self._name = new_name\n",
    "   \n",
    "    @min.setter\n",
    "    def min(self, new_min):\n",
    "        self._min = new_min\n",
    "        \n",
    "    @max.setter\n",
    "    def max(self, new_max):\n",
    "        self._max = new_max\n",
    "        \n",
    "    @default.setter\n",
    "    def default(self, new_def):\n",
    "        self._default = new_def\n",
    "        \n",
    "    @value.setter\n",
    "    def value(self, new_val):\n",
    "        self._value = new_val\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return \"%s:\\n\\tloc = %s\\n\\tdefault = %s\\n\\tmin = %s\\n\\tmax = %s\\n\\tvalue = %s\" % (self.name, self.location, self.default, self.min, self.max, self.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: add these or other unit tests to ParamInfo class itself\n",
    "# Check every time the code updates, or adding new functionality\n",
    "\n",
    "# testing out the class/dictionary functionality\n",
    "test_dict = {\"P1\": ParamInfo(\"P1\", minval=0.0, maxval=1.0, defval=2.0, loc='N'),\n",
    "             \"P2\": ParamInfo(\"P2\", minval=[0,0,0,0,0], maxval=[100,100,100,100,100], defval=[0,1,2,3,4], loc='P'),\n",
    "             \"P3\": ParamInfo(\"P3\", minval=\"min\", maxval=\"max\", defval=\"value\", loc='N'),\n",
    "             \"P4\": ParamInfo(\"P4\", loc='P')\n",
    "            }\n",
    "\n",
    "# example of adding a new parameter\n",
    "test_dict[\"new_param\"] = ParamInfo(\"new_param\", 'N')\n",
    "\n",
    "# example of setting the max value\n",
    "test_dict[\"P4\"].max = 200\n",
    "\n",
    "# example of setting the value for a given ensemble member\n",
    "test_dict[\"new_param\"].value = 100\n",
    "\n",
    "# look at the test dictionary\n",
    "for key in test_dict:\n",
    "    print(test_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a class for organizing ensemble members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Member(object):\n",
    "    \"\"\"\n",
    "    Stores and works with a bunch of ParamInfos.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name, paraminfo):\n",
    "        self._name = name\n",
    "        self._paraminfo = paraminfo\n",
    "        \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @property\n",
    "    def paraminfo(self):\n",
    "        return self._paraminfo\n",
    "    \n",
    "    @name.setter\n",
    "    def name(self, new_name):\n",
    "        self._name = new_name\n",
    "    \n",
    "    def get_names(self):\n",
    "        \"\"\"\n",
    "        Returns a list of parameter names.\n",
    "        \"\"\"\n",
    "        \n",
    "        names = []\n",
    "        for param in self._paraminfo:\n",
    "            names.append(self._paraminfo[param].name)\n",
    "        return names\n",
    "                 \n",
    "    def write(self, sampling_protocol):\n",
    "        \"\"\"\n",
    "        Writes files to disk for each member: param netcdf, namelist mods txt.\n",
    "        \"\"\"\n",
    "        \n",
    "        # TO DO: remove existing files from these folders before writing output?\n",
    "        \n",
    "        # generate file names based on member name\n",
    "        i = int(self._name)\n",
    "        self._paramkey = sampling_protocol+str(i+1).zfill(4)\n",
    "        #self._pftfile = \"../paramfiles/\"+self._paramkey+\".nc\"\n",
    "        #self._nlfile = \"../namelist_mods/\"+self._paramkey+\".txt\" \n",
    "        self._pftfile = \"/glade/scratch/kdagon/CLM5PPE/paramfiles/\"+self._paramkey+\".nc\"\n",
    "        self._nlfile = \"/glade/scratch/kdagon/CLM5PPE/namelist_mods/\"+self._paramkey+\".txt\"\n",
    "        \n",
    "        # assign the basepftfile (this also happens in Ensemble class)\n",
    "        #self._basepftfile = \"../basecase/clm5_params.c200717.nc\"\n",
    "        self._basepftfile= '/glade/p/cgd/tss/people/oleson/modify_param/ctsm51_params.c210217_kwo.c210222.nc'\n",
    "        \n",
    "        # create the pftfile as a copy of the basepftfile\n",
    "        # NOTE: this will create a file for each ensemble member, regardless of if param mods are needed\n",
    "        cmd = 'cp '+self._basepftfile+' '+self._pftfile\n",
    "        os.system(cmd)\n",
    "        \n",
    "        # create the nlfile\n",
    "        # NOTE: this will create a file for each ensemble member, regardless of if nl mods are needed\n",
    "        with open(self._nlfile,\"w\") as file:\n",
    "            output = \"! user_nl_clm namelist options written by generate_params:\\n\"\n",
    "            file.write(output)\n",
    "            \n",
    "        # read in the pftfile using netCDF4 package\n",
    "        dset = netCDF4.Dataset(self._pftfile,'r+')\n",
    "        \n",
    "        # modify the param/nl files\n",
    "        if sampling_protocol == \"OAAT\":\n",
    "            for paramname in self.get_names():\n",
    "                \n",
    "                # TO DO: code these flags more universally?\n",
    "                # NOTE: this assumes all flagged parameters are loc=P (true for now)\n",
    "                \n",
    "                # CWD flag \n",
    "                if paramname == ['cwd_fcel', 'cwd_flig']: \n",
    "                    # only modify if list is not empty\n",
    "                    if self._paraminfo['CWD'].value:\n",
    "                        # loop over parameters\n",
    "                        for i in np.arange(len(paramname)):\n",
    "                            print(paramname[i]+' modified in '+self._pftfile)\n",
    "                            dset[paramname[i]][:] = self._paraminfo['CWD'].value[i]\n",
    "                                \n",
    "                # Q10 flag\n",
    "                elif paramname == ['q10_hr', 'froz_q10']: \n",
    "                    # only modify if list is not empty\n",
    "                    if self._paraminfo['Q10'].value:\n",
    "                        # loop over parameters\n",
    "                        for i in np.arange(len(paramname)):\n",
    "                            print(paramname[i]+' modified in '+self._pftfile)\n",
    "                            dset[paramname[i]][:] = self._paraminfo['Q10'].value[i]\n",
    "                \n",
    "                # LF flag\n",
    "                elif paramname == ['lf_fcel', 'lf_flab', 'lf_flig']:\n",
    "                    # only modify if list is not empty\n",
    "                    if self._paraminfo['LF'].value:\n",
    "                        # loop over parameters\n",
    "                        for i in np.arange(len(paramname)):\n",
    "                            print(paramname[i]+' modified in '+self._pftfile)\n",
    "                            dset[paramname[i]][:] = self._paraminfo['LF'].value[i]\n",
    "                \n",
    "                # FR flag\n",
    "                elif paramname == ['fr_fcel', 'fr_flab', 'fr_flig']:\n",
    "                    # only modify if list is not empty\n",
    "                    if self._paraminfo['FR'].value:\n",
    "                        # loop over parameters\n",
    "                        for i in np.arange(len(paramname)):\n",
    "                            print(paramname[i]+' modified in '+self._pftfile)\n",
    "                            dset[paramname[i]][:] = self._paraminfo['FR'].value[i]\n",
    "                            \n",
    "                # KCN flag\n",
    "                elif paramname == ['kc_nonmyc', 'kn_nonmyc', 'akc_active', 'akn_active', 'ekc_active', 'ekn_active']:\n",
    "                    # only modify if list is not empty\n",
    "                    if self._paraminfo['KCN'].value:\n",
    "                        # loop over parameters\n",
    "                        for i in np.arange(len(paramname)):\n",
    "                            print(paramname[i]+' modified in '+self._pftfile)\n",
    "                            dset[paramname[i]][:] = self._paraminfo['KCN'].value[i]\n",
    "                \n",
    "                # for OAAT, only modify if value is not 'None'\n",
    "                elif self._paraminfo[paramname].value is not None:\n",
    "                    \n",
    "                    # check if perturbation value is equal to default (TO DO: check this for dependencies?)\n",
    "                    # if so, don't modify files\n",
    "                    \n",
    "                    # logic if value is an array (i.e., PFT-dependent)\n",
    "                    if type(self._paraminfo[paramname].value) == np.ndarray:\n",
    "                        if all(self._paraminfo[paramname].value == self._paraminfo[paramname].default):\n",
    "                            print(paramname+' skipped in '+self._pftfile)\n",
    "                            continue\n",
    "                    # logic if value is a single value but default is an array\n",
    "                    # TO DO: need separate logic for P and N defaults (N defaults don't have a \"size\" attribute)\n",
    "                    elif type(self._paraminfo[paramname].value)== str and self._paraminfo[paramname].default.size > 1:\n",
    "                        # start at index 1 in default to skip non-veg values\n",
    "                        if float(self._paraminfo[paramname].value) == all(self._paraminfo[paramname].default[1:]):\n",
    "                            print(paramname+' skipped in '+self._pftfile)\n",
    "                            continue\n",
    "                    # logic if value and default are single values\n",
    "                    elif type(self._paraminfo[paramname].value)== str and self._paraminfo[paramname].default.size == 1:\n",
    "                        if float(self._paraminfo[paramname].value) == self._paraminfo[paramname].default:\n",
    "                            print(paramname+' skipped in '+self._pftfile)\n",
    "                            continue\n",
    "                             \n",
    "                        # if skipping, remove the files?\n",
    "                        # but what about the naming convention?\n",
    "                        #cmd = 'rm '+self._pftfile\n",
    "                        #os.system(cmd)\n",
    "                        #cmd = 'rm '+self._nlfile\n",
    "                        #os.system(cmd)\n",
    "                        #break\n",
    "                    \n",
    "                    # params file\n",
    "                    if self._paraminfo[paramname].location == \"P\":\n",
    "                        print(paramname+' modified in '+self._pftfile)\n",
    "                        dset[paramname][:] = self._paraminfo[paramname].value\n",
    "                    # namelist\n",
    "                    elif self._paraminfo[paramname].location == \"N\":\n",
    "                        print(paramname+' modified in '+self._nlfile)\n",
    "                        with open(self._nlfile,\"a\") as file: # using \"a\" for append option\n",
    "                            output = \"%s=%s\\n\" % (paramname, self._paraminfo[paramname].value) # TO DO: round values?\n",
    "                            file.write(output)\n",
    "\n",
    "        # TO DO: LHC code for writing files\n",
    "        elif sampling_protocol == \"LHC\":\n",
    "            pass\n",
    "        \n",
    "        # need to \"close\" netcdf file to write out\n",
    "        dset.close() \n",
    "        \n",
    "    def __repr__(self):\n",
    "        i = int(self._name)\n",
    "        return \"Ensemble member %s\" % (str(i+1), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: add these or other unit tests to Member class itself\n",
    "# Check every time the code updates, or adding new functionality\n",
    "\n",
    "# testing out the class/dictionary functionality\n",
    "member_test_dict = {\"M1\": Member(\"0\", paraminfo=test_dict),\n",
    "             \"M2\": Member(\"1\", paraminfo=test_dict),\n",
    "             \"M3\": Member(\"2\", paraminfo=None),\n",
    "             \"M4\": Member(\"3\", paraminfo=None)\n",
    "            }\n",
    "\n",
    "# example of adding a new member\n",
    "member_test_dict[\"new_member\"] = Member(\"new_member\", paraminfo=test_dict)\n",
    "\n",
    "# example of setting the name\n",
    "member_test_dict[\"new_member\"].name = \"4\"\n",
    "\n",
    "# look at the test dictionary\n",
    "for key in member_test_dict:\n",
    "    print(member_test_dict[key])\n",
    "    \n",
    "# look at a member's paraminfo in the test dictionary\n",
    "member_test_dict['M1'].paraminfo\n",
    "\n",
    "# look at a member's paraminfo for a specific parameter\n",
    "member_test_dict['M1'].paraminfo['P1']\n",
    "\n",
    "# get the list of parameter names\n",
    "member_test_dict['M1'].get_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a class for organizing the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(object):\n",
    "    \"\"\"\n",
    "    Stores and works with a bunch of Members.\n",
    "    \"\"\"\n",
    "    \n",
    "    # assign the basepftfile (this also happens in Member class)\n",
    "    #_basepftfile = \"../basecase/clm5_params.c200717.nc\"\n",
    "    _basepftfile='/glade/p/cgd/tss/people/oleson/modify_param/ctsm51_params.c210217_kwo.c210222.nc'\n",
    "    \n",
    "    # using an example lnd_in file to pull in default namelist values\n",
    "    # could also parse the namelist defaults file, see: https://github.com/ESCOMP/CTSM/blob/e2b9745d81ed5cb7cd7f5d6098edf506a4956335/bld/namelist_files/namelist_defaults_ctsm.xml\n",
    "    #_thedir = '/glade/work/djk2120/ctsm_hardcode_co/cime/scripts/clm50c6_ctsmhardcodep_2deg_GSWP3V1_Sparse250_2000/CaseDocs/'\n",
    "    _thedir = '/glade/work/oleson/lmbirch_wkattge.n01_ctsm5.1.dev006/cime/scripts/clm51_lmbirchwkattgen01ctsm51d006_2deg_GSWP3V1_PPE_1850pAD/CaseDocs/'\n",
    "    _thefil = 'lnd_in'\n",
    "    _lndin = _thedir+_thefil\n",
    "    \n",
    "    def __init__(self, csvfile, sampling_protocol):\n",
    "        self._sampling_protocol = sampling_protocol\n",
    "        \n",
    "        print(\"Reading in data from spreadsheet...\",end=\"\")\n",
    "        \n",
    "        # read in csv file, filtering by the \"include\" column\n",
    "        data = pd.read_csv(csvfile,header=0,skiprows=[1]) # modify read_csv to account for header spanning 2 rows\n",
    "        #included = data['test'] == 1 # testing flag\n",
    "        included = data['final'] == 1 # final flag\n",
    "        params_full = data.loc[included,['name','location','min','max','flag','pft_mins','pft_maxs']]\n",
    "\n",
    "        # reset indexing and get rid of excel row number\n",
    "        params = params_full.reset_index(drop=True)\n",
    "        \n",
    "        print(\"Done\")\n",
    "        \n",
    "        print(\"Creating dictionary of parameter information and reading default values...\",end=\"\")\n",
    "        \n",
    "        # declare a dictionary to store parameter information\n",
    "        self._params_dict = {}\n",
    "        \n",
    "        # read in default pftfile\n",
    "        #def_params = xr.open_dataset(self._basepftfile) \n",
    "        # replacing xarray with netcdf due to issues with reading ndays* params\n",
    "        def_params = netCDF4.Dataset(self._basepftfile,'r')\n",
    "        \n",
    "        # assigning the default values\n",
    "        # loop over parameters grabbing name, location, and flags\n",
    "        for name,loc,flag in zip(params['name'],params['location'],params['flag']):      \n",
    "            \n",
    "            # check for flags\n",
    "            # NOTE: this assumes all flagged parameters are loc=P (true for now)\n",
    "            if pd.notnull(flag):\n",
    "\n",
    "                # check to see if a params_dict entry has been created with flag label\n",
    "                if flag in self._params_dict.keys():\n",
    "                    # if it has already been created, append next parameter name and default value\n",
    "                    self._params_dict[flag].name.append(name)\n",
    "                    #x = def_params[name].values\n",
    "                    x = def_params[name][:]\n",
    "                    self._params_dict[flag].default.append(x) \n",
    "                else:\n",
    "                    # if it hasn't been created, initialize the ParamInfo with placeholder lists\n",
    "                    #x = def_params[name].values\n",
    "                    x = def_params[name][:]\n",
    "                    self._params_dict[flag] = ParamInfo(name=[name], loc=loc, defval=[x], minval=[], maxval=[], value=[])\n",
    "                    \n",
    "                # for KCN flag, parameters needs to be perturbed together and OAAT so also set up the OAAT ParamInfos\n",
    "                if flag=='KCN':\n",
    "                    #x = def_params[name].values\n",
    "                    x = def_params[name][:]\n",
    "                    self._params_dict[name] = ParamInfo(name, defval=x, loc=loc)    \n",
    "            \n",
    "            # select parameters located in the params file\n",
    "            elif loc=='P':\n",
    "                # getting parameter dims (i.e., checking for segment variation)\n",
    "                #dims = len(def_params[name].values.shape)\n",
    "                dims = len(def_params[name][:].shape)\n",
    "                if dims<2:\n",
    "                    # no segment variation\n",
    "                    #x = def_params[name].values\n",
    "                    x = def_params[name][:]\n",
    "                else:\n",
    "                    # segment variation: ck,kmax,psi50,rootprof_beta\n",
    "                    # assumes the same values are applied across segments\n",
    "                    # NOTE: this assumption is not strictly true for rootprof_beta\n",
    "                    #x = def_params[name][0,:].values\n",
    "                    x = def_params[name][0,:]\n",
    "                    \n",
    "                self._params_dict[name] = ParamInfo(name, defval=x, loc='P')\n",
    "            \n",
    "            # select namelist parameters\n",
    "            elif loc=='N':\n",
    "                # build a command to search lnd_in file for the parameter by name and put output in a tmp file\n",
    "                cmd = 'grep '+name+' '+self._lndin+' > tmp.txt'\n",
    "                ret = os.system(cmd)\n",
    "                # checking for nonzero return code, meaning parameter is not found\n",
    "                if ret != 0:\n",
    "                    # NOTE: will need to address these special cases if they exist\n",
    "                    print(name+' not found')\n",
    "                else:\n",
    "                    f = open('tmp.txt', 'r')\n",
    "                    # parse the value from the parameter name\n",
    "                    tmp = f.read().split()[2]\n",
    "                    f.close()\n",
    "                    # cases where scientific notation is specified by a \"d\"\n",
    "                    if 'd' in tmp:\n",
    "                        tmp = tmp.split('d')\n",
    "                        x = float(tmp[0])*10**float(tmp[1])\n",
    "                    else:\n",
    "                        x = float(tmp)\n",
    "                    self._params_dict[name] = ParamInfo(name, defval=x, loc='N')\n",
    "                    # TO DO: remove tmp.txt file when finished?\n",
    "        \n",
    "        # count entries in params_dict as number of parameters (accounts for parameter dependencies)\n",
    "        self._nparam = len(self._params_dict)\n",
    "        \n",
    "        print(\"Done\")\n",
    "        \n",
    "        print(\"Assigning min and max values...\",end=\"\")\n",
    "        \n",
    "        # assigning min and max values\n",
    "        if sampling_protocol == 'OAAT':\n",
    "            for name,minv,maxv,pftmin,pftmax,flag in zip(params['name'],params['min'],params['max'],params['pft_mins'],params['pft_maxs'],params['flag']): \n",
    "                \n",
    "                # first check for KCN flag, needs to be perturbed together and OAAT\n",
    "                if flag=='KCN':\n",
    "                    # check for \"XXpercent\" perturb from default\n",
    "                    if \"percent\" in minv and \"percent\" in maxv: # NOTE: assumes \"percent\" is written in both min and max cells\n",
    "                        percent_perturb_min = float(minv.split(\"percent\")[0])\n",
    "                        percent_perturb_max = float(maxv.split(\"percent\")[0])\n",
    "                        percent_min_values = self._params_dict[name].default*(1 - percent_perturb_min/100)\n",
    "                        percent_max_values = self._params_dict[name].default*(1 + percent_perturb_max/100)\n",
    "                        self._params_dict[name].min = percent_min_values\n",
    "                        self._params_dict[name].max = percent_max_values\n",
    "                    else:\n",
    "                        self._params_dict[name].min = minv\n",
    "                        self._params_dict[name].max = maxv\n",
    "                \n",
    "                # check for flags\n",
    "                if pd.notnull(flag):\n",
    "                    # check for \"XXpercent\" perturb from default\n",
    "                    if \"percent\" in minv and \"percent\" in maxv: # NOTE: assumes \"percent\" is written in both min and max cells\n",
    "                        # need to keep track parameter order for the default indexing\n",
    "                        # only want to do this for loop ONCE so only execute if min/max lists are currently empty\n",
    "                        if self._params_dict[flag].min == [] and self._params_dict[flag].max == []:\n",
    "                            for i,p in enumerate(self._params_dict[flag].name):\n",
    "                                percent_perturb_min = float(minv.split(\"percent\")[0])\n",
    "                                percent_perturb_max = float(maxv.split(\"percent\")[0])\n",
    "                                percent_min_values = self._params_dict[flag].default[i]*(1 - percent_perturb_min/100)\n",
    "                                percent_max_values = self._params_dict[flag].default[i]*(1 + percent_perturb_max/100)\n",
    "                                self._params_dict[flag].min.append(percent_min_values)\n",
    "                                self._params_dict[flag].max.append(percent_max_values)\n",
    "                    else:\n",
    "                        # append min and max values for each parameter in a given flag\n",
    "                        self._params_dict[flag].min.append(minv)\n",
    "                        self._params_dict[flag].max.append(maxv)\n",
    "                \n",
    "                # check for pft variation\n",
    "                elif minv=='pft' and maxv=='pft': # NOTE: assumes \"pft\" is written in both min and max cells\n",
    "                    self._params_dict[name].min = np.fromstring(pftmin, dtype='float', sep=',')\n",
    "                    self._params_dict[name].max = np.fromstring(pftmax, dtype='float', sep=',')\n",
    "                \n",
    "                # check for \"XXpercent\" perturb from default\n",
    "                elif \"percent\" in minv and \"percent\" in maxv: # NOTE: assumes \"percent\" is written in both min and max cells\n",
    "                    percent_perturb_min = float(minv.split(\"percent\")[0])\n",
    "                    percent_perturb_max = float(maxv.split(\"percent\")[0])\n",
    "                    percent_min_values = self._params_dict[name].default*(1 - percent_perturb_min/100)\n",
    "                    percent_max_values = self._params_dict[name].default*(1 + percent_perturb_max/100)\n",
    "                    self._params_dict[name].min = percent_min_values\n",
    "                    self._params_dict[name].max = percent_max_values\n",
    "                \n",
    "                else:\n",
    "                    # assign min/max values directly\n",
    "                    self._params_dict[name].min = minv\n",
    "                    self._params_dict[name].max = maxv\n",
    "        \n",
    "        elif sampling_protocol == 'LHC':\n",
    "            # TO DO: assign LHC min/maxes\n",
    "            pass\n",
    "        \n",
    "        print(\"Done\")\n",
    "        \n",
    "        # declare a dictionary to store member information\n",
    "        self._members = {}\n",
    "        \n",
    "        # set the number of ensemble members\n",
    "        if sampling_protocol == 'OAAT':\n",
    "            # number of samples is twice the number of parameter entries in param_dict (min and max perturbations)\n",
    "            nsamp = 2*self._nparam\n",
    "        elif sampling_protocol == 'LHC':\n",
    "            # define sample size for LHC (user-specified)\n",
    "            nsamp = 10\n",
    "        \n",
    "        print(\"Creating ensemble with \"+str(nsamp)+\" members...\",end=\"\")\n",
    "        \n",
    "        # create the ensemble members\n",
    "        # need to \"deepcopy\" the dictionary for each member so they can be modified independently\n",
    "        for i in range(nsamp):\n",
    "            self._members[i] = Member(str(i), copy.deepcopy(self._params_dict))\n",
    "        \n",
    "        # loop over members and calculate parameter values for each member                \n",
    "        # TO DO: OAAT ONLY - NEED TO ADD LHC CODE\n",
    "        doneparams = []\n",
    "        for member in self._members:\n",
    "            for paramname in self._params_dict.keys():\n",
    "                # check if this parameter has already been assigned\n",
    "                if paramname in doneparams:\n",
    "                    continue\n",
    "                # check if this is a min or max perturbation\n",
    "                if int(self._members[member].name)%2 == 0:\n",
    "                    # min values\n",
    "                    self._members[member].paraminfo[paramname].value = self._members[member].paraminfo[paramname].min\n",
    "                    break\n",
    "                else:\n",
    "                    # max values\n",
    "                    self._members[member].paraminfo[paramname].value = self._members[member].paraminfo[paramname].max\n",
    "                    \n",
    "                    # parameter is \"done\" after creating min/max ensemble members in sequence\n",
    "                    doneparams.append(paramname)\n",
    "                    break\n",
    "        \n",
    "        print(\"Done\")\n",
    "        \n",
    "    @property\n",
    "    def params(self):\n",
    "        return self._params_dict\n",
    "    \n",
    "    @property\n",
    "    def members(self):\n",
    "        return self._members\n",
    "    \n",
    "    def output_files(self):\n",
    "        \"\"\"\n",
    "        Loop over members in the ensemble and call the write function.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Writing files to disk for each member...\")\n",
    "        \n",
    "        for member in self._members:\n",
    "            self._members[member].write(self._sampling_protocol)\n",
    "    \n",
    "        print(\"Done\")\n",
    "    \n",
    "    def save_psets(self, ensemble_name):\n",
    "        \"\"\"\n",
    "        Save the parameter values for the ensemble.\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Writing out parameter info for the ensemble...\",end=\"\")\n",
    "        \n",
    "        # build the file name with the prefix (ensemble type)\n",
    "        #psetsfile = \"../parameter_sets/\"+self._sampling_protocol+\"_\"+ensemble_name+\".txt\"\n",
    "        #psetsfile = \"../parameter_sets/\"+self._sampling_protocol+\"_\"+ensemble_name+\".json\"\n",
    "        psetsfile = \"../parameter_sets/\"+self._sampling_protocol+\"_\"+ensemble_name+\".csv\"\n",
    "        #psetsfile = \"/glade/scratch/kdagon/CLM5PPE/parameter_sets/\"+self._sampling_protocol+\"_\"+ensemble_name+\".csv\"\n",
    "        \n",
    "        # TO DO: figure out how to organize pset info\n",
    "        # Question is for reading this info back in for analysis, what is the best way to store the pset info?\n",
    "        \n",
    "        # This writes a very long text file, but all the information is there:\n",
    "        #with open(psetsfile, 'w') as fp:\n",
    "            #for member in self._members:\n",
    "                #fp.write(str(self._members[member]) + '\\n')\n",
    "                ##for paramname in self._members[member].get_names():\n",
    "                #for paramname in self._params_dict.keys():\n",
    "                    #fp.write(str(self._members[member].paraminfo[paramname]) + '\\n')\n",
    "                    #fp.write('\\n')\n",
    "                #fp.write('\\n')\n",
    "        \n",
    "        # This writes a csv file with basic information:\n",
    "        with open(psetsfile, 'w') as fp:\n",
    "            pset_writer = csv.writer(fp, delimiter=',')\n",
    "            \n",
    "            # first row points to default file\n",
    "            pset_writer.writerow([self._sampling_protocol+'0000', 'default', 'none', 'none'])\n",
    "            \n",
    "            # each subsequent row is an ensemble member\n",
    "            for member in self._members:\n",
    "                i = int(self._members[member].name)\n",
    "                paramkey = self._sampling_protocol+str(i+1).zfill(4)\n",
    "                \n",
    "                # check for min or max\n",
    "                if i%2 == 0:\n",
    "                    # min values\n",
    "                    perturblev = \"min\"\n",
    "                else:\n",
    "                    # max values\n",
    "                    perturblev = \"max\"\n",
    "                \n",
    "                # write the specific paramname and min/max for each member\n",
    "                # TO DO: code these flags more universally? see also Member class 'write' function\n",
    "                # TO DO: add perturbation value at least for single-values, TBD PFT-dependencies\n",
    "                for paramname in self._members[member].get_names():\n",
    "                    if paramname == ['cwd_fcel', 'cwd_flig']: \n",
    "                        if self._members[member].paraminfo['CWD'].value:\n",
    "                            paramval = self._members[member].paraminfo['CWD'].value\n",
    "                            pset_writer.writerow([paramkey, paramname, perturblev, paramval])\n",
    "                    elif paramname == ['q10_hr', 'froz_q10']:\n",
    "                        if self._members[member].paraminfo['Q10'].value:\n",
    "                            paramval = self._members[member].paraminfo['Q10'].value\n",
    "                            pset_writer.writerow([paramkey, paramname, perturblev, paramval])\n",
    "                    elif paramname == ['lf_fcel', 'lf_flab', 'lf_flig']:\n",
    "                        if self._members[member].paraminfo['LF'].value:\n",
    "                            paramval = self._members[member].paraminfo['LF'].value\n",
    "                            pset_writer.writerow([paramkey, paramname, perturblev, paramval])\n",
    "                    elif paramname == ['fr_fcel', 'fr_flab', 'fr_flig']:\n",
    "                        if self._members[member].paraminfo['FR'].value:\n",
    "                            paramval = self._members[member].paraminfo['FR'].value\n",
    "                            pset_writer.writerow([paramkey, paramname, perturblev, paramval])\n",
    "                    elif paramname == ['kc_nonmyc', 'kn_nonmyc', 'akc_active', 'akn_active', 'ekc_active', 'ekn_active']:\n",
    "                        if self._members[member].paraminfo['KCN'].value:\n",
    "                            paramval = self._members[member].paraminfo['KCN'].value\n",
    "                            pset_writer.writerow([paramkey, paramname, perturblev, paramval])\n",
    "                    elif self._members[member].paraminfo[paramname].value is not None:\n",
    "                        paramval = self._members[member].paraminfo[paramname].value\n",
    "                        pset_writer.writerow([paramkey, paramname, perturblev, paramval])\n",
    "        \n",
    "        print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Ensemble class with a given input csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in data from spreadsheet...Done\n",
      "Creating dictionary of parameter information and reading default values...Done\n",
      "Assigning min and max values...Done\n",
      "Creating ensemble with 400 members...Done\n"
     ]
    }
   ],
   "source": [
    "# Using this Ensemble class with the input csv file\n",
    "newEns = Ensemble('params.csv', 'OAAT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following includes checks and information associated with newEns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the params_dict - not associated with a specific member (none of the \"value\" entries are set)\n",
    "#newEns.params\n",
    "\n",
    "# get parameter names for a specific ensemble member\n",
    "#newEns.members[0].get_names()\n",
    "\n",
    "# print member/param info across all members\n",
    "#for member in newEns.members:\n",
    "#    print(newEns.members[member])\n",
    "#    print(newEns.members[member].paraminfo)\n",
    "    \n",
    "# print paraminfo for a given member\n",
    "#newEns.members[0].paraminfo\n",
    "\n",
    "# print paraminfo of a specific parameter for a given member\n",
    "#newEns.members[0].paraminfo['fff']\n",
    "\n",
    "# print paraminfo of a specific parameter for all members\n",
    "#for member in newEns.members:\n",
    "#    print(newEns.members[member].paraminfo['fff'])\n",
    "\n",
    "# print the \"value\" info of a specific parameter for all members\n",
    "#for member in newEns.members:\n",
    "#    print(newEns.members[member].paraminfo['fff'].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print list of parameters for a given member\n",
    "# dependencies will be grouped together as a list\n",
    "newEns.members[0].get_names()\n",
    "# get number of parameters\n",
    "len(newEns.members[0].get_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative way to print list of parameters\n",
    "# dependencies will be denoted by the flag\n",
    "#for param in newEns.members[0].paraminfo:\n",
    "#    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check the \"values\" across ensemble members\n",
    "# NOTE: this may print a LOT of output if the parameter list is long\n",
    "#for member in newEns.members:\n",
    "#    print(newEns.members[member])\n",
    "#    for param in newEns.members[member].paraminfo:\n",
    "#        print(param)\n",
    "#        print(newEns.members[member].paraminfo[param].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "# sanity check length of pft-specific values\n",
    "print(len(newEns.members[0].paraminfo['taulnir'].value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#newEns.members[0].paraminfo['taulnir'].value\n",
    "#newEns.members[0].paraminfo['taulnir'].default\n",
    "# when value is an array\n",
    "all(newEns.members[0].paraminfo['taulnir'].value == newEns.members[0].paraminfo['taulnir'].default)\n",
    "# logic to check for value array\n",
    "#type(newEns.members[0].paraminfo['taulnir'].value) == np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#float(newEns.members[18].paraminfo['displar'].value)\n",
    "#newEns.members[18].paraminfo['displar'].default.data[1:]\n",
    "# when value is a single number (but default is an array)\n",
    "# use indexing to skip first default value (non-veg)\n",
    "float(newEns.members[18].paraminfo['displar'].value) == all(newEns.members[18].paraminfo['displar'].default[1:])\n",
    "# logic to check for default array\n",
    "#type(newEns.members[18].paraminfo['displar'].default) == np.ma.core.MaskedArray and type(newEns.members[18].paraminfo['displar'].value) == str\n",
    "# !!corrected logic\n",
    "#type(newEns.members[18].paraminfo['displar'].value) == str and newEns.members[18].paraminfo['displar'].default.size > 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#float(newEns.members[24].paraminfo['csoilc'].value)\n",
    "#newEns.members[24].paraminfo['csoilc'].default\n",
    "# when value is a single number - false BFB test case\n",
    "float(newEns.members[24].paraminfo['csoilc'].value) == newEns.members[24].paraminfo['csoilc'].default\n",
    "# logic to check for single values\n",
    "#type(newEns.members[24].paraminfo['csoilc'].value) == str and newEns.members[24].paraminfo['csoilc'].default.size == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#float(newEns.members[29].paraminfo['a_coef'].value)\n",
    "#newEns.members[29].paraminfo['a_coef'].default\n",
    "# when value is a single number - true BFB test case\n",
    "float(newEns.members[29].paraminfo['a_coef'].value) == newEns.members[29].paraminfo['a_coef'].default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-170-8fa5d57c40a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnewEns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmembers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m44\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparaminfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'zetamaxstable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "# TO DO: namelist parameters do not have size attribute, how to identify with logic?\n",
    "newEns.members[44].paraminfo['zetamaxstable'].default.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out paramfiles and nl_mod files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing files to disk for each member...\n",
      "taulnir modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0001.nc\n",
      "taulnir modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0002.nc\n",
      "taulvis modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0003.nc\n",
      "taulvis modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0004.nc\n",
      "tausnir modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0005.nc\n",
      "tausnir modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0006.nc\n",
      "tausvis modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0007.nc\n",
      "tausvis modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0008.nc\n",
      "rholnir modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0009.nc\n",
      "rholnir modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0010.nc\n",
      "rholvis modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0011.nc\n",
      "rholvis modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0012.nc\n",
      "rhosnir modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0013.nc\n",
      "rhosnir modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0014.nc\n",
      "rhosvis modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0015.nc\n",
      "rhosvis modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0016.nc\n",
      "xl modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0017.nc\n",
      "xl modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0018.nc\n",
      "displar modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0019.nc\n",
      "displar modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0020.nc\n",
      "dleaf modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0021.nc\n",
      "dleaf modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0022.nc\n",
      "z0mr modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0023.nc\n",
      "z0mr modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0024.nc\n",
      "csoilc modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0025.nc\n",
      "csoilc modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0026.nc\n",
      "cv modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0027.nc\n",
      "cv modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0028.nc\n",
      "a_coef modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0029.nc\n",
      "a_coef skipped in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0030.nc\n",
      "a_exp skipped in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0031.nc\n",
      "a_exp modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0032.nc\n",
      "zlnd modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0033.nc\n",
      "zlnd modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0034.nc\n",
      "zsno modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0035.nc\n",
      "zsno modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0036.nc\n",
      "d_max modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0037.nc\n",
      "d_max modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0038.nc\n",
      "frac_sat_soil_dsl_init modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0039.nc\n",
      "frac_sat_soil_dsl_init modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0040.nc\n",
      "lai_dl skipped in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0041.nc\n",
      "lai_dl modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0042.nc\n",
      "z_dl modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0043.nc\n",
      "z_dl modified in /glade/scratch/kdagon/CLM5PPE/paramfiles/OAAT0044.nc\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-ec40189b6fc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnewEns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-159-9b5fd7d3fb2a>\u001b[0m in \u001b[0;36moutput_files\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmember\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_members\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_members\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampling_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-158-e861c5656c26>\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, sampling_protocol)\u001b[0m\n\u001b[1;32m    127\u001b[0m                             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                     \u001b[0;31m# logic if value is a single value but default is an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                     \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_paraminfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparamname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_paraminfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparamname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m                         \u001b[0;31m# start at index 1 in default to skip non-veg values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_paraminfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparamname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_paraminfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparamname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "newEns.output_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write out ensemble info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing out parameter info for the ensemble...Done\n"
     ]
    }
   ],
   "source": [
    "# Testing writing out ensemble info, need to provide a name for the Ensemble\n",
    "#newEns.save_psets('test0001') # 148 parameters on 8/25/20\n",
    "#newEns.save_psets('test0002') # 178 parameters on 10/9/20\n",
    "#newEns.save_psets('test0003') # 183 parameters on 10/9/20\n",
    "#newEns.save_psets('test0004') # 192 parameters on 10/14/20\n",
    "#newEns.save_psets('test0005') # testing CWD dependency on 10/21/20\n",
    "#newEns.save_psets('test0006') # testing all parameter dependencies on 10/21/20\n",
    "#newEns.save_psets('test0007') # 192 parameters including dependencies on 10/22/20\n",
    "#newEns.save_psets('test_miniens_20201102') # testing mini-ensemble (medlynslope and slatop) on 11/2/20\n",
    "#newEns.save_psets('test_miniens_20201211') # testing mini-ensemble (sand_pf and clay_pf) on 12/11/20\n",
    "#newEns.save_psets('test_bhs') # testing biomass heat storage params on 2/4/21\n",
    "#newEns.save_psets('test_miniens_20210222') # testing mini-ensemble (17 params) on 2/22/21\n",
    "#newEns.save_psets('20210408') # 400-member OAAT ensemble on 4/8/21\n",
    "newEns.save_psets('csv_testing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some notes on OAAT parameter perturbations:\n",
    "* don't currently have checks to see if min or max are equivalent to default value (in that case, don't change params files / don't make a namelist mod?) - precision/round-off errors could be important here\n",
    "* `rootprof_beta` has slighty different default values across variants, code currently assumes the same values applied across these secondary dims\n",
    "* for parameters that vary with PFT but only a single value is specified in the spreadsheet, that value will propogate across all PFTs (including index 0 = non-vegetated)\n",
    "* all current parameter dependencies (e.g., \"these three terms need to add up to 1\") are working, but solution could be cleaner and more universal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (work in progress) Define a class for converting numpy arrays to be JSON serializable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another option: Create a new dictionary converting numpy arrays to lists so they are serializable with JSON\n",
    "# But then they are not readable as numpy arrays after saving out the JSON\n",
    "        \n",
    "# This JSON hack method doesn't work because self._members is a dictionary of dictionaries\n",
    "#dumped = json.dumps(self._members, cls=NumpyEncoder)\n",
    "#with open(psetsfile, 'w') as fp:\n",
    "    #json.dump(dumped, fp)\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" \n",
    "    Special json encoder for numpy types\n",
    "    \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO: integrate this code above for LHC option\n",
    " * careful, each time you run LHC you get a new random draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sampling_protocol == 'LHC':\n",
    "    # define sample size (number of ensemble members)\n",
    "    nsamp = 10\n",
    "\n",
    "    # Generate the latin hypercube sample\n",
    "    lhd = lhs(nparam, samples=int(nsamp))\n",
    "    # lhd is a 2D array indexed by ensemble member x parameter\n",
    "    \n",
    "    # figure out how many pft-dependent params there are in this sample\n",
    "    npftparam = sum(params['min']=='pft')\n",
    "    \n",
    "    if npftparam>0:\n",
    "        # get dataframe index of first pft param\n",
    "        pftfirstind = params.index[params['min']=='pft'][0]\n",
    "        \n",
    "        # get number of pfts\n",
    "        npft = len(np.fromstring(params['pft_mins'][pftfirstind],dtype='float',sep=','))\n",
    "        \n",
    "        # set up numpy array to store pft-specific values\n",
    "        pft_array = np.nan*np.ones([npftparam,npft,nsamp])\n",
    "        \n",
    "        for j in range(npftparam):\n",
    "            # get the index for the current pft param\n",
    "            pftind = params.index[params['min']=='pft'][j]\n",
    "            \n",
    "            # get min values\n",
    "            min_pft_array = np.fromstring(params['pft_mins'][pftind],dtype='float',sep=',')\n",
    "            # max values\n",
    "            max_pft_array = np.fromstring(params['pft_maxs'][pftind],dtype='float',sep=',')\n",
    "            \n",
    "            # loop over samples and calculate parameter values for each pft\n",
    "            for i in range(nsamp):\n",
    "                pft_array[j,:,i] = (max_pft_array - min_pft_array)*lhd[i,pftind] + min_pft_array\n",
    "                # can't store pft_array as a pandas dataframe because it's 3D\n",
    "                # unless there is some alternate way to store this data?\n",
    "    \n",
    "    # initialize min/max arrays - for params without pft-variation\n",
    "    min_array = np.nan*np.ones(nparam)\n",
    "    max_array = np.nan*np.ones(nparam)\n",
    "    \n",
    "    # generate arrays with min and max values\n",
    "    for i in range(nparam):\n",
    "        if params['min'].values[i]=='pft':\n",
    "            # TO DO: what's a good placeholder, to denote need to reference pft_array?\n",
    "            # numpy doesn't like assigning a string to an existing array of floats\n",
    "            # for now, just print a message\n",
    "            print('skipping '+params['name'].values[i]+'...this parameter varies with PFT')\n",
    "            \n",
    "            # Numpy doesn't like assigning an array to a single index in an existing array\n",
    "            # The problem is still that I'm declaring min_array before trying to assign values\n",
    "            # If I could build it all at once, numpy would allow for nested arrays\n",
    "            #min_array[i] = np.fromstring(params['pft_mins'].values[i],dtype='float',sep=',')\n",
    "            #max_array[i] = np.fromstring(params['pft_maxs'].values[i],dtype='float',sep=',')\n",
    "        else:\n",
    "            # assign min/max values\n",
    "            min_array[i] = float(params['min'].values[i])\n",
    "            max_array[i] = float(params['max'].values[i])\n",
    "            \n",
    "    # calculate parameter values; skip pft params (NaNs in min/max arrays)\n",
    "    param_array = (max_array - min_array)*lhd + min_array\n",
    "\n",
    "# store psets in a pandas dataframe\n",
    "#psets = pd.DataFrame(data=param_array, index=None, columns=params['name'])\n",
    "#psets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda-analysis)",
   "language": "python",
   "name": "analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
