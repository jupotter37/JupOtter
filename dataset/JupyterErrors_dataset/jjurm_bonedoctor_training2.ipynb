{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "do5klOVqEsYa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b0f28c3-0ec5-4ad4-a084-1ad6bebe9e3d"
      },
      "cell_type": "code",
      "source": [
        "#make sure GPU available\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z4hekRbKEu7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6e4bd7f3-e26d-49f5-8bce-091581fbd95f"
      },
      "cell_type": "code",
      "source": [
        "# import modules required\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import numpy\n",
        "import csv\n",
        "import imageio\n",
        "import numpy as np\n",
        "import cv2\n",
        "import math\n",
        "from keras import backend as K\n",
        "import zipfile\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "UeuL4xBfEvVl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "outputId": "017955ba-3ce2-46d0-b6bf-921a7f42fd7d"
      },
      "cell_type": "code",
      "source": [
        "# download and extract MURA dataset\n",
        "!wget \"https://cs.stanford.edu/group/mlgroup/MURA-v1.1.zip\"\n",
        "with zipfile.ZipFile(\"MURA-v1.1.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\".\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-03 10:24:46--  https://cs.stanford.edu/group/mlgroup/MURA-v1.1.zip\n",
            "Resolving cs.stanford.edu (cs.stanford.edu)... 171.64.64.64\n",
            "Connecting to cs.stanford.edu (cs.stanford.edu)|171.64.64.64|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3380245855 (3.1G) [application/zip]\n",
            "Saving to: ‘MURA-v1.1.zip.3’\n",
            "\n",
            "MURA-v1.1.zip.3     100%[===================>]   3.15G  90.8MB/s    in 35s     \n",
            "\n",
            "2019-03-03 10:25:21 (92.1 MB/s) - ‘MURA-v1.1.zip.3’ saved [3380245855/3380245855]\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-173aa297ab5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget \"https://cs.stanford.edu/group/mlgroup/MURA-v1.1.zip\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MURA-v1.1.zip\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1198\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ARU3ezGMEvXt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# removes filename from a path\n",
        "def remove_filename(p):\n",
        "    output = \"\"\n",
        "    file_gone = False\n",
        "    for c in reversed(p):\n",
        "        if file_gone:\n",
        "            output += c\n",
        "        else:\n",
        "            if c == '/':\n",
        "                output += c\n",
        "                file_gone = True\n",
        "    return output[::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jw7w9z3eEvaC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "b43ef6ff-f1d3-4d3d-d719-0fdbcce01717"
      },
      "cell_type": "code",
      "source": [
        "# build model and initialise with imagenet pretrained weights\n",
        "densenet = DenseNet169(include_top=False, weights='imagenet', input_tensor=None, input_shape=(320,320,3), pooling=None, classes=False)\n",
        "model = Sequential()\n",
        "model.add(densenet)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "51879936/51877672 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NnpJ2T87EvcI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# compile model\n",
        "model.compile(optimizer=Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MWoXgSY5Eveg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# gets images, labels and number of normal/abnormal images for a bodypart\n",
        "def get_training_data(bodypart):\n",
        "  label_dict = {}\n",
        "  studies = open(\"MURA-v1.1/train_labeled_studies.csv\", newline='')\n",
        "  for study in csv.reader(studies):\n",
        "    label_dict[study[0]] = study[1]\n",
        "  normal = 0\n",
        "  abnormal = 0\n",
        "  paths = open(\"MURA-v1.1/train_image_paths.csv\", newline='')\n",
        "  images = []\n",
        "  labels = []\n",
        "  for path in csv.reader(paths):\n",
        "    if bodypart.upper() in path[0]:\n",
        "      images.append(imageio.imread(path[0]))\n",
        "      label = int(label_dict[remove_filename(path[0])])\n",
        "      labels.append(label)\n",
        "      if label == 1:\n",
        "        abnormal += 1\n",
        "      else:\n",
        "        normal += 1\n",
        "  for i in range(len(images)):\n",
        "    img = images[i]\n",
        "    resized_img = cv2.resize(img, (320, 320))\n",
        "    if len(img.shape) == 2:\n",
        "        resized_img = np.dstack([resized_img, resized_img, resized_img])\n",
        "    images[i] = resized_img\n",
        "  for i in range(len(images)):\n",
        "    img = images[i]\n",
        "    images[i] = img[np.newaxis, ...]\n",
        "  images_tensor = np.concatenate(images, axis=0)\n",
        "  return (images_tensor, labels, normal, abnormal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P2j9kY6lEvgb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# training function for a particular bodypart\n",
        "def train_bodypart(bodypart):\n",
        "  # get data\n",
        "  training_images, training_labels, normal, abnormal = get_training_data(bodypart)\n",
        "  normal_fraction = normal / (abnormal + normal)\n",
        "  abnormal_fraction = abnormal / (abnormal + normal)\n",
        "  # fit model and evaluate on validation dataset\n",
        "  model.fit(x=training_images, y=training_labels, class_weight={0: abnormal_fraction, 1: normal_fraction}, epochs=3, batch_size=11)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NjCLM3HSjRmN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "for i in range(50):\n",
        "  for bodypart in ['elbow', 'forearm', 'hand', 'wrist', 'humerus', 'finger', 'shoulder']:\n",
        "    train_bodypart(bodypart)\n",
        "  filename = 'my_model_weights' + str(i) + '.h5'\n",
        "  model.save_weights(filename)\n",
        "  files.download(filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WINTKPzKq0qj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}