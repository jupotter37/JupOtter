{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"images/dans-small.png\"/>\n",
    "<img align=\"right\" src=\"images/tf-small.png\"/>\n",
    "<img align=\"right\" src=\"images/etcbc.png\"/>\n",
    "\n",
    "\n",
    "![mql](images/emdros.png)\n",
    "\n",
    "# TF from MQL\n",
    "\n",
    "This notebook can read an\n",
    "[MQL](https://emdros.org/mql.html)\n",
    "dump of a version of the [BHSA](https://github.com/ETCBC/bhsa) Hebrew Text Database\n",
    "and transform it in a Text-Fabric\n",
    "[Text-Fabric](https://github.com/Dans-labs/text-fabric)\n",
    "resource.\n",
    "\n",
    "## Discussion\n",
    "\n",
    "The principled way of going about such a conversion is to import the MQL source into\n",
    "an [Emdros](https://emdros.org) database, and use it to retrieve objects and features from there.\n",
    "\n",
    "Because the syntax of an MQL file leaves some freedom, it is error prone to do a text-to-text conversion from\n",
    "MQL to something else.\n",
    "\n",
    "Yet this is what we do, the error-prone thing. We then avoid installing and configuring and managing Emdros, MYSQL/SQLite3.\n",
    "Aside the upfront work to get this going, the going after that would also be much slower.\n",
    "\n",
    "So here you are, a smallish script to do an awful lot of work, mostly correct, if careful used.\n",
    "\n",
    "# Caveat\n",
    "\n",
    "This notebook makes use of a new feature of text-fabric, first present in 2.3.12.\n",
    "Make sure to upgrade first.\n",
    "\n",
    "```sudo -H pip3 install --upgrade text-fabric\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "from shutil import rmtree\n",
    "from tf.fabric import Fabric\n",
    "from tf.core.helpers import formatMeta\n",
    "from tf.convert.mql import importMQL\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "See [operation](https://github.com/ETCBC/pipeline/blob/master/README.md#operation)\n",
    "for how to run this script in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"SCRIPT\" not in locals():\n",
    "    SCRIPT = False\n",
    "    FORCE = True\n",
    "    CORE_NAME = \"bhsa\"\n",
    "    VERSION = \"2021\"\n",
    "    RENAME = (\n",
    "        (\"g_suffix\", \"trailer\"),\n",
    "        (\"g_suffix_utf8\", \"trailer_utf8\"),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def stop(good=False):\n",
    "    if SCRIPT:\n",
    "        sys.exit(0 if good else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the context: source file and target directories\n",
    "\n",
    "The conversion is executed in an environment of directories, so that sources, temp files and\n",
    "results are in convenient places and do not have to be shifted around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "repoBase = os.path.expanduser(\"~/github/etcbc\")\n",
    "thisRepo = \"{}/{}\".format(repoBase, CORE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisSource = \"{}/source/{}\".format(thisRepo, VERSION)\n",
    "mqlzFile = \"{}/{}.mql.bz2\".format(thisSource, CORE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisTemp = \"{}/_temp/{}\".format(thisRepo, VERSION)\n",
    "thisTempSource = \"{}/source\".format(thisTemp)\n",
    "mqlFile = \"{}/{}.mql\".format(thisTempSource, CORE_NAME)\n",
    "thisTempTf = \"{}/tf\".format(thisTemp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "thisTf = \"{}/tf/{}\".format(thisRepo, VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test\n",
    "\n",
    "Check whether this conversion is needed in the first place.\n",
    "Only when run as a script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    testFile = \"{}/.tf/otype.tfx\".format(thisTf)\n",
    "    (good, work) = utils.mustRun(\n",
    "        mqlzFile, \"{}/.tf/otype.tfx\".format(thisTf), force=FORCE\n",
    "    )\n",
    "    if not good:\n",
    "        stop(good=False)\n",
    "    if not work:\n",
    "        stop(good=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Settings\n",
    "\n",
    "We add some custom information here.\n",
    "\n",
    "* the MQL object type that corresponds to the Text-Fabric slot type, typically `word`;\n",
    "* a piece of metadata that will go into every feature; the time will be added automatically\n",
    "* suitable text formats for the `otext` feature of TF.\n",
    "\n",
    "The `otext` feature is very sensitive to what is available in the source MQL.\n",
    "It needs to be configured here.\n",
    "We save the configs we need per source and version.\n",
    "And we define a stripped down default version to start with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "slotType = \"word\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "genericMetaPath = f\"{thisRepo}/yaml/generic.yaml\"\n",
    "coreMetaPath = f\"{thisRepo}/yaml/core.yaml\"\n",
    "\n",
    "with open(genericMetaPath) as fh:\n",
    "    genericMeta = yaml.load(fh, Loader=yaml.FullLoader)\n",
    "    genericMeta[\"version\"] = VERSION\n",
    "with open(coreMetaPath) as fh:\n",
    "    coreMeta = formatMeta(yaml.load(fh, Loader=yaml.FullLoader))\n",
    "    \n",
    "featureMetaData = {\"\": genericMeta, **coreMeta}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "oText = {\n",
    "    \"\": {\n",
    "        \"\": \"\"\"\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "@fmt:text-orig-full={g_word_utf8}{g_suffix_utf8}\n",
    "\"\"\",\n",
    "    },\n",
    "    \"_temp\": \"\"\"\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "\"\"\",  # noqa W291\n",
    "    \"2021\": \"\"\"\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "\"\"\",  # noqa W291\n",
    "    \"2017\": \"\"\"\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "\"\"\",  # noqa W291\n",
    "    \"2016\": \"\"\"\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "\"\"\",  # noqa W291\n",
    "    \"4b\": \"\"\"\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word} \n",
    "@fmt:text-trans-full-ketiv={g_word} \n",
    "@fmt:text-trans-plain={g_cons} \n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "\"\"\",  # noqa W291\n",
    "    \"4\": \"\"\"\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-full-ketiv={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word} \n",
    "@fmt:text-trans-full-ketiv={g_word} \n",
    "@fmt:text-trans-plain={g_cons} \n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "\"\"\",  # noqa W291\n",
    "    \"3\": \"\"\"\n",
    "@fmt:lex-orig-full={graphical_lexeme_utf8} \n",
    "@fmt:lex-orig-plain={lexeme_utf8} \n",
    "@fmt:lex-trans-full={graphical_lexeme} \n",
    "@fmt:lex-trans-plain={lexeme} \n",
    "@fmt:text-orig-full={text}{suffix}\n",
    "@fmt:text-orig-plain={surface_consonants_utf8}{suffix}\n",
    "@fmt:text-trans-full={graphical_word} \n",
    "@fmt:text-trans-plain={surface_consonants} \n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "\"\"\",  # noqa W291\n",
    "    \"c\": \"\"\"\n",
    "@fmt:lex-orig-full={g_lex_utf8} \n",
    "@fmt:lex-orig-plain={lex_utf8} \n",
    "@fmt:lex-trans-full={g_lex} \n",
    "@fmt:lex-trans-plain={lex} \n",
    "@fmt:text-orig-full={g_word_utf8}{trailer_utf8}\n",
    "@fmt:text-orig-plain={g_cons_utf8}{trailer_utf8}\n",
    "@fmt:text-trans-full={g_word}{trailer}\n",
    "@fmt:text-trans-plain={g_cons}{trailer}\n",
    "@sectionFeatures=book,chapter,verse\n",
    "@sectionTypes=book,chapter,verse\n",
    "\"\"\",  # noqa W291\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function selects the proper `otext` material, falling back on a default if nothing\n",
    "appropriate has been specified in `otext`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisOtext = oText.get(VERSION, oText[\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       0.00s INFO: otext feature information found\n",
      "|       0.00s \tfmt:lex-orig-full    = \"{g_lex_utf8} \"\n",
      "|       0.00s \tfmt:lex-orig-plain   = \"{lex_utf8} \"\n",
      "|       0.00s \tfmt:lex-trans-full   = \"{g_lex} \"\n",
      "|       0.00s \tfmt:lex-trans-plain  = \"{lex} \"\n",
      "|       0.00s \tfmt:text-orig-full   = \"{g_word_utf8}{trailer_utf8}\"\n",
      "|       0.00s \tfmt:text-orig-plain  = \"{g_cons_utf8}{trailer_utf8}\"\n",
      "|       0.00s \tfmt:text-trans-full  = \"{g_word}{trailer}\"\n",
      "|       0.00s \tfmt:text-trans-plain = \"{g_cons}{trailer}\"\n",
      "|       0.00s \tsectionFeatures      = \"book,chapter,verse\"\n",
      "|       0.00s \tsectionTypes         = \"book,chapter,verse\"\n"
     ]
    }
   ],
   "source": [
    "if thisOtext is oText[\"\"]:\n",
    "    utils.caption(\n",
    "        0, \"WARNING: no otext feature info provided, using a meager default value\"\n",
    "    )\n",
    "    otextInfo = {}\n",
    "else:\n",
    "    utils.caption(0, \"INFO: otext feature information found\")\n",
    "    otextInfo = dict(\n",
    "        line[1:].split(\"=\", 1) for line in thisOtext.strip(\"\\n\").split(\"\\n\")\n",
    "    )\n",
    "    for x in sorted(otextInfo.items()):\n",
    "        utils.caption(0, '\\t{:<20} = \"{}\"'.format(*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "The program has several stages:\n",
    "\n",
    "1. **prepare** the source (utils.bunzip if needed)\n",
    "1. **convert** convert the MQL file into a text-fabric dataset\n",
    "1. **differences** (informational)\n",
    "1. **deliver** the TF data at its destination directory\n",
    "1. **compile** all TF features to binary format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare\n",
    "\n",
    "Check the source, utils.bunzip it if needed, empty the result directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(thisTempSource):\n",
    "    os.makedirs(thisTempSource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|       4.33s bunzipping /Users/me/github/etcbc/bhsa/source/2021/bhsa.mql.bz2 ...\n",
      "|       4.33s \tNOTE: Using existing unzipped file which is newer than bzipped one\n",
      "|       4.33s Done\n"
     ]
    }
   ],
   "source": [
    "utils.caption(0, \"bunzipping {} ...\".format(mqlzFile))\n",
    "utils.bunzip(mqlzFile, mqlFile)\n",
    "utils.caption(0, \"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if os.path.exists(thisTempTf):\n",
    "    rmtree(thisTempTf)\n",
    "os.makedirs(thisTempTf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MQL to Text-Fabric\n",
    "Transform the collected information in feature-like data-structures, and write it all\n",
    "out to `.tf` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 11.2.3\n",
      "75 features found and 0 ignored\n",
      "  0.00s Parsing mql source ...\n",
      "  0.00s \t\tenum boolean_t\n",
      "  0.00s \t\tenum phrase_determination_t\n",
      "  0.00s \t\tenum language_t\n",
      "  0.00s \t\tenum book_name_t\n",
      "  0.00s \t\tenum lexical_set_t\n",
      "  0.00s \t\tenum verbal_stem_t\n",
      "  0.00s \t\tenum verbal_tense_t\n",
      "  0.00s \t\tenum person_t\n",
      "  0.00s \t\tenum number_t\n",
      "  0.01s \t\tenum gender_t\n",
      "  0.01s \t\tenum state_t\n",
      "  0.01s \t\tenum part_of_speech_t\n",
      "  0.01s \t\tenum phrase_type_t\n",
      "  0.01s \t\tenum phrase_atom_relation_t\n",
      "  0.01s \t\tenum phrase_relation_t\n",
      "  0.01s \t\tenum phrase_atom_unit_distance_to_mother_t\n",
      "  0.01s \t\tenum subphrase_relation_t\n",
      "  0.01s \t\tenum subphrase_mother_object_type_t\n",
      "  0.01s \t\tenum phrase_function_t\n",
      "  0.01s \t\tenum clause_atom_type_t\n",
      "  0.01s \t\tenum clause_type_t\n",
      "  0.01s \t\tenum clause_kind_t\n",
      "  0.01s \t\tenum clause_constituent_relation_t\n",
      "  0.01s \t\tenum clause_constituent_mother_object_type_t\n",
      "  0.01s \t\tenum clause_constituent_unit_distance_to_mother_t\n",
      "  0.01s \t\totype word\n",
      "  0.01s \t\t\tfeature number (int) =def= 0 : node\n",
      "  0.01s \t\t\tfeature lexeme_count (int) =def= 0 : node\n",
      "  0.01s \t\t\tfeature kq_hybrid (str) =def=  : node\n",
      "  0.01s \t\t\tfeature qere_utf8 (str) =def=  : node\n",
      "  0.01s \t\t\tfeature qere (str) =def=  : node\n",
      "  0.01s \t\t\tfeature kq_hybrid_utf8 (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_word (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_word_utf8 (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_cons_utf8 (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_cons (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_suffix (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_suffix_utf8 (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_pfm (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_pfm_utf8 (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_vbs (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_vbs_utf8 (str) =def=  : node\n",
      "  0.01s \t\t\tfeature lex (str) =def=  : node\n",
      "  0.01s \t\t\tfeature lex_utf8 (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_lex (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_lex_utf8 (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_voc_lex (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_voc_lex_utf8 (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_prs_utf8 (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_prs (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_vbe (str) =def=  : node\n",
      "  0.01s \t\t\tfeature g_uvf_utf8 (str) =def=  : node\n",
      "  0.02s \t\t\tfeature g_uvf (str) =def=  : node\n",
      "  0.02s \t\t\tfeature g_vbe_utf8 (str) =def=  : node\n",
      "  0.02s \t\t\tfeature g_nme (str) =def=  : node\n",
      "  0.02s \t\t\tfeature g_nme_utf8 (str) =def=  : node\n",
      "  0.02s \t\t\tfeature nme (str) =def=  : node\n",
      "  0.02s \t\t\tfeature distributional_parent (str) =def= 0 : edge\n",
      "  0.02s \t\t\tfeature functional_parent (str) =def= 0 : edge\n",
      "  0.02s \t\t\tfeature prs (str) =def=  : node\n",
      "  0.02s \t\t\tfeature vbe (str) =def=  : node\n",
      "  0.02s \t\t\tfeature vbs (str) =def=  : node\n",
      "  0.02s \t\t\tfeature pfm (str) =def=  : node\n",
      "  0.02s \t\t\tfeature uvf (str) =def=  : node\n",
      "  0.02s \t\t\tfeature language (str) =def= Hebrew : node\n",
      "  0.02s \t\t\tfeature ls (str) =def= none : node\n",
      "  0.02s \t\t\tfeature vs (str) =def= NA : node\n",
      "  0.02s \t\t\tfeature vt (str) =def= NA : node\n",
      "  0.02s \t\t\tfeature prs_ps (str) =def= NA : node\n",
      "  0.02s \t\t\tfeature ps (str) =def= NA : node\n",
      "  0.02s \t\t\tfeature suffix_person (str) =def= NA : node\n",
      "  0.02s \t\t\tfeature prs_nu (str) =def= NA : node\n",
      "  0.02s \t\t\tfeature nu (str) =def= NA : node\n",
      "  0.02s \t\t\tfeature suffix_number (str) =def= NA : node\n",
      "  0.02s \t\t\tfeature gn (str) =def= NA : node\n",
      "  0.02s \t\t\tfeature suffix_gender (str) =def= NA : node\n",
      "  0.02s \t\t\tfeature prs_gn (str) =def= NA : node\n",
      "  0.02s \t\t\tfeature st (str) =def= NA : node\n",
      "  0.02s \t\t\tfeature sp (str) =def= art : node\n",
      "  0.02s \t\t\tfeature pdp (str) =def= art : node\n",
      "  0.02s \t\totype clause_atom\n",
      "  0.02s \t\t\tfeature tab (int) =def= 0 : node\n",
      "  0.02s \t\t\tfeature code (int) =def= 0 : node\n",
      "  0.02s \t\t\tfeature dist (int) =def= 0 : node\n",
      "  0.02s \t\t\tfeature number (int) =def= 0 : node\n",
      "  0.02s \t\t\tfeature distributional_parent (str) =def= 0 : edge\n",
      "  0.02s \t\t\tfeature mother (str) =def= 0 : edge\n",
      "  0.02s \t\t\tfeature functional_parent (str) =def= 0 : edge\n",
      "  0.02s \t\t\tfeature is_root (str) =def= false : node\n",
      "  0.02s \t\t\tfeature typ (str) =def= Unkn : node\n",
      "  0.02s \t\totype sentence_atom\n",
      "  0.02s \t\t\tfeature number (int) =def= 0 : node\n",
      "  0.02s \t\t\tfeature functional_parent (str) =def= 0 : edge\n",
      "  0.02s \t\totype subphrase\n",
      "  0.02s \t\t\tfeature dist (int) =def= 0 : node\n",
      "  0.03s \t\t\tfeature mother (str) =def= 0 : edge\n",
      "  0.03s \t\t\tfeature rela (str) =def= NA : node\n",
      "  0.03s \t\t\tfeature mother_object_type (str) =def= NA : node\n",
      "  0.03s \t\totype phrase\n",
      "  0.03s \t\t\tfeature dist (int) =def= 0 : node\n",
      "  0.03s \t\t\tfeature number (int) =def= 0 : node\n",
      "  0.03s \t\t\tfeature functional_parent (str) =def= 0 : edge\n",
      "  0.03s \t\t\tfeature mother (str) =def= 0 : edge\n",
      "  0.03s \t\t\tfeature det (str) =def= NA : node\n",
      "  0.03s \t\t\tfeature typ (str) =def= VP : node\n",
      "  0.03s \t\t\tfeature rela (str) =def= NA : node\n",
      "  0.03s \t\t\tfeature dist_unit (str) =def= clause_atoms : node\n",
      "  0.03s \t\t\tfeature function (str) =def= Unkn : node\n",
      "  0.03s \t\totype sentence\n",
      "  0.03s \t\t\tfeature number (int) =def= 0 : node\n",
      "  0.03s \t\totype chapter\n",
      "  0.03s \t\t\tfeature chapter (int) =def= 0 : node\n",
      "  0.03s \t\t\tfeature book (str) =def= Genesis : node\n",
      "  0.03s \t\totype book\n",
      "  0.03s \t\t\tfeature book (str) =def= Genesis : node\n",
      "  0.03s \t\totype clause\n",
      "  0.03s \t\t\tfeature dist (int) =def= 0 : node\n",
      "  0.03s \t\t\tfeature number (int) =def= 0 : node\n",
      "  0.03s \t\t\tfeature domain (str) =def=  : node\n",
      "  0.03s \t\t\tfeature mother (str) =def= 0 : edge\n",
      "  0.03s \t\t\tfeature functional_parent (str) =def= 0 : edge\n",
      "  0.03s \t\t\tfeature txt (str) =def=  : node\n",
      "  0.03s \t\t\tfeature typ (str) =def= Unkn : node\n",
      "  0.03s \t\t\tfeature kind (str) =def= unknown : node\n",
      "  0.03s \t\t\tfeature rela (str) =def= NA : node\n",
      "  0.03s \t\t\tfeature mother_object_type (str) =def= clause : node\n",
      "  0.03s \t\t\tfeature dist_unit (str) =def= clause_atoms : node\n",
      "  0.03s \t\totype half_verse\n",
      "  0.03s \t\t\tfeature label (str) =def=  : node\n",
      "  0.03s \t\totype verse\n",
      "  0.03s \t\t\tfeature verse (int) =def= 0 : node\n",
      "  0.03s \t\t\tfeature chapter (int) =def= 0 : node\n",
      "  0.03s \t\t\tfeature label (str) =def=  : node\n",
      "  0.03s \t\t\tfeature book (str) =def= Genesis : node\n",
      "  0.03s \t\totype phrase_atom\n",
      "  0.03s \t\t\tfeature number (int) =def= 0 : node\n",
      "  0.03s \t\t\tfeature dist (int) =def= 0 : node\n",
      "  0.03s \t\t\tfeature distributional_parent (str) =def= 0 : edge\n",
      "  0.03s \t\t\tfeature mother (str) =def= 0 : edge\n",
      "  0.03s \t\t\tfeature functional_parent (str) =def= 0 : edge\n",
      "  0.04s \t\t\tfeature det (str) =def= NA : node\n",
      "  0.04s \t\t\tfeature typ (str) =def= VP : node\n",
      "  0.04s \t\t\tfeature rela (str) =def= NA : node\n",
      "  0.04s \t\t\tfeature dist_unit (str) =def= clause_atoms : node\n",
      "  0.04s \t\tobjects in word\n",
      "  1.61s \tline   1000000\n",
      "  3.22s \tline   2000000\n",
      "  4.69s \t\tobjects in word\n",
      "  4.85s \tline   3000000\n",
      "  6.48s \tline   4000000\n",
      "  8.11s \tline   5000000\n",
      "  9.44s \t\tobjects in word\n",
      "  9.77s \tline   6000000\n",
      "    11s \tline   7000000\n",
      "    13s \tline   8000000\n",
      "    14s \t\tobjects in word\n",
      "    15s \tline   9000000\n",
      "    16s \tline  10000000\n",
      "    18s \tline  11000000\n",
      "    19s \t\tobjects in word\n",
      "    20s \tline  12000000\n",
      "    21s \tline  13000000\n",
      "    23s \tline  14000000\n",
      "    24s \t\tobjects in word\n",
      "    24s \tline  15000000\n",
      "    26s \tline  16000000\n",
      "    27s \tline  17000000\n",
      "    28s \t\tobjects in word\n",
      "    29s \tline  18000000\n",
      "    31s \tline  19000000\n",
      "    33s \tline  20000000\n",
      "    33s \t\tobjects in word\n",
      "    34s \tline  21000000\n",
      "    36s \tline  22000000\n",
      "    37s \tline  23000000\n",
      "    38s \t\tobjects in word\n",
      "    39s \tline  24000000\n",
      "    40s \t\tobjects in clause_atom\n",
      "    41s \tline  25000000\n",
      "    41s \t\tobjects in clause_atom\n",
      "    42s \t\tobjects in sentence_atom\n",
      "    42s \tline  26000000\n",
      "    42s \t\tobjects in sentence_atom\n",
      "    43s \t\tobjects in subphrase\n",
      "    43s \t\tobjects in subphrase\n",
      "    43s \tline  27000000\n",
      "    43s \t\tobjects in subphrase\n",
      "    43s \t\tobjects in phrase\n",
      "    45s \t\tobjects in phrase\n",
      "    45s \tline  28000000\n",
      "    45s \t\tobjects in phrase\n",
      "    46s \tline  29000000\n",
      "    46s \t\tobjects in phrase\n",
      "    47s \t\tobjects in phrase\n",
      "    47s \tline  30000000\n",
      "    48s \t\tobjects in phrase\n",
      "    48s \t\tobjects in sentence\n",
      "    48s \t\tobjects in sentence\n",
      "    48s \t\tobjects in chapter\n",
      "    48s \t\tobjects in book\n",
      "    48s \t\tobjects in clause\n",
      "    48s \tline  31000000\n",
      "    49s \t\tobjects in clause\n",
      "    50s \tline  32000000\n",
      "    50s \t\tobjects in half_verse\n",
      "    51s \t\tobjects in verse\n",
      "    51s \t\tobjects in phrase_atom\n",
      "    51s \tline  33000000\n",
      "    52s \t\tobjects in phrase_atom\n",
      "    52s \t\tobjects in phrase_atom\n",
      "    52s \tline  34000000\n",
      "    53s \t\tobjects in phrase_atom\n",
      "    53s \tline  35000000\n",
      "    54s \t\tobjects in phrase_atom\n",
      "    54s \t\tobjects in phrase_atom\n",
      "    55s \tline  36000000\n",
      "    55s 36047659 lines parsed\n",
      "    55s 426590 objects of type word\n",
      "    55s 90704 objects of type clause_atom\n",
      "    55s 64514 objects of type sentence_atom\n",
      "    55s 113850 objects of type subphrase\n",
      "    55s 253203 objects of type phrase\n",
      "    55s 63717 objects of type sentence\n",
      "    55s 929 objects of type chapter\n",
      "    55s 39 objects of type book\n",
      "    55s 88131 objects of type clause\n",
      "    55s 45179 objects of type half_verse\n",
      "    55s 23213 objects of type verse\n",
      "    55s 267532 objects of type phrase_atom\n",
      "    55s Making TF data ...\n",
      "    55s Monad - idd mapping ...\n",
      "    56s Removing holes in the monad sequence\n",
      "    56s maxSlot=426590\n",
      "    56s Node mapping and otype ...\n",
      "    56s oslots ...\n",
      "    58s metadata ...\n",
      "    58s features ...\n",
      "    58s \tfeatures from words\n",
      "    59s \t   100000 words\n",
      " 1m 00s \t   200000 words\n",
      " 1m 01s \t   300000 words\n",
      " 1m 03s \t   400000 words\n",
      " 1m 04s \t   426590 words\n",
      " 1m 04s \tfeatures from books\n",
      " 1m 04s \t       39 books\n",
      " 1m 04s \tfeatures from chapters\n",
      " 1m 04s \t      929 chapters\n",
      " 1m 04s \tfeatures from clauses\n",
      " 1m 04s \t    88131 clauses\n",
      " 1m 04s \tfeatures from clause_atoms\n",
      " 1m 04s \t    90704 clause_atoms\n",
      " 1m 04s \tfeatures from half_verses\n",
      " 1m 04s \t    45179 half_verses\n",
      " 1m 04s \tfeatures from phrases\n",
      " 1m 04s \t   100000 phrases\n",
      " 1m 05s \t   200000 phrases\n",
      " 1m 05s \t   253203 phrases\n",
      " 1m 05s \tfeatures from phrase_atoms\n",
      " 1m 05s \t   100000 phrase_atoms\n",
      " 1m 07s \t   200000 phrase_atoms\n",
      " 1m 07s \t   267532 phrase_atoms\n",
      " 1m 07s \tfeatures from sentences\n",
      " 1m 07s \t    63717 sentences\n",
      " 1m 07s \tfeatures from sentence_atoms\n",
      " 1m 07s \t    64514 sentence_atoms\n",
      " 1m 07s \tfeatures from subphrases\n",
      " 1m 07s \t   100000 subphrases\n",
      " 1m 07s \t   113850 subphrases\n",
      " 1m 07s \tfeatures from verses\n",
      " 1m 07s \t    23213 verses\n",
      "  0.00s Exporting 70 node and 4 edge and 1 config features to /Users/me/github/etcbc/bhsa/_temp/2021/tf:\n",
      "  0.00s VALIDATING oslots feature\n",
      "  0.06s VALIDATING oslots feature\n",
      "  0.06s maxSlot=     426590\n",
      "  0.06s maxNode=    1437601\n",
      "  0.13s OK: oslots is valid\n",
      "   |     0.01s T book                 to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.01s T chapter              to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.04s T code                 to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.23s T det                  to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.34s T dist                 to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.27s T dist_unit            to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.04s T domain               to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.11s T function             to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T g_cons               to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T g_cons_utf8          to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.24s T g_lex                to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T g_lex_utf8           to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.19s T g_nme                to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.20s T g_nme_utf8           to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.17s T g_pfm                to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.17s T g_pfm_utf8           to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.17s T g_prs                to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.18s T g_prs_utf8           to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.18s T g_suffix             to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.19s T g_suffix_utf8        to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.16s T g_uvf                to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.16s T g_uvf_utf8           to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.17s T g_vbe                to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.17s T g_vbe_utf8           to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.17s T g_vbs                to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.17s T g_vbs_utf8           to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.24s T g_voc_lex            to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T g_voc_lex_utf8       to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.24s T g_word               to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.23s T g_word_utf8          to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.21s T gn                   to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.04s T is_root              to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.04s T kind                 to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.16s T kq_hybrid            to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.16s T kq_hybrid_utf8       to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.03s T label                to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.23s T language             to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T lex                  to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T lex_utf8             to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.23s T lexeme_count         to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.23s T ls                   to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.09s T mother_object_type   to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.21s T nme                  to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T nu                   to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.56s T number               to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.14s T otype                to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.23s T pdp                  to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T pfm                  to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.23s T prs                  to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T prs_gn               to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T prs_nu               to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T prs_ps               to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T ps                   to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.16s T qere                 to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.16s T qere_utf8            to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.31s T rela                 to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.23s T sp                   to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.21s T st                   to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T suffix_gender        to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T suffix_number        to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T suffix_person        to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.04s T tab                  to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.04s T txt                  to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.30s T typ                  to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T uvf                  to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T vbe                  to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T vbs                  to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.01s T verse                to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T vs                   to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.22s T vt                   to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.75s T distributional_parent to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     1.14s T functional_parent    to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.18s T mother               to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     1.17s T oslots               to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "   |     0.00s M otext                to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n",
      "    16s Exported 70 node features and 4 edge features and 1 config features to /Users/me/github/etcbc/bhsa/_temp/2021/tf\n"
     ]
    }
   ],
   "source": [
    "TF = importMQL(\n",
    "    mqlFile,\n",
    "    thisTempTf,\n",
    "    silent=SCRIPT,\n",
    "    slotType=slotType,\n",
    "    otext=otextInfo,\n",
    "    meta=featureMetaData,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename features\n",
    "We rename the features mentioned in the RENAME dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      3m 10s Renaming 2 features in /Users/me/github/etcbc/bhsa/_temp/2021/tf               .\n",
      "..............................................................................................\n",
      "|      3m 10s \trenamed g_suffix to trailer\n",
      "|      3m 10s \trenamed g_suffix_utf8 to trailer_utf8\n"
     ]
    }
   ],
   "source": [
    "if RENAME is None:\n",
    "    utils.caption(4, \"Rename features: nothing to do\")\n",
    "else:\n",
    "    utils.caption(4, \"Renaming {} features in {}\".format(len(RENAME), thisTempTf))\n",
    "    for (srcFeature, dstFeature) in RENAME:\n",
    "        srcPath = \"{}/{}.tf\".format(thisTempTf, srcFeature)\n",
    "        dstPath = \"{}/{}.tf\".format(thisTempTf, dstFeature)\n",
    "        if os.path.exists(srcPath):\n",
    "            os.rename(srcPath, dstPath)\n",
    "            utils.caption(0, \"\\trenamed {} to {}\".format(srcFeature, dstFeature))\n",
    "        else:\n",
    "            utils.caption(0, \"\\tsource feature {} does not exist.\".format(srcFeature))\n",
    "            utils.caption(\n",
    "                0, \"\\tdestination feature {} will not be created.\".format(dstFeature)\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffs\n",
    "\n",
    "Check differences with previous versions.\n",
    "\n",
    "The new dataset has been created in a temporary directory,\n",
    "and has not yet been copied to its destination.\n",
    "\n",
    "Here is your opportunity to compare the newly created features with the older features.\n",
    "You expect some differences in some features.\n",
    "\n",
    "We check the differences between the previous version of the features and what has been generated.\n",
    "We list features that will be added and deleted and changed.\n",
    "For each changed feature we show the first line where the new feature differs from the old one.\n",
    "We ignore changes in the metadata, because the timestamp in the metadata will always change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".      3m 13s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|      3m 13s \t2 features to add\n",
      "|      3m 13s \t\tg_voc_lex\n",
      "|      3m 13s \t\tg_voc_lex_utf8\n",
      "|      3m 13s \t43 features to delete\n",
      "|      3m 13s \t\tbook@am\n",
      "|      3m 13s \t\tbook@ar\n",
      "|      3m 13s \t\tbook@bn\n",
      "|      3m 13s \t\tbook@da\n",
      "|      3m 13s \t\tbook@de\n",
      "|      3m 13s \t\tbook@el\n",
      "|      3m 13s \t\tbook@en\n",
      "|      3m 13s \t\tbook@es\n",
      "|      3m 13s \t\tbook@fa\n",
      "|      3m 13s \t\tbook@fr\n",
      "|      3m 13s \t\tbook@he\n",
      "|      3m 13s \t\tbook@hi\n",
      "|      3m 13s \t\tbook@id\n",
      "|      3m 13s \t\tbook@ja\n",
      "|      3m 13s \t\tbook@ko\n",
      "|      3m 13s \t\tbook@la\n",
      "|      3m 13s \t\tbook@nl\n",
      "|      3m 13s \t\tbook@pa\n",
      "|      3m 13s \t\tbook@pt\n",
      "|      3m 13s \t\tbook@ru\n",
      "|      3m 13s \t\tbook@sw\n",
      "|      3m 13s \t\tbook@syc\n",
      "|      3m 13s \t\tbook@tr\n",
      "|      3m 13s \t\tbook@ur\n",
      "|      3m 13s \t\tbook@yo\n",
      "|      3m 13s \t\tbook@zh\n",
      "|      3m 13s \t\tfreq_lex\n",
      "|      3m 13s \t\tfreq_occ\n",
      "|      3m 13s \t\tgloss\n",
      "|      3m 13s \t\tinstruction\n",
      "|      3m 13s \t\tlanguageISO\n",
      "|      3m 13s \t\tlex0\n",
      "|      3m 13s \t\tnametype\n",
      "|      3m 13s \t\tomap@2017-2021\n",
      "|      3m 13s \t\tomap@c-2021\n",
      "|      3m 13s \t\tpargr\n",
      "|      3m 13s \t\tqere_trailer\n",
      "|      3m 13s \t\tqere_trailer_utf8\n",
      "|      3m 13s \t\trank_lex\n",
      "|      3m 13s \t\trank_occ\n",
      "|      3m 13s \t\troot\n",
      "|      3m 13s \t\tvoc_lex\n",
      "|      3m 13s \t\tvoc_lex_utf8\n",
      "|      3m 13s \t73 features in common\n",
      "|      3m 13s book                      ... no changes\n",
      "|      3m 13s chapter                   ... no changes\n",
      "|      3m 13s code                      ... no changes\n",
      "|      3m 13s det                       ... no changes\n",
      "|      3m 14s dist                      ... no changes\n",
      "|      3m 14s dist_unit                 ... no changes\n",
      "|      3m 14s distributional_parent     ... no changes\n",
      "|      3m 14s domain                    ... no changes\n",
      "|      3m 14s function                  ... no changes\n",
      "|      3m 14s functional_parent         ... no changes\n",
      "|      3m 15s g_cons                    ... no changes\n",
      "|      3m 15s g_cons_utf8               ... no changes\n",
      "|      3m 15s g_lex                     ... no changes\n",
      "|      3m 15s g_lex_utf8                ... no changes\n",
      "|      3m 15s g_nme                     ... no changes\n",
      "|      3m 15s g_nme_utf8                ... no changes\n",
      "|      3m 16s g_pfm                     ... no changes\n",
      "|      3m 16s g_pfm_utf8                ... no changes\n",
      "|      3m 16s g_prs                     ... no changes\n",
      "|      3m 16s g_prs_utf8                ... no changes\n",
      "|      3m 16s g_uvf                     ... no changes\n",
      "|      3m 16s g_uvf_utf8                ... no changes\n",
      "|      3m 16s g_vbe                     ... no changes\n",
      "|      3m 16s g_vbe_utf8                ... no changes\n",
      "|      3m 16s g_vbs                     ... no changes\n",
      "|      3m 17s g_vbs_utf8                ... no changes\n",
      "|      3m 17s g_word                    ... no changes\n",
      "|      3m 17s g_word_utf8               ... no changes\n",
      "|      3m 17s gn                        ... no changes\n",
      "|      3m 17s is_root                   ... no changes\n",
      "|      3m 17s kind                      ... no changes\n",
      "|      3m 17s kq_hybrid                 ... no changes\n",
      "|      3m 17s kq_hybrid_utf8            ... no changes\n",
      "|      3m 17s label                     ... no changes\n",
      "|      3m 17s language                  ... differences after the metadata\n",
      "|      3m 17s \tline 426592 OLD -->1437602\tHebrew<--\n",
      "|      3m 17s \tline 426592 NEW --><empty><--\n",
      "|      3m 17s \tline 426593 OLD -->Hebrew<--\n",
      "|      3m 17s \tline 426593 NEW --><empty><--\n",
      "|      3m 17s \tline 426594 OLD -->Hebrew<--\n",
      "|      3m 17s \tline 426594 NEW --><empty><--\n",
      "|      3m 17s \tline 426595 OLD -->Hebrew<--\n",
      "|      3m 17s \tline 426595 NEW --><empty><--\n",
      "\n",
      "|      3m 17s lex                       ... differences after the metadata\n",
      "|      3m 18s \tline 426592 OLD -->1437602\tB<--\n",
      "|      3m 18s \tline 426592 NEW --><empty><--\n",
      "|      3m 18s \tline 426593 OLD -->R>CJT/<--\n",
      "|      3m 18s \tline 426593 NEW --><empty><--\n",
      "|      3m 18s \tline 426594 OLD -->BR>[<--\n",
      "|      3m 18s \tline 426594 NEW --><empty><--\n",
      "|      3m 18s \tline 426595 OLD -->>LHJM/<--\n",
      "|      3m 18s \tline 426595 NEW --><empty><--\n",
      "\n",
      "|      3m 18s lex_utf8                  ... differences after the metadata\n",
      "|      3m 18s \tline      3 OLD -->ראשׁית<--\n",
      "|      3m 18s \tline      3 NEW -->ראשׁית֜<--\n",
      "|      3m 18s \tline      5 OLD -->אלהים<--\n",
      "|      3m 18s \tline      5 NEW -->אלהים֜<--\n",
      "|      3m 18s \tline      8 OLD -->שׁמים<--\n",
      "|      3m 18s \tline      8 NEW -->שׁמים֜<--\n",
      "|      3m 18s \tline     12 OLD -->ארץ<--\n",
      "|      3m 18s \tline     12 NEW -->ארץ֜<--\n",
      "\n",
      "|      3m 18s lexeme_count              ... no changes\n",
      "|      3m 18s ls                        ... differences after the metadata\n",
      "|      3m 18s \tline 426592 OLD -->1437611\tvbcp<--\n",
      "|      3m 18s \tline 426592 NEW --><empty><--\n",
      "|      3m 18s \tline 426593 OLD -->1437621\tquot<--\n",
      "|      3m 18s \tline 426593 NEW --><empty><--\n",
      "|      3m 18s \tline 426594 OLD -->1437627\tppre<--\n",
      "|      3m 18s \tline 426594 NEW --><empty><--\n",
      "|      3m 18s \tline 426595 OLD -->1437630\tpadv<--\n",
      "|      3m 18s \tline 426595 NEW --><empty><--\n",
      "\n",
      "|      3m 18s mother                    ... no changes\n",
      "|      3m 18s mother_object_type        ... no changes\n",
      "|      3m 18s nme                       ... no changes\n",
      "|      3m 18s nu                        ... no changes\n",
      "|      3m 18s number                    ... no changes\n",
      "|      3m 19s oslots                    ... differences after the metadata\n",
      "|      3m 19s \tline 1011013 OLD -->1,84,197,220,241,270,318,330,334,428,435 ...<--\n",
      "|      3m 19s \tline 1011013 NEW --><empty><--\n",
      "|      3m 19s \tline 1011014 OLD -->2,4662,27812,41332,48285,53078,66102,796 ...<--\n",
      "|      3m 19s \tline 1011014 NEW --><empty><--\n",
      "|      3m 19s \tline 1011015 OLD -->3,381,535,545,550,724,736,2126,2137,2148 ...<--\n",
      "|      3m 19s \tline 1011015 NEW --><empty><--\n",
      "|      3m 19s \tline 1011016 OLD -->4,26,34,42,50,60,81,97,127,142,162,176,1 ...<--\n",
      "|      3m 19s \tline 1011016 NEW --><empty><--\n",
      "\n",
      "|      3m 19s otext                     ... differences\n",
      "|      3m 19s \tline      5 OLD -->@dateWritten=2021-12-09T14:21:19Z<--\n",
      "|      3m 19s \tline      5 NEW -->@email=shebanq@ancient-data.org<--\n",
      "|      3m 19s \tline      6 OLD -->@email=shebanq@ancient-data.org<--\n",
      "|      3m 19s \tline      6 NEW -->@encoders=Constantijn Sikkel (QDF), Ulri ...<--\n",
      "|      3m 19s \tline      7 OLD -->@encoders=Constantijn Sikkel (QDF), Ulri ...<--\n",
      "|      3m 19s \tline      7 NEW -->@fmt:lex-orig-full={g_lex_utf8} <--\n",
      "|      3m 19s \tline      8 OLD -->@fmt:lex-default={voc_lex_utf8} <--\n",
      "|      3m 19s \tline      8 NEW -->@fmt:lex-orig-plain={lex_utf8} <--\n",
      "\n",
      "|      3m 19s otype                     ... differences after the metadata\n",
      "|      3m 19s \tline     14 OLD -->1437602-1446831\tlex<--\n",
      "|      3m 19s \tline     14 NEW --><empty><--\n",
      "\n",
      "|      3m 19s pdp                       ... no changes\n",
      "|      3m 19s pfm                       ... no changes\n",
      "|      3m 19s prs                       ... no changes\n",
      "|      3m 19s prs_gn                    ... no changes\n",
      "|      3m 19s prs_nu                    ... no changes\n",
      "|      3m 20s prs_ps                    ... no changes\n",
      "|      3m 20s ps                        ... no changes\n",
      "|      3m 20s qere                      ... differences after the metadata\n",
      "|      3m 20s \tline      2 OLD -->3897\tHAJ:Y;74><--\n",
      "|      3m 20s \tline      2 NEW --><--\n",
      "|      3m 20s \tline      3 OLD -->4420\t>@H:@LO75W<--\n",
      "|      3m 20s \tline      3 NEW --><--\n",
      "|      3m 20s \tline      4 OLD -->5645\t>@H:@LO92W<--\n",
      "|      3m 20s \tline      4 NEW --><--\n",
      "|      3m 20s \tline      5 OLD -->5912\t>@95H:@LOW03<--\n",
      "|      3m 20s \tline      5 NEW --><--\n",
      "\n",
      "|      3m 20s qere_utf8                 ... differences after the metadata\n",
      "|      3m 20s \tline      2 OLD -->3897\tהַיְצֵ֣א<--\n",
      "|      3m 20s \tline      2 NEW --><--\n",
      "|      3m 20s \tline      3 OLD -->4420\tאָהֳלֹֽו<--\n",
      "|      3m 20s \tline      3 NEW --><--\n",
      "|      3m 20s \tline      4 OLD -->5645\tאָהֳלֹ֑ו<--\n",
      "|      3m 20s \tline      4 NEW --><--\n",
      "|      3m 20s \tline      5 OLD -->5912\tאָֽהֳלֹו֙<--\n",
      "|      3m 20s \tline      5 NEW --><--\n",
      "\n",
      "|      3m 20s rela                      ... no changes\n",
      "|      3m 20s sp                        ... differences after the metadata\n",
      "|      3m 20s \tline 426592 OLD -->1437602\tprep<--\n",
      "|      3m 20s \tline 426592 NEW --><empty><--\n",
      "|      3m 20s \tline 426593 OLD -->subs<--\n",
      "|      3m 20s \tline 426593 NEW --><empty><--\n",
      "|      3m 20s \tline 426594 OLD -->verb<--\n",
      "|      3m 20s \tline 426594 NEW --><empty><--\n",
      "|      3m 20s \tline 426595 OLD -->subs<--\n",
      "|      3m 20s \tline 426595 NEW --><empty><--\n",
      "\n",
      "|      3m 20s st                        ... no changes\n",
      "|      3m 20s suffix_gender             ... no changes\n",
      "|      3m 20s suffix_number             ... no changes\n",
      "|      3m 21s suffix_person             ... no changes\n",
      "|      3m 21s tab                       ... no changes\n",
      "|      3m 21s trailer                   ... no changes\n",
      "|      3m 21s trailer_utf8              ... no changes\n",
      "|      3m 21s txt                       ... no changes\n",
      "|      3m 21s typ                       ... no changes\n",
      "|      3m 21s uvf                       ... no changes\n",
      "|      3m 21s vbe                       ... no changes\n",
      "|      3m 21s vbs                       ... no changes\n",
      "|      3m 22s verse                     ... no changes\n",
      "|      3m 22s vs                        ... no changes\n",
      "|      3m 22s vt                        ... no changes\n",
      "|      3m 22s Done\n"
     ]
    }
   ],
   "source": [
    "utils.checkDiffs(thisTempTf, thisTf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliver\n",
    "\n",
    "Copy the new TF dataset from the temporary location where it has been created to its final destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     19m 22s Deliver data set to /Users/werk/github/etcbc/bhsa/tf/2021                      .\n",
      "..............................................................................................\n"
     ]
    }
   ],
   "source": [
    "utils.deliverDataset(thisTempTf, thisTf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile TF\n",
    "\n",
    "Just to see whether everything loads and the pre-computing of extra information works out.\n",
    "Moreover, if you want to work with these features, then the pre-computing has already been done, and everything is quicker in subsequent runs.\n",
    "\n",
    "We issue load statement to trigger the pre-computing of extra data.\n",
    "Note that all features specified text formats in the `otext` config feature,\n",
    "will be loaded, as well as the features for sections.\n",
    "\n",
    "At that point we have access to the full list of features.\n",
    "We grab them and are going to load them all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     19m 26s Load and compile standard TF features                                          .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 9.1.6\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "75 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.42s T otype                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     7.31s T oslots               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "   |     0.90s T g_word_utf8          from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.83s T g_lex_utf8           from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.03s T verse                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.81s T g_cons_utf8          from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.73s T g_lex                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.59s T trailer              from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.04s T book                 from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.72s T lex                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.61s T trailer_utf8         from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.81s T lex_utf8             from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.03s T chapter              from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.73s T g_cons               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.81s T g_word               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |      |     0.52s C __levels__           from otype, oslots, otext\n",
      "   |      |       11s C __order__            from otype, oslots, __levels__\n",
      "   |      |     0.60s C __rank__             from otype, __order__\n",
      "   |      |       13s C __levUp__            from otype, oslots, __rank__\n",
      "   |      |     8.44s C __levDown__          from otype, __levUp__, __rank__\n",
      "   |      |     3.97s C __boundary__         from otype, oslots, __rank__\n",
      "   |      |     0.06s C __sections__         from otype, oslots, otext, __levUp__, __levels__, book, chapter, verse\n",
      "    53s All features loaded/computed - for details use TF.isLoaded()\n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, \"Load and compile standard TF features\")\n",
    "TF = Fabric(locations=thisTf, modules=[\"\"])\n",
    "api = TF.load(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     20m 19s Load and compile all other TF features                                         .\n",
      "..............................................................................................\n",
      "   |     0.00s Feature overview: 70 for nodes; 4 for edges; 1 configs; 8 computed\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "   |     0.11s T code                 from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.83s T det                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.89s T dist                 from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     1.00s T dist_unit            from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     2.68s T distributional_parent from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.14s T domain               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.43s T function             from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     3.75s T functional_parent    from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.53s T g_nme                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.57s T g_nme_utf8           from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.44s T g_pfm                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.44s T g_pfm_utf8           from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.44s T g_prs                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.44s T g_prs_utf8           from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.39s T g_uvf                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.38s T g_uvf_utf8           from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.45s T g_vbe                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.41s T g_vbe_utf8           from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.40s T g_vbs                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.40s T g_vbs_utf8           from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.74s T g_voc_lex            from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.83s T g_voc_lex_utf8       from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.68s T gn                   from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.14s T is_root              from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.14s T kind                 from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.41s T kq_hybrid            from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.40s T kq_hybrid_utf8       from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.11s T label                from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.68s T language             from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.50s T lexeme_count         from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.69s T ls                   from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.57s T mother               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.36s T mother_object_type   from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.61s T nme                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.69s T nu                   from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     1.43s T number               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.71s T pdp                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.69s T pfm                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.71s T prs                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.69s T prs_gn               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.69s T prs_nu               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.70s T prs_ps               from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.68s T ps                   from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.40s T qere                 from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.39s T qere_utf8            from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     1.22s T rela                 from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.72s T sp                   from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.70s T st                   from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.69s T suffix_gender        from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.67s T suffix_number        from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.68s T suffix_person        from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.10s T tab                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.14s T txt                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     1.21s T typ                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.68s T uvf                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.66s T vbe                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.73s T vbs                  from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.73s T vs                   from ~/github/etcbc/bhsa/tf/2021\n",
      "   |     0.70s T vt                   from ~/github/etcbc/bhsa/tf/2021\n",
      "    41s All features loaded/computed - for details use TF.isLoaded()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Computed',\n",
       "  'computed-data',\n",
       "  ('C Computed', 'Call AllComputeds', 'Cs ComputedString')),\n",
       " ('Features', 'edge-features', ('E Edge', 'Eall AllEdges', 'Es EdgeString')),\n",
       " ('Fabric', 'loading', ('TF',)),\n",
       " ('Locality', 'locality', ('L Locality',)),\n",
       " ('Nodes', 'navigating-nodes', ('N Nodes',)),\n",
       " ('Features',\n",
       "  'node-features',\n",
       "  ('F Feature', 'Fall AllFeatures', 'Fs FeatureString')),\n",
       " ('Search', 'search', ('S Search',)),\n",
       " ('Text', 'text', ('T Text',))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.caption(4, \"Load and compile all other TF features\")\n",
    "allFeatures = TF.explore(silent=False, show=True)\n",
    "loadableFeatures = allFeatures[\"nodes\"] + allFeatures[\"edges\"]\n",
    "api = TF.load(loadableFeatures)\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............................................................................................\n",
      ".     21m 43s Basic test                                                                     .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     21m 43s First verse in all formats                                                     .\n",
      "..............................................................................................\n",
      "lex-orig-full\n",
      "\tבְּ רֵאשִׁית בָּרָא אֱלֹה אֵת הַ שָּׁמַי וְ אֵת הָ אָרֶץ \n",
      "lex-orig-plain\n",
      "\tב ראשׁית֜ ברא אלהים֜ את ה שׁמים֜ ו את ה ארץ֜ \n",
      "lex-trans-full\n",
      "\tB.:- R;>CIJT B.@R@> >:ELOH >;T HA- C.@MAJ W:- >;T H@- >@REY \n",
      "lex-trans-plain\n",
      "\tB R>CJT/ BR>[ >LHJM/ >T H CMJM/ W >T H >RY/ \n",
      "text-orig-full\n",
      "\tבְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃ \n",
      "text-orig-plain\n",
      "\tבראשׁית ברא אלהים את השׁמים ואת הארץ׃ \n",
      "text-trans-full\n",
      "\tB.:-R;>CI73JT B.@R@74> >:ELOHI92JM >;71T HA-C.@MA73JIM W:->;71T H@->@75REY00 \n",
      "text-trans-plain\n",
      "\tBR>CJT BR> >LHJM >T HCMJM W>T H>RY00 \n"
     ]
    }
   ],
   "source": [
    "utils.caption(4, \"Basic test\")\n",
    "utils.caption(4, \"First verse in all formats\")\n",
    "for fmt in T.formats:\n",
    "    utils.caption(0, \"{}\".format(fmt), continuation=True)\n",
    "    utils.caption(0, \"\\t{}\".format(T.text(range(1, 12), fmt=fmt)), continuation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if SCRIPT:\n",
    "    stop(good=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    15s Node feature \"subphrase_type\" not loaded\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'freqList'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-ecb467d6013a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'subphrase_type'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'` `'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mFs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreqList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'freqList'"
     ]
    }
   ],
   "source": [
    "f = \"subphrase_type\"\n",
    "print(\"`\" + \"` `\".join(sorted(str(x[0]) for x in Fs(f).freqList())) + \"`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
