{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [모듈 5.1] 모델 빌딩 파이프라인 개발 (SageMaker Model Building Pipeline 모든 스텝)\n",
    "\n",
    "이 노트북은 아래와 같은 목차로 진행 됩니다. 전체를 모두 실행시에 완료 시간은 **약 30분** 소요 됩니다.\n",
    "\n",
    "- 0. SageMaker Model Building Pipeline 개요\n",
    "- 1. 파이프라인 변수 및 환경 설정\n",
    "- 2. 파이프라인 스텝 단계 정의\n",
    "\n",
    "    - (1) 전처리 스텝 스텝 정의    \n",
    "    - (2) 모델 학습을 위한 학습 스텝 정의 \n",
    "    - (3) 모델 평가 스텝\n",
    "    - (4) 모델 등록 스텝\n",
    "    - (5) HPO 단계    \n",
    "    - (6) 최고 모델 등록 스텝    \n",
    "    - (7) 모델 승인 상태 변경 람다 스텝    \n",
    "    - (8) 배포할 세이지 메이커 모델 스텝 생성\n",
    "    - (9) 모델 앤드 포인트 배포를 위한 람다 스텝 생성    \n",
    "    - (5) 세이지 메이커 모델 생성 스텝 생성    \n",
    "    - (6) HPO 스텝\n",
    "    - (7) 조건 스텝\n",
    "    - (10) 조건 스텝\n",
    "    \n",
    "- 3. 모델 빌딩 파이프라인 정의 및 실행\n",
    "- 4. Pipleline 캐싱 및 파라미터 이용한 실행\n",
    "- 5. 정리 작업\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.SageMaker Model Building Pipeline 개요\n",
    "\n",
    "Amazon SageMaker 모델 구축 파이프라인은 직접 SageMaker 통합을 활용하는 머신 러닝 파이프라인을 구축하기 위한 도구입니다. 이러한 통합으로 인해 많은 단계 생성 및 관리를 처리하는 도구를 사용하여 파이프라인을 생성하고 오케스트레이션용 SageMaker Projects를 설정할 수 있습니다. SageMaker 파이프라인은 다른 파이프라인에 비해 다음과 같은 이점을 제공합니다\n",
    "\n",
    "- 상세 사항은 개발자 가이드 참조 하세요. --> [Amazon SageMaker 모델 구축 파이프라인](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/pipelines.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 파이프라인 변수 및 환경 설정\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sm_client = boto3.client('sagemaker', region_name=region)\n",
    "\n",
    "%store -r "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 모델 빌딩 파이프라인 변수 생성\n",
    "\n",
    "파이프라인에 인자로 넘길 변수는 아래 크게 3가지 종류가 있습니다.\n",
    "- 프로세싱 스텝을 위한 인스턴스 타입 및 인스턴스 수\n",
    "    - 데이터 전처리 스텝 및 실시간 앤드 포인트 스텝에 사용 됨.\n",
    "- 훈련 스텝을 위한 인스턴스 타입 및 인스턴스 수    \n",
    "- 모델 평가를 통해 나온 validation:roc-auc 에 대한 분기 조건 값\n",
    "- 원본 데이터 세트에 대한 S3 주소\n",
    "    - 데이터 전처리 스텝에서 사용 됩니다.\n",
    "- 모델 레지스트리에 모델 등록시에 모델 승인 상태 값    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    "    ParameterFloat,\n",
    ")\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "training_instance_count = ParameterInteger(\n",
    "    name=\"TrainingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "\n",
    "model_eval_threshold = ParameterFloat(\n",
    "    name=\"model2eval2threshold\",\n",
    "    default_value=0.85\n",
    ")\n",
    "\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=input_data_uri,\n",
    ")\n",
    "\n",
    "model_approval_status = ParameterString(\n",
    "    name=\"ModelApprovalStatus\", default_value=\"PendingManualApproval\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 캐싱 정의\n",
    "\n",
    "- 참고: 캐싱 파이프라인 단계:  [Caching Pipeline Steps](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/pipelines-caching.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.steps import CacheConfig\n",
    "\n",
    "cache_config = CacheConfig(enable_caching=True, \n",
    "                           expire_after=\"7d\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 파이프라인 스텝 단계 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 전처리 스텝 단계 정의\n",
    "- input_data_uri 입력 데이타를 대상으로 전처리를 수행 합니다.\n",
    "\n",
    "크게 아래와 같은 순서로 정의 합니다.\n",
    "- 프로세싱 오브젝트 정의 (SKLearnProcessor)\n",
    "- 프로세싱 스텝 정의\n",
    "    - 일력 데이터 세트\n",
    "        - source: S3 경로 (input_data_uri)\n",
    "        - destination: 도커 컨테이너의 내부 폴더 위치\n",
    "    - 출력 위치\n",
    "        - 훈련 전처리 데이터 결과 위치\n",
    "        - 테스트 전처리 데이터 결과 위치\n",
    "    - 프로세싱 코드\n",
    "    - 프로세싱 코드에 넘길 인자 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_data: \n",
      " s3://sagemaker-us-east-1-028703291518/sagemaker-pipeline-step-by-step-phase02/input\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "split_rate = 0.2\n",
    "framework_version = \"0.23-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=processing_instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-fraud-process\",\n",
    "    role=role,\n",
    ")\n",
    "print(\"input_data: \\n\", input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "    \n",
    "step_process = ProcessingStep(\n",
    "    name=\"FraudProcess\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "#         ProcessingInput(source=input_data_uri,destination='/opt/ml/processing/input'),\n",
    "        ProcessingInput(source=input_data, destination='/opt/ml/processing/input'),        \n",
    "         ],\n",
    "    outputs=[ProcessingOutput(output_name=\"train\",\n",
    "                              source='/opt/ml/processing/output/train'),\n",
    "             ProcessingOutput(output_name=\"test\",\n",
    "                              source='/opt/ml/processing/output/test')],\n",
    "    job_arguments=[\"--split_rate\", f\"{split_rate}\"],        \n",
    "    code= 'src/preprocessing.py',\n",
    "    cache_config = cache_config, # 캐시 정의\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 모델 학습을 위한 학습단계 정의 \n",
    "\n",
    "학습 스텝을 정의하기 위해서는 크게 아래와 같은 과정이 있습니다.\n",
    "- XGBoost Estimator 정의\n",
    "- 학습 스텝 정의\n",
    "    - 아래와 같은 중요한 인자가 필요 합니다.\n",
    "        - Estimator (위에서 정의한 것 사용)\n",
    "        - 훈련을 위한 입력 데이터 위치\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기본 훈련 변수 및 하이퍼파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.xgboost.estimator import XGBoost\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'fraud2train'\n",
    "estimator_output_path = f's3://{bucket}/{prefix}/training_jobs'\n",
    "\n",
    "base_hyperparameters = {\n",
    "       \"scale_pos_weight\" : \"29\",        \n",
    "        \"max_depth\": \"6\",\n",
    "        \"alpha\" : \"0\", \n",
    "        \"eta\": \"0.3\",\n",
    "        \"min_child_weight\": \"1\",\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"num_round\": \"100\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_train = XGBoost(\n",
    "    entry_point = \"xgboost_script.py\",\n",
    "    source_dir = \"src\",\n",
    "    output_path = estimator_output_path,\n",
    "    code_location = estimator_output_path,\n",
    "    hyperparameters = base_hyperparameters,\n",
    "    role = role,\n",
    "    instance_count = training_instance_count,\n",
    "    instance_type = training_instance_type,\n",
    "    framework_version = \"1.0-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련의 입력이 이전 전처리의 결과가 제공됩니다.\n",
    "- `step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"FraudTrain\",\n",
    "    estimator=xgb_train,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            # s3_data= train_preproc_dir_artifact,            \n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "    },\n",
    "    cache_config = cache_config, # 캐시 정의    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) 모델 평가 단계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKLearnProcessor 의 기본 도커 컨테이너 지정\n",
    "ScriptProcessor 의 기본 도커 컨테이너로 Scikit-learn를 기본 이미지를 사용함. \n",
    "- 사용자가 정의한 도커 컨테이너도 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_eval = SKLearnProcessor(\n",
    "                             framework_version= \"0.23-1\",\n",
    "                             role=role,\n",
    "                             instance_type=processing_instance_type,\n",
    "                             instance_count=1,\n",
    "                             base_job_name=\"script-fraud-scratch-eval\",\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 평가 지표를 jons 파일에 저장을 하고 property로 등록을 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"FraudEval\",\n",
    "    processor=script_eval,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source= step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"test\"\n",
    "            ].S3Output.S3Uri,\n",
    "        destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"src/evaluation.py\",\n",
    "    cache_config = cache_config, # 캐시 정의    \n",
    "  property_files=[evaluation_report], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) 모델 등록 스텝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 그룹 생성\n",
    "- 위의 step_eval 에서 S3 로 올린 evaluation.json 파일안의 지표를 \"모델 레지스트리\" 안에 모델 패키지의 모델 버전 등록시에 삽입함\n",
    "\n",
    "- 참고\n",
    "    - 모델 그룹 릭스팅 API:  [ListModelPackageGroups](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_ListModelPackageGroups.html)\n",
    "    - 모델 지표 등록: [Model Quality Metrics](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/model-monitor-model-quality-metrics.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker-pipeline-step-by-step-phase02 exitss\n"
     ]
    }
   ],
   "source": [
    "model_package_group_name = f\"{project_prefix}\"\n",
    "model_package_group_input_dict = {\n",
    " \"ModelPackageGroupName\" : model_package_group_name,\n",
    " \"ModelPackageGroupDescription\" : \"Sample model package group\"\n",
    "}\n",
    "response = sm_client.list_model_package_groups(NameContains=model_package_group_name)\n",
    "if len(response['ModelPackageGroupSummaryList']) == 0:\n",
    "    print(\"No model group exists\")\n",
    "    print(\"Create model group\")    \n",
    "    \n",
    "    create_model_pacakge_group_response = sm_client.create_model_package_group(**model_package_group_input_dict)\n",
    "    print('ModelPackageGroup Arn : {}'.format(create_model_pacakge_group_response['ModelPackageGroupArn']))    \n",
    "else:\n",
    "    print(f\"{model_package_group_name} exitss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "from sagemaker.model_metrics import MetricsSource, ModelMetrics \n",
    "\n",
    "# 위의 step_eval 에서 S3 로 올린 evaluation.json 파일안의 지표를 \"모델 레지스트리\" 에 모데 버전 등록시에 삽입함\n",
    "model_metrics = ModelMetrics(\n",
    "    model_statistics=MetricsSource(\n",
    "        s3_uri=\"{}/evaluation.json\".format(\n",
    "            step_eval.arguments[\"ProcessingOutputConfig\"][\"Outputs\"][0][\"S3Output\"][\"S3Uri\"]\n",
    "        ),\n",
    "        content_type=\"application/json\"\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "step_register = RegisterModel(\n",
    "    name= \"FraudcRegisterhModel\",\n",
    "    estimator=xgb_train,\n",
    "    image_uri= step_train.properties.AlgorithmSpecification.TrainingImage,\n",
    "    model_data= step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.xlarge\"],\n",
    "    transform_instances=[\"ml.m5.xlarge\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    model_metrics=model_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) HPO 스텝\n",
    "- 하이퍼 파라미터 튜닝 스텝을 정의 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import (\n",
    "    IntegerParameter,\n",
    "    CategoricalParameter,\n",
    "    ContinuousParameter,\n",
    "    HyperparameterTuner,\n",
    ")\n",
    "\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"eta\": ContinuousParameter(0, 1),\n",
    "    \"min_child_weight\": ContinuousParameter(1, 10),\n",
    "    \"alpha\": ContinuousParameter(0, 2),\n",
    "    \"max_depth\": IntegerParameter(1, 10),\n",
    "}\n",
    "\n",
    "\n",
    "objective_metric_name = \"validation:auc\"\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    xgb_train, objective_metric_name, hyperparameter_ranges, \n",
    "    max_jobs=5,\n",
    "    max_parallel_jobs=5,\n",
    ")\n",
    "\n",
    "from sagemaker.workflow.steps import TuningStep\n",
    "    \n",
    "step_tuning = TuningStep(\n",
    "    name = \"FraudTuning\",\n",
    "    tuner = tuner,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"train\"\n",
    "            ].S3Output.S3Uri,\n",
    "            # s3_data= train_preproc_dir_artifact,            \n",
    "            content_type=\"text/csv\"\n",
    "        ),\n",
    "    },    \n",
    "    cache_config = cache_config, # 캐시 정의        \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) 최고 모델 등록 스텝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 최고의 모델 생성 및 등록\n",
    "\n",
    "하이퍼파라미터 튜닝 작업을 성공적으로 완료한 후TuningStep의 교육 작업에 의해 생성된 모델 아티팩트에서 SageMaker 모델을 생성하거나 모델 레지스트리에 모델을 등록할 수 있습니다.\n",
    "\n",
    "\n",
    "TuningStep 클래스의 get_top_model_s3_uri 메서드를 사용하여 최고 성능의 모델 버전의 모델 아티팩트를 가져옵니다.\n",
    "\n",
    "- `model_bucket_key` 는 튜닝 스텝을 통해서 생성된 훈련 잡의 위치 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_bucket_key:  sagemaker-us-east-1-028703291518/fraud2train/training_jobs\n",
      "model_package_group_name:  sagemaker-pipeline-step-by-step-phase02\n"
     ]
    }
   ],
   "source": [
    "model_bucket_key = estimator_output_path.split('//')[1]\n",
    "print(\"model_bucket_key: \", model_bucket_key)\n",
    "print(\"model_package_group_name: \", model_package_group_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "\n",
    "step_register_best = RegisterModel(\n",
    "    name=\"RegisterBestFraudModel\",\n",
    "    estimator=xgb_train,\n",
    "    model_data=step_tuning.get_top_model_s3_uri(top_k=0, s3_bucket=model_bucket_key),\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (7) 모델 승인 상태 변경 람다 스텝\n",
    "- 모델 레지스트리에서 해당 모델 패키지 그룹을 조회하고, 가장 최신 버전의 모델에 대해서 '모델 승인 상태 변경' 을 합니다.\n",
    "\n",
    "#### 참고: \n",
    "`step_approve_lambda.add_depends_on([step_register_best])`시에 에러 발생\n",
    "- 에러 발생 원인은 명시적으로 `RegisterModel` 은 의존성을 허용하지 않아서 나는 것으로 추정이 됨.\n",
    "- 그래서 의존 스텝을 step_tuning 으로 지정 함.\n",
    "\n",
    "```\n",
    "ValueError: Invalid input step name: RegisterModel(steps=[_RegisterModelStep(name='test', step_type=<StepTypeEnum.REGISTER_MODEL: 'RegisterModel'>, depends_on=None)])\n",
    "```\n",
    "\n",
    "#### [에러] \n",
    "아래와 같은 데러가 발생시에 `0.0.Setup-Environment.ipynb` 의 정책 추가 부분을 진행 해주세요.\n",
    "```\n",
    "ClientError: An error occurred (AccessDenied) when calling the CreateRole operation: User: arn:aws:sts::0287032915XX:assumed-role/AmazonSageMaker-ExecutionRole-20210827T141955/SageMaker is not authorized to perform: iam:CreateRole on resource: arn:aws:iam::0287032915XX:role/lambda-deployment-role\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda_role: \n",
      " arn:aws:iam::028703291518:role/lambda-deployment-role\n"
     ]
    }
   ],
   "source": [
    "from src.iam_helper import create_lambda_role\n",
    "\n",
    "lambda_role = create_lambda_role(\"lambda-deployment-role\")\n",
    "print(\"lambda_role: \\n\", lambda_role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function_name: \n",
      " sagemaker-lambda-step-approve-model-deployment-08-27-08-24-45\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.lambda_helper import Lambda\n",
    "from sagemaker.workflow.lambda_step import (\n",
    "    LambdaStep,\n",
    "    LambdaOutput,\n",
    "    LambdaOutputTypeEnum,\n",
    ")\n",
    "\n",
    "import time \n",
    "\n",
    "current_time = time.strftime(\"%m-%d-%H-%M-%S\", time.localtime())\n",
    "function_name = \"sagemaker-lambda-step-approve-model-deployment-\" + current_time\n",
    "\n",
    "print(\"function_name: \\n\", function_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda helper class can be used to create the Lambda function\n",
    "func_approve_model = Lambda(\n",
    "    function_name=function_name,\n",
    "    execution_role_arn=lambda_role,\n",
    "    script=\"src/iam_change_model_approval.py\",\n",
    "    handler=\"iam_change_model_approval.lambda_handler\",\n",
    ")\n",
    "\n",
    "output_param_1 = LambdaOutput(output_name=\"statusCode\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_2 = LambdaOutput(output_name=\"body\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_3 = LambdaOutput(output_name=\"other_key\", output_type=LambdaOutputTypeEnum.String)\n",
    "\n",
    "step_approve_lambda = LambdaStep(\n",
    "    name=\"LambdaApproveModelStep\",\n",
    "    lambda_func=func_approve_model,\n",
    "    inputs={\n",
    "        \"model_package_group_name\" : model_package_group_name,\n",
    "        \"ModelApprovalStatus\": \"Approved\",\n",
    "    },\n",
    "    outputs=[output_param_1, output_param_2, output_param_3],\n",
    ")\n",
    "step_approve_lambda.add_depends_on([step_tuning])\n",
    "# step_approve_lambda.add_depends_on([step_register_best])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (8) 배포할 세이지 메이커 모델 스텝 생성\n",
    "- 위의 람다 스텝에서 \"모델 승인 상태\" 를 변경한 모델에 대하여 '모델 레지스트리'에서 저장된 도커 컨테이너 이미지, 모델 아티펙트의 위치를 가져 옵니다.\n",
    "- 이후에 이 두개의 인자를 가지고 세이지 메이커 모델을 생성 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-42191cfcf33a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_model_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelPackageGroupName\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel_package_group_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mModelPackageArn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ModelPackageSummaryList'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ModelPackageArn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0msm_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_model_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelPackageName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModelPackageArn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msm_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe_model_package\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModelPackageName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModelPackageArn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "sm_client = boto3.client('sagemaker')\n",
    "\n",
    "# 위에서 생성한 model_package_group_name 을 인자로 제공 합니다.\n",
    "response = sm_client.list_model_packages(ModelPackageGroupName= model_package_group_name)\n",
    "\n",
    "ModelPackageArn = response['ModelPackageSummaryList'][0]['ModelPackageArn']\n",
    "sm_client.describe_model_package(ModelPackageName=ModelPackageArn)\n",
    "response = sm_client.describe_model_package(ModelPackageName=ModelPackageArn)\n",
    "image_uri_approved = response[\"InferenceSpecification\"][\"Containers\"][0][\"Image\"]\n",
    "ModelDataUrl_approved = response[\"InferenceSpecification\"][\"Containers\"][0][\"ModelDataUrl\"]\n",
    "print(\"image_uri_approved: \", image_uri_approved)\n",
    "print(\"ModelDataUrl_approved: \", ModelDataUrl_approved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "    \n",
    "model = Model(\n",
    "    image_uri= image_uri_approved,\n",
    "    model_data= ModelDataUrl_approved,    \n",
    "    sagemaker_session=sagemaker_session,\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import CreateModelInput\n",
    "from sagemaker.workflow.steps import CreateModelStep\n",
    "\n",
    "\n",
    "inputs = CreateModelInput(\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    # accelerator_type=\"ml.eia1.medium\",\n",
    ")\n",
    "step_create_best_model = CreateModelStep(\n",
    "    name=\"CreateFraudhModel\",\n",
    "    model=model,\n",
    "    inputs=inputs,\n",
    ")\n",
    "step_create_best_model.add_depends_on([step_approve_lambda]) # step_approve_lambda 완료 후 실행 함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (9) 모델 앤드 포인트 배포를 위한 람다 스텝 생성\n",
    "- 람다 함수는 입력으로 세이지 메이커 모델, 앤드 포인트 컨피그 및 앤드 포인트 이름을 받아서, 앤드포인트를 생성 함.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = project_prefix + \"-lambda-model\" + current_time\n",
    "endpoint_config_name = \"lambda-deploy-endpoint-config-\" + current_time\n",
    "endpoint_name = \"lambda-deploy-endpoint-\" + current_time\n",
    "\n",
    "function_name = \"sagemaker-lambda-step-endpoint-deploy-\" + current_time\n",
    "\n",
    "# print(\"model_name: \\n\", model_name)\n",
    "print(\"endpoint_config_name: \\n\", endpoint_config_name)\n",
    "print(\"endpoint_config_name: \\n\", len(endpoint_config_name))\n",
    "print(\"endpoint_name: \\n\", endpoint_name)\n",
    "print(\"function_name: \\n\", function_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda helper class can be used to create the Lambda function\n",
    "func_deploy_model = Lambda(\n",
    "    function_name=function_name,\n",
    "    execution_role_arn=lambda_role,\n",
    "    script=\"src/iam_create_endpoint.py\",\n",
    "    handler=\"iam_create_endpoint.lambda_handler\",\n",
    "    timeout = 900, # 디폴트는 120초 임. 10분으로 연장\n",
    ")\n",
    "\n",
    "output_param_1 = LambdaOutput(output_name=\"statusCode\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_2 = LambdaOutput(output_name=\"body\", output_type=LambdaOutputTypeEnum.String)\n",
    "output_param_3 = LambdaOutput(output_name=\"other_key\", output_type=LambdaOutputTypeEnum.String)\n",
    "\n",
    "step_deploy_lambda = LambdaStep(\n",
    "    name=\"LambdaDeployStep\",\n",
    "    lambda_func=func_deploy_model,\n",
    "    inputs={\n",
    "        \"model_name\": step_create_best_model.properties.ModelName,\n",
    "        \"endpoint_config_name\": endpoint_config_name,\n",
    "        \"endpoint_name\": endpoint_name,\n",
    "    },\n",
    "    outputs=[output_param_1, output_param_2, output_param_3],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다음 노트북의 추론을 위해서 저장\n",
    "all_adv_pipeline_endpoint_name = endpoint_name\n",
    "%store all_adv_pipeline_endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (10) 조건 스텝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet,\n",
    ")\n",
    "\n",
    "\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step=step_eval,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"binary_classification_metrics.auc.value\",\n",
    "    ),\n",
    "    # right=8.0\n",
    "    right = model_eval_threshold\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"FruadMetricCond\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_tuning],        \n",
    "    else_steps=[step_register], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.모델 빌딩 파이프라인 정의 및 실행\n",
    "위에서 정의한 아래의 4개의 스텝으로 파이프라인 정의를 합니다.\n",
    "-     steps=[step_process, step_train, step_create_model, step_deploy],\n",
    "- 아래는 약 20분 정도 소요 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "project_prefix = 'sagemaker-pipeline-phase2-step-by-step'\n",
    "\n",
    "pipeline_name = project_prefix\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type, \n",
    "        processing_instance_count,\n",
    "        training_instance_type,        \n",
    "        training_instance_count,                \n",
    "        input_data,\n",
    "        model_eval_threshold,\n",
    "        model_approval_status,        \n",
    "    ],\n",
    "\n",
    "    \n",
    "  steps=[step_process, step_train, step_eval, step_cond, step_register_best, step_approve_lambda, \n",
    "         step_create_best_model, step_deploy_lambda],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_adv_pipeline_name = pipeline_name\n",
    "%store all_adv_pipeline_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "# definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인을 SageMaker에 제출하고 실행하기 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "디폴트값을 이용하여 파이프라인을 샐행합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인 운영: 파이프라인 대기 및 실행상태 확인\n",
    "\n",
    "워크플로우의 실행상황을 살펴봅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행이 완료될 때까지 기다립니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실행된 단계들을 리스트업합니다. 파이프라인의 단계실행 서비스에 의해 시작되거나 완료된 단계를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Pipeline 캐싱 및 파라미터 이용한 실행\n",
    "- 캐싱은 2021년 7월 현재 Training, Processing, Transform 의 Step에 적용이 되어 있습니다.\n",
    "- 상세 사항은 여기를 확인하세요. -->  [캐싱 파이프라인 단계](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/pipelines-caching.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "from IPython.display import display as dp\n",
    "import time\n",
    "\n",
    "if is_cache:\n",
    "    execution = pipeline.start(\n",
    "        parameters=dict(\n",
    "            model2eval2threshold=0.8,\n",
    "        )\n",
    "    )    \n",
    "    \n",
    "    # execution = pipeline.start()\n",
    "    time.sleep(10)\n",
    "    dp(execution.list_steps())    \n",
    "    execution.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_cache:\n",
    "    dp(execution.list_steps())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 정리 작업\n",
    "\n",
    "#### 아티펙트 경로 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_proc_artifact(execution, client, kind=0):\n",
    "    '''\n",
    "    kind: 0 --> train\n",
    "    kind: 2 --> test\n",
    "    '''\n",
    "    response = execution.list_steps()\n",
    "\n",
    "    proc_arn = response[-1]['Metadata']['ProcessingJob']['Arn'] # index -1은 가장 처음 실행 step\n",
    "    #proc_arn = response[-1]['Metadata']\n",
    "    # print(\"proc_arn: \", proc_arn)\n",
    "    proc_job_name = proc_arn.split('/')[-1]\n",
    "    print(\"proc_job_name: \", proc_job_name)\n",
    "    \n",
    "    response = client.describe_processing_job(ProcessingJobName = proc_job_name)\n",
    "    test_preprocessed_file = response['ProcessingOutputConfig']['Outputs'][kind]['S3Output']['S3Uri'] # index 1: test 파일    \n",
    "    print(\"test_preprocessed_file: \\n \", test_preprocessed_file)\n",
    "    \n",
    "    return test_preprocessed_file\n",
    "\n",
    "import boto3\n",
    "client = boto3.client(\"sagemaker\")\n",
    "\n",
    "test_preproc_dir_artifact = get_proc_artifact(execution, client, kind=1 )\n",
    "train_preproc_dir_artifact = get_proc_artifact(execution, client, kind=0 )\n",
    "\n",
    "#print(\"test_preproc__dir_artifact: \", test_preproc_dir_artifact)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store test_preproc_dir_artifact\n",
    "%store train_preproc_dir_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
