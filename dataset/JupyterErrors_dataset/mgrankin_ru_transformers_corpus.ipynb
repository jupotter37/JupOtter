{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "corpus.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Rl_q51Sm2vBh",
        "LpOckVwMevdh",
        "BO9ngT11evfA",
        "kQtmmHf4evfx"
      ],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cb618f20c7964d11a7f55c20ff53ddb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1f8f0921270b4d9d87fbc6b2046543d9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fe1db8fc144641fc95d030c49be2ceea",
              "IPY_MODEL_4ee8131635904188a9ee433ec69fb304"
            ]
          }
        },
        "1f8f0921270b4d9d87fbc6b2046543d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe1db8fc144641fc95d030c49be2ceea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a646b45c6064e1caf2dd1256424bfb2",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e5e2d7e1a6241dda1874764965bb36c"
          }
        },
        "4ee8131635904188a9ee433ec69fb304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_12ab7454c50f4ef69045d6c98faacc87",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:00&lt;00:00,  3.17it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9bc37e75c8d248aa9ea40fe2d20c81d0"
          }
        },
        "6a646b45c6064e1caf2dd1256424bfb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e5e2d7e1a6241dda1874764965bb36c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12ab7454c50f4ef69045d6c98faacc87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9bc37e75c8d248aa9ea40fe2d20c81d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9Jttgd8evcI",
        "colab_type": "text"
      },
      "source": [
        "# Russian language dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqpAlCYkxe9e",
        "colab_type": "text"
      },
      "source": [
        "First, install all prerequisites. In order to convert you need to get the conversion xsl from here: https://github.com/mgrankin/ru_transformers/blob/master/corpus/FB2_2_txt.xsl and put it in the root folder. Otherwise, you will get empty txts as result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyM4bYZgevcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install langdetect tqdm\n",
        "!pip install \"tqdm==4.43.0\"\n",
        "!sudo apt-get install -y xsltproc\n",
        "from fastai.basics import *\n",
        "from tqdm import *\n",
        "from tqdm.contrib.concurrent import process_map, thread_map\n",
        "from multiprocessing import Pool\n",
        "import regex as re\n",
        "import time\n",
        "from langdetect import detect\n",
        "from langdetect.lang_detect_exception import LangDetectException\n",
        "\n",
        "NEW_LINE = '<|n|>'\n",
        "\n",
        "librusec = '/home/u/nas/librusec/lib.rus.ec'\n",
        "tmpzips = './tmp/zip'\n",
        "tmptxt = './tmp/txt'\n",
        "tmpfb2clean = './tmp/fb2clean'\n",
        "tmpfb2unzip = './tmp/fb2unzip'\n",
        "data = Path('../data/full')\n",
        "\n",
        "!curl -LJO https://raw.githubusercontent.com/mgrankin/ru_transformers/master/corpus/FB2_2_txt.xsl",
        "\n",
        "!mkdir ../data\n",
        "!mkdir ../data/full\n",
        "!mkdir ../data/classic\n",
        "!mkdir tmp\n",
        "!mkdir tmp/fb2unzip\n",
        "!mkdir tmp/fb2clean\n",
        "!mkdir tmp/txt\n",
        "!mkdir tmp/zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfsNWkxOevcy",
        "colab_type": "text"
      },
      "source": [
        "### Unpack ZIPs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWZmL9zGsljA",
        "colab_type": "text"
      },
      "source": [
        "Before running this we need to upload our fb2 zip files to /tmp/zip and then run this script"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u1sPX302-Vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean the output directory \n",
        "!rm -rfv {tmpfb2unzip + '/*'}"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb9jDGqTevcz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "cb618f20c7964d11a7f55c20ff53ddb6",
            "1f8f0921270b4d9d87fbc6b2046543d9",
            "fe1db8fc144641fc95d030c49be2ceea",
            "4ee8131635904188a9ee433ec69fb304",
            "6a646b45c6064e1caf2dd1256424bfb2",
            "9e5e2d7e1a6241dda1874764965bb36c",
            "12ab7454c50f4ef69045d6c98faacc87",
            "9bc37e75c8d248aa9ea40fe2d20c81d0"
          ]
        },
        "outputId": "5ea921c8-8741-49bf-ef24-3af009501030"
      },
      "source": [
        "zips = get_files(tmpzips, '.zip')\n",
        "print(f'{len(zips)} zip file(s) found')\n",
        "\n",
        "def unpack(fn):\n",
        "    # replace -o with -n to not overwrite existing files\n",
        "    # remove the -q flag for more logging\n",
        "    # -j  junk paths (do not make directories)  \n",
        "    # -qo flag to remove annoying warning https://www.directadmin.com/features.php?id=2213\n",
        "    !unzip -qq -joL -qo -O cp396 {fn} -d {tmpfb2unzip} >>/dev/null\n",
        "\n",
        "# Unpack zips in parallel\n",
        "thread_map(unpack, zips, max_workers=64)\n",
        "print(f'Unzipped all - DONE')\n",
        "\n",
        "# Sanitize file and folder names - remove spaces\n",
        "!find $tmp -depth -name \"* *\" -execdir rename 's/ /_/g' \"{}\" \\;"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 zip file(s) found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cb618f20c7964d11a7f55c20ff53ddb6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Unzipped all\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axX-uz4EevdM",
        "colab_type": "text"
      },
      "source": [
        "### Convert fb2 to txt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcbAxHyL2sYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean the output directory \n",
        "!rm -rfv {tmpfb2clean + '/*'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCY0yEsX20Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clean the output directory \n",
        "!rm -rfv {tmptxt + '/*'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oQ0Ot4BevdN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get fb2s\n",
        "fbs = get_files(tmpfb2unzip, '.fb2', recurse=True)\n",
        "\n",
        "# Sanitize filenames and move to the 'clean' dir\n",
        "for fn in fbs:\n",
        "    nn = (str(fn.name)\n",
        "        .replace(' ','')\n",
        "        .replace('_quot;','')\n",
        "        .replace('!','')\n",
        "        .replace(',','')\n",
        "        .replace('(','')\n",
        "        .replace(')','')\n",
        "        .replace('\\xa0','')\n",
        "        .replace('.','')\n",
        "        .replace('fb2', '.fb2')\n",
        "         )\n",
        "    shutil.move(fn, f'{tmpfb2clean}/{nn}')\n",
        "print(f'{len(fbs)} fb2(s) sanitized')\n",
        "\n",
        "# In order to convert you need to get the conversion xsl from here:\n",
        "# https://github.com/mgrankin/ru_transformers/blob/master/corpus/FB2_2_txt.xsl\n",
        "# and put it in the root folder\n",
        "def convert_fb2(fn):\n",
        "    #!xsltproc FB2_2_txt.xsl {fn} > {str(fn).replace(' ', '').replace('.fb2','.txt').replace('/fb2','/txt')} 2>>/dev/null\n",
        "    !xsltproc FB2_2_txt.xsl {fn} > {tmptxt + '/' + fn.name.replace('fb2', 'txt')} 2>>/dev/null\n",
        "    return {fn}\n",
        "\n",
        "# Get fb2s from the clean snitized dir\n",
        "fbs = get_files(tmpfb2clean, '.fb2')\n",
        "\n",
        "# convert all to .txt\n",
        "thread_map(convert_fb2, fbs, max_workers=64)\n",
        "print('FB2(s) conversion done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIuco_8a1I-4",
        "colab_type": "text"
      },
      "source": [
        "### Filter and concat txt files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puHJbvlq1SIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txts = get_files('./tmp/txt', '.txt')\n",
        "print(f'Found {len(txts)} txt(s)')\n",
        "\n",
        "# this will take time, bcs langdetect fails on multithreading\n",
        "print('Running langdetect . . . ')\n",
        "for fn in progress_bar(txts):\n",
        "    with open(f'./{fn}', 'r') as f:\n",
        "        lines = f.read()\n",
        "        print(f)\n",
        "        print(fn)\n",
        "        print(len(lines))\n",
        "        try:\n",
        "            if len(lines) > 1e+4 and detect(lines) == 'ru':\n",
        "                with open(f'{data}/{fn.name}', 'w') as c:\n",
        "                    c.write(lines)\n",
        "        except LangDetectException as e:\n",
        "            pass\n",
        "\n",
        "# Add space before each word. It's not really nesessary. \n",
        "# It just makes encoding a bit more meaningful to the model and the text smaller(after encoding).\n",
        "print('Running text sanitization . . . ')\n",
        "def process_fn(fn):\n",
        "    match = re.compile(r'(?=[^ ])([\\W])([\\w])')\n",
        "    match2 = re.compile('(.|\\s)\\\\1\\\\1+')\n",
        "    with open(fn, 'r') as f:\n",
        "        lines = f.read()\n",
        "    if lines and lines[0] != ' ': lines = ' ' + lines\n",
        "    lines = match.sub(r'\\g<1> \\g<2>', lines)\n",
        "    lines = match2.sub(r'\\1'*3, lines)\n",
        "    with open(fn, 'w') as c:\n",
        "        c.write(lines)\n",
        "        \n",
        "thread_map(process_fn, txts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ612AmS2B5K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txts = get_files(data, '.txt'); \n",
        "print(f'Amount of txt(s): {len(txts)}')\n",
        "\n",
        "fsorted = get_files('../data/classic', '.txt') + sorted(txts, key=lambda fn: os.path.getsize(fn))\n",
        "\n",
        "print('Building text corpus')\n",
        "sz=0\n",
        "with open('./tmp/russian_corpus_for_vocab.txt', 'w') as c:\n",
        "    for fn in fsorted:\n",
        "        with open(fn, 'r') as f:\n",
        "            sz += c.write(f.read().replace('\\n', f' {NEW_LINE} ') + '\\n')\n",
        "            if sz > 5e+9:\n",
        "                break\n",
        "print('Done ./tmp/russian_corpus_for_vocab.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do8mJhK82iHp",
        "colab_type": "text"
      },
      "source": [
        "Now a text corpus can be collected from ./tmp/russian_corpus_for_vocab.txt to use with gpt-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl_q51Sm2vBh",
        "colab_type": "text"
      },
      "source": [
        "## Historical workbook\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpOckVwMevdh",
        "colab_type": "text"
      },
      "source": [
        "### more data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hki075J3evdj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c6012fe1-f997-4603-dc0b-11f27d2b019e"
      },
      "source": [
        "!rm -R /share/CE_CACHEDEV1_DATA/data/classic_lit/*\n",
        "!cp -R /share/CE_CACHEDEV1_DATA/data/downloads/txt /share/CE_CACHEDEV1_DATA/data/classic_lit/"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/share/CE_CACHEDEV1_DATA/data/classic_lit/*': No such file or directory\n",
            "cp: cannot stat '/share/CE_CACHEDEV1_DATA/data/downloads/txt': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "an7ff5lcevdr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be8d2aa9-8462-410c-b15c-5c50ac82f4a2"
      },
      "source": [
        "fbs = get_files('/home/u/nas/classic_lit/txt/', '.fb2', recurse=True); len(fbs)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmkgZ3M1evdu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a030d03c-3746-4ada-b209-8b6aaac34c1f"
      },
      "source": [
        "!rm -R /home/u/nas/classic_lit/out"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/home/u/nas/classic_lit/out': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFg_SqN0evd1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "97835324-b490-4980-b273-aaf54f4d2c43"
      },
      "source": [
        "path_out = Path('/home/u/nas/classic_lit/out'); path_out.mkdir(exist_ok = True)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-bfd493a3dc54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpath_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/u/nas/classic_lit/out'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mpath_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexist_ok\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.6/pathlib.py\u001b[0m in \u001b[0;36mmkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1246\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparents\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/pathlib.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(pathobj, *args)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/u/nas/classic_lit/out'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGSadcrNevd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for fn in fbs:\n",
        "    nn = (str(fn.name)\n",
        "        .replace(' ','.')\n",
        "        .replace('_quot;','.')\n",
        "        .replace('!','.')\n",
        "        .replace(',','.')\n",
        "        .replace('(','.')\n",
        "        .replace(')','.')\n",
        "        .replace('\\xa0','.')\n",
        "         )\n",
        "    shutil.move(fn, path_out/nn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72pfrvmkevd-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fbs = get_files(path_out, '.fb2'); len(fbs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W05gSPjGeveE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm ../data/classic/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1qCeHKXeveJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = Path('../data/classic')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ae5_j5XeveM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_fb2(fn):\n",
        "    name = str(fn.name).replace('.fb2','.txt')\n",
        "    !xsltproc FB2_2_txt.xsl {fn} > {data/name} 2>>/dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8vpXjNBeveR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for _ in progress_bar(Pool(64).imap_unordered(convert_fb2, fbs), len(fbs)):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIviSH8IeveY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm ../data/classic/*месяцеслов*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8owOhU6Heveg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir ../data/classic/valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hoRiwtMeven",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mv ../data/classic/Tolstoy_Dva_pisma_k_M_Gandi.56185.txt ../data/classic/valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4a3btKSevev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mv ../data/classic/Tolstoy_Sobranie_sochineniy_v_dvadtsati_dvuh_tomah_22_Tom_22._Izbrannyie_dnevniki_1895-1910.142868.txt ../data/classic/valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ960U6Oeve5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mv ../data/classic/Tolstoy_Sobranie_sochineniy_v_dvadtsati_dvuh_tomah_20_Tom_20._Izbrannyie_pisma_1900-1910.142866.txt ../data/classic/valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO9ngT11evfA",
        "colab_type": "text"
      },
      "source": [
        "### filter txts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nlnHHhnevfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txts = get_files('./tmp/txt', '.txt')\n",
        "print(f'Found {len(txts)} txt(s)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOo8JeN2evfK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test\n",
        "fn = txts[0]\n",
        "match = re.compile('(.|\\s)\\\\1\\\\1+')\n",
        "with open(fn, 'r') as f:\n",
        "    lines = f.read()\n",
        "lines = 'asdf aaaa dddddfffff' + lines\n",
        "lines = match.sub(r'\\1'*3, lines)             \n",
        "lines[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCwGdb2SevfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test\n",
        "detect(lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHmAOG3kevfR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test\n",
        "expr = re.compile('([^\\n]{150,})([.] )([^\\n]{150,})')\n",
        "while expr.search(lines):\n",
        "    lines = expr.sub(r'\\g<1>.\\n\\g<3>', lines, 1)\n",
        "lines[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "JKZEYY96evfX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this will take time, bcs langdetect fails on multithreading\n",
        "for fn in progress_bar(txts):\n",
        "    with open(f'./{fn}', 'r') as f:\n",
        "        lines = f.read()\n",
        "        print(f)\n",
        "        print(fn)\n",
        "        print(len(lines))\n",
        "        try:\n",
        "            if len(lines) > 1e+4 and detect(lines) == 'ru':\n",
        "                with open(f'{data}/{fn.name}', 'w') as c:\n",
        "                    c.write(lines)\n",
        "        except LangDetectException as e:\n",
        "            pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfsMrxfzevfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txts = get_files(data, '.txt')\n",
        "print(txts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg4a8qQievfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txts += ['../data/poetry_base.txt']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTu9VRYUevfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txts += get_files('../data/classic', '.txt', recurse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqND_JDKevfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add space before each word. It's not really nesessary. \n",
        "# It just makes encoding a bit more meaningful to the model and the text smaller(after encoding).\n",
        "\n",
        "def process_fn(fn):\n",
        "    match = re.compile(r'(?=[^ ])([\\W])([\\w])')\n",
        "    match2 = re.compile('(.|\\s)\\\\1\\\\1+')\n",
        "    with open(fn, 'r') as f:\n",
        "        lines = f.read()\n",
        "    if lines and lines[0] != ' ': lines = ' ' + lines\n",
        "    lines = match.sub(r'\\g<1> \\g<2>', lines)\n",
        "    lines = match2.sub(r'\\1'*3, lines)\n",
        "    with open(fn, 'w') as c:\n",
        "        c.write(lines)\n",
        "        \n",
        "thread_map(process_fn, txts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIqCH20Pevfq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('../data/poetry_base.txt', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "    \n",
        "split = int(len(lines)*0.95)\n",
        "\n",
        "with open('../data/poetry_dry.txt', 'w') as f:\n",
        "    f.writelines(lines[:split])\n",
        "\n",
        "with open('../data/poetry_eval.txt', 'w') as f:\n",
        "    f.writelines(lines[split:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQtmmHf4evfx",
        "colab_type": "text"
      },
      "source": [
        "### concat for vocab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJm_suk3evfx",
        "colab_type": "text"
      },
      "source": [
        "Take smallest files to increase word diversity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wacmgVLQevfy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txts = get_files(data, '.txt'); \n",
        "print(f'Amount of txt(s): {len(txts)}')\n",
        "\n",
        "for fn in txts:\n",
        "    if os.path.getsize(fn) <= 1e+3: \n",
        "        os.remove(fn)\n",
        "\n",
        "txts = get_files(data, '.txt'); \n",
        "print(f'Amount of txt(s): {len(txts)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5S_pgL-evf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fsorted = get_files('../data/classic', '.txt') + sorted(txts, key=lambda fn: os.path.getsize(fn))  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q47SJJyYevgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sz=0\n",
        "with open('./tmp/russian_corpus_for_vocab.txt', 'w') as c:\n",
        "    for fn in fsorted:\n",
        "        with open(fn, 'r') as f:\n",
        "            sz += c.write(f.read().replace('\\n', f' {NEW_LINE} ') + '\\n')\n",
        "            if sz > 5e+9:\n",
        "                break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdkNamXdevgI",
        "colab_type": "text"
      },
      "source": [
        "### cache tokenization (optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dSxS7_VevgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os,sys,inspect\n",
        "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
        "parentdir = os.path.dirname(currentdir)\n",
        "sys.path.insert(0,parentdir) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D49B7UlLevgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from run_lm_finetuning import TextDataset\n",
        "from yt_encoder import YTEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKyVzGUtevgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "txts = get_files(data, '.txt'); len(txts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wB6cIV9wevgg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cache_fn(fn):\n",
        "    tokenizer = YTEncoder.from_pretrained('../bpe/yt.model')\n",
        "    TextDataset.process_file(fn, tokenizer, 1024, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4JCw8ykevgj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for _ in progress_bar(Pool(32).imap_unordered(cache_fn, txts), len(txts)):\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02-nJdymevgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDJ5oygzevgs",
        "colab_type": "text"
      },
      "source": [
        "# Prepare cached dataset for upload (for GCloud)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwwcel9Mevgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = get_files('upload', '.txt', True); len(files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH_PocUFevgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files = [item for item in files if '/full' in str(item) and '/cached' not in str(item)]; len(files)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Hvi_nytevgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for item in files:\n",
        "    with open(item, 'w'):\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAJnAXmzevg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
