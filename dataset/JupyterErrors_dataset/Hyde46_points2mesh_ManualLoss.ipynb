{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import tensorflow as tf\n",
    "import cPickle as pickle\n",
    "from cd_dist import *\n",
    "from Arrow3D import *\n",
    "from scipy import spatial\n",
    "import os\n",
    "from mayavi import mlab\n",
    "from mayavi.mlab import *\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_ellipsoid = '/home/heid/Documents/master/pc2mesh/points2mesh/utils/ellipsoid/'\n",
    "path_point_cloud_data = '/home/heid/Documents/master/pc2mesh/point_cloud_data/big/'\n",
    "path_mesh_output = '/home/heid/Documents/master/pc2mesh/points2mesh/manual_loss/figures/'\n",
    "path_to_plots = '/home/heid/Documents/master/pc2mesh/points2mesh/manual_loss/figures/tmp/'\n",
    "movie_folder = '/home/heid/Documents/master/pc2mesh/points2mesh/manual_loss/figures/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loss functions for gradient descent calculations\n",
    "\n",
    "def unit(tensor):\n",
    "    return tf.nn.l2_normalize(tensor, axis=1)\n",
    "# Define loss functions\n",
    "def laplace_coord(pred, lape_idx, block_id):\n",
    "    vertex = tf.concat([pred, tf.zeros([1,3])], 0)\n",
    "    indices = lape_idx[block_id - 1][:, :8]\n",
    "    weights = tf.cast(lape_idx[block_id - 1][:, -1], tf.float32)\n",
    "    \n",
    "    weights = tf.tile(tf.reshape(tf.reciprocal(weights), [-1, 1]), [1,3])\n",
    "    laplace = tf.reduce_sum(tf.gather(vertex, indices), 1)\n",
    "    laplace = tf.subtract(pred, tf.multiply(laplace, weights))\n",
    "    return laplace\n",
    "\n",
    "def laplace_loss(pred1, pred2, lape_idx, block_id=1):\n",
    "    lap1 = laplace_coord(pred1, lape_idx, block_id)\n",
    "    lap2 = laplace_coord(pred2, lape_idx, block_id)\n",
    "    \n",
    "    l_loss = tf.reduce_mean(tf.reduce_sum(tf.square(tf.subtract(lap1,lap2)),1)) * 1500\n",
    "    \n",
    "    move_loss = tf.reduce_mean(tf.reduce_sum(tf.square(tf.subtract(pred1, pred2)), 1)) * 100\n",
    "    move_loss = tf.cond(tf.equal(block_id,1), lambda:0., lambda:move_loss)\n",
    "    return l_loss + move_loss\n",
    "\n",
    "def pseudo_chamfer_loss(pred, positions):\n",
    "    gt_pt = positions\n",
    "    dist1, idx1, dist2, idx2 = nn_distance(gt_pt, pred)\n",
    "#     point_loss = (tf.reduce_mean(dist1) + 0.55 * tf.reduce_mean(dist2)) * 3000\n",
    "    point_loss = (0.55 * tf.reduce_mean(dist1) + 1 * tf.reduce_mean(dist2)) * 3000\n",
    "    return point_loss\n",
    "    \n",
    "def edge_length_loss(pred,edges,block_id=1):\n",
    "    nod1 = tf.gather(pred, edges[block_id  - 1][:, 0], axis=0)\n",
    "    nod2 = tf.gather(pred, edges[block_id  - 1][:, 1], axis=0)\n",
    "    edge = tf.subtract(nod1 , nod2 )\n",
    "    edge_length = tf.reduce_sum(tf.square(edge), 1)\n",
    "    edge_loss = tf.reduce_mean(edge_length) * 300\n",
    "#     print edge_loss.shape\n",
    "    return edge_loss\n",
    "    \n",
    "def normal_cosine_loss(gt_pt,gt_nm,pred,edges, block_id = 1):\n",
    "    nod1 = tf.gather(pred, edges[block_id  - 1][:, 0], axis=0)\n",
    "    nod2 = tf.gather(pred, edges[block_id  - 1][:, 1], axis=0)\n",
    "    edge = tf.subtract(nod1 , nod2 )\n",
    "    \n",
    "    dist1, idx1, dist2, idx2 = nn_distance(gt_pt, pred)\n",
    "    normal = tf.gather(gt_nm, tf.squeeze(idx2,0))\n",
    "    normal = tf.gather(normal, edges[block_id  - 1][:, 0])\n",
    "    cosine = tf.abs(tf.reduce_sum(tf.multiply(unit(normal), unit(edge)), 1))\n",
    "    normal_loss = tf.reduce_mean(cosine) * 0.5\n",
    "    \n",
    "    return normal_loss\n",
    "\n",
    "def inverse_density_loss(pred):\n",
    "    _,distances = python_knn_bruteforce(pred,8)\n",
    "    distances = tf.convert_to_tensor(distances[0], dtype=tf.float32)\n",
    "    max_d = tf.reduce_max(distances)\n",
    "    point_loss = tf.reduce_mean(tf.subtract(max_d, distances))\n",
    "    return point_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpool(inputs,pool_idx,block_id=1):\n",
    "    block_pool_idx = pool_idx[block_id - 1]\n",
    "    X = inputs\n",
    "    add_feat = (1 / 2.0) * tf.reduce_sum(tf.gather(X, block_pool_idx), 1)\n",
    "    outputs = tf.concat([X, add_feat], 0)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_support_to_tensor(to_convert):\n",
    "    indices = tf.convert_to_tensor(to_convert[0], dtype=tf.int64)\n",
    "    values = tf.convert_to_tensor(to_convert[1], dtype=tf.float32)\n",
    "    d_shape = tf.convert_to_tensor(to_convert[2], dtype=tf.int64)\n",
    "    return tf.SparseTensor(indices, values=values, dense_shape=d_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(vertices,output,pc,prefix,num=1):\n",
    "    vert = np.hstack((np.full([vertices.shape[0], 1], 'v'), vertices))\n",
    "    face = np.loadtxt(path_to_ellipsoid+'face'+str(num)+'.obj', dtype='|S32')\n",
    "    mesh = np.vstack((vert,face))\n",
    "    \n",
    "    result_name=pc.replace(\".txt\", \"_result_p\"+str(num)+\".obj\")\n",
    "    result_name = prefix+result_name\n",
    "    path_to_mesh = os.path.join(output, result_name)\n",
    "\n",
    "    np.savetxt(output, mesh, fmt='%s', delimiter=' ')\n",
    "    print \"Saved to {}\".format(output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_pc(points):\n",
    "    mean_points = np.mean(points,axis=0)\n",
    "    points = points - mean_points\n",
    "    max_val = np.max(np.abs(points)) *3\n",
    "    return points / max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ellipsoid():\n",
    "    # Load Ellipsoid\n",
    "    placeholders = {}\n",
    "    pkl = pickle.load(open(path_to_ellipsoid+'info_ellipsoid.dat', 'rb'))\n",
    "    coord = normalize_pc(pkl[0])\n",
    "    #coord = pkl[0]\n",
    "    \n",
    "    pool_idx = pkl[4]\n",
    "    faces = pkl[5]\n",
    "    lape_idx = pkl[7]\n",
    "    edges = []\n",
    "    for i in range(1, 4):\n",
    "        adj = pkl[i][1]\n",
    "        edges.append(adj[0])\n",
    "    for i in range(0,3):\n",
    "        lape_idx[i] = np.array(lape_idx[i])\n",
    "        lape_idx[i][lape_idx[i] == -1 ] = np.max(lape_idx[i]) + 1\n",
    "    neighbors = [[],[],[],]\n",
    "    neighbors[0] = [ [] for i in range(156) ]\n",
    "    neighbors[1] = [ [] for i in range(618) ]\n",
    "    neighbors[2] = [ [] for i in range(2466) ]\n",
    "    i = 0\n",
    "    for e in edges:\n",
    "        for p in e:\n",
    "            if p[0] == p[1]:\n",
    "                continue\n",
    "            neighbors[i][p[0]].append(p[1])\n",
    "        i = i + 1\n",
    "    \n",
    "    placeholders[\"coord\"] = coord\n",
    "    placeholders[\"tCoord\"] = tf.convert_to_tensor(coord, dtype=tf.float32)\n",
    "    placeholders[\"support1\"] = [ convert_support_to_tensor(s) for s in pkl[1]]\n",
    "    placeholders[\"support2\"] = [ convert_support_to_tensor(s) for s in pkl[2]]\n",
    "    placeholders[\"support3\"] = [ convert_support_to_tensor(s) for s in pkl[3]]\n",
    "    placeholders[\"faces\"] = [tf.convert_to_tensor(f, dtype=tf.int32) for f in faces ]\n",
    "    placeholders[\"edges\"] = [tf.convert_to_tensor(e, dtype=tf.int32) for e in edges ]\n",
    "    placeholders[\"lape_idx\"] = [tf.convert_to_tensor(l, dtype=tf.int32) for l in lape_idx ]\n",
    "    placeholders[\"pool_idx\"] = [tf.convert_to_tensor(p, dtype=tf.int32) for p in pool_idx ]\n",
    "    placeholders[\"neighbors\"] = neighbors\n",
    "    return placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gt():\n",
    "    # Load Object to compare Ellipsoid to\n",
    "    #path_to_object = '/home/heid/Documents/master/pc2mesh/point_cloud_data/big/airplane_0396.txt'\n",
    "    path_to_object = path_point_cloud_data+'airplane_0616.txt'\n",
    "    #path_to_object = '/home/heid/Documents/master/pc2mesh/point_cloud_data/big/sofa_0262.txt'\n",
    "    airplane = np.loadtxt(path_to_object, delimiter=',', dtype =np.float32 )[0:1024]\n",
    "    gt_pos = airplane[:,0:3]\n",
    "    gt_norm = airplane[:,3:6]\n",
    "    #mesh_loss(tCoord, gt_pos, gt_norm, edges)\n",
    "    #pseudo_chamfer_loss(tCoord, gt_pos)\n",
    "    return [gt_pos,gt_norm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mesh(vertices,block_id=1):\n",
    "    vert = np.hstack((np.full([vertices.shape[0], 1], 'v'), vertices))\n",
    "    face = np.loadtxt(path_to_ellipsoid+'face'+str(block_id)+'.obj', dtype='|S32')\n",
    "    mesh = np.vstack((vert, face))\n",
    "    \n",
    "    result_name = path_mesh_output+\"_\"+str(block_id)+\"_pred.obj\"\n",
    "    np.savetxt(result_name, mesh, fmt='%s', delimiter=' ')\n",
    "    return result_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points(gt_pos, temp_coord, gradients,name,save_figure,show_figure,iteration=0,block_id=1):\n",
    "    # Plot with mayavi\n",
    "#     mlab.figure(bgcolor=(0,0,0),size=(1280,720))\n",
    "\n",
    "    num_v = [156,618,2466]\n",
    "    mlab.figure(bgcolor=(1,1,1))\n",
    "    \n",
    "    mlab.points3d(gt_pos[:,0], gt_pos[:,1], gt_pos[:,2],color=(0,1,0),scale_factor=0.02)\n",
    "    #mlab.points3d(coord[:,0], coord[:,1], coord[:,2],color=(1,0,0),scale_factor=0.01)\n",
    "    #mlab.points3d(temp_coord[:,0], temp_coord[:,1], temp_coord[:,2],color=(1,0,0),scale_factor=0.09)\n",
    "    \n",
    "    mesh_path = create_mesh(temp_coord,block_id)\n",
    "    mesh_txt = np.loadtxt(mesh_path, dtype='|S32')\n",
    "    mesh_vertices = np.delete(mesh_txt[:num_v[block_id-1]],0,1)\n",
    "    mesh_faces = np.delete(mesh_txt[num_v[block_id-1]:],0,1).astype(int)\n",
    "    mesh_faces = mesh_faces - 1\n",
    "    x = mesh_vertices[:,0].astype(float)\n",
    "    y = mesh_vertices[:,1].astype(float)\n",
    "    z = mesh_vertices[:,2].astype(float)\n",
    "\n",
    "    f = mlab.gcf()\n",
    "    m = mlab.triangular_mesh(x,y,z,mesh_faces,opacity=0.5)\n",
    "    \n",
    "    u = gradients[:,0]\n",
    "    v = gradients[:,1]\n",
    "    w = gradients[:,2]\n",
    "    # Define quiver arrows\n",
    "    #obj = mlab.quiver3d(x, y, z, u, v, w, line_width=5, scale_factor=1)\n",
    "#     m.enable_contours = True\n",
    "#     m.contour.number_of_contours = 35\n",
    "#     m.actor.actor.rotate_y(iteration*2)\n",
    "#     m.actor.actor.rotate_z(iteration*2)\n",
    "#     m.actor.actor.rotate_z((360.0/50.0)*iteration)\n",
    "#     camera = f.scene.camera\n",
    "#     camera.yaw()\n",
    "#     camera.pitch(iteration*0.1)\n",
    "    if save_figure:\n",
    "        mlab.savefig(path_to_plots+name+'.png',figure=f, magnification=1)\n",
    "        mlab.close()\n",
    "    if show_figure:\n",
    "        mlab.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_movie(name): \n",
    "    video_name = movie_folder+name+'.avi'\n",
    "    images = [img for img in os.listdir(path_to_plots) if img.endswith(\".png\")]\n",
    "    im_reverse = images[::-1]\n",
    "    images.extend(im_reverse)\n",
    "    frame = cv2.imread(os.path.join(path_to_plots, images[0]))\n",
    "    height, width, layers = frame.shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    video = cv2.VideoWriter(video_name, fourcc, 30.0,frameSize=(width,height))\n",
    "\n",
    "    for image in images:\n",
    "        video.write(cv2.imread(os.path.join(path_to_plots, image)))\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "tf.set_random_seed(666)\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gt_pos,gt_norm = load_gt()\n",
    "placeholders = load_ellipsoid()\n",
    "features = placeholders[\"tCoord\"]\n",
    "\n",
    "step_size = 3e-3\n",
    "\n",
    "ellipsoid = placeholders[\"coord\"]\n",
    "temp_coord = placeholders[\"coord\"]\n",
    "\n",
    "#plot_points(gt_pos,temp_coord,\"fig_\"+str(0),True,False)\n",
    "# for i in range(0,5):\n",
    "num_v = [156,618,2466]\n",
    "features = tf.convert_to_tensor(temp_coord, dtype=tf.float32)\n",
    "prev = gt_pos\n",
    "for block_id in range(1, 2):\n",
    "    for i in range(1,2):\n",
    "        #gradient_total = tf.gradients(mesh_loss(features,gt_pos,gt_norm, edges),features,aggregation_method=tf.AggregationMethod.ADD_N)\n",
    "        \n",
    "        gradient_chamfer = tf.gradients(pseudo_chamfer_loss(features,gt_pos),features) \n",
    "        gradient_laplace = tf.gradients(laplace_loss(ellipsoid, features,placeholders[\"lape_idx\"],\n",
    "                                                    block_id=block_id),features)\n",
    "        gradient_normal = tf.gradients(\n",
    "                           normal_cosine_loss(gt_pos,gt_norm,features,\n",
    "                                            placeholders[\"edges\"],block_id=block_id),\n",
    "                            features)\n",
    "\n",
    "        gradients_chamfer_156 = sess.run(gradient_chamfer)[0]\n",
    "        gradients_laplace_156 = sess.run(gradient_laplace)[0]\n",
    "        gradients_normal_156 = sess.run(gradient_normal)[0]\n",
    "        res_indices = np.zeros([num_v[block_id - 1],3])\n",
    "        \n",
    "        for j in range(0,gradients_chamfer_156.shape[0]):\n",
    "            n = placeholders[\"neighbors\"][block_id-1][j] \n",
    "            res_indices[j] += gradients_chamfer_156[j]\n",
    "            res_indices[n] += 0.2*gradients_chamfer_156[j]\n",
    "\n",
    "        for j in range(0,gradients_laplace_156[0].shape[0]):\n",
    "            res_indices[gradients_laplace_156[1][j]] += gradients_laplace_156[0][j]\n",
    "        for k in range(0,gradients_normal_156[0].shape[0]):\n",
    "            res_indices[gradients_normal_156[1][k]] += gradients_normal_156[0][k]\n",
    "\n",
    "        prev_coord = temp_coord\n",
    "        temp_coord = temp_coord - res_indices * step_size\n",
    "        features = tf.convert_to_tensor(temp_coord, dtype=tf.float32)\n",
    "\n",
    "        plot_points(gt_pos,prev_coord,res_indices*-1.0*step_size,\"fig_\"+str(block_id)+\"_\"+str(i),True,False,i,block_id)\n",
    "\n",
    "    #plot_points(gt_pos,prev_coord,res_indices*-1.0*step_size,\"fig_\"+str(i),False,True,51)\n",
    "    if block_id < 3:\n",
    "        features= unpool(features, placeholders[\"pool_idx\"], block_id)\n",
    "    prev = temp_coord\n",
    "    temp_coord = sess.run(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gradient_edge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-0d15570a7115>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_edge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gradient_edge' is not defined"
     ]
    }
   ],
   "source": [
    "ret = sess.run(gradient_edge)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_movie(\"plane\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_arrow3d():\n",
    "    # Plot with Arrow3D\n",
    "    # Generate some example data\n",
    "\n",
    "    ################################\n",
    "    #plotting\n",
    "    ################################    \n",
    "    fig = plt.figure(figsize=(15,15))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    ax.plot(gt_pos[:,0], gt_pos[:,1], gt_pos[:,2], '.', markersize=5, color='g', alpha=0.5)\n",
    "    ax.plot(coord[:,0], coord[:,1], coord[:,2], '.', markersize=3, color='b', alpha=0.9)\n",
    "    ax.plot(temp_coord[:,0], temp_coord[:,1], temp_coord[:,2], '.', markersize=5, color='r', alpha=0.9)\n",
    "    #x.plot(new_coord_edge[:,0], new_coord_edge[:,1], new_coord_edge[:,2], '.', markersize=5, color='r', alpha=0.9)\n",
    "    '''\n",
    "    for v in eig_vec:\n",
    "    #ax.plot([mean_x,v[0]], [mean_y,v[1]], [mean_z,v[2]], color='red', alpha=0.8, lw=3)\n",
    "    #I will replace this line with:\n",
    "    a = Arrow3D([mean_x, v[0]], [mean_y, v[1]], \n",
    "                [mean_z, v[2]], mutation_scale=20, \n",
    "                lw=3, arrowstyle=\"-|>\", color=\"r\")\n",
    "    ax.add_artist(a)\n",
    "    '''\n",
    "    ax.set_xlabel('x_values')\n",
    "    ax.set_ylabel('y_values')\n",
    "    ax.set_zlabel('z_values')\n",
    "\n",
    "    #plt.title('Eigenvectors')\n",
    "\n",
    "    plt.draw()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
