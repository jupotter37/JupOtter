{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for connection file: ~/.ipython/profile_default/security/ipcontroller-ippdpp_c-client.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connecting to ipyparallel cluster......."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing torch distributed group with GPUs [0, 1, 2]\n",
      "Local Ranks initialized:  ['GPU0=0', 'GPU1=1', 'GPU2=2']\n",
      "Importing on cluster: ['import fastai, fastai.torch_core, torch, fastprogress', 'from fastai.distributed import *', 'from ippddp.ddipp.fastai_v1 import initializer, finalizer, set_verbose, lr_find_bypass']\n",
      "fastai_v1:\n",
      "[Process 19239] Rank 0 fastai initialized for distributed data parallel.\n",
      "[Process 19243] Rank 1 fastai initialized for distributed data parallel.\n",
      "[Process 19244] Rank 2 fastai initialized for distributed data parallel.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%load_ext Ddip\n",
    "%makedip -g all -a fastai_v1 --verbose True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip everywhere: Running cell in local namespace.\n",
      "%%dip everywhere: Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n"
     ]
    }
   ],
   "source": [
    "%%dip everywhere\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's download the dataset we are going to study. The [dataset](http://ai.stanford.edu/~amaas/data/sentiment/) has been curated by Andrew Maas et al. and contains a total of 100,000 reviews on IMDB. 25,000 of them are labelled as positive and negative for training, another 25,000 are labelled for testing (in both cases they are highly polarized). The remaning 50,000 is an additional unlabelled data (but we will find a use for it nonetheless).\n",
    "\n",
    "We'll begin with a sample we've prepared for you, so that things run quickly before going over the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/ndim1/.fastai/data/imdb_sample/texts.csv')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It only contains one csv file, let's have a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie wi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most u...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  is_valid\n",
       "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
       "1  positive  This is a extremely well-made film. The acting...     False\n",
       "2  negative  Every once in a long while a movie will come a...     False\n",
       "3  positive  Name just says it all. I watched this movie wi...     False\n",
       "4  negative  This movie succeeds at being one of the most u...     False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path/'texts.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is some merit in this view, but it\\'s also true that no one forced Hindus and Muslims in the region to mistreat each other as they did around the time of partition. It seems more likely that the British simply saw the tensions between the religions and were clever enough to exploit them to their own ends.<br /><br />The result is that there is much cruelty and inhumanity in the situation and this is very unpleasant to remember and to see on the screen. But it is never painted as a black-and-white case. There is baseness and nobility on both sides, and also the hope for change in the younger generation.<br /><br />There is redemption of a sort, in the end, when Puro has to make a hard choice between a man who has ruined her life, but also truly loved her, and her family which has disowned her, then later come looking for her. But by that point, she has no option that is without great pain for her.<br /><br />This film carries the message that both Muslims and Hindus have their grave faults, and also that both can be dignified and caring people. The reality of partition makes that realisation all the more wrenching, since there can never be real reconciliation across the India/Pakistan border. In that sense, it is similar to \"Mr & Mrs Iyer\".<br /><br />In the end, we were glad to have seen the film, even though the resolution was heartbreaking. If the UK and US could deal with their own histories of racism with this kind of frankness, they would certainly be better off.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It contains one line per review, with the label ('negative' or 'positive'), the text and a flag to determine if it should be part of the validation set or the training set. If we ignore this flag, we can create a DataBunch containing this data in one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm = TextDataBunch.from_csv(path, 'texts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By executing this line a process was launched that took a bit of time. Let's dig a bit into it. Images could be fed (almost) directly into a model because they're just a big array of pixel values that are floats between 0 and 1. A text is composed of words, and we can't apply mathematical functions to them directly. We first have to convert them to numbers. This is done in two differents steps: tokenization and numericalization. A `TextDataBunch` does all of that behind the scenes for you.\n",
    "\n",
    "Before we delve into the explanations, let's take the time to save the things that were calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lm.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next time we launch this notebook, we can skip the cell above that took a bit of time (and that will take a lot more when you get to the full dataset) and load those results like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of processing we make the texts go through is to split the raw sentences into words, or more exactly tokens. The easiest way to do this would be to split the string on spaces, but we can be smarter:\n",
    "\n",
    "- we need to take care of punctuation\n",
    "- some words are contractions of two different words, like isn't or don't\n",
    "- we may need to clean some parts of our texts, if there's HTML code for instance\n",
    "\n",
    "To see what the tokenizer had done behind the scenes, let's have a look at a few texts in a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj raising xxmaj victor xxmaj vargas : a xxmaj review \\n \\n  xxmaj you know , xxmaj raising xxmaj victor xxmaj vargas is like sticking your hands into a big , xxunk bowl of xxunk . xxmaj it 's warm and gooey , but you 're not sure if it feels right . xxmaj try as i might , no matter how warm and gooey xxmaj raising xxmaj</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxup the xxup shop xxup around xxup the xxup corner is one of the sweetest and most feel - good romantic comedies ever made . xxmaj there 's just no getting around that , and it 's hard to actually put one 's feeling for this film into words . xxmaj it 's not one of those films that tries too hard , nor does it come up with</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj now that xxmaj che(2008 ) has finished its relatively short xxmaj australian cinema run ( extremely limited xxunk screen in xxmaj xxunk , after xxunk ) , i can xxunk join both xxunk of \" xxmaj at xxmaj the xxmaj movies \" in taking xxmaj steven xxmaj soderbergh to task . \\n \\n  xxmaj it 's usually satisfying to watch a film director change his style /</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj this film sat on my xxmaj tivo for weeks before i watched it . i dreaded a self - indulgent xxunk flick about relationships gone bad . i was wrong ; this was an xxunk xxunk into the screwed - up xxunk of xxmaj new xxmaj yorkers . \\n \\n  xxmaj the format is the same as xxmaj max xxmaj xxunk ' \" xxmaj la xxmaj ronde</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos \\n \\n  i 'm sure things did n't exactly go the same way in the real life of xxmaj homer xxmaj hickam as they did in the film adaptation of his book , xxmaj rocket xxmaj boys , but the movie \" xxmaj october xxmaj sky \" ( an xxunk of the book 's title ) is good enough to stand alone . i have not read xxmaj</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = TextClasDataBunch.from_csv(path, 'texts.csv')\n",
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The texts are truncated at 100 tokens for more readability. We can see that it did more than just split on space and punctuation symbols: \n",
    "- the \"'s\" are grouped together in one token\n",
    "- the contractions are separated like this: \"did\", \"n't\"\n",
    "- content has been cleaned for any HTML symbol and lower cased\n",
    "- there are several special tokens (all those that begin by xx), to replace unknown tokens (see below) or to introduce different text fields (here we only have one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numericalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have extracted tokens from our texts, we convert to integers by creating a list of all the words used. We only keep the ones that appear at least twice with a maximum vocabulary size of 60,000 (by default) and replace the ones that don't make the cut by the unknown token `UNK`.\n",
    "\n",
    "The correspondance from ids to tokens is stored in the `vocab` attribute of our datasets, in a dictionary called `itos` (for int to string)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xxunk',\n",
       " 'xxpad',\n",
       " 'xxbos',\n",
       " 'xxeos',\n",
       " 'xxfld',\n",
       " 'xxmaj',\n",
       " 'xxup',\n",
       " 'xxrep',\n",
       " 'xxwrep',\n",
       " 'the']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we look at what a what's in our datasets, we'll see the tokenized text as a representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text xxbos i rated this film 7 / 10 which is an average of 8 / 10 for screenplay , direction and 1944 production values and 6 / 10 for acting . xxmaj my acting rating in turn was xxunk at 4 / 10 for all the screen characters except for that played by heroine xxmaj ella xxmaj raines as xxmaj carol xxmaj xxunk who was excellent at 8 / xxunk i commend xxmaj thomas xxmaj xxunk as xxmaj inspector xxmaj burgess whose character convinces that he personally does not think the guilty verdict on xxmaj scott xxmaj henderson ( xxmaj alan xxmaj curtis ) was just in view of his naive alibi . xxmaj these two then form an alliance to prove xxmaj scott 's alibi . \n",
       " \n",
       "  i have this film on a \" xxmaj xxunk xxmaj film xxmaj noir xxmaj xxunk xxmaj xxunk \" xxup dvd in xxmaj spanish as \" xxmaj la xxmaj xxunk xxmaj xxunk \" with the original soundtrack \" xxmaj xxunk \" as an alternative language , since despite searching i could not find a wholly xxmaj english version . i was however xxunk to see another performance by xxmaj ella xxmaj raines after being impressed with her performance as a heroine in \" xxmaj impact \" playing a sole female xxunk xxunk . xxmaj here xxmaj ella performs another heroic role believing in the innocence of her engineer boss and refuses several xxunk that she should return to her home in xxmaj kansas ( her boss 's pet name for her ) before xxunk the missing alibi . xxmaj the fact that she is secretly in love with her boss is a little hard to believe since he xxunk just seemed to have had a xxunk business relationship with her . xxmaj he had however designed children 's homes and xxunk so i suppose \" family man \" had lit up in xxmaj carol 's brain . \n",
       " \n",
       "  xxmaj in the 1940s with \" the film code \" in operation , producers could only portray sex through metaphors and here it is done in the form of furious xxunk played by xxmaj xxunk xxmaj xxunk xxunk . xxmaj carol dolls herself up as a girl of easy virtue in an attempt to lure the xxunk into giving her information about \" xxmaj the xxmaj phantom xxmaj lady \" alibi . xxmaj the other main character , xxmaj jack xxmaj xxunk ( an xxunk of xxmaj scott xxmaj henderson ) is played by xxmaj franchot xxmaj tone whose performance i found too theatrical and wondered why xxmaj carol , for instance , did not notice him constantly and strangely xxunk his hands . xxmaj here the screenplay should have been improved and provided more suspense as these theatrical moves telegraphed the plot far too early to the audience ."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the underlying data is all numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   2,   19, 1046,   21,   32,  802,  115,  164,   85,   16])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0][0].data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the data block API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the data block API with NLP and have a lot more flexibility than what the default factory methods offer. In the previous example for instance, the data was randomly split between train and validation instead of reading the third column of the csv.\n",
    "\n",
    "With the data block API though, we have to manually call the tokenize and numericalize steps. This allows more flexibility, and if you're not using the defaults from fastai, the various arguments to pass will appear in the step they're revelant, so it'll be more readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = (TextList.from_csv(path, 'texts.csv', cols='text')\n",
    "                .split_from_df(col=2)\n",
    "                .label_from_df(cols=0)\n",
    "                .databunch())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that language models can use a lot of GPU, so you may need to decrease batchsize here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bs=48\n",
    "bs=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's grab the full dataset for what follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/ndim1/.fastai/data/imdb/imdb.vocab'),\n",
       " PosixPath('/home/ndim1/.fastai/data/imdb/tmp_lm'),\n",
       " PosixPath('/home/ndim1/.fastai/data/imdb/models'),\n",
       " PosixPath('/home/ndim1/.fastai/data/imdb/README'),\n",
       " PosixPath('/home/ndim1/.fastai/data/imdb/unsup'),\n",
       " PosixPath('/home/ndim1/.fastai/data/imdb/tmp'),\n",
       " PosixPath('/home/ndim1/.fastai/data/imdb/data_clas.pkl'),\n",
       " PosixPath('/home/ndim1/.fastai/data/imdb/data_lm.pkl'),\n",
       " PosixPath('/home/ndim1/.fastai/data/imdb/tmp_clas'),\n",
       " PosixPath('/home/ndim1/.fastai/data/imdb/train'),\n",
       " PosixPath('/home/ndim1/.fastai/data/imdb/test')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/ndim1/.fastai/data/imdb/train/neg'),\n",
       " PosixPath('/home/ndim1/.fastai/data/imdb/train/pos'),\n",
       " PosixPath('/home/ndim1/.fastai/data/imdb/train/unsupBow.feat'),\n",
       " PosixPath('/home/ndim1/.fastai/data/imdb/train/labeledBow.feat')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reviews are in a training and test set following an imagenet structure. The only difference is that there is an `unsup` folder on top of `train` and `test` that contains the unlabelled data.\n",
    "\n",
    "We're not going to train a model that classifies the reviews from scratch. Like in computer vision, we'll use a model pretrained on a bigger dataset (a cleaned subset of wikipedia called [wikitext-103](https://einstein.ai/research/blog/the-wikitext-long-term-dependency-language-modeling-dataset)). That model has been trained to guess what the next word is, its input being all the previous words. It has a recurrent structure and a hidden state that is updated each time it sees a new word. This hidden state thus contains information about the sentence up to that point.\n",
    "\n",
    "We are going to use that 'knowledge' of the English language to build our classifier, but first, like for computer vision, we need to fine-tune the pretrained model to our particular dataset. Because the English of the reviews left by people on IMDB isn't the same as the English of wikipedia, we'll need to adjust the parameters of our model by a little bit. Plus there might be some words that would be extremely common in the reviews dataset but would be barely present in wikipedia, and therefore might not be part of the vocabulary the model was trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the unlabelled data is going to be useful to us, as we can use it to fine-tune our model. Let's create our data object with the data block API (next line takes a few minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm = (TextList.from_folder(path)\n",
    "           #Inputs: all the text files in path\n",
    "            .filter_by_folder(include=['train', 'test', 'unsup']) \n",
    "           #We may have other temp folders that contain text files so we only keep what's in train and test\n",
    "            .split_by_rand_pct(0.1)\n",
    "           #We randomly split and keep 10% (10,000 reviews) for validation\n",
    "            .label_for_lm()           \n",
    "           #We want to do a language model so we label accordingly\n",
    "            .databunch(bs=bs))\n",
    "data_lm.save('data_lm.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushing parameters to DDP namespace: ['bs', 'path']\n",
      "Auto Execution on DDP group: on, will run cell as %%dip\n"
     ]
    }
   ],
   "source": [
    "%dipush bs path\n",
    "%autodip on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to use a special kind of `TextDataBunch` for the language model, that ignores the labels (that's why we put 0 everywhere), will shuffle the texts at each epoch before concatenating them all together (only for training, we don't shuffle for the validation set) and will send batches that read that text in order with targets that are the next word in the sentence.\n",
    "\n",
    "The line before being a bit long, we want to load quickly the final ids by using the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n"
     ]
    }
   ],
   "source": [
    "data_lm = load_data(path, 'data_lm.pkl', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[output:0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>of xxmaj ajax and xxmaj parry of the xxmaj new xxmaj zealand ship xxmaj achilles , gambling that the xxmaj germans will head for the xxmaj river xxmaj plate before returning home . \\n \\n  a fierce battle rages throughout the following day , with xxmaj exeter suffering heavy damage . xxmaj the xxmaj graf xxmaj spee escapes under cover of nightfall to neutral xxmaj montevideo harbour where ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>a lot of movies when this movie came out and i noticed in the paper a listing for xxmaj bad xxmaj moon . xxmaj so i decided since i had xxunk seen every other movie playing in the theater to give it a try . xxmaj it was opening day of the movie and i notice that only three other people in the theater had come to see it .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>as she was . xxmaj the real story behind it is such a tragedy . xxmaj poor xxmaj irene xxmaj silverman and other victims who was so suspicious and caught on to their act only to get murdered and discarded like garbage . xxmaj it is such a shame that they never found her body and probably never will at this point . xxmaj but what gall is that they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>i think he would have far better in the role of xxmaj norman xxmaj main . xxmaj after xxmaj judy xxmaj garland was fired from xxmaj annie xxmaj get xxmaj your xxmaj gun , the first person that they wanted to play xxmaj annie was xxmaj betty xxmaj garrett , but because of her an - gent she lost out having the role of a lifetime in the movies ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>best and only possibility for a new century audience . xxbos 1st watched 2 / 13 / 2007 - 1 out of 10(dir - xxmaj dwain xxmaj esper ) : xxmaj absolutely horrible excuse for a movie . i mean , if it did it 's job of educating the public against syphilis it might have been somewhat worthwhile , but even this attempt was executed very badly . xxmaj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "engine": 0
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then put this in a learner object very easily with a model loaded with the pretrained weights. They'll be downloaded the first time you'll execute the following line and stored in `~/.fastai/models/` (or elsewhere if you specified different paths in your config file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip -S all: Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[0:4]: \u001b[0mdevice(type='cuda', index=0)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-01-26T16:25:47.809984",
      "data": {},
      "engine_id": 0,
      "engine_uuid": "5c36ec84-1346e6ecdf342d5a012aafa8",
      "error": null,
      "execute_input": "data_lm.device\n",
      "execute_result": {
       "data": {
        "text/plain": "device(type='cuda', index=0)"
       },
       "execution_count": 4,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "8f63775d-e4b83fb6cb60e4e25d17b14a",
      "outputs": [],
      "received": "2020-01-26T16:25:47.814013",
      "started": "2020-01-26T16:25:47.805997",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-01-26T16:25:47.802774"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[1:4]: \u001b[0mdevice(type='cuda', index=1)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-01-26T16:25:47.809070",
      "data": {},
      "engine_id": 1,
      "engine_uuid": "fd7ca528-93c8ee5bc2491c204ff9e50a",
      "error": null,
      "execute_input": "data_lm.device\n",
      "execute_result": {
       "data": {
        "text/plain": "device(type='cuda', index=1)"
       },
       "execution_count": 4,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "5112a66a-7ba6af99e2a00bc8dd36accc",
      "outputs": [],
      "received": "2020-01-26T16:25:47.812719",
      "started": "2020-01-26T16:25:47.805764",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-01-26T16:25:47.802951"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mOut[2:4]: \u001b[0mdevice(type='cuda', index=2)"
      ]
     },
     "metadata": {
      "after": [],
      "completed": "2020-01-26T16:25:47.810945",
      "data": {},
      "engine_id": 2,
      "engine_uuid": "bea195bd-c54824ccf0eb43ac7fa1df6c",
      "error": null,
      "execute_input": "data_lm.device\n",
      "execute_result": {
       "data": {
        "text/plain": "device(type='cuda', index=2)"
       },
       "execution_count": 4,
       "metadata": {}
      },
      "follow": [],
      "msg_id": "d62ac043-b4388c171acf7406c1def366",
      "outputs": [],
      "received": "2020-01-26T16:25:47.815200",
      "started": "2020-01-26T16:25:47.806248",
      "status": "ok",
      "stderr": "",
      "stdout": "",
      "submitted": "2020-01-26T16:25:47.803084"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%dip -S all\n",
    "data_lm.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n"
     ]
    }
   ],
   "source": [
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n",
      "Proc [18240] Rank [0] Removing callback <class 'fastai.distributed.DistributedTrainer'> from learner.\n",
      "Proc [18240] Rank [0] Removing callback <class 'fastai.distributed.DistributedRecorder'> from learner.\n",
      "Proc [18240] Rank [0] Running lr_find() in non DDP mode\n",
      "Proc [18244] Rank [1] cannot run lr_find() in DDP mode (only Rank [0] can).\n",
      "Proc [18245] Rank [2] cannot run lr_find() in DDP mode (only Rank [0] can).\n",
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         13.113811   #na#        00:18     ---------| 1.64% [99/6048 00:18<18:19 11.5804]\n",
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[output:0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "engine": 0,
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot(skip_end=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n",
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         3.948259    3.906367    0.301439  09:25                                            \n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n"
     ]
    }
   ],
   "source": [
    "learn.save('fit_head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n"
     ]
    }
   ],
   "source": [
    "learn.load('fit_head');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the fine-tuning, we can then unfeeze and launch a new training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n"
     ]
    }
   ],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n",
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         4.147244    4.069795    0.313324  12:17                                            \n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n",
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         4.025886    3.994853    0.318539  12:08                                             \n",
      "1         3.893934    3.847466    0.327336  12:09                                             \n",
      "2         3.723466    3.738838    0.333429  12:09                                             \n",
      "3         3.635816    3.678081    0.337518  12:10                                             \n",
      "4         3.564397    3.643063    0.339820  12:10                                             \n",
      "5         3.507471    3.618983    0.341879  12:10                                             \n",
      "6         3.444421    3.603808    0.343339  12:10                                             \n",
      "7         3.403359    3.593566    0.344421  12:10                                             \n",
      "8         3.373981    3.589162    0.345017  12:10                                             \n",
      "9         3.352196    3.588360    0.345142  12:10                                              \n"
     ]
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How good is our model? Well let's try to see what it predicts after a few given words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/distributed/distributed_c10d.py:100: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    }
   ],
   "source": [
    "learn.save('fine_tuned-ddp');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n"
     ]
    }
   ],
   "source": [
    "learn.load('fine_tuned-ddp');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n"
     ]
    }
   ],
   "source": [
    "TEXT = \"I liked this movie because\"\n",
    "N_WORDS = 40\n",
    "N_SENTENCES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n",
      "I liked this movie because it has a good story line , and a good performance by Sean Bean , who had a great role in this movie ! ! ! It is n't Oscar material , but it makes fun\n",
      "I liked this movie because it was great to see Jon Voight and Susan Sarandon do a movie together . It 's about a very man who has a son . So he and his son move onto a\n",
      "I liked this movie because it did n't give you too many twists and turns , but so did the music and the movie . i would recommend this movie to fans of the Matrix . The movie is not just action ,\n",
      "I liked this movie because of the title . It has a good story about the two leads , Weir and Weir . The only thing seemed to be a little bit of a plot twist . The direction was\n",
      "I liked this movie because of the good acting and the great script . It 's filled with clever and realistic situations and Hollywood still has n't found a new way to make movies . It does have some very good actors\n",
      "I liked this movie because it was brilliant . i was a little disappointed in the way it was written . It was so slow and unbelievable . The acting was very good . But the script was horrible . There\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to save not only the model, but also its encoder, the part that's responsible for creating and updating the hidden state. For the next part, we don't care about the part that tries to guess the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n"
     ]
    }
   ],
   "source": [
    "learn.save_encoder('fine_tuned_enc-ddp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto Execution on DDP group: Off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shutting down cluster....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DDP.exit_group(): [0, 1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cluster takes a few secons to shut down....\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3.795089</td>\n",
       "      <td>3.764953</td>\n",
       "      <td>0.318825</td>\n",
       "      <td>22:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.765301</td>\n",
       "      <td>3.724154</td>\n",
       "      <td>0.326427</td>\n",
       "      <td>22:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.715838</td>\n",
       "      <td>3.696973</td>\n",
       "      <td>0.330910</td>\n",
       "      <td>22:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.666868</td>\n",
       "      <td>3.666649</td>\n",
       "      <td>0.334794</td>\n",
       "      <td>22:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3.624236</td>\n",
       "      <td>3.642181</td>\n",
       "      <td>0.338301</td>\n",
       "      <td>22:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.573047</td>\n",
       "      <td>3.621949</td>\n",
       "      <td>0.340508</td>\n",
       "      <td>22:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>3.493925</td>\n",
       "      <td>3.606817</td>\n",
       "      <td>0.342836</td>\n",
       "      <td>22:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.419490</td>\n",
       "      <td>3.601450</td>\n",
       "      <td>0.343797</td>\n",
       "      <td>22:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.377777</td>\n",
       "      <td>3.600045</td>\n",
       "      <td>0.344160</td>\n",
       "      <td>22:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.331737</td>\n",
       "      <td>3.602314</td>\n",
       "      <td>0.344029</td>\n",
       "      <td>22:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.246588</td>\n",
       "      <td>0.178410</td>\n",
       "      <td>0.932320</td>\n",
       "      <td>01:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.227889</td>\n",
       "      <td>0.161970</td>\n",
       "      <td>0.939600</td>\n",
       "      <td>02:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.197898</td>\n",
       "      <td>0.148056</td>\n",
       "      <td>0.944520</td>\n",
       "      <td>03:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='2', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/2 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='390', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/390 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 10.91 GiB total capacity; 10.08 GiB already allocated; 25.44 MiB free; 188.75 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-5a3250b615ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfreeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.6\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I really loved that movie, it was awesome!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'last-single'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/fastai/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     21\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     22\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m def fit_fc(learn:Learner, tot_epochs:int=1, lr:float=defaults.lr,  moms:Tuple[float,float]=(0.95,0.85), start_pct:float=0.72,\n",
      "\u001b[0;32m~/Dropbox/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callback_fns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/fastai/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/fastai/fastai/text/learner.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mraw_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m def get_text_classifier(arch:Callable, vocab_sz:int, n_class:int, bptt:int=70, max_len:int=20*70, config:dict=None,\n",
      "\u001b[0;32m~/Dropbox/fastai/fastai/text/learner.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(self, arrs)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;34m\"Concatenate the `arrs` along the batch dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/fastai/fastai/text/learner.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;34m\"Concatenate the `arrs` along the batch dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 392.00 MiB (GPU 0; 10.91 GiB total capacity; 10.08 GiB already allocated; 25.44 MiB free; 188.75 MiB cached)"
     ]
    }
   ],
   "source": [
    "%autodip off\n",
    "%makedip -k\n",
    "data_lm = load_data(path, 'data_lm.pkl', bs=bs)\n",
    "learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n",
    "learn.load('fit_head')\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))\n",
    "learn.save('fine_tuned-single');\n",
    "learn.save_encoder('fine_tuned_enc-single')\n",
    "data_clas = load_data(path, 'data_clas.pkl', bs=bs)\n",
    "\n",
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
    "learn.load_encoder('fine_tuned_enc-single')\n",
    "learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))\n",
    "learn.save('first-single')\n",
    "learn.load('first-single')\n",
    "\n",
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))\n",
    "learn.save('second-single')\n",
    "learn.load('second-single')\n",
    "\n",
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))\n",
    "learn.save('third-single')\n",
    "learn.load('third-single')\n",
    "\n",
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))\n",
    "learn.predict(\"I really loved that movie, it was awesome!\")\n",
    "learn.save('last-single')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create a new data object that only grabs the labelled data and keeps those labels. Again, this line takes a bit of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n"
     ]
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip local: Running cell in local namespace.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%dip local\n",
    "data_clas = (TextList.from_folder(path, vocab=data_lm.vocab)\n",
    "             #grab all the text files in path\n",
    "             .split_by_folder(valid='test')\n",
    "             #split by train and valid folder (that only keeps 'train' and 'test' so no need to filter)\n",
    "             .label_from_folder(classes=['neg', 'pos'])\n",
    "             #label them all with their folders\n",
    "             .databunch(bs=bs))\n",
    "\n",
    "data_clas.save('data_clas.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto Execution on DDP group: Off\n"
     ]
    }
   ],
   "source": [
    "%autodip off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = load_data(path, 'data_clas.pkl', bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj match 1 : xxmaj tag xxmaj team xxmaj table xxmaj match xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley vs xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit xxmaj bubba xxmaj ray and xxmaj spike xxmaj dudley started things off with a xxmaj tag xxmaj team xxmaj table xxmaj match against xxmaj eddie xxmaj guerrero and xxmaj chris xxmaj benoit . xxmaj according to the rules</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj by now you 've probably heard a bit about the new xxmaj disney dub of xxmaj miyazaki 's classic film , xxmaj laputa : xxmaj castle xxmaj in xxmaj the xxmaj sky . xxmaj during late summer of 1998 , xxmaj disney released \" xxmaj kiki 's xxmaj delivery xxmaj service \" on video which included a preview of the xxmaj laputa dub saying it was due out</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos * * * xxmaj warning - this review contains \" plot spoilers , \" though nothing could \" spoil \" this movie any more than it already is . xxmaj it really xxup is that bad . * * * \\n \\n  xxmaj before i begin , i 'd like to let everyone know that this definitely is one of those so - incredibly - bad - that</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos xxmaj this movie was recently released on xxup dvd in the xxup us and i finally got the chance to see this hard - to - find gem . xxmaj it even came with original theatrical previews of other xxmaj italian horror classics like \" xxup xxunk \" and \" xxup beyond xxup the xxup darkness \" . xxmaj unfortunately , the previews were the best thing about this</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos i thought that xxup rotj was clearly the best out of the three xxmaj star xxmaj wars movies . i find it surprising that xxup rotj is considered the weakest installment in the xxmaj trilogy by many who have voted . xxmaj to me it seemed like xxup rotj was the best because it had the most profound plot , the most suspense , surprises , most xxunk the</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_clas.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then create a model to classify those reviews and load the encoder we saved before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (25000 items)\n",
       "x: TextList\n",
       "xxbos xxmaj the first xxmaj matrix movie was lush with incredible character development , witty dialog , and action scenes that kept with the flow of the story . xxmaj these elements -- coupled by incredible special effects of the day -- presented a magical ride that kept you in suspense the entire time . xxmaj enter xxmaj matrix xxmaj reloaded ( and its sequel , xxmaj revolutions ) . xxmaj the problem here is n't the special effects or the fight sequences as some may argue ; xxmaj the brothers have taken well - developed characters from the first film and hollowed them out like rotten tree logs . \n",
       "  xxmaj the connection that was first established between viewers and on - screen characters in the first film is lost when you realize these are not the same characters from the first xxmaj matrix movie . \n",
       " \n",
       "  xxmaj to wit , xxmaj morpheus was developed as a charismatic , philosophical character with insight far exceeding anyone else in the movie , but here in xxmaj reloaded -- we 're presented by a different xxmaj morpheus who stands hard and hollow , reduced to corny one - liners that contradict the character we saw develop in the first film . xxmaj this character just did n't feel the same , and this could also be said about the supporting characters in the movie . \n",
       " \n",
       "  xxmaj the removal of ' xxmaj tank ' was also a disappointment . xxmaj tank 's involvement in the first film was minimal at best , but he played the role extremely well . xxmaj in xxmaj reloaded , we discover that xxmaj tank dies after the events in the first film , and he is replaced by a xxmaj jar xxmaj jar xxmaj binks stunt double that could n't act to save his live ( think stale box of xxmaj kellogg 's xxmaj corn xxmaj flakes ) . xxmaj his performance left me chuckling throughout , and most of his spoken dialog lacked timing . xxmaj there was an overwhelming sense that he was either trying too hard to convey his emotions on - screen or the delivery in the script was off ; in either case , the experience was humorous ! xxmaj at times i felt embarrassed for the actor xxrep 4 . \n",
       " \n",
       "  xxmaj even xxmaj neo 's xxmaj godly persona was suspect during most of the fighting sequences . xxmaj the alleyway battle with the 200 xxmaj agent xxmaj smith clones was certainly exaggerated . xxmaj one must wonder , for a man so gifted as xxmaj neo -- that he would even waste his time engaging in such a fruitless , frivolous battle when more pressing matters attend ( especially when you consider his ability to fly or his ungodly ability to bend the xxmaj matrix ; certainly xxmaj neo could have dispatched the clones much quicker , and more efficiently ) . xxmaj again , such acts lend themselves to a script hindered by consistency , and scenes created as filler to keep us from feeling gypped . xxmaj in jest , our expectations of the characters created in the first film are discarded promptly . xxmaj sadly , for those expecting more of the same -- you will certainly walk away feeling gravely disappointed . \n",
       " \n",
       "  xxmaj however , if you take xxmaj reloaded as your standard , run - of - the - mill action movie , and forget the incredible story inconsistencies and the xxunk of already - established character development from the first film , you should walk away feeling quite pleased .,xxbos a 1957 ( yes , that 's the correct date ) xxup j. xxmaj arthur xxmaj rank production with xxmaj james xxmaj robertson xxmaj justice , xxmaj margaret xxmaj rutherford , xxmaj wilfred xxmaj hyde xxmaj white ; it has to be a smash comedy , right ? xxmaj oh , it 's just awful . xxmaj it 's a one gag film : watching people be shocked at the sight of a little alligator . xxmaj music is thrown in , most inappropriately and xxunk . xxmaj jeannie xxmaj carson is a lively dancer and competent singer . xxmaj but what was she doing in this film ? xxmaj diana xxmaj dors is here too , providing oh - so - daring shots for use in the previews . xxmaj her acting level is not bad , but she 's in the film to provide someone to leer at . xxmaj well , one must do something beside groan during this film . xxmaj the movie is being sold on xxup vhs now by people on e - xxmaj bay . xxmaj spare yourself the expense and the waste of time . a comedy without a laugh . a musical without a memorable song or dance .,xxbos xxmaj xxunk : xxmaj excellent , nice camera angles ( i do n't remember seeing a movie of late , with good close - ups , until this one ) . xxmaj could have avoided gruesome scenes with a soft camera . xxup ny is pictured good . i liked the upside down angles , in particular ( a different touch ) . \n",
       " \n",
       "  xxmaj music : xxmaj not impressive . xxmaj songs do n't stick around in your mind even after watching the movie . xxmaj may be , i expected same quality like \" xxmaj xxunk \" . a disappointment . \n",
       " \n",
       "  xxmaj actors : xxmaj kamal needs to slowly pull away from hard - core action sequences . xxmaj his age and belly really show up . xxmaj also , he should avoid close romantic sequences going forward . xxmaj it was a very awkward to see a mature / aged star still trying to play like a 20 + heroes scenes . xxmaj love can be expressed at any age ; as we get older , you still can express love nicely from a distance ( without touching a woman too much . xxmaj for example , the love expressed by xxmaj rajinikanth in \" xxunk \" ) . \n",
       " \n",
       "  xxmaj xxunk just appears for the namesake in the movie . xxmaj not sure why she accepted this . xxmaj well , that is not my problem , i guess . \n",
       " \n",
       "  xxmaj others just have a small presence . \n",
       " \n",
       "  xxmaj direction : i expected xxmaj gautham to excel ( or measure - up ) to his other movie \" xxmaj kakka xxmaj kakka \" . xxmaj he xxunk me . xxmaj it took a long time to release the movie due to various issues . xxmaj he slips in few scenes . xxmaj even xxunk things got slipped from a famous director . \n",
       " \n",
       "  xxmaj overall : xxmaj just a okay movie . xxmaj too much graphics . xxup definitely not for kids ( and adults who expect some kind of \" xxmaj entertainment \" ) . \n",
       " \n",
       "  xxmaj thx,xxbos xxmaj follow - up to 1973 's far better \" xxmaj cleopatra xxmaj jones \" has statuesque black actress xxmaj tamara xxmaj dobson returning to her signature role as chic , super - tough narcotics agent , here busting a heroin ring in xxmaj hong xxmaj kong . xxmaj cross - pollination of blaxploitation action - flick and kung - fu b - movie is fun at the outset but eventually flags . xxmaj the shoot - out finale is right off the assembly - line , and xxmaj dobson herself seems less energetic than before ( she 's still sexy , and she puts a unique spin on her comically - stilted dialogue , but these surroundings may have been too much of one thing for her -- she 's jaded ) . xxmaj stella xxmaj stevens plays the villainess this time ; she 's good , but ca n't match xxmaj shelley xxmaj winters in the predecessor . * * from xxrep 4 *,xxbos xxmaj considering the risk of showing same - sex relationships before the late 1980 's , xxmaj personal xxmaj best could have done better to play the same - sex relationship between xxmaj hemingway ( xxmaj chris xxmaj cahill ) and xxmaj donnelly ( xxmaj tory xxmaj skinner ) as a more than experimental phase of xxmaj cahill 's life . \n",
       " \n",
       "  xxmaj it seems to me that the creators of this movie threw in the same - sex relationship between two fairly attractive women in order to attract viewers . xxmaj also consider the 90 seconds of exposing the xxunk of several women jumping backwards over a high jump pole . xxmaj this random scene had xxup very xxup little relevance to the movie and it appeared as though this was done merely to keep the audience interested in this bland movie . i suppose the producers were trying to counteract the boring plot and the even more boring setting of the movie ( the 1980 xxmaj oregon xxmaj track and xxmaj field xxmaj competition ) . \n",
       " \n",
       "  xxmaj this review may seem harsh , but it is the truth . xxmaj the exploitation of young xxmaj muriel xxmaj hemingway 's body and the same - sex relationship ruined any credit that i would have given to this film . \n",
       " \n",
       "  xxmaj pepper xxmaj thompson\n",
       "y: CategoryList\n",
       "neg,neg,neg,neg,neg\n",
       "Path: /home/ndim1/.fastai/data/imdb;\n",
       "\n",
       "Valid: LabelList (25000 items)\n",
       "x: TextList\n",
       "xxbos xxmaj strange things happen to xxmaj americans xxmaj will ( xxmaj greg xxmaj evigan ) , xxmaj maura ( xxmaj alexandra xxmaj paul ) and their young daughter xxmaj aubrey ( xxmaj xxunk xxmaj evigan , xxmaj greg 's real life daughter ) when they move into a large , newly inherited house in xxmaj ireland . xxmaj crusty corpses are found in the cellar , a turkey squirts blood , furniture moves and the ghosts of a dead child and a cackling old lady show up to scare the little girl . xxmaj paranormal investigators are eventually called in to banish the evil spirits , but xxmaj maura becomes possessed anyway and chases everyone around with a meat cleaver . \n",
       " \n",
       "  xxmaj this film is full of cliches , but there 's a standout performance from xxmaj alexandra xxmaj paul ... too bad it does n't belong in this movie ( nor any other i can think of off hand ) ! xxmaj she can barely keep a straight face and her over - emoting and hysterical screaming tantrums are a joy to behold . xxmaj in any case , she 's a lot more interesting to watch than anything else in this movie . \n",
       " \n",
       "  xxmaj score : 3 out of 10,xxbos xxmaj sure , you get to see some boobies , but if that 's all you 're looking for in a film , you get more mileage from youtube . i just paid a dollar from redbox because i saw xxmaj val xxmaj kilmer 's name . xxmaj bad move . xxmaj plot did n't thicken , dialogue was shoddy , characters undeveloped at best . xxmaj somebody said cinematography was alright but do n't expect too much . xxmaj this movie moved very slow and ended without grace . xxmaj blacklist . i spent much of the movie wondering if some event or color scheme of things was symbolic . i never actually rewound to figure it out because nothing was ever explained in the end . xxmaj no twists . xxmaj it also left many questions that as it turns out , i had no desire to hear answered . xxmaj one of the worst movies i have ever seen .,xxbos xxmaj the pace of this movie is quite slow . xxmaj it takes about 70 minutes to get xxmaj katie to xxmaj china ( which we know that she will ) and leaves 30 minutes to wrap things up . xxmaj the storyline is so predictable that you know everything after about 5 minutes . xxmaj nothing surprises you . i guess that the movie is a coming of age movie but the movie is full of stereotypes that are quite over the top : \n",
       " \n",
       "  xxmaj katie - a beauty that realizes that looks , boys and shopping is n't everything . xxmaj she realizes that she can \" feel \" and \" see the real world \" . xxmaj touching . \n",
       " \n",
       "  xxmaj the mother - high strung , nervous , screaming mother ( wow very innovative ) that need taking care of by a strong man . \n",
       " \n",
       "  xxmaj the father - patient and always understanding and takes care of the incapable woman . \n",
       " \n",
       "  xxmaj the boyfriend that only wants to get into her pants . \n",
       " \n",
       "  xxmaj the comedian clown xxmaj chinese guy that does n't know how to speak xxmaj english properly and made a laughing stock . xxmaj thought xxmaj hollywood dropped those characters in the mid fifties . \n",
       " \n",
       "  xxmaj the nurse that at times knows everything how to get around in xxmaj china that in the next moment is a carbon copy of xxmaj the mother i.e. a woman who ca nt handle the situation or knows anything . \n",
       " \n",
       "  xxmaj the deformed xxmaj chinese girl that with the help of us westerns get help and become a beautiful girl . xxmaj because in xxmaj china ( a third world country according to the film ) do n't have anything and hence needs our charity . xxmaj gah , wake up and smell what you are shoveling . \n",
       " \n",
       "  xxmaj sure that there are some poverty in xxmaj china but the portrayal of the aid from western countries ( read xxup usa ) is so shallow and happy ending - ish that it is sad and revolting . xxmaj shanghai ( where the movie is set ) is the most expanding and evolving city in the world at the moment . \n",
       " \n",
       "  xxmaj the xxmaj chinese father that is so nice and goodhearted that in the end has one wish ... to be a cowboy with a white hat ... \n",
       " \n",
       "  xxmaj the teacher ( xxmaj sean xxmaj astin ) that has this really heart ripping story ( not ) that he tells without feel . xxmaj why xxmaj sean ? xxup why ! ? \n",
       " \n",
       "  xxmaj etc etc . xxmaj it is difficult to actually finding a \" real \" person in the entire movie . \n",
       " \n",
       "  xxmaj this is nothing but a feel good movie for xxmaj americans below age 15 . xxmaj if you want to learn anything about the world watch e.g. xxmaj hotel xxmaj rwanda instead . xxmaj for a better life story or coming of age movie i suggest you watch the xxmaj italian \" xxmaj cinema xxmaj paradiso \" that won the best foreign film academy reward some years back . \n",
       " \n",
       "  xxmaj the only nice thing in the movie were the small town sceneries that truly capture some ( not all ) of the beautiful xxmaj chinese country side . i have been there and seen some of it .,xxbos xxmaj after receiving a xxup dvd of this with a xxmaj sunday newspaper , i hoped that it was not the usual duff films that are given away because no one would ever buy them . i was wrong . xxmaj xxunk acting is on par with that of a ten year old in a school pantomime production and the same goes for the majority of the cast . xxmaj neill is satisfactory , but plays a xxmaj russian and is n't helped by his hybrid xxmaj northern xxmaj irish / xxmaj new xxmaj zealand accent , and nor are the rest of the xxup kgb characters , all of whom sound like they 're in a xxmaj cambridge xxmaj footlights reunion . xxmaj in fact , the only people with genuine accents are extras who supply an odd word here and there , helpfully letting us know at least where the hell everything is going on in what is otherwise a complete mash . xxmaj the \" espionage \" factor is unimpressive for the most part and primarily consists of xxmaj sheen xxunk about in various ridiculous disguises whilst trying to blend into the background , quickly becoming not only boring but laughable . xxmaj the plot has potential but is completely murdered by the rest of the confusing production elements . xxmaj this could have been so much better .,xxbos xxmaj this seventh ( yes you read right - the seventh ) xxmaj puppet xxmaj master movie shows how the demented group of dolls came to be ; by a french puppeteer who uses them to get revenge on a group of ancient mummies who are after him once they learn that he holds the secret to life . xxmaj it was taught to him by a sorcerer , also on the run , before he died . xxmaj he used this power to bring normal puppets to life . xxmaj this sequel is basically nonsense , sprinkled upon even more nonsense like most of the xxmaj puppet xxmaj master sequels . xxmaj due to the xxup pg13 rating , we do n't even get any entertaining puppet murders . xxmaj come to think of it , there are xxup no damn puppet murders . xxmaj if there was one franchise that needed to be cut off it would be this one . xxmaj no more xxrep 4 . god , please no more ...\n",
       "y: CategoryList\n",
       "neg,neg,neg,neg,neg\n",
       "Path: /home/ndim1/.fastai/data/imdb;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(60000, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(60000, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f2121bf2440>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('/home/ndim1/.fastai/data/imdb'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: ...\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(60000, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60000, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=0.5)\n",
    "learn.load_encoder('fine_tuned_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n",
      "Proc [18240] Rank [0] Removing callback <class 'fastai.distributed.DistributedTrainer'> from learner.\n",
      "Proc [18240] Rank [0] Removing callback <class 'fastai.distributed.DistributedRecorder'> from learner.\n",
      "Proc [18240] Rank [0] Running lr_find() in non DDP mode\n",
      "Proc [18244] Rank [1] cannot run lr_find() in DDP mode (only Rank [0] can).\n",
      "Proc [18245] Rank [2] cannot run lr_find() in DDP mode (only Rank [0] can).\n",
      "epoch     train_loss  valid_loss  accuracy  time    \n",
      "0         4.296188    #na#        00:18     ---------| 24.10% [94/390 00:18<00:57 2.4029]\n",
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%dip : Running cell in remote DDP namespace (GPUs: [0, 1, 2]).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[output:0]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd3yUVdbA8d/JpDeSQBIgISQ0Cb1EEBQb2FFsu8LqKtZV17q77uuuZX3VXV15V9e1rGLHAiqioqKIIigCQugdAgQILQklDSbJJPf9YyYwhAlJSJ4pyfl+PvNhnn6ekMmZe+9z7xVjDEoppVRtQb4OQCmllH/SBKGUUsojTRBKKaU80gShlFLKI00QSimlPAr2dQDNpV27diY9Pd3XYSilVEBZsmRJoTEm0dO2FpMg0tPTyc7O9nUYSikVUERkW13btIpJKaWUR5oglFJKeaQJQimllEeaIJRSSnmkCUIppZRHmiCUUkp5pAlCKaWUR5oglFIqgE1dksfkRdstObcmCKWUCmBTl+zg06U7LTm3JgillApghaUVtI0OteTcmiCUUiqAFZaW0y46zJJza4JQSqkAVVlVzcFDlZoglFJKHWtfaQUA7WK0ikkppZSbwtJyAC1BKKWUOlaBJgillFKeFJY4E0SiJgillFLuCrUNQimllCeFpeVEhtqIDLVmclBLE4SIXCgiG0QkR0Qe9LD9ORFZ7nptFJGDbtueEZE1IrJORP4jImJlrEopFWis7AMBFs5JLSI24CXgPCAPWCwi040xa2v2Mcbc77b/3cBA1/vhwOlAP9fmecBZwByr4lVKqUCzz8Je1GBtCWIIkGOM2WKMqQCmAGNOsP84YLLrvQHCgVAgDAgB9loYq1JKBRyrSxBWJogUYIfbcp5r3XFEpDOQAcwGMMYsAH4AdrteM40x6zwcd5uIZItIdkFBQTOHr5RS/i2QE0RjjAWmGmOqAESkG5AJpOJMKueKyIjaBxljJhpjsowxWYmJiV4NWCmlfKmq2rC/rILEAK1i2gl0cltOda3zZCxHq5cArgAWGmNKjTGlwNfAMEuiVEqpALS/rIJqA+1iArMEsRjoLiIZIhKKMwlMr72TiPQE4oEFbqu3A2eJSLCIhOBsoD6uikkppVorq4fZAAsThDHGAdwFzMT5x/0jY8waEXlcRC5z23UsMMUYY9zWTQU2A6uAFcAKY8wXVsWqlFKBxhsJwrLHXAGMMTOAGbXWPVpr+TEPx1UBv7MyNqWUCmRHE0RgtkEopZSySGFJzTAbAVjFpJRSyjqFpeWEBgcRE2ZdRZAmCKWUCkAFpeW0iwrFylGINEEopVQA2ldaYWn1EmiCUEqpgGR1L2rQBKGUUgHJmSCse4IJNEEopVTAqa42ziomLUEopZRyV3S4Eke10QShlFLqWEc6yWkjtVJKKXcFXuhFDZoglFIq4BSWOntRJ2oVk1JKKXeFJc4SRFtNEEoppdwVlpZjCxLiIkIsvY4mCKWUCjCFpeW0jQolKMi6YTZAE4RSSgUcb/SBAE0QSikVcApLyy1/xBU0QSilVMApLK2w/BFX0AShlFIBxRhDQWm55Y+4giYIpZQKKCXlDioc1doGoZRS6lg1fSDaxWgVk1d8s3o39soqX4ehlFL1qulFrSUIL8jJL+WO95dy9SvzyTtwyNfhKKXUCdUM1Nc2ShOE5bolRfPab7PYVniIS1+Yx0+bCnwdklJK1enoSK5axeQVo3olM/3uM0iKCeeGNxfx8pwcjDG+DksppY5TWFKOCCREWp8ggi2/QoDIaBfFp78fzp+nruSZbzaQ2SGWc05J8moMny3byaQFuSREhZESF07HuAiGZCQwMC3eq3EopfzX/kMVxEWEEGyz/vu9Jgg3kaHBPPvrAczZUMC3a/Z6LUE4qqp56uv1vDFvK92SojlUUcUvW/dRYncQHCR8cfcZZHaI9UosSin/VnzYQRuLB+mroQmiltDgIM7s0Y7Z6/diTB9ErB0M60BZBXdNXsrPOfsYPzydhy7JJMT1zWBvsZ2Ln/+JB6etYtodw7FZPDCXUsr/ldgriQn3ToLQNggPzu2ZzN7ictbsKrb0OoWl5Vz20jwW5x5gwtX9eOyy3keSA0BybDiPXtqLFTsOMmlBrqWxKKUCQ7HdQWyEd77ba4Lw4JxTEhGB79flW3qd79buZcf+w7w9/lR+ldXJ4z6X9e/IWT0SmTBzAzsPHrY0HqWU/yuxVxITpiUIn2kbHcbATnF8v36vpdfJ3naA+MgQhnVtW+c+IsKTl/fBGHjks9X6dJVSrVzxYQcx4VqC8KmRmcmszCsiv9hu2TWWbDvA4M7x9bZzdEqI5I/n92D2+nw+X77LsniUUv6vxF5JrJcaqTVB1GFkpvMJptnrralm2ldaztbCMgZ3TmjQ/uOHp9M/tQ33fbicW95ZzLLtByyJSynlvxxV1ZRVVGkJwtdOSY4hJS6C7y1KEEu2Of/AZ6U3rI9DsC2ISTcP5f5RPcjedoArXp7Pda//wndr91Lu0HGklGoNSssdAMR66Skmfcy1DiLCuT2TmLokD3tlFeEhtmY9/5JtBwixCX1T2jT4mDYRIdw7qjs3j8jg/YXbeO2nrdwyKZuYsGBGZiZxUd8OjMpM1sdhlWqhSuzOBKElCD8wMjOJw5VVLNiyr9nPvWTbAfqktDmpxBMdFszvzurK/AfP5e0bT+Xivh2Ys7GA3727hJd+yGn2WJVS/qHocCWAtkH4g9O6tCUy1MbsZn7ctdxRxcqdRWR1btoQGqHBQZx9ShL/vLofix8axWldEvh02U590kmpFkpLEH4kPMTGGd3a8f26vTiqqpvtvKt3FlHhqG5wA3VDhNiCuLR/R7YWlrFhb0mznVcp5T+K7a4SREvoSS0iF4rIBhHJEZEHPWx/TkSWu14bReSg27Y0EflWRNaJyFoRSbcy1rpc0q8Du4rsnP1/c3jr560cqnA0+Zw1DdSDm1iCqO2C3u0JEpixak+znlcp5R9qShABnyBExAa8BFwE9ALGiUgv932MMfcbYwYYYwYALwDT3DZPAiYYYzKBIYC13ZrrcFn/jrx2fRbtY8P53y/WMvzp2bwxb2uTzpmde4DObSNJjGneCT/aRYcxNKMtX6/a3aznVUr5h2JXG0RLqGIaAuQYY7YYYyqAKcCYE+w/DpgM4EokwcaYWQDGmFJjjE+mexMRzuuVzNQ7hvPJHcPIbB/LE1+uZcf+kwvHGHOkg5wVLu7bnk35pWzSaialWpyW1AaRAuxwW85zrTuOiHQGMoDZrlU9gIMiMk1ElonIBFeJpPZxt4lItohkFxRYPxPc4M4JPHN1PwC+XHly39K37TvEvrIKspqx/cHdBb3bIwJfr9ZqJqVamhJ7JZGhNq/MBQH+00g9FphqjKnp8RUMjAD+BJwKdAHG1z7IGDPRGJNljMlKTEz0SqCdEiIZmBbH9BUnN+RFtkXtDzWSYsM5tXMCM7SaSakWp9he6bX2B7A2QewE3IcoTXWt82Qsruollzxguat6ygF8BgyyJMqTcFn/jqzbXUxOfuOrcZZs209seDDdk6ItiMzpor7tWb+nhC0FpUfWFdsr+WRJHocrtNe1UoGqxO69gfrA2gSxGOguIhkiEoozCUyvvZOI9ATigQW1jo0TkZpiwbnAWgtjbZRL+nZABL5Y0fhv6Uu2HWBQ53iCLOztfGGf9sDRaqb1e4oZ8+LP/PHjFVz+0s9sdkscSqnAUWyvbBkJwvXN/y5gJrAO+MgYs0ZEHheRy9x2HQtMMW69u1xVTX8CvheRVYAAr1kVa2MlxYZzWkZbvli5q1Gd0vYU2dm4t7TJHeTq06FNBIPS4vh69W4+W7aTK16aT1m5g0dH96KgtJxLX5jH58vrKswppfxVid3htV7UYPFYTMaYGcCMWuserbX8WB3HzgL6WRZcE13avyN//XQVa3cX07tjw8ZT+vuMdYQGBzG6X0eLo4OL+3bgya/Wcd+HyxmSkcCLvxlIUkw4F/Vtzz2Tl3HvlOVk5x7g8TG9LZ9WVSnVPIoPV9K5bZTXrucvjdQB56I+7QkOkgY3Vv+0qYAvVuzizrO7kt7O+v/gS/p1oF10GLeOyOD9W4aSFBMOOEsXk289jfHD03l34TZ+3FRoeSxKqeZRYncQ2xKqmFq6+KhQRnRvx5crdtdbzWSvrOLRz9eQ3jaS28/q6pX4OrSJYPFDI3nokl7HzHMNzqHD/3pxJh3ahPOyDu6nVEAwxrgaqVvGU0wt3qX9O7Lz4GGWbj94wv1enbuFrYVlPHF5n2YfNvxETlR1FBocxC0juvDL1v1Hhv5QSvmvckc1FVXVxEZoCSIgnNcrmdDgIKYu2VFnKSK3sIyX5uQwul8HRnT3Tl+Nhhp7aifiIkP475zNvg5FKVWPmoH6tAQRIGLCQxjdtwOTF+3g/Od+5N2F2ygrd2CMYcf+Q3y2bCf3fricUFsQj4zuVf8JvSwqLJjxw9P5bt1eNuzRoTmU8mfFh2sG6vNeCUJnlGuip67qy/Bu7Xhnfi6PfLaaZ75eT1RYMHuK7YBzcp/Hx/QmOTbcx5F6dsOwdCb+uIVX5m7muWsG+DocpVQdSrw81DdogmiysGAbVw9O5apBKSzbcZAPftlOhaOarPR4BneOp2f7WL+eAjQ+KpRxQ9J4e34ufzivB50SIo/bxxjDy3M20yelDWf18K9qMqVai2IvD9QHmiCajYgwKC2eQWnWdoKzwi0jMpi0IJfXftrC42P6HLd96pI8JszcQGp8BHMfOMevE55SLdWREoQXO8ppG4SiQ5sIrh6cynsLt/FNrVFgt+0r47Hpa0iMCSPvwGHmbPDJtBxKtXo1bRAtYqgNFVgeGd2LAZ3iuGfyMua5Os85qqq5/8PlBAUJn9w+nOTYMCYt2ObjSJVqnXzRBqEJQgEQGRrMW+OH0CUxitvezWbZ9gO8PGczS7cf5MnL+5DWNpJxQ9KYu7GArYVlvg5XqVanxO7AFiREhnqvL5UmCHVEm8gQJt00hMSYMG54cxHPf7+Jywd0ZMwA5zxPvxmSRnCQ8N5CLUUo5W01I7l6c+w0TRDqGEmx4bx381AiQm3OebjdGq2TYsO5sE97Ps7eofNKKOVl3p4LAjRBKA86JUQy874z+eLuM2hT64mJ64elU2x36HDhSnlZ8eFKYsK81/4AmiBUHeIiQ0mICj1u/anp8fRsH8OkBdsaNReGUqppnHNBaAlC+TER4bfDOrN2d7EO8qeUFznbILQEofzc5QNSiIsM4d/fbdJShFJe4pwLQhOE8nNRYcHcc2535uUUMmdjga/DUapV8PZ81KAJQp2k607rTHrbSP7x1TocVdW+DkepFq262lBa7t35qEEThDpJocFBPHhRTzbll/JRdt4J9526JI9z/zWHn3N0elOlTkZphQNjvDvUN2iCUE1wQe/2nJoez7OzNlBa7vC4z4GyCp74ci25hWVc98YvTJi5XkscSjVS8eGayYI0QagAISL89eJMCksreHWu51npnv9+EyX2Sj65YzjXZHXipR82c83EheQdOOTlaJUKXCX2msmCtIpJBZCBafFc2r8jr/20hdxaYzRt2lvCuwu3MW5IGgPT4nn6qn78Z9xANuwp4dx/zeVPH69gza6iJl1/x/5DPP7FWvaXVTTpPEr5s6MlCE0QKsD8+YJTnBMnvTKfFTsOHln/5FfriAy18YfzehxZd1n/jnx97wiuyerEjFW7ueQ/8/j1KwtYnLu/0dc1xvDnqSt58+etXPPqAvJds/gp1dIcKUFoRzkVaDolRPLJHcMID7FxzcQFzFq7lx/W5zN3YwH3juxO2+iw4/Z/4vI+LPjLSB6+JJO8A4e45Z1s8ksa9wd++opdLNiyj3FDOrHz4GF+9eoCrbpSLVJJuZYgVADrlhTDp3eeTo/kGH73bjZ/+ngFXdpFcf2w9DqPaRMRwi0juvDuLUM5XFHF/36xtsHXK7ZX8uRX6+iX2oYnL+/Le7cMZX9ZBb9+ZYEOR65anJrJgvzyKSYR6SoiYa73Z4vIPSISZ21oKtAkxoQx5bbTGJmZzL6yCh4enUlocP2/Yl0To7n73G58tXI336/b26BrPTdrI4Wl5Tx5eR9sQc7pXiffehp2RzXXvraQSn1SSrUgNZMF+WsJ4hOgSkS6AROBTsAHlkWlAlZkaDCvXDeYuQ+czbk9kxt83O/O6sopyTE8/NnqOh+ZrbFmVxHvzM/l2qFp9Es9+j2lT0ob/nFFH3YV2Vm0tfFtGkr5q2K7g7DgoAZ94WpODb1atTHGAVwBvGCMeQDoYF1YKpDZgoTObaMadUxocBBPXdWXPcV2Jnyzvs79ig5X8shnq4mPDOWB83set/3MHomEBQcxa23DSiJKBYISe6XXe1EDNLRCq1JExgE3AJe61nk/WtWiDUqL54Zh6byzIJdOCZFktIuibXQY0WHB/LJ1HzPX7GXB5kIqqwzP/ro/bSKP/xWMDA1mRPd2zFq7l79d2surs28pZZXiw96fLAganiBuBG4H/m6M2SoiGcC71oWlWqs/XXAKP24q4Mmv1h23Lb1tJDednsFFfTswoFPdTWCjMpP5bl0+6/eUkNkh1spwlfKKYnul1zvJQQMThDFmLXAPgIjEAzHGmH9aGZhqnaLDgpl535nsLbazr7SCfWXlHCirpE9KG3okRzeoRDAyMxmRVcxau1cThGoRfDHdKDT8KaY5IhIrIgnAUuA1EXnW2tBUaxViCyI1PpL+neI4t2cyVw1O5ZT2MQ2uLkqMCWNgpzi+a+ATUTVKyx3c/+Fylm7XiZCUfyn2URtEQxup2xhjioErgUnGmKHAKOvCUqppRvVKZmVeEXuKGt757plv1vPpsp3cN2U5hypO/CSVUt7knCzIT0sQQLCIdAB+DXxpYTxKNYvzezkfsW1oKWJx7n4mLdjGiO7t2L7/EM9+u9HK8JRqlOLD3p9uFBqeIB4HZgKbjTGLRaQLsMm6sJRqmq6J0aS3jTzucdfpK3bx7Zo9x6yzV1bxP5+sJCUugleuG8x1p6Xx5s9bWaZVTcoPlDuqKHdU+28JwhjzsTGmnzHmDtfyFmPMVfUdJyIXisgGEckRkQc9bH9ORJa7XhtF5GCt7bEikiciLzb0hpQC51Dk5/VKZsHmfZSWO6hwVPOXaau4Z/Iybnt3CX/8aMWRDnkvzs5hS0EZT13Zl6iwYP7nwp60jw3nz1NXUu6o8vGdqNauZqA+vy1BiEiqiHwqIvmu1yciklrPMTbgJeAioBcwTkR6ue9jjLnfGDPAGDMAeAGYVus0TwA/NvRmlHI3KjOZiqpqpi3N4zevLWTyou3cflZX7hnZnU+X5XHx8z/xUfYOXpm7mSsHpXBmj0TA+UH8+xV92ZRfyks/eJ7nQilv8dVIrtDwKqa3gOlAR9frC9e6ExkC5LhKGxXAFGDMCfYfB0yuWRCRwUAy8G0DY1TqGIM7xxMfGcKjn69h9a4i/jNuIA9e1JM/nNeDD383jKpq53DhbSJCeOSSY767cE7PJK4YmMLLP+Swdlexj+5AKbdxmML8tAQBJBpj3jLGOFyvt4HEeo5JAXa4Lee51h1HRDoDGcBs13IQ8C/gTye6gIjcJiLZIpJdUFDQsDtRrUawLYgrB6WSlhDJ1NuHc1n/jke2nZqewIx7R3DLGRm8MG4g8VGhxx3/6OhexEeFct+Hy7BXalWT8o0jI7n68WOu+0TkOhGxuV7XAfuaMY6xwFRjTM2n8E5ghjEm70QHGWMmGmOyjDFZiYn15SvVGj10cSZzHzibPiltjtvWJiKEh0f3Yni3dh6PjY8KZcLV/di4t5QJMzdYHapSHh0dydV/q5huwvmI6x5gN3A1ML6eY3biHPW1RqprnSdjcateAoYBd4lILvB/wPUi8nQDY1XqiKAgadJ4TGefksT1wzrzxryt/JxT2IyRKdUwxf6eIIwx24wxlxljEo0xScaYy4H6nmJaDHQXkQwRCcWZBKbX3klEegLxwAK3611rjEkzxqTjrGaaZIw57ikopbzhLxdl0iUxij9+tIKiQ5W+Dke1Mjn5pYTagmhXa2ZGb2jK4OJ/ONFG1/Dgd+HsP7EO+MgYs0ZEHheRy9x2HQtMMcaYJsSilGUiQm38+5oBFJaW89fPVulkRMqrvl+Xz9AuCYSH2Lx+7aaUWeottxtjZgAzaq17tNbyY/Wc423g7UZHp1Qz6pcax/3n9WDCzA2szDvInWd346pBqV6fwEW1LlsKStlSWMYNw9N9cv2m/HbrN37Vqtx5dldevz6LhMhQ/jJtFWdP+IEpi7bT0MLvjxsLKCwttzhK1ZJ8vy4fgJGZST65/gkThIiUiEixh1cJzv4QSrUaIsKoXsl89vvTeeemIXSIi+DBaat4oAE9ricv2s71by7if6au9FK0qiX4bt1eeraPITU+0ifXP2GCMMbEGGNiPbxijDHeb1JXyg+ICGf1SGTq7cO4b1R3pi7J47rXf2FfHaWDORvyefiz1cRFhvD9+nzteKcapOhQJdnbDvis9ABNq2JSqlUTEe4b1YMXxg1kZV4RY176mdU7i47ZZ82uIn7//lJ6JMfw1T0jiA4L5uU5OT6KWAWSORvzqao2jMxM9lkMWgpQqoku7d+RTgmR3Dopm9EvzKN7UjQX9G7PkIwEHpi6gtiIEN4afyrt24Tz22GdeWXuZv5QUEqXxGhfh6782Hfr8mkXHcqA1Lqn17WaliCUagYDOsXxzb0jeOzSXrSLDuPlOTlc/+YiDpVX8daNzuQAcNPpGYTagnhlrg4CqOpWWVXNnA35nHNKEkFBJ9/Rs6m0BKFUM2kbHcb40zMYf3oG+8sq+GF9Pt2To+nZ/ui82IkxYYwbksZ7C7dx76gepMRF+DBi5a8W5+6nxO7wafUSaAlCKUskRIVy1eBU+nmoHrj1zC4ATNRShKrD9+vyCbUFMaK753HCvEUThFJelhIXwZWDUpiyeAcFJdovQh3LGMP36/YyrGtbosJ8W8mjCUIpH7j9rK5UVFUzaUGur0NRfmZLYRm5+w4xyoePt9bQBKGUD3RJjGZkzyQ++GW7TmuqjrE5vxSA/p189/RSDU0QSvnI+OEZ7Cur4MsVu30divIjR6YY9cEc1LVpglDKR07v1pZuSdG8PT+3weM5qZbPlxME1aYJQikfERHGD09n1c4ilmw74OtwlJ8oLXeWIGK0BKFU63bloBRiw4N5a36ur0NRfqLE7iAsOMgvhpL3fQRKtWKRocGMHZLGN6v3sLvosK/DUX6g2O7wi9IDaIJQyud+e1pnjDG8t3Cbr0NRfqDEXkmsH7Q/gCYIpXyuU0IkozKT+eCX7dgr9ZHX1q7E7vCLBmrQBKGUX7j5jAwOHKrkue82+joU5WMl9kqiNUEopWoM7dKWcUPSmPjjFhZu2efrcJQPldgdxIRpG4RSys0jozNJbxvFHz9aQdHhSl+Ho3xEq5iUUseJDA3muWsGsKfYzt8+X+3rcJSPlNgr9SkmpdTxBnSK496R3fls+S6mr9jl63CUl1VVG8oqqrQEoZTy7M6zuzIoLY6HP11F3oFDvg5HeVGpvaYXtSYIpZQHwbYg/n3NQIyBeyYvo7Kq2tchKS8pKXe2PfnDQH2gCUIpv5TWNpJ/XNmXpdsP8uwsffS1tSjREoRSqiEu7d+RcUM68d85m/lxY4Gvw1FecDRBaAlCKVWPR0f3pkdyNH/4aDn5JXZfh6Ms5k9DfYMmCKX8WkSojRd/M4jScgcPfLzS1+Eoi9WUILQntVKqQXokx3DXOd2Yu7GAHfv1qaaWTEsQSqlGG92vIwDfrt3r40iUlYr9aLpR0AShVEBIbxfFKckxzFyzx9ehKAuV2B2E2IQwP5gsCDRBKBUwLuidTHbufvaVlvs6FGWRmmE2RMTXoQCaIJQKGOf3bk+1ge/X5fs6FGURfxqoDzRBKBUweneMJSUugm/XajVTS+UsQWiCUEo1kohwfu9kftxUSFm5w9fhKAuUlvvPXBCgCUKpgHJ+r/ZUOKq1Z3UL1aqqmETkQhHZICI5IvKgh+3Pichy12ujiBx0rR8gIgtEZI2IrBSRa6yMU6lAcWp6PPGRIfo0UwvlTBD+U4KwLFWJiA14CTgPyAMWi8h0Y8zamn2MMfe77X83MNC1eAi43hizSUQ6AktEZKYx5qBV8SoVCIJtQYzMTGbmmj1UVlUTYtNKgJakuBW1QQwBcowxW4wxFcAUYMwJ9h8HTAYwxmw0xmxyvd8F5AOJFsaqVMC4oHd7SuwOnbu6hamuNs42iFaSIFKAHW7Lea51xxGRzkAGMNvDtiFAKLDZw7bbRCRbRLILCrROVrUOI7q3IyLEptVMLUxZhQNj/GeYDfCfRuqxwFRjTJX7ShHpALwL3GiMOW7WFGPMRGNMljEmKzFRCxiqdQgPsXF+72SmLskjt7DM1+GoZuJvQ32DtQliJ9DJbTnVtc6Tsbiql2qISCzwFfCQMWahJREqFaD+clEmIbYg/jx1JdXV5rjtu4sO49CZ6AKKv00WBNYmiMVAdxHJEJFQnElgeu2dRKQnEA8scFsXCnwKTDLGTLUwRqUCUvs24fzt0t4syt3P2/Nzj9n2UfYOzvjnDzwzc4NvglMn5ehIrq2gBGGMcQB3ATOBdcBHxpg1IvK4iFzmtutYYIoxxv1r0K+BM4Hxbo/BDrAqVqUC0VWDUji3ZxLPzFzPVldV0ytzN/PnqSsJsQkf/LL9yB8d5f/8sQRhaSTGmBnAjFrrHq21/JiH494D3rMyNqUCnYjw1JV9Oe/ZuTzw8QoGpsXx2k9bGd2vA+OHp3P1KwuYuiSPG0/P8HWoqgGKXck81o8ShL80UiulTkJyrLOqKXvbAV77aSs3DOvMf8YOJCs9gUFpcbw9P5cqD20Uyv+UlvtfI7X/pCql1Em5clAKG/eWkBgTxs1nZBwZKvqmMzK464NlzF6fz3m9kn0cpapPq6tiUkpZT0T4y8WZx62/sHd7OrYJ562ft2qCCAAl9kpsQUJEiM3XoRyhVUxKtVDBtiB+Oyyd+Zv3sW53sa/DUfUosTuIDgv2m8mCQBOEUi3auCGdCA8J4u2fc30diqqHvz6/F6cAABH/SURBVI3kCpoglGrR4iJDuWpQKp8u30mhTlXq12qmG/UnmiCUauFuPD2DqmrD3R8sw15ZVf8ByieKtQShlPK2bknR/OtX/Vm4dR93fbCMSh2Cwy+V2B1+1QcCNEEo1SpcPjCFxy/rzXfr9vLAxys8jt+kfMsfq5j8K10ppSzz22HpFNsdTJi5gYjQYO44qysp8RHYgvznqZnWzB8bqf0rGqWUpe48uyvFhyt59cctTF60nbDgILomRtOzQwxndk/kzB6JJESF+jrMVscY/5ssCDRBKNWqiAgPXtSTi/t2YP2eYjbtLSWnoJS5GwqYtnQnItAvNY4Leidz7ZDOtIn0ryqPlupwZRVV1UarmJRSviUi9O8UR/9OcUfWVVcbVu0sYs6GAn7YkM8z32zgxdk5jBuSxs1nZNAxLsKHEbd8NcNsRIf5159k/4pGKeUTQUFHk8a9o7qzfk8xr87dwtvzc3lnfi73n9eD35/TzddhtlhH54Lwrz/J+hSTUuo4PdvH8tw1A5j7wNmcfUoiz83aSN6BQ74Oq8UqdpUgYv2sikkThFKqTqnxkTw+pg8i8OrcLb4Op8Xyx5FcQROEUqoeHeMiuHpwKh9m72Bvsd3X4bRI/jjdKGiCUEo1wB1ndaOq2jDxRy1FWEFLEEqpgJXWNpIxAzry/i/b2KeD/jU7baRWSgW035/TjXJHNW/M2+rrUFqcErsDEYgK1QShlApAXROjuaRvByYt2MbBQxW+DqdFqZksKMjPhj3RBKGUarC7zu1GabmDf3+3CWN0wL/m4hzJ1b8aqEEThFKqEXq2j+WGYZ15e34u//5uk6/DaTFK7JV+14satCe1UqqR/nZpbw5VVPH895uwBQn3jOzu65ACnj+O5AqaIJRSjRQUJDx9VT+qjOHZWRuxBYkOw9FEJeWVJEaH+TqM42iCUEo1mi1ImHB1f6qrDRNmbuDz5TvplhRNt8RoenaIZVRmMqHBWoPdUCV2B13aRfs6jONoglBKnRRbkPB/v+pPj/YxLMk9wJpdxXyzeg/VBkZ0b8d/rxvsl/Xq/kirmJRSLU6wLYg7zz5avWSvrGLa0p088vlqrnl1AW+NP5Wk2HAfRuj/jDF+Od0o6FNMSqlmFB5i4zdD03j9hiy2FpZxxcvzyckvxRjDoQoHuw4eZn+Z9qFwV+6oprLKaAlCKdU6nHNKElNuO42b3l7Mxc//BEBFVTUAITbhoYszuWF4OiL+1THMFwpKnEOXxGqCUEq1Fv1S45h2x+m8syCXEFsQcZEhxEWEMGvtXh77Yi2Lcw/w9FV9fVa1YozxaYIyxjBt6U7+MWMdtiChT0obn8VSF2kpvSGzsrJMdna2r8NQStWjutow8actTJi5gbSESF6+dhCZHWK9GsOhCgfXv7GI+KhQXr52ECE279a25+SX8PBnq1m4ZT8D0+L4++V96dXRuz+DGiKyxBiT5WmbtkEopbwqKEi4/ayufHDLUMrKHYx7beGRapamOlThqHcIkOpqwx8/WsGS7QeYtXYvj3y22qvDhqzeWcRlL/7Mut0lPHVlXz65fbjPkkN9tIpJKeUTQ7u05YNbh3Lx8/N4bPoaXrp2UJPO969vN/DC7Bzax4YzuHM8gzvHc3q3dpzSPuaY/Z77biNfr97Dw5dkUnS4khdm59ApIdIrnf32FNm55Z1s4iJCmHbn6bRv499PeGmCUEr5TLekGO4d1Z0JMzcwetVuLurb4aTO88a8rbwwO4fzeyUTHmJjybYDfLVqN+Dsk/H7c7oxNCOB6St28cLsHH6dlcrNZ2QAsH3/ISbM3EBqfARjBqQ0273VdqjCwS2TFlNir2TqHcP9PjmAJgillI/ddmYXvl69m0c+X8Owrm2Jiwxt1PHTlubxxJdruahPe178zSBsriGzdxcd5vPlu3j9p62MnbiQgWlxrNlVzJCMBJ68vO+RBupnru7H7iI7D3y8kgNlFZzfuz0d4yKa9R6rqw33TVnO2l3FvH5DltfbXE6WpY3UInIh8DxgA143xjxda/tzwDmuxUggyRgT59p2A/Cwa9uTxph3TnQtbaRWKnCt3VXMZS/O47IBHXn21wM87mOvrOKnTYUE24SObSLoGBfO4tz93DppCUMzEnjrxlMJC7Z5PO6j7B28OncLITZh2p2nkxB1bBI6eKiC376xiFU7iwDo2T6GkZlJ3DqiS6MTVm1Fhyt5+uv1TF60nUdG9zpScvEXJ2qktixBiIgN2AicB+QBi4Fxxpi1dex/NzDQGHOTiCQA2UAWYIAlwGBjzIG6rqcJQqnA9uy3G/jP7ByeGNOboV3akhofQWRoMGt3FfPh4u18umwnxa65m931TWnD5NtOq3dYj6pqQ1W1qXOMKGMMOfmlzF6fz+z1+WRvO8DATnG8f+vQ4xJPTn4p01fs4rYzu9R53aLDlbz181bemLeVEruDW87I4KFLMv2u78eJEoSVVUxDgBxjzBZXEFOAMYDHBAGMA/7men8BMMsYs9917CzgQmCyhfEqpXzo9+d2Y9a6fB75fM2RdbHhwRTbHYQGB3FRn/ZcPTiViBAbu4rs7D54mEMVVVw/rHODxnyyBcmR6idPRITuyTF0T47hd2d15cuVu7jrg2X8Zdoq/vWr/kf+sK/fU8y1r/3CvrIK5mzI583xp9LObSRWR1U1r8/byks/5FBid3BB72TuGdmd3h39r59DfaxMECnADrflPGCopx1FpDOQAcw+wbHWtR4ppXwuLNjGp3cOZ+3uYvIOHGbH/kPsOniY7knRXD4wpclVPY01ul9HNueX8dx3G+mRHMPtZ3Vlza4irnv9F8KCbTwxpjd/n7GOq/47n0k3DaFz2yjW7ynmgY9XsmpnEaMyk7j/vB4BmRhq+Esj9VhgqjGmqjEHichtwG0AaWlpVsSllPKi8BAbg9LiGZQW7+tQALhnZDc25Zfwz2/WU1VtmPjjFqJCbUy+7TQ6t42iV8c23PzOYq7673yuGJjC2/NziQ0P4aXfDOKSfif3RJY/sbKj3E6gk9tyqmudJ2M5tvqoQccaYyYaY7KMMVmJiYlNDFcppY4l4hzSvF9KGybM3EB0WDAf/m4YndtGATC4czxTbx9OWLCN137ayoV9OvDt/We2iOQA1jZSB+NspB6J84/7YuA3xpg1tfbrCXwDZBhXMK5G6iVATc+ZpTgbqffXdT1tpFZKWSW/2M4rc7dw0xnppMZHHrd9X2k5WwvLyEpP8EF0TeOTRmpjjENE7gJm4nzM9U1jzBoReRzINsZMd+06Fphi3DKVMWa/iDyBM6kAPH6i5KCUUlZKig3n0Ut71bm9bXQYbf1wytCm0sH6lFKqFdPB+pRSSjWaJgillFIeaYJQSinlkSYIpZRSHmmCUEop5ZEmCKWUUh5pglBKKeVRi+kHISIFwDYPm9oARfWsc1/29L7m33ZA4UmG6CmOhmzX+I9dd7L3UF/8J9rnRPHWXq7vvcbf+H3q+x2q636aM/4TxVffdn//DHc2xngeq8gY06JfwMT61rkve3rv9m92c8bRkO0a/3HrTuoe6ou/MffQ2Pib4/9A4697XV3305zxN+QeAv0z7OnVGqqYvmjAui/qee/pHM0RR0O2a/zeif9E+5wo3trLDXl/MjT+utfVdT/NGX9DztESPgPHaDFVTN4gItmmji7pgSDQ44fAvweN37c0/sZpDSWI5jTR1wE0UaDHD4F/Dxq/b2n8jaAlCKWUUh5pCUIppZRHmiCUUkp51GoThIi8KSL5IrL6JI4dLCKrRCRHRP4jIuK27W4RWS8ia0TkmeaN+pgYmj1+EXlMRHaKyHLX6+Lmj/xIDJb8/F3b/ygiRkTaNV/EHuOw4v/gCRFZ6fr5fysiHZs/8iMxWBH/BNfv/0oR+VRE4po/8iMxWBH/r1yf3WoRsaQxuClx13G+G0Rkk+t1g9v6E35OGuRkn6kN9BdwJs4pTVefxLGLgNMAAb4GLnKtPwf4DghzLScFWPyPAX8K1J+/a1snnLMYbgPaBdo9ALFu+9wDvBJg8Z8PBLve/xP4Z4DFnwmcAswBsvwpbldM6bXWJQBbXP/Gu97Hn+geG/NqtSUIY8yPwDHTmIpIVxH5RkSWiMhPrvmyqbVPB5wf4oXG+b8wCbjctfkO4GljTLnrGvkBFr/XWBj/c8CfAcufvrDiHowxxW67RmHhfVgU/7fGGIdr14VAaoDFv84Ys8GqmJsSdx0uAGYZY/YbYw4As4ALm+tz3moTRB0mAncbYwYDfwJe9rBPCpDntpznWgfQAxghIr+IyFwROdXSaI/X1PgB7nJVD7wpIvHWhepRk+IXkTHATmPMCqsDPYEm/x+IyN9FZAdwLfCohbF60hy/QzVuwvnN1ZuaM35vakjcnqQAO9yWa+6lWe4xuLEHtFQiEg0MBz52q6pr7CzkwTiLeqcBpwIfiUgXVwa3VDPF/1/gCZzfWp8A/oXzQ265psYvIpHAX3FWcfhEM/0fYIx5CHhIRP4C3AX8rdmCPIHmit91rocAB/B+80TXoGs2W/zedKK4ReRG4F7Xum7ADBGpALYaY66wOjZNEEcFAQeNMQPcV4qIDVjiWpyO84+oe7E5Fdjpep8HTHMlhEUiUo1zcK0CKwN3aXL8xpi9bse9BnxpZcC1NDX+rkAGsML1IUsFlorIEGPMHotjr9Ecv0Pu3gdm4KUEQTPFLyLjgdHASG98OXLT3D9/b/EYN4Ax5i3gLQARmQOMN8bkuu2yEzjbbTkVZ1vFTprjHq1ohAmUF5COW0MRMB/4leu9AP3rOK5248/FrvW3A4+73vfAWfSTAIq/g9s+9wNTAunnX2ufXCxupLbo/6C72z53A1MDLP4LgbVAotU/eyt/h7Cwkfpk46buRuqtOBuo413vExpyjw2K0xv/if74AiYDu4FKnN/8b8b5DfQbYIXrl/zROo7NAlYDm4EXOdojPRR4z7VtKXBugMX/LrAKWInzm1aHQIq/1j65WP8UkxX/B5+41q/EObhaSoDFn4Pzi9Fy18vKp7CsiP8K17nKgb3ATH+JGw8JwrX+JtfPPQe4sTGfk/peOtSGUkopj/QpJqWUUh5pglBKKeWRJgillFIeaYJQSinlkSYIpZRSHmmCUC2aiJR6+Xqvi0ivZjpXlThHdV0tIl/UNzKqiMSJyJ3NcW2lQGeUUy2ciJQaY6Kb8XzB5uhgdJZyj11E3gE2GmP+foL904EvjTF9vBGfavm0BKFaHRFJFJFPRGSx63W6a/0QEVkgIstEZL6InOJaP15EpovIbOB7ETlbROaIyFRxzn3wfs1Y+671Wa73pa6B91aIyEIRSXat7+paXiUiTzawlLOAo4MSRovI9yKy1HWOMa59nga6ukodE1z7PuC6x5Ui8r/N+GNUrYAmCNUaPQ88Z4w5FbgKeN21fj0wwhgzEOcoqv9wO2YQcLUx5izX8kDgPqAX0AU43cN1ooCFxpj+wI/ArW7Xf94Y05djR9z0yDWW0EicvdsB7MAVxphBOOcg+ZcrQT0IbDbGDDDGPCAi5wPdgSHAAGCwiJxZ3/WUqqGD9anWaBTQy23kzFjXiJptgHdEpDvOEW1D3I6ZZYxxH8N/kTEmD0BEluMcW2deretUcHTAwyXAea73wzg6Nv8HwP/VEWeE69wpwDqcY/2Dc2ydf7j+2Fe7tid7OP5812uZazkaZ8L4sY7rKXUMTRCqNQoCTjPG2N1XisiLwA/GmCtc9flz3DaX1TpHudv7Kjx/lirN0Ua+uvY5kcPGmAGuocxnAr8H/oNznohEYLAxplJEcoFwD8cL8JQx5tVGXlcpQKuYVOv0Lc6RUgEQkZphlttwdEjk8RZefyHOqi2AsfXtbIw5hHP60T+KSDDOOPNdyeEcoLNr1xIgxu3QmcBNrtIRIpIiIknNdA+qFdAEoVq6SBHJc3v9Aecf2yxXw+1anMO0AzwDPCUiy7C2dH0f8AcRWYlzEpii+g4wxizDOcLrOJzzRGSJyCrgepxtJxhj9gE/ux6LnWCM+RZnFdYC175TOTaBKHVC+pirUl7mqjI6bIwxIjIWGGeMGVPfcUp5m7ZBKOV9g4EXXU8eHcRL07oq1VhaglBKKeWRtkEopZTySBOEUkopjzRBKKWU8kgThFJKKY80QSillPLo/wHg1BoWTWiElgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "engine": 0,
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.586601</td>\n",
       "      <td>0.530112</td>\n",
       "      <td>0.737600</td>\n",
       "      <td>02:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 2e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('first');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 04:03 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.255913</th>\n",
       "    <th>0.169186</th>\n",
       "    <th>0.937800</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('second')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('second');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 05:42 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.223174</th>\n",
       "    <th>0.165679</th>\n",
       "    <th>0.939600</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(1, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('third')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('third');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 15:17 <p><table style='width:300px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.240424</th>\n",
       "    <th>0.155204</th>\n",
       "    <th>0.943160</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>0.217462</th>\n",
       "    <th>0.153421</th>\n",
       "    <th>0.943960</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(2, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Category pos, tensor(1), tensor([7.5928e-04, 9.9924e-01]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.predict(\"I really loved that movie, it was awesome!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
