{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -s https://course.fast.ai/colab/setup | bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastai2 --upgrade > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai2.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datablock = DataBlock(\n",
    "    blocks=(ImageBlock(cls=PILImageBW),CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    get_y=parent_label,\n",
    "    splitter=GrandparentSplitter(),\n",
    "    item_tfms=Resize(28),\n",
    "    batch_tfms=[]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting-up type transforms pipelines\n",
      "Collecting items from /Users/butch/.fastai/data/mnist_tiny\n",
      "Found 1428 items\n",
      "2 datasets of sizes 709,699\n",
      "Setting up Pipeline: PILBase.create\n",
      "Setting up Pipeline: parent_label -> Categorize\n",
      "\n",
      "Building one sample\n",
      "  Pipeline: PILBase.create\n",
      "    starting from\n",
      "      /Users/butch/.fastai/data/mnist_tiny/train/7/9243.png\n",
      "    applying PILBase.create gives\n",
      "      PILImageBW mode=L size=28x28\n",
      "  Pipeline: parent_label -> Categorize\n",
      "    starting from\n",
      "      /Users/butch/.fastai/data/mnist_tiny/train/7/9243.png\n",
      "    applying parent_label gives\n",
      "      7\n",
      "    applying Categorize gives\n",
      "      TensorCategory(1)\n",
      "\n",
      "Final sample: (PILImageBW mode=L size=28x28, TensorCategory(1))\n",
      "\n",
      "\n",
      "Setting up after_item: Pipeline: Resize -> ToTensor\n",
      "Setting up before_batch: Pipeline: \n",
      "Setting up after_batch: Pipeline: IntToFloatTensor\n",
      "\n",
      "Building one batch\n",
      "Applying item_tfms to the first sample:\n",
      "  Pipeline: Resize -> ToTensor\n",
      "    starting from\n",
      "      (PILImageBW mode=L size=28x28, TensorCategory(1))\n",
      "    applying Resize gives\n",
      "      (PILImageBW mode=L size=28x28, TensorCategory(1))\n",
      "    applying ToTensor gives\n",
      "      (TensorImageBW of size 1x28x28, TensorCategory(1))\n",
      "\n",
      "Adding the next 3 samples\n",
      "\n",
      "No before_batch transform to apply\n",
      "\n",
      "Collating items in a batch\n",
      "\n",
      "Applying batch_tfms to the batch built\n",
      "  Pipeline: IntToFloatTensor\n",
      "    starting from\n",
      "      (TensorImageBW of size 4x1x28x28, TensorCategory([1, 1, 1, 1]))\n",
      "    applying IntToFloatTensor gives\n",
      "      (TensorImageBW of size 4x1x28x28, TensorCategory([1, 1, 1, 1]))\n"
     ]
    }
   ],
   "source": [
    "datablock.summary(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = datablock.dataloaders(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAAIHCAYAAADpfeRCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd7QV5dXH8f3Qe1Ow0hVBwIoNYkQ0imJBLCCKGMWGLbFh12WJBSsWLNGFBkUQUWJBXbGAigWxxYKoFxuCiIgU4dLm/eMmeU32vjLnzLnnzNz9/azFH/l5ZmYHHi6bYd/nCVEUCQAA8KVGqQsAAADFRwMAAIBDNAAAADhEAwAAgEM0AAAAOEQDAACAQzQAAAA4RAOQoxDCsv/5sTaEcFup6wJyEUIYG0KYF0JYEkKYHUIYVuqagFyxjpMJbASUvxBCIxGZLyL7R1E0rdT1AHGFELqKyOdRFJWHEDqLyMsi0i+KopmlrQyIj3WcDG8AkjlURBaIyCulLgTIRRRFH0VRVP7v//mvHx1LWBKQM9ZxMjQAyQwVkQcjXqMgg0IId4YQfhGRWSIyT0SeKXFJQM5Yx/njnwDyFEJoKyJlIrJFFEVzSl0PkI8QQk0R2U1EeovIdVEUrS5tRUDuWMf54Q1A/oaIyKv84Y8si6JobRRFr4rI5iJySqnrAfLBOs4PDUD+jhGRB0pdBFAgtYR/O0X2sY5zQAOQhxBCTxHZTEQeLXUtQK5CCK1CCINCCI1CCDVDCPuKyJEi8kKpawPiYh0nxwxAHkIId4tIgyiKhpS6FiBXIYSWIjJRRLaVir8EfCUio6IourekhQE5YB0nRwMAAIBD/BMAAAAO0QAAAOAQDQAAAA7RAAAA4BANAAAADtVaz3/nWwSQRCh1AcIaRjJpWMMirGMkY65j3gAAAOAQDQAAAA7RAAAA4BANAAAADtEAAADgEA0AAAAO0QAAAOAQDQAAAA6tbyMgAABS7bLLLlPZVVddleieffr0Udn111+vsm7duqmsdu3aiZ5dLLwBAADAIRoAAAAcogEAAMAhGgAAABwKUfSbh0xxAhWSSMNJaqxhJJGGNSzCOv6P9957T2U77rijykIo/C+d9eflaaedprJbb7214M9OiNMAAQBABRoAAAAcogEAAMAhGgAAAByiAQAAwCG+CwBVKQ0T1KxhJJGGNSzCOv6PxYsXq2zYsGEqmzdvnsratWsX+zlPPPGEylauXKmypk2bqmzKlCkq22WXXWI/uwrwXQAAAKACDQAAAA7RAAAA4BANAAAADjEEiKqUhgEq1jCSSMMaFmEd/6a1a9eqbPXq1SqrV69e7Hsee+yxKvvb3/6mMmvL4YEDB6rsoYceiv3sKsAQIAAAqEADAACAQzQAAAA4RAMAAIBDmRoC/Omnn1Rm7Qr10ksvqezTTz9N9OwBAwaorFWrVirbdNNNVVa3bt1Ez86wNAxQpWoNL1y4UGU333yzyq655hqVVfZ7Ne6552eccYbKBg8erLJmzZqpbMaMGSpbsWKF+ZwOHTqobPPNN49Tomy22WYqa9iwYaxrq0ga1rBIytaxB23atFHZ3LlzVWb9/nvjjTdU1qNHj8IUlh+GAAEAQAUaAAAAHKIBAADAIRoAAAAcytQQ4AYbbKCyRYsWxbq2fv36Zt6pUyeVWcdILl++PFZm3e/uu+9W2e67727WU7NmTTPPqDQMUBVlDVvHhI4ePVplV1xxhcp+/vnnKqkpi4466iiVPfDAAyqrUaNof3dJwxoWSdnX4iywdgf85ptvVHbppZea11s7961bt05l/fr1U9lTTz0Vp8RiYggQAABUoAEAAMAhGgAAAByiAQAAwKFapS4gF48//nje1+66665mXqdOnbzv+frrr6vMGhzp06ePyrp162be8+mnn1ZZ69at86gOxTRmzBiVnX322cUvJOOmTZumsvLycpVVNtQLn5YuXaqye+65R2UjRoyIfU9rh78rr7xSZaeddlrse6YNbwAAAHCIBgAAAIdoAAAAcIgGAAAAhzK1E2BW1a5dW2WVHRE8c+ZMlW211VYFr6lI0rCLWlHW8D/+8Q+VDRo0SGVxd67ccccdVda9e3fzswcccIDK5s+fr7L+/furbOONN45Vj8Xa6VBE5PTTT8/7nrfffrvKhg8fnvf9CiANa1jE6dfisrIylVnHvV9//fUq++KLLxI9+7rrrlNZhgd72QkQAABUoAEAAMAhGgAAAByiAQAAwKFM7QSYBS+88ILKrGMpX3zxRfP6DA/8ubb33nurzBpgWrVqVaz7NWnSRGVJdq2sjFWPdRy2NdD4wQcfJHp23759VXbwwQcnuifSzzo6W8Qe9nz00UdVtmLFCpVZw+zWTn6WHj16mHmSYdas4A0AAAAO0QAAAOAQDQAAAA7RAAAA4BANAAAADrEVcAKLFy9W2fbbb6+yzp07q+ypp54y71mzZs3khaVHGrZRdbmGP/vsM5U99thjKps4caLK3nnnnUTPbt26tcquuuoqlR1++OEqq1evXqJnV4E0rGGRjK7j5cuXq2yLLbYwP/vDDz/k/Zwk3wVQmY022khl06dPV1nbtm0TPadI2AoYAABUoAEAAMAhGgAAAByiAQAAwKFqOQT45ptvqmzq1KnmZ0855RSVNW7cONZzdthhB5W9++67Kps8ebLKDjrooFjPyLg0DFBlcg1bvv76azMfN26cyi6++GKVWVtSx9WgQQOVjRo1yvzsMccco7JatTK763ga1rBINVrH7733npmff/75KrO2xE6yXfQXX3yhsquvvtr87Jo1a1R29NFHq+yBBx7Iu54iYggQAABUoAEAAMAhGgAAAByiAQAAwKFqOQRonSF9xBFHmJ/ddtttVTZ69GiVbbDBBirr3r27ynr16qWy559/XmUZHorKRRoGqFK1hq1BvOeee05lY8eOVdmECRPMe65bty55Yb/SoUMHlU2ZMkVlm222Wex71q9fX2VJd2orkrQUmap1XJ3ccsstZn7OOeeozNqp8v3331dZx44dkxdWWAwBAgCACjQAAAA4RAMAAIBDNAAAADhULYcAV65cqbJJkyaZnz3qqKNUVqdOHZU1atRIZdbPnbUL4ZZbbmk+24E0DFClag2XlZWprLLjUauTm266SWUnnXSSyqxhwRJLwxoWSdk6rk6WLVtm5tYg38KFC1V27LHHquy+++5LXFeBMQQIAAAq0AAAAOAQDQAAAA7RAAAA4FC13I7O2q3pyCOPND9rHfk4dOhQlS1atCjWPVu2bBmnRDhlrU1r8G3FihWx72kdS92wYUOVbbzxxiqzjqW+5557VLZ06VKVVXasq+Wss85S2eeff66ykSNHqiyFg4GoRqwBbxGRunXrxrr+s88+K2Q5RcUbAAAAHKIBAADAIRoAAAAcogEAAMCharkTYC7effddlVlDVdbRpdbP3YYbbqiyPn36qGzw4MFmPdagVnl5ucq6dOmishYtWpj3jKOyo1lr1EjUI6ZhF7XUr+FvvvlGZQ8++KDKjjnmGPP6TTbZRGWFPm569erVKps/f7752b/85S8qu/fee1VmHWP8zDPPqGzfffdVWRGPEk7DGhYp0jpevny5yp544gmV3XbbbSr77rvvVGYNo1588cWx6znkkENU1qBBg9jXJ9GmTRuVzZ07V2XWEfDTpk2rkpoSYCdAAABQgQYAAACHaAAAAHCIBgAAAIfcDwFef/31KrvssstU9txzz8W639ixY1VmDTZZwySl1KlTJzPv16+fyrp27aqy448/3ro8DQNU1X4NZ8GNN96osnPPPTfWtYsXL1ZZkyZNEtcUUxrWsEgVrOPXXntNZb///e8L+gxr0DPhYHHs52y66aYq+9Of/hT7nldeeaXKrB0xredYP7fWYGD37t1Vtv3228ctMRcMAQIAgAo0AAAAOEQDAACAQzQAAAA4RAMAAIBDbr4LYPbs2Wbeo0cPlbVu3VplH330Ud7PXrZsmcqsLTdFRMaMGZP3c3bbbTeVff/99yqztq5csGCBeU9ra+KaNWuqrGXLltblaZigrjZrOMu+/PJLlXXo0CHWtXwXgIhUwToeOXKkyi644IJY11pbnlvfSZT0uwCs7abLyspUZv05VhXbRSd5zjbbbKOy8847T2WDBg3KvbD147sAAABABRoAAAAcogEAAMAhGgAAABwq7KHhKfbqq6+aubW145lnnlnQZzdq1ChWJiIyYsSIgj47Lms7SyAfa9asUdnhhx8e61prwLQqhrkgsuWWW+Z9bf369VVmbfdsfS4X1nDy6NGjVTZp0qREz4mrbt26KjvppJNUNmzYMJVtscUWse5XTLwBAADAIRoAAAAcogEAAMAhGgAAAByqljsBWjuHVXbGsrXT1Hfffaey5s2bJy/MnzRMb2VyDWeBNewnIrLVVlupbM6cObHuec8996jMGqgqojSsYZEqWMdr165V2a233qoya7e6uLKwQ1+XLl3M/O9//7vKGjRooLKNNtoo1nNKjJ0AAQBABRoAAAAcogEAAMAhGgAAAByqlkOAN9xwg8rOPfdc87NDhgxR2YMPPljwmpxKwwBVJtdw2ixcuFBl++23n/nZmTNnxrqndYT0+++/rzLrSOoiSsMaFinSOrYGA1euXKkya+c9a2jO+lyxhgCtr+2HHHKIyvr27Wves9S79BUYQ4AAAKACDQAAAA7RAAAA4BANAAAADlXL44C/+uorldWoYfc6++67b1WXA/yHNWRlrc1cBqWsASgrKysrU9ns2bNVNmXKFJU9+eSTKvv666/jliitWrVS2euvv66yEg/8uWcdx9ywYUOVWQN2VoZ04w0AAAAO0QAAAOAQDQAAAA7RAAAA4FDmdwJct26dyvr166eyrbfe2rz+xhtvLHhN+I807KJWlDX8008/qcwacjvooINUdvPNN6tsr732Utl9991nPvuXX35R2bRp01T2ySefmNfnyxoYExEZPXq0yoYOHaqy2rVrF7SeKpKGNSySga/FSDV2AgQAABVoAAAAcIgGAAAAh2gAAABwKPM7AVpDjNYxjtYQElAo48ePV9nw4cNjXXvmmWcWuhxTvXr1VNasWbNY2aGHHqqy8847z3xO48aN86gOQLHxBgAAAIdoAAAAcIgGAAAAh2gAAABwiAYAAACHMv9dANZ2pA899JDKrDOtgSzZeOONzfzoo49W2QEHHKCy9u3bq6x58+Yqa9SoUR7VAcga3gAAAOAQDQAAAA7RAAAA4BANAAAADgVrK91f4QxqJJGGs9RZw0giDWtYhHWMZMx1zBsAAAAcogEAAMAhGgAAAByiAQAAwCEaAAAAHKIBAADAIRoAAAAcogEAAMAhGgAAABxa306AAACgGuINAAAADtEAAADgEA0AAAAO0QAAAOAQDQAAAA7RAAAA4BANAAAADtEAAADgEA0AAAAO0QAAAOAQDQAAAA7RAAAA4BANAAAADtEAAADgEA1AjkIIy/7nx9oQwm2lrgvIBesY1UEIYWwIYV4IYUkIYXYIYVipa8qSEEVRqWvIrBBCIxGZLyL7R1E0rdT1APlgHSOrQghdReTzKIrKQwidReRlEekXRdHM0laWDbwBSOZQEVkgIq+UuhAgAdYxMimKoo+iKCr/9//814+OJSwpU2gAkhkqIg9GvEZBtrGOkVkhhDtDCL+IyCwRmSciz5S4pMzgnwDyFEJoKyJlIrJFFEVzSl0PkA/WMaqDEEJNEdlNRHqLyHVRFK0ubUXZwBuA/A0RkVf5oomMYx0j86IoWhtF0asisrmInFLqerKCBiB/x4jIA6UuAkiIdYzqpJYwAxAbDUAeQgg9RWQzEXm01LUA+WIdI8tCCK1CCINCCI1CCDVDCPuKyJEi8kKpa8uKWqUuIKOGisikKIqWlroQIAHWMbIskorX/XdJxV9mvxKRP0VR9PeSVpUhDAECAOAQ/wQAAIBDNAAAADhEAwAAgEM0AAAAOLS+7wJgQhBJhFIXIKxhJJOGNSzCOkYy5jrmDQAAAA7RAAAA4BANAAAADtEAAADgEA0AAAAO0QAAAOAQDQAAAA7RAAAA4BANAAAADtEAAADgEA0AAAAO0QAAAOAQDQAAAA7RAAAA4BANAAAADtEAAADgEA0AAAAO0QAAAOAQDQAAAA7RAAAA4FCtUhcAAEChrVq1SmUzZsxQ2e67725eH0JQWf369VX25JNPqmzPPfeMU2LJ8QYAAACHaAAAAHCIBgAAAIdoAAAAcIghQABAps2fP19ljz/+uMpOP/10lVnDfpXlK1euVNmdd96psl133VVl1gBhqfEGAAAAh2gAAABwiAYAAACHaAAAAHCIIUAAQGa88MILKhs9erTKnnjiiVj3mzBhgpnPnj1bZZdcconKPv/881jPSSPeAAAA4BANAAAADtEAAADgEA0AAAAOMQQY05IlS1T24YcfqmzatGkq++qrr1R21113xX72ySefrDJr6AUA0mTt2rUqs3btExHZbLPNVDZ8+HCVTZ48WWXff/+9ynr06KGyW265RWXWrn0i9g5/lgEDBqgsjbv+WXgDAACAQzQAAAA4RAMAAIBDNAAAADgUoij6rf/+m/8xH9dee63KrCE5izU417dvX5V9+umnKpszZ06sZ2TFF198obIOHTqUoJLfZJ+zWVwFX8PVyYoVK1S2bNkylTVu3FhlI0eONO+5atUqlX3wwQcq22abbVR2/vnnq6xhw4bmc4okDWtYJKPreNasWSqrbOhuq622Utnbb7+tMuuY3ksvvVRlZ555psqaNm2qskWLFpn17LTTTipbsGCBymbMmKGyzp07m/csIXMd8wYAAACHaAAAAHCIBgAAAIdoAAAAcKjKhgDLysrMvGPHjvneMnXat2+vMmuQpV27diobMmSIec9evXrFevZrr72msp49e8a6tojSMEBVsuEpa1fINWvWFPw5Tz75pMqs4SuLNYDboEEDlVkDUXfffXesZ+TinXfeUdl2221X8OfkIA1rWCSjQ4CrV69W2TPPPGN+9v7771fZtttuq7Jzzz1XZdaQalynn366mVs7AZ544okqy8iurAwBAgCACjQAAAA4RAMAAIBDNAAAADhUZUOA1vG5IiIDBw5U2SWXXJLvY2Lr1q2bmTdp0qTKn21JOiS5nl+3tEjDAFVRfqLKy8tVZu1SOXXq1Fj3s359rR3QqoL1HCtbt25dwZ89ePBglY0dO7bgz8lBGtawSEaHANPG2vWvX79+5metHf5efPFFlf3+979PXljVYwgQAABUoAEAAMAhGgAAAByiAQAAwCEaAAAAHKpVVTeubLp+ypQpVfXITJkwYUKpS0ABWVuevvHGG3nfr1gT/xbrOxCK9V0nhx9+eFGeg+xauXKlyqzfL9Z3op1zzjkqe+utt8znnH322Srbdddd45SYGbwBAADAIRoAAAAcogEAAMAhGgAAAByqsiFA/La4W8IiGxo1aqSy1157TWXjxo1T2b333quyunXrqqx+/frmszt06KCyQYMGmZ/9X9Z5602bNlXZe++9pzJr295cXHfddSo78MADE90T1cuzzz6rsuOPP15lG2ywQaz7ffzxxyrr37+/+dkRI0aorE6dOrGekxW8AQAAwCEaAAAAHKIBAADAIRoAAAAcCuvZ4YszqKtILju9nXzyySobPXp0IcupKmk4Sz31a/iHH35QmTXwZw0aVoVVq1apbPfdd1eZdV56ZY4++miV3XHHHSpr3Lhx7HsWSRrWsEgG1nFSr7zyisoOO+wwlf34448q22WXXVT25ptvxnpuZQOETz75pMp23nnnWPdMIXMd8wYAAACHaAAAAHCIBgAAAIdoAAAAcIidADOgbdu2pS4BVahly5alLuG/3HnnnSrLZeDPkpGBPxTBwoULzdwa+FuwYIHKatTQf2+1jt5u2LChyrp06aKyygayx48fr7Ltt99eZbVr1zavzwLeAAAA4BANAAAADtEAAADgEA0AAAAOMQRYBNYRsLk4//zzC1QJsH4PPvhgout79+6tsnr16iW6J6qPyoburNwa+LM+Z62vM844Q2UXXXSRyvr06WPW8+6775p5dcIbAAAAHKIBAADAIRoAAAAcogEAAMAhhgCLYPDgwbE/27dv3yqsBPhv1q5/7733Xqxr27RpY+ZPPPGEyrK8WxoKq1mzZmb+8ssvq2yvvfZS2R//+EeVWTv8HXXUUbHqqWxHyiVLlqgsiqrXqcy8AQAAwCEaAAAAHKIBAADAIRoAAAAcYgiwwKzBkVzsscceBaoEWL+JEyfmfW3Hjh3NvEmTJnnfE9VfzZo1zbxz584qmzt3blWXYx4bLCIyf/78Kn92qfEGAAAAh2gAAABwiAYAAACHaAAAAHCIBgAAAIf4LoACGzFiRKLrzz///AJVAs/WrVunsrPOOktlM2bMiHU/a0J70qRJuRcGlNC8efNUNn36dPOz5557rspq1apef2TyBgAAAIdoAAAAcIgGAAAAh2gAAABwKKznfOPqdfhxEYQQYn2ub9++Zj5lypRCllNq8X4yqpbLNTxr1iyVbb311nnfzxr469+/f973y5A0rGGRBOt48eLFZr5y5UqVNW/eXGV169bN99FFYw29vvTSSyrbZ599VFbZ/79PPvlEZW3bts2julQw1zFvAAAAcIgGAAAAh2gAAABwiAYAAACHqte2RkV27bXX5n3tHXfcUcBK4Nny5ctVNnz48Lzvt8cee6isZ8+eed8PxWMN9l188cXmZ8eMGaOyiRMnqqyygeVS+fTTT1VmDalecsklKuvatavKbrrpJvM5GR74i403AAAAOEQDAACAQzQAAAA4RAMAAIBD7ASYQNxd/9q3b6+ysrKyQpeTRmnYRa3ar+HZs2erzDq+19K6dWuVTZs2TWUeBqIqkYY1LBJzHVsDoT169DA/+/nnn6tst912U9nIkSNV1q1btzjl5OSbb75RmTXI9/TTT6ts1apVKttyyy1VNm7cOJVtt912cUvMMnYCBAAAFWgAAABwiAYAAACHaAAAAHCInQBjsoZH4rr66qsLWAnw37799tu8r33llVdU1qZNmyTloIQaNmyosn333df87Geffaay6dOnq6xXr14qs4bH4w5F58J6ziabbKKyP//5zyo78MADVdapU6fCFFZN8AYAAACHaAAAAHCIBgAAAIdoAAAAcIidAGNKMuCynp/j6iwNu6hVm59866hXEZHevXur7K233lLZ0KFDVTZq1CiVNW7cOPfiqq80rGGRBOu4vLzczF977TWVWUOho0ePVtkPP/ygsqRDgKeeeqrKLrzwQpXVr19fZU2aNEn0bAfYCRAAAFSgAQAAwCEaAAAAHKIBAADAIXYCNCTZ9e/kk08uYCXA/3v44YfN3Br4swwaNEhlDPxVf3Xr1jXzPn36xMouu+yygteEdOANAAAADtEAAADgEA0AAAAO0QAAAOAQDQAAAA7xXQCGiy66KO9rrW0zgUJYs2ZN7M9a26VaWwYD8Is3AAAAOEQDAACAQzQAAAA4RAMAAIBDDAEaxo4dq7JevXqp7JprrilGOYCIiDz66KOxPztq1CiVVbYlLACfeAMAAIBDNAAAADhEAwAAgEM0AAAAOMQQoKFnz54qi6KoBJUA/+/II48089mzZ6ts4MCBVV0OgIzjDQAAAA7RAAAA4BANAAAADtEAAADgUGC4DQAAf3gDAACAQzQAAAA4RAMAAIBDNAAAADhEAwAAgEM0AAAAOEQDAACAQzQAAAA4RAMAAIBDNAAAADhEAwAAgEM0AAAAOEQDAACAQzQAAAA4RAOQhxDC2BDCvBDCkhDC7BDCsFLXBOQihLDsf36sDSHcVuq6gLhYw8mFKIpKXUPmhBC6isjnURSVhxA6i8jLItIviqKZpa0MyF0IoZGIzBeR/aMomlbqeoBcsYbzwxuAPERR9FEUReX//p//+tGxhCUBSRwqIgtE5JVSFwLkiTWcBxqAPIUQ7gwh/CIis0Rknog8U+KSgHwNFZEHI14HIrtYw3ngnwASCCHUFJHdRKS3iFwXRdHq0lYE5CaE0FZEykRkiyiK5pS6HiBXrOH88QYggSiK1kZR9KqIbC4ip5S6HiAPQ0TkVb5wIsNYw3miASiMWsIMALLpGBF5oNRFAAmwhvNEA5CjEEKrEMKgEEKjEELNEMK+InKkiLxQ6tqAXIQQeorIZiLyaKlrAfLBGk6mVqkLyKBIKl733yUVDdRXIvKnKIr+XtKqgNwNFZFJURQtLXUhQJ5YwwkwBAgAgEP8EwAAAA7RAAAA4BANAAAADtEAAADg0Pq+C4AJQSQRSl2AsIaRTBrWsAjrGMmY65g3AAAAOEQDAACAQzQAAAA4RAMAAIBDNAAAADhEAwAAgEM0AAAAOEQDAACAQzQAAAA4RAMAAIBDNAAAADhEAwAAgEM0AAAAOEQDAACAQzQAAAA4RAMAAIBDNAAAADhEAwAAgEM0AAAAOEQDAACAQ7VKXUCxLF682MxXrlypsnr16qmsWbNmBa8JAIBS4Q0AAAAO0QAAAOAQDQAAAA7RAAAA4FBqhwDXrFmjshkzZqjs/vvvV9miRYtUNm3aNPM5P/30k8qaN2+usj322ENlURSpbNCgQSo75JBDVFarVmp/6gEADvAGAAAAh2gAAABwiAYAAACHaAAAAHAoWINsv/Kb/zEf5eXlKrv99ttVdsMNN6jshx9+UNmGG26oMmvobtttt41boun9999X2aRJk1T2448/quy4445T2Z133mk+p5oNB4ZSFyBVsIbhShrWsEiR1vEFF1ygMmso+vDDD1fZJptsojJrV9VcWDu1Ll26VGV16tRRWc2aNVW2ZMkSlTVp0sR8tlV7hr8+m+uYNwAAADhEAwAAgEM0AAAAOEQDAACAQ0UfAhw2bJjKxowZE+vagQMHqszaCbBu3bo515UPa6Bx3LhxKhs+fLjK+vTpY97z4YcfVlllQyoZkIYBqmozBGgNRImIvPjiiyqbPHmyyt58802VWYNOxx57rMoOPfRQlbVs2dKsp5pJwxoWKdI6PuKII1T22GOPxbq2VatWKuvevXuiembOnKmyyo52/1/Wn20hxP/l7Nq1q8ruuusulfXs2TP2PaEzLq0AAAnNSURBVEuIIUAAAFCBBgAAAIdoAAAAcIgGAAAAh4o+BGjtzmQNZvTv319lDz30kMqKNfCXxFVXXaWyyy+/3PysdWxxRoZMLGkYoEr9EOC6detUZg38HXbYYeb1zz77rMqs4b64A1ArVqxQmTXgZT1XRGS77baL9ZyMSMMaFinSOrbW4lNPPaWyRx55JNb9PvnkE5V98MEH5md33nlnlbVv3z7Wc5J46623zHzOnDkq+93vfqeyqVOnFrymKsAQIAAAqEADAACAQzQAAAA4RAMAAIBDRR8CtHYPswZP5s6dq7KkR0uWyvLly1WWy+5+a9euLWQ5xZSGAaqiDE+tWrVKZffcc4/KrIGjsrIylX344Ycq+8Mf/mA++6KLLlJZly5dVBZ3YNbazfKEE05QWaNGjczrv/76a5VZx7VmRBrWsEgGhlkt1td2KxMRqVFD/33UygrN+r0mIrLDDjuozFrzL730ksqSHj9fBRgCBAAAFWgAAABwiAYAAACHaAAAAHCo6EOAX375pcqsY0qto3+zyhoCbNq0aezr16xZU8hyiikNA1RFGZ6aMmWKyvbff3+VWbudWUdAd+zYsTCFFYh1pLV1NKqIyC+//KKyrA7wSjrWsEhGhwCzrGHDhiqzduj8/vvvVbbhhhtWSU0JMAQIAAAq0AAAAOAQDQAAAA7RAAAA4BANAAAADtUq9gPbtWsXK8sqa0q0svOv41q9erXKateuneieKCzrnPDHHntMZdY2uWmb+LdY35VT2XcBWFur9ujRo+A1AYUwc+ZMMy8vL1fZVlttpbLmzZsXvKZi4Q0AAAAO0QAAAOAQDQAAAA7RAAAA4FDRhwDT5osvvlDZ3LlzVfbII4/Eut/kyZNVZm0VmYt99tlHZQcffLDKjj32WJU1a9Ys0bMRT+PGjVU2YMCAElRSNe69916V1a1b1/xshw4dqrocIC/W1vfHHHNM7M/uvffeKqtZs2bywkqENwAAADhEAwAAgEM0AAAAOEQDAACAQ8EadPiVTJ5BvWLFCpXdeuut5mcvu+wyla1du1Zlp556qsreeustlc2YMSNOiTmxfo1C0Mc7W8NXb7zxhspatGhRmMLWLw1nqWdyDZfSd999p7L27durrH///ub148ePL3hNJZSGNSzCOi4Ia20OHjzY/GyNGvrvx9bX9+222y55YVXPXMe8AQAAwCEaAAAAHKIBAADAIRoAAAAcyvxOgIsWLVLZ/vvvr7LKhvNOPPFElVkDg9b1o0aNUpk1OGLtFHXooYea9VxxxRUqu/baa1U2ZswYlVm7GrZs2VJln376qcq22GILsx74Yw3RWkdSA1lz3333xf5sz549VZaRgb/YeAMAAIBDNAAAADhEAwAAgEM0AAAAOJT5IcD99ttPZW+//bbKunbtal6//fbbq8w68nH69Okqswb+rB36rON8x40bZ9ZjGT16tMp69OihstNPPz3W/ax6ysrKYtcDiIgMHDiw1CUAlZo6darKXnnlldjXX3755Sq75pprVLbJJpuozBq0tnTv3l1l/fr1Mz/btGnTWPfMBW8AAABwiAYAAACHaAAAAHCIBgAAAIcyPwQY18cff2zmw4cPz/ueTZo0UZm1O2DSYak6deqo7IQTTlDZL7/8orIRI0ao7Ouvv05UD6q35557Ltbn+vbtW8WVAPG8/vrrKuvdu7fKrCHtyuy1115JSlI22GADlbVu3Vpl9erVM68fMGBAQesR4Q0AAAAu0QAAAOAQDQAAAA7RAAAA4JCbIcBevXqZeatWrWJdf9xxx6lsl112UVmLFi1yKyxPtWrpX7oGDRoU5dmo3qzd0ho1aqQyaydMoKotW7ZMZcOGDVOZNfDXvHlzlUVRZD5n6623jpVZfzZYf65suummKqts4K9Y+B0MAIBDNAAAADhEAwAAgEM0AAAAOEQDAACAQ5n/LoApU6aobNasWSrr0aOHeb21zW4WPPTQQyq76qqrSlAJsmzVqlUqmzZtmsqsbVFLPcGM6u/nn39W2Yknnqgy62t+ly5dVDZ16lSV1a9f33x2w4YN45SYabwBAADAIRoAAAAcogEAAMAhGgAAABzK/BCgtfVuz549S1BJ5datW6eyBQsWxL6+f//+KpsxY0be9VjbWcKn7777TmXz5s1TmXWWOVBIixYtUtlpp52msokTJ6rMGua2BsQ33HDDPKurnngDAACAQzQAAAA4RAMAAIBDNAAAADiUiiHAxx57TGUHH3ywymrVKl25//znP1W2dOlSlY0fP15lZWVlKrMGVCpjnVdtnXVt6du3r8oefvjh2M9G9fbiiy/G+tyIESOquBJ4sWTJEjO3dmv96quvVLbRRhupbPLkySpr06ZNHtX5whsAAAAcogEAAMAhGgAAAByiAQAAwKFgDZj9ym/+x0IZMmSIyqZPn66yc845J9b9rMEm6365WLhwocrWrFmjsrjDeblo3Lixynr16qWyq6++WmVdu3ZVWRGHKQv/k5G7oqzhLLCGr9q2basyaxjrueeeU1mNGi7+/pCGNSxSjdbxX//6VzM/6aSTVGYd1fvUU0+prHfv3onrqubMdezidzAAAPhvNAAAADhEAwAAgEM0AAAAOJSKnQAvvvhilZ133nkqe+CBB1Q2a9YslbVr105lVXFE8J577qmyV199VWXWoOWZZ54Z+zmdOnVSmXUMMvBb5syZo7Kff/5ZZbvvvrvKnAz8IQHr69wjjzyislNOOcW83jrSd+rUqSrbcccd86gOFn5XAwDgEA0AAAAO0QAAAOAQDQAAAA6lYidAy7p161S2evVqlS1fvlxl1u5RVlYVysvLVVa7dm2VORmqSsMuatVmB7WkjjzySJU9//zzKnvnnXdUZu0Y6EQa1rBIytbxBx98oDLriPMLL7xQZZV9LZ4wYYLK9t9//zyqg4GdAAEAQAUaAAAAHKIBAADAIRoAAAAcSu0QIKqFNAxQuVzDcY/+3WmnnVRmDQY6loY1LFLCdbx06VKVdevWTWXffvutyqyBv4cffth8zkEHHZRHdYiJIUAAAFCBBgAAAIdoAAAAcIgGAAAAh2gAAABwqFapCwBQeMuWLVPZzz//rLLBgwcXoxxk2Jw5c1R29913x7q2Y8eOKttyyy0T14TC4A0AAAAO0QAAAOAQDQAAAA7RAAAA4BBDgIATLVq0UJm1pSvwa9tss02sDNnDGwAAAByiAQAAwCEaAAAAHKIBAADAoRBFv3nMtMuz1FEwaThLnTWMJNKwhkVYx0jGXMe8AQAAwCEaAAAAHKIBAADAIRoAAAAcWt8QIAAAqIZ4AwAAgEM0AAAAOEQDAACAQzQAAAA4RAMAAIBDNAAAADj0fzlmi5g8Y24UAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 648x648 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /Users/butch/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cac65aa244142b6a350e8ec03319cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "learner = cnn_learner(dls, alexnet, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (192x2x2). Calculated output size: (192x0x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-cb11a8ee8975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/devt/workspaces/python3/fastai2_2020/fastai2/fastai2/callback/hook.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;34m\"Print a summary of the model, optimizer and loss function.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_inp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"Optimizer used: {self.opt_func}\\nLoss function: {self.loss_func}\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devt/workspaces/python3/fastai2_2020/fastai2/fastai2/callback/hook.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, *xb)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;34m\"Print a summary of `self` using `xb`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0msample_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minfos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfind_bs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0minp_sz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_print_shapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devt/workspaces/python3/fastai2_2020/fastai2/fastai2/callback/hook.py\u001b[0m in \u001b[0;36mlayer_info\u001b[0;34m(model, *xb)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflatten_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mHooks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_track\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.7/site-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[1;32m    140\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             self.return_indices)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.7/site-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fastai2/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     return torch.max_pool2d(\n\u001b[0;32m--> 488\u001b[0;31m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m max_pool2d = boolean_dispatch(\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (192x2x2). Calculated output size: (192x0x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = cnn_learner(dls, resnet18, metrics=accuracy, opt_func=SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential (Input shape: ['64 x 3 x 28 x 28'])\n",
       "================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "================================================================\n",
       "Conv2d               64 x 64 x 14 x 14    9,408      False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 64 x 14 x 14    128        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 64 x 14 x 14    0          False     \n",
       "________________________________________________________________\n",
       "MaxPool2d            64 x 64 x 7 x 7      0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 64 x 7 x 7      0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 64 x 7 x 7      0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 128 x 4 x 4     73,728     False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 128 x 4 x 4     0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 128 x 4 x 4     8,192      False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 128 x 4 x 4     0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 256 x 2 x 2     294,912    False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 256 x 2 x 2     0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 256 x 2 x 2     32,768     False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 256 x 2 x 2     0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 512 x 1 x 1     1,179,648  False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 512 x 1 x 1     0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 512 x 1 x 1     131,072    False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 512 x 1 x 1     0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
       "________________________________________________________________\n",
       "AdaptiveAvgPool2d    64 x 512 x 1 x 1     0          False     \n",
       "________________________________________________________________\n",
       "AdaptiveMaxPool2d    64 x 512 x 1 x 1     0          False     \n",
       "________________________________________________________________\n",
       "Flatten              64 x 1024            0          False     \n",
       "________________________________________________________________\n",
       "BatchNorm1d          64 x 1024            2,048      True      \n",
       "________________________________________________________________\n",
       "Dropout              64 x 1024            0          False     \n",
       "________________________________________________________________\n",
       "Linear               64 x 512             524,288    True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 512             0          False     \n",
       "________________________________________________________________\n",
       "BatchNorm1d          64 x 512             1,024      True      \n",
       "________________________________________________________________\n",
       "Dropout              64 x 512             0          False     \n",
       "________________________________________________________________\n",
       "Linear               64 x 2               1,024      True      \n",
       "________________________________________________________________\n",
       "\n",
       "Total params: 11,704,896\n",
       "Total trainable params: 537,984\n",
       "Total non-trainable params: 11,166,912\n",
       "\n",
       "Optimizer used: <function SGD at 0x133315cb0>\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Model frozen up to parameter group number 2\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.wd_bn_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.140227</td>\n",
       "      <td>0.791532</td>\n",
       "      <td>0.519313</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit(1,lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.081549</td>\n",
       "      <td>0.844730</td>\n",
       "      <td>0.535050</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.998293</td>\n",
       "      <td>0.795291</td>\n",
       "      <td>0.556509</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.952209</td>\n",
       "      <td>0.688622</td>\n",
       "      <td>0.623748</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.939883</td>\n",
       "      <td>0.618122</td>\n",
       "      <td>0.650930</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.930532</td>\n",
       "      <td>0.578174</td>\n",
       "      <td>0.686695</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.920849</td>\n",
       "      <td>0.541732</td>\n",
       "      <td>0.716738</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.894360</td>\n",
       "      <td>0.515756</td>\n",
       "      <td>0.742489</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.875680</td>\n",
       "      <td>0.498612</td>\n",
       "      <td>0.742489</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.844649</td>\n",
       "      <td>0.474820</td>\n",
       "      <td>0.758226</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.807186</td>\n",
       "      <td>0.448703</td>\n",
       "      <td>0.798283</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.fit(10,lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.717846</td>\n",
       "      <td>0.447404</td>\n",
       "      <td>0.796853</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.701267</td>\n",
       "      <td>0.430635</td>\n",
       "      <td>0.798283</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.678428</td>\n",
       "      <td>0.416647</td>\n",
       "      <td>0.809728</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.650394</td>\n",
       "      <td>0.401261</td>\n",
       "      <td>0.822604</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.623968</td>\n",
       "      <td>0.379458</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.608785</td>\n",
       "      <td>0.375489</td>\n",
       "      <td>0.831187</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.615184</td>\n",
       "      <td>0.366129</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.596886</td>\n",
       "      <td>0.357960</td>\n",
       "      <td>0.846924</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.573839</td>\n",
       "      <td>0.347584</td>\n",
       "      <td>0.864092</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.557128</td>\n",
       "      <td>0.339520</td>\n",
       "      <td>0.855508</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.549335</td>\n",
       "      <td>0.326350</td>\n",
       "      <td>0.868383</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.531980</td>\n",
       "      <td>0.319036</td>\n",
       "      <td>0.872675</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.521329</td>\n",
       "      <td>0.304866</td>\n",
       "      <td>0.886981</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.510307</td>\n",
       "      <td>0.303990</td>\n",
       "      <td>0.882690</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.495027</td>\n",
       "      <td>0.299089</td>\n",
       "      <td>0.879828</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.486096</td>\n",
       "      <td>0.287643</td>\n",
       "      <td>0.889843</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.463260</td>\n",
       "      <td>0.285260</td>\n",
       "      <td>0.889843</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.451357</td>\n",
       "      <td>0.276183</td>\n",
       "      <td>0.905579</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.431582</td>\n",
       "      <td>0.269510</td>\n",
       "      <td>0.907010</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.415263</td>\n",
       "      <td>0.266755</td>\n",
       "      <td>0.904149</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%timeit\n",
    "learner.fit(20,lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.361845</td>\n",
       "      <td>0.264043</td>\n",
       "      <td>0.909871</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.338599</td>\n",
       "      <td>0.255041</td>\n",
       "      <td>0.915594</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.355070</td>\n",
       "      <td>0.251709</td>\n",
       "      <td>0.909871</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.369649</td>\n",
       "      <td>0.241889</td>\n",
       "      <td>0.914163</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.362715</td>\n",
       "      <td>0.238208</td>\n",
       "      <td>0.919886</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.359822</td>\n",
       "      <td>0.235703</td>\n",
       "      <td>0.917024</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.354073</td>\n",
       "      <td>0.233433</td>\n",
       "      <td>0.911302</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.345470</td>\n",
       "      <td>0.227964</td>\n",
       "      <td>0.919886</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.337191</td>\n",
       "      <td>0.224390</td>\n",
       "      <td>0.921316</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.327125</td>\n",
       "      <td>0.217334</td>\n",
       "      <td>0.925608</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.320282</td>\n",
       "      <td>0.215767</td>\n",
       "      <td>0.927039</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.319955</td>\n",
       "      <td>0.213689</td>\n",
       "      <td>0.925608</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.313257</td>\n",
       "      <td>0.209276</td>\n",
       "      <td>0.928469</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.302478</td>\n",
       "      <td>0.203670</td>\n",
       "      <td>0.929900</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.291826</td>\n",
       "      <td>0.204639</td>\n",
       "      <td>0.925608</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.284575</td>\n",
       "      <td>0.205694</td>\n",
       "      <td>0.922747</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.277328</td>\n",
       "      <td>0.202550</td>\n",
       "      <td>0.927039</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.269694</td>\n",
       "      <td>0.196630</td>\n",
       "      <td>0.934192</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.270836</td>\n",
       "      <td>0.193003</td>\n",
       "      <td>0.937053</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.271430</td>\n",
       "      <td>0.187825</td>\n",
       "      <td>0.938484</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.189907</td>\n",
       "      <td>0.932761</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.241252</td>\n",
       "      <td>0.187551</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.241316</td>\n",
       "      <td>0.184173</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.237732</td>\n",
       "      <td>0.177933</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.230465</td>\n",
       "      <td>0.185951</td>\n",
       "      <td>0.934192</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.232735</td>\n",
       "      <td>0.181054</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.230071</td>\n",
       "      <td>0.180957</td>\n",
       "      <td>0.937053</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.220286</td>\n",
       "      <td>0.177879</td>\n",
       "      <td>0.937053</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.214231</td>\n",
       "      <td>0.172464</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.218660</td>\n",
       "      <td>0.165961</td>\n",
       "      <td>0.938484</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.211536</td>\n",
       "      <td>0.169118</td>\n",
       "      <td>0.934192</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.205849</td>\n",
       "      <td>0.169846</td>\n",
       "      <td>0.942775</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.210463</td>\n",
       "      <td>0.164881</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.203423</td>\n",
       "      <td>0.161642</td>\n",
       "      <td>0.947067</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.202393</td>\n",
       "      <td>0.162729</td>\n",
       "      <td>0.942775</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.204621</td>\n",
       "      <td>0.159671</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.207198</td>\n",
       "      <td>0.157774</td>\n",
       "      <td>0.951359</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.198096</td>\n",
       "      <td>0.157338</td>\n",
       "      <td>0.949928</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.196097</td>\n",
       "      <td>0.156323</td>\n",
       "      <td>0.949928</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.200034</td>\n",
       "      <td>0.157372</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.221464</td>\n",
       "      <td>0.158813</td>\n",
       "      <td>0.945637</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.183886</td>\n",
       "      <td>0.157548</td>\n",
       "      <td>0.947067</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.175355</td>\n",
       "      <td>0.153216</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.174035</td>\n",
       "      <td>0.153555</td>\n",
       "      <td>0.947067</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.169273</td>\n",
       "      <td>0.148172</td>\n",
       "      <td>0.949928</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.180499</td>\n",
       "      <td>0.148703</td>\n",
       "      <td>0.945637</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.174771</td>\n",
       "      <td>0.149866</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.171486</td>\n",
       "      <td>0.147031</td>\n",
       "      <td>0.951359</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.176926</td>\n",
       "      <td>0.145674</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.177065</td>\n",
       "      <td>0.145383</td>\n",
       "      <td>0.951359</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.169989</td>\n",
       "      <td>0.147850</td>\n",
       "      <td>0.949928</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.165895</td>\n",
       "      <td>0.147291</td>\n",
       "      <td>0.949928</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.161999</td>\n",
       "      <td>0.144128</td>\n",
       "      <td>0.949928</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.159793</td>\n",
       "      <td>0.143767</td>\n",
       "      <td>0.951359</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.158504</td>\n",
       "      <td>0.141708</td>\n",
       "      <td>0.949928</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.149597</td>\n",
       "      <td>0.140362</td>\n",
       "      <td>0.954220</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.143151</td>\n",
       "      <td>0.143595</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.147694</td>\n",
       "      <td>0.137926</td>\n",
       "      <td>0.955651</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.145539</td>\n",
       "      <td>0.138281</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.146070</td>\n",
       "      <td>0.136266</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.129601</td>\n",
       "      <td>0.132996</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.129946</td>\n",
       "      <td>0.133433</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.128208</td>\n",
       "      <td>0.129892</td>\n",
       "      <td>0.955651</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.120742</td>\n",
       "      <td>0.132465</td>\n",
       "      <td>0.955651</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.138095</td>\n",
       "      <td>0.126904</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.138132</td>\n",
       "      <td>0.127653</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.137143</td>\n",
       "      <td>0.129716</td>\n",
       "      <td>0.955651</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.135820</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.959943</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.131570</td>\n",
       "      <td>0.127648</td>\n",
       "      <td>0.954220</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.134062</td>\n",
       "      <td>0.124646</td>\n",
       "      <td>0.954220</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.134313</td>\n",
       "      <td>0.124329</td>\n",
       "      <td>0.955651</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.138254</td>\n",
       "      <td>0.122709</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.133553</td>\n",
       "      <td>0.120340</td>\n",
       "      <td>0.959943</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.131805</td>\n",
       "      <td>0.121310</td>\n",
       "      <td>0.962804</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.128107</td>\n",
       "      <td>0.122033</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.128328</td>\n",
       "      <td>0.118475</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.119562</td>\n",
       "      <td>0.117963</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.121165</td>\n",
       "      <td>0.119237</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.124530</td>\n",
       "      <td>0.119804</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.117402</td>\n",
       "      <td>0.118564</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.107820</td>\n",
       "      <td>0.119149</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.103584</td>\n",
       "      <td>0.119928</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.109780</td>\n",
       "      <td>0.117310</td>\n",
       "      <td>0.955651</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.120818</td>\n",
       "      <td>0.110927</td>\n",
       "      <td>0.962804</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.121658</td>\n",
       "      <td>0.114518</td>\n",
       "      <td>0.959943</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.119774</td>\n",
       "      <td>0.110626</td>\n",
       "      <td>0.959943</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.113971</td>\n",
       "      <td>0.111588</td>\n",
       "      <td>0.962804</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.111001</td>\n",
       "      <td>0.115789</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.107010</td>\n",
       "      <td>0.112649</td>\n",
       "      <td>0.958512</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.103320</td>\n",
       "      <td>0.112497</td>\n",
       "      <td>0.955651</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.101043</td>\n",
       "      <td>0.110860</td>\n",
       "      <td>0.959943</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.102507</td>\n",
       "      <td>0.108965</td>\n",
       "      <td>0.959943</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.105102</td>\n",
       "      <td>0.108487</td>\n",
       "      <td>0.962804</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.100539</td>\n",
       "      <td>0.110750</td>\n",
       "      <td>0.954220</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.096193</td>\n",
       "      <td>0.107886</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.093662</td>\n",
       "      <td>0.108236</td>\n",
       "      <td>0.959943</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.093756</td>\n",
       "      <td>0.106595</td>\n",
       "      <td>0.959943</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.091590</td>\n",
       "      <td>0.107496</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.097607</td>\n",
       "      <td>0.104269</td>\n",
       "      <td>0.962804</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.094760</td>\n",
       "      <td>0.107292</td>\n",
       "      <td>0.959943</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.092167</td>\n",
       "      <td>0.103575</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.092147</td>\n",
       "      <td>0.105561</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.097012</td>\n",
       "      <td>0.106281</td>\n",
       "      <td>0.964235</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.097692</td>\n",
       "      <td>0.102113</td>\n",
       "      <td>0.962804</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.106139</td>\n",
       "      <td>0.102522</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.098633</td>\n",
       "      <td>0.104275</td>\n",
       "      <td>0.959943</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.096710</td>\n",
       "      <td>0.106977</td>\n",
       "      <td>0.959943</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.091889</td>\n",
       "      <td>0.102852</td>\n",
       "      <td>0.962804</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.094292</td>\n",
       "      <td>0.102722</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.099691</td>\n",
       "      <td>0.101845</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.102271</td>\n",
       "      <td>0.102228</td>\n",
       "      <td>0.964235</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.095173</td>\n",
       "      <td>0.102707</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.090408</td>\n",
       "      <td>0.102377</td>\n",
       "      <td>0.964235</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.087654</td>\n",
       "      <td>0.100884</td>\n",
       "      <td>0.968526</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.089814</td>\n",
       "      <td>0.096990</td>\n",
       "      <td>0.967096</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.085828</td>\n",
       "      <td>0.097155</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.082589</td>\n",
       "      <td>0.100330</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.084838</td>\n",
       "      <td>0.099993</td>\n",
       "      <td>0.964235</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.090986</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.085276</td>\n",
       "      <td>0.098680</td>\n",
       "      <td>0.962804</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.078780</td>\n",
       "      <td>0.098427</td>\n",
       "      <td>0.962804</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.077797</td>\n",
       "      <td>0.099750</td>\n",
       "      <td>0.967096</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.077928</td>\n",
       "      <td>0.100336</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.069888</td>\n",
       "      <td>0.100538</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.068005</td>\n",
       "      <td>0.099084</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.076393</td>\n",
       "      <td>0.097958</td>\n",
       "      <td>0.967096</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.073143</td>\n",
       "      <td>0.097704</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.074439</td>\n",
       "      <td>0.097380</td>\n",
       "      <td>0.967096</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.076126</td>\n",
       "      <td>0.095434</td>\n",
       "      <td>0.968526</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.072238</td>\n",
       "      <td>0.096098</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.078019</td>\n",
       "      <td>0.094928</td>\n",
       "      <td>0.968526</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.075998</td>\n",
       "      <td>0.095391</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.075846</td>\n",
       "      <td>0.096986</td>\n",
       "      <td>0.967096</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.075209</td>\n",
       "      <td>0.093782</td>\n",
       "      <td>0.967096</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.075937</td>\n",
       "      <td>0.095866</td>\n",
       "      <td>0.967096</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.073471</td>\n",
       "      <td>0.094595</td>\n",
       "      <td>0.968526</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.071515</td>\n",
       "      <td>0.096635</td>\n",
       "      <td>0.967096</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.067516</td>\n",
       "      <td>0.092361</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.069279</td>\n",
       "      <td>0.095630</td>\n",
       "      <td>0.967096</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.075211</td>\n",
       "      <td>0.095633</td>\n",
       "      <td>0.967096</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.093608</td>\n",
       "      <td>0.968526</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.057862</td>\n",
       "      <td>0.095118</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.055557</td>\n",
       "      <td>0.093023</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.057780</td>\n",
       "      <td>0.093787</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.055363</td>\n",
       "      <td>0.092301</td>\n",
       "      <td>0.968526</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.057437</td>\n",
       "      <td>0.093534</td>\n",
       "      <td>0.968526</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.059653</td>\n",
       "      <td>0.093754</td>\n",
       "      <td>0.968526</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.062564</td>\n",
       "      <td>0.092330</td>\n",
       "      <td>0.967096</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.061531</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.968526</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.060313</td>\n",
       "      <td>0.092729</td>\n",
       "      <td>0.967096</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.057058</td>\n",
       "      <td>0.091374</td>\n",
       "      <td>0.968526</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.062132</td>\n",
       "      <td>0.091534</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.060528</td>\n",
       "      <td>0.092152</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.057187</td>\n",
       "      <td>0.090740</td>\n",
       "      <td>0.964235</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.057580</td>\n",
       "      <td>0.091578</td>\n",
       "      <td>0.968526</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.054892</td>\n",
       "      <td>0.089070</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.058194</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.062871</td>\n",
       "      <td>0.088173</td>\n",
       "      <td>0.968526</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.059452</td>\n",
       "      <td>0.091516</td>\n",
       "      <td>0.967096</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.057893</td>\n",
       "      <td>0.087009</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5min 7s ± 4.67 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit learner.fit(20,lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.recorder.plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [{'wd': 0.0, 'lr': 0.001, 'mom': 0.0},{'wd': 0.0, 'lr': 0.001, 'mom': 0.0},{'wd': 0.0, 'lr': 0.001, 'mom': 0.0}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.opt.hypers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = learner.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential (Input shape: ['64 x 3 x 28 x 28'])\n",
       "================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "================================================================\n",
       "Conv2d               64 x 64 x 14 x 14    9,408      False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 64 x 14 x 14    128        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 64 x 14 x 14    0          False     \n",
       "________________________________________________________________\n",
       "MaxPool2d            64 x 64 x 7 x 7      0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 64 x 7 x 7      0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 64 x 7 x 7      0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 64 x 7 x 7      36,864     False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 64 x 7 x 7      128        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 128 x 4 x 4     73,728     False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 128 x 4 x 4     0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 128 x 4 x 4     8,192      False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 128 x 4 x 4     0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 128 x 4 x 4     147,456    False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 128 x 4 x 4     256        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 256 x 2 x 2     294,912    False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 256 x 2 x 2     0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 256 x 2 x 2     32,768     False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 256 x 2 x 2     0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 256 x 2 x 2     589,824    False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 256 x 2 x 2     512        True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 512 x 1 x 1     1,179,648  False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 512 x 1 x 1     0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 512 x 1 x 1     131,072    False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 512 x 1 x 1     0          False     \n",
       "________________________________________________________________\n",
       "Conv2d               64 x 512 x 1 x 1     2,359,296  False     \n",
       "________________________________________________________________\n",
       "BatchNorm2d          64 x 512 x 1 x 1     1,024      True      \n",
       "________________________________________________________________\n",
       "AdaptiveAvgPool2d    64 x 512 x 1 x 1     0          False     \n",
       "________________________________________________________________\n",
       "AdaptiveMaxPool2d    64 x 512 x 1 x 1     0          False     \n",
       "________________________________________________________________\n",
       "Flatten              64 x 1024            0          False     \n",
       "________________________________________________________________\n",
       "BatchNorm1d          64 x 1024            2,048      True      \n",
       "________________________________________________________________\n",
       "Dropout              64 x 1024            0          False     \n",
       "________________________________________________________________\n",
       "Linear               64 x 512             524,288    True      \n",
       "________________________________________________________________\n",
       "ReLU                 64 x 512             0          False     \n",
       "________________________________________________________________\n",
       "BatchNorm1d          64 x 512             1,024      True      \n",
       "________________________________________________________________\n",
       "Dropout              64 x 512             0          False     \n",
       "________________________________________________________________\n",
       "Linear               64 x 2               1,024      True      \n",
       "________________________________________________________________\n",
       "\n",
       "Total params: 11,704,896\n",
       "Total trainable params: 537,984\n",
       "Total non-trainable params: 11,166,912\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/Users/butch/.fastai/data/mnist_tiny')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('.')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
