{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T05:27:14.083245Z",
     "start_time": "2020-07-30T05:27:10.858818Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch_optimizer as optim\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from importlib import reload\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.float_format', '{:0.3f}'.format)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.width = 0\n",
    "import warnings\n",
    "import torchvision\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from facebook_hateful_memes_detector.utils.globals import set_global, get_global\n",
    "set_global(\"cache_dir\", \"/home/ahemf/cache/cache\")\n",
    "set_global(\"dataloader_workers\", 4)\n",
    "set_global(\"use_autocast\", True)\n",
    "set_global(\"models_dir\", \"/home/ahemf/cache/\")\n",
    "\n",
    "from facebook_hateful_memes_detector.utils import read_json_lines_into_df, in_notebook, set_device\n",
    "get_global(\"cache_dir\")\n",
    "from facebook_hateful_memes_detector.models import Fasttext1DCNNModel, MultiImageMultiTextAttentionEarlyFusionModel, LangFeaturesModel, AlbertClassifer, TransformerImageModel\n",
    "\n",
    "from facebook_hateful_memes_detector.preprocessing import TextImageDataset, my_collate, get_datasets, get_image2torchvision_transforms, TextAugment\n",
    "from facebook_hateful_memes_detector.preprocessing import DefinedRotation, QuadrantCut, ImageAugment, DefinedAffine, HalfSwap\n",
    "from facebook_hateful_memes_detector.training import *\n",
    "import facebook_hateful_memes_detector\n",
    "reload(facebook_hateful_memes_detector)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://discuss.pytorch.org/t/how-to-implement-torch-optim-lr-scheduler-cosineannealinglr/28797/11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T05:27:15.970028Z",
     "start_time": "2020-07-30T05:27:15.848605Z"
    }
   },
   "outputs": [],
   "source": [
    "choice_probas = {\n",
    "    \"keyboard\": 0.1,\n",
    "    \"char_substitute\": 0.0,\n",
    "    \"char_insert\": 0.1,\n",
    "    \"char_swap\": 0.0,\n",
    "    \"ocr\": 0.0,\n",
    "    \"char_delete\": 0.1,\n",
    "    \"fasttext\": 0.0,\n",
    "    \"glove_twitter\": 0.0,\n",
    "    \"glove_wiki\": 0.0,\n",
    "    \"word2vec\": 0.0,\n",
    "    \"split\": 0.1,\n",
    "    \"stopword_insert\": 0.4,\n",
    "    \"word_join\": 0.1,\n",
    "    \"word_cutout\": 0.8,\n",
    "    \"text_rotate\": 0.,\n",
    "    \"sentence_shuffle\": 0.5,\n",
    "    \"one_third_cut\": 0.4,\n",
    "    \"half_cut\": 0.\n",
    "}\n",
    "preprocess_text = TextAugment([0.0, 0.1, 0.05, 0.35, 0.3, 0.2],\n",
    "                              choice_probas,\n",
    "                              fasttext_file=\"wiki-news-300d-1M-subword.bin\")\n",
    "\n",
    "augs_dict = dict(\n",
    "    grayscale=transforms.Grayscale(num_output_channels=3),\n",
    "    hflip=transforms.RandomHorizontalFlip(p=1.0),\n",
    "    rc2=transforms.Compose(\n",
    "        [transforms.Resize(480),\n",
    "         transforms.CenterCrop(400)]),\n",
    "    rotate=DefinedRotation(15),\n",
    "    affine=DefinedAffine(0, scale=(0.6, 0.6)),\n",
    "    translate1=DefinedAffine(0, translate=(0.25, 0.25)),\n",
    "    swap=HalfSwap(),\n",
    ")\n",
    "im_transform = ImageAugment(count_proba=[0.0, 1.0],\n",
    "                            augs_dict=augs_dict,\n",
    "                            choice_probas=\"uniform\")\n",
    "\n",
    "torchvision_pre_image_transform = transforms.Compose([\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.RandomHorizontalFlip(p=0.2),\n",
    "    transforms.RandomPerspective(distortion_scale=0.25, p=0.2),\n",
    "    transforms.ColorJitter(brightness=0.1,\n",
    "                           contrast=0.1,\n",
    "                           saturation=0.1,\n",
    "                           hue=0.1),\n",
    "    transforms.RandomChoice([\n",
    "        transforms.RandomRotation(15),\n",
    "        DefinedRotation(90),\n",
    "        transforms.RandomAffine(\n",
    "            0,\n",
    "            translate=(0.25, 0.25),\n",
    "            scale=(0.6, 1.4),\n",
    "            shear=None,\n",
    "        ),\n",
    "        transforms.RandomResizedCrop(480, scale=(0.6, 1.0))  # Zoom in\n",
    "    ]),\n",
    "])\n",
    "\n",
    "data = get_datasets(\n",
    "    data_dir=\"../data/\",\n",
    "    train_text_transform=preprocess_text,\n",
    "    train_image_transform=im_transform,\n",
    "    test_text_transform=None,\n",
    "    test_image_transform=None,\n",
    "    train_torchvision_image_transform=transforms.RandomErasing(p=0.5,\n",
    "                                                               scale=(0.05,\n",
    "                                                                      0.2),\n",
    "                                                               ratio=(0.3,\n",
    "                                                                      3.3),\n",
    "                                                               value=0,\n",
    "                                                               inplace=False),\n",
    "    test_torchvision_image_transform=None,\n",
    "    train_torchvision_pre_image_transform=torchvision_pre_image_transform,\n",
    "    test_torchvision_pre_image_transform=None,\n",
    "    cache_images=True,\n",
    "    use_images=True,\n",
    "    dev=False,\n",
    "    test_dev=True,\n",
    "    keep_original_text=False,\n",
    "    keep_original_image=False,\n",
    "    keep_processed_image=True,\n",
    "    keep_torchvision_image=True,\n",
    "    train_mixup_config=dict(proba=0.0),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T05:27:16.665891Z",
     "start_time": "2020-07-30T05:27:16.653263Z"
    }
   },
   "outputs": [],
   "source": [
    "sgd = torch.optim.SGD\n",
    "sgd_params = dict(lr=2e-2, momentum=0.9, dampening=0, weight_decay=0, nesterov=False)\n",
    "\n",
    "rangerQH = optim.RangerQH\n",
    "rangerQHparams = dict(lr=1e-3, betas=(0.9, 0.999), nus=(.7, 1.0),\n",
    "    weight_decay=0.0,\n",
    "    k=6,\n",
    "    alpha=.5,\n",
    "    decouple_weight_decay=True,\n",
    "    eps=1e-8,)\n",
    "\n",
    "adam = torch.optim.Adam\n",
    "adam_params = params=dict(lr=1e-4, weight_decay=1e-6)\n",
    "\n",
    "adamw = torch.optim.AdamW\n",
    "adamw_params = dict(lr=1e-4, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-2)\n",
    "\n",
    "novograd = optim.NovoGrad\n",
    "novograd_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=0,\n",
    "    grad_averaging=False,\n",
    "    amsgrad=False,)\n",
    "\n",
    "qhadam = optim.QHAdam\n",
    "qhadam_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    nus=(1.0, 1.0),\n",
    "    weight_decay=0,\n",
    "    decouple_weight_decay=False,\n",
    "    eps=1e-8,)\n",
    "\n",
    "radam = optim.RAdam\n",
    "radam_params = dict(lr= 1e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-8,\n",
    "    weight_decay=0,)\n",
    "\n",
    "yogi = optim.Yogi\n",
    "yogi_params = dict(lr= 1e-2,\n",
    "    betas=(0.9, 0.999),\n",
    "    eps=1e-3,\n",
    "    initial_accumulator=1e-6,\n",
    "    weight_decay=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T05:27:17.746245Z",
     "start_time": "2020-07-30T05:27:17.741049Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "epochs = 25\n",
    "\n",
    "adamw = torch.optim.AdamW\n",
    "adamw_params = dict(lr=1e-4, betas=(0.9, 0.99), eps=1e-08, weight_decay=1e-3)\n",
    "optimizer = adamw\n",
    "optimizer_params = adamw_params\n",
    "\n",
    "scheduler_init_fn = get_multistep_lr([5, 7, 10, 17], gamma=0.1) # get_cosine_schedule_with_warmup # get_cosine_with_hard_restarts_schedule_with_warmup\n",
    "scheduler_init_fn = get_cosine_schedule_with_warmup()\n",
    "reg_sched = get_regularizer_scheduler()\n",
    "\n",
    "\n",
    "# {\"lr\": optimizer_params[\"lr\"]/500}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Image Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-30T06:48:58.231370Z",
     "start_time": "2020-07-30T05:27:18.760532Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_strategy = {\n",
    "    \"finetune\": True,\n",
    "    \"im_models\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 10,\n",
    "        \"torchvision_resnet18_ssl-contrastive\": {\n",
    "            \"lambd\": {\n",
    "                \"7\": {\n",
    "                    \"finetune\": True\n",
    "                },\n",
    "                \"8\": {\n",
    "                    \"finetune\": True\n",
    "                }\n",
    "            },\n",
    "            \"lr\": optimizer_params[\"lr\"] / 10,\n",
    "            \"finetune\": False,\n",
    "        },\n",
    "        \"vgg_face\": {\n",
    "            \"lr\": optimizer_params[\"lr\"] / 10,\n",
    "            \"lambd\": {\n",
    "                \"0\": {\n",
    "                    \"feat_extract\": {\n",
    "                        \"finetune\": True\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"finetune\": False,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "adam = torch.optim.Adam\n",
    "adam_params = params=dict(lr=5e-4, weight_decay=1e-6)\n",
    "adamw = torch.optim.AdamW\n",
    "adamw_params = dict(lr=1e-4, betas=(0.9, 0.99), eps=1e-08, weight_decay=1e-3)\n",
    "optimizer = adamw\n",
    "optimizer_params = adamw_params\n",
    "\n",
    "model_fn = model_builder(\n",
    "    TransformerImageModel,\n",
    "    dict(\n",
    "        image_models=[\n",
    "            #             {\n",
    "            #                 \"model\": 'caption_features',\n",
    "            #                 \"gaussian_noise\": 0.0,\n",
    "            #                 \"dropout\": 0.0\n",
    "            #             },\n",
    "            {\n",
    "                \"model\": 'vgg_face',\n",
    "                \"gaussian_noise\": 0.0, # 0.0\n",
    "                \"dropout\": 0.1,\n",
    "            },\n",
    "            {\n",
    "                \"model\": 'detr',\n",
    "                \"gaussian_noise\": 0.0,\n",
    "                \"dropout\": 0.0\n",
    "            },\n",
    "            {\n",
    "                \"model\": \"torchvision_resnet18_ssl-contrastive\",\n",
    "                \"large_rf\": True,\n",
    "                \"dropout\": 0.1,\n",
    "                \"gaussian_noise\": 0.0, # 0.0\n",
    "            },\n",
    "        ],\n",
    "        classifier_dims=768,\n",
    "        num_classes=2,\n",
    "        gaussian_noise=0.0,\n",
    "        dropout=0.0,\n",
    "        word_masking_proba=0.0,\n",
    "        internal_dims=768,\n",
    "        final_layer_builder=fb_1d_loss_builder,\n",
    "        n_layers=2,\n",
    "        n_encoders=0,\n",
    "        n_decoders=1,\n",
    "        n_tokens_in=160,\n",
    "        n_tokens_out=32,\n",
    "        featurizer=\"transformer\",\n",
    "        model='distilbert-nsp',\n",
    "        loss=\"focal\",\n",
    "        classification_head=\"decoder_ensemble\",  # decoder_ensemble\n",
    "        dice_loss_coef=0.0,\n",
    "        auc_loss_coef=0.5,\n",
    "        attention_drop_proba=0.0,\n",
    "        finetune=False,\n",
    "    ),\n",
    "    per_param_opts_fn=lr_strategy,\n",
    "    optimiser_class=optimizer,\n",
    "    optimiser_params=optimizer_params)\n",
    "\n",
    "batch_size=40\n",
    "epochs = 20\n",
    "kfold = False\n",
    "results, prfs = train_validate_ntimes(\n",
    "    model_fn,\n",
    "    data,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    kfold=kfold,\n",
    "    scheduler_init_fn=scheduler_init_fn,\n",
    "    accumulation_steps=4,\n",
    "    model_call_back=reg_sched, # reg_sched\n",
    "    validation_epochs=[4, 7, 9, 11, 14, 17, 19, 23, 27, 31, 34, 37, 41, 44, 47, 51, 54],\n",
    "    show_model_stats=False,\n",
    "    sampling_policy=\"without_replacement\",\n",
    "    prediction_iters=1, evaluate_in_train_mode=True\n",
    ")\n",
    "r2, p2 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# 0.854\t0.654 (0.765\t0.620) dropout=0.05 lr=1e-4\n",
    "# 0.827\t0.638 (0.732\t0.590) dropout=0.1 lr=1e-4\n",
    "\n",
    "# 0.871\t0.641 (0.871\t0.641) gaussian_noise=0.05, dropout=0.05, word_masking_proba=0.15,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T05:51:45.030452Z",
     "start_time": "2020-07-23T05:51:45.028077Z"
    }
   },
   "outputs": [],
   "source": [
    "# 16 sized outputs were best for decoder.\n",
    "# For ASIN tasks of AMLC train image model with other supervised tasks like GL/Category etc predictions. \n",
    "# MLM for transformerImage Model needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Multi-Text Multi Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T05:51:45.316142Z",
     "start_time": "2020-07-23T05:51:45.294960Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizer_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e11764c255f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m lr_strategy = {\n\u001b[1;32m      2\u001b[0m     \"im_models\": {\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moptimizer_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \"torchvision_resnet18_ssl-contrastive\": {\n\u001b[1;32m      5\u001b[0m             \"lambd\": {\n",
      "\u001b[0;31mNameError\u001b[0m: name 'optimizer_params' is not defined"
     ]
    }
   ],
   "source": [
    "lr_strategy = {\n",
    "    \"im_models\": {\n",
    "        \"lr\": optimizer_params[\"lr\"] / 10,\n",
    "        \"torchvision_resnet18_ssl-contrastive\": {\n",
    "            \"lambd\": {\n",
    "                \"8\": {\n",
    "                    \"finetune\": True\n",
    "                }\n",
    "            },\n",
    "            \"lr\": optimizer_params[\"lr\"] / 10,\n",
    "            \"finetune\": False,\n",
    "        },\n",
    "        \"vgg_face\": {\n",
    "            \"lr\": optimizer_params[\"lr\"] / 10,\n",
    "            \"lambd\": {\n",
    "                \"0\": {\n",
    "                    \"feat_extract\": {\n",
    "                        \"finetune\": True\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"finetune\": False,\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "model_fn = model_builder(\n",
    "    MultiImageMultiTextAttentionEarlyFusionModel,\n",
    "    dict(\n",
    "        image_models=[\n",
    "            #             {\n",
    "            #                 \"model\": 'caption_features',\n",
    "            #                 \"gaussian_noise\": 0.0,\n",
    "            #                 \"dropout\": 0.0\n",
    "            #             },\n",
    "            {\n",
    "                \"model\": 'vgg_face',\n",
    "                \"gaussian_noise\": 0.0,\n",
    "                \"dropout\": 0.0,\n",
    "            },\n",
    "            #             {\n",
    "            #                 \"model\": 'detr_resnet50',\n",
    "            #                 \"gaussian_noise\": 0.0,\n",
    "            #                 \"dropout\": 0.0\n",
    "            #             },\n",
    "            #             {\n",
    "            #                 \"model\": 'detr_resnet50_panoptic',\n",
    "            #                 \"gaussian_noise\": 0.0,\n",
    "            #                 \"dropout\": 0.0\n",
    "            #             },\n",
    "            {\n",
    "                \"model\": \"torchvision_resnet18_ssl-contrastive\",\n",
    "                \"large_rf\": True,\n",
    "                \"dropout\": 0.0,\n",
    "                \"gaussian_noise\": 0.0,\n",
    "            },\n",
    "        ],\n",
    "        num_classes=2,\n",
    "        text_models=[\n",
    "            dict(\n",
    "                cls=Fasttext1DCNNModel,\n",
    "                params=dict(\n",
    "                    classifier_dims=256,\n",
    "                    num_classes=2,\n",
    "                    n_tokens_in=64,\n",
    "                    n_tokens_out=16,\n",
    "                    n_layers=2,\n",
    "                    final_layer_builder=lambda *args: None,\n",
    "                    gaussian_noise=0.0,\n",
    "                    dropout=0.0,\n",
    "                    embedding_dims=256,\n",
    "                    internal_dims=256,\n",
    "                    featurizer=\"gru\",\n",
    "                ),\n",
    "                in_channels=256,\n",
    "                in_tokens=64,\n",
    "                forward=\"get_word_vectors\",\n",
    "                dropout=0.2,\n",
    "                gaussian_noise=0.25,\n",
    "            ),\n",
    "            dict(\n",
    "                cls=AlbertClassifer,\n",
    "                params=dict(classifier_dims=256,\n",
    "                            num_classes=2,\n",
    "                            embedding_dims=768,\n",
    "                            gaussian_noise=0.0,\n",
    "                            dropout=0.0,\n",
    "                            word_masking_proba=0.25,\n",
    "                            internal_dims=512,\n",
    "                            final_layer_builder=fb_1d_loss_builder,\n",
    "                            n_layers=2,\n",
    "                            n_encoders=2,\n",
    "                            n_decoders=2,\n",
    "                            n_tokens_in=96,\n",
    "                            n_tokens_out=16,\n",
    "                            featurizer=\"transformer\",\n",
    "                            model='./distilbert-nsp',\n",
    "                            finetune=False),\n",
    "                in_channels=768,\n",
    "                in_tokens=96,\n",
    "                forward=\"get_word_vectors\",\n",
    "                dropout=0.2,\n",
    "                gaussian_noise=0.25,\n",
    "            )\n",
    "        ],\n",
    "        internal_dims=256,\n",
    "        classifier_dims=256,\n",
    "        n_tokens_out=32,\n",
    "        n_layers=2,\n",
    "        n_encoders=2,\n",
    "        n_decoders=2,\n",
    "        final_layer_builder=fb_1d_loss_builder,\n",
    "        gaussian_noise=0.75,\n",
    "        dropout=0.3,  # 0.3\n",
    "        loss=\"focal\",\n",
    "        dice_loss_coef=0.0,\n",
    "        auc_loss_coef=0.0,\n",
    "    ),\n",
    "    per_param_opts_fn=lr_strategy,\n",
    "    optimiser_class=optimizer,\n",
    "    optimiser_params=optimizer_params)\n",
    "\n",
    "data[\"metadata\"][\"use_images\"] = True\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "kfold = False\n",
    "results, prfs = train_validate_ntimes(\n",
    "    model_fn,\n",
    "    data,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    kfold=kfold,\n",
    "    scheduler_init_fn=scheduler_init_fn,\n",
    "    validation_epochs=[7, 11, 14, 17, 20, 23, 27],\n",
    "    show_model_stats=False,\n",
    "    sampling_policy=\"without_replacement\",\n",
    "    accumulation_steps=4,\n",
    "    model_call_back=reg_sched,\n",
    ")\n",
    "r1, p1 = results, prfs\n",
    "results\n",
    "prfs\n",
    "\n",
    "# 0.824\t0.750 (0.761\t0.711)\n",
    "\n",
    "# \"detr_demo\", 'detr_resnet50', 'detr_resnet50_panoptic', 'detr_resnet101', 'detr_resnet101_panoptic', \"caption_features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T05:51:45.318265Z",
     "start_time": "2020-07-23T05:51:44.860Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=512\n",
    "epochs = 1\n",
    "\n",
    "submission, text_model = train_and_predict(model_fn, data, batch_size, epochs, scheduler_init_fn=scheduler_init_fn)\n",
    "submission.to_csv(\"submission.csv\",index=False)\n",
    "submission.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-23T05:51:45.319205Z",
     "start_time": "2020-07-23T05:51:44.862Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.sample(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
