{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "reshape_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2qJIRS3RBhVKrKKb12go6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhuwanupadhyay/codes/blob/main/ipynbs/reshape_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm8U8GsL9U3V",
        "outputId": "c3815ce8-d7dd-41ce-9788-e7db69349399"
      },
      "source": [
        "pip install pydicom"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-2.2.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 25.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: pydicom\n",
            "Successfully installed pydicom-2.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "Kl-d4Gmc8aTF",
        "outputId": "305ab2af-da26-4ded-af31-e9ccee8703ea"
      },
      "source": [
        "# Import tensorflow\n",
        "import logging\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "\n",
        "# Helper libraries\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pydicom\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "# Imports for dataset manipulation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Improve progress bar display\n",
        "import tqdm\n",
        "import tqdm.auto\n",
        "\n",
        "tqdm.tqdm = tqdm.auto.tqdm\n",
        "\n",
        "#tf.enable_eager_execution() #comment this out if causing errors\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.DEBUG)\n",
        "\n",
        "\n",
        "###             SET MODEL CONFIGURATIONS             ###\n",
        "# Data Loading\n",
        "CSV_PATH = 'label_data/CCC_clean.csv'\n",
        "IMAGE_BASE_PATH = './data/'\n",
        "test_size_percent = 0.15  # percent of total data reserved for testing\n",
        "\n",
        "print(IMAGE_BASE_PATH)\n",
        "\n",
        "# Data Augmentation\n",
        "mirror_im = False\n",
        "\n",
        "# Loss\n",
        "lambda_coord = 5\n",
        "epsilon = 0.00001\n",
        "\n",
        "# Learning\n",
        "step_size = 0.00001\n",
        "BATCH_SIZE = 5\n",
        "num_epochs = 1\n",
        "\n",
        "# Saving\n",
        "shape_path = 'trained_model/model_shape.json'\n",
        "weight_path = 'trained_model/model_weights.h5'\n",
        "\n",
        "# TensorBoard\n",
        "tb_graph = False\n",
        "tb_update_freq = 'batch'\n",
        "\n",
        "###         GET THE DATASET AND PREPROCESS IT        ###\n",
        "\n",
        "print(\"Loading and processing data\\n\")\n",
        "\n",
        "data_frame = pd.read_csv(CSV_PATH)\n",
        "\n",
        "\"\"\"\n",
        "Construct numpy ndarrays from the loaded csv to use as training\n",
        "and testing datasets.\n",
        "\"\"\"\n",
        "# zip all points for each image label together into a tuple\n",
        "points = zip(data_frame['start_x'], data_frame['start_y'],\n",
        "             data_frame['end_x'], data_frame['end_y'])\n",
        "img_paths = data_frame['imgPath']\n",
        "\n",
        "def path_to_image(path):\n",
        "    \"\"\"\n",
        "    Load a matrix of pixel values from the DICOM image stored at the\n",
        "    input path.\n",
        "\n",
        "    @param path - string, relative path (from IMAGE_BASE_PATH) to\n",
        "                  a DICOM file\n",
        "    @return image - numpy ndarray (int), 2D matrix of pixel\n",
        "                    values of the image loaded from path\n",
        "    \"\"\"\n",
        "    # load image from path as numpy array\n",
        "    image = pydicom.dcmread(os.path.join(IMAGE_BASE_PATH, path)).pixel_array\n",
        "    return image\n",
        "\n",
        "\n",
        "# normalize dicom image pixel values to 0-1 range\n",
        "def normalize_image(img):\n",
        "    \"\"\"\n",
        "    Normalize the pixel values in img to be withing the range\n",
        "    of 0 to 1.\n",
        "\n",
        "    @param img - numpy ndarray, 2D matrix of pixel values\n",
        "    @return img - numpy ndarray (float), 2D matrix of pixel values, every\n",
        "                  element is valued between 0 and 1 (inclusive)\n",
        "    \"\"\"\n",
        "    img = img.astype(np.float32)\n",
        "    img += abs(np.amin(img))  # account for negatives\n",
        "    img /= np.amax(img)\n",
        "    return img\n",
        "\n",
        "\n",
        "# normalize the ground truth bounding box labels wrt image dimensions\n",
        "def normalize_points(points):\n",
        "    \"\"\"\n",
        "    Normalize values in points to be within the range of 0 to 1.\n",
        "\n",
        "    @param points - 1x4 tuple, elements valued in the range of 0\n",
        "                    512 (inclusive). This is known from the nature\n",
        "                    of the dataset used in this program\n",
        "    @return - 1x4 numpy ndarray (float), elements valued in range\n",
        "              0 to 1 (inclusive)\n",
        "    \"\"\"\n",
        "    imDims = 512.0  # each image in our dataset is 512x512\n",
        "    points = list(points)\n",
        "    for i in range(len(points)):\n",
        "        points[i] /= imDims\n",
        "    return np.array(points).astype(np.float32)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Convert the numpy array of paths to the DICOM images to pixel\n",
        "matrices that have been normalized to a 0-1 range.\n",
        "Also normalize the bounding box labels to make it easier for\n",
        "the model to predict on them.\n",
        "\"\"\"\n",
        "\n",
        "# apply preprocessing functions\n",
        "points = map(normalize_points, points)\n",
        "imgs = map(path_to_image, img_paths)\n",
        "imgs = map(normalize_image, imgs)\n",
        "\n",
        "print(list(imgs))\n",
        "\n",
        "# reshape input image data to 4D shape (as expected by the model)\n",
        "# and cast all data to np arrays (just in case)\n",
        "imgs = np.array(imgs)\n",
        "points = np.array(points)\n",
        "imgs = imgs.reshape((-1, 512, 512, 1))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./data/\n",
            "Loading and processing data\n",
            "\n",
            "[array([[0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       ...,\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.],\n",
            "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-0ba4f51b4ac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0mpoints\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 1 into shape (512,512,1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zv9BxzVK8eUI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}