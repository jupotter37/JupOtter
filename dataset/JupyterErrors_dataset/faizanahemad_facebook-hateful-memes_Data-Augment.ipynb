{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T11:04:01.309545Z",
     "start_time": "2020-08-23T11:03:57.927019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jsonlines\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch_optimizer as optim\n",
    "import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from importlib import reload\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.float_format', '{:0.3f}'.format)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.width = 0\n",
    "import warnings\n",
    "import torchvision\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from facebook_hateful_memes_detector.utils.globals import set_global, get_global\n",
    "set_global(\"cache_dir\", \"/home/ahemf/cache/cache\")\n",
    "set_global(\"dataloader_workers\", 4)\n",
    "set_global(\"use_autocast\", True)\n",
    "set_global(\"models_dir\", \"/home/ahemf/cache/\")\n",
    "\n",
    "from facebook_hateful_memes_detector.utils import read_json_lines_into_df, in_notebook, set_device, my_collate\n",
    "get_global(\"cache_dir\")\n",
    "from facebook_hateful_memes_detector.models import Fasttext1DCNNModel, MultiImageMultiTextAttentionEarlyFusionModel, LangFeaturesModel, AlbertClassifer\n",
    "from facebook_hateful_memes_detector.preprocessing import TextImageDataset, get_datasets, get_image2torchvision_transforms, TextAugment\n",
    "from facebook_hateful_memes_detector.preprocessing import DefinedRotation, QuadrantCut, ImageAugment\n",
    "from facebook_hateful_memes_detector.training import *\n",
    "import facebook_hateful_memes_detector\n",
    "reload(facebook_hateful_memes_detector)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_device(device)\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T11:04:01.315377Z",
     "start_time": "2020-08-23T11:04:01.311526Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from transformers import pipeline\n",
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from tqdm.auto import tqdm, trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T16:25:45.017923Z",
     "start_time": "2020-08-15T16:25:44.913868Z"
    }
   },
   "outputs": [],
   "source": [
    "data = get_datasets(data_dir=\"../data/\", train_text_transform=None, train_image_transform=None, \n",
    "                    test_text_transform=None, test_image_transform=None, \n",
    "                    cache_images = True, use_images = False, dev=False, test_dev=True,\n",
    "                    keep_original_text=False, keep_original_image=False, \n",
    "                    keep_processed_image=True, keep_torchvision_image=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T16:25:47.623212Z",
     "start_time": "2020-08-15T16:25:47.601905Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42953</td>\n",
       "      <td>../data/img/42953.png</td>\n",
       "      <td>0</td>\n",
       "      <td>its their character not their color that matters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23058</td>\n",
       "      <td>../data/img/23058.png</td>\n",
       "      <td>0</td>\n",
       "      <td>don't be afraid to love again everyone is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13894</td>\n",
       "      <td>../data/img/13894.png</td>\n",
       "      <td>0</td>\n",
       "      <td>putting bows on your pet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37408</td>\n",
       "      <td>../data/img/37408.png</td>\n",
       "      <td>0</td>\n",
       "      <td>i love everything and everybody! except for sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82403</td>\n",
       "      <td>../data/img/82403.png</td>\n",
       "      <td>0</td>\n",
       "      <td>everybody loves chocolate chip cookies, even h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8495</th>\n",
       "      <td>10423</td>\n",
       "      <td>../data/img/10423.png</td>\n",
       "      <td>1</td>\n",
       "      <td>nobody wants to hang auschwitz me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8496</th>\n",
       "      <td>98203</td>\n",
       "      <td>../data/img/98203.png</td>\n",
       "      <td>1</td>\n",
       "      <td>when god grants you a child after 20 years of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8497</th>\n",
       "      <td>36947</td>\n",
       "      <td>../data/img/36947.png</td>\n",
       "      <td>1</td>\n",
       "      <td>gays on social media: equality! body positivit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8498</th>\n",
       "      <td>16492</td>\n",
       "      <td>../data/img/16492.png</td>\n",
       "      <td>1</td>\n",
       "      <td>having a bad day? you could be a siamese twin ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8499</th>\n",
       "      <td>15937</td>\n",
       "      <td>../data/img/15937.png</td>\n",
       "      <td>1</td>\n",
       "      <td>i hate muslims too they take their religion to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                    img  label  \\\n",
       "0     42953  ../data/img/42953.png      0   \n",
       "1     23058  ../data/img/23058.png      0   \n",
       "2     13894  ../data/img/13894.png      0   \n",
       "3     37408  ../data/img/37408.png      0   \n",
       "4     82403  ../data/img/82403.png      0   \n",
       "...     ...                    ...    ...   \n",
       "8495  10423  ../data/img/10423.png      1   \n",
       "8496  98203  ../data/img/98203.png      1   \n",
       "8497  36947  ../data/img/36947.png      1   \n",
       "8498  16492  ../data/img/16492.png      1   \n",
       "8499  15937  ../data/img/15937.png      1   \n",
       "\n",
       "                                                   text  \n",
       "0      its their character not their color that matters  \n",
       "1     don't be afraid to love again everyone is not ...  \n",
       "2                              putting bows on your pet  \n",
       "3     i love everything and everybody! except for sq...  \n",
       "4     everybody loves chocolate chip cookies, even h...  \n",
       "...                                                 ...  \n",
       "8495                  nobody wants to hang auschwitz me  \n",
       "8496  when god grants you a child after 20 years of ...  \n",
       "8497  gays on social media: equality! body positivit...  \n",
       "8498  having a bad day? you could be a siamese twin ...  \n",
       "8499  i hate muslims too they take their religion to...  \n",
       "\n",
       "[8500 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL/Transformers based Aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T16:28:24.127922Z",
     "start_time": "2020-08-15T16:28:24.124145Z"
    }
   },
   "outputs": [],
   "source": [
    "ARTICLE = \"\"\" New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\n",
    "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\n",
    "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\n",
    "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\n",
    "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the\n",
    "2010 marriage license application, according to court documents.\n",
    "Prosecutors said the marriages were part of an immigration scam.\n",
    "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further.\n",
    "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective\n",
    "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002.\n",
    "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say.\n",
    "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages.\n",
    "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted.\n",
    "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s\n",
    "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali.\n",
    "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force.\n",
    "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
    "\"\"\"\n",
    "text = 'have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.'\n",
    "\n",
    "text_long = 'have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments, monopolized the financial systems of nations instigated wars and intentionally created chaos in societies? the jews have mass murdered millions of non- jews over the centuries they have seized control of the media so you will never find out study the history of the jews!'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- summary\n",
    "    - with synonym replacement\n",
    "    - with word2vec based replacement\n",
    "    - with word cutout and stopword insert\n",
    "    - word split and word join\n",
    "- qna with various questions\n",
    "    - with synonym replacement\n",
    "    - with word2vec based replacement\n",
    "    - with word cutout and stopword insert\n",
    "    - word split and word join\n",
    "    - QnA over summary\n",
    "    - QnA over translation\n",
    "- Back translate\n",
    "    - with synonym replacement\n",
    "    - with word2vec based replacement\n",
    "    - with word cutout and stopword insert\n",
    "    - word split and word join\n",
    "    - Over summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T16:30:30.468143Z",
     "start_time": "2020-08-15T16:28:52.428124Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ddb06dc7ba6409b90ec51f2eee9b63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=443.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b19b2b4ce9748e187f90d28b8373ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2124801240428b8490c64a8112a32a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1340675298.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16d2972e820743a2ae173bd0aa6c55af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=716.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad26d4ee06b447daa486b2e2ca138b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa2f077fb444303b6565cc85da27b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=156.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd71d6897644c7197273a3bcaa14cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=39.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb423ffcc214f579b1a884c19ac1f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=46747084.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b642a87deea2462bacdee2500e5b87fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=463.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04f19c903bf1490386f91c8d435e9d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c88f6d445b419ab61cde3797bb047e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=112.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c38a08e043b41149c7a24d114146d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=23.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7729e8b74264466d99ebadff5c124669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=165529444.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0179c858dc894034a10a56d49976baa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=451.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "217817b590c94bd783eb46ce3963daf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784cc76e6a3343bd9bf5de899cc1be60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=265481570.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57a5948bc984ad28db3921890ff2dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=798011.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a308e3f875b4c88926213815f97fa8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4553d4ac8a564a36a7c2a15081cf8932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=467042463.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# twmkn9/albert-base-v2-squad2 , twmkn9/distilroberta-base-squad2, huggingface/prunebert-base-uncased-6-finepruned-w-distil-squad\n",
    "# mrm8488/bert-tiny-finetuned-squadv2 , mrm8488/bert-small-finetuned-squadv2, mrm8488/bert-mini-finetuned-squadv2\n",
    "\n",
    "\n",
    "bert_qna_tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "bert_qna_model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "albert_qna_tokenizer = AutoTokenizer.from_pretrained(\"twmkn9/albert-base-v2-squad2\")\n",
    "albert_qna_model = AutoModelForQuestionAnswering.from_pretrained(\"twmkn9/albert-base-v2-squad2\")\n",
    "\n",
    "tiny_bert_qna_tokenizer = AutoTokenizer.from_pretrained(\"mrm8488/bert-medium-finetuned-squadv2\")\n",
    "tiny_bert_qna_model = AutoModelForQuestionAnswering.from_pretrained(\"mrm8488/bert-medium-finetuned-squadv2\")\n",
    "\n",
    "\n",
    "distilbert_qna_tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
    "distilbert_qna_model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert-base-uncased-distilled-squad\")\n",
    "\n",
    "from transformers import XLNetTokenizer, XLNetForQuestionAnswering, XLNetForQuestionAnsweringSimple\n",
    "import torch\n",
    "\n",
    "XLNet_qna_tokenizer =  XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "XLNet_qna_model = XLNetForQuestionAnsweringSimple.from_pretrained('xlnet-base-cased')\n",
    "\n",
    "\n",
    "qna_models = dict(bert=dict(tokenizer=bert_qna_tokenizer, model=bert_qna_model),\n",
    "                 albert=dict(tokenizer=albert_qna_tokenizer, model=albert_qna_model),\n",
    "                 tiny_bert=dict(tokenizer=tiny_bert_qna_tokenizer, model=tiny_bert_qna_model),\n",
    "                 distilbert=dict(tokenizer=distilbert_qna_tokenizer, model=distilbert_qna_model),\n",
    "                 XLNet=dict(tokenizer=XLNet_qna_tokenizer, model=XLNet_qna_model))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T16:32:58.432588Z",
     "start_time": "2020-08-15T16:32:58.421833Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_question_answering(initial_aug=None, qna_model: dict=qna_models[\"bert\"]):\n",
    "    questions = [\"Is this offensive?\", \n",
    "                 \"What part is offensive, bad, misinformed, hurtful?\", \n",
    "                 \"Blatantly misguiding and forming opinion?\", \n",
    "                 \"Only opinions are expressed?\",\n",
    "                \"Targeted towards a particular race, gender, community?\", \n",
    "                 \"Is this hate speech?\",\n",
    "                \"Is there a show of disdain and cynicism?\",\n",
    "                \"Who is responsible and who should be blamed?\",\n",
    "                \"Are they doing the right thing? Should they be corrected?\",\n",
    "                \"We need to stop them!\",\n",
    "                \"Us vs them,\",\n",
    "                 \"What is happening?\",\"Why?\", \"How\", \"When did they?\", \"Thier ways?\"]\n",
    "    from collections import defaultdict\n",
    "    def transform(text):\n",
    "        tokenizer = qna_model[\"tokenizer\"]\n",
    "        model = qna_model[\"model\"]\n",
    "        with torch.no_grad():\n",
    "            text = initial_aug(text) if initial_aug is not None else text\n",
    "            answers = []\n",
    "            batch_inputs = defaultdict(list)\n",
    "            for question in questions:\n",
    "                inputs = tokenizer.encode_plus(question, text, add_special_tokens=True, return_tensors=\"pt\", pad_to_max_length=True, max_length=256)\n",
    "                for k, v in inputs.items():\n",
    "                    batch_inputs[k].append(v)\n",
    "\n",
    "            for k, v in batch_inputs.items():\n",
    "                batch_inputs[k] = torch.cat(v, 0)\n",
    "            answer_start_scores, answer_end_scores = model(**batch_inputs)\n",
    "            answer_start = torch.argmax(answer_start_scores, 1)  # Get the most likely beginning of answer with the argmax of the score\n",
    "            answer_end = torch.argmax(answer_end_scores, 1) + 1 \n",
    "            for i, input_ids in  enumerate(batch_inputs[\"input_ids\"]):\n",
    "                answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start[i]:answer_end[i]]))\n",
    "                answers.append(answer)\n",
    "            answers = list(set([a for a in answers if len(a.split())>=2]))\n",
    "            return answers\n",
    "        \n",
    "    return transform\n",
    "\n",
    "qna = get_question_answering(qna_model=qna_models[\"distilbert\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T16:33:01.135832Z",
     "start_time": "2020-08-15T16:32:59.429870Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they have always banded together as a tribe , infiltrated governments',\n",
       " 'infiltrated governments']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qna('have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Summarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T16:50:01.441662Z",
     "start_time": "2020-08-15T16:42:58.553907Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b928687b93743488c10888d34468d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1200.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0d8fa1af5b40ce912f0b6264cab634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2950825948.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f508c45a9c6d449299ad0127108d764d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=791656.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d21d58fb6aa490787e082b2beda4059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1300.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7daee27caa4946009d3b580109e017fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1625270765.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f05a92fba24776a973ea1c012f6392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=611.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5c3cac78e741739a50bfc11f5932c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=2049344.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d93aa658ab4173b448ddae7bb18e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1004909.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8120a4ddbf4dc48a0c3cdaec5309f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=6552025106.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelWithLMHead, AutoTokenizer\n",
    "\n",
    "t5_summarizer_model = AutoModelWithLMHead.from_pretrained(\"t5-large\")\n",
    "t5_summarizer_tokenizer = AutoTokenizer.from_pretrained(\"t5-large\")\n",
    "\n",
    "bart_summarizer_tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "bart_summarizer_model = AutoModelWithLMHead.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "\n",
    "ctrl_summarizer_tokenizer = AutoTokenizer.from_pretrained(\"ctrl\")\n",
    "ctrl_summarizer_model = AutoModelWithLMHead.from_pretrained(\"ctrl\")\n",
    "\n",
    "\n",
    "\n",
    "summary_models = dict(ctrl=dict(tokenizer=ctrl_summarizer_tokenizer, model=ctrl_summarizer_model),\n",
    "                    bart=dict(tokenizer=bart_summarizer_tokenizer, model=bart_summarizer_model),\n",
    "                    t5=dict(tokenizer=t5_summarizer_tokenizer, model=t5_summarizer_model))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T16:51:56.173624Z",
     "start_time": "2020-08-15T16:51:35.482753Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summarize: New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York.\\n A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband.\\n Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other.\\n In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage.\\n Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in',\n",
       " '</s><s>Liana Barrientos has been married five times since she was 23 years old. She got married in Westchester County, New York, in',\n",
       " 'Liana barrientos declared \"i do\" five more times, sometimes within two weeks of each other . in 2010, she married once more,']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "['summarize: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.',\n",
       " '</s><s>The jews have always banded together as a tribe, infiltrated governments. Have you ever studied the history of the jews? did you know',\n",
       " 'jews have always banded together as a tribe, infiltrated governments . they have always banded together as a']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def get_summarizer(models, initial_aug=None, ):\n",
    "    from collections import defaultdict\n",
    "    def transform(text):\n",
    "        summaries = []\n",
    "        with torch.no_grad():\n",
    "            for k, m in models.items():\n",
    "                tokenizer = m[\"tokenizer\"]\n",
    "                model = m[\"model\"]\n",
    "                _ = model.eval()\n",
    "                inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=128)\n",
    "                outputs = model.generate(inputs, max_length=32, min_length=16, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "                summ = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(outputs[0]))\n",
    "                summaries.append(summ)\n",
    "            return summaries\n",
    "    return transform\n",
    "\n",
    "summary_generator = get_summarizer(summary_models)\n",
    "summary_generator(ARTICLE)\n",
    "summary_generator(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T11:07:45.125647Z",
     "start_time": "2020-08-23T11:07:29.947063Z"
    }
   },
   "outputs": [],
   "source": [
    "btdict = dict()\n",
    "\n",
    "# model_name = 'Helsinki-NLP/opus-mt-en-tn'\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# model = MarianMTModel.from_pretrained(model_name)\n",
    "# btdict[\"en-tn\"] = dict(fwd=(tokenizer, model))\n",
    "\n",
    "# model_name = 'Helsinki-NLP/opus-mt-tn-en'\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# btdict[\"en-tn\"][\"inv\"] = (tokenizer, model)\n",
    "\n",
    "\n",
    "model_name = 'Helsinki-NLP/opus-mt-en-ru'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "btdict[\"en-ru\"] = dict(fwd=(tokenizer, model))\n",
    "\n",
    "model_name = 'Helsinki-NLP/opus-mt-ru-en'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "btdict[\"en-ru\"][\"inv\"] = (tokenizer, model)\n",
    "\n",
    "\n",
    "# model_name = 'Helsinki-NLP/opus-mt-en-de'\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# model = MarianMTModel.from_pretrained(model_name)\n",
    "# btdict[\"en-de\"] = dict(fwd=(tokenizer, model))\n",
    "\n",
    "# model_name = 'Helsinki-NLP/opus-mt-de-en'\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# btdict[\"en-de\"][\"inv\"] = (tokenizer, model)\n",
    "\n",
    "\n",
    "# model_name = 'Helsinki-NLP/opus-mt-en-CELTIC'\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# model = MarianMTModel.from_pretrained(model_name)\n",
    "# btdict[\"en-CELTIC\"] = dict(fwd=(tokenizer, model))\n",
    "\n",
    "# model_name = 'sshleifer/opus-mt-CELTIC-en'\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# btdict[\"en-CELTIC\"][\"inv\"] = (tokenizer, model)\n",
    "\n",
    "\n",
    "# model_name = 'Helsinki-NLP/opus-mt-en-ROMANCE'\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# model = MarianMTModel.from_pretrained(model_name)\n",
    "# btdict[\"en-ROMANCE\"] = dict(fwd=(tokenizer, model))\n",
    "\n",
    "# model_name = 'Helsinki-NLP/opus-mt-ROMANCE-en'\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# btdict[\"en-ROMANCE\"][\"inv\"] = (tokenizer, model)\n",
    "\n",
    "# model_name = 'Helsinki-NLP/opus-mt-en-chk'\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# model = MarianMTModel.from_pretrained(model_name)\n",
    "# btdict[\"en-chk\"] = dict(fwd=(tokenizer, model))\n",
    "\n",
    "# model_name = 'Helsinki-NLP/opus-mt-chk-en'\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# btdict[\"en-chk\"][\"inv\"] = (tokenizer, model)\n",
    "\n",
    "# model_name = 'Helsinki-NLP/opus-mt-en-jap'\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# model = MarianMTModel.from_pretrained(model_name)\n",
    "# btdict[\"en-jap\"] = dict(fwd=(tokenizer, model))\n",
    "\n",
    "# model_name = 'Helsinki-NLP/opus-mt-jap-en'\n",
    "# tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "# model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "# btdict[\"en-jap\"][\"inv\"] = (tokenizer, model)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T11:40:16.744657Z",
     "start_time": "2020-08-23T11:40:16.733843Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "def get_back_translation_model(btdict):\n",
    "    def back_translate(text):\n",
    "        texts = [text]\n",
    "        tl = len(text.split())\n",
    "        answers = []\n",
    "        for k, v in btdict.items():\n",
    "            fwd_tokenizer, fwd_model = v[\"fwd\"]\n",
    "            inv_tokenizer, inv_model = v[\"inv\"]\n",
    "            lang_codes = fwd_tokenizer.supported_language_codes\n",
    "            if \"ROMANCE\" in k:\n",
    "                lang_codes = ['>>fr<<', '>>es<<', '>>it<<', '>>pt<<', '>>ro<<', '>>ca<<', '>>gl<<', '>>la<<', '>>wa<<', '>>fur<<', '>>oc<<', '>>sc<<', '>>an<<', '>>frp<<',]\n",
    "            if len(lang_codes) > 0:\n",
    "                texts = [t for text in texts for t in [lang+\" \"+text for lang in lang_codes]]\n",
    "            translated = fwd_model.generate(**fwd_tokenizer.prepare_translation_batch(texts))\n",
    "            fwd_translations = [fwd_tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "            inv_batch = inv_tokenizer.prepare_translation_batch(fwd_translations)\n",
    "            translated = inv_model.generate(**inv_batch)\n",
    "            tgt_text = [inv_tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "            answers.append(tgt_text)\n",
    "        answers = [a for ans in answers for a in ans]\n",
    "        ans_lens = [len(a.split()) for a in answers]\n",
    "        answers = list(set([a for l,a in zip(ans_lens,answers) if l>=2 and l>=tl/2]))\n",
    "        return answers\n",
    "    return back_translate\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T11:40:18.920574Z",
     "start_time": "2020-08-23T11:40:17.254122Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Кошка сидела на крыльце, потягивая пинту молока.']\n",
      "{'input_ids': tensor([[ 5468,  7555, 18523,    41,    17,    42,  3170,  7795,    30,     2,\n",
      "            15,   275,  8020,  2434,   106,    21, 23045,  2055, 36515,     3,\n",
      "             0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "tensor([[62517,    32, 12936, 19046,    25,     4,   562,   649,  2161,     2,\n",
      "         29932,    13,   562,  7307,     5, 18675,     3]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The cat sat on the porch, pulling a pint of milk.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_translate = get_back_translation_model(btdict)\n",
    "back_translate(\"The cat sat on the front porch sipping a pint of milk.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T06:31:48.076942Z",
     "start_time": "2020-06-06T06:25:54.748970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.8 s ± 3.82 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit back_translate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T08:08:18.888140Z",
     "start_time": "2020-08-23T08:00:21.733616Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/fairseq/archive/master.zip\" to /home/ahemf/.cache/torch/hub/master.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running build_ext\n",
      "cythoning fairseq/data/data_utils_fast.pyx to fairseq/data/data_utils_fast.cpp\n",
      "cythoning fairseq/data/token_block_utils_fast.pyx to fairseq/data/token_block_utils_fast.cpp\n",
      "building 'fairseq.libbleu' extension\n",
      "creating /local/home/ahemf/.cache/torch/hub/pytorch_fairseq_master/build\n",
      "creating /local/home/ahemf/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7\n",
      "creating /local/home/ahemf/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq\n",
      "creating /local/home/ahemf/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/clib\n",
      "creating /local/home/ahemf/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu\n",
      "Emitting ninja build file /local/home/ahemf/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "creating build/lib.linux-x86_64-3.7\n",
      "creating build/lib.linux-x86_64-3.7/fairseq\n",
      "g++ -pthread -shared -B /home/ahemf/anaconda3/compiler_compat -L/home/ahemf/anaconda3/lib -Wl,-rpath=/home/ahemf/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ /local/home/ahemf/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/libbleu.o /local/home/ahemf/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/clib/libbleu/module.o -o build/lib.linux-x86_64-3.7/fairseq/libbleu.cpython-37m-x86_64-linux-gnu.so\n",
      "building 'fairseq.data.data_utils_fast' extension\n",
      "creating /local/home/ahemf/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/data\n",
      "Emitting ninja build file /local/home/ahemf/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "creating build/lib.linux-x86_64-3.7/fairseq/data\n",
      "g++ -pthread -shared -B /home/ahemf/anaconda3/compiler_compat -L/home/ahemf/anaconda3/lib -Wl,-rpath=/home/ahemf/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ /local/home/ahemf/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/data/data_utils_fast.o -o build/lib.linux-x86_64-3.7/fairseq/data/data_utils_fast.cpython-37m-x86_64-linux-gnu.so\n",
      "building 'fairseq.data.token_block_utils_fast' extension\n",
      "Emitting ninja build file /local/home/ahemf/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "g++ -pthread -shared -B /home/ahemf/anaconda3/compiler_compat -L/home/ahemf/anaconda3/lib -Wl,-rpath=/home/ahemf/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ /local/home/ahemf/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.o -o build/lib.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.cpython-37m-x86_64-linux-gnu.so\n",
      "building 'fairseq.libnat' extension\n",
      "creating /local/home/ahemf/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/clib/libnat\n",
      "Emitting ninja build file /local/home/ahemf/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/build.ninja...\n",
      "Compiling objects...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "g++ -pthread -shared -B /home/ahemf/anaconda3/compiler_compat -L/home/ahemf/anaconda3/lib -Wl,-rpath=/home/ahemf/anaconda3/lib -Wl,--no-as-needed -Wl,--sysroot=/ /local/home/ahemf/.cache/torch/hub/pytorch_fairseq_master/build/temp.linux-x86_64-3.7/fairseq/clib/libnat/edit_dist.o -L/home/ahemf/anaconda3/lib/python3.7/site-packages/torch/lib -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-3.7/fairseq/libnat.cpython-37m-x86_64-linux-gnu.so\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/libbleu.cpython-37m-x86_64-linux-gnu.so -> fairseq\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/data_utils_fast.cpython-37m-x86_64-linux-gnu.so -> fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/data/token_block_utils_fast.cpython-37m-x86_64-linux-gnu.so -> fairseq/data\n",
      "copying build/lib.linux-x86_64-3.7/fairseq/libnat.cpython-37m-x86_64-linux-gnu.so -> fairseq\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2988854245/2988854245 [00:59<00:00, 50220417.19B/s]\n",
      "Using cache found in /home/ahemf/.cache/torch/hub/pytorch_fairseq_master\n",
      "100%|██████████| 2992273886/2992273886 [01:01<00:00, 48385103.15B/s]\n",
      "Using cache found in /home/ahemf/.cache/torch/hub/pytorch_fairseq_master\n",
      " 44%|████▍     | 5265638400/11946275315 [02:02<03:36, 30829950.00B/s] "
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-905029d6d86d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m en2de_cp4 = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de',\n\u001b[1;32m      6\u001b[0m                        \u001b[0mcheckpoint_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model1.pt:model2.pt:model3.pt:model4.pt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                        tokenizer='moses', bpe='fastbpe')\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m de2en_cp4 = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.de-en',\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/hub.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(github, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[0mentry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_entry_from_hubconf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhub_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 353\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_master/fairseq/models/fairseq_model.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, model_name_or_path, checkpoint_file, data_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mdata_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0marchive_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         )\n\u001b[1;32m    257\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"args\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/torch/hub/pytorch_fairseq_master/fairseq/hub_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(model_name_or_path, checkpoint_file, data_name_or_path, archive_map, **kwargs)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# convenience hack for loading data and BPE codes from model archive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_name_or_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_archive_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_name_or_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/posixpath.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(a, *p)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdiscarded\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mAn\u001b[0m \u001b[0mempty\u001b[0m \u001b[0mlast\u001b[0m \u001b[0mpart\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpath\u001b[0m \u001b[0mthat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     ends with a separator.\"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_sep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "models_dict= dict()\n",
    "import torch\n",
    "en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "de2en = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.de-en.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "en2de_cp4 = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de',\n",
    "                       checkpoint_file='model1.pt:model2.pt:model3.pt:model4.pt',\n",
    "                       tokenizer='moses', bpe='fastbpe')\n",
    "\n",
    "de2en_cp4 = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.de-en',\n",
    "                       checkpoint_file='model1.pt:model2.pt:model3.pt:model4.pt',\n",
    "                       tokenizer='moses', bpe='fastbpe')\n",
    "en2de_wmt16 = torch.hub.load('pytorch/fairseq', 'transformer.wmt16.en-de', tokenizer='moses', bpe='fastbpe')\n",
    "en2de_wmt17 = torch.hub.load('pytorch/fairseq', 'conv.wmt17.en-de', tokenizer='moses', bpe='fastbpe')\n",
    "en2ru = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-ru.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "ru2en = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.ru-en.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "\n",
    "models_dict[\"en-de\"] = dict(fwd=[en2de, en2de_cp4, en2de_wmt16, en2de_wmt17], inv=[de2en, de2en_cp4])\n",
    "models_dict[\"en-ru\"] = dict(fwd=[en2ru], inv=[ru2en])\n",
    "\n",
    "\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-23T08:08:18.890811Z",
     "start_time": "2020-08-23T08:00:37.269Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 5268157440/11946275315 [02:20<03:36, 30829950.00B/s]"
     ]
    }
   ],
   "source": [
    "def get_pytorch_backtranslate(mdict):\n",
    "    def py_translate(text):\n",
    "        tl = len(text.split())\n",
    "        answers = []\n",
    "        for k, v in mdict.items():\n",
    "            fwd = v[\"fwd\"]\n",
    "            inv = v[\"inv\"]\n",
    "            for fm in fwd:\n",
    "                intermediate = fm.translate(text)\n",
    "                for bm in inv:\n",
    "                    res = bm.translate(intermediate)\n",
    "                    answers.append(res)\n",
    "        ans_lens = [len(a.split()) for a in answers]\n",
    "        answers = list(set([a for l,a in zip(ans_lens,answers) if l>=2 and l>=tl/2]))\n",
    "        return answers\n",
    "    return py_translate\n",
    "\n",
    "py_translate = get_pytorch_backtranslate(models_dict)\n",
    "py_translate(\"The cat sat on the front porch sipping a pint of milk.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Text Generation [x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T11:45:41.671622Z",
     "start_time": "2020-06-07T11:42:44.407310Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd159f87d86e4fde9aa4a40f3bb7a1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020ab5c675cc47ffa5ce3683eed752e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fdeb3f655a47d686c4fece9db5ea4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0fb0b7e570452aa8af4c74228242fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5acc5efdbf147b6a7714a8716b5a3d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gen_model_names = [\"gpt2\", \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\", \"microsoft/DialoGPT-large\"]\n",
    "\n",
    "gen_models = [pipeline(\"text-generation\")] + [pipeline(\"text-generation\", model=m, tokenizer=m) for m in gen_model_names]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T16:21:48.595623Z",
     "start_time": "2020-06-07T16:17:48.958272Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-07 16:17:48 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:17:51 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:17:55 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:17:57 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:02 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:05 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:07 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:10 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:13 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:15 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:18 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:20 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:21 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:22 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:23 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:24 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:25 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:27 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:28 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:29 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:29 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:30 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:31 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:31 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:32 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:33 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:35 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:36 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:38 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:39 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:41 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:42 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:43 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:45 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:46 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:47 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:51 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:18:55 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:19:03 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:19:06 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:19:10 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:19:13 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:19:17 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:19:19 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:19:22 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:19:24 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:19:26 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:19:32 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:19:37 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:19:47 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:20:00 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:20:13 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:20:17 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:20:23 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:20:29 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:20:33 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:20:37 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:20:40 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:20:43 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:20:46 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:20:50 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:20:51 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:20:52 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:20:56 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:21:03 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:21:08 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:21:16 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:21:20 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:21:27 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:21:31 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:21:39 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
      "2020-06-07 16:21:44 WARNING: Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments. Did you ever know that jews know the unspoken regulations of the land that our country',\n",
       " \"0: have you ever studied the history of the jews? did you all somehow think the jews were good, if not the fair? did you know there were hundreds of 'ducks' of coloured parts, only four-fif\",\n",
       " \"0: know that they have always banded together as a tribe, infiltrated governments. But by now, it's all too familiar. At the very least, they have known each other before.\\n\\nThis summer, more and more people\",\n",
       " '0: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments. now they have joined together as a community?\"\\n\\n\\nAnd, \"but I know all',\n",
       " \"0: have you ever studied the history of the jews? did you see a lot of them?\\n\\n\\nLurker: Never. People did know about these people. They don't talk about them now. They're on the\",\n",
       " '0: know that they have always banded together as a tribe, infiltrated governments. [7] It has been stated that she and The Prophet of Christ had a relationship known as the Confession of Faith. This was not the case for',\n",
       " '0: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. Our opinion is that no matter how ancient there is like the Greek, Antigua,',\n",
       " '0: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. You know, these are great people and how do you come up with an argument about how',\n",
       " '0: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. They are well known for their black magic, and both Adolf Hitler and Benjamin Brown, leader',\n",
       " '0: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. I think they are due for an excommunication as soon as we give them our vote?',\n",
       " '0: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. Their poeple have done it wrong!! The best way to tell if the jews',\n",
       " '0: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. In the past those guys have always done interesting things like overthrowing US President George Washington,\\n----------------------------------------------------------------------------------------------------\\n',\n",
       " '1: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments. They become so afraid of every good man of great strength and prosperity that they say \"Get',\n",
       " '1: have you ever studied the history of the jews? did you have a lover (or worse) both being held by J.I.P. Lee in 1888? Or at least are you pretty sure them?) On display are',\n",
       " \"1: know that they have always banded together as a tribe, infiltrated governments. One of her best friends is captured by the CIA. She learns of the war's true origins, and sends a team to be careful with their communications.\",\n",
       " '1: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments. they have been trained, financed, and trained as they are now? And how does this',\n",
       " \"1: have you ever studied the history of the jews? did you play with them till a little while ago? do you know a lot about them? what about jews who are killed in our country's history or do they die\",\n",
       " \"1: know that they have always banded together as a tribe, infiltrated governments. However, when the last remnants of their tribe were defeated by the North's last ally, they turned their attention to the South and tried to make their way\",\n",
       " '1: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. Our opinion is it? if you wondered why, we checked it.\\n\\nand you',\n",
       " '1: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. You know those mighty empires which have now so far made the two kingdoms independent completely but by',\n",
       " '1: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. They are well known for their allegiance to Nazis, when they were on their crusade against the',\n",
       " '1: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. I think they are as much interested in fighting their own tribes as they are in modern reality',\n",
       " '1: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. Their poeple have done nearly all of the damage to us.. Their wars have gone',\n",
       " '1: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. In the past those guys took over Japan and America and cut down the currency.. Some of\\n----------------------------------------------------------------------------------------------------\\n',\n",
       " \"2: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments. they are always hidden away in the Illuminati? You can't even take class 6 notes in\",\n",
       " '2: have you ever studied the history of the jews? did you eat up every last piece of it?\\' \"\\'Yes, a little.\\' \"\\'Perhaps,\\' said he, \\'you may be able to tell what rank you hold.\\' \"\\'',\n",
       " '2: know that they have always banded together as a tribe, infiltrated governments. Let them know just what a despicable group they are.\" Trump used the power of the presidency to curtail the conservative movement and embolden the resistance movement, and',\n",
       " '2: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments. just like the Romans did? as soon as they are faced with the obvious choice. they',\n",
       " \"2: have you ever studied the history of the jews? did you know that they're not only a jew, but the most feared people in the world??? You know those people who worship the jews at their temple? Well\",\n",
       " '2: know that they have always banded together as a tribe, infiltrated governments. … Well, all I can do is tell you that one of them had the ability to manipulate others by having them be led into doing his bidding and then',\n",
       " '2: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. Our opinion is, that they deserve to be forgiven for what they have done.\\n\\n\\n',\n",
       " '2: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. You know.. why do you think they havent...\\n\\nYeah, and the government',\n",
       " '2: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. They are well known for bullying and instilling distrust in everyone. They make sure that every',\n",
       " '2: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. I think they are behind 100% of the violence around the world. this mass genocide is',\n",
       " '2: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. Their poeple have done huge damage in the world through espionage and wanton tyranny.',\n",
       " '2: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. In the past those guys have been an important part of the Roman State and they ruled through\\n----------------------------------------------------------------------------------------------------\\n',\n",
       " '3: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments. many times. but they have always been forbidden to. as for this: believe me,',\n",
       " '3: have you ever studied the history of the jews? did you see his \\'official\\' views? how is it possible to say that he was an \"atheist\" while calling for an atheist revolution.\\n\\nPossible responses',\n",
       " '3: know that they have always banded together as a tribe, infiltrated governments. and are in constant surveillance of people, taking photos and listening to conversations. All they ever hear, for good reason, is exactly what they want it to',\n",
       " \"3: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments. the only reason they don't control the banks is because jews were there to put them\",\n",
       " '3: have you ever studied the history of the jews? did you have any good experience? You know there is no need to feel uncomfortable when you come here. do you wish to ask me anything else? Good night\"',\n",
       " '3: know that they have always banded together as a tribe, infiltrated governments.\\n\\nWhy they don\\'t just blow us all up and run off. Because, in the words of one of our very good, trusted friends: \"',\n",
       " '3: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. Our opinion is 100% in favor of jews.. and that is why Israel has a',\n",
       " '3: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. You know.. The history of their people is infinite.. have you watched the great depression?',\n",
       " '3: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. They are well known for their uncanny ability to gather, sell and then infiltrate cultures.. Have',\n",
       " '3: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. I think they had to when they found out the USA was the most powerful empire on the',\n",
       " '3: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. Their poeple have done the deed together... what, people, ARE YOU READY',\n",
       " '3: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. In the past those guys were the vikings.. still are... they think they own\\n----------------------------------------------------------------------------------------------------\\n',\n",
       " '4: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments. they are terrorist in origin.. while others may call them jews.... yes.. there has',\n",
       " '4: have you ever studied the history of the jews? did you know jews are the dindus of the world you are missing the point i am nothing but a nigger im the most dangerous man in the world your on',\n",
       " \"4: know that they have always banded together as a tribe, infiltrated governments. They are like child's play to the real terrorists, like little ants to be made fun of, like ants and bumble bees and the like. They\",\n",
       " '4: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments. I am not saying, do they not know how to use this power of persuasion, manipulation',\n",
       " \"4: have you ever studied the history of the jews? did you ever wonder how we got here, how the jews ended up like this, where we're going, why, etc. etc.? so many myths, so little\",\n",
       " '4: know that they have always banded together as a tribe, infiltrated governments. That you know.\\n\\n\"Even if the United States was not a nation, it is more than a country. I love this nation. I love',\n",
       " '4: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. Our opinion is that these people are aligned with humanity more than they are with race.\" –',\n",
       " '4: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. You know what I mean... THEY HAVE MASSIVE ARMY WANTS.. That',\n",
       " '4: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. They are well known for their treason and plotting against religions. This crime of genocide is how',\n",
       " '4: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. I think they have \"found some new nerve\" if you could call it that, with',\n",
       " '4: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. Their poeple have done terrible things in the past..and now they are doing the',\n",
       " '4: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. In the past those guys were called catholics, they were part of a much older group\\n----------------------------------------------------------------------------------------------------\\n',\n",
       " '5: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.lol',\n",
       " '5: have you ever studied the history of the jews? did you do the research yourself? historians work long hours.',\n",
       " \"5: know that they have always banded together as a tribe, infiltrated governments.It'll take some serious dedication to try to go through all the channels channels.\",\n",
       " '5: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.Its why Jews are all over the world today',\n",
       " '5: have you ever studied the history of the jews? did you ever understand that they were a historical figure who was literally murdered.',\n",
       " '5: know that they have always banded together as a tribe, infiltrated governments.It is the part that changed my opinion on this whole thing.',\n",
       " '5: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. Our opinion is enough to say to save in peace of mind',\n",
       " '5: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. You know, and when they successfully attack and stop...',\n",
       " \"5: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. They are well known for they're cult mentality if you'll believe it!\",\n",
       " '5: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. I think they had a claim to the desert. nomnomnomnomnomnomnomnom',\n",
       " '5: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. Their poeple have done this for thousands and thousands of years.',\n",
       " '5: have you ever studied the history of the jews? did you know that they have always banded together as a tribe, infiltrated governments.. In the past those guys are still around.\\n----------------------------------------------------------------------------------------------------\\n']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_gen_models(gen_models):\n",
    "    def generate(text, nlp):\n",
    "        spaced_tokens = text.split()\n",
    "        n_tokens = len(spaced_tokens)\n",
    "        nlp1 = lambda t: nlp(t,max_length=n_tokens*2, clean_up_tokenization_spaces=True, do_sample=True, top_p=0.97, top_k=500)[0]['generated_text']\n",
    "        nlp2 = lambda t: nlp(t,max_length=n_tokens*2, clean_up_tokenization_spaces=True, do_sample=True, top_p=0.95, top_k=100)[0]['generated_text']\n",
    "        if n_tokens <= 3:\n",
    "            return [text]\n",
    "        t1 = nlp1(text)\n",
    "        t2 = nlp1(\" \".join(spaced_tokens[:int(n_tokens/2)]))\n",
    "        t3 = nlp1(\" \".join(spaced_tokens[int(n_tokens/2):]))\n",
    "        t4 = nlp2(text)\n",
    "        t5 = nlp2(\" \".join(spaced_tokens[:int(n_tokens/2)]))\n",
    "        t6 = nlp2(\" \".join(spaced_tokens[int(n_tokens/2):]))\n",
    "        \n",
    "        t7 = nlp1(text + \". Our opinion is\")\n",
    "        t8 = nlp1(text + \". You know\")\n",
    "        t9 = nlp1(text + \". They are well known for\")\n",
    "        t10 =  nlp1(text + \". I think they\")\n",
    "        t11 = nlp1(text + \". Their poeple have done\")\n",
    "        t12 = nlp1(text + \". In the past those guys\")\n",
    "        \n",
    "        return [t1, t2, t3, t4, t5, t6, t7, t8, t9, t10, t11, t12]\n",
    "    \n",
    "    def transform(text):\n",
    "        answers=[]\n",
    "        for i, nlp in enumerate(gen_models):\n",
    "            generated = generate(text, nlp)\n",
    "            generated = [str(i) + \": \"+ g for g in generated]\n",
    "            generated[-1] = generated[-1] + \"\\n\" + \"-\"*100 + \"\\n\"\n",
    "            answers.extend(generated)\n",
    "        return answers\n",
    "    return transform\n",
    "\n",
    "text_gen = get_gen_models(gen_models)\n",
    "text_gen(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-06T11:04:57.964510Z",
     "start_time": "2020-06-06T11:03:25.272922Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488ed2aa944e4b60aa56adf3bc259457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2fc3aaa754146868fea0455a81552f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6e5204ca7c499eb11c14d8086097e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "982d8cee4c9641fc847480db5b812ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=230.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fill_mask_model_names = [\n",
    "    \"distilroberta-base\", \"bert-large-uncased-whole-word-masking\",\n",
    "    \"albert-base-v2\", \"Hate-speech-CNERG/dehatebert-mono-english\",\n",
    "    \"novinsh/xlm-roberta-large-toxicomments-12k\",\n",
    "    \"allenai/reviews_roberta_base\", \"ssun32/bert_twitter_turkle\",\n",
    "    \"activebus/BERT_Review\", \"sap-ai-research/BERT-Large-Contrastive-Self-Supervised-ACL2020\"\n",
    "]\n",
    "\n",
    "# \"mrm8488/t5-base-finetuned-span-sentiment-extraction\",\n",
    "# \"mrm8488/distilroberta-base-finetuned-sentiment\",\n",
    "\n",
    "fill_mask_models = [pipeline(\"fill-mask\")] + [\n",
    "    pipeline(\"fill-mask\", model=m, tokenizer=m) for m in fill_mask_model_names\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-07T12:20:01.879802Z",
     "start_time": "2020-06-07T12:20:01.628753Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fill_mask_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-814644aef1b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mfill_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_fill_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_mask_models\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mfill_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fill_mask_models' is not defined"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def get_fill_mask(fill_mask_models):\n",
    "    def fill_mask_ntimes(text, nlp, n=2):\n",
    "        mask = nlp.tokenizer.mask_token\n",
    "        for _ in range(n):\n",
    "            spaced_tokens = clean_text(text).split()\n",
    "            n_tokens = len(spaced_tokens)\n",
    "            token_lengths = list(map(len, spaced_tokens))\n",
    "            token_lengths = np.array([0 if t<=2 else t for t in token_lengths])\n",
    "            token_probas = token_lengths / token_lengths.sum()\n",
    "            mask_pos = np.random.choice(list(range(n_tokens)), 1, replace=False, p=token_probas)[0]\n",
    "            spaced_tokens[mask_pos] = mask\n",
    "            masked_text = \" \".join(spaced_tokens)\n",
    "            replies = nlp(masked_text)\n",
    "            text = [r['sequence'] for r in replies][0]\n",
    "        return text\n",
    "            \n",
    "        \n",
    "    \n",
    "    def fill_mask(text):\n",
    "        spaced_tokens = clean_text(text).split()\n",
    "        n_tokens = len(spaced_tokens)\n",
    "        token_lengths = list(map(len, spaced_tokens))\n",
    "        token_lengths = np.array([0 if t<=2 else t for t in token_lengths])\n",
    "        token_probas = token_lengths / token_lengths.sum()\n",
    "        answers = []\n",
    "        for i, nlp in enumerate(fill_mask_models):\n",
    "            mask = nlp.tokenizer.mask_token\n",
    "            mask_pos = np.random.choice(list(range(n_tokens)), 3, replace=False, p=token_probas)\n",
    "            for p in mask_pos:\n",
    "                tks = list(spaced_tokens)\n",
    "                tks[p] = mask\n",
    "                masked_text = \" \".join(tks)\n",
    "                replies = nlp(masked_text)\n",
    "                replies = [r['sequence'] for r in replies][:2]\n",
    "                answers.extend(replies)\n",
    "        answers = list(set([clean_text(a) for a in answers]))\n",
    "        return answers\n",
    "    \n",
    "    def fill_mask(text):\n",
    "        answers = []\n",
    "        for i, nlp in enumerate(fill_mask_models):\n",
    "            t = fill_mask_ntimes(text, nlp, n=2)\n",
    "            answers.append(t)\n",
    "        answers = list(set([clean_text(a) for a in answers]))\n",
    "        return answers\n",
    "    \n",
    "    return fill_mask\n",
    "\n",
    "    \n",
    "\n",
    "fill_mask = get_fill_mask(fill_mask_models)\n",
    "fill_mask(text)\n",
    "\n",
    "        \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
