{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from math import e\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for checking the datasets\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(points,m):\n",
    "    costt = 0 \n",
    "    M =len(points)\n",
    "    for i in range(M):\n",
    "        y = points[i,(len(points[0])-1)]\n",
    "        x_total=0\n",
    "        for j in range((len(points[0])-1)):\n",
    "            x_total += m[j]*points[i,j]\n",
    "        x_h = sigmoid(x_total)\n",
    "        costt += (1/M)*((-y)*(log(x_h)-(1-y)*(log(1-x_h))))\n",
    "        return costt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding h(x) ie., 1/(1+e^(-mTx))\n",
    "def sigmoid(mTx):\n",
    "    den = 1 + e**(-mTx)\n",
    "    res = 1/den\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Gradient Descent Code Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate through all the data points and find the slope \n",
    "#for generic gradient descent you have only one array of m and the last c have a coeff of 1\n",
    "def step_grad(points,learning_rate,m):\n",
    "    m_slope =np.zeros(len(points[0]))\n",
    "    M = len(points)\n",
    "    for i in range(M):\n",
    "      #  x = points[i,0] this will not work we have to cal x_total (m1x1+m2x2+......)\n",
    "        x_total =0\n",
    "        for j in range((len(points[0])-1)):\n",
    "            x_total += m[j]*points[i,j]\n",
    "    #find the logisics h(x)\n",
    "        x_h = sigmoid(x_total)\n",
    "        y = points[i,(len(points[0])-1)]\n",
    "        l=0\n",
    "        for k in range((len(points[0])-1)):\n",
    "            m_slope[l] += (-1/M)*(y-x_h)*points[i,k]\n",
    "            l=l+1\n",
    "        #c_slope += (-2/M)*(y-m*x-c)\n",
    "    new_m=list([0 for j in range(len(points[0])-1)])\n",
    "    a=0\n",
    "    for i in range((len(points[0])-1)):\n",
    "        new_m[i]=m[i]-learning_rate*m_slope[i]\n",
    "    #new_m = m - learning_rate * m_slope\n",
    "   # new_c = c - learning_rate * c_slope\n",
    "    return new_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as said in gd defnition we have to start m&c with any random value\n",
    "#substract the slope from the m or c till num_iter\n",
    "def gd(points,learning_rate,num_iter):\n",
    "    m=np.zeros(points.shape[1])\n",
    "    #c=0\n",
    "    for i in range(num_iter):\n",
    "        m = step_grad(points,learning_rate,m)\n",
    "        #use cost function not for calculating gd but for getting yourself idea of which way code is going!\n",
    "        #print(i,\"cost:\")\n",
    "        print(i,\"cost:\",cost(points,m))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to load data and send it to gd function to figure out m & c\n",
    "#gd requiires learning rate & number of iter\n",
    "#generic data requires addition of 1 as the coeff of c to each row\n",
    "def run():\n",
    "    cancer_ds = datasets.load_breast_cancer()\n",
    "    x = cancer_ds.data\n",
    "    y = cancer_ds.target\n",
    "    y = y.reshape(-1,1)\n",
    "   # x = preprocessing.scale(x_unscaled)\n",
    "    z = np.ones((len(x),1))\n",
    "    new_d = np.hstack((x,z))\n",
    "    new_d = np.hstack((new_d,y))\n",
    "    learning_rate = 0.1\n",
    "    num_iter =100\n",
    "    m = gd(new_d,learning_rate,num_iter)\n",
    "    #print(m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no we need a predict fuction which pedicts the data by reading the values from test set\n",
    "def predict(points,m):\n",
    "    z = np.ones((len(points),1))\n",
    "    new_d = np.hstack((points,z))\n",
    "    y_pred = np.zeros(len(new_d))\n",
    "    for i in range(len(new_d)):\n",
    "        #y_pred[i]\n",
    "        for j in range(len(new_d[0])):\n",
    "            y_pred[i] += m[j]*new_d[i,j]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mrinal/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in double_scalars\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a5fe13892fde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-29c4a349bbbf>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mnum_iter\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;31m#print(m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-496f541d0017>\u001b[0m in \u001b[0;36mgd\u001b[0;34m(points, learning_rate, num_iter)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m#use cost function not for calculating gd but for getting yourself idea of which way code is going!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m#print(i,\"cost:\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"cost:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-1028e876e253>\u001b[0m in \u001b[0;36mcost\u001b[0;34m(points, m)\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mx_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mx_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mcostt\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcostt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "m = run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
