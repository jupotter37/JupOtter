{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/server/workspace/tensor_spv_zx/resnet.py:43: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\n",
      "\n",
      "WARNING:tensorflow:models/research/resnet is deprecated. Please use models/official/resnet instead.\n",
      "number gpu: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os, time\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from infolog import log\n",
    "from utils import ValueWindow\n",
    "\n",
    "from tensorflow.errors import OutOfRangeError\n",
    "from feeder_wav import Feeder\n",
    "from resnet import ResNet\n",
    "from vox12_hparams import train_feeder_hparams, dev_feeder_hparams, resnet_hparams, train_hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(fbanks, labels):\n",
    "    with tf.variable_scope('resnet', reuse=tf.AUTO_REUSE):\n",
    "        train_resnet = ResNet(resnet_hparams, fbanks, labels, 'train')\n",
    "        train_resnet.build_graph()\n",
    "    with tf.variable_scope('resnet', reuse=tf.AUTO_REUSE):\n",
    "        eval_resnet = ResNet(resnet_hparams, fbanks, labels, 'eval')\n",
    "        eval_resnet.build_graph()\n",
    "\n",
    "    return train_resnet, eval_resnet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_dir = 'vox12_aug_model_multi_gpu/'\n",
    "model_dir = 'vox12_model_multi_gpu_zc/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/server/workspace/tensor_spv_zx/resnet.py:67: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/server/workspace/tensor_spv_zx/resnet.py:90: The name tf.train.replica_device_setter is deprecated. Please use tf.compat.v1.train.replica_device_setter instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/server/workspace/tensor_spv_zx/resnet.py:398: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/server/workspace/tensor_spv_zx/resnet.py:270: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/server/workspace/tensor_spv_zx/resnet.py:346: The name tf.logging.debug is deprecated. Please use tf.compat.v1.logging.debug instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/server/anaconda3/envs/MultiSpeakerTTS/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py:507: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n",
      "WARNING:tensorflow:From /home/server/workspace/tensor_spv_zx/resnet.py:417: The name tf.nn.xw_plus_b is deprecated. Please use tf.compat.v1.nn.xw_plus_b instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/server/workspace/tensor_spv_zx/resnet.py:163: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/server/workspace/tensor_spv_zx/resnet.py:387: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/server/workspace/tensor_spv_zx/resnet.py:432: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/server/workspace/tensor_spv_zx/resnet.py:205: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/server/workspace/tensor_spv_zx/resnet.py:219: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/server/workspace/tensor_spv_zx/resnet.py:226: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/server/workspace/tensor_spv_zx/resnet.py:226: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/server/workspace/tensor_spv_zx/resnet.py:73: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    fbanks = tf.placeholder(dtype=tf.float32, shape=(None, None, 80), name='fbanks')\n",
    "    labels = tf.placeholder(dtype=tf.int32, shape=(None), name='labels')\n",
    "    _, resnet = create_model(fbanks, labels)\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(graph=graph, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "checkpoint_state = tf.train.get_checkpoint_state(model_dir)\n",
    "checkpoint_path = checkpoint_state.model_checkpoint_path\n",
    "# checkpoint_path = checkpoint_state.all_model_checkpoint_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from vox12_model_multi_gpu_zc/gvector.ckpt-300000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'vox12_model_multi_gpu_zc/gvector.ckpt-300000'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver.restore(sess, checkpoint_path)\n",
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel = np.load('/home/server/Real-Time-Voice-Cloning/datasets/vctk_clean/synthesizer/mels/mel-p260_321.wav.npy')\n",
    "gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mel, axis=0)})\n",
    "gv = gv.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.5762787e-06, -4.0531158e-06, -1.9073486e-06, -2.8610229e-06,\n",
       "        2.1457672e-06, -2.3841858e-06,  2.3841858e-06, -1.1920929e-06,\n",
       "        1.6689301e-06,  9.5367432e-07,  7.1525574e-07,  0.0000000e+00,\n",
       "        2.1457672e-06, -1.9073486e-06, -9.5367432e-07, -4.7683716e-07,\n",
       "        1.9073486e-06,  4.7683716e-07, -6.6757202e-06,  9.5367432e-07,\n",
       "        8.1062317e-06,  1.9073486e-06,  5.2452087e-06,  1.9073486e-06,\n",
       "        5.4836273e-06,  1.4305115e-06,  9.5367432e-07, -9.5367432e-07,\n",
       "        1.4305115e-06,  4.7683716e-06, -6.6757202e-06, -1.6689301e-06,\n",
       "        3.8146973e-06,  4.7683716e-07,  7.6293945e-06, -7.1525574e-07,\n",
       "        3.0994415e-06, -4.7683716e-07,  1.1920929e-07,  4.2915344e-06,\n",
       "       -2.8610229e-06,  2.2649765e-06,  4.7683716e-07,  1.4305115e-06,\n",
       "       -4.7683716e-07,  3.8146973e-06,  0.0000000e+00, -3.8146973e-06,\n",
       "        4.7683716e-06,  8.3446503e-07,  2.8610229e-06,  2.3841858e-07,\n",
       "        1.1920929e-06,  2.3841858e-06,  4.7683716e-07,  7.1525574e-07,\n",
       "        9.5367432e-07,  1.6689301e-06, -3.3378601e-06,  2.3841858e-06,\n",
       "       -5.2452087e-06,  3.3378601e-06,  2.3841858e-06,  4.0531158e-06,\n",
       "       -2.8610229e-06,  7.1525574e-07, -2.6226044e-06, -3.8146973e-06,\n",
       "       -1.4305115e-06, -4.0531158e-06, -9.5367432e-07, -4.7683716e-07,\n",
       "        2.8610229e-06, -1.3113022e-06, -3.5762787e-06, -1.4305115e-06,\n",
       "       -4.7683716e-07, -1.6689301e-06,  2.3841858e-07,  3.3378601e-06,\n",
       "       -1.9073486e-06, -1.9073486e-06,  9.5367432e-07,  4.7683716e-07,\n",
       "        1.4305115e-06, -1.4305115e-06, -4.7683716e-06, -1.1920929e-06,\n",
       "       -4.7683716e-07,  0.0000000e+00,  2.3841858e-06, -1.3113022e-06,\n",
       "       -2.8610229e-06, -1.9073486e-06, -9.5367432e-07, -2.1457672e-06,\n",
       "       -4.2915344e-06,  4.2915344e-06, -2.3841858e-06, -6.6757202e-06,\n",
       "        9.5367432e-07, -4.7683716e-07,  1.9073486e-06, -7.3909760e-06,\n",
       "        2.8610229e-06, -4.7683716e-07,  9.5367432e-07,  2.3841858e-06,\n",
       "        4.7683716e-06, -3.5762787e-06, -1.4305115e-06, -5.9604645e-07,\n",
       "        0.0000000e+00, -4.7683716e-07,  2.3841858e-06,  3.8146973e-06,\n",
       "        0.0000000e+00,  4.2915344e-06, -4.7683716e-07,  0.0000000e+00,\n",
       "       -4.7683716e-06,  9.5367432e-07, -2.3841858e-06, -4.7683716e-07,\n",
       "        9.5367432e-07,  2.1457672e-06, -1.9073486e-06, -4.5299530e-06,\n",
       "        5.9604645e-07,  0.0000000e+00,  4.7683716e-06, -4.5299530e-06,\n",
       "        9.5367432e-07, -2.8610229e-06, -1.1324883e-06,  4.2915344e-06,\n",
       "       -3.8146973e-06,  2.3841858e-06, -1.6689301e-06,  2.8610229e-06,\n",
       "        2.8610229e-06,  4.7683716e-07,  1.6689301e-06, -9.5367432e-07,\n",
       "       -2.3841858e-06,  9.5367432e-07,  1.0728836e-06, -3.8146973e-06,\n",
       "        0.0000000e+00,  0.0000000e+00, -1.4305115e-06, -5.0067902e-06,\n",
       "        3.3378601e-06, -9.5367432e-07,  4.3511391e-06,  4.1127205e-06,\n",
       "        1.3113022e-06, -9.5367432e-07, -1.9073486e-06,  6.1988831e-06,\n",
       "        5.3644180e-07, -3.8146973e-06,  4.7683716e-07,  1.4305115e-06,\n",
       "       -2.8610229e-06,  4.7683716e-07, -1.9073486e-06, -2.3841858e-06,\n",
       "       -1.4305115e-06, -3.4570694e-06, -3.3378601e-06, -1.9073486e-06,\n",
       "        9.5367432e-07,  0.0000000e+00,  2.8610229e-06,  4.2915344e-06,\n",
       "        0.0000000e+00,  1.9073486e-06,  0.0000000e+00, -2.8610229e-06,\n",
       "       -4.2915344e-06,  1.4305115e-06, -2.9206276e-06, -4.5299530e-06,\n",
       "        1.3113022e-06,  0.0000000e+00,  3.3378601e-06, -2.6226044e-06,\n",
       "        1.4305115e-06,  9.5367432e-07,  1.9073486e-06,  1.4305115e-06,\n",
       "        4.2915344e-06, -8.3446503e-07,  5.0067902e-06,  3.8146973e-06,\n",
       "       -1.4901161e-06,  4.7683716e-07, -2.3841858e-06,  7.1525574e-07,\n",
       "        3.5762787e-07,  2.8610229e-06,  3.5762787e-06,  1.4305115e-06,\n",
       "        3.3378601e-06, -3.8146973e-06, -9.5367432e-07,  2.8610229e-06,\n",
       "        2.8610229e-06,  2.3841858e-06,  0.0000000e+00,  1.9073486e-06,\n",
       "       -2.6226044e-06,  4.0531158e-06, -2.3841858e-06,  9.5367432e-07,\n",
       "        2.3841858e-06, -9.5367432e-07,  1.4305115e-06, -9.5367432e-07,\n",
       "        0.0000000e+00,  4.2915344e-06,  4.1723251e-06, -4.5299530e-06,\n",
       "       -1.4305115e-06, -2.3841858e-07,  9.5367432e-07,  5.2452087e-06,\n",
       "        4.7683716e-07,  1.3113022e-06,  4.7683716e-07, -1.4305115e-06,\n",
       "        1.9073486e-06,  1.1920929e-06, -2.8610229e-06,  4.7683716e-06,\n",
       "       -2.3841858e-06,  9.5367432e-07,  9.5367432e-07, -7.7486038e-07,\n",
       "       -9.5367432e-07,  7.1525574e-07, -5.7220459e-06, -9.5367432e-07,\n",
       "       -1.9073486e-06, -5.6028366e-06, -9.5367432e-07, -4.7683716e-07,\n",
       "        3.3378601e-06,  2.2649765e-06,  1.1920929e-06,  9.5367432e-07,\n",
       "        3.8146973e-06, -5.3644180e-07,  8.3446503e-07, -4.2915344e-06],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed = np.load('/home/server/Real-Time-Voice-Cloning/datasets/vctk_clean/synthesizer/embeds/embed-p260_321.wav.npy')\n",
    "gv - embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mel spc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_vox12/vctk.csv') as fid:\n",
    "    cont = fid.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(mels, num_frames):\n",
    "    while len(mels) < num_frames:\n",
    "        mels = np.concatenate([mels, mels[:num_frames-len(mels)]])\n",
    "    return mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "embed_dir = '/home/server/Real-Time-Voice-Cloning/datasets/vctk_clean_all/synthesizer/embed_gvector3/'\n",
    "\n",
    "for line in tqdm(cont):\n",
    "    mel_file = line.strip()\n",
    "    name = mel_file.split('/')[-1].replace('mel', 'embed')\n",
    "    name = embed_dir + name\n",
    "    mels = np.load(mel_file)\n",
    "    #mels = expand(mels, 400)\n",
    "    gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "    gv = gv.squeeze()\n",
    "    np.save(name, gv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_vox12/test.csv') as fid:\n",
    "    cont = fid.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import audio\n",
    "from hparams import hparams as audio_hparams\n",
    "import random\n",
    "def get_spc(wav, num_frames):\n",
    "    wav = audio.load_wav(wav_file, sr=audio_hparams.sample_rate)\n",
    "    if audio_hparams.trim_silence:\n",
    "        wav = audio.trim_silence(wav, audio_hparams)\n",
    "    \n",
    "    expect_len =  num_frames * audio_hparams.hop_size + audio_hparams.win_size\n",
    "    if len(wav) < expect_len:\n",
    "        wav = np.concatenate([wav] * np.math.ceil(expect_len / len(wav)))\n",
    "    \n",
    "#     if len(wav) > expect_len:\n",
    "#         sp = random.randint(0, len(wav)-expect_len)\n",
    "#         wav = wav[sp: sp+expect_len]\n",
    "        \n",
    "    wav = audio.preemphasis(wav, audio_hparams.preemphasis, audio_hparams.preemphasize)\n",
    "    \n",
    "    if audio_hparams.rescale:\n",
    "        wav = wav / np.abs(wav).max() * audio_hparams.rescaling_max\n",
    "        \n",
    "    mels = audio.melspectrogram(wav, audio_hparams).astype(np.float32).T\n",
    "    return mels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "gvectors = dict()\n",
    "for line in tqdm(cont):\n",
    "    spkid, wav_file = line.strip().split()\n",
    "    mels = get_spc(wav_file, 400)\n",
    "    gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "    if spkid not in gvectors:\n",
    "        gvectors[spkid] = dict()\n",
    "    \n",
    "    uttid = '-'.join(wav_file.split('/')[-3:]).replace('.wav', '')\n",
    "    gvectors[spkid][uttid] = gv\n",
    "\n",
    "np.savez('WCHdata/gvector.npz', **gvectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd WCHdata && python cal_trials.py && cd -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get gvector for vctk_clean without jointlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "save_dir = '/home/server/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-vctk_clean_gvector3/syn_gvectors/'\n",
    "mel_dir = '/home/server/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-vctk_clean_gvector3/syn_mels/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open('/home/server/Real-Time-Voice-Cloning/datasets/vctk_clean/synthesizer/test.txt') as testfile:\n",
    "#with open('/home/server/Real-Time-Voice-Cloning/datasets/vctk_clean/synthesizer/val.txt') as testfile:\n",
    "    for line in testfile.readlines():\n",
    "        items = line.strip().split('|')\n",
    "        pairs.append((mel_dir + items[1], save_dir + items[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mel_file, embed_file in tqdm(pairs):\n",
    "    try:\n",
    "        mels = np.load(mel_file).T\n",
    "        gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "        gv = gv.squeeze()\n",
    "        np.save(embed_file, gv)\n",
    "    except:\n",
    "        print('file not found: ', mel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get gvector for vctk_clean with jointlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'logs-vctk_gvector3_scale_1_cos'\n",
    "pairs = []\n",
    "save_dir = '/home/server/Real-Time-Voice-Cloning/synthesizer_with_encoder/saved_models/' + dir_name + '/syn_gvectors/'\n",
    "mel_dir = '/home/server/Real-Time-Voice-Cloning/synthesizer_with_encoder/saved_models/' + dir_name + '/syn_mels/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open('/home/server/Real-Time-Voice-Cloning/datasets/vctk_clean/synthesizer/test.txt') as testfile:\n",
    "#with open('/home/server/Real-Time-Voice-Cloning/datasets/vctk_clean/synthesizer/val.txt') as testfile:\n",
    "    for line in testfile.readlines():\n",
    "        items = line.strip().split('|')\n",
    "        pairs.append((mel_dir + items[1], save_dir + items[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mel_file, embed_file in tqdm(pairs):\n",
    "    try:\n",
    "        mels = np.load(mel_file).T\n",
    "        gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "        gv = gv.squeeze()\n",
    "        np.save(embed_file, gv)\n",
    "    except:\n",
    "        print('file not found: ', mel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For embedding extration from wav using different embedding from the same speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## get gvector for vctk_clean without jointlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "save_dir = '/home/server/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-vctk_clean_gvector3/syn_rande_gvectors/'\n",
    "mel_dir = '/home/server/Real-Time-Voice-Cloning/synthesizer/saved_models/logs-vctk_clean_gvector3/syn_rande_mels/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open('/home/server/Real-Time-Voice-Cloning/datasets/vctk_clean/synthesizer/test.txt') as testfile:\n",
    "#with open('/home/server/Real-Time-Voice-Cloning/datasets/vctk_clean/synthesizer/val.txt') as testfile:\n",
    "    for line in testfile.readlines():\n",
    "        items = line.strip().split('|')\n",
    "        pairs.append((mel_dir + items[1], save_dir + items[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mel_file, embed_file in tqdm(pairs):\n",
    "    try:\n",
    "        mels = np.load(mel_file).T\n",
    "        gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "        gv = gv.squeeze()\n",
    "        np.save(embed_file, gv)\n",
    "    except:\n",
    "        print('file not found: ', mel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get gvector for vctk_clean with jointlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_name = 'logs-vctk_gvector3_scale_1_cos'\n",
    "pairs = []\n",
    "save_dir = '/home/server/Real-Time-Voice-Cloning/synthesizer_with_encoder/saved_models/' + dir_name + '/syn_rande_gvectors/'\n",
    "mel_dir = '/home/server/Real-Time-Voice-Cloning/synthesizer_with_encoder/saved_models/' + dir_name + '/syn_rande_mels/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open('/home/server/Real-Time-Voice-Cloning/datasets/vctk_clean/synthesizer/test.txt') as testfile:\n",
    "#with open('/home/server/Real-Time-Voice-Cloning/datasets/vctk_clean/synthesizer/val.txt') as testfile:\n",
    "    for line in testfile.readlines():\n",
    "        items = line.strip().split('|')\n",
    "        pairs.append((mel_dir + items[1], save_dir + items[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mel_file, embed_file in tqdm(pairs):\n",
    "    try:\n",
    "        mels = np.load(mel_file).T\n",
    "        gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "        gv = gv.squeeze()\n",
    "        np.save(embed_file, gv)\n",
    "    except:\n",
    "        print('file not found: ', mel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get gvector for librispeech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "save_dir = '/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/embeds_gvector/'\n",
    "mel_dir = '/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/mels/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open('/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/test.txt') as testfile:\n",
    "    for line in testfile.readlines():\n",
    "        items = line.strip().split('|')\n",
    "        pairs.append((mel_dir + items[1], save_dir + items[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mel_file, embed_file in tqdm(pairs):\n",
    "    try:\n",
    "        mels = np.load(mel_file)\n",
    "        gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "        gv = gv.squeeze()\n",
    "        np.save(embed_file, gv)\n",
    "    except e:\n",
    "        print(e)\n",
    "        #print('file not found: ', mel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get gvector for librispeech without joinlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "save_dir = '/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/syn_gvector/'\n",
    "mel_dir = '/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/syn_mels/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open('/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/test.txt') as testfile:\n",
    "    for line in testfile.readlines():\n",
    "        items = line.strip().split('|')\n",
    "        pairs.append((mel_dir + items[1], save_dir + items[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mel_file, embed_file in tqdm(pairs):\n",
    "    try:\n",
    "        mels = np.load(mel_file).T\n",
    "        gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "        gv = gv.squeeze()\n",
    "        np.save(embed_file, gv)\n",
    "    except e:\n",
    "        print(e)\n",
    "        #print('file not found: ', mel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get gvector for librispeech with joinlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "save_dir = '/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/syn_gvector_nj/'\n",
    "mel_dir = '/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/syn_mels_nj/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open('/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/test.txt') as testfile:\n",
    "    for line in testfile.readlines():\n",
    "        items = line.strip().split('|')\n",
    "        pairs.append((mel_dir + items[1], save_dir + items[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mel_file, embed_file in tqdm(pairs):\n",
    "    try:\n",
    "        mels = np.load(mel_file).T\n",
    "        gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "        gv = gv.squeeze()\n",
    "        np.save(embed_file, gv)\n",
    "    except e:\n",
    "        print(e)\n",
    "        #print('file not found: ', mel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get gvector for librispeech with joinlearning random embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "save_dir = '/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/syn_gvector_rande/'\n",
    "mel_dir = '/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/syn_rande_mels/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open('/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/test.txt') as testfile:\n",
    "    for line in testfile.readlines():\n",
    "        items = line.strip().split('|')\n",
    "        pairs.append((mel_dir + items[1], save_dir + items[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mel_file, embed_file in tqdm(pairs):\n",
    "    try:\n",
    "        mels = np.load(mel_file).T\n",
    "        gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "        gv = gv.squeeze()\n",
    "        np.save(embed_file, gv)\n",
    "    except e:\n",
    "        print(e)\n",
    "        #print('file not found: ', mel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get gvector for librispeech without joinlearning random embedding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "save_dir = '/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/syn_gvector_rande_nj/'\n",
    "mel_dir = '/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/syn_rande_mels_nj/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open('/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/test.txt') as testfile:\n",
    "    for line in testfile.readlines():\n",
    "        items = line.strip().split('|')\n",
    "        pairs.append((mel_dir + items[1], save_dir + items[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mel_file, embed_file in tqdm(pairs):\n",
    "    try:\n",
    "        mels = np.load(mel_file).T\n",
    "        gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "        gv = gv.squeeze()\n",
    "        np.save(embed_file, gv)\n",
    "    except e:\n",
    "        print(e)\n",
    "        #print('file not found: ', mel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get gvector for vcc2018 and vcc2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "save_dir = '/home/server/workspace/vcc2020/data/vcc_synthesizer/embeds/'\n",
    "mel_dir = '/home/server/workspace/vcc2020/data/vcc_synthesizer/mels/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open('/home/server/workspace/vcc2020/data/vcc_synthesizer/train.txt') as testfile:\n",
    "    for line in testfile.readlines():\n",
    "        items = line.strip().split('|')\n",
    "        pairs.append((mel_dir + items[1], save_dir + items[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mel_file, embed_file in tqdm(pairs):\n",
    "    try:\n",
    "        mels = np.load(mel_file)\n",
    "        gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "        gv = gv.squeeze()\n",
    "        np.save(embed_file, gv)\n",
    "    except e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "save_dir = '/home/server/workspace/vcc2020/data/vctk_syn_embeds/'\n",
    "mel_dir = '/home/server/workspace/vcc2020/data/vctk_syn_mels/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open('/home/server/workspace/vcc2020/data/syn_mels_list.txt') as testfile:\n",
    "    for line in testfile.readlines():\n",
    "        utt = line.strip()\n",
    "        pairs.append((mel_dir + utt, save_dir + utt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mel_file, embed_file in tqdm(pairs):\n",
    "    try:\n",
    "        mels = np.load(mel_file).T\n",
    "        gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "        gv = gv.squeeze()\n",
    "        np.save(embed_file, gv)\n",
    "    except e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utts = [line.strip().split('|')[2] for line in open('/home/server/workspace/vcc2020/data/vctk_intracross_syn/syn_metadata.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '/home/server/workspace/vcc2020/data/vctk_intracross_syn/gvectors/'\n",
    "mel_dir = '/home/server/workspace/vcc2020/data/vctk_intracross_syn/mels/'\n",
    "\n",
    "for file in tqdm(utts):\n",
    "    try:\n",
    "        mels = np.load(mel_dir + file).T\n",
    "        gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "        gv = gv.squeeze()\n",
    "        np.save(save_dir + file, gv)\n",
    "    except e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get gvector for librispeech all speakers \n",
    "## select one utt per speaker randomly, used for VCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "save_dir = '/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/embeds_gvector/'\n",
    "mel_dir = '/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/mels/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open('/home/server/Real-Time-Voice-Cloning/datasets/LibriSpeech/synthesizer/vcc_mel2embed.txt') as testfile:\n",
    "    for line in testfile.readlines():\n",
    "        items = line.strip().split('|')\n",
    "        pairs.append((mel_dir + items[0], save_dir + items[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mel_file, embed_file in tqdm(pairs):\n",
    "    try:\n",
    "        mels = np.load(mel_file)\n",
    "        gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "        gv = gv.squeeze()\n",
    "        np.save(embed_file, gv)\n",
    "    except e:\n",
    "        print(e)\n",
    "        #print('file not found: ', mel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get gvector for Timit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "save_dir = '/home/server/workspace/vcc2020/TIMIT/synthesizer/gvectors/'\n",
    "mel_dir = '/home/server/workspace/vcc2020/TIMIT/synthesizer/mels/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open('/home/server/workspace/vcc2020/TIMIT/synthesizer/train.txt') as testfile:\n",
    "    for line in testfile.readlines():\n",
    "        items = line.strip().split('|')\n",
    "        pairs.append((mel_dir + items[1], save_dir + items[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mel_file, embed_file in tqdm(pairs):\n",
    "    try:\n",
    "        mels = np.load(mel_file)\n",
    "        gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "        gv = gv.squeeze()\n",
    "        np.save(embed_file, gv)\n",
    "    except e:\n",
    "        print(e)\n",
    "        #print('file not found: ', mel_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get gvector for aishell ssb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/server/Real-Time-Voice-Cloning/temp/ssb_syn_mels/feature.meta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c31e40c61470>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmel_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/server/Real-Time-Voice-Cloning/temp/ssb_syn_mels/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/server/Real-Time-Voice-Cloning/temp/ssb_syn_mels/feature.meta'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtestfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtestfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/server/Real-Time-Voice-Cloning/temp/ssb_syn_mels/feature.meta'"
     ]
    }
   ],
   "source": [
    "pairs = []\n",
    "save_dir = '/home/server/Real-Time-Voice-Cloning/temp/ssb_syn_mels/embeds/'\n",
    "mel_dir = '/home/server/Real-Time-Voice-Cloning/temp/ssb_syn_mels/mels/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open('/home/server/Real-Time-Voice-Cloning/temp/ssb_syn_mels/train.txt') as testfile:\n",
    "    for line in testfile.readlines():\n",
    "        items = line.strip().split('|')\n",
    "        pairs.append((mel_dir + items[1], save_dir + items[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mel_file, embed_file in tqdm(pairs):\n",
    "    try:\n",
    "        mels = np.load(mel_file)\n",
    "        gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "        gv = gv.squeeze()\n",
    "        np.save(embed_file, gv)\n",
    "    except e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get gvector for vox2 dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "save_dir = '/home/server/Real-Time-Voice-Cloning/temp/vox2_dev_syn/embeds/'\n",
    "mel_dir = '/home/server/Real-Time-Voice-Cloning/temp/vox2_dev_syn/'\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "with open('/home/server/Real-Time-Voice-Cloning/temp/vox2_dev_syn/feature.meta') as testfile:\n",
    "    for line in testfile.readlines():\n",
    "        items = line.strip().split('|')\n",
    "        pairs.append((mel_dir + items[1], save_dir + items[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 5802/5994 [02:15<00:03, 63.93it/s]"
     ]
    }
   ],
   "source": [
    "for mel_file, embed_file in tqdm(pairs):\n",
    "    try:\n",
    "        mels = np.load(mel_file)\n",
    "        gv = sess.run(resnet.gv, feed_dict={fbanks: np.expand_dims(mels, axis=0)})\n",
    "        gv = gv.squeeze()\n",
    "        np.save(embed_file, gv)\n",
    "    except e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fbanks.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_file = 'gvector.pb'\n",
    "graph_def = tf.graph_util.convert_variables_to_constants(sess, \n",
    "                                                        graph.as_graph_def(), \n",
    "                                                        output_node_names=[resnet.gv.op.name])\n",
    "\n",
    "with tf.gfile.GFile(pb_file, 'wb') as fid:\n",
    "    fid.write(graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_n = tf.Graph()\n",
    "with tf.gfile.GFile(pb_file, 'rb') as fid:\n",
    "    graph_def_n = graph_n.as_graph_def()\n",
    "    graph_def_n.ParseFromString(fid.read())\n",
    "    \n",
    "with graph_n.as_default():\n",
    "    tf.import_graph_def(graph_def_n, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_n.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gv = graph_n.get_tensor_by_name('vector_1/xw_plus_b:0')\n",
    "fbanks_n = graph_n.get_tensor_by_name('fbanks:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(graph = graph_n) as sess_n:\n",
    "    print(sess_n.run(gv, feed_dict={fbanks_n: np.ones((1, 400, 80), dtype=np.float32)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python MultiSpeakerTTS",
   "language": "python",
   "name": "multispeakertts"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
