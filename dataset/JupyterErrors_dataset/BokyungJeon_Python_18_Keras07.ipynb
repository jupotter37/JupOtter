{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "img_np = np.ones([5, 5])\n",
    "\n",
    "print(img_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0  1]\n"
     ]
    }
   ],
   "source": [
    "kernel = np.array([-1, 0, 1])\n",
    "\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# 디지털 신호처리의 FIR필터를 공부해보면 좋음\n",
    "\n",
    "# cv는 OpenCV라는 C++로 작성된 라이브러리를 python으로 가져다 사용하기 때문에 python의 행렬 정보를 OpenCV용으로 변환할 필요가 있음\n",
    "# cv2.resize 목적: 타입 컨버팅\n",
    "img_cv = cv2.resize(img_np, (5, 5))\n",
    "\n",
    "print(img_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1]\n",
      " [ 0]\n",
      " [ 1]]\n"
     ]
    }
   ],
   "source": [
    "kernel = cv2.resize(kernel, (1, 3))\n",
    "\n",
    "print(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 2. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 1. 1. 3.]]\n"
     ]
    }
   ],
   "source": [
    "img_cv[0][0] = 0\n",
    "img_cv[2][2] = 2\n",
    "img_cv[4][4] = 3\n",
    "\n",
    "print(img_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  2.]\n",
      " [ 0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# cv2.fliter2D 컨벌루션이 라플라스 변환과 푸리에 변환이랑 관련이 있다.\n",
    "# 푸리에 변환(주파수 영역으로 변환)이 완료된 두 함수의 곱은 시간 영역에서 컨벌루션과 동일하다.\n",
    "# (증명: 자코비안 행렬과 라플라스 변환이 필요함)\n",
    "# 위의 내용은 FIR필터의 가장 기본 근간이 됨\n",
    "#                                앵커\n",
    "conv_test = cv2.filter2D(img_cv, -1, kernel)\n",
    "\n",
    "print(conv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "# copy.deepcopy() 하는 이유\n",
    "# C++관점에서 포인터를 공유하는 상황이 될 수 있어 malloc을 통해 해결하는 것과 같다.\n",
    "# 자바관점에서 객체를 공유하는 상황이 될 수 있어 new를 통해 해결하는 것과 같다.\n",
    "def filter_2d(input_img, kernel):\n",
    "    input_img = copy.deepcopy(input_img)\n",
    "    output_img = copy.deepcopy(input_img)\n",
    "    # 상용화시 이렇게 딥카피를 두번하는 건 하면 안되지만 이미지를 보려고 하는 것이기 때문에 그냥 함\n",
    "    \n",
    "    print('input_img.shape[0]:', input_img.shape[0])\n",
    "    print('input_img.shape[1]:', input_img.shape[1])\n",
    "    \n",
    "    # 연산을 올바르게 하고 있는가 확인 필요\n",
    "    # 사실 5개정도는 for문보다는 바로 확인이 좋다. 파이프라인이 깨지기 때문\n",
    "    # for i in range(input_img.shape[0]):\n",
    "    #    print(input_img[i])\n",
    "        \n",
    "    # 컨벌루션 연산이 적용되는 대상은 이미지이다.\n",
    "    # 이미지 -> (다차원)행렬\n",
    "    for row in range(input_img.shape[0]):\n",
    "        \n",
    "        output_img[row][0] = input_img[row][1] * kernel[0] + \\\n",
    "                        input_img[row][0] * kernel[1] + \\\n",
    "                        input_img[row][1] * kernel[2]\n",
    "        \n",
    "        for col in range(1, input_img.shape[1] -1):\n",
    "            output_img[row][col] = input_img[row][col -1] + kernel[0] +\\\n",
    "                                input_img[row][col] * kernel[1] + \\\n",
    "                                input_img[row][col + 1] * kernel[2]\n",
    "            \n",
    "        output_img[row][input_img.shape[1] - 1] = \\\n",
    "            input_img[row][input_img.shape[1] - 2] * kernel[0] + \\\n",
    "            input_img[row][input_img.shape[1] - 1] * kernel[1] + \\\n",
    "            input_img[row][input_img.shape[1] - 2] * kernel[2]\n",
    "            \n",
    "    return output_img.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_img.shape[0]: 5\n",
      "input_img.shape[1]: 5\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 1. 2. 1. 1.]\n",
      " [1. 1. 1. 1. 1.]\n",
      " [1. 1. 2. 1. 3.]\n",
      " [0. 0. 0. 0. 0.]]\n",
      "[[ True  True  True  True  True]\n",
      " [False False False False False]\n",
      " [False False False False False]\n",
      " [False False False False False]\n",
      " [ True  True  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "conv_img = filter_2d(img_cv, kernel)\n",
    "conv_img2 = cv2.filter2D(img_cv, -1, kernel)\n",
    "\n",
    "print(conv_img)\n",
    "print(conv_img == conv_img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Microsoft의 FPGA: 하드웨어를 소프트웨어로 변형 가능. 삼성 메모리 반도체에도 이용됨."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "suitImg = image.load_img(\"suit.jpg\", target_size=(224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "transformed_img = image.img_to_array(suitImg)\n",
    "print(transformed_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformed_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-f731f10e2578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformed_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transformed_image' is not defined"
     ]
    }
   ],
   "source": [
    "transformed_img = np.expand_dims(transformed_image, axis = 0)\n",
    "print(transformed_img.shape)\n",
    "print(transformed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_img = preprocess_input(transformed_img)\n",
    "print(transformed_img.shape)\n",
    "print(transformed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = classifier.predict(transformed_img)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = decode_predictions(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%s (%.2f%%)' % (label[0][0][1], label[0][0][2] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%s (%.2f%%)' % (label[0][1][1], label[0][1][2] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%s (%.2f%%)' % (label[0][2][1], label[0][2][2] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('top 5!')\n",
    "\n",
    "for i in range(5):\n",
    "    print('%16s (%.2f%%)' % (label[0][i][1], label[0][i][2] * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
