{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/enis/projects/nna/src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('../../src'))\n",
    "print(module_path)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from models_api import classicML\n",
    "\n",
    "\n",
    "# Torch Model \n",
    "\n",
    "import torch\n",
    "import exp.modelArchs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### example of running on a file and save it\n",
    "\n",
    "# filename=\"/scratch/enis/data/nna/real/ivvavik/SINP01/2019/SINP-01_20190516_033000_vgg/SINP-01_20190516_033000_rawembeddings000.npy\"\n",
    "# modelPath=\"/home/enis/projects/nna/src/assets/sklearnModels/Wind_Neural Net_Raw_many2one_2020-03-02--14-06.joblib\"\n",
    "\n",
    "# model=classicML(modelPath)\n",
    "# load a file and then save to correct place \n",
    "# model.classify_file(filename,\"_Insect\",saveAsFile=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### example of running on a numpy array in memory\n",
    "# import numpy as np\n",
    "# results_file_path='/scratch/enis/data/nna/real/ivvavik/SINP01/2019/SINP-01_20190516_033000_Insect/SINP-01_20190516_033000_Insect000.npy'\n",
    "# results=np.load(results_file_path)\n",
    "\n",
    "# raw_embeddings = np.load(filename)\n",
    "# classified = model.classify_embeddings(raw_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorized_y_true(humanresults,tag_set):\n",
    "    y_true={tag: [None]*len(humanresults) for tag in tag_set}\n",
    "    for i,tags in enumerate(humanresults.values()):\n",
    "        # we  only look for tags in tag_set\n",
    "        for tag in tag_set:\n",
    "            if tag in tags:\n",
    "                y_true[tag][i] = 1\n",
    "            else:\n",
    "                y_true[tag][i] = 0 \n",
    "    return y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique files: 757 \n",
      "total files 797\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from pathlib import Path\n",
    "import csv\n",
    "\n",
    "# LOAD LABELS by human\n",
    "labelsbyhumanpath=Path('/scratch/enis/data/nna/labeling/resultsReal/')\n",
    "# filter by username\n",
    "labelsbyhuman=[i for i in listdir(labelsbyhumanpath) if (\".csv\" in i) ]\n",
    "\n",
    "humanresults={}\n",
    "counter=0\n",
    "for apath in labelsbyhuman:\n",
    "    with open(labelsbyhumanpath / apath, newline='') as f:\n",
    "        reader=csv.reader(f)\n",
    "        for row in reader:\n",
    "            counter+=1\n",
    "            humanresults[row[0]]=row[1:]\n",
    "\n",
    "print(\"unique files:\",len(humanresults),\"\\ntotal files\",counter)\n",
    "\n",
    "humanresultsAll=humanresults.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "humanresultsSlim={}\n",
    "humanresultsClipping={}\n",
    "for k in humanresultsAll:\n",
    "    val=humanresultsAll[k]\n",
    "#     print(val)\n",
    "    val2=[i.lower().replace(\"+\",\"\") for i in val ]\n",
    "    val2=[i.lower().replace(\"+\",\"\") for i in val2 if i not in [\"clipping\",\"wind\"]]\n",
    "    if len(val2)>0:\n",
    "#         print(val)\n",
    "        humanresultsSlim[k]=val\n",
    "    else:\n",
    "        humanresultsClipping[k]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aircraft_AdaBoost_Raw_Average_2020-03-02--14-06.joblib\n",
      "Cable_Gaussian Process_Raw_Concat_2020-03-02--14-06.joblib\n",
      "Insect_Linear SVM_Raw_Concat_2020-03-02--14-06.joblib\n",
      "Rain_Gaussian Process_Raw_Concat_2020-03-02--14-06.joblib\n",
      "Running Water_Neural Net_Raw_Concat_2020-03-02--14-06.joblib\n",
      "Songbird_Neural Net_Raw_many2one_2020-03-02--14-06.joblib\n",
      "Water Bird_RBF SVM_Raw_many2one_2020-03-02--14-06.joblib\n",
      "Wind_Neural Net_Raw_many2one_2020-03-02--14-06.joblib\n"
     ]
    }
   ],
   "source": [
    "modelsPath=\"/home/enis/projects/nna/src/assets/sklearnModels/\"\n",
    "!ls /home/enis/projects/nna/src/assets/sklearnModels/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'modelsPath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0d9f31f51dc6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m Wind_Neural Net_Raw_many2one_2020-03-02--14-06.joblib\"\"\"\n\u001b[1;32m      9\u001b[0m \u001b[0mtagNames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodelList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodelList\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelsPath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodelList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-0d9f31f51dc6>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      8\u001b[0m Wind_Neural Net_Raw_many2one_2020-03-02--14-06.joblib\"\"\"\n\u001b[1;32m      9\u001b[0m \u001b[0mtagNames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodelList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodelList\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodelsPath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodelList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'modelsPath' is not defined"
     ]
    }
   ],
   "source": [
    "modelList=\"\"\"Aircraft_AdaBoost_Raw_Average_2020-03-02--14-06.joblib\n",
    "Cable_Gaussian Process_Raw_Concat_2020-03-02--14-06.joblib\n",
    "Insect_Linear SVM_Raw_Concat_2020-03-02--14-06.joblib\n",
    "Rain_Gaussian Process_Raw_Concat_2020-03-02--14-06.joblib\n",
    "Running Water_Neural Net_Raw_Concat_2020-03-02--14-06.joblib\n",
    "Songbird_Neural Net_Raw_many2one_2020-03-02--14-06.joblib\n",
    "Water Bird_RBF SVM_Raw_many2one_2020-03-02--14-06.joblib\n",
    "Wind_Neural Net_Raw_many2one_2020-03-02--14-06.joblib\"\"\"\n",
    "tagNames=[i.split(\"_\")[0] for i in modelList.split(\"\\n\")]\n",
    "modelList=[modelsPath+i for i in modelList.split(\"\\n\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    }
   ],
   "source": [
    "#select the files to process\n",
    "# humanresults=humanresultsAll.copy()\n",
    "humanresults=humanresultsSlim.copy()\n",
    "# humanresults=humanresultsClipping.copy()\n",
    "\n",
    "print(len(humanresults))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data for ClassicMLModel\n",
    "results={i:[] for i in tagNames}\n",
    "for tagName,modelPath in zip(tagNames,modelList):\n",
    "    model=classicML(modelPath,predictProbFlag=True)\n",
    "    for k in humanresults:\n",
    "        file_name=k.replace(\".flac\",\"_rawembed.npy\")\n",
    "        filepath=\"/scratch/enis/data/nna/labeling/split_real_embeddings/\"+file_name\n",
    "        raw_embeddings = np.load(filepath)\n",
    "        classified = model.classify_embeddings(raw_embeddings)\n",
    "        results[tagName].append(classified[0])\n",
    "\n",
    "tagSet=[\"Songbird\",\"Water Bird\",\"Insect\",\"Running Water\",\"Rain\",\"Cable\",\"Wind\",\"Aircraft\"]\n",
    "\n",
    "y_true_dict=vectorized_y_true(humanresults,tagSet)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# humanresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NetCNN1(\n",
       "  (conv1): Conv2d(1, 45, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=1224000, out_features=10, bias=True)\n",
       "  (fc1_bn): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (fc2_bn): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (fc3_bn): BatchNorm1d(5, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc4): Linear(in_features=10, out_features=8, bias=True)\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelPath=\"/home/enis/projects/nna/src/exp/wandb/run-20200722_055604-2yqh4nns/best_model_84_ROC_AUC=0.7935.pt\"\n",
    "modelPath=\"/home/enis/projects/nna/src/exp/wandb/run-20200723_180356-18s086k5/best_model_79_ROC_AUC=0.7362.pt\"\n",
    "model = exp.modelArchs.NetCNN1(45,[128,850],(3,3)).float()\n",
    "model.load_state_dict(torch.load(modelPath))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "\n",
    "tagSet=[\"Songbird\",\"Water Bird\",\"Insect\",\"Running Water\",\"Rain\",\"Cable\",\"Wind\",\"Aircraft\"]\n",
    "\n",
    "y_true_dict = vectorized_y_true(humanresults,tagSet)\n",
    "y_true_all = pd.DataFrame(y_true_dict)\n",
    "y_true = np.array(y_true_all).astype(\"float\")\n",
    "\n",
    "\n",
    "\n",
    "maxLen=850\n",
    "res=[]\n",
    "for k in humanresults:\n",
    "    filepath=\"/scratch/enis/data/nna/labeling/splits_real/\"+k\n",
    "    x,sr=librosa.load(filepath,sr=None)\n",
    "    mel = librosa.feature.melspectrogram(y=x.reshape(-1), sr=44100)\n",
    "    an_x = librosa.power_to_db(mel, ref=np.max)\n",
    "    an_x = an_x.astype(\"float32\")\n",
    "#     if an_x.shape[1]!=938:\n",
    "#         print((k,an_x.shape))\n",
    "#     res.append((k,an_x.shape))\n",
    "    an_x = an_x[:,:maxLen]\n",
    "    x = an_x.reshape(1,1,*an_x.shape[:])\n",
    "   \n",
    "    out = model(torch.Tensor(x))\n",
    "    out = torch.sigmoid(out)\n",
    "    out = out.detach().numpy()[0]\n",
    "#     print(out.value())\n",
    "    res.append(out)\n",
    "#     break\n",
    "res=np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true[0][5]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([282., 127.,  18.,  19.,  64.,   1., 208.,  28.])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.545026809475398\n",
      "Songbird\n",
      "0.3693052049525183\n",
      "Water Bird\n",
      "0.5565025525655447\n",
      "Insect\n",
      "0.7248400232693426\n",
      "Running Water\n",
      "0.7121149330017958\n",
      "Rain\n",
      "0.5638020833333333\n",
      "Cable\n",
      "0.03759398496240607\n",
      "Wind\n",
      "0.7651993189102564\n",
      "Aircraft\n",
      "0.6308563748079877\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "score=roc_auc_score(y_true,res)\n",
    "print(score)\n",
    "for i,tag in enumerate(tagSet):\n",
    "    print(tag)\n",
    "    print(roc_auc_score(y_true[:,i],res[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.54\n",
      "Songbird\n",
      "0.45\n",
      "Water Bird\n",
      "0.63\n",
      "Insect\n",
      "0.68\n",
      "Running Water\n",
      "0.78\n",
      "Rain\n",
      "0.53\n",
      "Cable\n",
      "0.12\n",
      "Wind\n",
      "0.76\n",
      "Aircraft\n",
      "0.34\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "score=roc_auc_score(y_true,res)\n",
    "print(f\"{score:.2f}\")\n",
    "for i,tag in enumerate(tagSet):\n",
    "    print(tag)\n",
    "    print(f\"{roc_auc_score(y_true[:,i],res[:,i]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "\n",
    "# labelsbyhumanpath=Path('/scratch/enis/data/nna/labeling/results/')\n",
    "# # splits_path= Path('/files/scratch/enis/data/nna/labeling/splits/')\n",
    "# sourcePath=Path(\"/scratch/enis/data/nna/labeling/splits/\")\n",
    "\n",
    "    \n",
    "# with open(labelsbyhumanpath/\"np_array_Ymatrix.npy\", 'rb') as f:\n",
    "#     y_true = np.load(f)\n",
    "\n",
    "#     # ## load Dataset\n",
    "#     # # X.shape is (1300, 10, 44100)\n",
    "# with open(sourcePath/\"np_array_Xmatrix_shortby441000.npy\", 'rb') as f:\n",
    "#     X = np.load(f)\n",
    "#     #\n",
    "#     # ### split data\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#                 X, y_true, test_size=0.2, random_state=42)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#                 X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "\n",
    "import librosa\n",
    "\n",
    "maxLen=850\n",
    "res=[]\n",
    "for x in X_val:\n",
    "#     filepath=\"/scratch/enis/data/nna/labeling/splits_real/\"+k\n",
    "#     x,sr=librosa.load(filepath,sr=None)\n",
    "    mel = librosa.feature.melspectrogram(y=x.reshape(-1), sr=44100)\n",
    "    an_x = librosa.power_to_db(mel, ref=np.max)\n",
    "    an_x = an_x.astype(\"float32\")\n",
    "#     if an_x.shape[1]!=938:\n",
    "#         print((k,an_x.shape))\n",
    "#     res.append((k,an_x.shape))\n",
    "    an_x = an_x[:,:maxLen]\n",
    "    x = an_x.reshape(1,1,*an_x.shape[:])\n",
    "   \n",
    "    out = model(torch.Tensor(x))\n",
    "    out = torch.sigmoid(out)\n",
    "    out = out.detach().numpy()[0]\n",
    "#     print(out.value())\n",
    "    res.append(out)\n",
    "#     break\n",
    "res=np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793516100966444\n",
      "Songbird\n",
      "0.7200205113178522\n",
      "Water Bird\n",
      "0.7296854521625163\n",
      "Insect\n",
      "0.6631027954115157\n",
      "Running Water\n",
      "0.923889082260123\n",
      "Rain\n",
      "0.6764583333333334\n",
      "Cable\n",
      "0.8252100840336135\n",
      "Wind\n",
      "0.9101562499999999\n",
      "Aircraft\n",
      "0.8996062992125985\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "score=roc_auc_score(y_val,res)\n",
    "print(score)\n",
    "for i,tag in enumerate(tagSet):\n",
    "    print(tag)\n",
    "    print(roc_auc_score(y_val[:,i],res[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aircraft\n",
      "no positive\n",
      "Cable\n",
      "no positive\n",
      "Insect\n",
      "no positive\n",
      "Rain\n",
      "no positive\n",
      "Running Water\n",
      "no positive\n",
      "Songbird\n",
      "no positive\n",
      "Water Bird\n",
      "no positive\n",
      "Wind\n",
      "0.56\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "tableResults={i:[i,] for i in tagNames}\n",
    "tableResultsHeaders=[\"Tag\",\"AUC\",\"tn\", \"fp\", \"fn\", \"tp\"]\n",
    "for tagName in tagNames:\n",
    "    print(tagName)\n",
    "    y_true=y_true_dict[tagName]\n",
    "    y_pred=results[tagName]\n",
    "    if sum(y_true)==0:\n",
    "        print(\"no positive\")\n",
    "        tableResults[tagName].append(\"NA\")\n",
    "        continue\n",
    "    score=roc_auc_score(y_true,y_pred)\n",
    "    score=\"{:.2}\".format(score)\n",
    "    print(score)\n",
    "    tableResults[tagName].append(score)\n",
    "    \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "for tagName in tagNames:\n",
    "#     print(tagName)\n",
    "    y_true=y_true_dict[tagName]\n",
    "    y_pred=results[tagName]\n",
    "    y_pred=np.array(y_pred)\n",
    "    y_pred = np.where(y_pred > 0.5, 1, 0)\n",
    "#     print(sum(y_true))\n",
    "    tn, fp, fn, tp=confusion_matrix(y_true, y_pred).ravel()\n",
    "    tableResults[tagName].extend([tn, fp, fn, tp])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag            AUC      tn    fp    fn    tp\n",
      "-------------  -----  ----  ----  ----  ----\n",
      "Aircraft       NA      339    18     0     0\n",
      "Cable          NA      228   129     0     0\n",
      "Insect         NA      354     3     0     0\n",
      "Rain           NA      354     3     0     0\n",
      "Running Water  NA      329    28     0     0\n",
      "Songbird       NA      194   163     0     0\n",
      "Water Bird     NA      356     1     0     0\n",
      "Wind           0.56     22   127     1   207\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "resultStr=tabulate(tableResults.values(), headers=tableResultsHeaders)\n",
    "print(resultStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10272_20190520_160000_55m_45s__55m_55s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10238_20190521_164602_33m_52s__34m_2s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10307_20190607_224602_68m_38s__68m_48s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10292_20190525_143000_46m_19s__46m_29s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10258_20190525_130000_10m_39s__10m_49s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10276_20190618_081602_46m_45s__46m_55s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10283_20190613_140000_27m_45s__27m_55s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10295_20190523_021602_41m_52s__42m_2s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10255_20190520_053000_57m_10s__57m_20s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10327_20190516_051602_45m_1s__45m_11s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10264_20190521_131602_22m_23s__22m_33s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10276_20190615_094602_41m_40s__41m_50s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10251_20190512_193000_54m_3s__54m_13s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10258_20190523_000000_74m_39s__74m_49s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10361_20190615_184602_62m_44s__62m_54s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10361_20190524_003000_37m_40s__37m_50s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10255_20190524_001602_52m_58s__53m_8s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10292_20190611_024602_26m_21s__26m_31s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10280_20190521_113000_63m_33s__63m_43s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10327_20190520_203000_19m_30s__19m_40s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10275_20190525_100000_25m_48s__25m_58s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10264_20190523_211602_30m_2s__30m_12s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10262_20190608_211602_11m_22s__11m_32s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10255_20190512_061602_25m_54s__26m_4s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10295_20190615_130000_27m_25s__27m_35s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10261_20190525_093000_54m_41s__54m_51s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10280_20190525_093000_47m_53s__48m_3s.flac\n",
      "/Users/berk/Documents/research/scratch/splits_realNoClipping04/S4A10238_20190507_130000_65m_50s__66m_0s.flac\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for k in humanresultsAll:\n",
    "    val=humanresultsAll[k]\n",
    "#     print(val)\n",
    "    val2=[i.lower().replace(\"+\",\"\") for i in val ]\n",
    "    val2=[i.lower().replace(\"+\",\"\") for i in val2 if i not in [\"clipping\",\"wind\"]]\n",
    "    if \"aircraft\" in val2:\n",
    "        print(\"/Users/berk/Documents/research/scratch/splits_realNoClipping04/\"+k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S4A10295_20190523_021602_41m_52s__42m_2s.flac ['Songbird', 'Water Bird', 'Aircraft']\n",
      "S4A10295_20190520_070000_74m_56s__75m_6s.flac ['Songbird', 'Wind']\n",
      "S4A10295_20190513_211602_24m_48s__24m_58s.flac ['Songbird', 'Wind']\n",
      "S4A10295_20190507_051602_15m_21s__15m_31s.flac ['Rain', 'Wind']\n",
      "S4A10295_20190516_043000_41m_22s__41m_32s.flac ['Wind']\n",
      "S4A10295_20190615_184602_5m_28s__5m_38s.flac ['Wind']\n",
      "S4A10295_20190520_070000_20m_41s__20m_51s.flac ['Songbird', 'Wind']\n",
      "S4A10295_20190615_130000_27m_25s__27m_35s.flac ['Aircraft']\n",
      "S4A10295_20190605_083000_58m_49s__58m_59s.flac ['Songbird', 'Wind', 'Clipping']\n",
      "S4A10295_20190601_060000_34m_22s__34m_32s.flac ['Clipping']\n",
      "S4A10295_20190527_094602_37m_10s__37m_20s.flac ['Clipping+++++']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for k in humanresultsAll:\n",
    "    if \"S4A10295\" in k:\n",
    "        print(k,humanresultsAll[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machinery or Helicopter \n",
    "S4A10295_20190520_070000_74m_56s__75m_6s.flac ['Songbird', 'Wind'] probably wind\n",
    "S4A10295_20190513_211602_24m_48s__24m_58s.flac ['Songbird', 'Wind'] wind\n",
    "\n",
    "S4A10295_20190605_083000_58m_49s__58m_59s.flac ['Songbird', 'Wind', 'Clipping'] wind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S4A10255 automobile field\n",
    "S4A10255_20190508_210000_67m_11s__67m_21s.flac ['Wind'] should have aircraft/engine\n",
    "S4A10255_20190608_010000_54m_36s__54m_46s.flac ['Clipping+++'] so much like wind \n",
    "S4A10255_20190528_013000_4m_29s__4m_39s.flac ['Clipping++++'] I cannot decide, would say wind\n",
    "S4A10255_20190515_044602_2m_15s__2m_25s.flac []  should probably have aircraft, frequent clipping\n",
    "S4A10255_20190608_010000_54m_36s__54m_46s.flac ['Clipping+++'] so much clipping, somethong\n",
    "S4A10255_20190513_140000_58m_19s__58m_29s.flac ['Wind', 'Clipping++++'] really hard to tell, in the beginning sounds like aircarft but then it sounds like wind\n",
    "S4A10255_20190521_143000_14m_45s__14m_55s.flac ['Songbird', 'Clipping++++'] flight or wind \n",
    "no\n",
    "no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is flare\n",
    "# how does she differentiate Commercial Airplane, Propeller Plane and Helicopter \n",
    "\n",
    "# maybe thats the difference of reading the image and listening"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speechEnv",
   "language": "python",
   "name": "speechenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
