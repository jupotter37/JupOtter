{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 706
    },
    "colab_type": "code",
    "id": "XljgxipmoCyy",
    "outputId": "358fc4f0-0e82-4a31-e177-22a1550fb978"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/ba/dda44bbf35b071441635708a3dd568a5ca6bf29f77389f7c7c6818ae9498/transformers-2.7.0-py3-none-any.whl (544kB)\n",
      "\r",
      "\u001b[K     |▋                               | 10kB 11.8MB/s eta 0:00:01\r",
      "\u001b[K     |█▏                              | 20kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 30kB 5.7MB/s eta 0:00:01\r",
      "\u001b[K     |██▍                             | 40kB 5.0MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 51kB 5.9MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 61kB 7.0MB/s eta 0:00:01\r",
      "\u001b[K     |████▏                           | 71kB 7.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▉                           | 81kB 8.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 92kB 7.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 102kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 112kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████▏                        | 122kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 133kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████▍                       | 143kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 153kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 163kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 174kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 184kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 194kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 204kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 215kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 225kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 235kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▍                 | 245kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 256kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 266kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 276kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▉               | 286kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▌              | 296kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 307kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 317kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 327kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 337kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 348kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 358kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 368kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 378kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 389kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 399kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 409kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▊       | 419kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▎      | 430kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 440kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 450kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 460kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 471kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 481kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 491kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 501kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 512kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▊ | 522kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▎| 532kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 542kB 8.3MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 552kB 8.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.31)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\r",
      "\u001b[K     |▎                               | 10kB 34.1MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 20kB 40.5MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 30kB 47.4MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 40kB 52.5MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 51kB 31.6MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 61kB 34.6MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 71kB 22.7MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 81kB 18.0MB/s eta 0:00:01\r",
      "\u001b[K     |██▉                             | 92kB 19.7MB/s eta 0:00:01\r",
      "\u001b[K     |███▏                            | 102kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▌                            | 112kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███▉                            | 122kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 133kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 143kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 153kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 163kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 174kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████▊                          | 184kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 194kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 204kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 215kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 225kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 235kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 245kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████▉                        | 256kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▏                       | 266kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▌                       | 276kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████▉                       | 286kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▏                      | 296kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▌                      | 307kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 317kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 327kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▍                     | 337kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▊                     | 348kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 358kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▍                    | 368kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 378kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 389kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 399kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 409kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 419kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 430kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▌                  | 440kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▉                  | 450kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 460kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 471kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 481kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 491kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▍                | 501kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▊                | 512kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 522kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▍               | 532kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 542kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 552kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 563kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 573kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 583kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 593kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 604kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 614kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 624kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▌            | 634kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▉            | 645kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▏           | 655kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▌           | 665kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▉           | 675kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 686kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 696kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 706kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 716kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▍         | 727kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▊         | 737kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 747kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 757kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 768kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 778kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 788kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 798kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 808kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 819kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 829kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 839kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 849kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 860kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 870kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████     | 880kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▍    | 890kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▊    | 901kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 911kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▍   | 921kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▊   | 931kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 942kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▎  | 952kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▋  | 962kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 972kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▎ | 983kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 993kB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 1.0MB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 1.0MB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 1.0MB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 1.0MB 21.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 1.0MB 21.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 59.7MB/s \n",
      "\u001b[?25hCollecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 54.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.31 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.31)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (2.8.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=9fe2ddcbc2aad8c82e427508959e031737ce537a8266c37d8b8b5b3746256f8d\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 166,
     "referenced_widgets": [
      "bded93ea97134f79bb537dbbd7170eab",
      "a5af6b66069448a6aa562b5fb13824c8",
      "3f3e8f1ac97b48e48d6a062538b62d59",
      "2c694d3d0edd46439557e4a24a58bb3c",
      "2a2d8dd35395442ba81600c83187f634",
      "6138fae6e7c24f379eb2901ea3a49210",
      "af20106f78f840ae9a932a4cd05e5efc",
      "b11cd12957644e3c99f658bdeecfdbeb",
      "555085b22706453cae970946de95c78f",
      "e7abb7b432834ae8b41ff5c42dc88fed",
      "76f1124a549648ceab7e4ba050f00ee9",
      "48f61c531c7a497187cea2ed374c9e9a",
      "0f1c2537775349939f8d6be4f36cc393",
      "7d173513c12e47018aac458428fb7e15",
      "748de3fa024448c29b84811a822425c0",
      "b0ff01d52e7a4d9ead07e6911c0dec98",
      "55007e41f7b841b7a0a3b9bdc4e1aad0",
      "df19cb6afc914b4a98cb4f1c7c4b4497",
      "e22cec4238864b38969782f6997ed2a1",
      "97af93557e3c4c28b1c9a24a6c6196ad",
      "dbfa3f514331448f854be7c4a193316b",
      "b75e577cf5664d169529525d9f7139c7",
      "07748db1f3ea424fa02c2246a4e1c494",
      "fe724cfa242a471681380037cc977abf"
     ]
    },
    "colab_type": "code",
    "id": "2pcuhJ2RnSj-",
    "outputId": "338bdd6c-a1f5-44f9-97b9-4c3897cba9bd"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bded93ea97134f79bb537dbbd7170eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=5069051, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "555085b22706453cae970946de95c78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=737, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55007e41f7b841b7a0a3b9bdc4e1aad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=1115590446, style=ProgressStyle(description…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import *\n",
    "\n",
    "# Transformers has a unified API\n",
    "# for 10 transformer architectures and 30 pretrained weights.\n",
    "#          Model          | Tokenizer          | Pretrained weights shortcut\n",
    "MODELS = [\n",
    "          (XLMRobertaModel, XLMRobertaTokenizer, 'xlm-roberta-base'),\n",
    "         ]\n",
    "\n",
    "\n",
    "# Let's encode some text in a sequence of hidden-states using each model:\n",
    "for model_class, tokenizer_class, pretrained_weights in MODELS:\n",
    "    # Load pretrained model/tokenizer\n",
    "    tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "    model = model_class.from_pretrained(pretrained_weights)\n",
    "\n",
    "    # Encode text\n",
    "    input_ids = torch.tensor([tokenizer.encode(\"Here is some text to encode\", add_special_tokens=True)])  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = model(input_ids)[0]  # Models outputs are now tuples\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rkdselMfo7YE",
    "outputId": "19f6dd58-352a-4987-b311-3c0e05c8e767"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sdoOniU7qFUX",
    "outputId": "f1919d94-a587-45f8-8b10-cacf3638953e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa.squeeze(0).mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230
    },
    "colab_type": "code",
    "id": "O5PEwOdJsRdB",
    "outputId": "187b42de-8e97-485d-f378-8fcadcc1ad22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 60\n",
      "Collecting wget\n",
      "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=64ddd42e975527f76d5c2c1d7c3adf5e34dac36b1791ae4ce9cf14a97ce30698\n",
      "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n",
      "Downloading dataset\n"
     ]
    }
   ],
   "source": [
    "!pip install wget\n",
    "import wget\n",
    "import os\n",
    "print('Downloading dataset')# The URL for the dataset zip file.\n",
    "url = 'https://nyu-mll.github.io/CoLA/cola_public_1.1.zip'# Download the file (if we haven't already)\n",
    "if not os.path.exists('./cola_public_1.1.zip'):\n",
    "  wget.download(url, './cola_public_1.1.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "78NEBaXStQKw",
    "outputId": "a789969a-3600-46c8-c1b5-22e29dc48a8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  cola_public_1.1.zip\n",
      "   creating: cola_public/\n",
      "  inflating: cola_public/README      \n",
      "   creating: cola_public/tokenized/\n",
      "  inflating: cola_public/tokenized/in_domain_dev.tsv  \n",
      "  inflating: cola_public/tokenized/in_domain_train.tsv  \n",
      "  inflating: cola_public/tokenized/out_of_domain_dev.tsv  \n",
      "   creating: cola_public/raw/\n",
      "  inflating: cola_public/raw/in_domain_dev.tsv  \n",
      "  inflating: cola_public/raw/in_domain_train.tsv  \n",
      "  inflating: cola_public/raw/out_of_domain_dev.tsv  \n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('./cola_public/'):\n",
    "  !unzip cola_public_1.1.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 378
    },
    "colab_type": "code",
    "id": "KJWs-rwlsRlA",
    "outputId": "9ca1c803-faaf-43a0-bf1a-ded44ca41fc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training sentences: 8,551\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_source</th>\n",
       "      <th>label</th>\n",
       "      <th>label_notes</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3747</th>\n",
       "      <td>ks08</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The kids in our class have arrived safely.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>l-93</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>Ellen conferred to Helen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>bc01</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>John kisses often Mary.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1497</th>\n",
       "      <td>r-67</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I promised that tomorrow he would be there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>c_13</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Molly gave Calvin a kiss.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5112</th>\n",
       "      <td>ks08</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>The writer is that gets you so involved.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751</th>\n",
       "      <td>bc01</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>They represented to the dean Mary as a genuine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>bc01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No candidate can predict how many people will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5976</th>\n",
       "      <td>c_13</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Calvin has a peanut.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7315</th>\n",
       "      <td>sks13</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>I said.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentence_source  ...                                           sentence\n",
       "3747            ks08  ...         The kids in our class have arrived safely.\n",
       "3076            l-93  ...                          Ellen conferred to Helen.\n",
       "352             bc01  ...                            John kisses often Mary.\n",
       "1497            r-67  ...        I promised that tomorrow he would be there.\n",
       "5916            c_13  ...                          Molly gave Calvin a kiss.\n",
       "5112            ks08  ...           The writer is that gets you so involved.\n",
       "751             bc01  ...  They represented to the dean Mary as a genuine...\n",
       "380             bc01  ...  No candidate can predict how many people will ...\n",
       "5976            c_13  ...                               Calvin has a peanut.\n",
       "7315           sks13  ...                                            I said.\n",
       "\n",
       "[10 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])# Report the number of sentences.\n",
    "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))# Display 10 random rows from the data.\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5lCFY7X0tf2Y"
   },
   "outputs": [],
   "source": [
    "sentences = df.sentence.values\n",
    "labels = df.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84,
     "referenced_widgets": [
      "c804913ce94445e197353d7ecbfa4665",
      "cd7352f11e374ad29d272bfc855eade2",
      "2f11e3e56dc44ce5bc09dfd926fbba1a",
      "908e7a499f0149ab9649b79a682060c2",
      "003a3c12d9b84715bfc5f075a4d90378",
      "efcb66a6dfc54a368c9a98389f85d29d",
      "e7e0586404204ee0a87713aadea96878",
      "bd503aece4fb413aa0452afcc168bb6e"
     ]
    },
    "colab_type": "code",
    "id": "hHqrLmzrtuAK",
    "outputId": "c0b454cd-981f-41df-a797-847fe191574d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c804913ce94445e197353d7ecbfa4665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ruh77fycvQuM",
    "outputId": "8a27def8-8c6f-4aad-c776-8ea83a5d6d9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Our friends won't buy this analysis, let alone the next one we propose.\""
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentence.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y4IBBAa4vFEN"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "input_ids = torch.tensor([tokenizer.encode(df.sentence.iloc[0], add_special_tokens=True)])  # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "colab_type": "code",
    "id": "jZUCxv5LvZgn",
    "outputId": "02813f39-935d-47e8-d679-e53b85128e7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  Our friends won't buy this analysis, let alone the next one we propose.\n",
      "Token IDs: [101, 2256, 2814, 2180, 1005, 1056, 4965, 2023, 4106, 1010, 2292, 2894, 1996, 2279, 2028, 2057, 16599, 1012, 102]\n",
      "\n",
      "Padding/truncating all sentences to 64 values...\n",
      "\n",
      "Padding token: \"[PAD]\", ID: 0\n",
      "\\Done.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []# For every sentence...\n",
    "for sent in sentences:\n",
    " # `encode` will:\n",
    " # (1) Tokenize the sentence.\n",
    " # (2) Prepend the `[CLS]` token to the start.\n",
    " # (3) Append the `[SEP]` token to the end.\n",
    " # (4) Map tokens to their IDs.\n",
    " encoded_sent = tokenizer.encode(\n",
    " sent, # Sentence to encode.\n",
    " add_special_tokens = True, # Add '[CLS]' and '[SEP]' # This function also supports truncation and conversion\n",
    " # to pytorch tensors, but we need to do padding, so we\n",
    " # can't use these features :( .\n",
    " #max_length = 128, # Truncate all sentences.\n",
    " #return_tensors = 'pt', # Return pytorch tensors.\n",
    " )\n",
    "\n",
    " # Add the encoded sentence to the list.\n",
    " input_ids.append(encoded_sent)# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])\n",
    "\n",
    "# We'll borrow the `pad_sequences` utility function to do this.\n",
    "from keras.preprocessing.sequence import pad_sequences# Set the maximum sequence length.\n",
    "# I've chosen 64 somewhat arbitrarily. It's slightly larger than the\n",
    "# maximum training sentence length of 47...\n",
    "MAX_LEN = 64\n",
    "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
    "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))# Pad our input tokens with value 0.\n",
    "# \"post\" indicates that we want to pad and truncate at the end of the sequence,\n",
    "# as opposed to the beginning.\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
    " value=0, truncating=\"post\", padding=\"post\")\n",
    "print('\\Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WMySQH-evwgT"
   },
   "outputs": [],
   "source": [
    "attention_masks = []\n",
    "for sent in input_ids:\n",
    "\n",
    "  # Create the attention mask.\n",
    "  # - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "  # - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "  att_mask = [int(token_id > 0) for token_id in sent]\n",
    "\n",
    "  # Store the attention mask for this sentence.\n",
    "  attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PA4X8AoRwQqd",
    "outputId": "05947d5b-dee9-4f60-ce62-de677c2ebec3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8551, 64), (8551,), 8551, (8551,))"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape, labels.shape, len(attention_masks), labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ND3hpPbIwJE4"
   },
   "outputs": [],
   "source": [
    "# Use train_test_split to split our data into train and validation sets for\n",
    "# training\n",
    "from sklearn.model_selection import train_test_split# Use 90% for training and 10% for validation.\n",
    "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n",
    " random_state=2018, test_size=0.1)\n",
    "# Do the same for the masks.\n",
    "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
    " random_state=2018, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x6LG7juYwzKt",
    "outputId": "c2cb3121-b757-41fe-ee57-65caaf564aca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 65\n"
     ]
    }
   ],
   "source": [
    "# Convert all inputs and labels into torch tensors, the required datatype \n",
    "# for our model.\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mae9CRwgw3Xo"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here.\n",
    "# For fine-tuning BERT on a specific task, the authors recommend a batch size of\n",
    "# 16 or 32.\n",
    "batch_size = 32# Create the DataLoader for our training set.\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)# Create the DataLoader for our validation set.\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "8fac748d0156426fb9254132a4c45b01",
      "f1fb663f86124547b0e20840baae040c",
      "2ceddc45414541b49dc9b80d4c01c93e",
      "e15d3549cd93471eaece9ed8a4fcc0ac",
      "72c6a7bb1a3f46449535b2e07af72197",
      "8617be0b4a6a472caebf7ba37477c8b2",
      "825dbab57e134a1184908c1f005390bc",
      "67bb5e798198435895111334791a1cf6",
      "2e372aa4c0c64fff8371a9372a209304",
      "a9bbdaec63a240f4af000c4b566b59f8",
      "94f3b7acedb645539d51b5e436609177",
      "5c2748202e184a03ae7794d91776280b",
      "34bf7a3766eb436486a812e07da7bbdb",
      "2a649a4c16d84cf98220d78cd46c35f1",
      "a5bce29138734c03bb06f4b6e07b44cd",
      "af43a0eb347342719a03d17440e1ad01"
     ]
    },
    "colab_type": "code",
    "id": "KoaZ7y3aw_rl",
    "outputId": "dc1dad8d-e10c-473f-8c63-60d6e053b93f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fac748d0156426fb9254132a4c45b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e372aa4c0c64fff8371a9372a209304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW, BertConfig# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    " \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    " num_labels = 2, # The number of output labels--2 for binary classification.\n",
    " # You can increase this for multi-class tasks. \n",
    " output_attentions = False, # Whether the model returns attentions weights.\n",
    " output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "n2GlHGwmxDdZ",
    "outputId": "566f55c3-94c2-4e96-fe15-4976749a41b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "print('==== Embedding Layer ====\\n')\n",
    "for p in params[0:5]:\n",
    "  print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "  print('\\n==== First Transformer ====\\n')\n",
    "for p in params[5:21]:\n",
    "  print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "  print('\\n==== Output Layer ====\\n')\n",
    "for p in params[-4:]:\n",
    "  print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "myogdXkjx6Vf"
   },
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    " lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    " eps = 1e-8 # args.adam_epsilon - default is 1e-8.\n",
    " )\n",
    "from transformers import get_linear_schedule_with_warmup# Number of training epochs (authors recommend between 2 and 4)\n",
    "epochs = 4# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    " num_warmup_steps = 0, # Default value in run_glue.py\n",
    " num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mq7he9kjyANi"
   },
   "outputs": [],
   "source": [
    "import numpy as np# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    " pred_flat = np.argmax(preds, axis=1).flatten()\n",
    " labels_flat = labels.flatten()\n",
    " return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WA8FTzwXyCQF"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "def format_time(elapsed):\n",
    " '''\n",
    " Takes a time in seconds and returns a string hh:mm:ss\n",
    " '''\n",
    " # Round to the nearest second.\n",
    " elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    " # Format as hh:mm:ss\n",
    " return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "ZmmF6DdqzNE9",
    "outputId": "5591d4ec-d39e-4714-d39d-89b14e290497"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch# If there's a GPU available...\n",
    "if torch.cuda.is_available():  # Tell PyTorch to use the GPU. \n",
    " device = torch.device(\"cuda\")\n",
    " print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    " print('We will use the GPU:', torch.cuda.get_device_name(0))# If not...\n",
    "else:\n",
    " print('No GPU available, using the CPU instead.')\n",
    " device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mL5UMpmh-qsn",
    "outputId": "4bcb94d7-99b3-4b65-da16-d1a5dc02cc1a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1])"
      ]
     },
     "execution_count": 86,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kff2UJ0qyhtX",
    "outputId": "6b86a6e4-067a-4031-853e-bd4c92aed657"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Epoch 1 / 4 ========\n",
      "Training...\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:01\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:01\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:01\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:02\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:02\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:02\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:03\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:03\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:04\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:04\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:04\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:05\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:05\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:05\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:06\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:06\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:07\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:07\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:07\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:08\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:08\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:08\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:09\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:09\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:10\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:10\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:10\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:11\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:11\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:11\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:12\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:12\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:13\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:13\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:13\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:14\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:14\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:15\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:15\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:15\n",
      " Batch    40 of   241. Elapsed: 0:00:15.\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:16\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:16\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:16\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:17\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:17\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:18\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:18\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:18\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:19\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:19\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:20\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:00:20\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:00:20\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:00:21\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:00:21\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:00:21\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:00:22\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:00:22\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:00:23\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:00:23\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:00:23\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:00:24\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:00:24\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:00:25\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:00:25\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:00:25\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:00:26\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:00:26\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:00:27\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:00:27\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:00:27\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:00:28\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:00:28\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:00:29\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:00:29\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:00:29\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:00:30\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:00:30\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:00:31\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:00:31\n",
      " Batch    80 of   241. Elapsed: 0:00:31.\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:00:31\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:00:32\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:00:32\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:00:32\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:00:33\n",
      "\n",
      " Average training loss: 0.20\n",
      " Training epcoh took: 0:00:33\n",
      "\n",
      " Average training loss: 0.20\n",
      " Training epcoh took: 0:00:34\n",
      "\n",
      " Average training loss: 0.20\n",
      " Training epcoh took: 0:00:34\n",
      "\n",
      " Average training loss: 0.20\n",
      " Training epcoh took: 0:00:34\n",
      "\n",
      " Average training loss: 0.20\n",
      " Training epcoh took: 0:00:35\n",
      "\n",
      " Average training loss: 0.21\n",
      " Training epcoh took: 0:00:35\n",
      "\n",
      " Average training loss: 0.21\n",
      " Training epcoh took: 0:00:36\n",
      "\n",
      " Average training loss: 0.21\n",
      " Training epcoh took: 0:00:36\n",
      "\n",
      " Average training loss: 0.21\n",
      " Training epcoh took: 0:00:36\n",
      "\n",
      " Average training loss: 0.21\n",
      " Training epcoh took: 0:00:37\n",
      "\n",
      " Average training loss: 0.22\n",
      " Training epcoh took: 0:00:37\n",
      "\n",
      " Average training loss: 0.22\n",
      " Training epcoh took: 0:00:38\n",
      "\n",
      " Average training loss: 0.22\n",
      " Training epcoh took: 0:00:38\n",
      "\n",
      " Average training loss: 0.22\n",
      " Training epcoh took: 0:00:38\n",
      "\n",
      " Average training loss: 0.22\n",
      " Training epcoh took: 0:00:39\n",
      "\n",
      " Average training loss: 0.23\n",
      " Training epcoh took: 0:00:39\n",
      "\n",
      " Average training loss: 0.23\n",
      " Training epcoh took: 0:00:40\n",
      "\n",
      " Average training loss: 0.23\n",
      " Training epcoh took: 0:00:40\n",
      "\n",
      " Average training loss: 0.23\n",
      " Training epcoh took: 0:00:40\n",
      "\n",
      " Average training loss: 0.24\n",
      " Training epcoh took: 0:00:41\n",
      "\n",
      " Average training loss: 0.24\n",
      " Training epcoh took: 0:00:41\n",
      "\n",
      " Average training loss: 0.24\n",
      " Training epcoh took: 0:00:41\n",
      "\n",
      " Average training loss: 0.24\n",
      " Training epcoh took: 0:00:42\n",
      "\n",
      " Average training loss: 0.25\n",
      " Training epcoh took: 0:00:42\n",
      "\n",
      " Average training loss: 0.25\n",
      " Training epcoh took: 0:00:43\n",
      "\n",
      " Average training loss: 0.25\n",
      " Training epcoh took: 0:00:43\n",
      "\n",
      " Average training loss: 0.25\n",
      " Training epcoh took: 0:00:43\n",
      "\n",
      " Average training loss: 0.25\n",
      " Training epcoh took: 0:00:44\n",
      "\n",
      " Average training loss: 0.26\n",
      " Training epcoh took: 0:00:44\n",
      "\n",
      " Average training loss: 0.26\n",
      " Training epcoh took: 0:00:45\n",
      "\n",
      " Average training loss: 0.26\n",
      " Training epcoh took: 0:00:45\n",
      "\n",
      " Average training loss: 0.26\n",
      " Training epcoh took: 0:00:45\n",
      "\n",
      " Average training loss: 0.26\n",
      " Training epcoh took: 0:00:46\n",
      "\n",
      " Average training loss: 0.27\n",
      " Training epcoh took: 0:00:46\n",
      "\n",
      " Average training loss: 0.27\n",
      " Training epcoh took: 0:00:47\n",
      " Batch   120 of   241. Elapsed: 0:00:47.\n",
      "\n",
      " Average training loss: 0.27\n",
      " Training epcoh took: 0:00:47\n",
      "\n",
      " Average training loss: 0.27\n",
      " Training epcoh took: 0:00:47\n",
      "\n",
      " Average training loss: 0.27\n",
      " Training epcoh took: 0:00:48\n",
      "\n",
      " Average training loss: 0.28\n",
      " Training epcoh took: 0:00:48\n",
      "\n",
      " Average training loss: 0.28\n",
      " Training epcoh took: 0:00:48\n",
      "\n",
      " Average training loss: 0.28\n",
      " Training epcoh took: 0:00:49\n",
      "\n",
      " Average training loss: 0.28\n",
      " Training epcoh took: 0:00:49\n",
      "\n",
      " Average training loss: 0.28\n",
      " Training epcoh took: 0:00:50\n",
      "\n",
      " Average training loss: 0.29\n",
      " Training epcoh took: 0:00:50\n",
      "\n",
      " Average training loss: 0.29\n",
      " Training epcoh took: 0:00:50\n",
      "\n",
      " Average training loss: 0.29\n",
      " Training epcoh took: 0:00:51\n",
      "\n",
      " Average training loss: 0.29\n",
      " Training epcoh took: 0:00:51\n",
      "\n",
      " Average training loss: 0.29\n",
      " Training epcoh took: 0:00:51\n",
      "\n",
      " Average training loss: 0.30\n",
      " Training epcoh took: 0:00:52\n",
      "\n",
      " Average training loss: 0.30\n",
      " Training epcoh took: 0:00:52\n",
      "\n",
      " Average training loss: 0.30\n",
      " Training epcoh took: 0:00:53\n",
      "\n",
      " Average training loss: 0.30\n",
      " Training epcoh took: 0:00:53\n",
      "\n",
      " Average training loss: 0.30\n",
      " Training epcoh took: 0:00:53\n",
      "\n",
      " Average training loss: 0.31\n",
      " Training epcoh took: 0:00:54\n",
      "\n",
      " Average training loss: 0.31\n",
      " Training epcoh took: 0:00:54\n",
      "\n",
      " Average training loss: 0.31\n",
      " Training epcoh took: 0:00:55\n",
      "\n",
      " Average training loss: 0.31\n",
      " Training epcoh took: 0:00:55\n",
      "\n",
      " Average training loss: 0.31\n",
      " Training epcoh took: 0:00:55\n",
      "\n",
      " Average training loss: 0.32\n",
      " Training epcoh took: 0:00:56\n",
      "\n",
      " Average training loss: 0.32\n",
      " Training epcoh took: 0:00:56\n",
      "\n",
      " Average training loss: 0.32\n",
      " Training epcoh took: 0:00:56\n",
      "\n",
      " Average training loss: 0.32\n",
      " Training epcoh took: 0:00:57\n",
      "\n",
      " Average training loss: 0.32\n",
      " Training epcoh took: 0:00:57\n",
      "\n",
      " Average training loss: 0.33\n",
      " Training epcoh took: 0:00:58\n",
      "\n",
      " Average training loss: 0.33\n",
      " Training epcoh took: 0:00:58\n",
      "\n",
      " Average training loss: 0.33\n",
      " Training epcoh took: 0:00:58\n",
      "\n",
      " Average training loss: 0.33\n",
      " Training epcoh took: 0:00:59\n",
      "\n",
      " Average training loss: 0.33\n",
      " Training epcoh took: 0:00:59\n",
      "\n",
      " Average training loss: 0.33\n",
      " Training epcoh took: 0:00:59\n",
      "\n",
      " Average training loss: 0.34\n",
      " Training epcoh took: 0:01:00\n",
      "\n",
      " Average training loss: 0.34\n",
      " Training epcoh took: 0:01:00\n",
      "\n",
      " Average training loss: 0.34\n",
      " Training epcoh took: 0:01:01\n",
      "\n",
      " Average training loss: 0.34\n",
      " Training epcoh took: 0:01:01\n",
      "\n",
      " Average training loss: 0.34\n",
      " Training epcoh took: 0:01:01\n",
      "\n",
      " Average training loss: 0.35\n",
      " Training epcoh took: 0:01:02\n",
      " Batch   160 of   241. Elapsed: 0:01:02.\n",
      "\n",
      " Average training loss: 0.35\n",
      " Training epcoh took: 0:01:02\n",
      "\n",
      " Average training loss: 0.35\n",
      " Training epcoh took: 0:01:02\n",
      "\n",
      " Average training loss: 0.35\n",
      " Training epcoh took: 0:01:03\n",
      "\n",
      " Average training loss: 0.35\n",
      " Training epcoh took: 0:01:03\n",
      "\n",
      " Average training loss: 0.36\n",
      " Training epcoh took: 0:01:04\n",
      "\n",
      " Average training loss: 0.36\n",
      " Training epcoh took: 0:01:04\n",
      "\n",
      " Average training loss: 0.36\n",
      " Training epcoh took: 0:01:04\n",
      "\n",
      " Average training loss: 0.36\n",
      " Training epcoh took: 0:01:05\n",
      "\n",
      " Average training loss: 0.36\n",
      " Training epcoh took: 0:01:05\n",
      "\n",
      " Average training loss: 0.36\n",
      " Training epcoh took: 0:01:06\n",
      "\n",
      " Average training loss: 0.37\n",
      " Training epcoh took: 0:01:06\n",
      "\n",
      " Average training loss: 0.37\n",
      " Training epcoh took: 0:01:06\n",
      "\n",
      " Average training loss: 0.37\n",
      " Training epcoh took: 0:01:07\n",
      "\n",
      " Average training loss: 0.37\n",
      " Training epcoh took: 0:01:07\n",
      "\n",
      " Average training loss: 0.37\n",
      " Training epcoh took: 0:01:07\n",
      "\n",
      " Average training loss: 0.38\n",
      " Training epcoh took: 0:01:08\n",
      "\n",
      " Average training loss: 0.38\n",
      " Training epcoh took: 0:01:08\n",
      "\n",
      " Average training loss: 0.38\n",
      " Training epcoh took: 0:01:09\n",
      "\n",
      " Average training loss: 0.38\n",
      " Training epcoh took: 0:01:09\n",
      "\n",
      " Average training loss: 0.38\n",
      " Training epcoh took: 0:01:09\n",
      "\n",
      " Average training loss: 0.38\n",
      " Training epcoh took: 0:01:10\n",
      "\n",
      " Average training loss: 0.39\n",
      " Training epcoh took: 0:01:10\n",
      "\n",
      " Average training loss: 0.39\n",
      " Training epcoh took: 0:01:10\n",
      "\n",
      " Average training loss: 0.39\n",
      " Training epcoh took: 0:01:11\n",
      "\n",
      " Average training loss: 0.39\n",
      " Training epcoh took: 0:01:11\n",
      "\n",
      " Average training loss: 0.39\n",
      " Training epcoh took: 0:01:12\n",
      "\n",
      " Average training loss: 0.40\n",
      " Training epcoh took: 0:01:12\n",
      "\n",
      " Average training loss: 0.40\n",
      " Training epcoh took: 0:01:12\n",
      "\n",
      " Average training loss: 0.40\n",
      " Training epcoh took: 0:01:13\n",
      "\n",
      " Average training loss: 0.40\n",
      " Training epcoh took: 0:01:13\n",
      "\n",
      " Average training loss: 0.40\n",
      " Training epcoh took: 0:01:13\n",
      "\n",
      " Average training loss: 0.40\n",
      " Training epcoh took: 0:01:14\n",
      "\n",
      " Average training loss: 0.40\n",
      " Training epcoh took: 0:01:14\n",
      "\n",
      " Average training loss: 0.41\n",
      " Training epcoh took: 0:01:14\n",
      "\n",
      " Average training loss: 0.41\n",
      " Training epcoh took: 0:01:15\n",
      "\n",
      " Average training loss: 0.41\n",
      " Training epcoh took: 0:01:15\n",
      "\n",
      " Average training loss: 0.41\n",
      " Training epcoh took: 0:01:16\n",
      "\n",
      " Average training loss: 0.41\n",
      " Training epcoh took: 0:01:16\n",
      "\n",
      " Average training loss: 0.42\n",
      " Training epcoh took: 0:01:16\n",
      "\n",
      " Average training loss: 0.42\n",
      " Training epcoh took: 0:01:17\n",
      " Batch   200 of   241. Elapsed: 0:01:17.\n",
      "\n",
      " Average training loss: 0.42\n",
      " Training epcoh took: 0:01:17\n",
      "\n",
      " Average training loss: 0.42\n",
      " Training epcoh took: 0:01:17\n",
      "\n",
      " Average training loss: 0.42\n",
      " Training epcoh took: 0:01:18\n",
      "\n",
      " Average training loss: 0.43\n",
      " Training epcoh took: 0:01:18\n",
      "\n",
      " Average training loss: 0.43\n",
      " Training epcoh took: 0:01:19\n",
      "\n",
      " Average training loss: 0.43\n",
      " Training epcoh took: 0:01:19\n",
      "\n",
      " Average training loss: 0.43\n",
      " Training epcoh took: 0:01:19\n",
      "\n",
      " Average training loss: 0.43\n",
      " Training epcoh took: 0:01:20\n",
      "\n",
      " Average training loss: 0.43\n",
      " Training epcoh took: 0:01:20\n",
      "\n",
      " Average training loss: 0.44\n",
      " Training epcoh took: 0:01:20\n",
      "\n",
      " Average training loss: 0.44\n",
      " Training epcoh took: 0:01:21\n",
      "\n",
      " Average training loss: 0.44\n",
      " Training epcoh took: 0:01:21\n",
      "\n",
      " Average training loss: 0.44\n",
      " Training epcoh took: 0:01:22\n",
      "\n",
      " Average training loss: 0.44\n",
      " Training epcoh took: 0:01:22\n",
      "\n",
      " Average training loss: 0.44\n",
      " Training epcoh took: 0:01:22\n",
      "\n",
      " Average training loss: 0.45\n",
      " Training epcoh took: 0:01:23\n",
      "\n",
      " Average training loss: 0.45\n",
      " Training epcoh took: 0:01:23\n",
      "\n",
      " Average training loss: 0.45\n",
      " Training epcoh took: 0:01:23\n",
      "\n",
      " Average training loss: 0.45\n",
      " Training epcoh took: 0:01:24\n",
      "\n",
      " Average training loss: 0.45\n",
      " Training epcoh took: 0:01:24\n",
      "\n",
      " Average training loss: 0.46\n",
      " Training epcoh took: 0:01:25\n",
      "\n",
      " Average training loss: 0.46\n",
      " Training epcoh took: 0:01:25\n",
      "\n",
      " Average training loss: 0.46\n",
      " Training epcoh took: 0:01:25\n",
      "\n",
      " Average training loss: 0.46\n",
      " Training epcoh took: 0:01:26\n",
      "\n",
      " Average training loss: 0.46\n",
      " Training epcoh took: 0:01:26\n",
      "\n",
      " Average training loss: 0.46\n",
      " Training epcoh took: 0:01:26\n",
      "\n",
      " Average training loss: 0.47\n",
      " Training epcoh took: 0:01:27\n",
      "\n",
      " Average training loss: 0.47\n",
      " Training epcoh took: 0:01:27\n",
      "\n",
      " Average training loss: 0.47\n",
      " Training epcoh took: 0:01:28\n",
      "\n",
      " Average training loss: 0.47\n",
      " Training epcoh took: 0:01:28\n",
      "\n",
      " Average training loss: 0.47\n",
      " Training epcoh took: 0:01:28\n",
      "\n",
      " Average training loss: 0.47\n",
      " Training epcoh took: 0:01:29\n",
      "\n",
      " Average training loss: 0.48\n",
      " Training epcoh took: 0:01:29\n",
      "\n",
      " Average training loss: 0.48\n",
      " Training epcoh took: 0:01:30\n",
      "\n",
      " Average training loss: 0.48\n",
      " Training epcoh took: 0:01:30\n",
      "\n",
      " Average training loss: 0.48\n",
      " Training epcoh took: 0:01:30\n",
      "\n",
      " Average training loss: 0.48\n",
      " Training epcoh took: 0:01:31\n",
      "\n",
      " Average training loss: 0.49\n",
      " Training epcoh took: 0:01:31\n",
      "\n",
      " Average training loss: 0.49\n",
      " Training epcoh took: 0:01:31\n",
      "\n",
      " Average training loss: 0.49\n",
      " Training epcoh took: 0:01:32\n",
      " Batch   240 of   241. Elapsed: 0:01:32.\n",
      "\n",
      " Average training loss: 0.49\n",
      " Training epcoh took: 0:01:32\n",
      "Running Validation...\n",
      " Accuracy: 0.78\n",
      " Validation took: 0:00:00\n",
      "\n",
      " Accuracy: 0.80\n",
      " Validation took: 0:00:00\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:00\n",
      "\n",
      " Accuracy: 0.80\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.81\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.81\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.80\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.80\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.80\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.79\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.80\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.80\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.81\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.80\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.79\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.79\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.79\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.78\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.79\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.79\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.79\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.80\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.80\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.80\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.80\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.79\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.80\n",
      " Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 2 / 4 ========\n",
      "Training...\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:00\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:01\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:01\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:01\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:02\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:02\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:03\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:03\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:03\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:04\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:04\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:05\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:05\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:05\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:06\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:06\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:06\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:07\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:07\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:08\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:08\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:08\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:09\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:09\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:09\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:10\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:10\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:11\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:11\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:11\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:12\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:12\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:13\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:13\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:13\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:14\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:14\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:14\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:15\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:15\n",
      " Batch    40 of   241. Elapsed: 0:00:15.\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:16\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:16\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:16\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:17\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:17\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:18\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:18\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:18\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:19\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:19\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:19\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:20\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:20\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:21\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:21\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:21\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:22\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:22\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:23\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:23\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:23\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:24\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:24\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:24\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:25\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:25\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:26\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:26\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:26\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:27\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:27\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:27\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:28\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:28\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:29\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:29\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:29\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:30\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:30\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:31\n",
      " Batch    80 of   241. Elapsed: 0:00:31.\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:31\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:31\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:32\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:32\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:32\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:33\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:33\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:34\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:34\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:34\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:35\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:35\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:36\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:36\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:36\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:37\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:37\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:00:37\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:00:38\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:00:38\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:00:39\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:00:39\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:00:39\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:00:40\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:00:40\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:00:41\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:00:41\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:00:41\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:00:42\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:00:42\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:00:42\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:00:43\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:00:43\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:00:44\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:00:44\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:00:44\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:00:45\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:00:45\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:00:45\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:00:46\n",
      " Batch   120 of   241. Elapsed: 0:00:46.\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:00:46\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:00:47\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:00:47\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:00:47\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:00:48\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:00:48\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:00:49\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:00:49\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:00:49\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:00:50\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:00:50\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:00:50\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:00:51\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:00:51\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:00:52\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:00:52\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:00:52\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:00:53\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:00:53\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:00:53\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:00:54\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:00:54\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:00:55\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:00:55\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:00:55\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:00:56\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:00:56\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:00:56\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:00:57\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:00:57\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:00:58\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:00:58\n",
      "\n",
      " Average training loss: 0.20\n",
      " Training epcoh took: 0:00:58\n",
      "\n",
      " Average training loss: 0.20\n",
      " Training epcoh took: 0:00:59\n",
      "\n",
      " Average training loss: 0.20\n",
      " Training epcoh took: 0:00:59\n",
      "\n",
      " Average training loss: 0.20\n",
      " Training epcoh took: 0:01:00\n",
      "\n",
      " Average training loss: 0.20\n",
      " Training epcoh took: 0:01:00\n",
      "\n",
      " Average training loss: 0.20\n",
      " Training epcoh took: 0:01:00\n",
      "\n",
      " Average training loss: 0.20\n",
      " Training epcoh took: 0:01:01\n",
      "\n",
      " Average training loss: 0.21\n",
      " Training epcoh took: 0:01:01\n",
      " Batch   160 of   241. Elapsed: 0:01:01.\n",
      "\n",
      " Average training loss: 0.21\n",
      " Training epcoh took: 0:01:01\n",
      "\n",
      " Average training loss: 0.21\n",
      " Training epcoh took: 0:01:02\n",
      "\n",
      " Average training loss: 0.21\n",
      " Training epcoh took: 0:01:02\n",
      "\n",
      " Average training loss: 0.21\n",
      " Training epcoh took: 0:01:03\n",
      "\n",
      " Average training loss: 0.21\n",
      " Training epcoh took: 0:01:03\n",
      "\n",
      " Average training loss: 0.21\n",
      " Training epcoh took: 0:01:03\n",
      "\n",
      " Average training loss: 0.21\n",
      " Training epcoh took: 0:01:04\n",
      "\n",
      " Average training loss: 0.22\n",
      " Training epcoh took: 0:01:04\n",
      "\n",
      " Average training loss: 0.22\n",
      " Training epcoh took: 0:01:04\n",
      "\n",
      " Average training loss: 0.22\n",
      " Training epcoh took: 0:01:05\n",
      "\n",
      " Average training loss: 0.22\n",
      " Training epcoh took: 0:01:05\n",
      "\n",
      " Average training loss: 0.22\n",
      " Training epcoh took: 0:01:06\n",
      "\n",
      " Average training loss: 0.22\n",
      " Training epcoh took: 0:01:06\n",
      "\n",
      " Average training loss: 0.22\n",
      " Training epcoh took: 0:01:06\n",
      "\n",
      " Average training loss: 0.22\n",
      " Training epcoh took: 0:01:07\n",
      "\n",
      " Average training loss: 0.23\n",
      " Training epcoh took: 0:01:07\n",
      "\n",
      " Average training loss: 0.23\n",
      " Training epcoh took: 0:01:07\n",
      "\n",
      " Average training loss: 0.23\n",
      " Training epcoh took: 0:01:08\n",
      "\n",
      " Average training loss: 0.23\n",
      " Training epcoh took: 0:01:08\n",
      "\n",
      " Average training loss: 0.23\n",
      " Training epcoh took: 0:01:09\n",
      "\n",
      " Average training loss: 0.23\n",
      " Training epcoh took: 0:01:09\n",
      "\n",
      " Average training loss: 0.23\n",
      " Training epcoh took: 0:01:09\n",
      "\n",
      " Average training loss: 0.24\n",
      " Training epcoh took: 0:01:10\n",
      "\n",
      " Average training loss: 0.24\n",
      " Training epcoh took: 0:01:10\n",
      "\n",
      " Average training loss: 0.24\n",
      " Training epcoh took: 0:01:11\n",
      "\n",
      " Average training loss: 0.24\n",
      " Training epcoh took: 0:01:11\n",
      "\n",
      " Average training loss: 0.24\n",
      " Training epcoh took: 0:01:11\n",
      "\n",
      " Average training loss: 0.24\n",
      " Training epcoh took: 0:01:12\n",
      "\n",
      " Average training loss: 0.24\n",
      " Training epcoh took: 0:01:12\n",
      "\n",
      " Average training loss: 0.24\n",
      " Training epcoh took: 0:01:12\n",
      "\n",
      " Average training loss: 0.24\n",
      " Training epcoh took: 0:01:13\n",
      "\n",
      " Average training loss: 0.25\n",
      " Training epcoh took: 0:01:13\n",
      "\n",
      " Average training loss: 0.25\n",
      " Training epcoh took: 0:01:14\n",
      "\n",
      " Average training loss: 0.25\n",
      " Training epcoh took: 0:01:14\n",
      "\n",
      " Average training loss: 0.25\n",
      " Training epcoh took: 0:01:14\n",
      "\n",
      " Average training loss: 0.25\n",
      " Training epcoh took: 0:01:15\n",
      "\n",
      " Average training loss: 0.25\n",
      " Training epcoh took: 0:01:15\n",
      "\n",
      " Average training loss: 0.25\n",
      " Training epcoh took: 0:01:15\n",
      "\n",
      " Average training loss: 0.25\n",
      " Training epcoh took: 0:01:16\n",
      "\n",
      " Average training loss: 0.26\n",
      " Training epcoh took: 0:01:16\n",
      " Batch   200 of   241. Elapsed: 0:01:16.\n",
      "\n",
      " Average training loss: 0.26\n",
      " Training epcoh took: 0:01:17\n",
      "\n",
      " Average training loss: 0.26\n",
      " Training epcoh took: 0:01:17\n",
      "\n",
      " Average training loss: 0.26\n",
      " Training epcoh took: 0:01:17\n",
      "\n",
      " Average training loss: 0.26\n",
      " Training epcoh took: 0:01:18\n",
      "\n",
      " Average training loss: 0.26\n",
      " Training epcoh took: 0:01:18\n",
      "\n",
      " Average training loss: 0.26\n",
      " Training epcoh took: 0:01:18\n",
      "\n",
      " Average training loss: 0.26\n",
      " Training epcoh took: 0:01:19\n",
      "\n",
      " Average training loss: 0.26\n",
      " Training epcoh took: 0:01:19\n",
      "\n",
      " Average training loss: 0.26\n",
      " Training epcoh took: 0:01:20\n",
      "\n",
      " Average training loss: 0.27\n",
      " Training epcoh took: 0:01:20\n",
      "\n",
      " Average training loss: 0.27\n",
      " Training epcoh took: 0:01:20\n",
      "\n",
      " Average training loss: 0.27\n",
      " Training epcoh took: 0:01:21\n",
      "\n",
      " Average training loss: 0.27\n",
      " Training epcoh took: 0:01:21\n",
      "\n",
      " Average training loss: 0.27\n",
      " Training epcoh took: 0:01:22\n",
      "\n",
      " Average training loss: 0.27\n",
      " Training epcoh took: 0:01:22\n",
      "\n",
      " Average training loss: 0.27\n",
      " Training epcoh took: 0:01:22\n",
      "\n",
      " Average training loss: 0.28\n",
      " Training epcoh took: 0:01:23\n",
      "\n",
      " Average training loss: 0.28\n",
      " Training epcoh took: 0:01:23\n",
      "\n",
      " Average training loss: 0.28\n",
      " Training epcoh took: 0:01:23\n",
      "\n",
      " Average training loss: 0.28\n",
      " Training epcoh took: 0:01:24\n",
      "\n",
      " Average training loss: 0.28\n",
      " Training epcoh took: 0:01:24\n",
      "\n",
      " Average training loss: 0.28\n",
      " Training epcoh took: 0:01:25\n",
      "\n",
      " Average training loss: 0.28\n",
      " Training epcoh took: 0:01:25\n",
      "\n",
      " Average training loss: 0.28\n",
      " Training epcoh took: 0:01:25\n",
      "\n",
      " Average training loss: 0.28\n",
      " Training epcoh took: 0:01:26\n",
      "\n",
      " Average training loss: 0.29\n",
      " Training epcoh took: 0:01:26\n",
      "\n",
      " Average training loss: 0.29\n",
      " Training epcoh took: 0:01:26\n",
      "\n",
      " Average training loss: 0.29\n",
      " Training epcoh took: 0:01:27\n",
      "\n",
      " Average training loss: 0.29\n",
      " Training epcoh took: 0:01:27\n",
      "\n",
      " Average training loss: 0.29\n",
      " Training epcoh took: 0:01:28\n",
      "\n",
      " Average training loss: 0.29\n",
      " Training epcoh took: 0:01:28\n",
      "\n",
      " Average training loss: 0.30\n",
      " Training epcoh took: 0:01:28\n",
      "\n",
      " Average training loss: 0.30\n",
      " Training epcoh took: 0:01:29\n",
      "\n",
      " Average training loss: 0.30\n",
      " Training epcoh took: 0:01:29\n",
      "\n",
      " Average training loss: 0.30\n",
      " Training epcoh took: 0:01:29\n",
      "\n",
      " Average training loss: 0.30\n",
      " Training epcoh took: 0:01:30\n",
      "\n",
      " Average training loss: 0.30\n",
      " Training epcoh took: 0:01:30\n",
      "\n",
      " Average training loss: 0.31\n",
      " Training epcoh took: 0:01:31\n",
      "\n",
      " Average training loss: 0.31\n",
      " Training epcoh took: 0:01:31\n",
      "\n",
      " Average training loss: 0.31\n",
      " Training epcoh took: 0:01:31\n",
      " Batch   240 of   241. Elapsed: 0:01:31.\n",
      "\n",
      " Average training loss: 0.31\n",
      " Training epcoh took: 0:01:32\n",
      "Running Validation...\n",
      " Accuracy: 0.81\n",
      " Validation took: 0:00:00\n",
      "\n",
      " Accuracy: 0.78\n",
      " Validation took: 0:00:00\n",
      "\n",
      " Accuracy: 0.84\n",
      " Validation took: 0:00:00\n",
      "\n",
      " Accuracy: 0.84\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.84\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.84\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 3 / 4 ========\n",
      "Training...\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:00\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:01\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:01\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:02\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:02\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:02\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:03\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:03\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:03\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:04\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:04\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:05\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:05\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:05\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:06\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:06\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:06\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:07\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:07\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:08\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:08\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:08\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:09\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:09\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:10\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:10\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:10\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:11\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:11\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:11\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:12\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:12\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:13\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:13\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:13\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:14\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:14\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:14\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:15\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:15\n",
      " Batch    40 of   241. Elapsed: 0:00:15.\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:16\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:16\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:16\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:17\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:17\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:18\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:18\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:18\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:19\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:19\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:19\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:20\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:20\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:21\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:21\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:21\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:22\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:22\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:22\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:23\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:23\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:24\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:24\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:24\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:25\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:25\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:26\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:26\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:26\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:27\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:27\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:27\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:28\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:28\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:29\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:29\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:29\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:30\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:30\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:30\n",
      " Batch    80 of   241. Elapsed: 0:00:30.\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:31\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:31\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:32\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:32\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:32\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:33\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:33\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:34\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:34\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:34\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:35\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:35\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:35\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:36\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:36\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:37\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:37\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:37\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:38\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:38\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:38\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:39\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:39\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:40\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:40\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:40\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:41\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:41\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:42\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:42\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:42\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:43\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:43\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:43\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:44\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:44\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:45\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:45\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:45\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:46\n",
      " Batch   120 of   241. Elapsed: 0:00:46.\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:46\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:46\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:47\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:47\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:48\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:48\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:48\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:49\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:00:49\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:50\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:50\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:50\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:51\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:51\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:51\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:52\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:52\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:53\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:53\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:53\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:54\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:54\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:00:54\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:55\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:55\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:56\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:56\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:56\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:57\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:57\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:58\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:58\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:58\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:59\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:59\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:00:59\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:00\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:00\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:01\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:01\n",
      " Batch   160 of   241. Elapsed: 0:01:01.\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:01\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:02\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:02\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:02\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:03\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:03\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:04\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:04\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:01:04\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:01:05\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:01:05\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:01:06\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:01:06\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:01:06\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:01:07\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:01:07\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:01:07\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:01:08\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:01:08\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:01:09\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:01:09\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:01:09\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:01:10\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:01:10\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:01:10\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:01:11\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:01:11\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:01:12\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:01:12\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:01:12\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:01:13\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:01:13\n",
      "\n",
      " Average training loss: 0.15\n",
      " Training epcoh took: 0:01:13\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:01:14\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:01:14\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:01:15\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:01:15\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:01:15\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:01:16\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:01:16\n",
      " Batch   200 of   241. Elapsed: 0:01:16.\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:01:17\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:01:17\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:01:17\n",
      "\n",
      " Average training loss: 0.16\n",
      " Training epcoh took: 0:01:18\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:01:18\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:01:18\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:01:19\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:01:19\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:01:20\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:01:20\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:01:20\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:01:21\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:01:21\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:01:21\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:01:22\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:01:22\n",
      "\n",
      " Average training loss: 0.17\n",
      " Training epcoh took: 0:01:23\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:01:23\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:01:23\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:01:24\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:01:24\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:01:25\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:01:25\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:01:25\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:01:26\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:01:26\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:01:26\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:01:27\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:01:27\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:01:28\n",
      "\n",
      " Average training loss: 0.18\n",
      " Training epcoh took: 0:01:28\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:01:28\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:01:29\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:01:29\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:01:29\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:01:30\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:01:30\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:01:31\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:01:31\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:01:31\n",
      " Batch   240 of   241. Elapsed: 0:01:31.\n",
      "\n",
      " Average training loss: 0.19\n",
      " Training epcoh took: 0:01:32\n",
      "Running Validation...\n",
      " Accuracy: 0.75\n",
      " Validation took: 0:00:00\n",
      "\n",
      " Accuracy: 0.77\n",
      " Validation took: 0:00:00\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:00\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.81\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.81\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.80\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.81\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:03\n",
      "\n",
      "======== Epoch 4 / 4 ========\n",
      "Training...\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:00\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:01\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:01\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:02\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:02\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:02\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:03\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:03\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:03\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:04\n",
      "\n",
      " Average training loss: 0.00\n",
      " Training epcoh took: 0:00:04\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:05\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:05\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:05\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:06\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:06\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:06\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:07\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:07\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:08\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:08\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:08\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:09\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:09\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:09\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:10\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:10\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:11\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:11\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:11\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:12\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:12\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:13\n",
      "\n",
      " Average training loss: 0.01\n",
      " Training epcoh took: 0:00:13\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:13\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:14\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:14\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:14\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:15\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:15\n",
      " Batch    40 of   241. Elapsed: 0:00:15.\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:16\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:16\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:16\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:17\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:17\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:17\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:18\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:18\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:19\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:19\n",
      "\n",
      " Average training loss: 0.02\n",
      " Training epcoh took: 0:00:19\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:20\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:20\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:20\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:21\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:21\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:22\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:22\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:22\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:23\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:23\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:24\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:24\n",
      "\n",
      " Average training loss: 0.03\n",
      " Training epcoh took: 0:00:24\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:25\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:25\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:25\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:26\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:26\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:27\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:27\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:27\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:28\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:28\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:28\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:29\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:29\n",
      "\n",
      " Average training loss: 0.04\n",
      " Training epcoh took: 0:00:30\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:30\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:30\n",
      " Batch    80 of   241. Elapsed: 0:00:30.\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:31\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:31\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:32\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:32\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:32\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:33\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:33\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:33\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:34\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:34\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:35\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:35\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:35\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:36\n",
      "\n",
      " Average training loss: 0.05\n",
      " Training epcoh took: 0:00:36\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:36\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:37\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:37\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:38\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:38\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:38\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:39\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:39\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:39\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:40\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:40\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:41\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:41\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:41\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:42\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:42\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:43\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:43\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:43\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:44\n",
      "\n",
      " Average training loss: 0.06\n",
      " Training epcoh took: 0:00:44\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:44\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:45\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:45\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:46\n",
      " Batch   120 of   241. Elapsed: 0:00:46.\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:46\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:46\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:47\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:47\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:47\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:48\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:48\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:49\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:49\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:49\n",
      "\n",
      " Average training loss: 0.07\n",
      " Training epcoh took: 0:00:50\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:50\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:51\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:51\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:51\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:52\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:52\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:52\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:53\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:53\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:54\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:54\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:54\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:55\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:55\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:55\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:56\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:56\n",
      "\n",
      " Average training loss: 0.08\n",
      " Training epcoh took: 0:00:57\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:57\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:57\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:58\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:58\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:59\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:59\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:00:59\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:01:00\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:01:00\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:01:00\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:01:01\n",
      " Batch   160 of   241. Elapsed: 0:01:01.\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:01:01\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:01:02\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:01:02\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:01:02\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:01:03\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:01:03\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:01:03\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:01:04\n",
      "\n",
      " Average training loss: 0.09\n",
      " Training epcoh took: 0:01:04\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:05\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:05\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:05\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:06\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:06\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:06\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:07\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:07\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:08\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:08\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:08\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:09\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:09\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:10\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:10\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:10\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:11\n",
      "\n",
      " Average training loss: 0.10\n",
      " Training epcoh took: 0:01:11\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:11\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:12\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:12\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:13\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:13\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:13\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:14\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:14\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:14\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:15\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:15\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:16\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:16\n",
      " Batch   200 of   241. Elapsed: 0:01:16.\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:16\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:17\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:17\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:18\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:18\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:18\n",
      "\n",
      " Average training loss: 0.11\n",
      " Training epcoh took: 0:01:19\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:19\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:19\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:20\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:20\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:21\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:21\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:21\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:22\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:22\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:22\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:23\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:23\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:24\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:24\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:24\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:25\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:25\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:26\n",
      "\n",
      " Average training loss: 0.12\n",
      " Training epcoh took: 0:01:26\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:26\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:27\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:27\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:27\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:28\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:28\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:29\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:29\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:29\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:30\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:30\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:30\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:31\n",
      "\n",
      " Average training loss: 0.13\n",
      " Training epcoh took: 0:01:31\n",
      " Batch   240 of   241. Elapsed: 0:01:31.\n",
      "\n",
      " Average training loss: 0.14\n",
      " Training epcoh took: 0:01:31\n",
      "Running Validation...\n",
      " Accuracy: 0.78\n",
      " Validation took: 0:00:00\n",
      "\n",
      " Accuracy: 0.78\n",
      " Validation took: 0:00:00\n",
      "\n",
      " Accuracy: 0.84\n",
      " Validation took: 0:00:00\n",
      "\n",
      " Accuracy: 0.84\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.84\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.81\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.84\n",
      " Validation took: 0:00:01\n",
      "\n",
      " Accuracy: 0.84\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.84\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.84\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:02\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.84\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.84\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.84\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.83\n",
      " Validation took: 0:00:03\n",
      "\n",
      " Accuracy: 0.82\n",
      " Validation took: 0:00:03\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    " # ========================================\n",
    " # Training\n",
    " # ========================================\n",
    "\n",
    " # Perform one full pass over the training set. print(\"\")\n",
    " print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    " print('Training...') # Measure how long the training epoch takes.\n",
    " t0 = time.time() # Reset the total loss for this epoch.\n",
    " total_loss = 0 # Put the model into training mode. Don't be mislead--the call to \n",
    " # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    " # `dropout` and `batchnorm` layers behave differently during training\n",
    " # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    " model.train() # For each batch of training data...\n",
    " for step, batch in enumerate(train_dataloader): # Progress update every 40 batches.\n",
    "  if step % 40 == 0 and not step == 0:\n",
    "  # Calculate elapsed time in minutes.\n",
    "    elapsed = format_time(time.time() - t0)\n",
    "\n",
    "    # Report progress.\n",
    "    print(' Batch {:>5,} of {:>5,}. Elapsed: {:}.'.format(step, len(train_dataloader), elapsed)) # Unpack this training batch from our dataloader. \n",
    "  #\n",
    "  # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "  # `to` method.\n",
    "  #\n",
    "  # `batch` contains three pytorch tensors:\n",
    "  # [0]: input ids \n",
    "  # [1]: attention masks\n",
    "  # [2]: labels \n",
    "  b_input_ids = batch[0].to(device)\n",
    "  b_input_mask = batch[1].to(device)\n",
    "  b_labels = batch[2].to(device) # Always clear any previously calculated gradients before performing a\n",
    "  # backward pass. PyTorch doesn't do this automatically because \n",
    "  # accumulating the gradients is \"convenient while training RNNs\". \n",
    "  # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "  model.zero_grad()  # Perform a forward pass (evaluate the model on this training batch).\n",
    "  # This will return the loss (rather than the model output) because we\n",
    "  # have provided the `labels`.\n",
    "  # The documentation for this `model` function is here: \n",
    "  # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "  outputs = model(b_input_ids, \n",
    "  token_type_ids=None, \n",
    "  attention_mask=b_input_mask, \n",
    "  labels=b_labels)\n",
    "\n",
    "  # The call to `model` always returns a tuple, so we need to pull the \n",
    "  # loss value out of the tuple.\n",
    "  loss = outputs[0] # Accumulate the training loss over all of the batches so that we can\n",
    "  # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "  # single value; the `.item()` function just returns the Python value \n",
    "  # from the tensor.\n",
    "  total_loss += loss.item() # Perform a backward pass to calculate the gradients.\n",
    "  loss.backward() # Clip the norm of the gradients to 1.0.\n",
    "  # This is to help prevent the \"exploding gradients\" problem.\n",
    "  torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Update parameters and take a step using the computed gradient.\n",
    "  # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "  # modified based on their gradients, the learning rate, etc.\n",
    "  optimizer.step() # Update the learning rate.\n",
    "  scheduler.step() # Calculate the average loss over the training data.\n",
    "  avg_train_loss = total_loss / len(train_dataloader) \n",
    "\n",
    "  # Store the loss value for plotting the learning curve.\n",
    "  loss_values.append(avg_train_loss)\n",
    "  print(\"\")\n",
    "  print(\" Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "  print(\" Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    " # ========================================\n",
    " # Validation\n",
    " # ========================================\n",
    " # After the completion of each training epoch, measure our performance on\n",
    " # our validation set. print(\"\")\n",
    " print(\"Running Validation...\") \n",
    " t0 = time.time() # Put the model in evaluation mode--the dropout layers behave differently\n",
    " # during evaluation.\n",
    " model.eval() # Tracking variables \n",
    " eval_loss, eval_accuracy = 0, 0\n",
    " nb_eval_steps, nb_eval_examples = 0, 0 # Evaluate data for one epoch\n",
    " for batch in validation_dataloader:\n",
    "\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "  # Telling the model not to compute or store gradients, saving memory and\n",
    "  # speeding up validation\n",
    "  with torch.no_grad():  # Forward pass, calculate logit predictions.\n",
    "    # This will return the logits rather than the loss because we have\n",
    "    # not provided labels.\n",
    "    # token_type_ids is the same as the \"segment ids\", which \n",
    "    # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
    "    # The documentation for this `model` function is here: \n",
    "    # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "    outputs = model(b_input_ids, \n",
    "    token_type_ids=None, \n",
    "    attention_mask=b_input_mask)\n",
    "\n",
    "    # Get the \"logits\" output by the model. The \"logits\" are the output\n",
    "    # values prior to applying an activation function like the softmax.\n",
    "    logits = outputs[0] # Move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    # Calculate the accuracy for this batch of test sentences.\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "\n",
    "    # Accumulate the total accuracy.\n",
    "    eval_accuracy += tmp_eval_accuracy # Track the number of batches\n",
    "    nb_eval_steps += 1 # Report the final accuracy for this validation run.\n",
    "    print(\" Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\" Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "    print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FeFj3dG1--PA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "BmLyo5AW01vV",
    "outputId": "cf3dd333-0f51-4dfd-e389-1f91f076a26b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
       "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
       "            <div id=\"1fc214cf-3bc9-44a0-9dc5-191e37bf48b0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                \n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"1fc214cf-3bc9-44a0-9dc5-191e37bf48b0\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '1fc214cf-3bc9-44a0-9dc5-191e37bf48b0',\n",
       "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"index=%{x}<br>Loss=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963], \"xaxis\": \"x\", \"y\": [0.002785055716502716, 0.005446318521539205, 0.00808567056022739, 0.011011157293042702, 0.013677569840458913, 0.016125611497158826, 0.018417706133419053, 0.020967168926698043, 0.023534480466882224, 0.026092335643610024, 0.028009173039084154, 0.02992618022123313, 0.03311865272858331, 0.03616751885018408, 0.03813438581233203, 0.04110354469524874, 0.04415938703351001, 0.0465313657438112, 0.04913152216381057, 0.05213384150964096, 0.05464879494485024, 0.05711998546271898, 0.059829378894750505, 0.062060683223716454, 0.06443582147483509, 0.066950001038951, 0.06940152177672168, 0.07168976066023482, 0.07328521080036876, 0.07559570027090207, 0.07737277293600976, 0.07922046745961138, 0.08178547272049046, 0.0833703270838963, 0.0861807066127967, 0.08851303364231379, 0.09151411711922325, 0.09358651645450672, 0.0962301944054014, 0.0990081289744476, 0.10091936662484007, 0.10285725942291164, 0.10509262057755497, 0.10749149780055794, 0.10991624566529301, 0.11182155747631278, 0.11415164401422398, 0.11638344793398846, 0.11881462493872741, 0.12103253108337213, 0.12327499557827518, 0.12578248928196697, 0.12805519336486754, 0.1306824666830514, 0.13312485702799565, 0.13503258542401167, 0.13728121021971168, 0.13945523374308194, 0.14143620190284065, 0.14421593499876156, 0.14569241748311212, 0.14790516770232268, 0.149681607222656, 0.15206856623724782, 0.15431025785034622, 0.1560168637279653, 0.15790925814897688, 0.16041220780230162, 0.16233515900200332, 0.16429356136262663, 0.16615009765407357, 0.16818944633749017, 0.17046983818295586, 0.17236604272577277, 0.17414545035955817, 0.1759183409303056, 0.17726710104843393, 0.17892512914056105, 0.18255120045911227, 0.18446257500232996, 0.18595678591134637, 0.1886485165827502, 0.1903574876023526, 0.19240961789590194, 0.19443895769811764, 0.19595518114655838, 0.1989413468916881, 0.20052448088202734, 0.2019594205365636, 0.20423984873838938, 0.2068536538800758, 0.2081880380256542, 0.2105770621804281, 0.21308966011921895, 0.2146108520228833, 0.21626503264755628, 0.21884683825663018, 0.22026752930953789, 0.2222369797991519, 0.22403433214084736, 0.22680281554020293, 0.22904995887605975, 0.23191036277786825, 0.2342315882568043, 0.2366199362327449, 0.23884009103062737, 0.24084722451649265, 0.24263307563496822, 0.24526252637760274, 0.24743791413010402, 0.2499617568190167, 0.2512243665847541, 0.2538237070888899, 0.2559848109963524, 0.2572837011942725, 0.2590136875502796, 0.2610473157953919, 0.2631373022107168, 0.26537971798315085, 0.2679731007433531, 0.26987063451921295, 0.27237113766155796, 0.27422564183033354, 0.27687775569338025, 0.27849929448974575, 0.2807823074556485, 0.28259812177958826, 0.28474058773507716, 0.2865936714089263, 0.28858430022026, 0.29081779532907415, 0.29297981853307037, 0.2949901017905271, 0.2966937735614935, 0.29834179994476284, 0.3003334984245142, 0.3019071039569823, 0.30426778350628264, 0.3061469628850454, 0.30821002061436287, 0.30985310005943806, 0.31143865384996183, 0.313229526350607, 0.315658022382942, 0.3180384580277803, 0.320184547995136, 0.32242375031051795, 0.3234672289171654, 0.3251893035603757, 0.32693428444169864, 0.3287123693964788, 0.33012305070255804, 0.33179848335095957, 0.3341258258493115, 0.3358902139782411, 0.3383709521214497, 0.34013753004093883, 0.34145597390119464, 0.34395759716568153, 0.34611179361204886, 0.3477806474905291, 0.34959215766661395, 0.35149616621341945, 0.35346762842162516, 0.35544199295558376, 0.35745496757297596, 0.35888850911524284, 0.36026926109899626, 0.3625491246642908, 0.3646423092026928, 0.3660731274804634, 0.36813416767911794, 0.369941907552268, 0.3714918365617016, 0.37280808024386647, 0.37516176107018817, 0.3775946020585373, 0.3792534058766741, 0.38111540749359923, 0.38248800786204357, 0.3847417297204995, 0.38625595245618544, 0.38861785130382076, 0.39019849154464437, 0.39185619069827543, 0.39348985025991545, 0.3954699279361741, 0.39689028757736394, 0.3987560029841063, 0.399819986330523, 0.40112011400495823, 0.40247021164142244, 0.4046373173161661, 0.4071107156791133, 0.40872771697914945, 0.4102022018422724, 0.411703977965715, 0.41367172588945916, 0.4154356787313564, 0.41722168405520965, 0.41949914414358336, 0.4214315360017832, 0.42326836281792257, 0.4252432712133495, 0.42739672618782865, 0.4286094918785254, 0.4302047174501221, 0.4328867244027957, 0.4343205679254413, 0.4359450769374974, 0.4377418883855907, 0.43911386513116446, 0.4409373502761002, 0.4423160779278308, 0.44456106782948823, 0.44688658113301544, 0.44842988178443116, 0.45089285230240883, 0.4522795528791752, 0.45378741560140584, 0.4555252492427826, 0.45659896236732295, 0.45859855450535214, 0.4604754012649979, 0.4626004715678108, 0.463791769322518, 0.46553073557580654, 0.46758447840995315, 0.4696215062220562, 0.4716043573692132, 0.4731784915528357, 0.4747751253769111, 0.47650564854570443, 0.4777607416958235, 0.47986380724986066, 0.4817093598397441, 0.4835761885672684, 0.4853271475966046, 0.48721264853022406, 0.4891677850014936, 0.4902159152436553, 0.0014542555165983336, 0.002929401348240643, 0.00501908479389808, 0.006179833560563717, 0.007364159426748505, 0.00862613913923873, 0.010000790426839932, 0.010578503190729133, 0.011424364947184488, 0.013479766571175509, 0.015227146477620137, 0.015841883804293588, 0.01709170045941697, 0.018655340763048513, 0.02002998265240697, 0.02140682842968905, 0.022362905604710718, 0.024018063522968053, 0.025448088391193217, 0.02635123546687399, 0.028052406563303777, 0.029793189521647095, 0.03106960753187599, 0.03321558002119737, 0.03536034854615872, 0.03625676314118492, 0.03706718622648864, 0.037950094000927144, 0.039126942575719845, 0.04016778942707663, 0.04160581158157206, 0.04277802756465817, 0.043971622571410976, 0.044735923965936876, 0.0457657419794328, 0.04629308263543236, 0.04885675087261991, 0.050154129066407926, 0.05175372939634125, 0.052984762921372885, 0.054232756935709246, 0.054926670129368416, 0.055898621183708, 0.05807866279762316, 0.05908364298680017, 0.06049665555172441, 0.06213383327133923, 0.0636657129555817, 0.06523317451051656, 0.06698891947130939, 0.06879610175661031, 0.06993609809034593, 0.07107390104735047, 0.07224380209485524, 0.0738408496889336, 0.0751010782367461, 0.07588896186272633, 0.07691598797982165, 0.07802536731191691, 0.0794632964732736, 0.08130002720474702, 0.08227966911317897, 0.08334158039439268, 0.08436240107439366, 0.08563691235429519, 0.08713220566882138, 0.08768289230176522, 0.08869062135328395, 0.09036389957819736, 0.092064798743893, 0.09329572517842177, 0.09526483646566937, 0.0970847546065002, 0.09865036322368131, 0.09919123827669135, 0.09945242749952182, 0.10080747974116773, 0.10216689857951833, 0.10390960805396321, 0.10467199968846506, 0.10620699909465442, 0.10808665877308589, 0.10934478916320563, 0.1101065258885815, 0.11138267295736495, 0.11239383082172189, 0.11455203809184157, 0.11563157528267856, 0.1169220319180073, 0.11828240851149024, 0.11925250668990661, 0.12011065164047653, 0.12138659924392384, 0.12245871998462439, 0.12302334142918409, 0.12364555246107806, 0.12492208003503158, 0.12650772286153927, 0.12808744937057812, 0.12908948079926344, 0.1299422074155689, 0.13172013297120566, 0.13320346603255054, 0.1347287851250518, 0.135490206020007, 0.1366518691367628, 0.13799337987088564, 0.13995062402175176, 0.14176603521054215, 0.14304177259013862, 0.14428516294946314, 0.14529322155778338, 0.14635093170082916, 0.14739897142307393, 0.1488800367873734, 0.1506281456759362, 0.15292711537408632, 0.15473006572960818, 0.15511827405804915, 0.15646450233904652, 0.15692691103056752, 0.15810329092983388, 0.15898228674756046, 0.15958172249843472, 0.1610037138476906, 0.16197949122343816, 0.16391163415186633, 0.16476370554989303, 0.16633535649519243, 0.16817226777185543, 0.1694550467848283, 0.17059760216113443, 0.17182772640618052, 0.17388860510345316, 0.17540498894032602, 0.1767374721676482, 0.17819046213666434, 0.1789777896587285, 0.180251339473665, 0.18163666815431287, 0.1825510884839964, 0.18406736485938313, 0.18474970665215457, 0.18613197805970536, 0.187031692921868, 0.18821979935485791, 0.18939943735282946, 0.18999680703606348, 0.19154335651160276, 0.19306392639999073, 0.1937858155654179, 0.19490625625824037, 0.1954754845730002, 0.19653226206411464, 0.19723926231079578, 0.19854403197518028, 0.19984886050224304, 0.2013624082957066, 0.2037480567500799, 0.20535529710939812, 0.20708561969990552, 0.20771012687089532, 0.2088570316550148, 0.21005830811761722, 0.21204812435193676, 0.21361178530697011, 0.21460348219297734, 0.2158019837007483, 0.21630389923500323, 0.21767731168581736, 0.21937266242578315, 0.22139939644153683, 0.2223804069072379, 0.22314992216241805, 0.22421854638583433, 0.22511871761924498, 0.22654089037931807, 0.22757777976668228, 0.2292980263280176, 0.2311443013459815, 0.23244950852329802, 0.2344501932070463, 0.23512703665682883, 0.23617312636736518, 0.23747996797329163, 0.23880681423354447, 0.2396431190900783, 0.2409233858043722, 0.2417993000495978, 0.24291028351333627, 0.24383722687781598, 0.245694153443659, 0.24731673581595243, 0.24890865147484784, 0.2498351715474208, 0.25140998920588076, 0.2517384782866324, 0.252936873445867, 0.2545710935632223, 0.2555826472667243, 0.25652602271667657, 0.2572262076297736, 0.25914094402335, 0.2601222626524842, 0.26071451579634086, 0.2612548772848493, 0.26197468140065916, 0.26327859471200415, 0.26487932505696643, 0.26669243392360653, 0.26801331539124373, 0.26995093650590335, 0.2710732177703707, 0.2728856515711274, 0.27378281827289536, 0.274596871182137, 0.2759597470898846, 0.2770923188118519, 0.27772551033012105, 0.2797280273002213, 0.2806616922631798, 0.28156725264683796, 0.28259015404831817, 0.28360606328085747, 0.2846944055121964, 0.28619871013392056, 0.28724619276296054, 0.28890412056594467, 0.2894743698266532, 0.29140827974837846, 0.29247320638158014, 0.2956891052455823, 0.2973430813348145, 0.2984957280742677, 0.2997571071648499, 0.30175939659854684, 0.3034222011002268, 0.3053064777890676, 0.3063987466309575, 0.3078922530427513, 0.30921037501319315, 0.0007112326711045261, 0.0014856061994782128, 0.002403434690598136, 0.003192684338795199, 0.0035532643067886227, 0.0042220294104572155, 0.004906550297103977, 0.005441855283693654, 0.006788394325007047, 0.007412832122126061, 0.008276607794880372, 0.009448781609535217, 0.010437445831002042, 0.011136721340452488, 0.011729187181381764, 0.012642279081819464, 0.014113228227093011, 0.014336659391391327, 0.015220250517006238, 0.015626856647586427, 0.016752004870735263, 0.01757328070050948, 0.01799175436936968, 0.018697762050321982, 0.018881897739602322, 0.019413058966769224, 0.020532286667972185, 0.021727955471183256, 0.0221060242395678, 0.022722040407390516, 0.023756771228620126, 0.024155747284533076, 0.025570576554512087, 0.02709920679632559, 0.027544161096153416, 0.027844722927605956, 0.028323030941713893, 0.029538166102532036, 0.030418650552444932, 0.03160742067449815, 0.03277137869373891, 0.033221343864543805, 0.03392079812609803, 0.03431489439178799, 0.03508944215863572, 0.03601261614763885, 0.03632315477023976, 0.03677327142587836, 0.03759742763156218, 0.03806488491069232, 0.0389267919407346, 0.039380718347195275, 0.04001003865508123, 0.04027196978261362, 0.04140805842594487, 0.04243179317950213, 0.042974439244794646, 0.04369967764714942, 0.04431187509872112, 0.04462754976823617, 0.045334935342869816, 0.04611968341828382, 0.04689001755719363, 0.048565630503462555, 0.050043333893742305, 0.051818046857954554, 0.05283494327696527, 0.05323082193175787, 0.05447522124190548, 0.055127020291520355, 0.05577470396193231, 0.05669573212189299, 0.05759519762147017, 0.0581959295260461, 0.05893844900907817, 0.05985055465050258, 0.060625032610665715, 0.06270598583077988, 0.06387914250376808, 0.06538919476923606, 0.06657180941327479, 0.0669254483152722, 0.06734067671526517, 0.06774377371513003, 0.06864812209645742, 0.06928816505734851, 0.0700951449232972, 0.07045569385235735, 0.07166112260699767, 0.07230677675162113, 0.07315153780072557, 0.07349020001551917, 0.0739112769357891, 0.07430075248123699, 0.07563329704445922, 0.07654252107336314, 0.07768929366377875, 0.07799422311213997, 0.07860149409142768, 0.07961134968085902, 0.07993167583131197, 0.0805475132470309, 0.0812182000440186, 0.0823047792392153, 0.08247826832706008, 0.08285133389145506, 0.0836702306055429, 0.08514829174735239, 0.08595641479823599, 0.086797089713985, 0.08717300693400173, 0.08755586741499881, 0.08968941295418996, 0.09098465106917615, 0.09149145752315205, 0.09185793989674185, 0.09235037118196487, 0.09378821600645904, 0.09410340978891522, 0.09520402513599, 0.09570384572774049, 0.0967962383543802, 0.0969955127732635, 0.09756300643210095, 0.09863455091212794, 0.09912957438109327, 0.10047959819188751, 0.10163132167765214, 0.10366077215654226, 0.10522755369915013, 0.10662427601787064, 0.1071622985805466, 0.10781870289276745, 0.10869596906284573, 0.10968581195997994, 0.109802636244485, 0.11029015586583941, 0.11098390050943462, 0.11199656660626044, 0.11283737618893508, 0.11325150994097048, 0.11401867340956486, 0.11456691204759589, 0.11594270472704622, 0.1163490053219914, 0.11694666022952661, 0.11744642477188862, 0.11875309201567995, 0.11911336783922559, 0.11965712697797791, 0.12085512741101728, 0.12098906302044006, 0.1224412164221908, 0.1227844576525243, 0.12304765432763891, 0.12417889050984779, 0.12537856729260619, 0.12615653874035693, 0.1268250435374337, 0.12772627485552765, 0.1290724461287631, 0.1301183539338379, 0.1303556496084231, 0.13104103958520158, 0.1322489270932694, 0.13240663974673422, 0.13336237091802958, 0.1348254586805694, 0.13518842666784758, 0.1364553256184481, 0.13732813151854698, 0.13831291414209915, 0.14003694225952834, 0.14042664487765044, 0.14154399973166434, 0.14249873901736687, 0.1430790129260651, 0.1432758316057599, 0.14429376455201648, 0.14482895403914928, 0.1460476239285281, 0.14732115247375738, 0.14837372598249882, 0.14969536969708705, 0.15012344753531995, 0.15038694340843878, 0.1511037038538713, 0.1526614112694481, 0.15329873949845796, 0.1537203285920422, 0.15424041708166175, 0.15440537319885744, 0.1549640701024859, 0.15538754731540363, 0.15759555340060555, 0.15841292413685826, 0.15996944959974882, 0.16033459841215758, 0.16066676999647092, 0.16225833693109606, 0.1628273369056555, 0.16337329826290678, 0.1638610408452042, 0.16487740712912746, 0.16536464709092968, 0.16620240762396968, 0.1669672771793678, 0.16753570194437295, 0.16790904726106595, 0.16925333962771902, 0.1695005523187738, 0.17034192591967423, 0.17093364571325512, 0.1716951302318405, 0.17187796788158752, 0.1726638217344571, 0.17409298221167194, 0.1750749433838233, 0.17628994128083292, 0.176551510730596, 0.17733691934171553, 0.17772169836267396, 0.17852016267872944, 0.17949993678086526, 0.18067580830939578, 0.18108642810793338, 0.18177402778470664, 0.18248956126481666, 0.18280018104000706, 0.18353362454109173, 0.184445654749252, 0.18529689823628956, 0.18596440001827552, 0.18711015834044123, 0.1887003194958095, 0.1895491887517737, 0.189942398552949, 0.19077914667265544, 0.1912900341898821, 0.19160310208364642, 0.1930642374849171, 0.00025671765331905413, 0.0006303451646165729, 0.0009766002630049756, 0.0018521461218471843, 0.0021512840267780904, 0.0024579300456274594, 0.002810579071524727, 0.0029695034799981416, 0.0037286072134724295, 0.004606405435385051, 0.0047922819636422075, 0.005724356212185627, 0.006429302695504857, 0.006550180745075352, 0.006674880416932443, 0.006916182788081189, 0.007690093391169156, 0.00856680302451755, 0.008878348650279382, 0.009300856267515555, 0.009462827051452582, 0.009583527956513448, 0.0100812831607597, 0.010818706323002384, 0.011016928896122453, 0.011163233211302657, 0.011371306039362032, 0.011973688324828365, 0.012571420396882964, 0.013233681050944626, 0.013369607743014933, 0.014359328895807266, 0.014641043262486636, 0.014748117380246088, 0.015398953048149085, 0.01560994532902211, 0.016396913120979094, 0.018011217867314074, 0.018172251346571317, 0.018930427621880012, 0.019012625209399774, 0.019839872756810605, 0.021064163413656203, 0.021328504974045693, 0.02139683268747884, 0.022615392147505433, 0.022845650346818305, 0.023040980533445523, 0.023292943757970305, 0.02377835019680969, 0.024914669962715807, 0.02545612881972582, 0.02560116233172753, 0.02575234230994189, 0.026795888930188173, 0.02693885509156587, 0.028217543766706318, 0.028532539722335784, 0.029674343115561237, 0.029875077786410992, 0.03172370149943344, 0.03316919476226652, 0.034272975709552095, 0.034572097569456735, 0.03502472989353896, 0.03512308244976018, 0.03559711194477388, 0.03615395356108786, 0.03643382154405117, 0.03662731395686563, 0.03762140096439613, 0.03841003496586287, 0.03987687979960095, 0.04005394525887808, 0.04128381352547046, 0.04260657241575698, 0.04442378744884893, 0.04494088318554445, 0.04518118875557209, 0.045309467975405734, 0.045982302147199505, 0.04666249934753936, 0.047145476216968164, 0.04730578881390857, 0.04747048259956214, 0.048043590842811894, 0.048942167342822085, 0.04903524591591348, 0.04913714023391983, 0.04965040139482971, 0.050052306827358686, 0.05109735061240642, 0.05251758411928579, 0.05331718352047487, 0.05434572423858514, 0.05505634713686106, 0.0554854643156296, 0.05619512809850121, 0.05694064716673244, 0.057094787622326636, 0.057836577195782383, 0.05874454179832797, 0.05913354539123066, 0.05921981201596033, 0.05954101161559835, 0.06098079866115236, 0.06130486664157438, 0.06164100978724442, 0.061863443872184176, 0.062008126820456935, 0.0627586146530645, 0.06284257742533793, 0.06343260800844654, 0.0641607588149329, 0.06484333797516417, 0.06493715290366614, 0.06558315286652429, 0.06660283413325355, 0.06718179148417043, 0.06725887077014228, 0.067617464802881, 0.06774033403557365, 0.0684381120092394, 0.06981270925694481, 0.07011532859250717, 0.07111693963532131, 0.07121716086516984, 0.07258196551491858, 0.07352098537400303, 0.07378534990443976, 0.07434928719402596, 0.07512077991367623, 0.07649662972454956, 0.07695151728682251, 0.07758361403347298, 0.0778065022792188, 0.07879696725345993, 0.07957743041031835, 0.07978580223543268, 0.08228315647181386, 0.08242983674761913, 0.08250023980327414, 0.08264162863654961, 0.08278099656939754, 0.08345526218012408, 0.08360359823153474, 0.08370158857669821, 0.08378536330682855, 0.08400468481124931, 0.08551951373359228, 0.08614200176632503, 0.08646186746471403, 0.0870251727843062, 0.0871245420897279, 0.08816667143023607, 0.08831782772735194, 0.08847391079044688, 0.08906352092585376, 0.08981954030445255, 0.08997998984059111, 0.09030593076094799, 0.09054488533358108, 0.09140422763264278, 0.09242990751329547, 0.09255092866966091, 0.09266535172633115, 0.09340670663105996, 0.09397006537224248, 0.09486154286013104, 0.09505562252399832, 0.09573870461387753, 0.09739529996863044, 0.09749214891421597, 0.09804826470176956, 0.0982021455154503, 0.09889450812271769, 0.0993245772445474, 0.10010458829646536, 0.10021986765207344, 0.10090996540650045, 0.10128401756997672, 0.10144686495645659, 0.10157625489246054, 0.10166310529027489, 0.1019287018561388, 0.10358646049075354, 0.10397194759510613, 0.10546826717300781, 0.10563690805058014, 0.10653332777754153, 0.10718350290973899, 0.10734902831621437, 0.1076885135882994, 0.10784698058986318, 0.10798953443425573, 0.10873698545967642, 0.10918487207307113, 0.10978689419561649, 0.11060994041936774, 0.1114796740833778, 0.11184105324207252, 0.11212034700477025, 0.11238213307784553, 0.11249350923349254, 0.11303369252637215, 0.11358747563297818, 0.11451865729578303, 0.1155115073214428, 0.1156864291466618, 0.11635224530434707, 0.11753521126953893, 0.11775922010115568, 0.1179886750134937, 0.11868516072878205, 0.11933700516201648, 0.11954642481390866, 0.11959133791849326, 0.11998432927235528, 0.12022604338855664, 0.12072782113344342, 0.1212603297718333, 0.12158137711375581, 0.12289579728950603, 0.123395990935846, 0.12424504426134078, 0.1243560918958479, 0.12626235552626774, 0.12746580619813247, 0.12798648319087336, 0.12816734957466233, 0.12841701536164987, 0.12914906953040248, 0.13002926016156852, 0.13078982284856783, 0.13095724037790446, 0.13133910118266012, 0.1315984600668008, 0.13279455463514042, 0.133010331533571, 0.13433566752094697, 0.1352831619362737], \"yaxis\": \"y\"}],\n",
       "                        {\"legend\": {\"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Training loss of the Model\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Epoch\"}}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"title\": {\"text\": \"Loss\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('1fc214cf-3bc9-44a0-9dc5-191e37bf48b0');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                \n",
       "            </script>\n",
       "        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "f = pd.DataFrame(loss_values)\n",
    "f.columns=['Loss']\n",
    "fig = px.line(f, x=f.index, y=f.Loss)\n",
    "fig.update_layout(title='Training loss of the Model',\n",
    "                   xaxis_title='Epoch',\n",
    "                   yaxis_title='Loss')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "yh6pMDA50_mt",
    "outputId": "dfc36b74-31e8-4252-bd19-83086c208ef7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test sentences: 516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the dataset into a pandas dataframe.\n",
    "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
    "# Report the number of sentences.\n",
    "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
    "# Create sentence and label lists\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    encoded_sent = tokenizer.encode(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                   )\n",
    "    \n",
    "    input_ids.append(encoded_sent)\n",
    "# Pad our input tokens\n",
    "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, \n",
    "                          dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "# Create attention masks\n",
    "attention_masks = []\n",
    "# Create a mask of 1s for each token followed by 0s for padding\n",
    "for seq in input_ids:\n",
    "  seq_mask = [float(i>0) for i in seq]\n",
    "  attention_masks.append(seq_mask) \n",
    "# Convert to tensors.\n",
    "prediction_inputs = torch.tensor(input_ids)\n",
    "prediction_masks = torch.tensor(attention_masks)\n",
    "prediction_labels = torch.tensor(labels)\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(prediction_inputs, prediction_masks, prediction_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "23nQBbJR1Ci0",
    "outputId": "149e5301-181e-4ed0-dd9a-834643be4487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 516 test sentences...\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "# Prediction on test set\n",
    "print('Predicting labels for {:,} test sentences...'.format(len(prediction_inputs)))\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "  logits = outputs[0]\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "print('DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KXfnLnD41K0d",
    "outputId": "3f2b2be4-c912-4112-d8f8-aa1de135b932"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive samples: 354 of 516 (68.60%)\n"
     ]
    }
   ],
   "source": [
    "print('Positive samples: %d of %d (%.2f%%)' % (df.label.sum(), len(df.label), (df.label.sum() / len(df.label) * 100.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "ym7m_LnL1O9h",
    "outputId": "69b737ba-4d4b-4c37-91b8-bdf4df41b042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Matthews Corr. Coef. for each batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:900: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in double_scalars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_set = []\n",
    "# Evaluate each test batch using Matthew's correlation coefficient\n",
    "print('Calculating Matthews Corr. Coef. for each batch...')\n",
    "# For each input batch...\n",
    "for i in range(len(true_labels)):\n",
    "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
    "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
    "  # in to a list of 0s and 1s.\n",
    "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
    "  \n",
    "  # Calculate and store the coef for this batch.  \n",
    "  try:\n",
    "    matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
    "    matthews_set.append(matthews)\n",
    "  except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "kanXctZX7Vqx",
    "outputId": "ebe70fab-80cd-4089-e103-d84204cf6ed1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCC: 0.561\n"
     ]
    }
   ],
   "source": [
    "# Combine the predictions for each batch into a single list of 0s and 1s.\n",
    "flat_predictions = [item for sublist in predictions for item in sublist]\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "print('MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ug1C_Vtr-irE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KgRoWb3B-itb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "colab_type": "code",
    "id": "w5DamtCt-ivq",
    "outputId": "b0100de6-f401-4fe3-9e00-48d9c5384fdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-01 13:59:33--  https://raw.githubusercontent.com/huggingface/transformers/master/examples/run_language_modeling.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 34311 (34K) [text/plain]\n",
      "Saving to: ‘run_language_modeling.py’\n",
      "\n",
      "\r",
      "run_language_modeli   0%[                    ]       0  --.-KB/s               \r",
      "run_language_modeli 100%[===================>]  33.51K  --.-KB/s    in 0.005s  \n",
      "\n",
      "2020-04-01 13:59:33 (7.20 MB/s) - ‘run_language_modeling.py’ saved [34311/34311]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/huggingface/transformers/master/examples/run_language_modeling.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "colab_type": "code",
    "id": "BmoLcF1D-ix4",
    "outputId": "3591e59e-932d-433e-a6cb-e9d130f5d3f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-01 14:09:08--  https://raw.githubusercontent.com/interactive-fiction-class/interactive-fiction-class.github.io/master/homeworks/language-model/presidential_speeches_test.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 622537 (608K) [text/plain]\n",
      "Saving to: ‘/content/presidential_speeches_test.txt’\n",
      "\n",
      "\r",
      "          /content/   0%[                    ]       0  --.-KB/s               \r",
      "/content/presidenti 100%[===================>] 607.95K  --.-KB/s    in 0.02s   \n",
      "\n",
      "2020-04-01 14:09:08 (25.8 MB/s) - ‘/content/presidential_speeches_test.txt’ saved [622537/622537]\n",
      "\n",
      "--2020-04-01 14:09:11--  https://raw.githubusercontent.com/interactive-fiction-class/interactive-fiction-class.github.io/master/homeworks/language-model/presidential_speeches_valid.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1117165 (1.1M) [text/plain]\n",
      "Saving to: ‘/content/presidential_speeches_valid.txt’\n",
      "\n",
      "/content/presidenti 100%[===================>]   1.06M  --.-KB/s    in 0.04s   \n",
      "\n",
      "2020-04-01 14:09:11 (24.1 MB/s) - ‘/content/presidential_speeches_valid.txt’ saved [1117165/1117165]\n",
      "\n",
      "--2020-04-01 14:09:13--  https://raw.githubusercontent.com/interactive-fiction-class/interactive-fiction-class.github.io/master/homeworks/language-model/presidential_speeches_train.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20269025 (19M) [text/plain]\n",
      "Saving to: ‘/content/presidential_speeches_train.txt’\n",
      "\n",
      "/content/presidenti 100%[===================>]  19.33M  --.-KB/s    in 0.09s   \n",
      "\n",
      "2020-04-01 14:09:14 (224 MB/s) - ‘/content/presidential_speeches_train.txt’ saved [20269025/20269025]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -nc -O /content/presidential_speeches_test.txt https://raw.githubusercontent.com/interactive-fiction-class/interactive-fiction-class.github.io/master/homeworks/language-model/presidential_speeches_test.txt\n",
    "!wget -nc -O /content/presidential_speeches_valid.txt https://raw.githubusercontent.com/interactive-fiction-class/interactive-fiction-class.github.io/master/homeworks/language-model/presidential_speeches_valid.txt\n",
    "!wget -nc -O /content/presidential_speeches_train.txt https://raw.githubusercontent.com/interactive-fiction-class/interactive-fiction-class.github.io/master/homeworks/language-model/presidential_speeches_train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BgVzjfOcCAt9",
    "outputId": "9cf8fd70-3add-4413-ab7d-f2ec5c44201a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "\n",
      "Evaluating:  36% 312/871 [00:22<00:40, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  36% 314/871 [00:22<00:40, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  36% 316/871 [00:22<00:39, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  37% 318/871 [00:22<00:39, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  37% 320/871 [00:23<00:40, 13.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  37% 322/871 [00:23<00:39, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  37% 324/871 [00:23<00:39, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  37% 326/871 [00:23<00:39, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  38% 328/871 [00:23<00:39, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  38% 330/871 [00:23<00:38, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  38% 332/871 [00:24<00:39, 13.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  38% 334/871 [00:24<00:38, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  39% 336/871 [00:24<00:38, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  39% 338/871 [00:24<00:38, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  39% 340/871 [00:24<00:38, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  39% 342/871 [00:24<00:37, 13.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  39% 344/871 [00:24<00:37, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  40% 346/871 [00:25<00:37, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  40% 348/871 [00:25<00:37, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  40% 350/871 [00:25<00:37, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  40% 352/871 [00:25<00:37, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  41% 354/871 [00:25<00:37, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  41% 356/871 [00:25<00:37, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  41% 358/871 [00:25<00:36, 13.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  41% 360/871 [00:26<00:36, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  42% 362/871 [00:26<00:36, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  42% 364/871 [00:26<00:36, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  42% 366/871 [00:26<00:36, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  42% 368/871 [00:26<00:36, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  42% 370/871 [00:26<00:36, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  43% 372/871 [00:26<00:35, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  43% 374/871 [00:27<00:35, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  43% 376/871 [00:27<00:35, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  43% 378/871 [00:27<00:35, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  44% 380/871 [00:27<00:35, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  44% 382/871 [00:27<00:35, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  44% 384/871 [00:27<00:35, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  44% 386/871 [00:27<00:35, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  45% 388/871 [00:28<00:34, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  45% 390/871 [00:28<00:34, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  45% 392/871 [00:28<00:34, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  45% 394/871 [00:28<00:34, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  45% 396/871 [00:28<00:34, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  46% 398/871 [00:28<00:34, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  46% 400/871 [00:28<00:34, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  46% 402/871 [00:29<00:33, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  46% 404/871 [00:29<00:33, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  47% 406/871 [00:29<00:33, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  47% 408/871 [00:29<00:33, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  47% 410/871 [00:29<00:33, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  47% 412/871 [00:29<00:32, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  48% 414/871 [00:29<00:32, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  48% 416/871 [00:30<00:32, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  48% 418/871 [00:30<00:32, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  48% 420/871 [00:30<00:32, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  48% 422/871 [00:30<00:32, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  49% 424/871 [00:30<00:32, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  49% 426/871 [00:30<00:32, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  49% 428/871 [00:30<00:32, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  49% 430/871 [00:31<00:31, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  50% 432/871 [00:31<00:31, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  50% 434/871 [00:31<00:31, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  50% 436/871 [00:31<00:31, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  50% 438/871 [00:31<00:31, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  51% 440/871 [00:31<00:31, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  51% 442/871 [00:31<00:31, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  51% 444/871 [00:32<00:30, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  51% 446/871 [00:32<00:30, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  51% 448/871 [00:32<00:30, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  52% 450/871 [00:32<00:30, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  52% 452/871 [00:32<00:30, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  52% 454/871 [00:32<00:29, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  52% 456/871 [00:32<00:29, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  53% 458/871 [00:33<00:30, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  53% 460/871 [00:33<00:29, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  53% 462/871 [00:33<00:29, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  53% 464/871 [00:33<00:29, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  54% 466/871 [00:33<00:29, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  54% 468/871 [00:33<00:29, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  54% 470/871 [00:33<00:28, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  54% 472/871 [00:34<00:28, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  54% 474/871 [00:34<00:28, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  55% 476/871 [00:34<00:28, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  55% 478/871 [00:34<00:28, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  55% 480/871 [00:34<00:28, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  55% 482/871 [00:34<00:28, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  56% 484/871 [00:34<00:27, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  56% 486/871 [00:35<00:28, 13.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  56% 488/871 [00:35<00:27, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  56% 490/871 [00:35<00:27, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  56% 492/871 [00:35<00:27, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  57% 494/871 [00:35<00:27, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  57% 496/871 [00:35<00:27, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  57% 498/871 [00:36<00:26, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  57% 500/871 [00:36<00:26, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  58% 502/871 [00:36<00:26, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  58% 504/871 [00:36<00:26, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  58% 506/871 [00:36<00:26, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  58% 508/871 [00:36<00:26, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  59% 510/871 [00:36<00:25, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  59% 512/871 [00:37<00:26, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  59% 514/871 [00:37<00:25, 13.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  59% 516/871 [00:37<00:25, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  59% 518/871 [00:37<00:25, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  60% 520/871 [00:37<00:25, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  60% 522/871 [00:37<00:25, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  60% 524/871 [00:37<00:25, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  60% 526/871 [00:38<00:25, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  61% 528/871 [00:38<00:24, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  61% 530/871 [00:38<00:24, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  61% 532/871 [00:38<00:24, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  61% 534/871 [00:38<00:24, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  62% 536/871 [00:38<00:24, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  62% 538/871 [00:38<00:24, 13.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  62% 540/871 [00:39<00:23, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  62% 542/871 [00:39<00:23, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  62% 544/871 [00:39<00:23, 13.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  63% 546/871 [00:39<00:23, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  63% 548/871 [00:39<00:23, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  63% 550/871 [00:39<00:23, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  63% 552/871 [00:39<00:23, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  64% 554/871 [00:40<00:22, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  64% 556/871 [00:40<00:22, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  64% 558/871 [00:40<00:22, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  64% 560/871 [00:40<00:22, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  65% 562/871 [00:40<00:22, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  65% 564/871 [00:40<00:22, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  65% 566/871 [00:40<00:22, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  65% 568/871 [00:41<00:21, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  65% 570/871 [00:41<00:21, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  66% 572/871 [00:41<00:21, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  66% 574/871 [00:41<00:21, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  66% 576/871 [00:41<00:21, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  66% 578/871 [00:41<00:21, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  67% 580/871 [00:41<00:20, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  67% 582/871 [00:42<00:20, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  67% 584/871 [00:42<00:20, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  67% 586/871 [00:42<00:20, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  68% 588/871 [00:42<00:20, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  68% 590/871 [00:42<00:20, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  68% 592/871 [00:42<00:20, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  68% 594/871 [00:42<00:20, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  68% 596/871 [00:43<00:19, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  69% 598/871 [00:43<00:19, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  69% 600/871 [00:43<00:19, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  69% 602/871 [00:43<00:19, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  69% 604/871 [00:43<00:19, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  70% 606/871 [00:43<00:19, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  70% 608/871 [00:43<00:19, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  70% 610/871 [00:44<00:18, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  70% 612/871 [00:44<00:18, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  70% 614/871 [00:44<00:18, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  71% 616/871 [00:44<00:18, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  71% 618/871 [00:44<00:18, 13.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  71% 620/871 [00:44<00:18, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  71% 622/871 [00:44<00:17, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  72% 624/871 [00:45<00:17, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  72% 626/871 [00:45<00:17, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  72% 628/871 [00:45<00:17, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  72% 630/871 [00:45<00:17, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  73% 632/871 [00:45<00:17, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  73% 634/871 [00:45<00:17, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  73% 636/871 [00:45<00:16, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  73% 638/871 [00:46<00:16, 13.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  73% 640/871 [00:46<00:16, 14.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  74% 642/871 [00:46<00:16, 14.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  74% 644/871 [00:46<00:16, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  74% 646/871 [00:46<00:16, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  74% 648/871 [00:46<00:16, 13.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  75% 650/871 [00:46<00:15, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  75% 652/871 [00:47<00:15, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  75% 654/871 [00:47<00:15, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  75% 656/871 [00:47<00:15, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  76% 658/871 [00:47<00:15, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  76% 660/871 [00:47<00:15, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  76% 662/871 [00:47<00:15, 13.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  76% 664/871 [00:47<00:14, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  76% 666/871 [00:48<00:14, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  77% 668/871 [00:48<00:14, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  77% 670/871 [00:48<00:14, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  77% 672/871 [00:48<00:14, 13.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  77% 674/871 [00:48<00:14, 13.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  78% 676/871 [00:48<00:14, 13.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  78% 678/871 [00:49<00:13, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  78% 680/871 [00:49<00:13, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  78% 682/871 [00:49<00:13, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  79% 684/871 [00:49<00:13, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  79% 686/871 [00:49<00:13, 13.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  79% 688/871 [00:49<00:13, 13.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  79% 690/871 [00:49<00:13, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  79% 692/871 [00:50<00:12, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  80% 694/871 [00:50<00:12, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  80% 696/871 [00:50<00:12, 13.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  80% 698/871 [00:50<00:12, 13.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  80% 700/871 [00:50<00:12, 13.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  81% 702/871 [00:50<00:12, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  81% 704/871 [00:50<00:12, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  81% 706/871 [00:51<00:12, 13.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  81% 708/871 [00:51<00:11, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  82% 710/871 [00:51<00:11, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  82% 712/871 [00:51<00:11, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  82% 714/871 [00:51<00:11, 13.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  82% 716/871 [00:51<00:11, 13.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  82% 718/871 [00:51<00:11, 13.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  83% 720/871 [00:52<00:10, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  83% 722/871 [00:52<00:10, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  83% 724/871 [00:52<00:10, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  83% 726/871 [00:52<00:10, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  84% 728/871 [00:52<00:10, 13.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  84% 730/871 [00:52<00:10, 13.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  84% 732/871 [00:52<00:10, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  84% 734/871 [00:53<00:09, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  85% 736/871 [00:53<00:09, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  85% 738/871 [00:53<00:09, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  85% 740/871 [00:53<00:09, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  85% 742/871 [00:53<00:09, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  85% 744/871 [00:53<00:09, 13.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  86% 746/871 [00:53<00:08, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  86% 748/871 [00:54<00:08, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  86% 750/871 [00:54<00:08, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  86% 752/871 [00:54<00:08, 13.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  87% 754/871 [00:54<00:08, 13.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  87% 756/871 [00:54<00:08, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  87% 758/871 [00:54<00:08, 13.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  87% 760/871 [00:54<00:08, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  87% 762/871 [00:55<00:07, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  88% 764/871 [00:55<00:07, 13.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  88% 766/871 [00:55<00:07, 13.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  88% 768/871 [00:55<00:07, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  88% 770/871 [00:55<00:07, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  89% 772/871 [00:55<00:07, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  89% 774/871 [00:55<00:07, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  89% 776/871 [00:56<00:06, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  89% 778/871 [00:56<00:06, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  90% 780/871 [00:56<00:06, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  90% 782/871 [00:56<00:06, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  90% 784/871 [00:56<00:06, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  90% 786/871 [00:56<00:06, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  90% 788/871 [00:56<00:06, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  91% 790/871 [00:57<00:05, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  91% 792/871 [00:57<00:05, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  91% 794/871 [00:57<00:05, 13.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  91% 796/871 [00:57<00:05, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  92% 798/871 [00:57<00:05, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  92% 800/871 [00:57<00:05, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  92% 802/871 [00:57<00:05, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  92% 804/871 [00:58<00:04, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  93% 806/871 [00:58<00:04, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  93% 808/871 [00:58<00:04, 13.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  93% 810/871 [00:58<00:04, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  93% 812/871 [00:58<00:04, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  93% 814/871 [00:58<00:04, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  94% 816/871 [00:58<00:04, 13.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  94% 818/871 [00:59<00:03, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  94% 820/871 [00:59<00:03, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  94% 822/871 [00:59<00:03, 13.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  95% 824/871 [00:59<00:03, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  95% 826/871 [00:59<00:03, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  95% 828/871 [00:59<00:03, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  95% 830/871 [00:59<00:02, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  96% 832/871 [01:00<00:02, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  96% 834/871 [01:00<00:02, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  96% 836/871 [01:00<00:02, 13.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  96% 838/871 [01:00<00:02, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  96% 840/871 [01:00<00:02, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  97% 842/871 [01:00<00:02, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  97% 844/871 [01:00<00:01, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  97% 846/871 [01:01<00:01, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  97% 848/871 [01:01<00:01, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  98% 850/871 [01:01<00:01, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  98% 852/871 [01:01<00:01, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  98% 854/871 [01:01<00:01, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  98% 856/871 [01:01<00:01, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  99% 858/871 [01:02<00:00, 13.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  99% 860/871 [01:02<00:00, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  99% 862/871 [01:02<00:00, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  99% 864/871 [01:02<00:00, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  99% 866/871 [01:02<00:00, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating: 100% 868/871 [01:02<00:00, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating: 100% 871/871 [01:02<00:00, 13.84it/s]\n",
      "04/01/2020 15:13:58 - INFO - __main__ -   ***** Eval results  *****\n",
      "04/01/2020 15:13:58 - INFO - __main__ -     perplexity = tensor(20.1480)\n",
      "04/01/2020 15:13:58 - INFO - transformers.configuration_utils -   Configuration saved in /content/drive/My Drive/finetuned_models/presidential_speeches/checkpoint-2500/config.json\n",
      "04/01/2020 15:14:06 - INFO - transformers.modeling_utils -   Model weights saved in /content/drive/My Drive/finetuned_models/presidential_speeches/checkpoint-2500/pytorch_model.bin\n",
      "04/01/2020 15:14:07 - INFO - __main__ -   Saving model checkpoint to /content/drive/My Drive/finetuned_models/presidential_speeches/checkpoint-2500\n",
      "04/01/2020 15:15:17 - INFO - __main__ -   Saving optimizer and scheduler states to /content/drive/My Drive/finetuned_models/presidential_speeches/checkpoint-2500\n",
      "\n",
      "Iteration:  79% 12500/15836 [1:04:09<39:43:19, 42.87s/it]\u001b[A\n",
      "Iteration:  79% 12501/15836 [1:04:10<27:52:15, 30.09s/it]\u001b[A\n",
      "Iteration:  79% 12502/15836 [1:04:10<19:33:44, 21.12s/it]\u001b[A\n",
      "Iteration:  79% 12503/15836 [1:04:10<13:44:54, 14.85s/it]\u001b[A\n",
      "Iteration:  79% 12504/15836 [1:04:10<9:40:46, 10.46s/it] \u001b[A\n",
      "Iteration:  79% 12505/15836 [1:04:11<6:52:27,  7.43s/it]\u001b[A\n",
      "Iteration:  79% 12506/15836 [1:04:11<4:52:18,  5.27s/it]\u001b[A\n",
      "Iteration:  79% 12507/15836 [1:04:11<3:28:08,  3.75s/it]\u001b[A\n",
      "Iteration:  79% 12508/15836 [1:04:11<2:29:11,  2.69s/it]\u001b[A\n",
      "Iteration:  79% 12509/15836 [1:04:12<1:48:06,  1.95s/it]\u001b[A\n",
      "Iteration:  79% 12510/15836 [1:04:12<1:21:36,  1.47s/it]\u001b[A\n",
      "Iteration:  79% 12511/15836 [1:04:12<1:00:39,  1.09s/it]\u001b[A\n",
      "Iteration:  79% 12512/15836 [1:04:12<46:00,  1.20it/s]  \u001b[A\n",
      "Iteration:  79% 12513/15836 [1:04:13<35:53,  1.54it/s]\u001b[A\n",
      "Iteration:  79% 12514/15836 [1:04:13<28:48,  1.92it/s]\u001b[A\n",
      "Iteration:  79% 12515/15836 [1:04:13<26:05,  2.12it/s]\u001b[A\n",
      "Iteration:  79% 12516/15836 [1:04:13<21:45,  2.54it/s]\u001b[A\n",
      "Iteration:  79% 12517/15836 [1:04:14<18:53,  2.93it/s]\u001b[A\n",
      "Iteration:  79% 12518/15836 [1:04:14<16:54,  3.27it/s]\u001b[A\n",
      "Iteration:  79% 12519/15836 [1:04:14<15:29,  3.57it/s]\u001b[A\n",
      "Iteration:  79% 12520/15836 [1:04:14<16:46,  3.29it/s]\u001b[A\n",
      "Iteration:  79% 12521/15836 [1:04:15<15:18,  3.61it/s]\u001b[A\n",
      "Iteration:  79% 12522/15836 [1:04:15<14:22,  3.84it/s]\u001b[A\n",
      "Iteration:  79% 12523/15836 [1:04:15<13:45,  4.01it/s]\u001b[A\n",
      "Iteration:  79% 12524/15836 [1:04:15<13:22,  4.13it/s]\u001b[A\n",
      "Iteration:  79% 12525/15836 [1:04:16<15:17,  3.61it/s]\u001b[A\n",
      "Iteration:  79% 12526/15836 [1:04:16<14:13,  3.88it/s]\u001b[A\n",
      "Iteration:  79% 12527/15836 [1:04:16<13:32,  4.07it/s]\u001b[A\n",
      "Iteration:  79% 12528/15836 [1:04:16<13:09,  4.19it/s]\u001b[A\n",
      "Iteration:  79% 12529/15836 [1:04:17<12:56,  4.26it/s]\u001b[A\n",
      "Iteration:  79% 12530/15836 [1:04:17<14:57,  3.68it/s]\u001b[A\n",
      "Iteration:  79% 12531/15836 [1:04:17<14:01,  3.93it/s]\u001b[A\n",
      "Iteration:  79% 12532/15836 [1:04:17<13:27,  4.09it/s]\u001b[A\n",
      "Iteration:  79% 12533/15836 [1:04:18<13:07,  4.19it/s]\u001b[A\n",
      "Iteration:  79% 12534/15836 [1:04:18<12:50,  4.29it/s]\u001b[A\n",
      "Iteration:  79% 12535/15836 [1:04:18<14:52,  3.70it/s]\u001b[A\n",
      "Iteration:  79% 12536/15836 [1:04:18<14:05,  3.91it/s]\u001b[A\n",
      "Iteration:  79% 12537/15836 [1:04:19<13:33,  4.06it/s]\u001b[A\n",
      "Iteration:  79% 12538/15836 [1:04:19<13:12,  4.16it/s]\u001b[A\n",
      "Iteration:  79% 12539/15836 [1:04:19<12:58,  4.23it/s]\u001b[A\n",
      "Iteration:  79% 12540/15836 [1:04:19<15:00,  3.66it/s]\u001b[A\n",
      "Iteration:  79% 12541/15836 [1:04:20<14:08,  3.88it/s]\u001b[A\n",
      "Iteration:  79% 12542/15836 [1:04:20<13:30,  4.06it/s]\u001b[A\n",
      "Iteration:  79% 12543/15836 [1:04:20<13:07,  4.18it/s]\u001b[A\n",
      "Iteration:  79% 12544/15836 [1:04:20<12:55,  4.24it/s]\u001b[A\n",
      "Iteration:  79% 12545/15836 [1:04:21<14:55,  3.67it/s]\u001b[A\n",
      "Iteration:  79% 12546/15836 [1:04:21<14:04,  3.90it/s]\u001b[A\n",
      "Iteration:  79% 12547/15836 [1:04:21<13:35,  4.04it/s]\u001b[A\n",
      "Iteration:  79% 12548/15836 [1:04:21<13:14,  4.14it/s]\u001b[A\n",
      "Iteration:  79% 12549/15836 [1:04:22<13:03,  4.20it/s]\u001b[A\n",
      "Iteration:  79% 12550/15836 [1:04:22<15:04,  3.63it/s]\u001b[A\n",
      "Iteration:  79% 12551/15836 [1:04:22<14:09,  3.87it/s]\u001b[A\n",
      "Iteration:  79% 12552/15836 [1:04:22<13:34,  4.03it/s]\u001b[A\n",
      "Iteration:  79% 12553/15836 [1:04:23<13:12,  4.14it/s]\u001b[A\n",
      "Iteration:  79% 12554/15836 [1:04:23<13:00,  4.20it/s]\u001b[A\n",
      "Iteration:  79% 12555/15836 [1:04:23<15:05,  3.62it/s]\u001b[A\n",
      "Iteration:  79% 12556/15836 [1:04:23<14:07,  3.87it/s]\u001b[A\n",
      "Iteration:  79% 12557/15836 [1:04:24<13:37,  4.01it/s]\u001b[A\n",
      "Iteration:  79% 12558/15836 [1:04:24<13:20,  4.09it/s]\u001b[A\n",
      "Iteration:  79% 12559/15836 [1:04:24<13:05,  4.17it/s]\u001b[A\n",
      "Iteration:  79% 12560/15836 [1:04:24<15:05,  3.62it/s]\u001b[A\n",
      "Iteration:  79% 12561/15836 [1:04:25<14:13,  3.84it/s]\u001b[A\n",
      "Iteration:  79% 12562/15836 [1:04:25<13:40,  3.99it/s]\u001b[A\n",
      "Iteration:  79% 12563/15836 [1:04:25<13:23,  4.07it/s]\u001b[A\n",
      "Iteration:  79% 12564/15836 [1:04:25<13:07,  4.16it/s]\u001b[A\n",
      "Iteration:  79% 12565/15836 [1:04:26<15:07,  3.60it/s]\u001b[A\n",
      "Iteration:  79% 12566/15836 [1:04:26<14:09,  3.85it/s]\u001b[A\n",
      "Iteration:  79% 12567/15836 [1:04:26<13:37,  4.00it/s]\u001b[A\n",
      "Iteration:  79% 12568/15836 [1:04:26<13:15,  4.11it/s]\u001b[A\n",
      "Iteration:  79% 12569/15836 [1:04:27<13:06,  4.15it/s]\u001b[A\n",
      "Iteration:  79% 12570/15836 [1:04:27<15:03,  3.61it/s]\u001b[A\n",
      "Iteration:  79% 12571/15836 [1:04:27<14:13,  3.83it/s]\u001b[A\n",
      "Iteration:  79% 12572/15836 [1:04:27<13:40,  3.98it/s]\u001b[A\n",
      "Iteration:  79% 12573/15836 [1:04:28<13:20,  4.07it/s]\u001b[A\n",
      "Iteration:  79% 12574/15836 [1:04:28<13:07,  4.14it/s]\u001b[A\n",
      "Iteration:  79% 12575/15836 [1:04:28<15:08,  3.59it/s]\u001b[A\n",
      "Iteration:  79% 12576/15836 [1:04:29<14:16,  3.81it/s]\u001b[A\n",
      "Iteration:  79% 12577/15836 [1:04:29<13:48,  3.93it/s]\u001b[A\n",
      "Iteration:  79% 12578/15836 [1:04:29<13:20,  4.07it/s]\u001b[A\n",
      "Iteration:  79% 12579/15836 [1:04:29<13:12,  4.11it/s]\u001b[A\n",
      "Iteration:  79% 12580/15836 [1:04:30<15:08,  3.58it/s]\u001b[A\n",
      "Iteration:  79% 12581/15836 [1:04:30<14:19,  3.79it/s]\u001b[A\n",
      "Iteration:  79% 12582/15836 [1:04:30<13:41,  3.96it/s]\u001b[A\n",
      "Iteration:  79% 12583/15836 [1:04:30<13:29,  4.02it/s]\u001b[A\n",
      "Iteration:  79% 12584/15836 [1:04:30<13:14,  4.09it/s]\u001b[A\n",
      "Iteration:  79% 12585/15836 [1:04:31<15:17,  3.54it/s]\u001b[A\n",
      "Iteration:  79% 12586/15836 [1:04:31<14:19,  3.78it/s]\u001b[A\n",
      "Iteration:  79% 12587/15836 [1:04:31<13:43,  3.94it/s]\u001b[A\n",
      "Iteration:  79% 12588/15836 [1:04:32<13:28,  4.02it/s]\u001b[A\n",
      "Iteration:  79% 12589/15836 [1:04:32<13:15,  4.08it/s]\u001b[A\n",
      "Iteration:  80% 12590/15836 [1:04:32<15:16,  3.54it/s]\u001b[A\n",
      "Iteration:  80% 12591/15836 [1:04:32<14:22,  3.76it/s]\u001b[A\n",
      "Iteration:  80% 12592/15836 [1:04:33<13:50,  3.91it/s]\u001b[A\n",
      "Iteration:  80% 12593/15836 [1:04:33<13:24,  4.03it/s]\u001b[A\n",
      "Iteration:  80% 12594/15836 [1:04:33<13:13,  4.08it/s]\u001b[A\n",
      "Iteration:  80% 12595/15836 [1:04:33<15:10,  3.56it/s]\u001b[A\n",
      "Iteration:  80% 12596/15836 [1:04:34<14:22,  3.76it/s]\u001b[A\n",
      "Iteration:  80% 12597/15836 [1:04:34<13:46,  3.92it/s]\u001b[A\n",
      "Iteration:  80% 12598/15836 [1:04:34<13:25,  4.02it/s]\u001b[A\n",
      "Iteration:  80% 12599/15836 [1:04:34<13:10,  4.10it/s]\u001b[A\n",
      "Iteration:  80% 12600/15836 [1:04:35<15:16,  3.53it/s]\u001b[A\n",
      "Iteration:  80% 12601/15836 [1:04:35<14:23,  3.75it/s]\u001b[A\n",
      "Iteration:  80% 12602/15836 [1:04:35<13:51,  3.89it/s]\u001b[A\n",
      "Iteration:  80% 12603/15836 [1:04:35<13:22,  4.03it/s]\u001b[A\n",
      "Iteration:  80% 12604/15836 [1:04:36<13:15,  4.06it/s]\u001b[A\n",
      "Iteration:  80% 12605/15836 [1:04:36<15:15,  3.53it/s]\u001b[A\n",
      "Iteration:  80% 12606/15836 [1:04:36<14:27,  3.73it/s]\u001b[A\n",
      "Iteration:  80% 12607/15836 [1:04:37<13:50,  3.89it/s]\u001b[A\n",
      "Iteration:  80% 12608/15836 [1:04:37<13:30,  3.98it/s]\u001b[A\n",
      "Iteration:  80% 12609/15836 [1:04:37<13:16,  4.05it/s]\u001b[A\n",
      "Iteration:  80% 12610/15836 [1:04:37<15:19,  3.51it/s]\u001b[A\n",
      "Iteration:  80% 12611/15836 [1:04:38<14:29,  3.71it/s]\u001b[A\n",
      "Iteration:  80% 12612/15836 [1:04:38<13:51,  3.88it/s]\u001b[A\n",
      "Iteration:  80% 12613/15836 [1:04:38<13:34,  3.96it/s]\u001b[A\n",
      "Iteration:  80% 12614/15836 [1:04:38<13:19,  4.03it/s]\u001b[A\n",
      "Iteration:  80% 12615/15836 [1:04:39<15:17,  3.51it/s]\u001b[A\n",
      "Iteration:  80% 12616/15836 [1:04:39<14:25,  3.72it/s]\u001b[A\n",
      "Iteration:  80% 12617/15836 [1:04:39<13:50,  3.88it/s]\u001b[A\n",
      "Iteration:  80% 12618/15836 [1:04:39<13:31,  3.97it/s]\u001b[A\n",
      "Iteration:  80% 12619/15836 [1:04:40<13:15,  4.04it/s]\u001b[A\n",
      "Iteration:  80% 12620/15836 [1:04:40<15:16,  3.51it/s]\u001b[A\n",
      "Iteration:  80% 12621/15836 [1:04:40<14:25,  3.72it/s]\u001b[A\n",
      "Iteration:  80% 12622/15836 [1:04:40<13:55,  3.85it/s]\u001b[A\n",
      "Iteration:  80% 12623/15836 [1:04:41<13:29,  3.97it/s]\u001b[A\n",
      "Iteration:  80% 12624/15836 [1:04:41<13:14,  4.04it/s]\u001b[A\n",
      "Iteration:  80% 12625/15836 [1:04:41<15:16,  3.50it/s]\u001b[A\n",
      "Iteration:  80% 12626/15836 [1:04:42<14:21,  3.72it/s]\u001b[A\n",
      "Iteration:  80% 12627/15836 [1:04:42<13:51,  3.86it/s]\u001b[A\n",
      "Iteration:  80% 12628/15836 [1:04:42<13:25,  3.98it/s]\u001b[A\n",
      "Iteration:  80% 12629/15836 [1:04:42<13:17,  4.02it/s]\u001b[A\n",
      "Iteration:  80% 12630/15836 [1:04:43<15:17,  3.49it/s]\u001b[A\n",
      "Iteration:  80% 12631/15836 [1:04:43<14:20,  3.73it/s]\u001b[A\n",
      "Iteration:  80% 12632/15836 [1:04:43<13:43,  3.89it/s]\u001b[A\n",
      "Iteration:  80% 12633/15836 [1:04:43<13:20,  4.00it/s]\u001b[A\n",
      "Iteration:  80% 12634/15836 [1:04:44<13:08,  4.06it/s]\u001b[A\n",
      "Iteration:  80% 12635/15836 [1:04:44<15:04,  3.54it/s]\u001b[A\n",
      "Iteration:  80% 12636/15836 [1:04:44<14:10,  3.76it/s]\u001b[A\n",
      "Iteration:  80% 12637/15836 [1:04:44<13:34,  3.93it/s]\u001b[A\n",
      "Iteration:  80% 12638/15836 [1:04:45<13:14,  4.02it/s]\u001b[A\n",
      "Iteration:  80% 12639/15836 [1:04:45<13:02,  4.09it/s]\u001b[A\n",
      "Iteration:  80% 12640/15836 [1:04:45<15:01,  3.55it/s]\u001b[A\n",
      "Iteration:  80% 12641/15836 [1:04:45<14:08,  3.76it/s]\u001b[A\n",
      "Iteration:  80% 12642/15836 [1:04:46<13:32,  3.93it/s]\u001b[A\n",
      "Iteration:  80% 12643/15836 [1:04:46<13:11,  4.03it/s]\u001b[A\n",
      "Iteration:  80% 12644/15836 [1:04:46<12:57,  4.10it/s]\u001b[A\n",
      "Iteration:  80% 12645/15836 [1:04:47<14:57,  3.56it/s]\u001b[A\n",
      "Iteration:  80% 12646/15836 [1:04:47<14:04,  3.78it/s]\u001b[A\n",
      "Iteration:  80% 12647/15836 [1:04:47<13:26,  3.95it/s]\u001b[A\n",
      "Iteration:  80% 12648/15836 [1:04:47<13:06,  4.05it/s]\u001b[A\n",
      "Iteration:  80% 12649/15836 [1:04:47<13:00,  4.08it/s]\u001b[A\n",
      "Iteration:  80% 12650/15836 [1:04:48<14:54,  3.56it/s]\u001b[A\n",
      "Iteration:  80% 12651/15836 [1:04:48<13:54,  3.82it/s]\u001b[A\n",
      "Iteration:  80% 12652/15836 [1:04:48<13:21,  3.97it/s]\u001b[A\n",
      "Iteration:  80% 12653/15836 [1:04:48<13:08,  4.04it/s]\u001b[A\n",
      "Iteration:  80% 12654/15836 [1:04:49<12:52,  4.12it/s]\u001b[A\n",
      "Iteration:  80% 12655/15836 [1:04:49<14:51,  3.57it/s]\u001b[A\n",
      "Iteration:  80% 12656/15836 [1:04:49<13:59,  3.79it/s]\u001b[A\n",
      "Iteration:  80% 12657/15836 [1:04:50<13:23,  3.96it/s]\u001b[A\n",
      "Iteration:  80% 12658/15836 [1:04:50<13:01,  4.07it/s]\u001b[A\n",
      "Iteration:  80% 12659/15836 [1:04:50<12:55,  4.10it/s]\u001b[A\n",
      "Iteration:  80% 12660/15836 [1:04:50<14:46,  3.58it/s]\u001b[A\n",
      "Iteration:  80% 12661/15836 [1:04:51<13:51,  3.82it/s]\u001b[A\n",
      "Iteration:  80% 12662/15836 [1:04:51<13:15,  3.99it/s]\u001b[A\n",
      "Iteration:  80% 12663/15836 [1:04:51<13:01,  4.06it/s]\u001b[A\n",
      "Iteration:  80% 12664/15836 [1:04:51<12:44,  4.15it/s]\u001b[A\n",
      "Iteration:  80% 12665/15836 [1:04:52<14:37,  3.61it/s]\u001b[A\n",
      "Iteration:  80% 12666/15836 [1:04:52<13:42,  3.85it/s]\u001b[A\n",
      "Iteration:  80% 12667/15836 [1:04:52<13:13,  3.99it/s]\u001b[A\n",
      "Iteration:  80% 12668/15836 [1:04:52<12:52,  4.10it/s]\u001b[A\n",
      "Iteration:  80% 12669/15836 [1:04:53<12:39,  4.17it/s]\u001b[A\n",
      "Iteration:  80% 12670/15836 [1:04:53<14:37,  3.61it/s]\u001b[A\n",
      "Iteration:  80% 12671/15836 [1:04:53<13:50,  3.81it/s]\u001b[A\n",
      "Iteration:  80% 12672/15836 [1:04:53<13:11,  4.00it/s]\u001b[A\n",
      "Iteration:  80% 12673/15836 [1:04:54<12:47,  4.12it/s]\u001b[A\n",
      "Iteration:  80% 12674/15836 [1:04:54<12:34,  4.19it/s]\u001b[A\n",
      "Iteration:  80% 12675/15836 [1:04:54<14:29,  3.63it/s]\u001b[A\n",
      "Iteration:  80% 12676/15836 [1:04:54<13:37,  3.87it/s]\u001b[A\n",
      "Iteration:  80% 12677/15836 [1:04:55<13:03,  4.03it/s]\u001b[A\n",
      "Iteration:  80% 12678/15836 [1:04:55<12:40,  4.15it/s]\u001b[A\n",
      "Iteration:  80% 12679/15836 [1:04:55<12:27,  4.22it/s]\u001b[A\n",
      "Iteration:  80% 12680/15836 [1:04:55<14:24,  3.65it/s]\u001b[A\n",
      "Iteration:  80% 12681/15836 [1:04:56<13:29,  3.90it/s]\u001b[A\n",
      "Iteration:  80% 12682/15836 [1:04:56<12:57,  4.06it/s]\u001b[A\n",
      "Iteration:  80% 12683/15836 [1:04:56<12:38,  4.16it/s]\u001b[A\n",
      "Iteration:  80% 12684/15836 [1:04:56<12:26,  4.22it/s]\u001b[A\n",
      "Iteration:  80% 12685/15836 [1:04:57<14:22,  3.65it/s]\u001b[A\n",
      "Iteration:  80% 12686/15836 [1:04:57<13:31,  3.88it/s]\u001b[A\n",
      "Iteration:  80% 12687/15836 [1:04:57<12:56,  4.06it/s]\u001b[A\n",
      "Iteration:  80% 12688/15836 [1:04:57<12:36,  4.16it/s]\u001b[A\n",
      "Iteration:  80% 12689/15836 [1:04:58<12:25,  4.22it/s]\u001b[A\n",
      "Iteration:  80% 12690/15836 [1:04:58<14:19,  3.66it/s]\u001b[A\n",
      "Iteration:  80% 12691/15836 [1:04:58<13:28,  3.89it/s]\u001b[A\n",
      "Iteration:  80% 12692/15836 [1:04:58<12:57,  4.04it/s]\u001b[A\n",
      "Iteration:  80% 12693/15836 [1:04:59<12:36,  4.16it/s]\u001b[A\n",
      "Iteration:  80% 12694/15836 [1:04:59<12:23,  4.23it/s]\u001b[A\n",
      "Iteration:  80% 12695/15836 [1:04:59<14:16,  3.67it/s]\u001b[A\n",
      "Iteration:  80% 12696/15836 [1:04:59<13:31,  3.87it/s]\u001b[A\n",
      "Iteration:  80% 12697/15836 [1:05:00<12:58,  4.03it/s]\u001b[A\n",
      "Iteration:  80% 12698/15836 [1:05:00<12:34,  4.16it/s]\u001b[A\n",
      "Iteration:  80% 12699/15836 [1:05:00<12:24,  4.22it/s]\u001b[A\n",
      "Iteration:  80% 12700/15836 [1:05:00<14:17,  3.66it/s]\u001b[A\n",
      "Iteration:  80% 12701/15836 [1:05:01<13:29,  3.87it/s]\u001b[A\n",
      "Iteration:  80% 12702/15836 [1:05:01<12:55,  4.04it/s]\u001b[A\n",
      "Iteration:  80% 12703/15836 [1:05:01<12:35,  4.15it/s]\u001b[A\n",
      "Iteration:  80% 12704/15836 [1:05:01<12:21,  4.23it/s]\u001b[A\n",
      "Iteration:  80% 12705/15836 [1:05:02<14:14,  3.66it/s]\u001b[A\n",
      "Iteration:  80% 12706/15836 [1:05:02<13:26,  3.88it/s]\u001b[A\n",
      "Iteration:  80% 12707/15836 [1:05:02<12:52,  4.05it/s]\u001b[A\n",
      "Iteration:  80% 12708/15836 [1:05:02<12:32,  4.16it/s]\u001b[A\n",
      "Iteration:  80% 12709/15836 [1:05:03<12:18,  4.24it/s]\u001b[A\n",
      "Iteration:  80% 12710/15836 [1:05:03<14:12,  3.67it/s]\u001b[A\n",
      "Iteration:  80% 12711/15836 [1:05:03<13:20,  3.90it/s]\u001b[A\n",
      "Iteration:  80% 12712/15836 [1:05:03<12:50,  4.05it/s]\u001b[A\n",
      "Iteration:  80% 12713/15836 [1:05:04<12:29,  4.17it/s]\u001b[A\n",
      "Iteration:  80% 12714/15836 [1:05:04<12:12,  4.26it/s]\u001b[A\n",
      "Iteration:  80% 12715/15836 [1:05:04<14:10,  3.67it/s]\u001b[A\n",
      "Iteration:  80% 12716/15836 [1:05:04<13:15,  3.92it/s]\u001b[A\n",
      "Iteration:  80% 12717/15836 [1:05:05<12:42,  4.09it/s]\u001b[A\n",
      "Iteration:  80% 12718/15836 [1:05:05<12:20,  4.21it/s]\u001b[A\n",
      "Iteration:  80% 12719/15836 [1:05:05<12:12,  4.26it/s]\u001b[A\n",
      "Iteration:  80% 12720/15836 [1:05:05<14:08,  3.67it/s]\u001b[A\n",
      "Iteration:  80% 12721/15836 [1:05:06<13:17,  3.91it/s]\u001b[A\n",
      "Iteration:  80% 12722/15836 [1:05:06<12:45,  4.07it/s]\u001b[A\n",
      "Iteration:  80% 12723/15836 [1:05:06<12:20,  4.20it/s]\u001b[A\n",
      "Iteration:  80% 12724/15836 [1:05:06<12:05,  4.29it/s]\u001b[A\n",
      "Iteration:  80% 12725/15836 [1:05:07<14:01,  3.69it/s]\u001b[A\n",
      "Iteration:  80% 12726/15836 [1:05:07<13:09,  3.94it/s]\u001b[A\n",
      "Iteration:  80% 12727/15836 [1:05:07<12:38,  4.10it/s]\u001b[A\n",
      "Iteration:  80% 12728/15836 [1:05:07<12:20,  4.20it/s]\u001b[A\n",
      "Iteration:  80% 12729/15836 [1:05:08<12:10,  4.25it/s]\u001b[A\n",
      "Iteration:  80% 12730/15836 [1:05:08<14:07,  3.66it/s]\u001b[A\n",
      "Iteration:  80% 12731/15836 [1:05:08<13:10,  3.93it/s]\u001b[A\n",
      "Iteration:  80% 12732/15836 [1:05:08<12:34,  4.11it/s]\u001b[A\n",
      "Iteration:  80% 12733/15836 [1:05:09<12:18,  4.20it/s]\u001b[A\n",
      "Iteration:  80% 12734/15836 [1:05:09<12:05,  4.27it/s]\u001b[A\n",
      "Iteration:  80% 12735/15836 [1:05:09<14:01,  3.68it/s]\u001b[A\n",
      "Iteration:  80% 12736/15836 [1:05:09<13:11,  3.92it/s]\u001b[A\n",
      "Iteration:  80% 12737/15836 [1:05:10<12:38,  4.08it/s]\u001b[A\n",
      "Iteration:  80% 12738/15836 [1:05:10<12:18,  4.20it/s]\u001b[A\n",
      "Iteration:  80% 12739/15836 [1:05:10<12:05,  4.27it/s]\u001b[A\n",
      "Iteration:  80% 12740/15836 [1:05:10<13:58,  3.69it/s]\u001b[A\n",
      "Iteration:  80% 12741/15836 [1:05:11<13:03,  3.95it/s]\u001b[A\n",
      "Iteration:  80% 12742/15836 [1:05:11<12:35,  4.10it/s]\u001b[A\n",
      "Iteration:  80% 12743/15836 [1:05:11<12:20,  4.18it/s]\u001b[A\n",
      "Iteration:  80% 12744/15836 [1:05:11<12:04,  4.27it/s]\u001b[A\n",
      "Iteration:  80% 12745/15836 [1:05:12<13:57,  3.69it/s]\u001b[A\n",
      "Iteration:  80% 12746/15836 [1:05:12<13:03,  3.95it/s]\u001b[A\n",
      "Iteration:  80% 12747/15836 [1:05:12<12:33,  4.10it/s]\u001b[A\n",
      "Iteration:  81% 12748/15836 [1:05:12<12:12,  4.21it/s]\u001b[A\n",
      "Iteration:  81% 12749/15836 [1:05:13<12:00,  4.28it/s]\u001b[A\n",
      "Iteration:  81% 12750/15836 [1:05:13<13:54,  3.70it/s]\u001b[A\n",
      "Iteration:  81% 12751/15836 [1:05:13<13:00,  3.95it/s]\u001b[A\n",
      "Iteration:  81% 12752/15836 [1:05:13<12:26,  4.13it/s]\u001b[A\n",
      "Iteration:  81% 12753/15836 [1:05:14<12:09,  4.22it/s]\u001b[A\n",
      "Iteration:  81% 12754/15836 [1:05:14<11:56,  4.30it/s]\u001b[A\n",
      "Iteration:  81% 12755/15836 [1:05:14<13:51,  3.71it/s]\u001b[A\n",
      "Iteration:  81% 12756/15836 [1:05:14<12:58,  3.96it/s]\u001b[A\n",
      "Iteration:  81% 12757/15836 [1:05:15<12:30,  4.10it/s]\u001b[A\n",
      "Iteration:  81% 12758/15836 [1:05:15<12:08,  4.23it/s]\u001b[A\n",
      "Iteration:  81% 12759/15836 [1:05:15<11:56,  4.29it/s]\u001b[A\n",
      "Iteration:  81% 12760/15836 [1:05:15<13:52,  3.70it/s]\u001b[A\n",
      "Iteration:  81% 12761/15836 [1:05:16<12:57,  3.96it/s]\u001b[A\n",
      "Iteration:  81% 12762/15836 [1:05:16<12:24,  4.13it/s]\u001b[A\n",
      "Iteration:  81% 12763/15836 [1:05:16<12:09,  4.21it/s]\u001b[A\n",
      "Iteration:  81% 12764/15836 [1:05:16<11:55,  4.29it/s]\u001b[A\n",
      "Iteration:  81% 12765/15836 [1:05:17<13:49,  3.70it/s]\u001b[A\n",
      "Iteration:  81% 12766/15836 [1:05:17<12:56,  3.96it/s]\u001b[A\n",
      "Iteration:  81% 12767/15836 [1:05:17<12:25,  4.12it/s]\u001b[A\n",
      "Iteration:  81% 12768/15836 [1:05:17<12:06,  4.22it/s]\u001b[A\n",
      "Iteration:  81% 12769/15836 [1:05:17<11:53,  4.30it/s]\u001b[A\n",
      "Iteration:  81% 12770/15836 [1:05:18<13:50,  3.69it/s]\u001b[A\n",
      "Iteration:  81% 12771/15836 [1:05:18<12:55,  3.95it/s]\u001b[A\n",
      "Iteration:  81% 12772/15836 [1:05:18<12:22,  4.13it/s]\u001b[A\n",
      "Iteration:  81% 12773/15836 [1:05:18<12:04,  4.23it/s]\u001b[A\n",
      "Iteration:  81% 12774/15836 [1:05:19<11:54,  4.29it/s]\u001b[A\n",
      "Iteration:  81% 12775/15836 [1:05:19<13:49,  3.69it/s]\u001b[A\n",
      "Iteration:  81% 12776/15836 [1:05:19<12:54,  3.95it/s]\u001b[A\n",
      "Iteration:  81% 12777/15836 [1:05:20<12:19,  4.14it/s]\u001b[A\n",
      "Iteration:  81% 12778/15836 [1:05:20<11:59,  4.25it/s]\u001b[A\n",
      "Iteration:  81% 12779/15836 [1:05:20<11:49,  4.31it/s]\u001b[A\n",
      "Iteration:  81% 12780/15836 [1:05:20<13:45,  3.70it/s]\u001b[A\n",
      "Iteration:  81% 12781/15836 [1:05:21<12:52,  3.96it/s]\u001b[A\n",
      "Iteration:  81% 12782/15836 [1:05:21<12:21,  4.12it/s]\u001b[A\n",
      "Iteration:  81% 12783/15836 [1:05:21<12:01,  4.23it/s]\u001b[A\n",
      "Iteration:  81% 12784/15836 [1:05:21<11:51,  4.29it/s]\u001b[A\n",
      "Iteration:  81% 12785/15836 [1:05:22<13:42,  3.71it/s]\u001b[A\n",
      "Iteration:  81% 12786/15836 [1:05:22<12:48,  3.97it/s]\u001b[A\n",
      "Iteration:  81% 12787/15836 [1:05:22<12:17,  4.13it/s]\u001b[A\n",
      "Iteration:  81% 12788/15836 [1:05:22<12:03,  4.21it/s]\u001b[A\n",
      "Iteration:  81% 12789/15836 [1:05:22<11:52,  4.28it/s]\u001b[A\n",
      "Iteration:  81% 12790/15836 [1:05:23<13:44,  3.70it/s]\u001b[A\n",
      "Iteration:  81% 12791/15836 [1:05:23<12:49,  3.96it/s]\u001b[A\n",
      "Iteration:  81% 12792/15836 [1:05:23<12:18,  4.12it/s]\u001b[A\n",
      "Iteration:  81% 12793/15836 [1:05:23<12:00,  4.22it/s]\u001b[A\n",
      "Iteration:  81% 12794/15836 [1:05:24<11:48,  4.30it/s]\u001b[A\n",
      "Iteration:  81% 12795/15836 [1:05:24<13:42,  3.70it/s]\u001b[A\n",
      "Iteration:  81% 12796/15836 [1:05:24<12:47,  3.96it/s]\u001b[A\n",
      "Iteration:  81% 12797/15836 [1:05:24<12:17,  4.12it/s]\u001b[A\n",
      "Iteration:  81% 12798/15836 [1:05:25<11:59,  4.22it/s]\u001b[A\n",
      "Iteration:  81% 12799/15836 [1:05:25<11:47,  4.29it/s]\u001b[A\n",
      "Iteration:  81% 12800/15836 [1:05:25<13:40,  3.70it/s]\u001b[A\n",
      "Iteration:  81% 12801/15836 [1:05:25<12:48,  3.95it/s]\u001b[A\n",
      "Iteration:  81% 12802/15836 [1:05:26<12:15,  4.12it/s]\u001b[A\n",
      "Iteration:  81% 12803/15836 [1:05:26<11:58,  4.22it/s]\u001b[A\n",
      "Iteration:  81% 12804/15836 [1:05:26<11:47,  4.28it/s]\u001b[A\n",
      "Iteration:  81% 12805/15836 [1:05:26<13:38,  3.70it/s]\u001b[A\n",
      "Iteration:  81% 12806/15836 [1:05:27<12:46,  3.95it/s]\u001b[A\n",
      "Iteration:  81% 12807/15836 [1:05:27<12:13,  4.13it/s]\u001b[A\n",
      "Iteration:  81% 12808/15836 [1:05:27<11:56,  4.23it/s]\u001b[A\n",
      "Iteration:  81% 12809/15836 [1:05:27<11:45,  4.29it/s]\u001b[A\n",
      "Iteration:  81% 12810/15836 [1:05:28<13:37,  3.70it/s]\u001b[A\n",
      "Iteration:  81% 12811/15836 [1:05:28<12:47,  3.94it/s]\u001b[A\n",
      "Iteration:  81% 12812/15836 [1:05:28<12:14,  4.12it/s]\u001b[A\n",
      "Iteration:  81% 12813/15836 [1:05:28<11:55,  4.23it/s]\u001b[A\n",
      "Iteration:  81% 12814/15836 [1:05:29<11:43,  4.30it/s]\u001b[A\n",
      "Iteration:  81% 12815/15836 [1:05:29<13:36,  3.70it/s]\u001b[A\n",
      "Iteration:  81% 12816/15836 [1:05:29<12:44,  3.95it/s]\u001b[A\n",
      "Iteration:  81% 12817/15836 [1:05:29<12:12,  4.12it/s]\u001b[A\n",
      "Iteration:  81% 12818/15836 [1:05:30<11:54,  4.22it/s]\u001b[A\n",
      "Iteration:  81% 12819/15836 [1:05:30<11:42,  4.29it/s]\u001b[A\n",
      "Iteration:  81% 12820/15836 [1:05:30<13:34,  3.70it/s]\u001b[A\n",
      "Iteration:  81% 12821/15836 [1:05:30<12:45,  3.94it/s]\u001b[A\n",
      "Iteration:  81% 12822/15836 [1:05:31<12:13,  4.11it/s]\u001b[A\n",
      "Iteration:  81% 12823/15836 [1:05:31<11:53,  4.22it/s]\u001b[A\n",
      "Iteration:  81% 12824/15836 [1:05:31<11:41,  4.29it/s]\u001b[A\n",
      "Iteration:  81% 12825/15836 [1:05:31<13:32,  3.71it/s]\u001b[A\n",
      "Iteration:  81% 12826/15836 [1:05:32<12:40,  3.96it/s]\u001b[A\n",
      "Iteration:  81% 12827/15836 [1:05:32<12:08,  4.13it/s]\u001b[A\n",
      "Iteration:  81% 12828/15836 [1:05:32<11:53,  4.22it/s]\u001b[A\n",
      "Iteration:  81% 12829/15836 [1:05:32<11:40,  4.29it/s]\u001b[A\n",
      "Iteration:  81% 12830/15836 [1:05:33<13:31,  3.71it/s]\u001b[A\n",
      "Iteration:  81% 12831/15836 [1:05:33<12:41,  3.95it/s]\u001b[A\n",
      "Iteration:  81% 12832/15836 [1:05:33<12:09,  4.12it/s]\u001b[A\n",
      "Iteration:  81% 12833/15836 [1:05:33<11:50,  4.23it/s]\u001b[A\n",
      "Iteration:  81% 12834/15836 [1:05:34<11:40,  4.28it/s]\u001b[A\n",
      "Iteration:  81% 12835/15836 [1:05:34<13:35,  3.68it/s]\u001b[A\n",
      "Iteration:  81% 12836/15836 [1:05:34<12:44,  3.93it/s]\u001b[A\n",
      "Iteration:  81% 12837/15836 [1:05:34<12:13,  4.09it/s]\u001b[A\n",
      "Iteration:  81% 12838/15836 [1:05:35<11:54,  4.20it/s]\u001b[A\n",
      "Iteration:  81% 12839/15836 [1:05:35<11:48,  4.23it/s]\u001b[A\n",
      "Iteration:  81% 12840/15836 [1:05:35<13:35,  3.67it/s]\u001b[A\n",
      "Iteration:  81% 12841/15836 [1:05:35<12:45,  3.91it/s]\u001b[A\n",
      "Iteration:  81% 12842/15836 [1:05:36<12:11,  4.09it/s]\u001b[A\n",
      "Iteration:  81% 12843/15836 [1:05:36<11:53,  4.20it/s]\u001b[A\n",
      "Iteration:  81% 12844/15836 [1:05:36<11:40,  4.27it/s]\u001b[A\n",
      "Iteration:  81% 12845/15836 [1:05:36<13:31,  3.69it/s]\u001b[A\n",
      "Iteration:  81% 12846/15836 [1:05:37<12:41,  3.93it/s]\u001b[A\n",
      "Iteration:  81% 12847/15836 [1:05:37<12:09,  4.10it/s]\u001b[A\n",
      "Iteration:  81% 12848/15836 [1:05:37<11:46,  4.23it/s]\u001b[A\n",
      "Iteration:  81% 12849/15836 [1:05:37<11:36,  4.29it/s]\u001b[A\n",
      "Iteration:  81% 12850/15836 [1:05:38<13:28,  3.70it/s]\u001b[A\n",
      "Iteration:  81% 12851/15836 [1:05:38<12:38,  3.93it/s]\u001b[A\n",
      "Iteration:  81% 12852/15836 [1:05:38<12:10,  4.09it/s]\u001b[A\n",
      "Iteration:  81% 12853/15836 [1:05:38<11:52,  4.19it/s]\u001b[A\n",
      "Iteration:  81% 12854/15836 [1:05:39<11:40,  4.26it/s]\u001b[A\n",
      "Iteration:  81% 12855/15836 [1:05:39<13:29,  3.68it/s]\u001b[A\n",
      "Iteration:  81% 12856/15836 [1:05:39<12:39,  3.92it/s]\u001b[A\n",
      "Iteration:  81% 12857/15836 [1:05:39<12:09,  4.08it/s]\u001b[A\n",
      "Iteration:  81% 12858/15836 [1:05:40<11:46,  4.21it/s]\u001b[A\n",
      "Iteration:  81% 12859/15836 [1:05:40<11:33,  4.29it/s]\u001b[A\n",
      "Iteration:  81% 12860/15836 [1:05:40<13:23,  3.70it/s]\u001b[A\n",
      "Iteration:  81% 12861/15836 [1:05:40<12:37,  3.93it/s]\u001b[A\n",
      "Iteration:  81% 12862/15836 [1:05:41<12:07,  4.09it/s]\u001b[A\n",
      "Iteration:  81% 12863/15836 [1:05:41<11:52,  4.17it/s]\u001b[A\n",
      "Iteration:  81% 12864/15836 [1:05:41<11:38,  4.25it/s]\u001b[A\n",
      "Iteration:  81% 12865/15836 [1:05:41<13:27,  3.68it/s]\u001b[A\n",
      "Iteration:  81% 12866/15836 [1:05:42<12:39,  3.91it/s]\u001b[A\n",
      "Iteration:  81% 12867/15836 [1:05:42<12:08,  4.08it/s]\u001b[A\n",
      "Iteration:  81% 12868/15836 [1:05:42<11:49,  4.18it/s]\u001b[A\n",
      "Iteration:  81% 12869/15836 [1:05:42<11:40,  4.23it/s]\u001b[A\n",
      "Iteration:  81% 12870/15836 [1:05:43<13:31,  3.66it/s]\u001b[A\n",
      "Iteration:  81% 12871/15836 [1:05:43<12:39,  3.91it/s]\u001b[A\n",
      "Iteration:  81% 12872/15836 [1:05:43<12:04,  4.09it/s]\u001b[A\n",
      "Iteration:  81% 12873/15836 [1:05:43<11:49,  4.17it/s]\u001b[A\n",
      "Iteration:  81% 12874/15836 [1:05:43<11:34,  4.26it/s]\u001b[A\n",
      "Iteration:  81% 12875/15836 [1:05:44<13:23,  3.68it/s]\u001b[A\n",
      "Iteration:  81% 12876/15836 [1:05:44<12:31,  3.94it/s]\u001b[A\n",
      "Iteration:  81% 12877/15836 [1:05:44<12:03,  4.09it/s]\u001b[A\n",
      "Iteration:  81% 12878/15836 [1:05:45<11:46,  4.19it/s]\u001b[A\n",
      "Iteration:  81% 12879/15836 [1:05:45<11:35,  4.25it/s]\u001b[A\n",
      "Iteration:  81% 12880/15836 [1:05:45<13:31,  3.64it/s]\u001b[A\n",
      "Iteration:  81% 12881/15836 [1:05:45<12:37,  3.90it/s]\u001b[A\n",
      "Iteration:  81% 12882/15836 [1:05:46<12:05,  4.07it/s]\u001b[A\n",
      "Iteration:  81% 12883/15836 [1:05:46<11:48,  4.17it/s]\u001b[A\n",
      "Iteration:  81% 12884/15836 [1:05:46<11:36,  4.24it/s]\u001b[A\n",
      "Iteration:  81% 12885/15836 [1:05:46<13:31,  3.64it/s]\u001b[A\n",
      "Iteration:  81% 12886/15836 [1:05:47<12:37,  3.89it/s]\u001b[A\n",
      "Iteration:  81% 12887/15836 [1:05:47<12:04,  4.07it/s]\u001b[A\n",
      "Iteration:  81% 12888/15836 [1:05:47<11:50,  4.15it/s]\u001b[A\n",
      "Iteration:  81% 12889/15836 [1:05:47<11:38,  4.22it/s]\u001b[A\n",
      "Iteration:  81% 12890/15836 [1:05:48<13:28,  3.65it/s]\u001b[A\n",
      "Iteration:  81% 12891/15836 [1:05:48<12:35,  3.90it/s]\u001b[A\n",
      "Iteration:  81% 12892/15836 [1:05:48<12:00,  4.09it/s]\u001b[A\n",
      "Iteration:  81% 12893/15836 [1:05:48<11:42,  4.19it/s]\u001b[A\n",
      "Iteration:  81% 12894/15836 [1:05:49<11:34,  4.24it/s]\u001b[A\n",
      "Iteration:  81% 12895/15836 [1:05:49<13:24,  3.65it/s]\u001b[A\n",
      "Iteration:  81% 12896/15836 [1:05:49<12:35,  3.89it/s]\u001b[A\n",
      "Iteration:  81% 12897/15836 [1:05:49<12:05,  4.05it/s]\u001b[A\n",
      "Iteration:  81% 12898/15836 [1:05:50<11:46,  4.16it/s]\u001b[A\n",
      "Iteration:  81% 12899/15836 [1:05:50<11:34,  4.23it/s]\u001b[A\n",
      "Iteration:  81% 12900/15836 [1:05:50<13:23,  3.65it/s]\u001b[A\n",
      "Iteration:  81% 12901/15836 [1:05:50<12:33,  3.90it/s]\u001b[A\n",
      "Iteration:  81% 12902/15836 [1:05:51<12:05,  4.04it/s]\u001b[A\n",
      "Iteration:  81% 12903/15836 [1:05:51<11:44,  4.16it/s]\u001b[A\n",
      "Iteration:  81% 12904/15836 [1:05:51<11:31,  4.24it/s]\u001b[A\n",
      "Iteration:  81% 12905/15836 [1:05:51<13:18,  3.67it/s]\u001b[A\n",
      "Iteration:  81% 12906/15836 [1:05:52<12:33,  3.89it/s]\u001b[A\n",
      "Iteration:  82% 12907/15836 [1:05:52<12:03,  4.05it/s]\u001b[A\n",
      "Iteration:  82% 12908/15836 [1:05:52<11:46,  4.15it/s]\u001b[A\n",
      "Iteration:  82% 12909/15836 [1:05:52<11:32,  4.22it/s]\u001b[A\n",
      "Iteration:  82% 12910/15836 [1:05:53<13:20,  3.65it/s]\u001b[A\n",
      "Iteration:  82% 12911/15836 [1:05:53<12:32,  3.89it/s]\u001b[A\n",
      "Iteration:  82% 12912/15836 [1:05:53<12:02,  4.05it/s]\u001b[A\n",
      "Iteration:  82% 12913/15836 [1:05:53<11:41,  4.17it/s]\u001b[A\n",
      "Iteration:  82% 12914/15836 [1:05:54<11:31,  4.23it/s]\u001b[A\n",
      "Iteration:  82% 12915/15836 [1:05:54<13:17,  3.66it/s]\u001b[A\n",
      "Iteration:  82% 12916/15836 [1:05:54<12:33,  3.88it/s]\u001b[A\n",
      "Iteration:  82% 12917/15836 [1:05:54<12:00,  4.05it/s]\u001b[A\n",
      "Iteration:  82% 12918/15836 [1:05:55<11:42,  4.16it/s]\u001b[A\n",
      "Iteration:  82% 12919/15836 [1:05:55<11:31,  4.22it/s]\u001b[A\n",
      "Iteration:  82% 12920/15836 [1:05:55<13:20,  3.64it/s]\u001b[A\n",
      "Iteration:  82% 12921/15836 [1:05:55<12:33,  3.87it/s]\u001b[A\n",
      "Iteration:  82% 12922/15836 [1:05:56<12:01,  4.04it/s]\u001b[A\n",
      "Iteration:  82% 12923/15836 [1:05:56<11:44,  4.13it/s]\u001b[A\n",
      "Iteration:  82% 12924/15836 [1:05:56<11:36,  4.18it/s]\u001b[A\n",
      "Iteration:  82% 12925/15836 [1:05:56<13:20,  3.64it/s]\u001b[A\n",
      "Iteration:  82% 12926/15836 [1:05:57<12:30,  3.88it/s]\u001b[A\n",
      "Iteration:  82% 12927/15836 [1:05:57<12:00,  4.04it/s]\u001b[A\n",
      "Iteration:  82% 12928/15836 [1:05:57<11:46,  4.12it/s]\u001b[A\n",
      "Iteration:  82% 12929/15836 [1:05:57<11:36,  4.17it/s]\u001b[A\n",
      "Iteration:  82% 12930/15836 [1:05:58<13:21,  3.63it/s]\u001b[A\n",
      "Iteration:  82% 12931/15836 [1:05:58<12:29,  3.87it/s]\u001b[A\n",
      "Iteration:  82% 12932/15836 [1:05:58<12:03,  4.01it/s]\u001b[A\n",
      "Iteration:  82% 12933/15836 [1:05:58<11:45,  4.11it/s]\u001b[A\n",
      "Iteration:  82% 12934/15836 [1:05:59<11:38,  4.15it/s]\u001b[A\n",
      "Iteration:  82% 12935/15836 [1:05:59<13:21,  3.62it/s]\u001b[A\n",
      "Iteration:  82% 12936/15836 [1:05:59<12:36,  3.83it/s]\u001b[A\n",
      "Iteration:  82% 12937/15836 [1:05:59<12:04,  4.00it/s]\u001b[A\n",
      "Iteration:  82% 12938/15836 [1:06:00<11:45,  4.11it/s]\u001b[A\n",
      "Iteration:  82% 12939/15836 [1:06:00<11:34,  4.17it/s]\u001b[A\n",
      "Iteration:  82% 12940/15836 [1:06:00<13:19,  3.62it/s]\u001b[A\n",
      "Iteration:  82% 12941/15836 [1:06:00<12:32,  3.85it/s]\u001b[A\n",
      "Iteration:  82% 12942/15836 [1:06:01<12:01,  4.01it/s]\u001b[A\n",
      "Iteration:  82% 12943/15836 [1:06:01<11:46,  4.10it/s]\u001b[A\n",
      "Iteration:  82% 12944/15836 [1:06:01<11:32,  4.17it/s]\u001b[A\n",
      "Iteration:  82% 12945/15836 [1:06:01<13:17,  3.63it/s]\u001b[A\n",
      "Iteration:  82% 12946/15836 [1:06:02<12:31,  3.85it/s]\u001b[A\n",
      "Iteration:  82% 12947/15836 [1:06:02<12:01,  4.00it/s]\u001b[A\n",
      "Iteration:  82% 12948/15836 [1:06:02<11:40,  4.12it/s]\u001b[A\n",
      "Iteration:  82% 12949/15836 [1:06:02<11:30,  4.18it/s]\u001b[A\n",
      "Iteration:  82% 12950/15836 [1:06:03<13:17,  3.62it/s]\u001b[A\n",
      "Iteration:  82% 12951/15836 [1:06:03<12:31,  3.84it/s]\u001b[A\n",
      "Iteration:  82% 12952/15836 [1:06:03<11:58,  4.01it/s]\u001b[A\n",
      "Iteration:  82% 12953/15836 [1:06:03<11:38,  4.13it/s]\u001b[A\n",
      "Iteration:  82% 12954/15836 [1:06:04<11:25,  4.20it/s]\u001b[A\n",
      "Iteration:  82% 12955/15836 [1:06:04<13:10,  3.64it/s]\u001b[A\n",
      "Iteration:  82% 12956/15836 [1:06:04<12:26,  3.86it/s]\u001b[A\n",
      "Iteration:  82% 12957/15836 [1:06:04<11:53,  4.03it/s]\u001b[A\n",
      "Iteration:  82% 12958/15836 [1:06:05<11:36,  4.13it/s]\u001b[A\n",
      "Iteration:  82% 12959/15836 [1:06:05<11:23,  4.21it/s]\u001b[A\n",
      "Iteration:  82% 12960/15836 [1:06:05<13:09,  3.64it/s]\u001b[A\n",
      "Iteration:  82% 12961/15836 [1:06:05<12:24,  3.86it/s]\u001b[A\n",
      "Iteration:  82% 12962/15836 [1:06:06<11:53,  4.03it/s]\u001b[A\n",
      "Iteration:  82% 12963/15836 [1:06:06<11:36,  4.13it/s]\u001b[A\n",
      "Iteration:  82% 12964/15836 [1:06:06<11:25,  4.19it/s]\u001b[A\n",
      "Iteration:  82% 12965/15836 [1:06:07<13:12,  3.62it/s]\u001b[A\n",
      "Iteration:  82% 12966/15836 [1:06:07<12:26,  3.85it/s]\u001b[A\n",
      "Iteration:  82% 12967/15836 [1:06:07<11:58,  4.00it/s]\u001b[A\n",
      "Iteration:  82% 12968/15836 [1:06:07<11:34,  4.13it/s]\u001b[A\n",
      "Iteration:  82% 12969/15836 [1:06:07<11:23,  4.20it/s]\u001b[A\n",
      "Iteration:  82% 12970/15836 [1:06:08<13:07,  3.64it/s]\u001b[A\n",
      "Iteration:  82% 12971/15836 [1:06:08<12:25,  3.84it/s]\u001b[A\n",
      "Iteration:  82% 12972/15836 [1:06:08<11:52,  4.02it/s]\u001b[A\n",
      "Iteration:  82% 12973/15836 [1:06:08<11:35,  4.12it/s]\u001b[A\n",
      "Iteration:  82% 12974/15836 [1:06:09<11:22,  4.19it/s]\u001b[A\n",
      "Iteration:  82% 12975/15836 [1:06:09<13:08,  3.63it/s]\u001b[A\n",
      "Iteration:  82% 12976/15836 [1:06:09<12:21,  3.86it/s]\u001b[A\n",
      "Iteration:  82% 12977/15836 [1:06:10<11:55,  4.00it/s]\u001b[A\n",
      "Iteration:  82% 12978/15836 [1:06:10<11:35,  4.11it/s]\u001b[A\n",
      "Iteration:  82% 12979/15836 [1:06:10<11:21,  4.19it/s]\u001b[A\n",
      "Iteration:  82% 12980/15836 [1:06:10<13:04,  3.64it/s]\u001b[A\n",
      "Iteration:  82% 12981/15836 [1:06:11<12:22,  3.85it/s]\u001b[A\n",
      "Iteration:  82% 12982/15836 [1:06:11<11:48,  4.03it/s]\u001b[A\n",
      "Iteration:  82% 12983/15836 [1:06:11<11:28,  4.14it/s]\u001b[A\n",
      "Iteration:  82% 12984/15836 [1:06:11<11:14,  4.23it/s]\u001b[A\n",
      "Iteration:  82% 12985/15836 [1:06:12<13:02,  3.64it/s]\u001b[A\n",
      "Iteration:  82% 12986/15836 [1:06:12<12:20,  3.85it/s]\u001b[A\n",
      "Iteration:  82% 12987/15836 [1:06:12<11:49,  4.01it/s]\u001b[A\n",
      "Iteration:  82% 12988/15836 [1:06:12<11:33,  4.11it/s]\u001b[A\n",
      "Iteration:  82% 12989/15836 [1:06:13<11:24,  4.16it/s]\u001b[A\n",
      "Iteration:  82% 12990/15836 [1:06:13<13:08,  3.61it/s]\u001b[A\n",
      "Iteration:  82% 12991/15836 [1:06:13<12:18,  3.85it/s]\u001b[A\n",
      "Iteration:  82% 12992/15836 [1:06:13<11:49,  4.01it/s]\u001b[A\n",
      "Iteration:  82% 12993/15836 [1:06:14<11:30,  4.12it/s]\u001b[A\n",
      "Iteration:  82% 12994/15836 [1:06:14<11:17,  4.19it/s]\u001b[A\n",
      "Iteration:  82% 12995/15836 [1:06:14<13:03,  3.63it/s]\u001b[A\n",
      "Iteration:  82% 12996/15836 [1:06:14<12:16,  3.86it/s]\u001b[A\n",
      "Iteration:  82% 12997/15836 [1:06:15<11:49,  4.00it/s]\u001b[A\n",
      "Iteration:  82% 12998/15836 [1:06:15<11:28,  4.12it/s]\u001b[A\n",
      "Iteration:  82% 12999/15836 [1:06:15<11:13,  4.21it/s]\u001b[A\n",
      "Iteration:  82% 13000/15836 [1:06:15<13:00,  3.63it/s]\u001b[A\n",
      "Iteration:  82% 13001/15836 [1:06:16<12:14,  3.86it/s]\u001b[A\n",
      "Iteration:  82% 13002/15836 [1:06:16<11:42,  4.03it/s]\u001b[A\n",
      "Iteration:  82% 13003/15836 [1:06:16<11:22,  4.15it/s]\u001b[A\n",
      "Iteration:  82% 13004/15836 [1:06:16<11:11,  4.22it/s]\u001b[A\n",
      "Iteration:  82% 13005/15836 [1:06:17<12:54,  3.66it/s]\u001b[A\n",
      "Iteration:  82% 13006/15836 [1:06:17<12:11,  3.87it/s]\u001b[A\n",
      "Iteration:  82% 13007/15836 [1:06:17<11:40,  4.04it/s]\u001b[A\n",
      "Iteration:  82% 13008/15836 [1:06:17<11:24,  4.13it/s]\u001b[A\n",
      "Iteration:  82% 13009/15836 [1:06:18<11:15,  4.19it/s]\u001b[A\n",
      "Iteration:  82% 13010/15836 [1:06:18<13:01,  3.62it/s]\u001b[A\n",
      "Iteration:  82% 13011/15836 [1:06:18<12:15,  3.84it/s]\u001b[A\n",
      "Iteration:  82% 13012/15836 [1:06:18<11:45,  4.00it/s]\u001b[A\n",
      "Iteration:  82% 13013/15836 [1:06:19<11:24,  4.13it/s]\u001b[A\n",
      "Iteration:  82% 13014/15836 [1:06:19<11:13,  4.19it/s]\u001b[A\n",
      "Iteration:  82% 13015/15836 [1:06:19<12:54,  3.64it/s]\u001b[A\n",
      "Iteration:  82% 13016/15836 [1:06:19<12:09,  3.87it/s]\u001b[A\n",
      "Iteration:  82% 13017/15836 [1:06:20<11:39,  4.03it/s]\u001b[A\n",
      "Iteration:  82% 13018/15836 [1:06:20<11:20,  4.14it/s]\u001b[A\n",
      "Iteration:  82% 13019/15836 [1:06:20<11:12,  4.19it/s]\u001b[A\n",
      "Iteration:  82% 13020/15836 [1:06:20<12:59,  3.61it/s]\u001b[A\n",
      "Iteration:  82% 13021/15836 [1:06:21<12:11,  3.85it/s]\u001b[A\n",
      "Iteration:  82% 13022/15836 [1:06:21<11:41,  4.01it/s]\u001b[A\n",
      "Iteration:  82% 13023/15836 [1:06:21<11:22,  4.12it/s]\u001b[A\n",
      "Iteration:  82% 13024/15836 [1:06:21<11:12,  4.18it/s]\u001b[A\n",
      "Iteration:  82% 13025/15836 [1:06:22<12:54,  3.63it/s]\u001b[A\n",
      "Iteration:  82% 13026/15836 [1:06:22<12:03,  3.88it/s]\u001b[A\n",
      "Iteration:  82% 13027/15836 [1:06:22<11:36,  4.03it/s]\u001b[A\n",
      "Iteration:  82% 13028/15836 [1:06:22<11:14,  4.16it/s]\u001b[A\n",
      "Iteration:  82% 13029/15836 [1:06:23<11:03,  4.23it/s]\u001b[A\n",
      "Iteration:  82% 13030/15836 [1:06:23<12:46,  3.66it/s]\u001b[A\n",
      "Iteration:  82% 13031/15836 [1:06:23<12:01,  3.89it/s]\u001b[A\n",
      "Iteration:  82% 13032/15836 [1:06:23<11:29,  4.06it/s]\u001b[A\n",
      "Iteration:  82% 13033/15836 [1:06:24<11:13,  4.16it/s]\u001b[A\n",
      "Iteration:  82% 13034/15836 [1:06:24<11:01,  4.23it/s]\u001b[A\n",
      "Iteration:  82% 13035/15836 [1:06:24<12:43,  3.67it/s]\u001b[A\n",
      "Iteration:  82% 13036/15836 [1:06:24<12:01,  3.88it/s]\u001b[A\n",
      "Iteration:  82% 13037/15836 [1:06:25<11:31,  4.05it/s]\u001b[A\n",
      "Iteration:  82% 13038/15836 [1:06:25<11:13,  4.16it/s]\u001b[A\n",
      "Iteration:  82% 13039/15836 [1:06:25<11:01,  4.23it/s]\u001b[A\n",
      "Iteration:  82% 13040/15836 [1:06:25<12:43,  3.66it/s]\u001b[A\n",
      "Iteration:  82% 13041/15836 [1:06:26<12:01,  3.87it/s]\u001b[A\n",
      "Iteration:  82% 13042/15836 [1:06:26<11:29,  4.05it/s]\u001b[A\n",
      "Iteration:  82% 13043/15836 [1:06:26<11:14,  4.14it/s]\u001b[A\n",
      "Iteration:  82% 13044/15836 [1:06:26<11:03,  4.21it/s]\u001b[A\n",
      "Iteration:  82% 13045/15836 [1:06:27<12:44,  3.65it/s]\u001b[A\n",
      "Iteration:  82% 13046/15836 [1:06:27<11:59,  3.88it/s]\u001b[A\n",
      "Iteration:  82% 13047/15836 [1:06:27<11:25,  4.07it/s]\u001b[A\n",
      "Iteration:  82% 13048/15836 [1:06:27<11:10,  4.16it/s]\u001b[A\n",
      "Iteration:  82% 13049/15836 [1:06:28<10:57,  4.24it/s]\u001b[A\n",
      "Iteration:  82% 13050/15836 [1:06:28<12:39,  3.67it/s]\u001b[A\n",
      "Iteration:  82% 13051/15836 [1:06:28<11:57,  3.88it/s]\u001b[A\n",
      "Iteration:  82% 13052/15836 [1:06:28<11:30,  4.03it/s]\u001b[A\n",
      "Iteration:  82% 13053/15836 [1:06:29<11:09,  4.16it/s]\u001b[A\n",
      "Iteration:  82% 13054/15836 [1:06:29<10:58,  4.22it/s]\u001b[A\n",
      "Iteration:  82% 13055/15836 [1:06:29<12:38,  3.67it/s]\u001b[A\n",
      "Iteration:  82% 13056/15836 [1:06:29<11:58,  3.87it/s]\u001b[A\n",
      "Iteration:  82% 13057/15836 [1:06:30<11:26,  4.05it/s]\u001b[A\n",
      "Iteration:  82% 13058/15836 [1:06:30<11:08,  4.16it/s]\u001b[A\n",
      "Iteration:  82% 13059/15836 [1:06:30<10:53,  4.25it/s]\u001b[A\n",
      "Iteration:  82% 13060/15836 [1:06:30<12:35,  3.67it/s]\u001b[A\n",
      "Iteration:  82% 13061/15836 [1:06:31<11:51,  3.90it/s]\u001b[A\n",
      "Iteration:  82% 13062/15836 [1:06:31<11:21,  4.07it/s]\u001b[A\n",
      "Iteration:  82% 13063/15836 [1:06:31<11:03,  4.18it/s]\u001b[A\n",
      "Iteration:  82% 13064/15836 [1:06:31<10:57,  4.22it/s]\u001b[A\n",
      "Iteration:  83% 13065/15836 [1:06:32<12:39,  3.65it/s]\u001b[A\n",
      "Iteration:  83% 13066/15836 [1:06:32<11:55,  3.87it/s]\u001b[A\n",
      "Iteration:  83% 13067/15836 [1:06:32<11:25,  4.04it/s]\u001b[A\n",
      "Iteration:  83% 13068/15836 [1:06:32<11:08,  4.14it/s]\u001b[A\n",
      "Iteration:  83% 13069/15836 [1:06:33<10:54,  4.23it/s]\u001b[A\n",
      "Iteration:  83% 13070/15836 [1:06:33<12:36,  3.66it/s]\u001b[A\n",
      "Iteration:  83% 13071/15836 [1:06:33<11:52,  3.88it/s]\u001b[A\n",
      "Iteration:  83% 13072/15836 [1:06:33<11:25,  4.03it/s]\u001b[A\n",
      "Iteration:  83% 13073/15836 [1:06:34<11:06,  4.15it/s]\u001b[A\n",
      "Iteration:  83% 13074/15836 [1:06:34<10:54,  4.22it/s]\u001b[A\n",
      "Iteration:  83% 13075/15836 [1:06:34<12:43,  3.62it/s]\u001b[A\n",
      "Iteration:  83% 13076/15836 [1:06:34<11:55,  3.86it/s]\u001b[A\n",
      "Iteration:  83% 13077/15836 [1:06:35<11:23,  4.03it/s]\u001b[A\n",
      "Iteration:  83% 13078/15836 [1:06:35<11:02,  4.17it/s]\u001b[A\n",
      "Iteration:  83% 13079/15836 [1:06:35<10:58,  4.19it/s]\u001b[A\n",
      "Iteration:  83% 13080/15836 [1:06:36<12:37,  3.64it/s]\u001b[A\n",
      "Iteration:  83% 13081/15836 [1:06:36<11:46,  3.90it/s]\u001b[A\n",
      "Iteration:  83% 13082/15836 [1:06:36<11:16,  4.07it/s]\u001b[A\n",
      "Iteration:  83% 13083/15836 [1:06:36<11:00,  4.17it/s]\u001b[A\n",
      "Iteration:  83% 13084/15836 [1:06:36<10:46,  4.26it/s]\u001b[A\n",
      "Iteration:  83% 13085/15836 [1:06:37<12:27,  3.68it/s]\u001b[A\n",
      "Iteration:  83% 13086/15836 [1:06:37<11:46,  3.89it/s]\u001b[A\n",
      "Iteration:  83% 13087/15836 [1:06:37<11:20,  4.04it/s]\u001b[A\n",
      "Iteration:  83% 13088/15836 [1:06:37<11:00,  4.16it/s]\u001b[A\n",
      "Iteration:  83% 13089/15836 [1:06:38<10:48,  4.23it/s]\u001b[A\n",
      "Iteration:  83% 13090/15836 [1:06:38<12:27,  3.68it/s]\u001b[A\n",
      "Iteration:  83% 13091/15836 [1:06:38<11:42,  3.91it/s]\u001b[A\n",
      "Iteration:  83% 13092/15836 [1:06:38<11:10,  4.09it/s]\u001b[A\n",
      "Iteration:  83% 13093/15836 [1:06:39<10:49,  4.22it/s]\u001b[A\n",
      "Iteration:  83% 13094/15836 [1:06:39<10:39,  4.29it/s]\u001b[A\n",
      "Iteration:  83% 13095/15836 [1:06:39<12:21,  3.69it/s]\u001b[A\n",
      "Iteration:  83% 13096/15836 [1:06:39<11:40,  3.91it/s]\u001b[A\n",
      "Iteration:  83% 13097/15836 [1:06:40<11:14,  4.06it/s]\u001b[A\n",
      "Iteration:  83% 13098/15836 [1:06:40<10:55,  4.18it/s]\u001b[A\n",
      "Iteration:  83% 13099/15836 [1:06:40<10:46,  4.23it/s]\u001b[A\n",
      "Iteration:  83% 13100/15836 [1:06:41<12:29,  3.65it/s]\u001b[A\n",
      "Iteration:  83% 13101/15836 [1:06:41<11:41,  3.90it/s]\u001b[A\n",
      "Iteration:  83% 13102/15836 [1:06:41<11:16,  4.04it/s]\u001b[A\n",
      "Iteration:  83% 13103/15836 [1:06:41<10:57,  4.16it/s]\u001b[A\n",
      "Iteration:  83% 13104/15836 [1:06:41<10:46,  4.22it/s]\u001b[A\n",
      "Iteration:  83% 13105/15836 [1:06:42<12:25,  3.66it/s]\u001b[A\n",
      "Iteration:  83% 13106/15836 [1:06:42<11:42,  3.89it/s]\u001b[A\n",
      "Iteration:  83% 13107/15836 [1:06:42<11:15,  4.04it/s]\u001b[A\n",
      "Iteration:  83% 13108/15836 [1:06:42<10:57,  4.15it/s]\u001b[A\n",
      "Iteration:  83% 13109/15836 [1:06:43<10:44,  4.23it/s]\u001b[A\n",
      "Iteration:  83% 13110/15836 [1:06:43<12:22,  3.67it/s]\u001b[A\n",
      "Iteration:  83% 13111/15836 [1:06:43<11:42,  3.88it/s]\u001b[A\n",
      "Iteration:  83% 13112/15836 [1:06:43<11:13,  4.04it/s]\u001b[A\n",
      "Iteration:  83% 13113/15836 [1:06:44<10:52,  4.18it/s]\u001b[A\n",
      "Iteration:  83% 13114/15836 [1:06:44<10:40,  4.25it/s]\u001b[A\n",
      "Iteration:  83% 13115/15836 [1:06:44<12:20,  3.67it/s]\u001b[A\n",
      "Iteration:  83% 13116/15836 [1:06:44<11:35,  3.91it/s]\u001b[A\n",
      "Iteration:  83% 13117/15836 [1:06:45<11:04,  4.09it/s]\u001b[A\n",
      "Iteration:  83% 13118/15836 [1:06:45<10:46,  4.20it/s]\u001b[A\n",
      "Iteration:  83% 13119/15836 [1:06:45<10:35,  4.28it/s]\u001b[A\n",
      "Iteration:  83% 13120/15836 [1:06:46<12:16,  3.69it/s]\u001b[A\n",
      "Iteration:  83% 13121/15836 [1:06:46<11:33,  3.92it/s]\u001b[A\n",
      "Iteration:  83% 13122/15836 [1:06:46<11:05,  4.08it/s]\u001b[A\n",
      "Iteration:  83% 13123/15836 [1:06:46<10:48,  4.18it/s]\u001b[A\n",
      "Iteration:  83% 13124/15836 [1:06:46<10:42,  4.22it/s]\u001b[A\n",
      "Iteration:  83% 13125/15836 [1:06:47<12:22,  3.65it/s]\u001b[A\n",
      "Iteration:  83% 13126/15836 [1:06:47<11:37,  3.89it/s]\u001b[A\n",
      "Iteration:  83% 13127/15836 [1:06:47<11:07,  4.06it/s]\u001b[A\n",
      "Iteration:  83% 13128/15836 [1:06:47<10:52,  4.15it/s]\u001b[A\n",
      "Iteration:  83% 13129/15836 [1:06:48<10:41,  4.22it/s]\u001b[A\n",
      "Iteration:  83% 13130/15836 [1:06:48<12:18,  3.66it/s]\u001b[A\n",
      "Iteration:  83% 13131/15836 [1:06:48<11:31,  3.91it/s]\u001b[A\n",
      "Iteration:  83% 13132/15836 [1:06:48<11:04,  4.07it/s]\u001b[A\n",
      "Iteration:  83% 13133/15836 [1:06:49<10:45,  4.19it/s]\u001b[A\n",
      "Iteration:  83% 13134/15836 [1:06:49<10:32,  4.27it/s]\u001b[A\n",
      "Iteration:  83% 13135/15836 [1:06:49<12:12,  3.69it/s]\u001b[A\n",
      "Iteration:  83% 13136/15836 [1:06:49<11:28,  3.92it/s]\u001b[A\n",
      "Iteration:  83% 13137/15836 [1:06:50<10:59,  4.09it/s]\u001b[A\n",
      "Iteration:  83% 13138/15836 [1:06:50<10:43,  4.19it/s]\u001b[A\n",
      "Iteration:  83% 13139/15836 [1:06:50<10:37,  4.23it/s]\u001b[A\n",
      "Iteration:  83% 13140/15836 [1:06:51<12:15,  3.67it/s]\u001b[A\n",
      "Iteration:  83% 13141/15836 [1:06:51<11:28,  3.91it/s]\u001b[A\n",
      "Iteration:  83% 13142/15836 [1:06:51<10:59,  4.09it/s]\u001b[A\n",
      "Iteration:  83% 13143/15836 [1:06:51<10:43,  4.19it/s]\u001b[A\n",
      "Iteration:  83% 13144/15836 [1:06:51<10:32,  4.25it/s]\u001b[A\n",
      "Iteration:  83% 13145/15836 [1:06:52<12:13,  3.67it/s]\u001b[A\n",
      "Iteration:  83% 13146/15836 [1:06:52<11:24,  3.93it/s]\u001b[A\n",
      "Iteration:  83% 13147/15836 [1:06:52<11:02,  4.06it/s]\u001b[A\n",
      "Iteration:  83% 13148/15836 [1:06:52<10:43,  4.18it/s]\u001b[A\n",
      "Iteration:  83% 13149/15836 [1:06:53<10:34,  4.23it/s]\u001b[A\n",
      "Iteration:  83% 13150/15836 [1:06:53<12:10,  3.68it/s]\u001b[A\n",
      "Iteration:  83% 13151/15836 [1:06:53<11:29,  3.90it/s]\u001b[A\n",
      "Iteration:  83% 13152/15836 [1:06:53<11:00,  4.06it/s]\u001b[A\n",
      "Iteration:  83% 13153/15836 [1:06:54<10:47,  4.14it/s]\u001b[A\n",
      "Iteration:  83% 13154/15836 [1:06:54<10:30,  4.25it/s]\u001b[A\n",
      "Iteration:  83% 13155/15836 [1:06:54<12:10,  3.67it/s]\u001b[A\n",
      "Iteration:  83% 13156/15836 [1:06:54<11:25,  3.91it/s]\u001b[A\n",
      "Iteration:  83% 13157/15836 [1:06:55<10:55,  4.09it/s]\u001b[A\n",
      "Iteration:  83% 13158/15836 [1:06:55<10:36,  4.21it/s]\u001b[A\n",
      "Iteration:  83% 13159/15836 [1:06:55<10:27,  4.27it/s]\u001b[A\n",
      "Iteration:  83% 13160/15836 [1:06:56<12:05,  3.69it/s]\u001b[A\n",
      "Iteration:  83% 13161/15836 [1:06:56<11:24,  3.91it/s]\u001b[A\n",
      "Iteration:  83% 13162/15836 [1:06:56<10:58,  4.06it/s]\u001b[A\n",
      "Iteration:  83% 13163/15836 [1:06:56<10:41,  4.17it/s]\u001b[A\n",
      "Iteration:  83% 13164/15836 [1:06:56<10:28,  4.25it/s]\u001b[A\n",
      "Iteration:  83% 13165/15836 [1:06:57<12:07,  3.67it/s]\u001b[A\n",
      "Iteration:  83% 13166/15836 [1:06:57<11:21,  3.92it/s]\u001b[A\n",
      "Iteration:  83% 13167/15836 [1:06:57<10:55,  4.07it/s]\u001b[A\n",
      "Iteration:  83% 13168/15836 [1:06:57<10:38,  4.18it/s]\u001b[A\n",
      "Iteration:  83% 13169/15836 [1:06:58<10:28,  4.25it/s]\u001b[A\n",
      "Iteration:  83% 13170/15836 [1:06:58<12:08,  3.66it/s]\u001b[A\n",
      "Iteration:  83% 13171/15836 [1:06:58<11:22,  3.90it/s]\u001b[A\n",
      "Iteration:  83% 13172/15836 [1:06:58<10:51,  4.09it/s]\u001b[A\n",
      "Iteration:  83% 13173/15836 [1:06:59<10:37,  4.18it/s]\u001b[A\n",
      "Iteration:  83% 13174/15836 [1:06:59<10:24,  4.26it/s]\u001b[A\n",
      "Iteration:  83% 13175/15836 [1:06:59<12:00,  3.69it/s]\u001b[A\n",
      "Iteration:  83% 13176/15836 [1:06:59<11:19,  3.92it/s]\u001b[A\n",
      "Iteration:  83% 13177/15836 [1:07:00<10:55,  4.05it/s]\u001b[A\n",
      "Iteration:  83% 13178/15836 [1:07:00<10:39,  4.16it/s]\u001b[A\n",
      "Iteration:  83% 13179/15836 [1:07:00<10:28,  4.23it/s]\u001b[A\n",
      "Iteration:  83% 13180/15836 [1:07:01<12:06,  3.65it/s]\u001b[A\n",
      "Iteration:  83% 13181/15836 [1:07:01<11:23,  3.88it/s]\u001b[A\n",
      "Iteration:  83% 13182/15836 [1:07:01<10:55,  4.05it/s]\u001b[A\n",
      "Iteration:  83% 13183/15836 [1:07:01<10:36,  4.17it/s]\u001b[A\n",
      "Iteration:  83% 13184/15836 [1:07:01<10:27,  4.22it/s]\u001b[A\n",
      "Iteration:  83% 13185/15836 [1:07:02<12:03,  3.66it/s]\u001b[A\n",
      "Iteration:  83% 13186/15836 [1:07:02<11:17,  3.91it/s]\u001b[A\n",
      "Iteration:  83% 13187/15836 [1:07:02<10:45,  4.10it/s]\u001b[A\n",
      "Iteration:  83% 13188/15836 [1:07:02<10:27,  4.22it/s]\u001b[A\n",
      "Iteration:  83% 13189/15836 [1:07:03<10:17,  4.28it/s]\u001b[A\n",
      "Iteration:  83% 13190/15836 [1:07:03<11:55,  3.70it/s]\u001b[A\n",
      "Iteration:  83% 13191/15836 [1:07:03<11:13,  3.93it/s]\u001b[A\n",
      "Iteration:  83% 13192/15836 [1:07:03<10:45,  4.09it/s]\u001b[A\n",
      "Iteration:  83% 13193/15836 [1:07:04<10:30,  4.19it/s]\u001b[A\n",
      "Iteration:  83% 13194/15836 [1:07:04<10:19,  4.27it/s]\u001b[A\n",
      "Iteration:  83% 13195/15836 [1:07:04<11:59,  3.67it/s]\u001b[A\n",
      "Iteration:  83% 13196/15836 [1:07:04<11:13,  3.92it/s]\u001b[A\n",
      "Iteration:  83% 13197/15836 [1:07:05<10:45,  4.09it/s]\u001b[A\n",
      "Iteration:  83% 13198/15836 [1:07:05<10:31,  4.18it/s]\u001b[A\n",
      "Iteration:  83% 13199/15836 [1:07:05<10:19,  4.25it/s]\u001b[A\n",
      "Iteration:  83% 13200/15836 [1:07:05<11:56,  3.68it/s]\u001b[A\n",
      "Iteration:  83% 13201/15836 [1:07:06<11:13,  3.91it/s]\u001b[A\n",
      "Iteration:  83% 13202/15836 [1:07:06<10:49,  4.06it/s]\u001b[A\n",
      "Iteration:  83% 13203/15836 [1:07:06<10:32,  4.16it/s]\u001b[A\n",
      "Iteration:  83% 13204/15836 [1:07:06<10:25,  4.21it/s]\u001b[A\n",
      "Iteration:  83% 13205/15836 [1:07:07<11:58,  3.66it/s]\u001b[A\n",
      "Iteration:  83% 13206/15836 [1:07:07<11:13,  3.90it/s]\u001b[A\n",
      "Iteration:  83% 13207/15836 [1:07:07<10:41,  4.10it/s]\u001b[A\n",
      "Iteration:  83% 13208/15836 [1:07:07<10:28,  4.18it/s]\u001b[A\n",
      "Iteration:  83% 13209/15836 [1:07:08<10:15,  4.27it/s]\u001b[A\n",
      "Iteration:  83% 13210/15836 [1:07:08<11:55,  3.67it/s]\u001b[A\n",
      "Iteration:  83% 13211/15836 [1:07:08<11:09,  3.92it/s]\u001b[A\n",
      "Iteration:  83% 13212/15836 [1:07:08<10:47,  4.05it/s]\u001b[A\n",
      "Iteration:  83% 13213/15836 [1:07:09<10:28,  4.17it/s]\u001b[A\n",
      "Iteration:  83% 13214/15836 [1:07:09<10:18,  4.24it/s]\u001b[A\n",
      "Iteration:  83% 13215/15836 [1:07:09<11:53,  3.67it/s]\u001b[A\n",
      "Iteration:  83% 13216/15836 [1:07:09<11:13,  3.89it/s]\u001b[A\n",
      "Iteration:  83% 13217/15836 [1:07:10<10:47,  4.05it/s]\u001b[A\n",
      "Iteration:  83% 13218/15836 [1:07:10<10:30,  4.15it/s]\u001b[A\n",
      "Iteration:  83% 13219/15836 [1:07:10<10:20,  4.22it/s]\u001b[A\n",
      "Iteration:  83% 13220/15836 [1:07:10<11:54,  3.66it/s]\u001b[A\n",
      "Iteration:  83% 13221/15836 [1:07:11<11:13,  3.89it/s]\u001b[A\n",
      "Iteration:  83% 13222/15836 [1:07:11<10:45,  4.05it/s]\u001b[A\n",
      "Iteration:  83% 13223/15836 [1:07:11<10:29,  4.15it/s]\u001b[A\n",
      "Iteration:  84% 13224/15836 [1:07:11<10:16,  4.24it/s]\u001b[A\n",
      "Iteration:  84% 13225/15836 [1:07:12<11:52,  3.66it/s]\u001b[A\n",
      "Iteration:  84% 13226/15836 [1:07:12<11:10,  3.89it/s]\u001b[A\n",
      "Iteration:  84% 13227/15836 [1:07:12<10:42,  4.06it/s]\u001b[A\n",
      "Iteration:  84% 13228/15836 [1:07:12<10:26,  4.16it/s]\u001b[A\n",
      "Iteration:  84% 13229/15836 [1:07:13<10:13,  4.25it/s]\u001b[A\n",
      "Iteration:  84% 13230/15836 [1:07:13<11:51,  3.66it/s]\u001b[A\n",
      "Iteration:  84% 13231/15836 [1:07:13<11:10,  3.89it/s]\u001b[A\n",
      "Iteration:  84% 13232/15836 [1:07:13<10:42,  4.05it/s]\u001b[A\n",
      "Iteration:  84% 13233/15836 [1:07:14<10:27,  4.15it/s]\u001b[A\n",
      "Iteration:  84% 13234/15836 [1:07:14<10:18,  4.21it/s]\u001b[A\n",
      "Iteration:  84% 13235/15836 [1:07:14<11:53,  3.64it/s]\u001b[A\n",
      "Iteration:  84% 13236/15836 [1:07:14<11:06,  3.90it/s]\u001b[A\n",
      "Iteration:  84% 13237/15836 [1:07:15<10:38,  4.07it/s]\u001b[A\n",
      "Iteration:  84% 13238/15836 [1:07:15<10:20,  4.19it/s]\u001b[A\n",
      "Iteration:  84% 13239/15836 [1:07:15<10:11,  4.24it/s]\u001b[A\n",
      "Iteration:  84% 13240/15836 [1:07:16<11:47,  3.67it/s]\u001b[A\n",
      "Iteration:  84% 13241/15836 [1:07:16<11:02,  3.92it/s]\u001b[A\n",
      "Iteration:  84% 13242/15836 [1:07:16<10:34,  4.09it/s]\u001b[A\n",
      "Iteration:  84% 13243/15836 [1:07:16<10:21,  4.17it/s]\u001b[A\n",
      "Iteration:  84% 13244/15836 [1:07:16<10:13,  4.23it/s]\u001b[A\n",
      "Iteration:  84% 13245/15836 [1:07:17<11:49,  3.65it/s]\u001b[A\n",
      "Iteration:  84% 13246/15836 [1:07:17<11:07,  3.88it/s]\u001b[A\n",
      "Iteration:  84% 13247/15836 [1:07:17<10:43,  4.02it/s]\u001b[A\n",
      "Iteration:  84% 13248/15836 [1:07:17<10:24,  4.15it/s]\u001b[A\n",
      "Iteration:  84% 13249/15836 [1:07:18<10:15,  4.20it/s]\u001b[A\n",
      "Iteration:  84% 13250/15836 [1:07:18<11:48,  3.65it/s]\u001b[A\n",
      "Iteration:  84% 13251/15836 [1:07:18<11:05,  3.89it/s]\u001b[A\n",
      "Iteration:  84% 13252/15836 [1:07:18<10:37,  4.06it/s]\u001b[A\n",
      "Iteration:  84% 13253/15836 [1:07:19<10:22,  4.15it/s]\u001b[A\n",
      "Iteration:  84% 13254/15836 [1:07:19<10:11,  4.22it/s]\u001b[A\n",
      "Iteration:  84% 13255/15836 [1:07:19<11:44,  3.66it/s]\u001b[A\n",
      "Iteration:  84% 13256/15836 [1:07:19<11:04,  3.88it/s]\u001b[A\n",
      "Iteration:  84% 13257/15836 [1:07:20<10:36,  4.05it/s]\u001b[A\n",
      "Iteration:  84% 13258/15836 [1:07:20<10:21,  4.15it/s]\u001b[A\n",
      "Iteration:  84% 13259/15836 [1:07:20<10:11,  4.22it/s]\u001b[A\n",
      "Iteration:  84% 13260/15836 [1:07:21<11:43,  3.66it/s]\u001b[A\n",
      "Iteration:  84% 13261/15836 [1:07:21<11:02,  3.89it/s]\u001b[A\n",
      "Iteration:  84% 13262/15836 [1:07:21<10:34,  4.06it/s]\u001b[A\n",
      "Iteration:  84% 13263/15836 [1:07:21<10:17,  4.16it/s]\u001b[A\n",
      "Iteration:  84% 13264/15836 [1:07:21<10:05,  4.25it/s]\u001b[A\n",
      "Iteration:  84% 13265/15836 [1:07:22<11:42,  3.66it/s]\u001b[A\n",
      "Iteration:  84% 13266/15836 [1:07:22<11:00,  3.89it/s]\u001b[A\n",
      "Iteration:  84% 13267/15836 [1:07:22<10:36,  4.03it/s]\u001b[A\n",
      "Iteration:  84% 13268/15836 [1:07:22<10:19,  4.14it/s]\u001b[A\n",
      "Iteration:  84% 13269/15836 [1:07:23<10:10,  4.21it/s]\u001b[A\n",
      "Iteration:  84% 13270/15836 [1:07:23<11:43,  3.65it/s]\u001b[A\n",
      "Iteration:  84% 13271/15836 [1:07:23<10:58,  3.90it/s]\u001b[A\n",
      "Iteration:  84% 13272/15836 [1:07:23<10:32,  4.06it/s]\u001b[A\n",
      "Iteration:  84% 13273/15836 [1:07:24<10:17,  4.15it/s]\u001b[A\n",
      "Iteration:  84% 13274/15836 [1:07:24<10:07,  4.22it/s]\u001b[A\n",
      "Iteration:  84% 13275/15836 [1:07:24<11:38,  3.67it/s]\u001b[A\n",
      "Iteration:  84% 13276/15836 [1:07:25<10:58,  3.89it/s]\u001b[A\n",
      "Iteration:  84% 13277/15836 [1:07:25<10:33,  4.04it/s]\u001b[A\n",
      "Iteration:  84% 13278/15836 [1:07:25<10:16,  4.15it/s]\u001b[A\n",
      "Iteration:  84% 13279/15836 [1:07:25<10:06,  4.21it/s]\u001b[A\n",
      "Iteration:  84% 13280/15836 [1:07:26<11:39,  3.65it/s]\u001b[A\n",
      "Iteration:  84% 13281/15836 [1:07:26<10:57,  3.88it/s]\u001b[A\n",
      "Iteration:  84% 13282/15836 [1:07:26<10:32,  4.04it/s]\u001b[A\n",
      "Iteration:  84% 13283/15836 [1:07:26<10:13,  4.16it/s]\u001b[A\n",
      "Iteration:  84% 13284/15836 [1:07:26<10:03,  4.23it/s]\u001b[A\n",
      "Iteration:  84% 13285/15836 [1:07:27<11:35,  3.67it/s]\u001b[A\n",
      "Iteration:  84% 13286/15836 [1:07:27<10:54,  3.90it/s]\u001b[A\n",
      "Iteration:  84% 13287/15836 [1:07:27<10:28,  4.05it/s]\u001b[A\n",
      "Iteration:  84% 13288/15836 [1:07:27<10:13,  4.15it/s]\u001b[A\n",
      "Iteration:  84% 13289/15836 [1:07:28<10:02,  4.23it/s]\u001b[A\n",
      "Iteration:  84% 13290/15836 [1:07:28<11:33,  3.67it/s]\u001b[A\n",
      "Iteration:  84% 13291/15836 [1:07:28<10:56,  3.88it/s]\u001b[A\n",
      "Iteration:  84% 13292/15836 [1:07:28<10:30,  4.03it/s]\u001b[A\n",
      "Iteration:  84% 13293/15836 [1:07:29<10:11,  4.16it/s]\u001b[A\n",
      "Iteration:  84% 13294/15836 [1:07:29<10:00,  4.23it/s]\u001b[A\n",
      "Iteration:  84% 13295/15836 [1:07:29<11:32,  3.67it/s]\u001b[A\n",
      "Iteration:  84% 13296/15836 [1:07:30<10:56,  3.87it/s]\u001b[A\n",
      "Iteration:  84% 13297/15836 [1:07:30<10:26,  4.05it/s]\u001b[A\n",
      "Iteration:  84% 13298/15836 [1:07:30<10:11,  4.15it/s]\u001b[A\n",
      "Iteration:  84% 13299/15836 [1:07:30<10:00,  4.22it/s]\u001b[A\n",
      "Iteration:  84% 13300/15836 [1:07:31<11:33,  3.66it/s]\u001b[A\n",
      "Iteration:  84% 13301/15836 [1:07:31<10:53,  3.88it/s]\u001b[A\n",
      "Iteration:  84% 13302/15836 [1:07:31<10:27,  4.04it/s]\u001b[A\n",
      "Iteration:  84% 13303/15836 [1:07:31<10:08,  4.16it/s]\u001b[A\n",
      "Iteration:  84% 13304/15836 [1:07:31<09:58,  4.23it/s]\u001b[A\n",
      "Iteration:  84% 13305/15836 [1:07:32<11:32,  3.65it/s]\u001b[A\n",
      "Iteration:  84% 13306/15836 [1:07:32<10:51,  3.88it/s]\u001b[A\n",
      "Iteration:  84% 13307/15836 [1:07:32<10:24,  4.05it/s]\u001b[A\n",
      "Iteration:  84% 13308/15836 [1:07:32<10:07,  4.16it/s]\u001b[A\n",
      "Iteration:  84% 13309/15836 [1:07:33<09:59,  4.22it/s]\u001b[A\n",
      "Iteration:  84% 13310/15836 [1:07:33<11:33,  3.64it/s]\u001b[A\n",
      "Iteration:  84% 13311/15836 [1:07:33<10:50,  3.88it/s]\u001b[A\n",
      "Iteration:  84% 13312/15836 [1:07:34<10:22,  4.05it/s]\u001b[A\n",
      "Iteration:  84% 13313/15836 [1:07:34<10:06,  4.16it/s]\u001b[A\n",
      "Iteration:  84% 13314/15836 [1:07:34<09:54,  4.24it/s]\u001b[A\n",
      "Iteration:  84% 13315/15836 [1:07:34<11:27,  3.67it/s]\u001b[A\n",
      "Iteration:  84% 13316/15836 [1:07:35<10:47,  3.89it/s]\u001b[A\n",
      "Iteration:  84% 13317/15836 [1:07:35<10:17,  4.08it/s]\u001b[A\n",
      "Iteration:  84% 13318/15836 [1:07:35<10:04,  4.16it/s]\u001b[A\n",
      "Iteration:  84% 13319/15836 [1:07:35<09:59,  4.20it/s]\u001b[A\n",
      "Iteration:  84% 13320/15836 [1:07:36<11:32,  3.63it/s]\u001b[A\n",
      "Iteration:  84% 13321/15836 [1:07:36<10:47,  3.88it/s]\u001b[A\n",
      "Iteration:  84% 13322/15836 [1:07:36<10:22,  4.04it/s]\u001b[A\n",
      "Iteration:  84% 13323/15836 [1:07:36<10:07,  4.13it/s]\u001b[A\n",
      "Iteration:  84% 13324/15836 [1:07:36<09:57,  4.21it/s]\u001b[A\n",
      "Iteration:  84% 13325/15836 [1:07:37<11:27,  3.65it/s]\u001b[A\n",
      "Iteration:  84% 13326/15836 [1:07:37<10:47,  3.88it/s]\u001b[A\n",
      "Iteration:  84% 13327/15836 [1:07:37<10:20,  4.04it/s]\u001b[A\n",
      "Iteration:  84% 13328/15836 [1:07:38<10:03,  4.16it/s]\u001b[A\n",
      "Iteration:  84% 13329/15836 [1:07:38<09:53,  4.23it/s]\u001b[A\n",
      "Iteration:  84% 13330/15836 [1:07:38<11:23,  3.66it/s]\u001b[A\n",
      "Iteration:  84% 13331/15836 [1:07:38<10:47,  3.87it/s]\u001b[A\n",
      "Iteration:  84% 13332/15836 [1:07:39<10:20,  4.04it/s]\u001b[A\n",
      "Iteration:  84% 13333/15836 [1:07:39<10:01,  4.16it/s]\u001b[A\n",
      "Iteration:  84% 13334/15836 [1:07:39<09:50,  4.23it/s]\u001b[A\n",
      "Iteration:  84% 13335/15836 [1:07:39<11:21,  3.67it/s]\u001b[A\n",
      "Iteration:  84% 13336/15836 [1:07:40<10:44,  3.88it/s]\u001b[A\n",
      "Iteration:  84% 13337/15836 [1:07:40<10:19,  4.03it/s]\u001b[A\n",
      "Iteration:  84% 13338/15836 [1:07:40<10:02,  4.14it/s]\u001b[A\n",
      "Iteration:  84% 13339/15836 [1:07:40<09:51,  4.22it/s]\u001b[A\n",
      "Iteration:  84% 13340/15836 [1:07:41<11:21,  3.66it/s]\u001b[A\n",
      "Iteration:  84% 13341/15836 [1:07:41<10:44,  3.87it/s]\u001b[A\n",
      "Iteration:  84% 13342/15836 [1:07:41<10:17,  4.04it/s]\u001b[A\n",
      "Iteration:  84% 13343/15836 [1:07:41<10:01,  4.15it/s]\u001b[A\n",
      "Iteration:  84% 13344/15836 [1:07:42<09:50,  4.22it/s]\u001b[A\n",
      "Iteration:  84% 13345/15836 [1:07:42<11:23,  3.64it/s]\u001b[A\n",
      "Iteration:  84% 13346/15836 [1:07:42<10:41,  3.88it/s]\u001b[A\n",
      "Iteration:  84% 13347/15836 [1:07:42<10:16,  4.04it/s]\u001b[A\n",
      "Iteration:  84% 13348/15836 [1:07:43<09:57,  4.17it/s]\u001b[A\n",
      "Iteration:  84% 13349/15836 [1:07:43<09:46,  4.24it/s]\u001b[A\n",
      "Iteration:  84% 13350/15836 [1:07:43<11:18,  3.67it/s]\u001b[A\n",
      "Iteration:  84% 13351/15836 [1:07:43<10:39,  3.89it/s]\u001b[A\n",
      "Iteration:  84% 13352/15836 [1:07:44<10:11,  4.06it/s]\u001b[A\n",
      "Iteration:  84% 13353/15836 [1:07:44<09:57,  4.16it/s]\u001b[A\n",
      "Iteration:  84% 13354/15836 [1:07:44<09:45,  4.24it/s]\u001b[A\n",
      "Iteration:  84% 13355/15836 [1:07:44<11:16,  3.67it/s]\u001b[A\n",
      "Iteration:  84% 13356/15836 [1:07:45<10:35,  3.90it/s]\u001b[A\n",
      "Iteration:  84% 13357/15836 [1:07:45<10:13,  4.04it/s]\u001b[A\n",
      "Iteration:  84% 13358/15836 [1:07:45<09:57,  4.14it/s]\u001b[A\n",
      "Iteration:  84% 13359/15836 [1:07:45<09:47,  4.21it/s]\u001b[A\n",
      "Iteration:  84% 13360/15836 [1:07:46<11:20,  3.64it/s]\u001b[A\n",
      "Iteration:  84% 13361/15836 [1:07:46<10:38,  3.88it/s]\u001b[A\n",
      "Iteration:  84% 13362/15836 [1:07:46<10:08,  4.07it/s]\u001b[A\n",
      "Iteration:  84% 13363/15836 [1:07:46<09:55,  4.15it/s]\u001b[A\n",
      "Iteration:  84% 13364/15836 [1:07:47<09:45,  4.22it/s]\u001b[A\n",
      "Iteration:  84% 13365/15836 [1:07:47<11:14,  3.66it/s]\u001b[A\n",
      "Iteration:  84% 13366/15836 [1:07:47<10:34,  3.89it/s]\u001b[A\n",
      "Iteration:  84% 13367/15836 [1:07:47<10:10,  4.05it/s]\u001b[A\n",
      "Iteration:  84% 13368/15836 [1:07:48<09:52,  4.16it/s]\u001b[A\n",
      "Iteration:  84% 13369/15836 [1:07:48<09:44,  4.22it/s]\u001b[A\n",
      "Iteration:  84% 13370/15836 [1:07:48<11:12,  3.66it/s]\u001b[A\n",
      "Iteration:  84% 13371/15836 [1:07:48<10:36,  3.87it/s]\u001b[A\n",
      "Iteration:  84% 13372/15836 [1:07:49<10:07,  4.05it/s]\u001b[A\n",
      "Iteration:  84% 13373/15836 [1:07:49<09:52,  4.15it/s]\u001b[A\n",
      "Iteration:  84% 13374/15836 [1:07:49<09:44,  4.21it/s]\u001b[A\n",
      "Iteration:  84% 13375/15836 [1:07:49<11:13,  3.66it/s]\u001b[A\n",
      "Iteration:  84% 13376/15836 [1:07:50<10:30,  3.90it/s]\u001b[A\n",
      "Iteration:  84% 13377/15836 [1:07:50<10:06,  4.05it/s]\u001b[A\n",
      "Iteration:  84% 13378/15836 [1:07:50<09:50,  4.16it/s]\u001b[A\n",
      "Iteration:  84% 13379/15836 [1:07:50<09:41,  4.22it/s]\u001b[A\n",
      "Iteration:  84% 13380/15836 [1:07:51<11:11,  3.66it/s]\u001b[A\n",
      "Iteration:  84% 13381/15836 [1:07:51<10:32,  3.88it/s]\u001b[A\n",
      "Iteration:  85% 13382/15836 [1:07:51<10:05,  4.05it/s]\u001b[A\n",
      "Iteration:  85% 13383/15836 [1:07:51<09:51,  4.15it/s]\u001b[A\n",
      "Iteration:  85% 13384/15836 [1:07:52<09:41,  4.22it/s]\u001b[A\n",
      "Iteration:  85% 13385/15836 [1:07:52<11:11,  3.65it/s]\u001b[A\n",
      "Iteration:  85% 13386/15836 [1:07:52<10:31,  3.88it/s]\u001b[A\n",
      "Iteration:  85% 13387/15836 [1:07:52<10:06,  4.04it/s]\u001b[A\n",
      "Iteration:  85% 13388/15836 [1:07:53<09:49,  4.15it/s]\u001b[A\n",
      "Iteration:  85% 13389/15836 [1:07:53<09:38,  4.23it/s]\u001b[A\n",
      "Iteration:  85% 13390/15836 [1:07:53<11:07,  3.66it/s]\u001b[A\n",
      "Iteration:  85% 13391/15836 [1:07:53<10:29,  3.88it/s]\u001b[A\n",
      "Iteration:  85% 13392/15836 [1:07:54<10:06,  4.03it/s]\u001b[A\n",
      "Iteration:  85% 13393/15836 [1:07:54<09:48,  4.15it/s]\u001b[A\n",
      "Iteration:  85% 13394/15836 [1:07:54<09:34,  4.25it/s]\u001b[A\n",
      "Iteration:  85% 13395/15836 [1:07:54<11:05,  3.67it/s]\u001b[A\n",
      "Iteration:  85% 13396/15836 [1:07:55<10:25,  3.90it/s]\u001b[A\n",
      "Iteration:  85% 13397/15836 [1:07:55<10:04,  4.04it/s]\u001b[A\n",
      "Iteration:  85% 13398/15836 [1:07:55<09:47,  4.15it/s]\u001b[A\n",
      "Iteration:  85% 13399/15836 [1:07:55<09:37,  4.22it/s]\u001b[A\n",
      "Iteration:  85% 13400/15836 [1:07:56<11:04,  3.66it/s]\u001b[A\n",
      "Iteration:  85% 13401/15836 [1:07:56<10:25,  3.89it/s]\u001b[A\n",
      "Iteration:  85% 13402/15836 [1:07:56<10:00,  4.06it/s]\u001b[A\n",
      "Iteration:  85% 13403/15836 [1:07:56<09:44,  4.16it/s]\u001b[A\n",
      "Iteration:  85% 13404/15836 [1:07:57<09:35,  4.23it/s]\u001b[A\n",
      "Iteration:  85% 13405/15836 [1:07:57<11:05,  3.66it/s]\u001b[A\n",
      "Iteration:  85% 13406/15836 [1:07:57<10:23,  3.89it/s]\u001b[A\n",
      "Iteration:  85% 13407/15836 [1:07:57<09:58,  4.06it/s]\u001b[A\n",
      "Iteration:  85% 13408/15836 [1:07:58<09:43,  4.16it/s]\u001b[A\n",
      "Iteration:  85% 13409/15836 [1:07:58<09:30,  4.25it/s]\u001b[A\n",
      "Iteration:  85% 13410/15836 [1:07:58<11:03,  3.66it/s]\u001b[A\n",
      "Iteration:  85% 13411/15836 [1:07:58<10:21,  3.90it/s]\u001b[A\n",
      "Iteration:  85% 13412/15836 [1:07:59<09:55,  4.07it/s]\u001b[A\n",
      "Iteration:  85% 13413/15836 [1:07:59<09:41,  4.17it/s]\u001b[A\n",
      "Iteration:  85% 13414/15836 [1:07:59<09:32,  4.23it/s]\u001b[A\n",
      "Iteration:  85% 13415/15836 [1:07:59<11:01,  3.66it/s]\u001b[A\n",
      "Iteration:  85% 13416/15836 [1:08:00<10:20,  3.90it/s]\u001b[A\n",
      "Iteration:  85% 13417/15836 [1:08:00<09:55,  4.06it/s]\u001b[A\n",
      "Iteration:  85% 13418/15836 [1:08:00<09:39,  4.18it/s]\u001b[A\n",
      "Iteration:  85% 13419/15836 [1:08:00<09:27,  4.26it/s]\u001b[A\n",
      "Iteration:  85% 13420/15836 [1:08:01<10:55,  3.68it/s]\u001b[A\n",
      "Iteration:  85% 13421/15836 [1:08:01<10:17,  3.91it/s]\u001b[A\n",
      "Iteration:  85% 13422/15836 [1:08:01<09:54,  4.06it/s]\u001b[A\n",
      "Iteration:  85% 13423/15836 [1:08:01<09:43,  4.14it/s]\u001b[A\n",
      "Iteration:  85% 13424/15836 [1:08:02<09:33,  4.20it/s]\u001b[A\n",
      "Iteration:  85% 13425/15836 [1:08:02<11:02,  3.64it/s]\u001b[A\n",
      "Iteration:  85% 13426/15836 [1:08:02<10:20,  3.88it/s]\u001b[A\n",
      "Iteration:  85% 13427/15836 [1:08:02<09:55,  4.05it/s]\u001b[A\n",
      "Iteration:  85% 13428/15836 [1:08:03<09:40,  4.15it/s]\u001b[A\n",
      "Iteration:  85% 13429/15836 [1:08:03<09:32,  4.21it/s]\u001b[A\n",
      "Iteration:  85% 13430/15836 [1:08:03<11:01,  3.64it/s]\u001b[A\n",
      "Iteration:  85% 13431/15836 [1:08:03<10:18,  3.89it/s]\u001b[A\n",
      "Iteration:  85% 13432/15836 [1:08:04<09:55,  4.04it/s]\u001b[A\n",
      "Iteration:  85% 13433/15836 [1:08:04<09:40,  4.14it/s]\u001b[A\n",
      "Iteration:  85% 13434/15836 [1:08:04<09:30,  4.21it/s]\u001b[A\n",
      "Iteration:  85% 13435/15836 [1:08:04<10:57,  3.65it/s]\u001b[A\n",
      "Iteration:  85% 13436/15836 [1:08:05<10:16,  3.89it/s]\u001b[A\n",
      "Iteration:  85% 13437/15836 [1:08:05<09:52,  4.05it/s]\u001b[A\n",
      "Iteration:  85% 13438/15836 [1:08:05<09:35,  4.17it/s]\u001b[A\n",
      "Iteration:  85% 13439/15836 [1:08:05<09:26,  4.23it/s]\u001b[A\n",
      "Iteration:  85% 13440/15836 [1:08:06<10:53,  3.66it/s]\u001b[A\n",
      "Iteration:  85% 13441/15836 [1:08:06<10:15,  3.89it/s]\u001b[A\n",
      "Iteration:  85% 13442/15836 [1:08:06<09:52,  4.04it/s]\u001b[A\n",
      "Iteration:  85% 13443/15836 [1:08:06<09:35,  4.16it/s]\u001b[A\n",
      "Iteration:  85% 13444/15836 [1:08:07<09:26,  4.22it/s]\u001b[A\n",
      "Iteration:  85% 13445/15836 [1:08:07<10:55,  3.65it/s]\u001b[A\n",
      "Iteration:  85% 13446/15836 [1:08:07<10:15,  3.88it/s]\u001b[A\n",
      "Iteration:  85% 13447/15836 [1:08:07<09:51,  4.04it/s]\u001b[A\n",
      "Iteration:  85% 13448/15836 [1:08:08<09:32,  4.17it/s]\u001b[A\n",
      "Iteration:  85% 13449/15836 [1:08:08<09:24,  4.23it/s]\u001b[A\n",
      "Iteration:  85% 13450/15836 [1:08:08<10:52,  3.66it/s]\u001b[A\n",
      "Iteration:  85% 13451/15836 [1:08:08<10:15,  3.87it/s]\u001b[A\n",
      "Iteration:  85% 13452/15836 [1:08:09<09:50,  4.04it/s]\u001b[A\n",
      "Iteration:  85% 13453/15836 [1:08:09<09:31,  4.17it/s]\u001b[A\n",
      "Iteration:  85% 13454/15836 [1:08:09<09:24,  4.22it/s]\u001b[A\n",
      "Iteration:  85% 13455/15836 [1:08:09<10:51,  3.65it/s]\u001b[A\n",
      "Iteration:  85% 13456/15836 [1:08:10<10:13,  3.88it/s]\u001b[A\n",
      "Iteration:  85% 13457/15836 [1:08:10<09:46,  4.06it/s]\u001b[A\n",
      "Iteration:  85% 13458/15836 [1:08:10<09:33,  4.15it/s]\u001b[A\n",
      "Iteration:  85% 13459/15836 [1:08:10<09:24,  4.21it/s]\u001b[A\n",
      "Iteration:  85% 13460/15836 [1:08:11<10:50,  3.65it/s]\u001b[A\n",
      "Iteration:  85% 13461/15836 [1:08:11<10:11,  3.88it/s]\u001b[A\n",
      "Iteration:  85% 13462/15836 [1:08:11<09:45,  4.05it/s]\u001b[A\n",
      "Iteration:  85% 13463/15836 [1:08:11<09:30,  4.16it/s]\u001b[A\n",
      "Iteration:  85% 13464/15836 [1:08:12<09:19,  4.24it/s]\u001b[A\n",
      "Iteration:  85% 13465/15836 [1:08:12<10:46,  3.67it/s]\u001b[A\n",
      "Iteration:  85% 13466/15836 [1:08:12<10:10,  3.88it/s]\u001b[A\n",
      "Iteration:  85% 13467/15836 [1:08:12<09:44,  4.05it/s]\u001b[A\n",
      "Iteration:  85% 13468/15836 [1:08:13<09:31,  4.15it/s]\u001b[A\n",
      "Iteration:  85% 13469/15836 [1:08:13<09:20,  4.22it/s]\u001b[A\n",
      "Iteration:  85% 13470/15836 [1:08:13<10:50,  3.64it/s]\u001b[A\n",
      "Iteration:  85% 13471/15836 [1:08:13<10:09,  3.88it/s]\u001b[A\n",
      "Iteration:  85% 13472/15836 [1:08:14<09:45,  4.04it/s]\u001b[A\n",
      "Iteration:  85% 13473/15836 [1:08:14<09:27,  4.16it/s]\u001b[A\n",
      "Iteration:  85% 13474/15836 [1:08:14<09:21,  4.21it/s]\u001b[A\n",
      "Iteration:  85% 13475/15836 [1:08:15<10:48,  3.64it/s]\u001b[A\n",
      "Iteration:  85% 13476/15836 [1:08:15<10:06,  3.89it/s]\u001b[A\n",
      "Iteration:  85% 13477/15836 [1:08:15<09:42,  4.05it/s]\u001b[A\n",
      "Iteration:  85% 13478/15836 [1:08:15<09:28,  4.15it/s]\u001b[A\n",
      "Iteration:  85% 13479/15836 [1:08:15<09:19,  4.22it/s]\u001b[A\n",
      "Iteration:  85% 13480/15836 [1:08:16<10:47,  3.64it/s]\u001b[A\n",
      "Iteration:  85% 13481/15836 [1:08:16<10:05,  3.89it/s]\u001b[A\n",
      "Iteration:  85% 13482/15836 [1:08:16<09:41,  4.05it/s]\u001b[A\n",
      "Iteration:  85% 13483/15836 [1:08:16<09:27,  4.14it/s]\u001b[A\n",
      "Iteration:  85% 13484/15836 [1:08:17<09:15,  4.23it/s]\u001b[A\n",
      "Iteration:  85% 13485/15836 [1:08:17<10:41,  3.66it/s]\u001b[A\n",
      "Iteration:  85% 13486/15836 [1:08:17<10:03,  3.89it/s]\u001b[A\n",
      "Iteration:  85% 13487/15836 [1:08:17<09:41,  4.04it/s]\u001b[A\n",
      "Iteration:  85% 13488/15836 [1:08:18<09:24,  4.16it/s]\u001b[A\n",
      "Iteration:  85% 13489/15836 [1:08:18<09:13,  4.24it/s]\u001b[A\n",
      "Iteration:  85% 13490/15836 [1:08:18<10:43,  3.65it/s]\u001b[A\n",
      "Iteration:  85% 13491/15836 [1:08:18<10:05,  3.87it/s]\u001b[A\n",
      "Iteration:  85% 13492/15836 [1:08:19<09:39,  4.05it/s]\u001b[A\n",
      "Iteration:  85% 13493/15836 [1:08:19<09:25,  4.15it/s]\u001b[A\n",
      "Iteration:  85% 13494/15836 [1:08:19<09:15,  4.22it/s]\u001b[A\n",
      "Iteration:  85% 13495/15836 [1:08:20<10:39,  3.66it/s]\u001b[A\n",
      "Iteration:  85% 13496/15836 [1:08:20<10:03,  3.88it/s]\u001b[A\n",
      "Iteration:  85% 13497/15836 [1:08:20<09:37,  4.05it/s]\u001b[A\n",
      "Iteration:  85% 13498/15836 [1:08:20<09:22,  4.15it/s]\u001b[A\n",
      "Iteration:  85% 13499/15836 [1:08:20<09:10,  4.25it/s]\u001b[A\n",
      "Iteration:  85% 13500/15836 [1:08:21<10:36,  3.67it/s]\u001b[A\n",
      "Iteration:  85% 13501/15836 [1:08:21<10:00,  3.89it/s]\u001b[A\n",
      "Iteration:  85% 13502/15836 [1:08:21<09:33,  4.07it/s]\u001b[A\n",
      "Iteration:  85% 13503/15836 [1:08:21<09:19,  4.17it/s]\u001b[A\n",
      "Iteration:  85% 13504/15836 [1:08:22<09:10,  4.23it/s]\u001b[A\n",
      "Iteration:  85% 13505/15836 [1:08:22<10:38,  3.65it/s]\u001b[A\n",
      "Iteration:  85% 13506/15836 [1:08:22<09:58,  3.89it/s]\u001b[A\n",
      "Iteration:  85% 13507/15836 [1:08:22<09:32,  4.07it/s]\u001b[A\n",
      "Iteration:  85% 13508/15836 [1:08:23<09:19,  4.16it/s]\u001b[A\n",
      "Iteration:  85% 13509/15836 [1:08:23<09:09,  4.23it/s]\u001b[A\n",
      "Iteration:  85% 13510/15836 [1:08:23<10:34,  3.66it/s]\u001b[A\n",
      "Iteration:  85% 13511/15836 [1:08:23<09:57,  3.89it/s]\u001b[A\n",
      "Iteration:  85% 13512/15836 [1:08:24<09:31,  4.07it/s]\u001b[A\n",
      "Iteration:  85% 13513/15836 [1:08:24<09:18,  4.16it/s]\u001b[A\n",
      "Iteration:  85% 13514/15836 [1:08:24<09:06,  4.25it/s]\u001b[A\n",
      "Iteration:  85% 13515/15836 [1:08:25<10:30,  3.68it/s]\u001b[A\n",
      "Iteration:  85% 13516/15836 [1:08:25<09:54,  3.91it/s]\u001b[A\n",
      "Iteration:  85% 13517/15836 [1:08:25<09:34,  4.04it/s]\u001b[A\n",
      "Iteration:  85% 13518/15836 [1:08:25<09:17,  4.16it/s]\u001b[A\n",
      "Iteration:  85% 13519/15836 [1:08:25<09:10,  4.21it/s]\u001b[A\n",
      "Iteration:  85% 13520/15836 [1:08:26<10:35,  3.64it/s]\u001b[A\n",
      "Iteration:  85% 13521/15836 [1:08:26<09:57,  3.88it/s]\u001b[A\n",
      "Iteration:  85% 13522/15836 [1:08:26<09:31,  4.05it/s]\u001b[A\n",
      "Iteration:  85% 13523/15836 [1:08:26<09:15,  4.17it/s]\u001b[A\n",
      "Iteration:  85% 13524/15836 [1:08:27<09:06,  4.23it/s]\u001b[A\n",
      "Iteration:  85% 13525/15836 [1:08:27<10:32,  3.65it/s]\u001b[A\n",
      "Iteration:  85% 13526/15836 [1:08:27<09:54,  3.89it/s]\u001b[A\n",
      "Iteration:  85% 13527/15836 [1:08:27<09:28,  4.06it/s]\u001b[A\n",
      "Iteration:  85% 13528/15836 [1:08:28<09:12,  4.18it/s]\u001b[A\n",
      "Iteration:  85% 13529/15836 [1:08:28<09:04,  4.24it/s]\u001b[A\n",
      "Iteration:  85% 13530/15836 [1:08:28<10:29,  3.66it/s]\u001b[A\n",
      "Iteration:  85% 13531/15836 [1:08:29<09:52,  3.89it/s]\u001b[A\n",
      "Iteration:  85% 13532/15836 [1:08:29<09:29,  4.05it/s]\u001b[A\n",
      "Iteration:  85% 13533/15836 [1:08:29<09:13,  4.16it/s]\u001b[A\n",
      "Iteration:  85% 13534/15836 [1:08:29<09:03,  4.23it/s]\u001b[A\n",
      "Iteration:  85% 13535/15836 [1:08:30<10:27,  3.67it/s]\u001b[A\n",
      "Iteration:  85% 13536/15836 [1:08:30<09:52,  3.88it/s]\u001b[A\n",
      "Iteration:  85% 13537/15836 [1:08:30<09:28,  4.05it/s]\u001b[A\n",
      "Iteration:  85% 13538/15836 [1:08:30<09:11,  4.16it/s]\u001b[A\n",
      "Iteration:  85% 13539/15836 [1:08:30<09:03,  4.22it/s]\u001b[A\n",
      "Iteration:  86% 13540/15836 [1:08:31<10:26,  3.67it/s]\u001b[A\n",
      "Iteration:  86% 13541/15836 [1:08:31<09:51,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13542/15836 [1:08:31<09:27,  4.04it/s]\u001b[A\n",
      "Iteration:  86% 13543/15836 [1:08:31<09:11,  4.16it/s]\u001b[A\n",
      "Iteration:  86% 13544/15836 [1:08:32<09:02,  4.23it/s]\u001b[A\n",
      "Iteration:  86% 13545/15836 [1:08:32<10:25,  3.66it/s]\u001b[A\n",
      "Iteration:  86% 13546/15836 [1:08:32<09:50,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13547/15836 [1:08:33<09:25,  4.05it/s]\u001b[A\n",
      "Iteration:  86% 13548/15836 [1:08:33<09:08,  4.17it/s]\u001b[A\n",
      "Iteration:  86% 13549/15836 [1:08:33<09:02,  4.22it/s]\u001b[A\n",
      "Iteration:  86% 13550/15836 [1:08:33<10:27,  3.64it/s]\u001b[A\n",
      "Iteration:  86% 13551/15836 [1:08:34<09:49,  3.87it/s]\u001b[A\n",
      "Iteration:  86% 13552/15836 [1:08:34<09:24,  4.05it/s]\u001b[A\n",
      "Iteration:  86% 13553/15836 [1:08:34<09:11,  4.14it/s]\u001b[A\n",
      "Iteration:  86% 13554/15836 [1:08:34<09:00,  4.23it/s]\u001b[A\n",
      "Iteration:  86% 13555/15836 [1:08:35<10:22,  3.66it/s]\u001b[A\n",
      "Iteration:  86% 13556/15836 [1:08:35<09:46,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13557/15836 [1:08:35<09:26,  4.02it/s]\u001b[A\n",
      "Iteration:  86% 13558/15836 [1:08:35<09:10,  4.14it/s]\u001b[A\n",
      "Iteration:  86% 13559/15836 [1:08:35<08:59,  4.22it/s]\u001b[A\n",
      "Iteration:  86% 13560/15836 [1:08:36<10:21,  3.66it/s]\u001b[A\n",
      "Iteration:  86% 13561/15836 [1:08:36<09:45,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13562/15836 [1:08:36<09:20,  4.06it/s]\u001b[A\n",
      "Iteration:  86% 13563/15836 [1:08:36<09:06,  4.16it/s]\u001b[A\n",
      "Iteration:  86% 13564/15836 [1:08:37<08:57,  4.22it/s]\u001b[A\n",
      "Iteration:  86% 13565/15836 [1:08:37<10:19,  3.67it/s]\u001b[A\n",
      "Iteration:  86% 13566/15836 [1:08:37<09:45,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13567/15836 [1:08:38<09:20,  4.05it/s]\u001b[A\n",
      "Iteration:  86% 13568/15836 [1:08:38<09:06,  4.15it/s]\u001b[A\n",
      "Iteration:  86% 13569/15836 [1:08:38<08:56,  4.23it/s]\u001b[A\n",
      "Iteration:  86% 13570/15836 [1:08:38<10:18,  3.66it/s]\u001b[A\n",
      "Iteration:  86% 13571/15836 [1:08:39<09:43,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13572/15836 [1:08:39<09:17,  4.06it/s]\u001b[A\n",
      "Iteration:  86% 13573/15836 [1:08:39<09:05,  4.15it/s]\u001b[A\n",
      "Iteration:  86% 13574/15836 [1:08:39<08:55,  4.23it/s]\u001b[A\n",
      "Iteration:  86% 13575/15836 [1:08:40<10:16,  3.67it/s]\u001b[A\n",
      "Iteration:  86% 13576/15836 [1:08:40<09:41,  3.89it/s]\u001b[A\n",
      "Iteration:  86% 13577/15836 [1:08:40<09:17,  4.06it/s]\u001b[A\n",
      "Iteration:  86% 13578/15836 [1:08:40<09:06,  4.14it/s]\u001b[A\n",
      "Iteration:  86% 13579/15836 [1:08:40<08:55,  4.22it/s]\u001b[A\n",
      "Iteration:  86% 13580/15836 [1:08:41<10:17,  3.65it/s]\u001b[A\n",
      "Iteration:  86% 13581/15836 [1:08:41<09:41,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13582/15836 [1:08:41<09:17,  4.04it/s]\u001b[A\n",
      "Iteration:  86% 13583/15836 [1:08:42<09:02,  4.15it/s]\u001b[A\n",
      "Iteration:  86% 13584/15836 [1:08:42<08:55,  4.21it/s]\u001b[A\n",
      "Iteration:  86% 13585/15836 [1:08:42<10:16,  3.65it/s]\u001b[A\n",
      "Iteration:  86% 13586/15836 [1:08:42<09:40,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13587/15836 [1:08:43<09:15,  4.05it/s]\u001b[A\n",
      "Iteration:  86% 13588/15836 [1:08:43<09:00,  4.16it/s]\u001b[A\n",
      "Iteration:  86% 13589/15836 [1:08:43<08:51,  4.23it/s]\u001b[A\n",
      "Iteration:  86% 13590/15836 [1:08:43<10:12,  3.66it/s]\u001b[A\n",
      "Iteration:  86% 13591/15836 [1:08:44<09:38,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13592/15836 [1:08:44<09:15,  4.04it/s]\u001b[A\n",
      "Iteration:  86% 13593/15836 [1:08:44<08:59,  4.15it/s]\u001b[A\n",
      "Iteration:  86% 13594/15836 [1:08:44<08:48,  4.24it/s]\u001b[A\n",
      "Iteration:  86% 13595/15836 [1:08:45<10:10,  3.67it/s]\u001b[A\n",
      "Iteration:  86% 13596/15836 [1:08:45<09:34,  3.90it/s]\u001b[A\n",
      "Iteration:  86% 13597/15836 [1:08:45<09:12,  4.05it/s]\u001b[A\n",
      "Iteration:  86% 13598/15836 [1:08:45<09:00,  4.14it/s]\u001b[A\n",
      "Iteration:  86% 13599/15836 [1:08:46<08:50,  4.21it/s]\u001b[A\n",
      "Iteration:  86% 13600/15836 [1:08:46<10:10,  3.66it/s]\u001b[A\n",
      "Iteration:  86% 13601/15836 [1:08:46<09:36,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13602/15836 [1:08:46<09:13,  4.04it/s]\u001b[A\n",
      "Iteration:  86% 13603/15836 [1:08:47<08:57,  4.15it/s]\u001b[A\n",
      "Iteration:  86% 13604/15836 [1:08:47<08:48,  4.23it/s]\u001b[A\n",
      "Iteration:  86% 13605/15836 [1:08:47<10:08,  3.67it/s]\u001b[A\n",
      "Iteration:  86% 13606/15836 [1:08:47<09:34,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13607/15836 [1:08:48<09:12,  4.04it/s]\u001b[A\n",
      "Iteration:  86% 13608/15836 [1:08:48<08:58,  4.14it/s]\u001b[A\n",
      "Iteration:  86% 13609/15836 [1:08:48<08:47,  4.22it/s]\u001b[A\n",
      "Iteration:  86% 13610/15836 [1:08:48<10:07,  3.66it/s]\u001b[A\n",
      "Iteration:  86% 13611/15836 [1:08:49<09:32,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13612/15836 [1:08:49<09:10,  4.04it/s]\u001b[A\n",
      "Iteration:  86% 13613/15836 [1:08:49<08:56,  4.15it/s]\u001b[A\n",
      "Iteration:  86% 13614/15836 [1:08:49<08:46,  4.22it/s]\u001b[A\n",
      "Iteration:  86% 13615/15836 [1:08:50<10:08,  3.65it/s]\u001b[A\n",
      "Iteration:  86% 13616/15836 [1:08:50<09:28,  3.90it/s]\u001b[A\n",
      "Iteration:  86% 13617/15836 [1:08:50<09:07,  4.05it/s]\u001b[A\n",
      "Iteration:  86% 13618/15836 [1:08:50<08:51,  4.17it/s]\u001b[A\n",
      "Iteration:  86% 13619/15836 [1:08:51<08:42,  4.25it/s]\u001b[A\n",
      "Iteration:  86% 13620/15836 [1:08:51<10:03,  3.67it/s]\u001b[A\n",
      "Iteration:  86% 13621/15836 [1:08:51<09:29,  3.89it/s]\u001b[A\n",
      "Iteration:  86% 13622/15836 [1:08:51<09:09,  4.03it/s]\u001b[A\n",
      "Iteration:  86% 13623/15836 [1:08:52<08:53,  4.14it/s]\u001b[A\n",
      "Iteration:  86% 13624/15836 [1:08:52<08:43,  4.22it/s]\u001b[A\n",
      "Iteration:  86% 13625/15836 [1:08:52<10:04,  3.66it/s]\u001b[A\n",
      "Iteration:  86% 13626/15836 [1:08:52<09:30,  3.87it/s]\u001b[A\n",
      "Iteration:  86% 13627/15836 [1:08:53<09:06,  4.04it/s]\u001b[A\n",
      "Iteration:  86% 13628/15836 [1:08:53<08:48,  4.18it/s]\u001b[A\n",
      "Iteration:  86% 13629/15836 [1:08:53<08:42,  4.22it/s]\u001b[A\n",
      "Iteration:  86% 13630/15836 [1:08:53<10:02,  3.66it/s]\u001b[A\n",
      "Iteration:  86% 13631/15836 [1:08:54<09:30,  3.86it/s]\u001b[A\n",
      "Iteration:  86% 13632/15836 [1:08:54<09:04,  4.05it/s]\u001b[A\n",
      "Iteration:  86% 13633/15836 [1:08:54<08:50,  4.16it/s]\u001b[A\n",
      "Iteration:  86% 13634/15836 [1:08:54<08:40,  4.23it/s]\u001b[A\n",
      "Iteration:  86% 13635/15836 [1:08:55<10:03,  3.65it/s]\u001b[A\n",
      "Iteration:  86% 13636/15836 [1:08:55<09:23,  3.90it/s]\u001b[A\n",
      "Iteration:  86% 13637/15836 [1:08:55<09:04,  4.04it/s]\u001b[A\n",
      "Iteration:  86% 13638/15836 [1:08:55<08:48,  4.16it/s]\u001b[A\n",
      "Iteration:  86% 13639/15836 [1:08:56<08:40,  4.22it/s]\u001b[A\n",
      "Iteration:  86% 13640/15836 [1:08:56<09:58,  3.67it/s]\u001b[A\n",
      "Iteration:  86% 13641/15836 [1:08:56<09:26,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13642/15836 [1:08:56<09:02,  4.05it/s]\u001b[A\n",
      "Iteration:  86% 13643/15836 [1:08:57<08:48,  4.15it/s]\u001b[A\n",
      "Iteration:  86% 13644/15836 [1:08:57<08:36,  4.24it/s]\u001b[A\n",
      "Iteration:  86% 13645/15836 [1:08:57<09:56,  3.67it/s]\u001b[A\n",
      "Iteration:  86% 13646/15836 [1:08:57<09:19,  3.91it/s]\u001b[A\n",
      "Iteration:  86% 13647/15836 [1:08:58<08:58,  4.07it/s]\u001b[A\n",
      "Iteration:  86% 13648/15836 [1:08:58<08:46,  4.16it/s]\u001b[A\n",
      "Iteration:  86% 13649/15836 [1:08:58<08:39,  4.21it/s]\u001b[A\n",
      "Iteration:  86% 13650/15836 [1:08:58<09:59,  3.64it/s]\u001b[A\n",
      "Iteration:  86% 13651/15836 [1:08:59<09:23,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13652/15836 [1:08:59<08:59,  4.05it/s]\u001b[A\n",
      "Iteration:  86% 13653/15836 [1:08:59<08:47,  4.14it/s]\u001b[A\n",
      "Iteration:  86% 13654/15836 [1:08:59<08:37,  4.22it/s]\u001b[A\n",
      "Iteration:  86% 13655/15836 [1:09:00<09:56,  3.66it/s]\u001b[A\n",
      "Iteration:  86% 13656/15836 [1:09:00<09:20,  3.89it/s]\u001b[A\n",
      "Iteration:  86% 13657/15836 [1:09:00<08:58,  4.05it/s]\u001b[A\n",
      "Iteration:  86% 13658/15836 [1:09:00<08:45,  4.15it/s]\u001b[A\n",
      "Iteration:  86% 13659/15836 [1:09:01<08:38,  4.20it/s]\u001b[A\n",
      "Iteration:  86% 13660/15836 [1:09:01<09:55,  3.66it/s]\u001b[A\n",
      "Iteration:  86% 13661/15836 [1:09:01<09:20,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13662/15836 [1:09:01<08:59,  4.03it/s]\u001b[A\n",
      "Iteration:  86% 13663/15836 [1:09:02<08:45,  4.13it/s]\u001b[A\n",
      "Iteration:  86% 13664/15836 [1:09:02<08:32,  4.23it/s]\u001b[A\n",
      "Iteration:  86% 13665/15836 [1:09:02<09:52,  3.67it/s]\u001b[A\n",
      "Iteration:  86% 13666/15836 [1:09:02<09:15,  3.91it/s]\u001b[A\n",
      "Iteration:  86% 13667/15836 [1:09:03<08:53,  4.06it/s]\u001b[A\n",
      "Iteration:  86% 13668/15836 [1:09:03<08:41,  4.16it/s]\u001b[A\n",
      "Iteration:  86% 13669/15836 [1:09:03<08:36,  4.19it/s]\u001b[A\n",
      "Iteration:  86% 13670/15836 [1:09:03<09:53,  3.65it/s]\u001b[A\n",
      "Iteration:  86% 13671/15836 [1:09:04<09:17,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13672/15836 [1:09:04<08:52,  4.07it/s]\u001b[A\n",
      "Iteration:  86% 13673/15836 [1:09:04<08:41,  4.15it/s]\u001b[A\n",
      "Iteration:  86% 13674/15836 [1:09:04<08:34,  4.20it/s]\u001b[A\n",
      "Iteration:  86% 13675/15836 [1:09:05<09:51,  3.65it/s]\u001b[A\n",
      "Iteration:  86% 13676/15836 [1:09:05<09:14,  3.89it/s]\u001b[A\n",
      "Iteration:  86% 13677/15836 [1:09:05<08:53,  4.05it/s]\u001b[A\n",
      "Iteration:  86% 13678/15836 [1:09:05<08:40,  4.15it/s]\u001b[A\n",
      "Iteration:  86% 13679/15836 [1:09:06<08:33,  4.20it/s]\u001b[A\n",
      "Iteration:  86% 13680/15836 [1:09:06<09:50,  3.65it/s]\u001b[A\n",
      "Iteration:  86% 13681/15836 [1:09:06<09:16,  3.87it/s]\u001b[A\n",
      "Iteration:  86% 13682/15836 [1:09:06<08:53,  4.03it/s]\u001b[A\n",
      "Iteration:  86% 13683/15836 [1:09:07<08:37,  4.16it/s]\u001b[A\n",
      "Iteration:  86% 13684/15836 [1:09:07<08:30,  4.21it/s]\u001b[A\n",
      "Iteration:  86% 13685/15836 [1:09:07<09:46,  3.67it/s]\u001b[A\n",
      "Iteration:  86% 13686/15836 [1:09:07<09:13,  3.88it/s]\u001b[A\n",
      "Iteration:  86% 13687/15836 [1:09:08<08:50,  4.05it/s]\u001b[A\n",
      "Iteration:  86% 13688/15836 [1:09:08<08:36,  4.16it/s]\u001b[A\n",
      "Iteration:  86% 13689/15836 [1:09:08<08:26,  4.24it/s]\u001b[A\n",
      "Iteration:  86% 13690/15836 [1:09:08<09:44,  3.67it/s]\u001b[A\n",
      "Iteration:  86% 13691/15836 [1:09:09<09:11,  3.89it/s]\u001b[A\n",
      "Iteration:  86% 13692/15836 [1:09:09<08:51,  4.03it/s]\u001b[A\n",
      "Iteration:  86% 13693/15836 [1:09:09<08:36,  4.15it/s]\u001b[A\n",
      "Iteration:  86% 13694/15836 [1:09:09<08:26,  4.23it/s]\u001b[A\n",
      "Iteration:  86% 13695/15836 [1:09:10<09:44,  3.66it/s]\u001b[A\n",
      "Iteration:  86% 13696/15836 [1:09:10<09:10,  3.89it/s]\u001b[A\n",
      "Iteration:  86% 13697/15836 [1:09:10<08:48,  4.05it/s]\u001b[A\n",
      "Iteration:  86% 13698/15836 [1:09:10<08:33,  4.17it/s]\u001b[A\n",
      "Iteration:  87% 13699/15836 [1:09:11<08:25,  4.23it/s]\u001b[A\n",
      "Iteration:  87% 13700/15836 [1:09:11<09:44,  3.65it/s]\u001b[A\n",
      "Iteration:  87% 13701/15836 [1:09:11<09:10,  3.88it/s]\u001b[A\n",
      "Iteration:  87% 13702/15836 [1:09:11<08:46,  4.06it/s]\u001b[A\n",
      "Iteration:  87% 13703/15836 [1:09:12<08:34,  4.14it/s]\u001b[A\n",
      "Iteration:  87% 13704/15836 [1:09:12<08:24,  4.23it/s]\u001b[A\n",
      "Iteration:  87% 13705/15836 [1:09:12<09:41,  3.66it/s]\u001b[A\n",
      "Iteration:  87% 13706/15836 [1:09:12<09:06,  3.90it/s]\u001b[A\n",
      "Iteration:  87% 13707/15836 [1:09:13<08:47,  4.03it/s]\u001b[A\n",
      "Iteration:  87% 13708/15836 [1:09:13<08:35,  4.13it/s]\u001b[A\n",
      "Iteration:  87% 13709/15836 [1:09:13<08:24,  4.22it/s]\u001b[A\n",
      "Iteration:  87% 13710/15836 [1:09:13<09:42,  3.65it/s]\u001b[A\n",
      "Iteration:  87% 13711/15836 [1:09:14<09:08,  3.88it/s]\u001b[A\n",
      "Iteration:  87% 13712/15836 [1:09:14<08:45,  4.04it/s]\u001b[A\n",
      "Iteration:  87% 13713/15836 [1:09:14<08:31,  4.15it/s]\u001b[A\n",
      "Iteration:  87% 13714/15836 [1:09:14<08:21,  4.23it/s]\u001b[A\n",
      "Iteration:  87% 13715/15836 [1:09:15<09:37,  3.67it/s]\u001b[A\n",
      "Iteration:  87% 13716/15836 [1:09:15<09:05,  3.89it/s]\u001b[A\n",
      "Iteration:  87% 13717/15836 [1:09:15<08:42,  4.05it/s]\u001b[A\n",
      "Iteration:  87% 13718/15836 [1:09:15<08:31,  4.14it/s]\u001b[A\n",
      "Iteration:  87% 13719/15836 [1:09:16<08:18,  4.25it/s]\u001b[A\n",
      "Iteration:  87% 13720/15836 [1:09:16<09:36,  3.67it/s]\u001b[A\n",
      "Iteration:  87% 13721/15836 [1:09:16<09:02,  3.90it/s]\u001b[A\n",
      "Iteration:  87% 13722/15836 [1:09:16<08:40,  4.07it/s]\u001b[A\n",
      "Iteration:  87% 13723/15836 [1:09:17<08:27,  4.16it/s]\u001b[A\n",
      "Iteration:  87% 13724/15836 [1:09:17<08:20,  4.22it/s]\u001b[A\n",
      "Iteration:  87% 13725/15836 [1:09:17<09:37,  3.65it/s]\u001b[A\n",
      "Iteration:  87% 13726/15836 [1:09:17<09:01,  3.90it/s]\u001b[A\n",
      "Iteration:  87% 13727/15836 [1:09:18<08:39,  4.06it/s]\u001b[A\n",
      "Iteration:  87% 13728/15836 [1:09:18<08:29,  4.14it/s]\u001b[A\n",
      "Iteration:  87% 13729/15836 [1:09:18<08:21,  4.20it/s]\u001b[A\n",
      "Iteration:  87% 13730/15836 [1:09:19<09:36,  3.66it/s]\u001b[A\n",
      "Iteration:  87% 13731/15836 [1:09:19<08:59,  3.90it/s]\u001b[A\n",
      "Iteration:  87% 13732/15836 [1:09:19<08:36,  4.07it/s]\u001b[A\n",
      "Iteration:  87% 13733/15836 [1:09:19<08:22,  4.18it/s]\u001b[A\n",
      "Iteration:  87% 13734/15836 [1:09:19<08:15,  4.24it/s]\u001b[A\n",
      "Iteration:  87% 13735/15836 [1:09:20<09:34,  3.66it/s]\u001b[A\n",
      "Iteration:  87% 13736/15836 [1:09:20<08:58,  3.90it/s]\u001b[A\n",
      "Iteration:  87% 13737/15836 [1:09:20<08:35,  4.07it/s]\u001b[A\n",
      "Iteration:  87% 13738/15836 [1:09:20<08:23,  4.17it/s]\u001b[A\n",
      "Iteration:  87% 13739/15836 [1:09:21<08:15,  4.23it/s]\u001b[A\n",
      "Iteration:  87% 13740/15836 [1:09:21<09:31,  3.67it/s]\u001b[A\n",
      "Iteration:  87% 13741/15836 [1:09:21<08:58,  3.89it/s]\u001b[A\n",
      "Iteration:  87% 13742/15836 [1:09:21<08:36,  4.06it/s]\u001b[A\n",
      "Iteration:  87% 13743/15836 [1:09:22<08:21,  4.18it/s]\u001b[A\n",
      "Iteration:  87% 13744/15836 [1:09:22<08:13,  4.24it/s]\u001b[A\n",
      "Iteration:  87% 13745/15836 [1:09:22<09:30,  3.66it/s]\u001b[A\n",
      "Iteration:  87% 13746/15836 [1:09:22<08:57,  3.89it/s]\u001b[A\n",
      "Iteration:  87% 13747/15836 [1:09:23<08:34,  4.06it/s]\u001b[A\n",
      "Iteration:  87% 13748/15836 [1:09:23<08:21,  4.16it/s]\u001b[A\n",
      "Iteration:  87% 13749/15836 [1:09:23<08:12,  4.24it/s]\u001b[A\n",
      "Iteration:  87% 13750/15836 [1:09:24<09:28,  3.67it/s]\u001b[A\n",
      "Iteration:  87% 13751/15836 [1:09:24<08:55,  3.89it/s]\u001b[A\n",
      "Iteration:  87% 13752/15836 [1:09:24<08:31,  4.07it/s]\u001b[A\n",
      "Iteration:  87% 13753/15836 [1:09:24<08:23,  4.14it/s]\u001b[A\n",
      "Iteration:  87% 13754/15836 [1:09:24<08:13,  4.22it/s]\u001b[A\n",
      "Iteration:  87% 13755/15836 [1:09:25<09:29,  3.65it/s]\u001b[A\n",
      "Iteration:  87% 13756/15836 [1:09:25<08:55,  3.88it/s]\u001b[A\n",
      "Iteration:  87% 13757/15836 [1:09:25<08:36,  4.03it/s]\u001b[A\n",
      "Iteration:  87% 13758/15836 [1:09:25<08:19,  4.16it/s]\u001b[A\n",
      "Iteration:  87% 13759/15836 [1:09:26<08:12,  4.22it/s]\u001b[A\n",
      "Iteration:  87% 13760/15836 [1:09:26<09:26,  3.66it/s]\u001b[A\n",
      "Iteration:  87% 13761/15836 [1:09:26<08:55,  3.88it/s]\u001b[A\n",
      "Iteration:  87% 13762/15836 [1:09:26<08:32,  4.05it/s]\u001b[A\n",
      "Iteration:  87% 13763/15836 [1:09:27<08:19,  4.15it/s]\u001b[A\n",
      "Iteration:  87% 13764/15836 [1:09:27<08:08,  4.24it/s]\u001b[A\n",
      "Iteration:  87% 13765/15836 [1:09:27<09:27,  3.65it/s]\u001b[A\n",
      "Iteration:  87% 13766/15836 [1:09:28<08:53,  3.88it/s]\u001b[A\n",
      "Iteration:  87% 13767/15836 [1:09:28<08:33,  4.03it/s]\u001b[A\n",
      "Iteration:  87% 13768/15836 [1:09:28<08:18,  4.15it/s]\u001b[A\n",
      "Iteration:  87% 13769/15836 [1:09:28<08:12,  4.19it/s]\u001b[A\n",
      "Iteration:  87% 13770/15836 [1:09:29<09:28,  3.64it/s]\u001b[A\n",
      "Iteration:  87% 13771/15836 [1:09:29<08:50,  3.89it/s]\u001b[A\n",
      "Iteration:  87% 13772/15836 [1:09:29<08:28,  4.06it/s]\u001b[A\n",
      "Iteration:  87% 13773/15836 [1:09:29<08:17,  4.15it/s]\u001b[A\n",
      "Iteration:  87% 13774/15836 [1:09:29<08:09,  4.21it/s]\u001b[A\n",
      "Iteration:  87% 13775/15836 [1:09:30<09:25,  3.65it/s]\u001b[A\n",
      "Iteration:  87% 13776/15836 [1:09:30<08:49,  3.89it/s]\u001b[A\n",
      "Iteration:  87% 13777/15836 [1:09:30<08:28,  4.05it/s]\u001b[A\n",
      "Iteration:  87% 13778/15836 [1:09:30<08:15,  4.15it/s]\u001b[A\n",
      "Iteration:  87% 13779/15836 [1:09:31<08:07,  4.22it/s]\u001b[A\n",
      "Iteration:  87% 13780/15836 [1:09:31<09:23,  3.65it/s]\u001b[A\n",
      "Iteration:  87% 13781/15836 [1:09:31<08:49,  3.88it/s]\u001b[A\n",
      "Iteration:  87% 13782/15836 [1:09:31<08:27,  4.05it/s]\u001b[A\n",
      "Iteration:  87% 13783/15836 [1:09:32<08:14,  4.15it/s]\u001b[A\n",
      "Iteration:  87% 13784/15836 [1:09:32<08:07,  4.21it/s]\u001b[A\n",
      "Iteration:  87% 13785/15836 [1:09:32<09:20,  3.66it/s]\u001b[A\n",
      "Iteration:  87% 13786/15836 [1:09:33<08:46,  3.89it/s]\u001b[A\n",
      "Iteration:  87% 13787/15836 [1:09:33<08:25,  4.06it/s]\u001b[A\n",
      "Iteration:  87% 13788/15836 [1:09:33<08:13,  4.15it/s]\u001b[A\n",
      "Iteration:  87% 13789/15836 [1:09:33<08:04,  4.22it/s]\u001b[A\n",
      "Iteration:  87% 13790/15836 [1:09:34<09:19,  3.66it/s]\u001b[A\n",
      "Iteration:  87% 13791/15836 [1:09:34<08:44,  3.90it/s]\u001b[A\n",
      "Iteration:  87% 13792/15836 [1:09:34<08:24,  4.05it/s]\u001b[A\n",
      "Iteration:  87% 13793/15836 [1:09:34<08:49,  3.86it/s]\u001b[A\n",
      "Iteration:  87% 13794/15836 [1:09:35<08:37,  3.94it/s]\u001b[A\n",
      "Iteration:  87% 13795/15836 [1:09:35<10:08,  3.35it/s]\u001b[A\n",
      "Iteration:  87% 13796/15836 [1:09:35<09:52,  3.44it/s]\u001b[A\n",
      "Iteration:  87% 13797/15836 [1:09:35<09:40,  3.51it/s]\u001b[A\n",
      "Iteration:  87% 13798/15836 [1:09:36<08:58,  3.78it/s]\u001b[A\n",
      "Iteration:  87% 13799/15836 [1:09:36<08:29,  4.00it/s]\u001b[A\n",
      "Iteration:  87% 13800/15836 [1:09:36<09:42,  3.49it/s]\u001b[A\n",
      "Iteration:  87% 13801/15836 [1:09:37<09:01,  3.76it/s]\u001b[A\n",
      "Iteration:  87% 13802/15836 [1:09:37<08:32,  3.97it/s]\u001b[A\n",
      "Iteration:  87% 13803/15836 [1:09:37<08:13,  4.12it/s]\u001b[A\n",
      "Iteration:  87% 13804/15836 [1:09:37<08:06,  4.18it/s]\u001b[A\n",
      "Iteration:  87% 13805/15836 [1:09:38<09:17,  3.64it/s]\u001b[A\n",
      "Iteration:  87% 13806/15836 [1:09:38<08:42,  3.88it/s]\u001b[A\n",
      "Iteration:  87% 13807/15836 [1:09:38<08:25,  4.02it/s]\u001b[A\n",
      "Iteration:  87% 13808/15836 [1:09:38<08:10,  4.14it/s]\u001b[A\n",
      "Iteration:  87% 13809/15836 [1:09:38<08:02,  4.20it/s]\u001b[A\n",
      "Iteration:  87% 13810/15836 [1:09:39<09:16,  3.64it/s]\u001b[A\n",
      "Iteration:  87% 13811/15836 [1:09:39<08:40,  3.89it/s]\u001b[A\n",
      "Iteration:  87% 13812/15836 [1:09:39<08:21,  4.04it/s]\u001b[A\n",
      "Iteration:  87% 13813/15836 [1:09:39<08:06,  4.16it/s]\u001b[A\n",
      "Iteration:  87% 13814/15836 [1:09:40<08:00,  4.21it/s]\u001b[A\n",
      "Iteration:  87% 13815/15836 [1:09:40<09:13,  3.65it/s]\u001b[A\n",
      "Iteration:  87% 13816/15836 [1:09:40<08:39,  3.89it/s]\u001b[A\n",
      "Iteration:  87% 13817/15836 [1:09:40<08:19,  4.05it/s]\u001b[A\n",
      "Iteration:  87% 13818/15836 [1:09:41<08:08,  4.13it/s]\u001b[A\n",
      "Iteration:  87% 13819/15836 [1:09:41<07:57,  4.23it/s]\u001b[A\n",
      "Iteration:  87% 13820/15836 [1:09:41<09:10,  3.66it/s]\u001b[A\n",
      "Iteration:  87% 13821/15836 [1:09:42<08:39,  3.88it/s]\u001b[A\n",
      "Iteration:  87% 13822/15836 [1:09:42<08:19,  4.03it/s]\u001b[A\n",
      "Iteration:  87% 13823/15836 [1:09:42<08:06,  4.14it/s]\u001b[A\n",
      "Iteration:  87% 13824/15836 [1:09:42<07:57,  4.21it/s]\u001b[A\n",
      "Iteration:  87% 13825/15836 [1:09:43<09:09,  3.66it/s]\u001b[A\n",
      "Iteration:  87% 13826/15836 [1:09:43<08:36,  3.90it/s]\u001b[A\n",
      "Iteration:  87% 13827/15836 [1:09:43<08:16,  4.05it/s]\u001b[A\n",
      "Iteration:  87% 13828/15836 [1:09:43<08:03,  4.15it/s]\u001b[A\n",
      "Iteration:  87% 13829/15836 [1:09:43<07:54,  4.23it/s]\u001b[A\n",
      "Iteration:  87% 13830/15836 [1:09:44<09:09,  3.65it/s]\u001b[A\n",
      "Iteration:  87% 13831/15836 [1:09:44<08:36,  3.88it/s]\u001b[A\n",
      "Iteration:  87% 13832/15836 [1:09:44<08:14,  4.05it/s]\u001b[A\n",
      "Iteration:  87% 13833/15836 [1:09:44<08:02,  4.15it/s]\u001b[A\n",
      "Iteration:  87% 13834/15836 [1:09:45<07:55,  4.21it/s]\u001b[A\n",
      "Iteration:  87% 13835/15836 [1:09:45<09:09,  3.64it/s]\u001b[A\n",
      "Iteration:  87% 13836/15836 [1:09:45<08:34,  3.89it/s]\u001b[A\n",
      "Iteration:  87% 13837/15836 [1:09:46<08:10,  4.07it/s]\u001b[A\n",
      "Iteration:  87% 13838/15836 [1:09:46<08:02,  4.14it/s]\u001b[A\n",
      "Iteration:  87% 13839/15836 [1:09:46<07:55,  4.20it/s]\u001b[A\n",
      "Iteration:  87% 13840/15836 [1:09:46<09:07,  3.64it/s]\u001b[A\n",
      "Iteration:  87% 13841/15836 [1:09:47<08:31,  3.90it/s]\u001b[A\n",
      "Iteration:  87% 13842/15836 [1:09:47<08:13,  4.04it/s]\u001b[A\n",
      "Iteration:  87% 13843/15836 [1:09:47<07:58,  4.17it/s]\u001b[A\n",
      "Iteration:  87% 13844/15836 [1:09:47<07:50,  4.23it/s]\u001b[A\n",
      "Iteration:  87% 13845/15836 [1:09:48<09:04,  3.66it/s]\u001b[A\n",
      "Iteration:  87% 13846/15836 [1:09:48<08:33,  3.87it/s]\u001b[A\n",
      "Iteration:  87% 13847/15836 [1:09:48<08:12,  4.04it/s]\u001b[A\n",
      "Iteration:  87% 13848/15836 [1:09:48<07:59,  4.14it/s]\u001b[A\n",
      "Iteration:  87% 13849/15836 [1:09:48<07:49,  4.23it/s]\u001b[A\n",
      "Iteration:  87% 13850/15836 [1:09:49<09:02,  3.66it/s]\u001b[A\n",
      "Iteration:  87% 13851/15836 [1:09:49<08:31,  3.88it/s]\u001b[A\n",
      "Iteration:  87% 13852/15836 [1:09:49<08:08,  4.06it/s]\u001b[A\n",
      "Iteration:  87% 13853/15836 [1:09:50<07:59,  4.14it/s]\u001b[A\n",
      "Iteration:  87% 13854/15836 [1:09:50<07:47,  4.24it/s]\u001b[A\n",
      "Iteration:  87% 13855/15836 [1:09:50<08:59,  3.67it/s]\u001b[A\n",
      "Iteration:  87% 13856/15836 [1:09:50<08:28,  3.89it/s]\u001b[A\n",
      "Iteration:  88% 13857/15836 [1:09:51<08:09,  4.05it/s]\u001b[A\n",
      "Iteration:  88% 13858/15836 [1:09:51<07:57,  4.14it/s]\u001b[A\n",
      "Iteration:  88% 13859/15836 [1:09:51<07:47,  4.23it/s]\u001b[A\n",
      "Iteration:  88% 13860/15836 [1:09:51<09:00,  3.65it/s]\u001b[A\n",
      "Iteration:  88% 13861/15836 [1:09:52<08:29,  3.88it/s]\u001b[A\n",
      "Iteration:  88% 13862/15836 [1:09:52<08:09,  4.03it/s]\u001b[A\n",
      "Iteration:  88% 13863/15836 [1:09:52<07:56,  4.14it/s]\u001b[A\n",
      "Iteration:  88% 13864/15836 [1:09:52<07:49,  4.20it/s]\u001b[A\n",
      "Iteration:  88% 13865/15836 [1:09:53<08:58,  3.66it/s]\u001b[A\n",
      "Iteration:  88% 13866/15836 [1:09:53<08:28,  3.88it/s]\u001b[A\n",
      "Iteration:  88% 13867/15836 [1:09:53<08:07,  4.04it/s]\u001b[A\n",
      "Iteration:  88% 13868/15836 [1:09:53<07:53,  4.16it/s]\u001b[A\n",
      "Iteration:  88% 13869/15836 [1:09:54<07:43,  4.24it/s]\u001b[A\n",
      "Iteration:  88% 13870/15836 [1:09:54<08:57,  3.66it/s]\u001b[A\n",
      "Iteration:  88% 13871/15836 [1:09:54<08:29,  3.86it/s]\u001b[A\n",
      "Iteration:  88% 13872/15836 [1:09:54<08:06,  4.04it/s]\u001b[A\n",
      "Iteration:  88% 13873/15836 [1:09:55<07:50,  4.17it/s]\u001b[A\n",
      "Iteration:  88% 13874/15836 [1:09:55<07:43,  4.23it/s]\u001b[A\n",
      "Iteration:  88% 13875/15836 [1:09:55<08:53,  3.67it/s]\u001b[A\n",
      "Iteration:  88% 13876/15836 [1:09:55<08:24,  3.89it/s]\u001b[A\n",
      "Iteration:  88% 13877/15836 [1:09:56<08:05,  4.04it/s]\u001b[A\n",
      "Iteration:  88% 13878/15836 [1:09:56<07:51,  4.15it/s]\u001b[A\n",
      "Iteration:  88% 13879/15836 [1:09:56<07:42,  4.23it/s]\u001b[A\n",
      "Iteration:  88% 13880/15836 [1:09:56<08:55,  3.65it/s]\u001b[A\n",
      "Iteration:  88% 13881/15836 [1:09:57<08:22,  3.89it/s]\u001b[A\n",
      "Iteration:  88% 13882/15836 [1:09:57<08:03,  4.04it/s]\u001b[A\n",
      "Iteration:  88% 13883/15836 [1:09:57<07:50,  4.15it/s]\u001b[A\n",
      "Iteration:  88% 13884/15836 [1:09:57<07:43,  4.21it/s]\u001b[A\n",
      "Iteration:  88% 13885/15836 [1:09:58<08:54,  3.65it/s]\u001b[A\n",
      "Iteration:  88% 13886/15836 [1:09:58<08:21,  3.89it/s]\u001b[A\n",
      "Iteration:  88% 13887/15836 [1:09:58<07:59,  4.06it/s]\u001b[A\n",
      "Iteration:  88% 13888/15836 [1:09:58<07:47,  4.17it/s]\u001b[A\n",
      "Iteration:  88% 13889/15836 [1:09:59<07:36,  4.26it/s]\u001b[A\n",
      "Iteration:  88% 13890/15836 [1:09:59<08:48,  3.68it/s]\u001b[A\n",
      "Iteration:  88% 13891/15836 [1:09:59<08:18,  3.90it/s]\u001b[A\n",
      "Iteration:  88% 13892/15836 [1:09:59<07:59,  4.05it/s]\u001b[A\n",
      "Iteration:  88% 13893/15836 [1:10:00<07:47,  4.15it/s]\u001b[A\n",
      "Iteration:  88% 13894/15836 [1:10:00<07:39,  4.23it/s]\u001b[A\n",
      "Iteration:  88% 13895/15836 [1:10:00<08:50,  3.66it/s]\u001b[A\n",
      "Iteration:  88% 13896/15836 [1:10:00<08:21,  3.87it/s]\u001b[A\n",
      "Iteration:  88% 13897/15836 [1:10:01<08:00,  4.04it/s]\u001b[A\n",
      "Iteration:  88% 13898/15836 [1:10:01<07:47,  4.14it/s]\u001b[A\n",
      "Iteration:  88% 13899/15836 [1:10:01<07:39,  4.22it/s]\u001b[A\n",
      "Iteration:  88% 13900/15836 [1:10:01<08:48,  3.66it/s]\u001b[A\n",
      "Iteration:  88% 13901/15836 [1:10:02<08:21,  3.86it/s]\u001b[A\n",
      "Iteration:  88% 13902/15836 [1:10:02<07:59,  4.03it/s]\u001b[A\n",
      "Iteration:  88% 13903/15836 [1:10:02<07:45,  4.16it/s]\u001b[A\n",
      "Iteration:  88% 13904/15836 [1:10:02<07:36,  4.23it/s]\u001b[A\n",
      "Iteration:  88% 13905/15836 [1:10:03<08:49,  3.64it/s]\u001b[A\n",
      "Iteration:  88% 13906/15836 [1:10:03<08:15,  3.89it/s]\u001b[A\n",
      "Iteration:  88% 13907/15836 [1:10:03<07:56,  4.05it/s]\u001b[A\n",
      "Iteration:  88% 13908/15836 [1:10:03<07:41,  4.18it/s]\u001b[A\n",
      "Iteration:  88% 13909/15836 [1:10:04<07:34,  4.24it/s]\u001b[A\n",
      "Iteration:  88% 13910/15836 [1:10:04<08:44,  3.67it/s]\u001b[A\n",
      "Iteration:  88% 13911/15836 [1:10:04<08:14,  3.89it/s]\u001b[A\n",
      "Iteration:  88% 13912/15836 [1:10:04<07:55,  4.05it/s]\u001b[A\n",
      "Iteration:  88% 13913/15836 [1:10:05<07:42,  4.16it/s]\u001b[A\n",
      "Iteration:  88% 13914/15836 [1:10:05<07:34,  4.23it/s]\u001b[A\n",
      "Iteration:  88% 13915/15836 [1:10:05<08:45,  3.66it/s]\u001b[A\n",
      "Iteration:  88% 13916/15836 [1:10:05<08:14,  3.88it/s]\u001b[A\n",
      "Iteration:  88% 13917/15836 [1:10:06<07:52,  4.06it/s]\u001b[A\n",
      "Iteration:  88% 13918/15836 [1:10:06<07:41,  4.16it/s]\u001b[A\n",
      "Iteration:  88% 13919/15836 [1:10:06<07:35,  4.21it/s]\u001b[A\n",
      "Iteration:  88% 13920/15836 [1:10:06<08:44,  3.65it/s]\u001b[A\n",
      "Iteration:  88% 13921/15836 [1:10:07<08:11,  3.89it/s]\u001b[A\n",
      "Iteration:  88% 13922/15836 [1:10:07<07:50,  4.07it/s]\u001b[A\n",
      "Iteration:  88% 13923/15836 [1:10:07<07:38,  4.17it/s]\u001b[A\n",
      "Iteration:  88% 13924/15836 [1:10:07<07:33,  4.22it/s]\u001b[A\n",
      "Iteration:  88% 13925/15836 [1:10:08<08:42,  3.66it/s]\u001b[A\n",
      "Iteration:  88% 13926/15836 [1:10:08<08:07,  3.91it/s]\u001b[A\n",
      "Iteration:  88% 13927/15836 [1:10:08<07:48,  4.08it/s]\u001b[A\n",
      "Iteration:  88% 13928/15836 [1:10:08<07:37,  4.17it/s]\u001b[A\n",
      "Iteration:  88% 13929/15836 [1:10:09<07:29,  4.24it/s]\u001b[A\n",
      "Iteration:  88% 13930/15836 [1:10:09<08:41,  3.65it/s]\u001b[A\n",
      "Iteration:  88% 13931/15836 [1:10:09<08:07,  3.91it/s]\u001b[A\n",
      "Iteration:  88% 13932/15836 [1:10:09<07:48,  4.06it/s]\u001b[A\n",
      "Iteration:  88% 13933/15836 [1:10:10<07:34,  4.18it/s]\u001b[A\n",
      "Iteration:  88% 13934/15836 [1:10:10<07:28,  4.24it/s]\u001b[A\n",
      "Iteration:  88% 13935/15836 [1:10:10<08:38,  3.67it/s]\u001b[A\n",
      "Iteration:  88% 13936/15836 [1:10:10<08:09,  3.88it/s]\u001b[A\n",
      "Iteration:  88% 13937/15836 [1:10:11<07:47,  4.06it/s]\u001b[A\n",
      "Iteration:  88% 13938/15836 [1:10:11<07:36,  4.16it/s]\u001b[A\n",
      "Iteration:  88% 13939/15836 [1:10:11<07:29,  4.22it/s]\u001b[A\n",
      "Iteration:  88% 13940/15836 [1:10:11<08:39,  3.65it/s]\u001b[A\n",
      "Iteration:  88% 13941/15836 [1:10:12<08:07,  3.89it/s]\u001b[A\n",
      "Iteration:  88% 13942/15836 [1:10:12<07:48,  4.04it/s]\u001b[A\n",
      "Iteration:  88% 13943/15836 [1:10:12<07:36,  4.15it/s]\u001b[A\n",
      "Iteration:  88% 13944/15836 [1:10:12<07:28,  4.22it/s]\u001b[A\n",
      "Iteration:  88% 13945/15836 [1:10:13<08:40,  3.63it/s]\u001b[A\n",
      "Iteration:  88% 13946/15836 [1:10:13<08:05,  3.90it/s]\u001b[A\n",
      "Iteration:  88% 13947/15836 [1:10:13<07:45,  4.05it/s]\u001b[A\n",
      "Iteration:  88% 13948/15836 [1:10:13<07:33,  4.16it/s]\u001b[A\n",
      "Iteration:  88% 13949/15836 [1:10:14<07:27,  4.22it/s]\u001b[A\n",
      "Iteration:  88% 13950/15836 [1:10:14<08:35,  3.66it/s]\u001b[A\n",
      "Iteration:  88% 13951/15836 [1:10:14<08:03,  3.90it/s]\u001b[A\n",
      "Iteration:  88% 13952/15836 [1:10:14<07:45,  4.05it/s]\u001b[A\n",
      "Iteration:  88% 13953/15836 [1:10:15<07:32,  4.16it/s]\u001b[A\n",
      "Iteration:  88% 13954/15836 [1:10:15<07:26,  4.21it/s]\u001b[A\n",
      "Iteration:  88% 13955/15836 [1:10:15<08:34,  3.66it/s]\u001b[A\n",
      "Iteration:  88% 13956/15836 [1:10:15<08:01,  3.90it/s]\u001b[A\n",
      "Iteration:  88% 13957/15836 [1:10:16<07:42,  4.07it/s]\u001b[A\n",
      "Iteration:  88% 13958/15836 [1:10:16<07:32,  4.15it/s]\u001b[A\n",
      "Iteration:  88% 13959/15836 [1:10:16<07:22,  4.25it/s]\u001b[A\n",
      "Iteration:  88% 13960/15836 [1:10:16<08:32,  3.66it/s]\u001b[A\n",
      "Iteration:  88% 13961/15836 [1:10:17<08:01,  3.89it/s]\u001b[A\n",
      "Iteration:  88% 13962/15836 [1:10:17<07:44,  4.04it/s]\u001b[A\n",
      "Iteration:  88% 13963/15836 [1:10:17<07:29,  4.17it/s]\u001b[A\n",
      "Iteration:  88% 13964/15836 [1:10:17<07:21,  4.24it/s]\u001b[A\n",
      "Iteration:  88% 13965/15836 [1:10:18<08:30,  3.66it/s]\u001b[A\n",
      "Iteration:  88% 13966/15836 [1:10:18<08:02,  3.88it/s]\u001b[A\n",
      "Iteration:  88% 13967/15836 [1:10:18<07:42,  4.05it/s]\u001b[A\n",
      "Iteration:  88% 13968/15836 [1:10:18<07:29,  4.15it/s]\u001b[A\n",
      "Iteration:  88% 13969/15836 [1:10:19<07:22,  4.22it/s]\u001b[A\n",
      "Iteration:  88% 13970/15836 [1:10:19<08:29,  3.66it/s]\u001b[A\n",
      "Iteration:  88% 13971/15836 [1:10:19<07:59,  3.89it/s]\u001b[A\n",
      "Iteration:  88% 13972/15836 [1:10:19<07:41,  4.04it/s]\u001b[A\n",
      "Iteration:  88% 13973/15836 [1:10:20<07:28,  4.16it/s]\u001b[A\n",
      "Iteration:  88% 13974/15836 [1:10:20<07:20,  4.23it/s]\u001b[A\n",
      "Iteration:  88% 13975/15836 [1:10:20<08:28,  3.66it/s]\u001b[A\n",
      "Iteration:  88% 13976/15836 [1:10:20<08:00,  3.87it/s]\u001b[A\n",
      "Iteration:  88% 13977/15836 [1:10:21<07:39,  4.04it/s]\u001b[A\n",
      "Iteration:  88% 13978/15836 [1:10:21<07:29,  4.14it/s]\u001b[A\n",
      "Iteration:  88% 13979/15836 [1:10:21<07:19,  4.23it/s]\u001b[A\n",
      "Iteration:  88% 13980/15836 [1:10:21<08:27,  3.66it/s]\u001b[A\n",
      "Iteration:  88% 13981/15836 [1:10:22<07:58,  3.87it/s]\u001b[A\n",
      "Iteration:  88% 13982/15836 [1:10:22<07:37,  4.05it/s]\u001b[A\n",
      "Iteration:  88% 13983/15836 [1:10:22<07:26,  4.15it/s]\u001b[A\n",
      "Iteration:  88% 13984/15836 [1:10:22<07:17,  4.23it/s]\u001b[A\n",
      "Iteration:  88% 13985/15836 [1:10:23<08:24,  3.67it/s]\u001b[A\n",
      "Iteration:  88% 13986/15836 [1:10:23<07:55,  3.89it/s]\u001b[A\n",
      "Iteration:  88% 13987/15836 [1:10:23<07:36,  4.05it/s]\u001b[A\n",
      "Iteration:  88% 13988/15836 [1:10:23<07:23,  4.17it/s]\u001b[A\n",
      "Iteration:  88% 13989/15836 [1:10:24<07:14,  4.25it/s]\u001b[A\n",
      "Iteration:  88% 13990/15836 [1:10:24<08:24,  3.66it/s]\u001b[A\n",
      "Iteration:  88% 13991/15836 [1:10:24<07:52,  3.91it/s]\u001b[A\n",
      "Iteration:  88% 13992/15836 [1:10:24<07:33,  4.07it/s]\u001b[A\n",
      "Iteration:  88% 13993/15836 [1:10:25<07:21,  4.17it/s]\u001b[A\n",
      "Iteration:  88% 13994/15836 [1:10:25<07:15,  4.23it/s]\u001b[A\n",
      "Iteration:  88% 13995/15836 [1:10:25<08:23,  3.66it/s]\u001b[A\n",
      "Iteration:  88% 13996/15836 [1:10:25<07:51,  3.91it/s]\u001b[A\n",
      "Iteration:  88% 13997/15836 [1:10:26<07:32,  4.06it/s]\u001b[A\n",
      "Iteration:  88% 13998/15836 [1:10:26<07:22,  4.15it/s]\u001b[A\n",
      "Iteration:  88% 13999/15836 [1:10:26<07:13,  4.24it/s]\u001b[A\n",
      "Iteration:  88% 14000/15836 [1:10:26<08:22,  3.65it/s]\u001b[A\n",
      "Iteration:  88% 14001/15836 [1:10:27<07:49,  3.91it/s]\u001b[A\n",
      "Iteration:  88% 14002/15836 [1:10:27<07:30,  4.07it/s]\u001b[A\n",
      "Iteration:  88% 14003/15836 [1:10:27<07:19,  4.17it/s]\u001b[A\n",
      "Iteration:  88% 14004/15836 [1:10:27<07:11,  4.25it/s]\u001b[A\n",
      "Iteration:  88% 14005/15836 [1:10:28<08:19,  3.67it/s]\u001b[A\n",
      "Iteration:  88% 14006/15836 [1:10:28<07:50,  3.89it/s]\u001b[A\n",
      "Iteration:  88% 14007/15836 [1:10:28<07:29,  4.07it/s]\u001b[A\n",
      "Iteration:  88% 14008/15836 [1:10:28<07:20,  4.15it/s]\u001b[A\n",
      "Iteration:  88% 14009/15836 [1:10:29<07:10,  4.24it/s]\u001b[A\n",
      "Iteration:  88% 14010/15836 [1:10:29<08:17,  3.67it/s]\u001b[A\n",
      "Iteration:  88% 14011/15836 [1:10:29<07:48,  3.89it/s]\u001b[A\n",
      "Iteration:  88% 14012/15836 [1:10:29<07:31,  4.04it/s]\u001b[A\n",
      "Iteration:  88% 14013/15836 [1:10:30<07:19,  4.15it/s]\u001b[A\n",
      "Iteration:  88% 14014/15836 [1:10:30<07:12,  4.21it/s]\u001b[A\n",
      "Iteration:  89% 14015/15836 [1:10:30<08:19,  3.65it/s]\u001b[A\n",
      "Iteration:  89% 14016/15836 [1:10:30<07:48,  3.89it/s]\u001b[A\n",
      "Iteration:  89% 14017/15836 [1:10:31<07:30,  4.04it/s]\u001b[A\n",
      "Iteration:  89% 14018/15836 [1:10:31<07:16,  4.17it/s]\u001b[A\n",
      "Iteration:  89% 14019/15836 [1:10:31<07:11,  4.21it/s]\u001b[A\n",
      "Iteration:  89% 14020/15836 [1:10:31<08:15,  3.66it/s]\u001b[A\n",
      "Iteration:  89% 14021/15836 [1:10:32<07:47,  3.89it/s]\u001b[A\n",
      "Iteration:  89% 14022/15836 [1:10:32<07:28,  4.04it/s]\u001b[A\n",
      "Iteration:  89% 14023/15836 [1:10:32<07:17,  4.14it/s]\u001b[A\n",
      "Iteration:  89% 14024/15836 [1:10:32<07:08,  4.23it/s]\u001b[A\n",
      "Iteration:  89% 14025/15836 [1:10:33<08:14,  3.66it/s]\u001b[A\n",
      "Iteration:  89% 14026/15836 [1:10:33<07:44,  3.90it/s]\u001b[A\n",
      "Iteration:  89% 14027/15836 [1:10:33<07:24,  4.07it/s]\u001b[A\n",
      "Iteration:  89% 14028/15836 [1:10:33<07:12,  4.18it/s]\u001b[A\n",
      "Iteration:  89% 14029/15836 [1:10:34<07:03,  4.26it/s]\u001b[A\n",
      "Iteration:  89% 14030/15836 [1:10:34<08:13,  3.66it/s]\u001b[A\n",
      "Iteration:  89% 14031/15836 [1:10:34<07:45,  3.88it/s]\u001b[A\n",
      "Iteration:  89% 14032/15836 [1:10:34<07:28,  4.02it/s]\u001b[A\n",
      "Iteration:  89% 14033/15836 [1:10:35<07:14,  4.15it/s]\u001b[A\n",
      "Iteration:  89% 14034/15836 [1:10:35<07:07,  4.21it/s]\u001b[A\n",
      "Iteration:  89% 14035/15836 [1:10:35<08:14,  3.64it/s]\u001b[A\n",
      "Iteration:  89% 14036/15836 [1:10:35<07:43,  3.88it/s]\u001b[A\n",
      "Iteration:  89% 14037/15836 [1:10:36<07:23,  4.05it/s]\u001b[A\n",
      "Iteration:  89% 14038/15836 [1:10:36<07:11,  4.16it/s]\u001b[A\n",
      "Iteration:  89% 14039/15836 [1:10:36<07:03,  4.25it/s]\u001b[A\n",
      "Iteration:  89% 14040/15836 [1:10:37<08:11,  3.65it/s]\u001b[A\n",
      "Iteration:  89% 14041/15836 [1:10:37<07:41,  3.89it/s]\u001b[A\n",
      "Iteration:  89% 14042/15836 [1:10:37<07:21,  4.07it/s]\u001b[A\n",
      "Iteration:  89% 14043/15836 [1:10:37<07:08,  4.18it/s]\u001b[A\n",
      "Iteration:  89% 14044/15836 [1:10:37<07:02,  4.24it/s]\u001b[A\n",
      "Iteration:  89% 14045/15836 [1:10:38<08:09,  3.66it/s]\u001b[A\n",
      "Iteration:  89% 14046/15836 [1:10:38<07:38,  3.91it/s]\u001b[A\n",
      "Iteration:  89% 14047/15836 [1:10:38<07:19,  4.07it/s]\u001b[A\n",
      "Iteration:  89% 14048/15836 [1:10:38<07:09,  4.16it/s]\u001b[A\n",
      "Iteration:  89% 14049/15836 [1:10:39<07:02,  4.23it/s]\u001b[A\n",
      "Iteration:  89% 14050/15836 [1:10:39<08:07,  3.66it/s]\u001b[A\n",
      "Iteration:  89% 14051/15836 [1:10:39<07:40,  3.87it/s]\u001b[A\n",
      "Iteration:  89% 14052/15836 [1:10:39<07:21,  4.04it/s]\u001b[A\n",
      "Iteration:  89% 14053/15836 [1:10:40<07:08,  4.16it/s]\u001b[A\n",
      "Iteration:  89% 14054/15836 [1:10:40<07:02,  4.21it/s]\u001b[A\n",
      "Iteration:  89% 14055/15836 [1:10:40<08:07,  3.65it/s]\u001b[A\n",
      "Iteration:  89% 14056/15836 [1:10:40<07:37,  3.89it/s]\u001b[A\n",
      "Iteration:  89% 14057/15836 [1:10:41<07:21,  4.03it/s]\u001b[A\n",
      "Iteration:  89% 14058/15836 [1:10:41<07:08,  4.15it/s]\u001b[A\n",
      "Iteration:  89% 14059/15836 [1:10:41<07:00,  4.23it/s]\u001b[A\n",
      "Iteration:  89% 14060/15836 [1:10:42<08:05,  3.66it/s]\u001b[A\n",
      "Iteration:  89% 14061/15836 [1:10:42<07:36,  3.89it/s]\u001b[A\n",
      "Iteration:  89% 14062/15836 [1:10:42<07:17,  4.05it/s]\u001b[A\n",
      "Iteration:  89% 14063/15836 [1:10:42<07:08,  4.14it/s]\u001b[A\n",
      "Iteration:  89% 14064/15836 [1:10:42<06:59,  4.23it/s]\u001b[A\n",
      "Iteration:  89% 14065/15836 [1:10:43<08:05,  3.65it/s]\u001b[A\n",
      "Iteration:  89% 14066/15836 [1:10:43<07:34,  3.89it/s]\u001b[A\n",
      "Iteration:  89% 14067/15836 [1:10:43<07:17,  4.04it/s]\u001b[A\n",
      "Iteration:  89% 14068/15836 [1:10:43<07:03,  4.18it/s]\u001b[A\n",
      "Iteration:  89% 14069/15836 [1:10:44<06:58,  4.23it/s]\u001b[A\n",
      "Iteration:  89% 14070/15836 [1:10:44<08:01,  3.66it/s]\u001b[A\n",
      "Iteration:  89% 14071/15836 [1:10:44<07:32,  3.90it/s]\u001b[A\n",
      "Iteration:  89% 14072/15836 [1:10:44<07:15,  4.05it/s]\u001b[A\n",
      "Iteration:  89% 14073/15836 [1:10:45<07:06,  4.13it/s]\u001b[A\n",
      "Iteration:  89% 14074/15836 [1:10:45<06:57,  4.22it/s]\u001b[A\n",
      "Iteration:  89% 14075/15836 [1:10:45<08:03,  3.64it/s]\u001b[A\n",
      "Iteration:  89% 14076/15836 [1:10:46<07:33,  3.89it/s]\u001b[A\n",
      "Iteration:  89% 14077/15836 [1:10:46<07:13,  4.05it/s]\u001b[A\n",
      "Iteration:  89% 14078/15836 [1:10:46<07:04,  4.14it/s]\u001b[A\n",
      "Iteration:  89% 14079/15836 [1:10:46<06:56,  4.22it/s]\u001b[A\n",
      "Iteration:  89% 14080/15836 [1:10:47<08:00,  3.66it/s]\u001b[A\n",
      "Iteration:  89% 14081/15836 [1:10:47<07:32,  3.88it/s]\u001b[A\n",
      "Iteration:  89% 14082/15836 [1:10:47<07:14,  4.03it/s]\u001b[A\n",
      "Iteration:  89% 14083/15836 [1:10:47<07:00,  4.17it/s]\u001b[A\n",
      "Iteration:  89% 14084/15836 [1:10:47<06:52,  4.24it/s]\u001b[A\n",
      "Iteration:  89% 14085/15836 [1:10:48<07:57,  3.67it/s]\u001b[A\n",
      "Iteration:  89% 14086/15836 [1:10:48<07:30,  3.88it/s]\u001b[A\n",
      "Iteration:  89% 14087/15836 [1:10:48<07:12,  4.04it/s]\u001b[A\n",
      "Iteration:  89% 14088/15836 [1:10:48<06:59,  4.17it/s]\u001b[A\n",
      "Iteration:  89% 14089/15836 [1:10:49<06:53,  4.22it/s]\u001b[A\n",
      "Iteration:  89% 14090/15836 [1:10:49<07:58,  3.65it/s]\u001b[A\n",
      "Iteration:  89% 14091/15836 [1:10:49<07:30,  3.87it/s]\u001b[A\n",
      "Iteration:  89% 14092/15836 [1:10:49<07:10,  4.05it/s]\u001b[A\n",
      "Iteration:  89% 14093/15836 [1:10:50<06:59,  4.16it/s]\u001b[A\n",
      "Iteration:  89% 14094/15836 [1:10:50<06:51,  4.23it/s]\u001b[A\n",
      "Iteration:  89% 14095/15836 [1:10:50<07:54,  3.67it/s]\u001b[A\n",
      "Iteration:  89% 14096/15836 [1:10:51<07:27,  3.88it/s]\u001b[A\n",
      "Iteration:  89% 14097/15836 [1:10:51<07:10,  4.03it/s]\u001b[A\n",
      "Iteration:  89% 14098/15836 [1:10:51<06:58,  4.16it/s]\u001b[A\n",
      "Iteration:  89% 14099/15836 [1:10:51<06:51,  4.22it/s]\u001b[A\n",
      "Iteration:  89% 14100/15836 [1:10:52<07:55,  3.65it/s]\u001b[A\n",
      "Iteration:  89% 14101/15836 [1:10:52<07:27,  3.88it/s]\u001b[A\n",
      "Iteration:  89% 14102/15836 [1:10:52<07:08,  4.05it/s]\u001b[A\n",
      "Iteration:  89% 14103/15836 [1:10:52<06:58,  4.14it/s]\u001b[A\n",
      "Iteration:  89% 14104/15836 [1:10:52<06:51,  4.21it/s]\u001b[A\n",
      "Iteration:  89% 14105/15836 [1:10:53<07:56,  3.64it/s]\u001b[A\n",
      "Iteration:  89% 14106/15836 [1:10:53<07:28,  3.86it/s]\u001b[A\n",
      "Iteration:  89% 14107/15836 [1:10:53<07:07,  4.05it/s]\u001b[A\n",
      "Iteration:  89% 14108/15836 [1:10:53<06:54,  4.17it/s]\u001b[A\n",
      "Iteration:  89% 14109/15836 [1:10:54<06:48,  4.23it/s]\u001b[A\n",
      "Iteration:  89% 14110/15836 [1:10:54<07:51,  3.66it/s]\u001b[A\n",
      "Iteration:  89% 14111/15836 [1:10:54<07:20,  3.91it/s]\u001b[A\n",
      "Iteration:  89% 14112/15836 [1:10:55<07:04,  4.06it/s]\u001b[A\n",
      "Iteration:  89% 14113/15836 [1:10:55<06:54,  4.16it/s]\u001b[A\n",
      "Iteration:  89% 14114/15836 [1:10:55<06:45,  4.25it/s]\u001b[A\n",
      "Iteration:  89% 14115/15836 [1:10:55<07:48,  3.67it/s]\u001b[A\n",
      "Iteration:  89% 14116/15836 [1:10:56<07:20,  3.91it/s]\u001b[A\n",
      "Iteration:  89% 14117/15836 [1:10:56<07:01,  4.08it/s]\u001b[A\n",
      "Iteration:  89% 14118/15836 [1:10:56<06:50,  4.19it/s]\u001b[A\n",
      "Iteration:  89% 14119/15836 [1:10:56<06:44,  4.25it/s]\u001b[A\n",
      "Iteration:  89% 14120/15836 [1:10:57<07:47,  3.67it/s]\u001b[A\n",
      "Iteration:  89% 14121/15836 [1:10:57<07:19,  3.91it/s]\u001b[A\n",
      "Iteration:  89% 14122/15836 [1:10:57<07:00,  4.07it/s]\u001b[A\n",
      "Iteration:  89% 14123/15836 [1:10:57<06:49,  4.18it/s]\u001b[A\n",
      "Iteration:  89% 14124/15836 [1:10:57<06:43,  4.24it/s]\u001b[A\n",
      "Iteration:  89% 14125/15836 [1:10:58<07:49,  3.65it/s]\u001b[A\n",
      "Iteration:  89% 14126/15836 [1:10:58<07:18,  3.90it/s]\u001b[A\n",
      "Iteration:  89% 14127/15836 [1:10:58<07:00,  4.06it/s]\u001b[A\n",
      "Iteration:  89% 14128/15836 [1:10:58<06:48,  4.19it/s]\u001b[A\n",
      "Iteration:  89% 14129/15836 [1:10:59<06:42,  4.24it/s]\u001b[A\n",
      "Iteration:  89% 14130/15836 [1:10:59<07:45,  3.66it/s]\u001b[A\n",
      "Iteration:  89% 14131/15836 [1:10:59<07:15,  3.91it/s]\u001b[A\n",
      "Iteration:  89% 14132/15836 [1:11:00<06:58,  4.07it/s]\u001b[A\n",
      "Iteration:  89% 14133/15836 [1:11:00<06:49,  4.15it/s]\u001b[A\n",
      "Iteration:  89% 14134/15836 [1:11:00<06:42,  4.23it/s]\u001b[A\n",
      "Iteration:  89% 14135/15836 [1:11:00<07:43,  3.67it/s]\u001b[A\n",
      "Iteration:  89% 14136/15836 [1:11:01<07:15,  3.91it/s]\u001b[A\n",
      "Iteration:  89% 14137/15836 [1:11:01<06:57,  4.07it/s]\u001b[A\n",
      "Iteration:  89% 14138/15836 [1:11:01<06:47,  4.17it/s]\u001b[A\n",
      "Iteration:  89% 14139/15836 [1:11:01<06:40,  4.24it/s]\u001b[A\n",
      "Iteration:  89% 14140/15836 [1:11:02<07:44,  3.65it/s]\u001b[A\n",
      "Iteration:  89% 14141/15836 [1:11:02<07:14,  3.90it/s]\u001b[A\n",
      "Iteration:  89% 14142/15836 [1:11:02<06:59,  4.04it/s]\u001b[A\n",
      "Iteration:  89% 14143/15836 [1:11:02<06:48,  4.14it/s]\u001b[A\n",
      "Iteration:  89% 14144/15836 [1:11:02<06:41,  4.21it/s]\u001b[A\n",
      "Iteration:  89% 14145/15836 [1:11:03<07:42,  3.65it/s]\u001b[A\n",
      "Iteration:  89% 14146/15836 [1:11:03<07:18,  3.86it/s]\u001b[A\n",
      "Iteration:  89% 14147/15836 [1:11:03<06:57,  4.05it/s]\u001b[A\n",
      "Iteration:  89% 14148/15836 [1:11:04<06:47,  4.14it/s]\u001b[A\n",
      "Iteration:  89% 14149/15836 [1:11:04<06:39,  4.23it/s]\u001b[A\n",
      "Iteration:  89% 14150/15836 [1:11:04<07:41,  3.65it/s]\u001b[A\n",
      "Iteration:  89% 14151/15836 [1:11:04<07:14,  3.88it/s]\u001b[A\n",
      "Iteration:  89% 14152/15836 [1:11:05<06:55,  4.05it/s]\u001b[A\n",
      "Iteration:  89% 14153/15836 [1:11:05<06:44,  4.16it/s]\u001b[A\n",
      "Iteration:  89% 14154/15836 [1:11:05<06:37,  4.23it/s]\u001b[A\n",
      "Iteration:  89% 14155/15836 [1:11:05<07:38,  3.67it/s]\u001b[A\n",
      "Iteration:  89% 14156/15836 [1:11:06<07:10,  3.90it/s]\u001b[A\n",
      "Iteration:  89% 14157/15836 [1:11:06<06:55,  4.04it/s]\u001b[A\n",
      "Iteration:  89% 14158/15836 [1:11:06<06:44,  4.15it/s]\u001b[A\n",
      "Iteration:  89% 14159/15836 [1:11:06<06:38,  4.20it/s]\u001b[A\n",
      "Iteration:  89% 14160/15836 [1:11:07<07:39,  3.65it/s]\u001b[A\n",
      "Iteration:  89% 14161/15836 [1:11:07<07:10,  3.89it/s]\u001b[A\n",
      "Iteration:  89% 14162/15836 [1:11:07<06:53,  4.04it/s]\u001b[A\n",
      "Iteration:  89% 14163/15836 [1:11:07<06:44,  4.14it/s]\u001b[A\n",
      "Iteration:  89% 14164/15836 [1:11:07<06:35,  4.22it/s]\u001b[A\n",
      "Iteration:  89% 14165/15836 [1:11:08<07:37,  3.66it/s]\u001b[A\n",
      "Iteration:  89% 14166/15836 [1:11:08<07:10,  3.88it/s]\u001b[A\n",
      "Iteration:  89% 14167/15836 [1:11:08<06:54,  4.03it/s]\u001b[A\n",
      "Iteration:  89% 14168/15836 [1:11:09<06:40,  4.17it/s]\u001b[A\n",
      "Iteration:  89% 14169/15836 [1:11:09<06:34,  4.23it/s]\u001b[A\n",
      "Iteration:  89% 14170/15836 [1:11:09<07:35,  3.66it/s]\u001b[A\n",
      "Iteration:  89% 14171/15836 [1:11:09<07:09,  3.88it/s]\u001b[A\n",
      "Iteration:  89% 14172/15836 [1:11:10<06:49,  4.06it/s]\u001b[A\n",
      "Iteration:  89% 14173/15836 [1:11:10<06:41,  4.15it/s]\u001b[A\n",
      "Iteration:  90% 14174/15836 [1:11:10<06:32,  4.23it/s]\u001b[A\n",
      "Iteration:  90% 14175/15836 [1:11:10<07:34,  3.65it/s]\u001b[A\n",
      "Iteration:  90% 14176/15836 [1:11:11<07:05,  3.90it/s]\u001b[A\n",
      "Iteration:  90% 14177/15836 [1:11:11<06:50,  4.05it/s]\u001b[A\n",
      "Iteration:  90% 14178/15836 [1:11:11<06:37,  4.17it/s]\u001b[A\n",
      "Iteration:  90% 14179/15836 [1:11:11<06:33,  4.21it/s]\u001b[A\n",
      "Iteration:  90% 14180/15836 [1:11:12<07:34,  3.65it/s]\u001b[A\n",
      "Iteration:  90% 14181/15836 [1:11:12<07:07,  3.87it/s]\u001b[A\n",
      "Iteration:  90% 14182/15836 [1:11:12<06:48,  4.04it/s]\u001b[A\n",
      "Iteration:  90% 14183/15836 [1:11:12<06:38,  4.15it/s]\u001b[A\n",
      "Iteration:  90% 14184/15836 [1:11:13<06:31,  4.22it/s]\u001b[A\n",
      "Iteration:  90% 14185/15836 [1:11:13<07:32,  3.65it/s]\u001b[A\n",
      "Iteration:  90% 14186/15836 [1:11:13<07:04,  3.88it/s]\u001b[A\n",
      "Iteration:  90% 14187/15836 [1:11:13<06:46,  4.06it/s]\u001b[A\n",
      "Iteration:  90% 14188/15836 [1:11:14<06:37,  4.15it/s]\u001b[A\n",
      "Iteration:  90% 14189/15836 [1:11:14<06:27,  4.25it/s]\u001b[A\n",
      "Iteration:  90% 14190/15836 [1:11:14<07:28,  3.67it/s]\u001b[A\n",
      "Iteration:  90% 14191/15836 [1:11:14<07:02,  3.89it/s]\u001b[A\n",
      "Iteration:  90% 14192/15836 [1:11:15<06:47,  4.04it/s]\u001b[A\n",
      "Iteration:  90% 14193/15836 [1:11:15<06:33,  4.17it/s]\u001b[A\n",
      "Iteration:  90% 14194/15836 [1:11:15<06:27,  4.24it/s]\u001b[A\n",
      "Iteration:  90% 14195/15836 [1:11:15<07:30,  3.64it/s]\u001b[A\n",
      "Iteration:  90% 14196/15836 [1:11:16<07:02,  3.88it/s]\u001b[A\n",
      "Iteration:  90% 14197/15836 [1:11:16<06:46,  4.04it/s]\u001b[A\n",
      "Iteration:  90% 14198/15836 [1:11:16<06:34,  4.15it/s]\u001b[A\n",
      "Iteration:  90% 14199/15836 [1:11:16<06:29,  4.21it/s]\u001b[A\n",
      "Iteration:  90% 14200/15836 [1:11:17<07:27,  3.65it/s]\u001b[A\n",
      "Iteration:  90% 14201/15836 [1:11:17<07:01,  3.88it/s]\u001b[A\n",
      "Iteration:  90% 14202/15836 [1:11:17<06:42,  4.06it/s]\u001b[A\n",
      "Iteration:  90% 14203/15836 [1:11:17<06:31,  4.17it/s]\u001b[A\n",
      "Iteration:  90% 14204/15836 [1:11:18<06:25,  4.23it/s]\u001b[A\n",
      "Iteration:  90% 14205/15836 [1:11:18<07:26,  3.66it/s]\u001b[A\n",
      "Iteration:  90% 14206/15836 [1:11:18<07:00,  3.88it/s]\u001b[A\n",
      "Iteration:  90% 14207/15836 [1:11:18<06:44,  4.03it/s]\u001b[A\n",
      "Iteration:  90% 14208/15836 [1:11:19<06:32,  4.15it/s]\u001b[A\n",
      "Iteration:  90% 14209/15836 [1:11:19<06:27,  4.20it/s]\u001b[A\n",
      "Iteration:  90% 14210/15836 [1:11:19<07:27,  3.64it/s]\u001b[A\n",
      "Iteration:  90% 14211/15836 [1:11:19<06:58,  3.89it/s]\u001b[A\n",
      "Iteration:  90% 14212/15836 [1:11:20<06:42,  4.03it/s]\u001b[A\n",
      "Iteration:  90% 14213/15836 [1:11:20<06:30,  4.15it/s]\u001b[A\n",
      "Iteration:  90% 14214/15836 [1:11:20<06:25,  4.21it/s]\u001b[A\n",
      "Iteration:  90% 14215/15836 [1:11:20<07:25,  3.64it/s]\u001b[A\n",
      "Iteration:  90% 14216/15836 [1:11:21<06:56,  3.89it/s]\u001b[A\n",
      "Iteration:  90% 14217/15836 [1:11:21<06:39,  4.05it/s]\u001b[A\n",
      "Iteration:  90% 14218/15836 [1:11:21<06:28,  4.17it/s]\u001b[A\n",
      "Iteration:  90% 14219/15836 [1:11:21<06:21,  4.23it/s]\u001b[A\n",
      "Iteration:  90% 14220/15836 [1:11:22<07:22,  3.65it/s]\u001b[A\n",
      "Iteration:  90% 14221/15836 [1:11:22<06:55,  3.89it/s]\u001b[A\n",
      "Iteration:  90% 14222/15836 [1:11:22<06:39,  4.04it/s]\u001b[A\n",
      "Iteration:  90% 14223/15836 [1:11:22<06:26,  4.18it/s]\u001b[A\n",
      "Iteration:  90% 14224/15836 [1:11:23<06:21,  4.23it/s]\u001b[A\n",
      "Iteration:  90% 14225/15836 [1:11:23<07:19,  3.67it/s]\u001b[A\n",
      "Iteration:  90% 14226/15836 [1:11:23<06:54,  3.88it/s]\u001b[A\n",
      "Iteration:  90% 14227/15836 [1:11:23<06:37,  4.04it/s]\u001b[A\n",
      "Iteration:  90% 14228/15836 [1:11:24<06:27,  4.15it/s]\u001b[A\n",
      "Iteration:  90% 14229/15836 [1:11:24<06:20,  4.23it/s]\u001b[A\n",
      "Iteration:  90% 14230/15836 [1:11:24<07:18,  3.66it/s]\u001b[A\n",
      "Iteration:  90% 14231/15836 [1:11:24<06:53,  3.89it/s]\u001b[A\n",
      "Iteration:  90% 14232/15836 [1:11:25<06:38,  4.03it/s]\u001b[A\n",
      "Iteration:  90% 14233/15836 [1:11:25<06:25,  4.16it/s]\u001b[A\n",
      "Iteration:  90% 14234/15836 [1:11:25<06:18,  4.23it/s]\u001b[A\n",
      "Iteration:  90% 14235/15836 [1:11:25<07:17,  3.66it/s]\u001b[A\n",
      "Iteration:  90% 14236/15836 [1:11:26<06:53,  3.87it/s]\u001b[A\n",
      "Iteration:  90% 14237/15836 [1:11:26<06:35,  4.04it/s]\u001b[A\n",
      "Iteration:  90% 14238/15836 [1:11:26<06:25,  4.15it/s]\u001b[A\n",
      "Iteration:  90% 14239/15836 [1:11:26<06:19,  4.21it/s]\u001b[A\n",
      "Iteration:  90% 14240/15836 [1:11:27<07:18,  3.64it/s]\u001b[A\n",
      "Iteration:  90% 14241/15836 [1:11:27<06:51,  3.88it/s]\u001b[A\n",
      "Iteration:  90% 14242/15836 [1:11:27<06:33,  4.05it/s]\u001b[A\n",
      "Iteration:  90% 14243/15836 [1:11:27<06:22,  4.16it/s]\u001b[A\n",
      "Iteration:  90% 14244/15836 [1:11:28<06:15,  4.24it/s]\u001b[A\n",
      "Iteration:  90% 14245/15836 [1:11:28<07:12,  3.68it/s]\u001b[A\n",
      "Iteration:  90% 14246/15836 [1:11:28<06:48,  3.89it/s]\u001b[A\n",
      "Iteration:  90% 14247/15836 [1:11:28<06:30,  4.07it/s]\u001b[A\n",
      "Iteration:  90% 14248/15836 [1:11:29<06:21,  4.16it/s]\u001b[A\n",
      "Iteration:  90% 14249/15836 [1:11:29<06:15,  4.23it/s]\u001b[A\n",
      "Iteration:  90% 14250/15836 [1:11:29<07:12,  3.67it/s]\u001b[A\n",
      "Iteration:  90% 14251/15836 [1:11:29<06:47,  3.89it/s]\u001b[A\n",
      "Iteration:  90% 14252/15836 [1:11:30<06:31,  4.05it/s]\u001b[A\n",
      "Iteration:  90% 14253/15836 [1:11:30<06:22,  4.14it/s]\u001b[A\n",
      "Iteration:  90% 14254/15836 [1:11:30<06:15,  4.21it/s]\u001b[A\n",
      "Iteration:  90% 14255/15836 [1:11:30<07:10,  3.67it/s]\u001b[A\n",
      "Iteration:  90% 14256/15836 [1:11:31<06:44,  3.91it/s]\u001b[A\n",
      "Iteration:  90% 14257/15836 [1:11:31<06:27,  4.08it/s]\u001b[A\n",
      "Iteration:  90% 14258/15836 [1:11:31<06:18,  4.17it/s]\u001b[A\n",
      "Iteration:  90% 14259/15836 [1:11:31<06:12,  4.23it/s]\u001b[A\n",
      "Iteration:  90% 14260/15836 [1:11:32<07:11,  3.66it/s]\u001b[A\n",
      "Iteration:  90% 14261/15836 [1:11:32<06:43,  3.90it/s]\u001b[A\n",
      "Iteration:  90% 14262/15836 [1:11:32<06:26,  4.08it/s]\u001b[A\n",
      "Iteration:  90% 14263/15836 [1:11:32<06:16,  4.17it/s]\u001b[A\n",
      "Iteration:  90% 14264/15836 [1:11:33<06:12,  4.22it/s]\u001b[A\n",
      "Iteration:  90% 14265/15836 [1:11:33<07:12,  3.64it/s]\u001b[A\n",
      "Iteration:  90% 14266/15836 [1:11:33<06:44,  3.88it/s]\u001b[A\n",
      "Iteration:  90% 14267/15836 [1:11:33<06:26,  4.06it/s]\u001b[A\n",
      "Iteration:  90% 14268/15836 [1:11:34<06:18,  4.14it/s]\u001b[A\n",
      "Iteration:  90% 14269/15836 [1:11:34<06:12,  4.21it/s]\u001b[A\n",
      "Iteration:  90% 14270/15836 [1:11:34<07:08,  3.65it/s]\u001b[A\n",
      "Iteration:  90% 14271/15836 [1:11:34<06:40,  3.90it/s]\u001b[A\n",
      "Iteration:  90% 14272/15836 [1:11:35<06:25,  4.05it/s]\u001b[A\n",
      "Iteration:  90% 14273/15836 [1:11:35<06:15,  4.16it/s]\u001b[A\n",
      "Iteration:  90% 14274/15836 [1:11:35<06:07,  4.25it/s]\u001b[A\n",
      "Iteration:  90% 14275/15836 [1:11:35<07:09,  3.63it/s]\u001b[A\n",
      "Iteration:  90% 14276/15836 [1:11:36<06:40,  3.89it/s]\u001b[A\n",
      "Iteration:  90% 14277/15836 [1:11:36<06:24,  4.05it/s]\u001b[A\n",
      "Iteration:  90% 14278/15836 [1:11:36<06:15,  4.15it/s]\u001b[A\n",
      "Iteration:  90% 14279/15836 [1:11:36<06:10,  4.21it/s]\u001b[A\n",
      "Iteration:  90% 14280/15836 [1:11:37<07:07,  3.64it/s]\u001b[A\n",
      "Iteration:  90% 14281/15836 [1:11:37<06:37,  3.91it/s]\u001b[A\n",
      "Iteration:  90% 14282/15836 [1:11:37<06:21,  4.07it/s]\u001b[A\n",
      "Iteration:  90% 14283/15836 [1:11:37<06:12,  4.17it/s]\u001b[A\n",
      "Iteration:  90% 14284/15836 [1:11:38<06:04,  4.26it/s]\u001b[A\n",
      "Iteration:  90% 14285/15836 [1:11:38<07:02,  3.67it/s]\u001b[A\n",
      "Iteration:  90% 14286/15836 [1:11:38<06:37,  3.90it/s]\u001b[A\n",
      "Iteration:  90% 14287/15836 [1:11:38<06:23,  4.04it/s]\u001b[A\n",
      "Iteration:  90% 14288/15836 [1:11:39<06:10,  4.17it/s]\u001b[A\n",
      "Iteration:  90% 14289/15836 [1:11:39<06:05,  4.23it/s]\u001b[A\n",
      "Iteration:  90% 14290/15836 [1:11:39<07:06,  3.63it/s]\u001b[A\n",
      "Iteration:  90% 14291/15836 [1:11:39<06:40,  3.85it/s]\u001b[A\n",
      "Iteration:  90% 14292/15836 [1:11:40<06:23,  4.03it/s]\u001b[A\n",
      "Iteration:  90% 14293/15836 [1:11:40<06:13,  4.13it/s]\u001b[A\n",
      "Iteration:  90% 14294/15836 [1:11:40<06:06,  4.21it/s]\u001b[A\n",
      "Iteration:  90% 14295/15836 [1:11:40<07:03,  3.64it/s]\u001b[A\n",
      "Iteration:  90% 14296/15836 [1:11:41<06:37,  3.87it/s]\u001b[A\n",
      "Iteration:  90% 14297/15836 [1:11:41<06:20,  4.05it/s]\u001b[A\n",
      "Iteration:  90% 14298/15836 [1:11:41<06:11,  4.14it/s]\u001b[A\n",
      "Iteration:  90% 14299/15836 [1:11:41<06:06,  4.20it/s]\u001b[A\n",
      "Iteration:  90% 14300/15836 [1:11:42<07:01,  3.64it/s]\u001b[A\n",
      "Iteration:  90% 14301/15836 [1:11:42<06:35,  3.89it/s]\u001b[A\n",
      "Iteration:  90% 14302/15836 [1:11:42<06:20,  4.04it/s]\u001b[A\n",
      "Iteration:  90% 14303/15836 [1:11:42<06:10,  4.14it/s]\u001b[A\n",
      "Iteration:  90% 14304/15836 [1:11:43<06:03,  4.22it/s]\u001b[A\n",
      "Iteration:  90% 14305/15836 [1:11:43<06:59,  3.65it/s]\u001b[A\n",
      "Iteration:  90% 14306/15836 [1:11:43<06:32,  3.90it/s]\u001b[A\n",
      "Iteration:  90% 14307/15836 [1:11:43<06:15,  4.07it/s]\u001b[A\n",
      "Iteration:  90% 14308/15836 [1:11:44<06:06,  4.17it/s]\u001b[A\n",
      "Iteration:  90% 14309/15836 [1:11:44<06:00,  4.23it/s]\u001b[A\n",
      "Iteration:  90% 14310/15836 [1:11:44<06:59,  3.64it/s]\u001b[A\n",
      "Iteration:  90% 14311/15836 [1:11:44<06:30,  3.90it/s]\u001b[A\n",
      "Iteration:  90% 14312/15836 [1:11:45<06:13,  4.08it/s]\u001b[A\n",
      "Iteration:  90% 14313/15836 [1:11:45<06:04,  4.18it/s]\u001b[A\n",
      "Iteration:  90% 14314/15836 [1:11:45<05:58,  4.24it/s]\u001b[A\n",
      "Iteration:  90% 14315/15836 [1:11:46<06:54,  3.67it/s]\u001b[A\n",
      "Iteration:  90% 14316/15836 [1:11:46<06:29,  3.90it/s]\u001b[A\n",
      "Iteration:  90% 14317/15836 [1:11:46<06:16,  4.04it/s]\u001b[A\n",
      "Iteration:  90% 14318/15836 [1:11:46<06:06,  4.15it/s]\u001b[A\n",
      "Iteration:  90% 14319/15836 [1:11:46<05:57,  4.24it/s]\u001b[A\n",
      "Iteration:  90% 14320/15836 [1:11:47<06:53,  3.67it/s]\u001b[A\n",
      "Iteration:  90% 14321/15836 [1:11:47<06:27,  3.91it/s]\u001b[A\n",
      "Iteration:  90% 14322/15836 [1:11:47<06:13,  4.06it/s]\u001b[A\n",
      "Iteration:  90% 14323/15836 [1:11:47<06:04,  4.15it/s]\u001b[A\n",
      "Iteration:  90% 14324/15836 [1:11:48<05:58,  4.22it/s]\u001b[A\n",
      "Iteration:  90% 14325/15836 [1:11:48<06:52,  3.66it/s]\u001b[A\n",
      "Iteration:  90% 14326/15836 [1:11:48<06:27,  3.90it/s]\u001b[A\n",
      "Iteration:  90% 14327/15836 [1:11:48<06:12,  4.05it/s]\u001b[A\n",
      "Iteration:  90% 14328/15836 [1:11:49<06:03,  4.15it/s]\u001b[A\n",
      "Iteration:  90% 14329/15836 [1:11:49<05:59,  4.19it/s]\u001b[A\n",
      "Iteration:  90% 14330/15836 [1:11:49<06:53,  3.64it/s]\u001b[A\n",
      "Iteration:  90% 14331/15836 [1:11:49<06:27,  3.88it/s]\u001b[A\n",
      "Iteration:  91% 14332/15836 [1:11:50<06:11,  4.04it/s]\u001b[A\n",
      "Iteration:  91% 14333/15836 [1:11:50<06:01,  4.15it/s]\u001b[A\n",
      "Iteration:  91% 14334/15836 [1:11:50<05:55,  4.23it/s]\u001b[A\n",
      "Iteration:  91% 14335/15836 [1:11:51<06:51,  3.65it/s]\u001b[A\n",
      "Iteration:  91% 14336/15836 [1:11:51<06:26,  3.88it/s]\u001b[A\n",
      "Iteration:  91% 14337/15836 [1:11:51<06:10,  4.05it/s]\u001b[A\n",
      "Iteration:  91% 14338/15836 [1:11:51<05:59,  4.16it/s]\u001b[A\n",
      "Iteration:  91% 14339/15836 [1:11:51<05:53,  4.23it/s]\u001b[A\n",
      "Iteration:  91% 14340/15836 [1:11:52<06:49,  3.65it/s]\u001b[A\n",
      "Iteration:  91% 14341/15836 [1:11:52<06:25,  3.88it/s]\u001b[A\n",
      "Iteration:  91% 14342/15836 [1:11:52<06:09,  4.04it/s]\u001b[A\n",
      "Iteration:  91% 14343/15836 [1:11:52<05:59,  4.15it/s]\u001b[A\n",
      "Iteration:  91% 14344/15836 [1:11:53<05:54,  4.21it/s]\u001b[A\n",
      "Iteration:  91% 14345/15836 [1:11:53<06:48,  3.65it/s]\u001b[A\n",
      "Iteration:  91% 14346/15836 [1:11:53<06:21,  3.90it/s]\u001b[A\n",
      "Iteration:  91% 14347/15836 [1:11:53<06:08,  4.05it/s]\u001b[A\n",
      "Iteration:  91% 14348/15836 [1:11:54<05:57,  4.17it/s]\u001b[A\n",
      "Iteration:  91% 14349/15836 [1:11:54<05:52,  4.22it/s]\u001b[A\n",
      "Iteration:  91% 14350/15836 [1:11:54<06:45,  3.66it/s]\u001b[A\n",
      "Iteration:  91% 14351/15836 [1:11:55<06:21,  3.90it/s]\u001b[A\n",
      "Iteration:  91% 14352/15836 [1:11:55<06:03,  4.08it/s]\u001b[A\n",
      "Iteration:  91% 14353/15836 [1:11:55<05:57,  4.15it/s]\u001b[A\n",
      "Iteration:  91% 14354/15836 [1:11:55<05:51,  4.21it/s]\u001b[A\n",
      "Iteration:  91% 14355/15836 [1:11:56<06:46,  3.64it/s]\u001b[A\n",
      "Iteration:  91% 14356/15836 [1:11:56<06:21,  3.88it/s]\u001b[A\n",
      "Iteration:  91% 14357/15836 [1:11:56<06:04,  4.06it/s]\u001b[A\n",
      "Iteration:  91% 14358/15836 [1:11:56<05:56,  4.15it/s]\u001b[A\n",
      "Iteration:  91% 14359/15836 [1:11:56<05:49,  4.23it/s]\u001b[A\n",
      "Iteration:  91% 14360/15836 [1:11:57<06:43,  3.65it/s]\u001b[A\n",
      "Iteration:  91% 14361/15836 [1:11:57<06:17,  3.90it/s]\u001b[A\n",
      "Iteration:  91% 14362/15836 [1:11:57<06:01,  4.07it/s]\u001b[A\n",
      "Iteration:  91% 14363/15836 [1:11:57<05:53,  4.17it/s]\u001b[A\n",
      "Iteration:  91% 14364/15836 [1:11:58<05:47,  4.24it/s]\u001b[A\n",
      "Iteration:  91% 14365/15836 [1:11:58<06:43,  3.64it/s]\u001b[A\n",
      "Iteration:  91% 14366/15836 [1:11:58<06:17,  3.89it/s]\u001b[A\n",
      "Iteration:  91% 14367/15836 [1:11:59<06:03,  4.04it/s]\u001b[A\n",
      "Iteration:  91% 14368/15836 [1:11:59<05:53,  4.15it/s]\u001b[A\n",
      "Iteration:  91% 14369/15836 [1:11:59<05:50,  4.19it/s]\u001b[A\n",
      "Iteration:  91% 14370/15836 [1:11:59<06:43,  3.64it/s]\u001b[A\n",
      "Iteration:  91% 14371/15836 [1:12:00<06:17,  3.88it/s]\u001b[A\n",
      "Iteration:  91% 14372/15836 [1:12:00<06:02,  4.04it/s]\u001b[A\n",
      "Iteration:  91% 14373/15836 [1:12:00<05:53,  4.14it/s]\u001b[A\n",
      "Iteration:  91% 14374/15836 [1:12:00<05:45,  4.23it/s]\u001b[A\n",
      "Iteration:  91% 14375/15836 [1:12:01<06:39,  3.66it/s]\u001b[A\n",
      "Iteration:  91% 14376/15836 [1:12:01<06:16,  3.88it/s]\u001b[A\n",
      "Iteration:  91% 14377/15836 [1:12:01<06:02,  4.02it/s]\u001b[A\n",
      "Iteration:  91% 14378/15836 [1:12:01<05:49,  4.17it/s]\u001b[A\n",
      "Iteration:  91% 14379/15836 [1:12:01<05:43,  4.24it/s]\u001b[A\n",
      "Iteration:  91% 14380/15836 [1:12:02<06:37,  3.66it/s]\u001b[A\n",
      "Iteration:  91% 14381/15836 [1:12:02<06:16,  3.86it/s]\u001b[A\n",
      "Iteration:  91% 14382/15836 [1:12:02<05:58,  4.06it/s]\u001b[A\n",
      "Iteration:  91% 14383/15836 [1:12:03<05:50,  4.15it/s]\u001b[A\n",
      "Iteration:  91% 14384/15836 [1:12:03<05:43,  4.23it/s]\u001b[A\n",
      "Iteration:  91% 14385/15836 [1:12:03<06:36,  3.66it/s]\u001b[A\n",
      "Iteration:  91% 14386/15836 [1:12:03<06:11,  3.90it/s]\u001b[A\n",
      "Iteration:  91% 14387/15836 [1:12:04<05:57,  4.05it/s]\u001b[A\n",
      "Iteration:  91% 14388/15836 [1:12:04<05:48,  4.16it/s]\u001b[A\n",
      "Iteration:  91% 14389/15836 [1:12:04<05:43,  4.21it/s]\u001b[A\n",
      "Iteration:  91% 14390/15836 [1:12:04<06:36,  3.65it/s]\u001b[A\n",
      "Iteration:  91% 14391/15836 [1:12:05<06:14,  3.86it/s]\u001b[A\n",
      "Iteration:  91% 14392/15836 [1:12:05<05:57,  4.03it/s]\u001b[A\n",
      "Iteration:  91% 14393/15836 [1:12:05<05:47,  4.16it/s]\u001b[A\n",
      "Iteration:  91% 14394/15836 [1:12:05<05:41,  4.23it/s]\u001b[A\n",
      "Iteration:  91% 14395/15836 [1:12:06<06:34,  3.66it/s]\u001b[A\n",
      "Iteration:  91% 14396/15836 [1:12:06<06:11,  3.87it/s]\u001b[A\n",
      "Iteration:  91% 14397/15836 [1:12:06<05:56,  4.04it/s]\u001b[A\n",
      "Iteration:  91% 14398/15836 [1:12:06<05:45,  4.16it/s]\u001b[A\n",
      "Iteration:  91% 14399/15836 [1:12:06<05:39,  4.23it/s]\u001b[A\n",
      "Iteration:  91% 14400/15836 [1:12:07<06:33,  3.65it/s]\u001b[A\n",
      "Iteration:  91% 14401/15836 [1:12:07<06:09,  3.88it/s]\u001b[A\n",
      "Iteration:  91% 14402/15836 [1:12:07<05:53,  4.06it/s]\u001b[A\n",
      "Iteration:  91% 14403/15836 [1:12:08<05:44,  4.16it/s]\u001b[A\n",
      "Iteration:  91% 14404/15836 [1:12:08<05:39,  4.22it/s]\u001b[A\n",
      "Iteration:  91% 14405/15836 [1:12:08<06:33,  3.64it/s]\u001b[A\n",
      "Iteration:  91% 14406/15836 [1:12:08<06:08,  3.88it/s]\u001b[A\n",
      "Iteration:  91% 14407/15836 [1:12:09<05:54,  4.03it/s]\u001b[A\n",
      "Iteration:  91% 14408/15836 [1:12:09<05:43,  4.15it/s]\u001b[A\n",
      "Iteration:  91% 14409/15836 [1:12:09<05:37,  4.22it/s]\u001b[A\n",
      "Iteration:  91% 14410/15836 [1:12:09<06:32,  3.63it/s]\u001b[A\n",
      "Iteration:  91% 14411/15836 [1:12:10<06:07,  3.88it/s]\u001b[A\n",
      "Iteration:  91% 14412/15836 [1:12:10<05:50,  4.06it/s]\u001b[A\n",
      "Iteration:  91% 14413/15836 [1:12:10<05:41,  4.17it/s]\u001b[A\n",
      "Iteration:  91% 14414/15836 [1:12:10<05:37,  4.21it/s]\u001b[A\n",
      "Iteration:  91% 14415/15836 [1:12:11<06:30,  3.64it/s]\u001b[A\n",
      "Iteration:  91% 14416/15836 [1:12:11<06:04,  3.89it/s]\u001b[A\n",
      "Iteration:  91% 14417/15836 [1:12:11<05:48,  4.07it/s]\u001b[A\n",
      "Iteration:  91% 14418/15836 [1:12:11<05:40,  4.16it/s]\u001b[A\n",
      "Iteration:  91% 14419/15836 [1:12:12<05:34,  4.24it/s]\u001b[A\n",
      "Iteration:  91% 14420/15836 [1:12:12<06:26,  3.67it/s]\u001b[A\n",
      "Iteration:  91% 14421/15836 [1:12:12<06:02,  3.90it/s]\u001b[A\n",
      "Iteration:  91% 14422/15836 [1:12:12<05:49,  4.04it/s]\u001b[A\n",
      "Iteration:  91% 14423/15836 [1:12:13<05:38,  4.17it/s]\u001b[A\n",
      "Iteration:  91% 14424/15836 [1:12:13<05:33,  4.23it/s]\u001b[A\n",
      "Iteration:  91% 14425/15836 [1:12:13<06:25,  3.66it/s]\u001b[A\n",
      "Iteration:  91% 14426/15836 [1:12:13<06:02,  3.89it/s]\u001b[A\n",
      "Iteration:  91% 14427/15836 [1:12:14<05:47,  4.06it/s]\u001b[A\n",
      "Iteration:  91% 14428/15836 [1:12:14<05:38,  4.16it/s]\u001b[A\n",
      "Iteration:  91% 14429/15836 [1:12:14<05:32,  4.23it/s]\u001b[A\n",
      "Iteration:  91% 14430/15836 [1:12:14<06:23,  3.67it/s]\u001b[A\n",
      "Iteration:  91% 14431/15836 [1:12:15<06:01,  3.89it/s]\u001b[A\n",
      "Iteration:  91% 14432/15836 [1:12:15<05:47,  4.04it/s]\u001b[A\n",
      "Iteration:  91% 14433/15836 [1:12:15<05:36,  4.18it/s]\u001b[A\n",
      "Iteration:  91% 14434/15836 [1:12:15<05:29,  4.25it/s]\u001b[A\n",
      "Iteration:  91% 14435/15836 [1:12:16<06:23,  3.66it/s]\u001b[A\n",
      "Iteration:  91% 14436/15836 [1:12:16<06:00,  3.88it/s]\u001b[A\n",
      "Iteration:  91% 14437/15836 [1:12:16<05:45,  4.05it/s]\u001b[A\n",
      "Iteration:  91% 14438/15836 [1:12:16<05:38,  4.14it/s]\u001b[A\n",
      "Iteration:  91% 14439/15836 [1:12:17<05:31,  4.22it/s]\u001b[A\n",
      "Iteration:  91% 14440/15836 [1:12:17<06:21,  3.66it/s]\u001b[A\n",
      "Iteration:  91% 14441/15836 [1:12:17<05:59,  3.88it/s]\u001b[A\n",
      "Iteration:  91% 14442/15836 [1:12:17<05:44,  4.04it/s]\u001b[A\n",
      "Iteration:  91% 14443/15836 [1:12:18<05:35,  4.15it/s]\u001b[A\n",
      "Iteration:  91% 14444/15836 [1:12:18<05:30,  4.21it/s]\u001b[A\n",
      "Iteration:  91% 14445/15836 [1:12:18<06:21,  3.64it/s]\u001b[A\n",
      "Iteration:  91% 14446/15836 [1:12:18<05:57,  3.89it/s]\u001b[A\n",
      "Iteration:  91% 14447/15836 [1:12:19<05:43,  4.04it/s]\u001b[A\n",
      "Iteration:  91% 14448/15836 [1:12:19<05:33,  4.16it/s]\u001b[A\n",
      "Iteration:  91% 14449/15836 [1:12:19<05:29,  4.21it/s]\u001b[A\n",
      "Iteration:  91% 14450/15836 [1:12:19<06:20,  3.64it/s]\u001b[A\n",
      "Iteration:  91% 14451/15836 [1:12:20<05:54,  3.90it/s]\u001b[A\n",
      "Iteration:  91% 14452/15836 [1:12:20<05:41,  4.05it/s]\u001b[A\n",
      "Iteration:  91% 14453/15836 [1:12:20<05:33,  4.15it/s]\u001b[A\n",
      "Iteration:  91% 14454/15836 [1:12:20<05:25,  4.24it/s]\u001b[A\n",
      "Iteration:  91% 14455/15836 [1:12:21<06:16,  3.67it/s]\u001b[A\n",
      "Iteration:  91% 14456/15836 [1:12:21<05:55,  3.88it/s]\u001b[A\n",
      "Iteration:  91% 14457/15836 [1:12:21<05:41,  4.04it/s]\u001b[A\n",
      "Iteration:  91% 14458/15836 [1:12:21<05:29,  4.18it/s]\u001b[A\n",
      "Iteration:  91% 14459/15836 [1:12:22<05:23,  4.25it/s]\u001b[A\n",
      "Iteration:  91% 14460/15836 [1:12:22<06:14,  3.67it/s]\u001b[A\n",
      "Iteration:  91% 14461/15836 [1:12:22<05:52,  3.90it/s]\u001b[A\n",
      "Iteration:  91% 14462/15836 [1:12:22<05:36,  4.08it/s]\u001b[A\n",
      "Iteration:  91% 14463/15836 [1:12:23<05:29,  4.17it/s]\u001b[A\n",
      "Iteration:  91% 14464/15836 [1:12:23<05:25,  4.22it/s]\u001b[A\n",
      "Iteration:  91% 14465/15836 [1:12:23<06:15,  3.65it/s]\u001b[A\n",
      "Iteration:  91% 14466/15836 [1:12:23<05:50,  3.91it/s]\u001b[A\n",
      "Iteration:  91% 14467/15836 [1:12:24<05:35,  4.08it/s]\u001b[A\n",
      "Iteration:  91% 14468/15836 [1:12:24<05:27,  4.18it/s]\u001b[A\n",
      "Iteration:  91% 14469/15836 [1:12:24<05:22,  4.24it/s]\u001b[A\n",
      "Iteration:  91% 14470/15836 [1:12:24<06:14,  3.64it/s]\u001b[A\n",
      "Iteration:  91% 14471/15836 [1:12:25<05:50,  3.90it/s]\u001b[A\n",
      "Iteration:  91% 14472/15836 [1:12:25<05:35,  4.06it/s]\u001b[A\n",
      "Iteration:  91% 14473/15836 [1:12:25<05:28,  4.16it/s]\u001b[A\n",
      "Iteration:  91% 14474/15836 [1:12:25<05:21,  4.24it/s]\u001b[A\n",
      "Iteration:  91% 14475/15836 [1:12:26<06:11,  3.67it/s]\u001b[A\n",
      "Iteration:  91% 14476/15836 [1:12:26<05:47,  3.91it/s]\u001b[A\n",
      "Iteration:  91% 14477/15836 [1:12:26<05:36,  4.04it/s]\u001b[A\n",
      "Iteration:  91% 14478/15836 [1:12:26<05:25,  4.17it/s]\u001b[A\n",
      "Iteration:  91% 14479/15836 [1:12:27<05:20,  4.23it/s]\u001b[A\n",
      "Iteration:  91% 14480/15836 [1:12:27<06:09,  3.67it/s]\u001b[A\n",
      "Iteration:  91% 14481/15836 [1:12:27<05:48,  3.88it/s]\u001b[A\n",
      "Iteration:  91% 14482/15836 [1:12:27<05:33,  4.06it/s]\u001b[A\n",
      "Iteration:  91% 14483/15836 [1:12:28<05:26,  4.15it/s]\u001b[A\n",
      "Iteration:  91% 14484/15836 [1:12:28<05:19,  4.23it/s]\u001b[A\n",
      "Iteration:  91% 14485/15836 [1:12:28<06:10,  3.65it/s]\u001b[A\n",
      "Iteration:  91% 14486/15836 [1:12:28<05:47,  3.89it/s]\u001b[A\n",
      "Iteration:  91% 14487/15836 [1:12:29<05:32,  4.06it/s]\u001b[A\n",
      "Iteration:  91% 14488/15836 [1:12:29<05:23,  4.16it/s]\u001b[A\n",
      "Iteration:  91% 14489/15836 [1:12:29<05:17,  4.24it/s]\u001b[A\n",
      "Iteration:  92% 14490/15836 [1:12:29<06:07,  3.66it/s]\u001b[A\n",
      "Iteration:  92% 14491/15836 [1:12:30<05:45,  3.89it/s]\u001b[A\n",
      "Iteration:  92% 14492/15836 [1:12:30<05:33,  4.03it/s]\u001b[A\n",
      "Iteration:  92% 14493/15836 [1:12:30<05:23,  4.15it/s]\u001b[A\n",
      "Iteration:  92% 14494/15836 [1:12:30<05:17,  4.22it/s]\u001b[A\n",
      "Iteration:  92% 14495/15836 [1:12:31<06:07,  3.65it/s]\u001b[A\n",
      "Iteration:  92% 14496/15836 [1:12:31<05:45,  3.88it/s]\u001b[A\n",
      "Iteration:  92% 14497/15836 [1:12:31<05:31,  4.04it/s]\u001b[A\n",
      "Iteration:  92% 14498/15836 [1:12:31<05:22,  4.14it/s]\u001b[A\n",
      "Iteration:  92% 14499/15836 [1:12:32<05:15,  4.23it/s]\u001b[A\n",
      "Iteration:  92% 14500/15836 [1:12:32<06:04,  3.67it/s]\u001b[A\n",
      "Iteration:  92% 14501/15836 [1:12:32<05:44,  3.88it/s]\u001b[A\n",
      "Iteration:  92% 14502/15836 [1:12:32<05:30,  4.04it/s]\u001b[A\n",
      "Iteration:  92% 14503/15836 [1:12:33<05:19,  4.17it/s]\u001b[A\n",
      "Iteration:  92% 14504/15836 [1:12:33<05:15,  4.22it/s]\u001b[A\n",
      "Iteration:  92% 14505/15836 [1:12:33<06:04,  3.65it/s]\u001b[A\n",
      "Iteration:  92% 14506/15836 [1:12:33<05:41,  3.90it/s]\u001b[A\n",
      "Iteration:  92% 14507/15836 [1:12:34<05:27,  4.06it/s]\u001b[A\n",
      "Iteration:  92% 14508/15836 [1:12:34<05:19,  4.16it/s]\u001b[A\n",
      "Iteration:  92% 14509/15836 [1:12:34<05:13,  4.24it/s]\u001b[A\n",
      "Iteration:  92% 14510/15836 [1:12:34<06:00,  3.67it/s]\u001b[A\n",
      "Iteration:  92% 14511/15836 [1:12:35<05:38,  3.91it/s]\u001b[A\n",
      "Iteration:  92% 14512/15836 [1:12:35<05:25,  4.07it/s]\u001b[A\n",
      "Iteration:  92% 14513/15836 [1:12:35<05:17,  4.16it/s]\u001b[A\n",
      "Iteration:  92% 14514/15836 [1:12:35<05:11,  4.24it/s]\u001b[A\n",
      "Iteration:  92% 14515/15836 [1:12:36<06:00,  3.66it/s]\u001b[A\n",
      "Iteration:  92% 14516/15836 [1:12:36<05:37,  3.91it/s]\u001b[A\n",
      "Iteration:  92% 14517/15836 [1:12:36<05:24,  4.07it/s]\u001b[A\n",
      "Iteration:  92% 14518/15836 [1:12:36<05:16,  4.16it/s]\u001b[A\n",
      "Iteration:  92% 14519/15836 [1:12:37<05:12,  4.22it/s]\u001b[A\n",
      "Iteration:  92% 14520/15836 [1:12:37<06:02,  3.63it/s]\u001b[A\n",
      "Iteration:  92% 14521/15836 [1:12:37<05:40,  3.86it/s]\u001b[A\n",
      "Iteration:  92% 14522/15836 [1:12:37<05:26,  4.03it/s]\u001b[A\n",
      "Iteration:  92% 14523/15836 [1:12:38<05:16,  4.14it/s]\u001b[A\n",
      "Iteration:  92% 14524/15836 [1:12:38<05:12,  4.20it/s]\u001b[A\n",
      "Iteration:  92% 14525/15836 [1:12:38<06:00,  3.64it/s]\u001b[A\n",
      "Iteration:  92% 14526/15836 [1:12:38<05:37,  3.88it/s]\u001b[A\n",
      "Iteration:  92% 14527/15836 [1:12:39<05:23,  4.05it/s]\u001b[A\n",
      "Iteration:  92% 14528/15836 [1:12:39<05:14,  4.16it/s]\u001b[A\n",
      "Iteration:  92% 14529/15836 [1:12:39<05:08,  4.23it/s]\u001b[A\n",
      "Iteration:  92% 14530/15836 [1:12:39<05:57,  3.65it/s]\u001b[A\n",
      "Iteration:  92% 14531/15836 [1:12:40<05:36,  3.88it/s]\u001b[A\n",
      "Iteration:  92% 14532/15836 [1:12:40<05:21,  4.05it/s]\u001b[A\n",
      "Iteration:  92% 14533/15836 [1:12:40<05:14,  4.15it/s]\u001b[A\n",
      "Iteration:  92% 14534/15836 [1:12:40<05:10,  4.20it/s]\u001b[A\n",
      "Iteration:  92% 14535/15836 [1:12:41<05:56,  3.65it/s]\u001b[A\n",
      "Iteration:  92% 14536/15836 [1:12:41<05:35,  3.88it/s]\u001b[A\n",
      "Iteration:  92% 14537/15836 [1:12:41<05:20,  4.06it/s]\u001b[A\n",
      "Iteration:  92% 14538/15836 [1:12:41<05:11,  4.16it/s]\u001b[A\n",
      "Iteration:  92% 14539/15836 [1:12:42<05:05,  4.25it/s]\u001b[A\n",
      "Iteration:  92% 14540/15836 [1:12:42<05:53,  3.66it/s]\u001b[A\n",
      "Iteration:  92% 14541/15836 [1:12:42<05:33,  3.88it/s]\u001b[A\n",
      "Iteration:  92% 14542/15836 [1:12:42<05:19,  4.05it/s]\u001b[A\n",
      "Iteration:  92% 14543/15836 [1:12:43<05:10,  4.16it/s]\u001b[A\n",
      "Iteration:  92% 14544/15836 [1:12:43<05:06,  4.22it/s]\u001b[A\n",
      "Iteration:  92% 14545/15836 [1:12:43<05:52,  3.66it/s]\u001b[A\n",
      "Iteration:  92% 14546/15836 [1:12:43<05:33,  3.87it/s]\u001b[A\n",
      "Iteration:  92% 14547/15836 [1:12:44<05:18,  4.04it/s]\u001b[A\n",
      "Iteration:  92% 14548/15836 [1:12:44<05:09,  4.16it/s]\u001b[A\n",
      "Iteration:  92% 14549/15836 [1:12:44<05:04,  4.22it/s]\u001b[A\n",
      "Iteration:  92% 14550/15836 [1:12:44<05:51,  3.66it/s]\u001b[A\n",
      "Iteration:  92% 14551/15836 [1:12:45<05:30,  3.89it/s]\u001b[A\n",
      "Iteration:  92% 14552/15836 [1:12:45<05:16,  4.05it/s]\u001b[A\n",
      "Iteration:  92% 14553/15836 [1:12:45<05:08,  4.16it/s]\u001b[A\n",
      "Iteration:  92% 14554/15836 [1:12:45<05:03,  4.23it/s]\u001b[A\n",
      "Iteration:  92% 14555/15836 [1:12:46<05:49,  3.67it/s]\u001b[A\n",
      "Iteration:  92% 14556/15836 [1:12:46<05:28,  3.90it/s]\u001b[A\n",
      "Iteration:  92% 14557/15836 [1:12:46<05:14,  4.07it/s]\u001b[A\n",
      "Iteration:  92% 14558/15836 [1:12:46<05:06,  4.17it/s]\u001b[A\n",
      "Iteration:  92% 14559/15836 [1:12:47<05:00,  4.25it/s]\u001b[A\n",
      "Iteration:  92% 14560/15836 [1:12:47<05:48,  3.66it/s]\u001b[A\n",
      "Iteration:  92% 14561/15836 [1:12:47<05:26,  3.91it/s]\u001b[A\n",
      "Iteration:  92% 14562/15836 [1:12:47<05:12,  4.08it/s]\u001b[A\n",
      "Iteration:  92% 14563/15836 [1:12:48<05:04,  4.19it/s]\u001b[A\n",
      "Iteration:  92% 14564/15836 [1:12:48<04:59,  4.25it/s]\u001b[A\n",
      "Iteration:  92% 14565/15836 [1:12:48<05:45,  3.68it/s]\u001b[A\n",
      "Iteration:  92% 14566/15836 [1:12:48<05:26,  3.89it/s]\u001b[A\n",
      "Iteration:  92% 14567/15836 [1:12:49<05:14,  4.04it/s]\u001b[A\n",
      "Iteration:  92% 14568/15836 [1:12:49<05:05,  4.15it/s]\u001b[A\n",
      "Iteration:  92% 14569/15836 [1:12:49<05:00,  4.22it/s]\u001b[A\n",
      "Iteration:  92% 14570/15836 [1:12:50<05:45,  3.66it/s]\u001b[A\n",
      "Iteration:  92% 14571/15836 [1:12:50<05:26,  3.88it/s]\u001b[A\n",
      "Iteration:  92% 14572/15836 [1:12:50<05:12,  4.05it/s]\u001b[A\n",
      "Iteration:  92% 14573/15836 [1:12:50<05:04,  4.15it/s]\u001b[A\n",
      "Iteration:  92% 14574/15836 [1:12:50<04:58,  4.23it/s]\u001b[A\n",
      "Iteration:  92% 14575/15836 [1:12:51<05:43,  3.67it/s]\u001b[A\n",
      "Iteration:  92% 14576/15836 [1:12:51<05:22,  3.90it/s]\u001b[A\n",
      "Iteration:  92% 14577/15836 [1:12:51<05:09,  4.07it/s]\u001b[A\n",
      "Iteration:  92% 14578/15836 [1:12:51<05:01,  4.17it/s]\u001b[A\n",
      "Iteration:  92% 14579/15836 [1:12:52<04:56,  4.24it/s]\u001b[A\n",
      "Iteration:  92% 14580/15836 [1:12:52<05:44,  3.64it/s]\u001b[A\n",
      "Iteration:  92% 14581/15836 [1:12:52<05:21,  3.90it/s]\u001b[A\n",
      "Iteration:  92% 14582/15836 [1:12:52<05:08,  4.07it/s]\u001b[A\n",
      "Iteration:  92% 14583/15836 [1:12:53<05:02,  4.14it/s]\u001b[A\n",
      "Iteration:  92% 14584/15836 [1:12:53<04:59,  4.18it/s]\u001b[A\n",
      "Iteration:  92% 14585/15836 [1:12:53<05:43,  3.64it/s]\u001b[A\n",
      "Iteration:  92% 14586/15836 [1:12:53<05:21,  3.88it/s]\u001b[A\n",
      "Iteration:  92% 14587/15836 [1:12:54<05:07,  4.06it/s]\u001b[A\n",
      "Iteration:  92% 14588/15836 [1:12:54<05:00,  4.15it/s]\u001b[A\n",
      "Iteration:  92% 14589/15836 [1:12:54<04:57,  4.20it/s]\u001b[A\n",
      "Iteration:  92% 14590/15836 [1:12:55<05:43,  3.63it/s]\u001b[A\n",
      "Iteration:  92% 14591/15836 [1:12:55<05:21,  3.87it/s]\u001b[A\n",
      "Iteration:  92% 14592/15836 [1:12:55<05:08,  4.03it/s]\u001b[A\n",
      "Iteration:  92% 14593/15836 [1:12:55<05:00,  4.14it/s]\u001b[A\n",
      "Iteration:  92% 14594/15836 [1:12:55<04:54,  4.22it/s]\u001b[A\n",
      "Iteration:  92% 14595/15836 [1:12:56<05:39,  3.66it/s]\u001b[A\n",
      "Iteration:  92% 14596/15836 [1:12:56<05:18,  3.89it/s]\u001b[A\n",
      "Iteration:  92% 14597/15836 [1:12:56<05:06,  4.05it/s]\u001b[A\n",
      "Iteration:  92% 14598/15836 [1:12:56<04:57,  4.15it/s]\u001b[A\n",
      "Iteration:  92% 14599/15836 [1:12:57<04:53,  4.22it/s]\u001b[A\n",
      "Iteration:  92% 14600/15836 [1:12:57<05:38,  3.65it/s]\u001b[A\n",
      "Iteration:  92% 14601/15836 [1:12:57<05:18,  3.88it/s]\u001b[A\n",
      "Iteration:  92% 14602/15836 [1:12:57<05:03,  4.06it/s]\u001b[A\n",
      "Iteration:  92% 14603/15836 [1:12:58<04:56,  4.17it/s]\u001b[A\n",
      "Iteration:  92% 14604/15836 [1:12:58<04:50,  4.24it/s]\u001b[A\n",
      "Iteration:  92% 14605/15836 [1:12:58<05:35,  3.67it/s]\u001b[A\n",
      "Iteration:  92% 14606/15836 [1:12:59<05:15,  3.90it/s]\u001b[A\n",
      "Iteration:  92% 14607/15836 [1:12:59<05:03,  4.04it/s]\u001b[A\n",
      "Iteration:  92% 14608/15836 [1:12:59<04:56,  4.14it/s]\u001b[A\n",
      "Iteration:  92% 14609/15836 [1:12:59<04:52,  4.20it/s]\u001b[A\n",
      "Iteration:  92% 14610/15836 [1:13:00<05:35,  3.65it/s]\u001b[A\n",
      "Iteration:  92% 14611/15836 [1:13:00<05:15,  3.88it/s]\u001b[A\n",
      "Iteration:  92% 14612/15836 [1:13:00<05:02,  4.04it/s]\u001b[A\n",
      "Iteration:  92% 14613/15836 [1:13:00<04:54,  4.15it/s]\u001b[A\n",
      "Iteration:  92% 14614/15836 [1:13:00<04:49,  4.21it/s]\u001b[A\n",
      "Iteration:  92% 14615/15836 [1:13:01<05:34,  3.66it/s]\u001b[A\n",
      "Iteration:  92% 14616/15836 [1:13:01<05:13,  3.89it/s]\u001b[A\n",
      "Iteration:  92% 14617/15836 [1:13:01<05:00,  4.05it/s]\u001b[A\n",
      "Iteration:  92% 14618/15836 [1:13:01<04:52,  4.17it/s]\u001b[A\n",
      "Iteration:  92% 14619/15836 [1:13:02<04:47,  4.24it/s]\u001b[A\n",
      "Iteration:  92% 14620/15836 [1:13:02<05:31,  3.66it/s]\u001b[A\n",
      "Iteration:  92% 14621/15836 [1:13:02<05:11,  3.90it/s]\u001b[A\n",
      "Iteration:  92% 14622/15836 [1:13:02<04:59,  4.06it/s]\u001b[A\n",
      "Iteration:  92% 14623/15836 [1:13:03<04:50,  4.17it/s]\u001b[A\n",
      "Iteration:  92% 14624/15836 [1:13:03<04:47,  4.22it/s]\u001b[A\n",
      "Iteration:  92% 14625/15836 [1:13:03<05:31,  3.65it/s]\u001b[A\n",
      "Iteration:  92% 14626/15836 [1:13:04<05:11,  3.89it/s]\u001b[A\n",
      "Iteration:  92% 14627/15836 [1:13:04<04:57,  4.06it/s]\u001b[A\n",
      "Iteration:  92% 14628/15836 [1:13:04<04:51,  4.15it/s]\u001b[A\n",
      "Iteration:  92% 14629/15836 [1:13:04<04:47,  4.20it/s]\u001b[A\n",
      "Iteration:  92% 14630/15836 [1:13:05<05:30,  3.65it/s]\u001b[A\n",
      "Iteration:  92% 14631/15836 [1:13:05<05:10,  3.88it/s]\u001b[A\n",
      "Iteration:  92% 14632/15836 [1:13:05<04:58,  4.03it/s]\u001b[A\n",
      "Iteration:  92% 14633/15836 [1:13:05<04:49,  4.15it/s]\u001b[A\n",
      "Iteration:  92% 14634/15836 [1:13:05<04:45,  4.21it/s]\u001b[A\n",
      "Iteration:  92% 14635/15836 [1:13:06<05:29,  3.64it/s]\u001b[A\n",
      "Iteration:  92% 14636/15836 [1:13:06<05:08,  3.89it/s]\u001b[A\n",
      "Iteration:  92% 14637/15836 [1:13:06<04:56,  4.05it/s]\u001b[A\n",
      "Iteration:  92% 14638/15836 [1:13:06<04:47,  4.17it/s]\u001b[A\n",
      "Iteration:  92% 14639/15836 [1:13:07<04:43,  4.23it/s]\u001b[A\n",
      "Iteration:  92% 14640/15836 [1:13:07<05:26,  3.67it/s]\u001b[A\n",
      "Iteration:  92% 14641/15836 [1:13:07<05:07,  3.88it/s]\u001b[A\n",
      "Iteration:  92% 14642/15836 [1:13:08<04:54,  4.05it/s]\u001b[A\n",
      "Iteration:  92% 14643/15836 [1:13:08<04:48,  4.14it/s]\u001b[A\n",
      "Iteration:  92% 14644/15836 [1:13:08<04:42,  4.22it/s]\u001b[A\n",
      "Iteration:  92% 14645/15836 [1:13:08<05:24,  3.67it/s]\u001b[A\n",
      "Iteration:  92% 14646/15836 [1:13:09<05:06,  3.89it/s]\u001b[A\n",
      "Iteration:  92% 14647/15836 [1:13:09<04:54,  4.03it/s]\u001b[A\n",
      "Iteration:  92% 14648/15836 [1:13:09<04:44,  4.18it/s]\u001b[A\n",
      "Iteration:  93% 14649/15836 [1:13:09<04:40,  4.24it/s]\u001b[A\n",
      "Iteration:  93% 14650/15836 [1:13:10<05:22,  3.67it/s]\u001b[A\n",
      "Iteration:  93% 14651/15836 [1:13:10<05:03,  3.90it/s]\u001b[A\n",
      "Iteration:  93% 14652/15836 [1:13:10<04:50,  4.08it/s]\u001b[A\n",
      "Iteration:  93% 14653/15836 [1:13:10<04:41,  4.21it/s]\u001b[A\n",
      "Iteration:  93% 14654/15836 [1:13:10<04:36,  4.28it/s]\u001b[A\n",
      "Iteration:  93% 14655/15836 [1:13:11<05:21,  3.68it/s]\u001b[A\n",
      "Iteration:  93% 14656/15836 [1:13:11<05:02,  3.90it/s]\u001b[A\n",
      "Iteration:  93% 14657/15836 [1:13:11<04:49,  4.07it/s]\u001b[A\n",
      "Iteration:  93% 14658/15836 [1:13:11<04:42,  4.17it/s]\u001b[A\n",
      "Iteration:  93% 14659/15836 [1:13:12<04:37,  4.25it/s]\u001b[A\n",
      "Iteration:  93% 14660/15836 [1:13:12<05:21,  3.66it/s]\u001b[A\n",
      "Iteration:  93% 14661/15836 [1:13:12<05:01,  3.89it/s]\u001b[A\n",
      "Iteration:  93% 14662/15836 [1:13:13<04:49,  4.05it/s]\u001b[A\n",
      "Iteration:  93% 14663/15836 [1:13:13<04:42,  4.15it/s]\u001b[A\n",
      "Iteration:  93% 14664/15836 [1:13:13<04:37,  4.23it/s]\u001b[A\n",
      "Iteration:  93% 14665/15836 [1:13:13<05:19,  3.67it/s]\u001b[A\n",
      "Iteration:  93% 14666/15836 [1:13:14<05:00,  3.89it/s]\u001b[A\n",
      "Iteration:  93% 14667/15836 [1:13:14<04:48,  4.05it/s]\u001b[A\n",
      "Iteration:  93% 14668/15836 [1:13:14<04:40,  4.17it/s]\u001b[A\n",
      "Iteration:  93% 14669/15836 [1:13:14<04:34,  4.25it/s]\u001b[A\n",
      "Iteration:  93% 14670/15836 [1:13:15<05:17,  3.67it/s]\u001b[A\n",
      "Iteration:  93% 14671/15836 [1:13:15<04:59,  3.89it/s]\u001b[A\n",
      "Iteration:  93% 14672/15836 [1:13:15<04:47,  4.05it/s]\u001b[A\n",
      "Iteration:  93% 14673/15836 [1:13:15<04:39,  4.15it/s]\u001b[A\n",
      "Iteration:  93% 14674/15836 [1:13:15<04:36,  4.21it/s]\u001b[A\n",
      "Iteration:  93% 14675/15836 [1:13:16<05:18,  3.65it/s]\u001b[A\n",
      "Iteration:  93% 14676/15836 [1:13:16<04:58,  3.88it/s]\u001b[A\n",
      "Iteration:  93% 14677/15836 [1:13:16<04:46,  4.05it/s]\u001b[A\n",
      "Iteration:  93% 14678/15836 [1:13:17<04:39,  4.15it/s]\u001b[A\n",
      "Iteration:  93% 14679/15836 [1:13:17<04:33,  4.23it/s]\u001b[A\n",
      "Iteration:  93% 14680/15836 [1:13:17<05:15,  3.67it/s]\u001b[A\n",
      "Iteration:  93% 14681/15836 [1:13:17<04:56,  3.90it/s]\u001b[A\n",
      "Iteration:  93% 14682/15836 [1:13:18<04:45,  4.05it/s]\u001b[A\n",
      "Iteration:  93% 14683/15836 [1:13:18<04:38,  4.15it/s]\u001b[A\n",
      "Iteration:  93% 14684/15836 [1:13:18<04:33,  4.22it/s]\u001b[A\n",
      "Iteration:  93% 14685/15836 [1:13:18<05:15,  3.65it/s]\u001b[A\n",
      "Iteration:  93% 14686/15836 [1:13:19<04:56,  3.88it/s]\u001b[A\n",
      "Iteration:  93% 14687/15836 [1:13:19<04:43,  4.05it/s]\u001b[A\n",
      "Iteration:  93% 14688/15836 [1:13:19<04:36,  4.15it/s]\u001b[A\n",
      "Iteration:  93% 14689/15836 [1:13:19<04:31,  4.23it/s]\u001b[A\n",
      "Iteration:  93% 14690/15836 [1:13:20<05:11,  3.67it/s]\u001b[A\n",
      "Iteration:  93% 14691/15836 [1:13:20<04:52,  3.91it/s]\u001b[A\n",
      "Iteration:  93% 14692/15836 [1:13:20<04:42,  4.04it/s]\u001b[A\n",
      "Iteration:  93% 14693/15836 [1:13:20<04:35,  4.15it/s]\u001b[A\n",
      "Iteration:  93% 14694/15836 [1:13:21<04:30,  4.23it/s]\u001b[A\n",
      "Iteration:  93% 14695/15836 [1:13:21<05:11,  3.66it/s]\u001b[A\n",
      "Iteration:  93% 14696/15836 [1:13:21<04:54,  3.87it/s]\u001b[A\n",
      "Iteration:  93% 14697/15836 [1:13:21<04:43,  4.02it/s]\u001b[A\n",
      "Iteration:  93% 14698/15836 [1:13:22<04:33,  4.16it/s]\u001b[A\n",
      "Iteration:  93% 14699/15836 [1:13:22<04:28,  4.24it/s]\u001b[A\n",
      "Iteration:  93% 14700/15836 [1:13:22<05:09,  3.67it/s]\u001b[A\n",
      "Iteration:  93% 14701/15836 [1:13:22<04:51,  3.89it/s]\u001b[A\n",
      "Iteration:  93% 14702/15836 [1:13:23<04:39,  4.05it/s]\u001b[A\n",
      "Iteration:  93% 14703/15836 [1:13:23<04:33,  4.14it/s]\u001b[A\n",
      "Iteration:  93% 14704/15836 [1:13:23<04:28,  4.22it/s]\u001b[A\n",
      "Iteration:  93% 14705/15836 [1:13:23<05:08,  3.66it/s]\u001b[A\n",
      "Iteration:  93% 14706/15836 [1:13:24<04:50,  3.88it/s]\u001b[A\n",
      "Iteration:  93% 14707/15836 [1:13:24<04:39,  4.04it/s]\u001b[A\n",
      "Iteration:  93% 14708/15836 [1:13:24<04:30,  4.17it/s]\u001b[A\n",
      "Iteration:  93% 14709/15836 [1:13:24<04:26,  4.23it/s]\u001b[A\n",
      "Iteration:  93% 14710/15836 [1:13:25<05:08,  3.65it/s]\u001b[A\n",
      "Iteration:  93% 14711/15836 [1:13:25<04:49,  3.88it/s]\u001b[A\n",
      "Iteration:  93% 14712/15836 [1:13:25<04:38,  4.04it/s]\u001b[A\n",
      "Iteration:  93% 14713/15836 [1:13:25<04:30,  4.16it/s]\u001b[A\n",
      "Iteration:  93% 14714/15836 [1:13:26<04:25,  4.22it/s]\u001b[A\n",
      "Iteration:  93% 14715/15836 [1:13:26<05:06,  3.65it/s]\u001b[A\n",
      "Iteration:  93% 14716/15836 [1:13:26<04:48,  3.88it/s]\u001b[A\n",
      "Iteration:  93% 14717/15836 [1:13:26<04:36,  4.05it/s]\u001b[A\n",
      "Iteration:  93% 14718/15836 [1:13:27<04:27,  4.19it/s]\u001b[A\n",
      "Iteration:  93% 14719/15836 [1:13:27<04:21,  4.27it/s]\u001b[A\n",
      "Iteration:  93% 14720/15836 [1:13:27<05:04,  3.67it/s]\u001b[A\n",
      "Iteration:  93% 14721/15836 [1:13:27<04:45,  3.91it/s]\u001b[A\n",
      "Iteration:  93% 14722/15836 [1:13:28<04:33,  4.08it/s]\u001b[A\n",
      "Iteration:  93% 14723/15836 [1:13:28<04:27,  4.16it/s]\u001b[A\n",
      "Iteration:  93% 14724/15836 [1:13:28<04:23,  4.22it/s]\u001b[A\n",
      "Iteration:  93% 14725/15836 [1:13:28<05:04,  3.65it/s]\u001b[A\n",
      "Iteration:  93% 14726/15836 [1:13:29<04:44,  3.91it/s]\u001b[A\n",
      "Iteration:  93% 14727/15836 [1:13:29<04:31,  4.09it/s]\u001b[A\n",
      "Iteration:  93% 14728/15836 [1:13:29<04:23,  4.20it/s]\u001b[A\n",
      "Iteration:  93% 14729/15836 [1:13:29<04:19,  4.26it/s]\u001b[A\n",
      "Iteration:  93% 14730/15836 [1:13:30<05:00,  3.68it/s]\u001b[A\n",
      "Iteration:  93% 14731/15836 [1:13:30<04:42,  3.92it/s]\u001b[A\n",
      "Iteration:  93% 14732/15836 [1:13:30<04:32,  4.05it/s]\u001b[A\n",
      "Iteration:  93% 14733/15836 [1:13:30<04:24,  4.16it/s]\u001b[A\n",
      "Iteration:  93% 14734/15836 [1:13:31<04:20,  4.23it/s]\u001b[A\n",
      "Iteration:  93% 14735/15836 [1:13:31<05:01,  3.65it/s]\u001b[A\n",
      "Iteration:  93% 14736/15836 [1:13:31<04:43,  3.89it/s]\u001b[A\n",
      "Iteration:  93% 14737/15836 [1:13:31<04:31,  4.04it/s]\u001b[A\n",
      "Iteration:  93% 14738/15836 [1:13:32<04:24,  4.16it/s]\u001b[A\n",
      "Iteration:  93% 14739/15836 [1:13:32<04:19,  4.23it/s]\u001b[A\n",
      "Iteration:  93% 14740/15836 [1:13:32<04:58,  3.68it/s]\u001b[A\n",
      "Iteration:  93% 14741/15836 [1:13:32<04:41,  3.89it/s]\u001b[A\n",
      "Iteration:  93% 14742/15836 [1:13:33<04:29,  4.06it/s]\u001b[A\n",
      "Iteration:  93% 14743/15836 [1:13:33<04:23,  4.15it/s]\u001b[A\n",
      "Iteration:  93% 14744/15836 [1:13:33<04:19,  4.22it/s]\u001b[A\n",
      "Iteration:  93% 14745/15836 [1:13:33<04:57,  3.67it/s]\u001b[A\n",
      "Iteration:  93% 14746/15836 [1:13:34<04:40,  3.88it/s]\u001b[A\n",
      "Iteration:  93% 14747/15836 [1:13:34<04:29,  4.04it/s]\u001b[A\n",
      "Iteration:  93% 14748/15836 [1:13:34<04:22,  4.15it/s]\u001b[A\n",
      "Iteration:  93% 14749/15836 [1:13:34<04:17,  4.22it/s]\u001b[A\n",
      "Iteration:  93% 14750/15836 [1:13:35<04:58,  3.64it/s]\u001b[A\n",
      "Iteration:  93% 14751/15836 [1:13:35<04:40,  3.87it/s]\u001b[A\n",
      "Iteration:  93% 14752/15836 [1:13:35<04:28,  4.03it/s]\u001b[A\n",
      "Iteration:  93% 14753/15836 [1:13:35<04:20,  4.15it/s]\u001b[A\n",
      "Iteration:  93% 14754/15836 [1:13:36<04:16,  4.23it/s]\u001b[A\n",
      "Iteration:  93% 14755/15836 [1:13:36<04:55,  3.66it/s]\u001b[A\n",
      "Iteration:  93% 14756/15836 [1:13:36<04:37,  3.89it/s]\u001b[A\n",
      "Iteration:  93% 14757/15836 [1:13:36<04:26,  4.05it/s]\u001b[A\n",
      "Iteration:  93% 14758/15836 [1:13:37<04:18,  4.16it/s]\u001b[A\n",
      "Iteration:  93% 14759/15836 [1:13:37<04:14,  4.23it/s]\u001b[A\n",
      "Iteration:  93% 14760/15836 [1:13:37<04:53,  3.67it/s]\u001b[A\n",
      "Iteration:  93% 14761/15836 [1:13:37<04:37,  3.88it/s]\u001b[A\n",
      "Iteration:  93% 14762/15836 [1:13:38<04:25,  4.05it/s]\u001b[A\n",
      "Iteration:  93% 14763/15836 [1:13:38<04:19,  4.14it/s]\u001b[A\n",
      "Iteration:  93% 14764/15836 [1:13:38<04:14,  4.22it/s]\u001b[A\n",
      "Iteration:  93% 14765/15836 [1:13:38<04:52,  3.66it/s]\u001b[A\n",
      "Iteration:  93% 14766/15836 [1:13:39<04:35,  3.88it/s]\u001b[A\n",
      "Iteration:  93% 14767/15836 [1:13:39<04:23,  4.05it/s]\u001b[A\n",
      "Iteration:  93% 14768/15836 [1:13:39<04:16,  4.16it/s]\u001b[A\n",
      "Iteration:  93% 14769/15836 [1:13:39<04:12,  4.23it/s]\u001b[A\n",
      "Iteration:  93% 14770/15836 [1:13:40<04:52,  3.65it/s]\u001b[A\n",
      "Iteration:  93% 14771/15836 [1:13:40<04:33,  3.89it/s]\u001b[A\n",
      "Iteration:  93% 14772/15836 [1:13:40<04:23,  4.04it/s]\u001b[A\n",
      "Iteration:  93% 14773/15836 [1:13:40<04:15,  4.17it/s]\u001b[A\n",
      "Iteration:  93% 14774/15836 [1:13:41<04:11,  4.22it/s]\u001b[A\n",
      "Iteration:  93% 14775/15836 [1:13:41<04:49,  3.66it/s]\u001b[A\n",
      "Iteration:  93% 14776/15836 [1:13:41<04:32,  3.89it/s]\u001b[A\n",
      "Iteration:  93% 14777/15836 [1:13:41<04:22,  4.03it/s]\u001b[A\n",
      "Iteration:  93% 14778/15836 [1:13:42<04:15,  4.14it/s]\u001b[A\n",
      "Iteration:  93% 14779/15836 [1:13:42<04:10,  4.22it/s]\u001b[A\n",
      "Iteration:  93% 14780/15836 [1:13:42<04:49,  3.65it/s]\u001b[A\n",
      "Iteration:  93% 14781/15836 [1:13:42<04:31,  3.88it/s]\u001b[A\n",
      "Iteration:  93% 14782/15836 [1:13:43<04:20,  4.04it/s]\u001b[A\n",
      "Iteration:  93% 14783/15836 [1:13:43<04:13,  4.16it/s]\u001b[A\n",
      "Iteration:  93% 14784/15836 [1:13:43<04:08,  4.23it/s]\u001b[A\n",
      "Iteration:  93% 14785/15836 [1:13:43<04:47,  3.66it/s]\u001b[A\n",
      "Iteration:  93% 14786/15836 [1:13:44<04:29,  3.89it/s]\u001b[A\n",
      "Iteration:  93% 14787/15836 [1:13:44<04:18,  4.05it/s]\u001b[A\n",
      "Iteration:  93% 14788/15836 [1:13:44<04:12,  4.15it/s]\u001b[A\n",
      "Iteration:  93% 14789/15836 [1:13:44<04:08,  4.21it/s]\u001b[A\n",
      "Iteration:  93% 14790/15836 [1:13:45<04:46,  3.65it/s]\u001b[A\n",
      "Iteration:  93% 14791/15836 [1:13:45<04:27,  3.90it/s]\u001b[A\n",
      "Iteration:  93% 14792/15836 [1:13:45<04:17,  4.05it/s]\u001b[A\n",
      "Iteration:  93% 14793/15836 [1:13:45<04:11,  4.15it/s]\u001b[A\n",
      "Iteration:  93% 14794/15836 [1:13:46<04:06,  4.22it/s]\u001b[A\n",
      "Iteration:  93% 14795/15836 [1:13:46<04:46,  3.64it/s]\u001b[A\n",
      "Iteration:  93% 14796/15836 [1:13:46<04:27,  3.89it/s]\u001b[A\n",
      "Iteration:  93% 14797/15836 [1:13:46<04:16,  4.05it/s]\u001b[A\n",
      "Iteration:  93% 14798/15836 [1:13:47<04:09,  4.16it/s]\u001b[A\n",
      "Iteration:  93% 14799/15836 [1:13:47<04:05,  4.22it/s]\u001b[A\n",
      "Iteration:  93% 14800/15836 [1:13:47<05:05,  3.39it/s]\u001b[A\n",
      "Iteration:  93% 14801/15836 [1:13:48<04:47,  3.60it/s]\u001b[A\n",
      "Iteration:  93% 14802/15836 [1:13:48<04:32,  3.80it/s]\u001b[A\n",
      "Iteration:  93% 14803/15836 [1:13:48<04:21,  3.94it/s]\u001b[A\n",
      "Iteration:  93% 14804/15836 [1:13:48<04:25,  3.88it/s]\u001b[A\n",
      "Iteration:  93% 14805/15836 [1:13:49<05:13,  3.29it/s]\u001b[A\n",
      "Iteration:  93% 14806/15836 [1:13:49<04:57,  3.46it/s]\u001b[A\n",
      "Iteration:  94% 14807/15836 [1:13:49<04:54,  3.49it/s]\u001b[A\n",
      "Iteration:  94% 14808/15836 [1:13:49<04:39,  3.67it/s]\u001b[A\n",
      "Iteration:  94% 14809/15836 [1:13:50<04:27,  3.84it/s]\u001b[A\n",
      "Iteration:  94% 14810/15836 [1:13:50<05:00,  3.41it/s]\u001b[A\n",
      "Iteration:  94% 14811/15836 [1:13:50<04:36,  3.71it/s]\u001b[A\n",
      "Iteration:  94% 14812/15836 [1:13:50<04:19,  3.95it/s]\u001b[A\n",
      "Iteration:  94% 14813/15836 [1:13:51<04:10,  4.09it/s]\u001b[A\n",
      "Iteration:  94% 14814/15836 [1:13:51<04:06,  4.14it/s]\u001b[A\n",
      "Iteration:  94% 14815/15836 [1:13:51<04:44,  3.58it/s]\u001b[A\n",
      "Iteration:  94% 14816/15836 [1:13:52<04:24,  3.85it/s]\u001b[A\n",
      "Iteration:  94% 14817/15836 [1:13:52<04:11,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14818/15836 [1:13:52<04:06,  4.13it/s]\u001b[A\n",
      "Iteration:  94% 14819/15836 [1:13:52<04:01,  4.21it/s]\u001b[A\n",
      "Iteration:  94% 14820/15836 [1:13:53<04:40,  3.63it/s]\u001b[A\n",
      "Iteration:  94% 14821/15836 [1:13:53<04:20,  3.90it/s]\u001b[A\n",
      "Iteration:  94% 14822/15836 [1:13:53<04:10,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14823/15836 [1:13:53<04:03,  4.17it/s]\u001b[A\n",
      "Iteration:  94% 14824/15836 [1:13:53<03:59,  4.22it/s]\u001b[A\n",
      "Iteration:  94% 14825/15836 [1:13:54<04:35,  3.67it/s]\u001b[A\n",
      "Iteration:  94% 14826/15836 [1:13:54<04:18,  3.91it/s]\u001b[A\n",
      "Iteration:  94% 14827/15836 [1:13:54<04:08,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14828/15836 [1:13:54<04:02,  4.15it/s]\u001b[A\n",
      "Iteration:  94% 14829/15836 [1:13:55<03:57,  4.23it/s]\u001b[A\n",
      "Iteration:  94% 14830/15836 [1:13:55<04:35,  3.65it/s]\u001b[A\n",
      "Iteration:  94% 14831/15836 [1:13:55<04:18,  3.89it/s]\u001b[A\n",
      "Iteration:  94% 14832/15836 [1:13:55<04:07,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14833/15836 [1:13:56<04:01,  4.15it/s]\u001b[A\n",
      "Iteration:  94% 14834/15836 [1:13:56<03:57,  4.21it/s]\u001b[A\n",
      "Iteration:  94% 14835/15836 [1:13:56<04:33,  3.65it/s]\u001b[A\n",
      "Iteration:  94% 14836/15836 [1:13:57<04:17,  3.88it/s]\u001b[A\n",
      "Iteration:  94% 14837/15836 [1:13:57<04:06,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14838/15836 [1:13:57<03:59,  4.16it/s]\u001b[A\n",
      "Iteration:  94% 14839/15836 [1:13:57<03:56,  4.22it/s]\u001b[A\n",
      "Iteration:  94% 14840/15836 [1:13:58<04:33,  3.64it/s]\u001b[A\n",
      "Iteration:  94% 14841/15836 [1:13:58<04:16,  3.88it/s]\u001b[A\n",
      "Iteration:  94% 14842/15836 [1:13:58<04:05,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14843/15836 [1:13:58<03:58,  4.16it/s]\u001b[A\n",
      "Iteration:  94% 14844/15836 [1:13:58<03:54,  4.23it/s]\u001b[A\n",
      "Iteration:  94% 14845/15836 [1:13:59<04:30,  3.67it/s]\u001b[A\n",
      "Iteration:  94% 14846/15836 [1:13:59<04:14,  3.89it/s]\u001b[A\n",
      "Iteration:  94% 14847/15836 [1:13:59<04:04,  4.04it/s]\u001b[A\n",
      "Iteration:  94% 14848/15836 [1:13:59<03:58,  4.14it/s]\u001b[A\n",
      "Iteration:  94% 14849/15836 [1:14:00<03:53,  4.23it/s]\u001b[A\n",
      "Iteration:  94% 14850/15836 [1:14:00<04:28,  3.67it/s]\u001b[A\n",
      "Iteration:  94% 14851/15836 [1:14:00<04:12,  3.90it/s]\u001b[A\n",
      "Iteration:  94% 14852/15836 [1:14:01<04:02,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14853/15836 [1:14:01<03:55,  4.18it/s]\u001b[A\n",
      "Iteration:  94% 14854/15836 [1:14:01<03:50,  4.26it/s]\u001b[A\n",
      "Iteration:  94% 14855/15836 [1:14:01<04:28,  3.66it/s]\u001b[A\n",
      "Iteration:  94% 14856/15836 [1:14:02<04:11,  3.90it/s]\u001b[A\n",
      "Iteration:  94% 14857/15836 [1:14:02<04:00,  4.08it/s]\u001b[A\n",
      "Iteration:  94% 14858/15836 [1:14:02<03:53,  4.20it/s]\u001b[A\n",
      "Iteration:  94% 14859/15836 [1:14:02<03:49,  4.26it/s]\u001b[A\n",
      "Iteration:  94% 14860/15836 [1:14:03<04:25,  3.68it/s]\u001b[A\n",
      "Iteration:  94% 14861/15836 [1:14:03<04:09,  3.91it/s]\u001b[A\n",
      "Iteration:  94% 14862/15836 [1:14:03<04:00,  4.06it/s]\u001b[A\n",
      "Iteration:  94% 14863/15836 [1:14:03<03:54,  4.15it/s]\u001b[A\n",
      "Iteration:  94% 14864/15836 [1:14:03<03:49,  4.23it/s]\u001b[A\n",
      "Iteration:  94% 14865/15836 [1:14:04<04:24,  3.67it/s]\u001b[A\n",
      "Iteration:  94% 14866/15836 [1:14:04<04:09,  3.90it/s]\u001b[A\n",
      "Iteration:  94% 14867/15836 [1:14:04<03:59,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14868/15836 [1:14:04<03:53,  4.15it/s]\u001b[A\n",
      "Iteration:  94% 14869/15836 [1:14:05<03:48,  4.23it/s]\u001b[A\n",
      "Iteration:  94% 14870/15836 [1:14:05<04:24,  3.65it/s]\u001b[A\n",
      "Iteration:  94% 14871/15836 [1:14:05<04:09,  3.87it/s]\u001b[A\n",
      "Iteration:  94% 14872/15836 [1:14:06<03:57,  4.06it/s]\u001b[A\n",
      "Iteration:  94% 14873/15836 [1:14:06<03:51,  4.15it/s]\u001b[A\n",
      "Iteration:  94% 14874/15836 [1:14:06<03:47,  4.23it/s]\u001b[A\n",
      "Iteration:  94% 14875/15836 [1:14:06<04:21,  3.67it/s]\u001b[A\n",
      "Iteration:  94% 14876/15836 [1:14:07<04:06,  3.90it/s]\u001b[A\n",
      "Iteration:  94% 14877/15836 [1:14:07<03:57,  4.03it/s]\u001b[A\n",
      "Iteration:  94% 14878/15836 [1:14:07<03:51,  4.13it/s]\u001b[A\n",
      "Iteration:  94% 14879/15836 [1:14:07<03:46,  4.23it/s]\u001b[A\n",
      "Iteration:  94% 14880/15836 [1:14:08<04:21,  3.66it/s]\u001b[A\n",
      "Iteration:  94% 14881/15836 [1:14:08<04:05,  3.89it/s]\u001b[A\n",
      "Iteration:  94% 14882/15836 [1:14:08<03:56,  4.04it/s]\u001b[A\n",
      "Iteration:  94% 14883/15836 [1:14:08<03:50,  4.14it/s]\u001b[A\n",
      "Iteration:  94% 14884/15836 [1:14:08<03:45,  4.22it/s]\u001b[A\n",
      "Iteration:  94% 14885/15836 [1:14:09<04:19,  3.66it/s]\u001b[A\n",
      "Iteration:  94% 14886/15836 [1:14:09<04:04,  3.89it/s]\u001b[A\n",
      "Iteration:  94% 14887/15836 [1:14:09<03:54,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14888/15836 [1:14:10<03:48,  4.15it/s]\u001b[A\n",
      "Iteration:  94% 14889/15836 [1:14:10<03:43,  4.24it/s]\u001b[A\n",
      "Iteration:  94% 14890/15836 [1:14:10<04:18,  3.67it/s]\u001b[A\n",
      "Iteration:  94% 14891/15836 [1:14:10<04:03,  3.89it/s]\u001b[A\n",
      "Iteration:  94% 14892/15836 [1:14:11<03:54,  4.03it/s]\u001b[A\n",
      "Iteration:  94% 14893/15836 [1:14:11<03:47,  4.15it/s]\u001b[A\n",
      "Iteration:  94% 14894/15836 [1:14:11<03:43,  4.21it/s]\u001b[A\n",
      "Iteration:  94% 14895/15836 [1:14:11<04:17,  3.66it/s]\u001b[A\n",
      "Iteration:  94% 14896/15836 [1:14:12<04:02,  3.87it/s]\u001b[A\n",
      "Iteration:  94% 14897/15836 [1:14:12<03:52,  4.04it/s]\u001b[A\n",
      "Iteration:  94% 14898/15836 [1:14:12<03:45,  4.16it/s]\u001b[A\n",
      "Iteration:  94% 14899/15836 [1:14:12<03:42,  4.22it/s]\u001b[A\n",
      "Iteration:  94% 14900/15836 [1:14:13<04:16,  3.65it/s]\u001b[A\n",
      "Iteration:  94% 14901/15836 [1:14:13<03:59,  3.90it/s]\u001b[A\n",
      "Iteration:  94% 14902/15836 [1:14:13<03:50,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14903/15836 [1:14:13<03:44,  4.15it/s]\u001b[A\n",
      "Iteration:  94% 14904/15836 [1:14:13<03:40,  4.23it/s]\u001b[A\n",
      "Iteration:  94% 14905/15836 [1:14:14<04:14,  3.66it/s]\u001b[A\n",
      "Iteration:  94% 14906/15836 [1:14:14<03:59,  3.89it/s]\u001b[A\n",
      "Iteration:  94% 14907/15836 [1:14:14<03:49,  4.04it/s]\u001b[A\n",
      "Iteration:  94% 14908/15836 [1:14:15<03:43,  4.15it/s]\u001b[A\n",
      "Iteration:  94% 14909/15836 [1:14:15<03:40,  4.20it/s]\u001b[A\n",
      "Iteration:  94% 14910/15836 [1:14:15<04:13,  3.65it/s]\u001b[A\n",
      "Iteration:  94% 14911/15836 [1:14:15<03:57,  3.89it/s]\u001b[A\n",
      "Iteration:  94% 14912/15836 [1:14:16<03:48,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14913/15836 [1:14:16<03:42,  4.16it/s]\u001b[A\n",
      "Iteration:  94% 14914/15836 [1:14:16<03:38,  4.23it/s]\u001b[A\n",
      "Iteration:  94% 14915/15836 [1:14:16<04:11,  3.66it/s]\u001b[A\n",
      "Iteration:  94% 14916/15836 [1:14:17<03:56,  3.88it/s]\u001b[A\n",
      "Iteration:  94% 14917/15836 [1:14:17<03:46,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14918/15836 [1:14:17<03:40,  4.16it/s]\u001b[A\n",
      "Iteration:  94% 14919/15836 [1:14:17<03:37,  4.22it/s]\u001b[A\n",
      "Iteration:  94% 14920/15836 [1:14:18<04:10,  3.66it/s]\u001b[A\n",
      "Iteration:  94% 14921/15836 [1:14:18<03:56,  3.87it/s]\u001b[A\n",
      "Iteration:  94% 14922/15836 [1:14:18<03:45,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14923/15836 [1:14:18<03:40,  4.15it/s]\u001b[A\n",
      "Iteration:  94% 14924/15836 [1:14:19<03:36,  4.22it/s]\u001b[A\n",
      "Iteration:  94% 14925/15836 [1:14:19<04:10,  3.64it/s]\u001b[A\n",
      "Iteration:  94% 14926/15836 [1:14:19<03:54,  3.88it/s]\u001b[A\n",
      "Iteration:  94% 14927/15836 [1:14:19<03:44,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14928/15836 [1:14:20<03:39,  4.15it/s]\u001b[A\n",
      "Iteration:  94% 14929/15836 [1:14:20<03:35,  4.21it/s]\u001b[A\n",
      "Iteration:  94% 14930/15836 [1:14:20<04:07,  3.66it/s]\u001b[A\n",
      "Iteration:  94% 14931/15836 [1:14:20<03:52,  3.90it/s]\u001b[A\n",
      "Iteration:  94% 14932/15836 [1:14:21<03:43,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14933/15836 [1:14:21<03:36,  4.16it/s]\u001b[A\n",
      "Iteration:  94% 14934/15836 [1:14:21<03:33,  4.23it/s]\u001b[A\n",
      "Iteration:  94% 14935/15836 [1:14:21<04:05,  3.67it/s]\u001b[A\n",
      "Iteration:  94% 14936/15836 [1:14:22<03:51,  3.89it/s]\u001b[A\n",
      "Iteration:  94% 14937/15836 [1:14:22<03:42,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14938/15836 [1:14:22<03:36,  4.15it/s]\u001b[A\n",
      "Iteration:  94% 14939/15836 [1:14:22<03:32,  4.23it/s]\u001b[A\n",
      "Iteration:  94% 14940/15836 [1:14:23<04:04,  3.67it/s]\u001b[A\n",
      "Iteration:  94% 14941/15836 [1:14:23<03:50,  3.88it/s]\u001b[A\n",
      "Iteration:  94% 14942/15836 [1:14:23<03:40,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14943/15836 [1:14:23<03:34,  4.16it/s]\u001b[A\n",
      "Iteration:  94% 14944/15836 [1:14:24<03:30,  4.24it/s]\u001b[A\n",
      "Iteration:  94% 14945/15836 [1:14:24<04:04,  3.65it/s]\u001b[A\n",
      "Iteration:  94% 14946/15836 [1:14:24<03:49,  3.87it/s]\u001b[A\n",
      "Iteration:  94% 14947/15836 [1:14:24<03:39,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14948/15836 [1:14:25<03:34,  4.14it/s]\u001b[A\n",
      "Iteration:  94% 14949/15836 [1:14:25<03:30,  4.21it/s]\u001b[A\n",
      "Iteration:  94% 14950/15836 [1:14:25<04:03,  3.64it/s]\u001b[A\n",
      "Iteration:  94% 14951/15836 [1:14:25<03:47,  3.89it/s]\u001b[A\n",
      "Iteration:  94% 14952/15836 [1:14:26<03:38,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14953/15836 [1:14:26<03:32,  4.16it/s]\u001b[A\n",
      "Iteration:  94% 14954/15836 [1:14:26<03:28,  4.23it/s]\u001b[A\n",
      "Iteration:  94% 14955/15836 [1:14:26<03:59,  3.67it/s]\u001b[A\n",
      "Iteration:  94% 14956/15836 [1:14:27<03:45,  3.90it/s]\u001b[A\n",
      "Iteration:  94% 14957/15836 [1:14:27<03:37,  4.05it/s]\u001b[A\n",
      "Iteration:  94% 14958/15836 [1:14:27<03:31,  4.15it/s]\u001b[A\n",
      "Iteration:  94% 14959/15836 [1:14:27<03:28,  4.21it/s]\u001b[A\n",
      "Iteration:  94% 14960/15836 [1:14:28<04:00,  3.64it/s]\u001b[A\n",
      "Iteration:  94% 14961/15836 [1:14:28<03:44,  3.90it/s]\u001b[A\n",
      "Iteration:  94% 14962/15836 [1:14:28<03:36,  4.04it/s]\u001b[A\n",
      "Iteration:  94% 14963/15836 [1:14:28<03:29,  4.17it/s]\u001b[A\n",
      "Iteration:  94% 14964/15836 [1:14:29<03:25,  4.24it/s]\u001b[A\n",
      "Iteration:  94% 14965/15836 [1:14:29<03:57,  3.67it/s]\u001b[A\n",
      "Iteration:  95% 14966/15836 [1:14:29<03:43,  3.89it/s]\u001b[A\n",
      "Iteration:  95% 14967/15836 [1:14:29<03:33,  4.06it/s]\u001b[A\n",
      "Iteration:  95% 14968/15836 [1:14:30<03:28,  4.15it/s]\u001b[A\n",
      "Iteration:  95% 14969/15836 [1:14:30<03:25,  4.23it/s]\u001b[A\n",
      "Iteration:  95% 14970/15836 [1:14:30<03:55,  3.67it/s]\u001b[A\n",
      "Iteration:  95% 14971/15836 [1:14:30<03:42,  3.89it/s]\u001b[A\n",
      "Iteration:  95% 14972/15836 [1:14:31<03:34,  4.03it/s]\u001b[A\n",
      "Iteration:  95% 14973/15836 [1:14:31<03:27,  4.17it/s]\u001b[A\n",
      "Iteration:  95% 14974/15836 [1:14:31<03:24,  4.22it/s]\u001b[A\n",
      "Iteration:  95% 14975/15836 [1:14:31<03:55,  3.66it/s]\u001b[A\n",
      "Iteration:  95% 14976/15836 [1:14:32<03:41,  3.88it/s]\u001b[A\n",
      "Iteration:  95% 14977/15836 [1:14:32<03:31,  4.05it/s]\u001b[A\n",
      "Iteration:  95% 14978/15836 [1:14:32<03:27,  4.14it/s]\u001b[A\n",
      "Iteration:  95% 14979/15836 [1:14:32<03:23,  4.22it/s]\u001b[A\n",
      "Iteration:  95% 14980/15836 [1:14:33<03:53,  3.66it/s]\u001b[A\n",
      "Iteration:  95% 14981/15836 [1:14:33<03:40,  3.88it/s]\u001b[A\n",
      "Iteration:  95% 14982/15836 [1:14:33<03:31,  4.03it/s]\u001b[A\n",
      "Iteration:  95% 14983/15836 [1:14:33<03:25,  4.16it/s]\u001b[A\n",
      "Iteration:  95% 14984/15836 [1:14:34<03:20,  4.25it/s]\u001b[A\n",
      "Iteration:  95% 14985/15836 [1:14:34<03:52,  3.66it/s]\u001b[A\n",
      "Iteration:  95% 14986/15836 [1:14:34<03:38,  3.88it/s]\u001b[A\n",
      "Iteration:  95% 14987/15836 [1:14:34<03:28,  4.06it/s]\u001b[A\n",
      "Iteration:  95% 14988/15836 [1:14:35<03:24,  4.14it/s]\u001b[A\n",
      "Iteration:  95% 14989/15836 [1:14:35<03:20,  4.23it/s]\u001b[A\n",
      "Iteration:  95% 14990/15836 [1:14:35<03:50,  3.67it/s]\u001b[A\n",
      "Iteration:  95% 14991/15836 [1:14:35<03:36,  3.91it/s]\u001b[A\n",
      "Iteration:  95% 14992/15836 [1:14:36<03:26,  4.08it/s]\u001b[A\n",
      "Iteration:  95% 14993/15836 [1:14:36<03:21,  4.18it/s]\u001b[A\n",
      "Iteration:  95% 14994/15836 [1:14:36<03:19,  4.22it/s]\u001b[A\n",
      "Iteration:  95% 14995/15836 [1:14:36<03:51,  3.63it/s]\u001b[A\n",
      "Iteration:  95% 14996/15836 [1:14:37<03:37,  3.87it/s]\u001b[A\n",
      "Iteration:  95% 14997/15836 [1:14:37<03:28,  4.02it/s]\u001b[A\n",
      "Iteration:  95% 14998/15836 [1:14:37<03:22,  4.13it/s]\u001b[A\n",
      "Iteration:  95% 14999/15836 [1:14:37<03:19,  4.20it/s]\u001b[A04/01/2020 15:25:46 - INFO - __main__ -   Loading features from cached file /content/gpt2_cached_lm_128_presidential_speeches_valid.txt\n",
      "04/01/2020 15:25:46 - INFO - __main__ -   ***** Running evaluation  *****\n",
      "04/01/2020 15:25:46 - INFO - __main__ -     Num examples = 1741\n",
      "04/01/2020 15:25:46 - INFO - __main__ -     Batch size = 2\n",
      "\n",
      "\n",
      "Evaluating:   0% 0/871 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0% 2/871 [00:00<00:55, 15.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   0% 4/871 [00:00<00:57, 15.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1% 6/871 [00:00<00:59, 14.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1% 8/871 [00:00<01:01, 14.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1% 10/871 [00:00<01:01, 14.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   1% 12/871 [00:00<01:03, 13.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2% 14/871 [00:01<01:02, 13.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2% 16/871 [00:01<01:01, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2% 18/871 [00:01<01:01, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   2% 20/871 [00:01<01:01, 13.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3% 22/871 [00:01<01:01, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3% 24/871 [00:01<01:01, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3% 26/871 [00:01<01:02, 13.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3% 28/871 [00:02<01:01, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   3% 30/871 [00:02<01:00, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   4% 32/871 [00:02<01:00, 13.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   4% 34/871 [00:02<00:59, 13.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   4% 36/871 [00:02<00:59, 14.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   4% 38/871 [00:02<00:59, 13.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   5% 40/871 [00:02<01:00, 13.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   5% 42/871 [00:03<00:59, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   5% 44/871 [00:03<00:58, 14.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   5% 46/871 [00:03<00:58, 14.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   6% 48/871 [00:03<00:58, 14.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   6% 50/871 [00:03<00:58, 14.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   6% 52/871 [00:03<00:58, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   6% 54/871 [00:03<00:59, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   6% 56/871 [00:04<00:58, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   7% 58/871 [00:04<00:58, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   7% 60/871 [00:04<00:58, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   7% 62/871 [00:04<00:58, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   7% 64/871 [00:04<00:58, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   8% 66/871 [00:04<00:58, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   8% 68/871 [00:04<00:58, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   8% 70/871 [00:05<00:57, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   8% 72/871 [00:05<00:57, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   8% 74/871 [00:05<00:56, 14.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   9% 76/871 [00:05<00:56, 13.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   9% 78/871 [00:05<00:56, 13.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   9% 80/871 [00:05<00:57, 13.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:   9% 82/871 [00:05<00:57, 13.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  10% 84/871 [00:06<00:56, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  10% 86/871 [00:06<00:56, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  10% 88/871 [00:06<00:56, 13.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  10% 90/871 [00:06<00:56, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  11% 92/871 [00:06<00:56, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  11% 94/871 [00:06<00:56, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  11% 96/871 [00:06<00:56, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  11% 98/871 [00:07<00:56, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  11% 100/871 [00:07<00:55, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  12% 102/871 [00:07<00:55, 13.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  12% 104/871 [00:07<00:55, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  12% 106/871 [00:07<00:54, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  12% 108/871 [00:07<00:55, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  13% 110/871 [00:07<00:55, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  13% 112/871 [00:08<00:54, 14.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  13% 114/871 [00:08<00:54, 13.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  13% 116/871 [00:08<00:53, 14.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  14% 118/871 [00:08<00:53, 14.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  14% 120/871 [00:08<00:53, 13.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  14% 122/871 [00:08<00:54, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  14% 124/871 [00:08<00:53, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  14% 126/871 [00:09<00:53, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  15% 128/871 [00:09<00:53, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  15% 130/871 [00:09<00:53, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  15% 132/871 [00:09<00:52, 13.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  15% 134/871 [00:09<00:53, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  16% 136/871 [00:09<00:53, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  16% 138/871 [00:09<00:52, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  16% 140/871 [00:10<00:52, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  16% 142/871 [00:10<00:52, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  17% 144/871 [00:10<00:52, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  17% 146/871 [00:10<00:52, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  17% 148/871 [00:10<00:52, 13.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  17% 150/871 [00:10<00:52, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  17% 152/871 [00:10<00:51, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  18% 154/871 [00:11<00:51, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  18% 156/871 [00:11<00:51, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  18% 158/871 [00:11<00:51, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  18% 160/871 [00:11<00:50, 13.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  19% 162/871 [00:11<00:51, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  19% 164/871 [00:11<00:51, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  19% 166/871 [00:11<00:50, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  19% 168/871 [00:12<00:50, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  20% 170/871 [00:12<00:50, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  20% 172/871 [00:12<00:50, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  20% 174/871 [00:12<00:50, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  20% 176/871 [00:12<00:50, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  20% 178/871 [00:12<00:50, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  21% 180/871 [00:12<00:50, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  21% 182/871 [00:13<00:49, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  21% 184/871 [00:13<00:49, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  21% 186/871 [00:13<00:49, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  22% 188/871 [00:13<00:49, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  22% 190/871 [00:13<00:49, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  22% 192/871 [00:13<00:49, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  22% 194/871 [00:13<00:48, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  23% 196/871 [00:14<00:48, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  23% 198/871 [00:14<00:48, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  23% 200/871 [00:14<00:48, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  23% 202/871 [00:14<00:48, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  23% 204/871 [00:14<00:48, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  24% 206/871 [00:14<00:48, 13.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  24% 208/871 [00:14<00:47, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  24% 210/871 [00:15<00:47, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  24% 212/871 [00:15<00:47, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  25% 214/871 [00:15<00:47, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  25% 216/871 [00:15<00:47, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  25% 218/871 [00:15<00:47, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  25% 220/871 [00:15<00:47, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  25% 222/871 [00:16<00:46, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  26% 224/871 [00:16<00:46, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  26% 226/871 [00:16<00:46, 13.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  26% 228/871 [00:16<00:45, 14.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  26% 230/871 [00:16<00:45, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  27% 232/871 [00:16<00:46, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  27% 234/871 [00:16<00:46, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  27% 236/871 [00:17<00:46, 13.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  27% 238/871 [00:17<00:45, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  28% 240/871 [00:17<00:45, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  28% 242/871 [00:17<00:45, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  28% 244/871 [00:17<00:45, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  28% 246/871 [00:17<00:45, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  28% 248/871 [00:17<00:45, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  29% 250/871 [00:18<00:45, 13.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  29% 252/871 [00:18<00:45, 13.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  29% 254/871 [00:18<00:44, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  29% 256/871 [00:18<00:44, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  30% 258/871 [00:18<00:44, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  30% 260/871 [00:18<00:44, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  30% 262/871 [00:18<00:43, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  30% 264/871 [00:19<00:43, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  31% 266/871 [00:19<00:43, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  31% 268/871 [00:19<00:43, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  31% 270/871 [00:19<00:43, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  31% 272/871 [00:19<00:43, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  31% 274/871 [00:19<00:42, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  32% 276/871 [00:19<00:42, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  32% 278/871 [00:20<00:42, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  32% 280/871 [00:20<00:42, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  32% 282/871 [00:20<00:42, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  33% 284/871 [00:20<00:42, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  33% 286/871 [00:20<00:42, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  33% 288/871 [00:20<00:41, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  33% 290/871 [00:20<00:41, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  34% 292/871 [00:21<00:41, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  34% 294/871 [00:21<00:41, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  34% 296/871 [00:21<00:41, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  34% 298/871 [00:21<00:41, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  34% 300/871 [00:21<00:40, 13.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  35% 302/871 [00:21<00:41, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  35% 304/871 [00:21<00:40, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  35% 306/871 [00:22<00:40, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  35% 308/871 [00:22<00:40, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  36% 310/871 [00:22<00:40, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  36% 312/871 [00:22<00:40, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  36% 314/871 [00:22<00:40, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  36% 316/871 [00:22<00:40, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  37% 318/871 [00:22<00:39, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  37% 320/871 [00:23<00:39, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  37% 322/871 [00:23<00:39, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  37% 324/871 [00:23<00:39, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  37% 326/871 [00:23<00:39, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  38% 328/871 [00:23<00:39, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  38% 330/871 [00:23<00:39, 13.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  38% 332/871 [00:23<00:39, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  38% 334/871 [00:24<00:38, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  39% 336/871 [00:24<00:38, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  39% 338/871 [00:24<00:38, 14.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  39% 340/871 [00:24<00:37, 14.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  39% 342/871 [00:24<00:37, 14.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  39% 344/871 [00:24<00:37, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  40% 346/871 [00:24<00:37, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  40% 348/871 [00:25<00:37, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  40% 350/871 [00:25<00:37, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  40% 352/871 [00:25<00:37, 14.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  41% 354/871 [00:25<00:37, 13.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  41% 356/871 [00:25<00:37, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  41% 358/871 [00:25<00:36, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  41% 360/871 [00:25<00:36, 13.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  42% 362/871 [00:26<00:36, 13.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  42% 364/871 [00:26<00:36, 13.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  42% 366/871 [00:26<00:36, 13.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  42% 368/871 [00:26<00:36, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  42% 370/871 [00:26<00:36, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  43% 372/871 [00:26<00:35, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  43% 374/871 [00:26<00:35, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  43% 376/871 [00:27<00:35, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  43% 378/871 [00:27<00:35, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  44% 380/871 [00:27<00:35, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  44% 382/871 [00:27<00:35, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  44% 384/871 [00:27<00:35, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  44% 386/871 [00:27<00:35, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  45% 388/871 [00:27<00:34, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  45% 390/871 [00:28<00:35, 13.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  45% 392/871 [00:28<00:34, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  45% 394/871 [00:28<00:34, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  45% 396/871 [00:28<00:34, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  46% 398/871 [00:28<00:34, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  46% 400/871 [00:28<00:34, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  46% 402/871 [00:28<00:33, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  46% 404/871 [00:29<00:33, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  47% 406/871 [00:29<00:33, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  47% 408/871 [00:29<00:33, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  47% 410/871 [00:29<00:33, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  47% 412/871 [00:29<00:33, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  48% 414/871 [00:29<00:33, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  48% 416/871 [00:29<00:32, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  48% 418/871 [00:30<00:32, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  48% 420/871 [00:30<00:32, 13.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  48% 422/871 [00:30<00:32, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  49% 424/871 [00:30<00:32, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  49% 426/871 [00:30<00:32, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  49% 428/871 [00:30<00:32, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  49% 430/871 [00:31<00:31, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  50% 432/871 [00:31<00:31, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  50% 434/871 [00:31<00:31, 13.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  50% 436/871 [00:31<00:31, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  50% 438/871 [00:31<00:31, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  51% 440/871 [00:31<00:31, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  51% 442/871 [00:31<00:31, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  51% 444/871 [00:32<00:30, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  51% 446/871 [00:32<00:30, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  51% 448/871 [00:32<00:30, 13.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  52% 450/871 [00:32<00:30, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  52% 452/871 [00:32<00:30, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  52% 454/871 [00:32<00:29, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  52% 456/871 [00:32<00:29, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  53% 458/871 [00:33<00:29, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  53% 460/871 [00:33<00:29, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  53% 462/871 [00:33<00:29, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  53% 464/871 [00:33<00:29, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  54% 466/871 [00:33<00:29, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  54% 468/871 [00:33<00:29, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  54% 470/871 [00:33<00:28, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  54% 472/871 [00:34<00:28, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  54% 474/871 [00:34<00:28, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  55% 476/871 [00:34<00:28, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  55% 478/871 [00:34<00:28, 13.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  55% 480/871 [00:34<00:28, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  55% 482/871 [00:34<00:27, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  56% 484/871 [00:34<00:27, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  56% 486/871 [00:35<00:27, 13.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  56% 488/871 [00:35<00:27, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  56% 490/871 [00:35<00:27, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  56% 492/871 [00:35<00:27, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  57% 494/871 [00:35<00:27, 13.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  57% 496/871 [00:35<00:26, 13.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  57% 498/871 [00:35<00:26, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  57% 500/871 [00:36<00:26, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  58% 502/871 [00:36<00:26, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  58% 504/871 [00:36<00:26, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  58% 506/871 [00:36<00:26, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  58% 508/871 [00:36<00:26, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  59% 510/871 [00:36<00:25, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  59% 512/871 [00:36<00:25, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  59% 514/871 [00:37<00:25, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  59% 516/871 [00:37<00:25, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  59% 518/871 [00:37<00:25, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  60% 520/871 [00:37<00:25, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  60% 522/871 [00:37<00:25, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  60% 524/871 [00:37<00:24, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  60% 526/871 [00:37<00:25, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  61% 528/871 [00:38<00:24, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  61% 530/871 [00:38<00:24, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  61% 532/871 [00:38<00:24, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  61% 534/871 [00:38<00:24, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  62% 536/871 [00:38<00:24, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  62% 538/871 [00:38<00:23, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  62% 540/871 [00:38<00:23, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  62% 542/871 [00:39<00:23, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  62% 544/871 [00:39<00:23, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  63% 546/871 [00:39<00:23, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  63% 548/871 [00:39<00:23, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  63% 550/871 [00:39<00:23, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  63% 552/871 [00:39<00:22, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  64% 554/871 [00:39<00:22, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  64% 556/871 [00:40<00:22, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  64% 558/871 [00:40<00:22, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  64% 560/871 [00:40<00:22, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  65% 562/871 [00:40<00:22, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  65% 564/871 [00:40<00:22, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  65% 566/871 [00:40<00:21, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  65% 568/871 [00:40<00:21, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  65% 570/871 [00:41<00:21, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  66% 572/871 [00:41<00:21, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  66% 574/871 [00:41<00:21, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  66% 576/871 [00:41<00:21, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  66% 578/871 [00:41<00:21, 13.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  67% 580/871 [00:41<00:20, 13.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  67% 582/871 [00:41<00:20, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  67% 584/871 [00:42<00:20, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  67% 586/871 [00:42<00:20, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  68% 588/871 [00:42<00:20, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  68% 590/871 [00:42<00:20, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  68% 592/871 [00:42<00:20, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  68% 594/871 [00:42<00:19, 13.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  68% 596/871 [00:42<00:19, 13.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  69% 598/871 [00:43<00:19, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  69% 600/871 [00:43<00:19, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  69% 602/871 [00:43<00:19, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  69% 604/871 [00:43<00:19, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  70% 606/871 [00:43<00:19, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  70% 608/871 [00:43<00:18, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  70% 610/871 [00:43<00:18, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  70% 612/871 [00:44<00:18, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  70% 614/871 [00:44<00:18, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  71% 616/871 [00:44<00:18, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  71% 618/871 [00:44<00:18, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  71% 620/871 [00:44<00:18, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  71% 622/871 [00:44<00:17, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  72% 624/871 [00:45<00:17, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  72% 626/871 [00:45<00:17, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  72% 628/871 [00:45<00:17, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  72% 630/871 [00:45<00:17, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  73% 632/871 [00:45<00:17, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  73% 634/871 [00:45<00:17, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  73% 636/871 [00:45<00:17, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  73% 638/871 [00:46<00:16, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  73% 640/871 [00:46<00:16, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  74% 642/871 [00:46<00:16, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  74% 644/871 [00:46<00:16, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  74% 646/871 [00:46<00:16, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  74% 648/871 [00:46<00:16, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  75% 650/871 [00:46<00:16, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  75% 652/871 [00:47<00:15, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  75% 654/871 [00:47<00:15, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  75% 656/871 [00:47<00:15, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  76% 658/871 [00:47<00:15, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  76% 660/871 [00:47<00:15, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  76% 662/871 [00:47<00:15, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  76% 664/871 [00:47<00:15, 13.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  76% 666/871 [00:48<00:14, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  77% 668/871 [00:48<00:14, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  77% 670/871 [00:48<00:14, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  77% 672/871 [00:48<00:14, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  77% 674/871 [00:48<00:14, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  78% 676/871 [00:48<00:14, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  78% 678/871 [00:48<00:13, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  78% 680/871 [00:49<00:13, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  78% 682/871 [00:49<00:13, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  79% 684/871 [00:49<00:13, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  79% 686/871 [00:49<00:13, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  79% 688/871 [00:49<00:13, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  79% 690/871 [00:49<00:12, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  79% 692/871 [00:49<00:12, 13.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  80% 694/871 [00:50<00:12, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  80% 696/871 [00:50<00:12, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  80% 698/871 [00:50<00:12, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  80% 700/871 [00:50<00:12, 13.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  81% 702/871 [00:50<00:12, 13.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  81% 704/871 [00:50<00:11, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  81% 706/871 [00:50<00:11, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  81% 708/871 [00:51<00:11, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  82% 710/871 [00:51<00:11, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  82% 712/871 [00:51<00:11, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  82% 714/871 [00:51<00:11, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  82% 716/871 [00:51<00:11, 13.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  82% 718/871 [00:51<00:10, 13.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  83% 720/871 [00:51<00:10, 13.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  83% 722/871 [00:52<00:10, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  83% 724/871 [00:52<00:10, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  83% 726/871 [00:52<00:10, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  84% 728/871 [00:52<00:10, 13.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  84% 730/871 [00:52<00:10, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  84% 732/871 [00:52<00:10, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  84% 734/871 [00:52<00:09, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  85% 736/871 [00:53<00:09, 13.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  85% 738/871 [00:53<00:09, 13.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  85% 740/871 [00:53<00:09, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  85% 742/871 [00:53<00:09, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  85% 744/871 [00:53<00:09, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  86% 746/871 [00:53<00:08, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  86% 748/871 [00:53<00:08, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  86% 750/871 [00:54<00:08, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  86% 752/871 [00:54<00:08, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  87% 754/871 [00:54<00:08, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  87% 756/871 [00:54<00:08, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  87% 758/871 [00:54<00:08, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  87% 760/871 [00:54<00:07, 13.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  87% 762/871 [00:54<00:07, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  88% 764/871 [00:55<00:07, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  88% 766/871 [00:55<00:07, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  88% 768/871 [00:55<00:07, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  88% 770/871 [00:55<00:07, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  89% 772/871 [00:55<00:07, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  89% 774/871 [00:55<00:06, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  89% 776/871 [00:55<00:06, 13.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  89% 778/871 [00:56<00:06, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  90% 780/871 [00:56<00:06, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  90% 782/871 [00:56<00:06, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  90% 784/871 [00:56<00:06, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  90% 786/871 [00:56<00:06, 13.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  90% 788/871 [00:56<00:06, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  91% 790/871 [00:56<00:05, 13.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  91% 792/871 [00:57<00:05, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  91% 794/871 [00:57<00:05, 13.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  91% 796/871 [00:57<00:05, 13.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  92% 798/871 [00:57<00:05, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  92% 800/871 [00:57<00:05, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  92% 802/871 [00:57<00:04, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  92% 804/871 [00:57<00:04, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  93% 806/871 [00:58<00:04, 13.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  93% 808/871 [00:58<00:04, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  93% 810/871 [00:58<00:04, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  93% 812/871 [00:58<00:04, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  93% 814/871 [00:58<00:04, 13.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  94% 816/871 [00:58<00:03, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  94% 818/871 [00:59<00:03, 13.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  94% 820/871 [00:59<00:03, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  94% 822/871 [00:59<00:03, 13.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  95% 824/871 [00:59<00:03, 13.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  95% 826/871 [00:59<00:03, 13.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  95% 828/871 [00:59<00:03, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  95% 830/871 [00:59<00:02, 13.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  96% 832/871 [01:00<00:02, 13.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  96% 834/871 [01:00<00:02, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  96% 836/871 [01:00<00:02, 13.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  96% 838/871 [01:00<00:02, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  96% 840/871 [01:00<00:02, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  97% 842/871 [01:00<00:02, 13.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  97% 844/871 [01:00<00:01, 13.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  97% 846/871 [01:01<00:01, 13.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  97% 848/871 [01:01<00:01, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  98% 850/871 [01:01<00:01, 13.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  98% 852/871 [01:01<00:01, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  98% 854/871 [01:01<00:01, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  98% 856/871 [01:01<00:01, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  99% 858/871 [01:01<00:00, 13.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  99% 860/871 [01:02<00:00, 13.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  99% 862/871 [01:02<00:00, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  99% 864/871 [01:02<00:00, 13.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating:  99% 866/871 [01:02<00:00, 13.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating: 100% 868/871 [01:02<00:00, 14.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "Evaluating: 100% 871/871 [01:02<00:00, 13.87it/s]\n",
      "04/01/2020 15:26:48 - INFO - __main__ -   ***** Eval results  *****\n",
      "04/01/2020 15:26:48 - INFO - __main__ -     perplexity = tensor(20.0059)\n",
      "04/01/2020 15:26:48 - INFO - transformers.configuration_utils -   Configuration saved in /content/drive/My Drive/finetuned_models/presidential_speeches/checkpoint-3000/config.json\n",
      "04/01/2020 15:26:57 - INFO - transformers.modeling_utils -   Model weights saved in /content/drive/My Drive/finetuned_models/presidential_speeches/checkpoint-3000/pytorch_model.bin\n",
      "04/01/2020 15:26:57 - INFO - __main__ -   Saving model checkpoint to /content/drive/My Drive/finetuned_models/presidential_speeches/checkpoint-3000\n",
      "04/01/2020 15:26:57 - INFO - __main__ -   Deleting older checkpoint [/content/drive/My Drive/finetuned_models/presidential_speeches/checkpoint-500] due to args.save_total_limit\n",
      "04/01/2020 15:28:08 - INFO - __main__ -   Saving optimizer and scheduler states to /content/drive/My Drive/finetuned_models/presidential_speeches/checkpoint-3000\n",
      "\n",
      "Iteration:  95% 15000/15836 [1:17:00<9:59:50, 43.05s/it]\u001b[A\n",
      "Iteration:  95% 15001/15836 [1:17:01<7:00:26, 30.21s/it]\u001b[A\n",
      "Iteration:  95% 15002/15836 [1:17:01<4:54:50, 21.21s/it]\u001b[A\n",
      "Iteration:  95% 15003/15836 [1:17:01<3:27:01, 14.91s/it]\u001b[A\n",
      "Iteration:  95% 15004/15836 [1:17:01<2:25:37, 10.50s/it]\u001b[A\n",
      "Iteration:  95% 15005/15836 [1:17:02<1:43:20,  7.46s/it]\u001b[A\n",
      "Iteration:  95% 15006/15836 [1:17:02<1:13:07,  5.29s/it]\u001b[A\n",
      "Iteration:  95% 15007/15836 [1:17:02<52:01,  3.77s/it]  \u001b[A\n",
      "Iteration:  95% 15008/15836 [1:17:02<37:14,  2.70s/it]\u001b[A\n",
      "Iteration:  95% 15009/15836 [1:17:02<26:58,  1.96s/it]\u001b[A\n",
      "Iteration:  95% 15010/15836 [1:17:03<20:19,  1.48s/it]\u001b[A\n",
      "Iteration:  95% 15011/15836 [1:17:03<15:05,  1.10s/it]\u001b[A\n",
      "Iteration:  95% 15012/15836 [1:17:03<11:25,  1.20it/s]\u001b[A\n",
      "Iteration:  95% 15013/15836 [1:17:03<08:54,  1.54it/s]\u001b[A\n",
      "Iteration:  95% 15014/15836 [1:17:04<07:08,  1.92it/s]\u001b[A\n",
      "Iteration:  95% 15015/15836 [1:17:04<06:27,  2.12it/s]\u001b[A\n",
      "Iteration:  95% 15016/15836 [1:17:04<05:23,  2.54it/s]\u001b[A\n",
      "Iteration:  95% 15017/15836 [1:17:04<04:39,  2.93it/s]\u001b[A\n",
      "Iteration:  95% 15018/15836 [1:17:05<04:10,  3.26it/s]\u001b[A\n",
      "Iteration:  95% 15019/15836 [1:17:05<03:50,  3.55it/s]\u001b[A\n",
      "Iteration:  95% 15020/15836 [1:17:05<04:08,  3.29it/s]\u001b[A\n",
      "Iteration:  95% 15021/15836 [1:17:05<03:45,  3.62it/s]\u001b[A\n",
      "Iteration:  95% 15022/15836 [1:17:06<03:30,  3.87it/s]\u001b[A\n",
      "Iteration:  95% 15023/15836 [1:17:06<03:22,  4.02it/s]\u001b[A\n",
      "Iteration:  95% 15024/15836 [1:17:06<03:16,  4.14it/s]\u001b[A\n",
      "Iteration:  95% 15025/15836 [1:17:06<03:43,  3.62it/s]\u001b[A\n",
      "Iteration:  95% 15026/15836 [1:17:07<03:28,  3.89it/s]\u001b[A\n",
      "Iteration:  95% 15027/15836 [1:17:07<03:19,  4.06it/s]\u001b[A\n",
      "Iteration:  95% 15028/15836 [1:17:07<03:13,  4.18it/s]\u001b[A\n",
      "Iteration:  95% 15029/15836 [1:17:07<03:09,  4.26it/s]\u001b[A\n",
      "Iteration:  95% 15030/15836 [1:17:08<03:39,  3.68it/s]\u001b[A\n",
      "Iteration:  95% 15031/15836 [1:17:08<03:25,  3.92it/s]\u001b[A\n",
      "Iteration:  95% 15032/15836 [1:17:08<03:17,  4.08it/s]\u001b[A\n",
      "Iteration:  95% 15033/15836 [1:17:08<03:12,  4.18it/s]\u001b[A\n",
      "Iteration:  95% 15034/15836 [1:17:09<03:08,  4.27it/s]\u001b[A\n",
      "Iteration:  95% 15035/15836 [1:17:09<03:38,  3.67it/s]\u001b[A\n",
      "Iteration:  95% 15036/15836 [1:17:09<03:24,  3.91it/s]\u001b[A\n",
      "Iteration:  95% 15037/15836 [1:17:09<03:16,  4.07it/s]\u001b[A\n",
      "Iteration:  95% 15038/15836 [1:17:10<03:11,  4.17it/s]\u001b[A\n",
      "Iteration:  95% 15039/15836 [1:17:10<03:07,  4.25it/s]\u001b[A\n",
      "Iteration:  95% 15040/15836 [1:17:10<03:36,  3.68it/s]\u001b[A\n",
      "Iteration:  95% 15041/15836 [1:17:10<03:24,  3.89it/s]\u001b[A\n",
      "Iteration:  95% 15042/15836 [1:17:11<03:15,  4.07it/s]\u001b[A\n",
      "Iteration:  95% 15043/15836 [1:17:11<03:10,  4.17it/s]\u001b[A\n",
      "Iteration:  95% 15044/15836 [1:17:11<03:07,  4.22it/s]\u001b[A\n",
      "Iteration:  95% 15045/15836 [1:17:11<03:36,  3.65it/s]\u001b[A\n",
      "Iteration:  95% 15046/15836 [1:17:12<03:23,  3.88it/s]\u001b[A\n",
      "Iteration:  95% 15047/15836 [1:17:12<03:14,  4.05it/s]\u001b[A\n",
      "Iteration:  95% 15048/15836 [1:17:12<03:09,  4.15it/s]\u001b[A\n",
      "Iteration:  95% 15049/15836 [1:17:12<03:07,  4.21it/s]\u001b[A\n",
      "Iteration:  95% 15050/15836 [1:17:13<03:35,  3.65it/s]\u001b[A\n",
      "Iteration:  95% 15051/15836 [1:17:13<03:21,  3.89it/s]\u001b[A\n",
      "Iteration:  95% 15052/15836 [1:17:13<03:13,  4.06it/s]\u001b[A\n",
      "Iteration:  95% 15053/15836 [1:17:13<03:08,  4.15it/s]\u001b[A\n",
      "Iteration:  95% 15054/15836 [1:17:14<03:05,  4.23it/s]\u001b[A\n",
      "Iteration:  95% 15055/15836 [1:17:14<03:34,  3.65it/s]\u001b[A\n",
      "Iteration:  95% 15056/15836 [1:17:14<03:21,  3.87it/s]\u001b[A\n",
      "Iteration:  95% 15057/15836 [1:17:14<03:13,  4.02it/s]\u001b[A\n",
      "Iteration:  95% 15058/15836 [1:17:15<03:08,  4.13it/s]\u001b[A\n",
      "Iteration:  95% 15059/15836 [1:17:15<03:06,  4.18it/s]\u001b[A\n",
      "Iteration:  95% 15060/15836 [1:17:15<03:34,  3.62it/s]\u001b[A\n",
      "Iteration:  95% 15061/15836 [1:17:15<03:22,  3.83it/s]\u001b[A\n",
      "Iteration:  95% 15062/15836 [1:17:16<03:13,  4.00it/s]\u001b[A\n",
      "Iteration:  95% 15063/15836 [1:17:16<03:08,  4.11it/s]\u001b[A\n",
      "Iteration:  95% 15064/15836 [1:17:16<03:05,  4.17it/s]\u001b[A\n",
      "Iteration:  95% 15065/15836 [1:17:17<03:33,  3.61it/s]\u001b[A\n",
      "Iteration:  95% 15066/15836 [1:17:17<03:20,  3.84it/s]\u001b[A\n",
      "Iteration:  95% 15067/15836 [1:17:17<03:12,  3.99it/s]\u001b[A\n",
      "Iteration:  95% 15068/15836 [1:17:17<03:07,  4.09it/s]\u001b[A\n",
      "Iteration:  95% 15069/15836 [1:17:17<03:04,  4.16it/s]\u001b[A\n",
      "Iteration:  95% 15070/15836 [1:17:18<03:33,  3.59it/s]\u001b[A\n",
      "Iteration:  95% 15071/15836 [1:17:18<03:20,  3.82it/s]\u001b[A\n",
      "Iteration:  95% 15072/15836 [1:17:18<03:12,  3.96it/s]\u001b[A\n",
      "Iteration:  95% 15073/15836 [1:17:18<03:08,  4.06it/s]\u001b[A\n",
      "Iteration:  95% 15074/15836 [1:17:19<03:06,  4.07it/s]\u001b[A\n",
      "Iteration:  95% 15075/15836 [1:17:19<03:34,  3.55it/s]\u001b[A\n",
      "Iteration:  95% 15076/15836 [1:17:19<03:20,  3.79it/s]\u001b[A\n",
      "Iteration:  95% 15077/15836 [1:17:20<03:13,  3.92it/s]\u001b[A\n",
      "Iteration:  95% 15078/15836 [1:17:20<03:07,  4.04it/s]\u001b[A\n",
      "Iteration:  95% 15079/15836 [1:17:20<03:05,  4.07it/s]\u001b[A\n",
      "Iteration:  95% 15080/15836 [1:17:20<03:32,  3.55it/s]\u001b[A\n",
      "Iteration:  95% 15081/15836 [1:17:21<03:20,  3.77it/s]\u001b[A\n",
      "Iteration:  95% 15082/15836 [1:17:21<03:12,  3.92it/s]\u001b[A\n",
      "Iteration:  95% 15083/15836 [1:17:21<03:06,  4.04it/s]\u001b[A\n",
      "Iteration:  95% 15084/15836 [1:17:21<03:04,  4.08it/s]\u001b[A\n",
      "Iteration:  95% 15085/15836 [1:17:22<03:31,  3.55it/s]\u001b[A\n",
      "Iteration:  95% 15086/15836 [1:17:22<03:19,  3.76it/s]\u001b[A\n",
      "Iteration:  95% 15087/15836 [1:17:22<03:11,  3.91it/s]\u001b[A\n",
      "Iteration:  95% 15088/15836 [1:17:22<03:06,  4.02it/s]\u001b[A\n",
      "Iteration:  95% 15089/15836 [1:17:23<03:03,  4.06it/s]\u001b[A\n",
      "Iteration:  95% 15090/15836 [1:17:23<03:31,  3.53it/s]\u001b[A\n",
      "Iteration:  95% 15091/15836 [1:17:23<03:20,  3.72it/s]\u001b[A\n",
      "Iteration:  95% 15092/15836 [1:17:23<03:11,  3.89it/s]\u001b[A\n",
      "Iteration:  95% 15093/15836 [1:17:24<03:06,  3.99it/s]\u001b[A\n",
      "Iteration:  95% 15094/15836 [1:17:24<03:04,  4.03it/s]\u001b[A\n",
      "Iteration:  95% 15095/15836 [1:17:24<03:30,  3.52it/s]\u001b[A\n",
      "Iteration:  95% 15096/15836 [1:17:25<03:18,  3.73it/s]\u001b[A\n",
      "Iteration:  95% 15097/15836 [1:17:25<03:09,  3.90it/s]\u001b[A\n",
      "Iteration:  95% 15098/15836 [1:17:25<03:04,  4.01it/s]\u001b[A\n",
      "Iteration:  95% 15099/15836 [1:17:25<03:01,  4.06it/s]\u001b[A\n",
      "Iteration:  95% 15100/15836 [1:17:26<03:28,  3.53it/s]\u001b[A\n",
      "Iteration:  95% 15101/15836 [1:17:26<03:17,  3.73it/s]\u001b[A\n",
      "Iteration:  95% 15102/15836 [1:17:26<03:09,  3.88it/s]\u001b[A\n",
      "Iteration:  95% 15103/15836 [1:17:26<03:03,  4.00it/s]\u001b[A\n",
      "Iteration:  95% 15104/15836 [1:17:27<03:01,  4.04it/s]\u001b[A\n",
      "Iteration:  95% 15105/15836 [1:17:27<03:27,  3.52it/s]\u001b[A\n",
      "Iteration:  95% 15106/15836 [1:17:27<03:15,  3.73it/s]\u001b[A\n",
      "Iteration:  95% 15107/15836 [1:17:27<03:08,  3.88it/s]\u001b[A\n",
      "Iteration:  95% 15108/15836 [1:17:28<03:03,  3.96it/s]\u001b[A\n",
      "Iteration:  95% 15109/15836 [1:17:28<03:01,  4.01it/s]\u001b[A\n",
      "Iteration:  95% 15110/15836 [1:17:28<03:27,  3.50it/s]\u001b[A\n",
      "Iteration:  95% 15111/15836 [1:17:28<03:17,  3.67it/s]\u001b[A\n",
      "Iteration:  95% 15112/15836 [1:17:29<03:09,  3.83it/s]\u001b[A\n",
      "Iteration:  95% 15113/15836 [1:17:29<03:02,  3.97it/s]\u001b[A\n",
      "Iteration:  95% 15114/15836 [1:17:29<02:59,  4.01it/s]\u001b[A\n",
      "Iteration:  95% 15115/15836 [1:17:30<03:27,  3.48it/s]\u001b[A\n",
      "Iteration:  95% 15116/15836 [1:17:30<03:14,  3.69it/s]\u001b[A\n",
      "Iteration:  95% 15117/15836 [1:17:30<03:06,  3.85it/s]\u001b[A\n",
      "Iteration:  95% 15118/15836 [1:17:30<03:01,  3.96it/s]\u001b[A\n",
      "Iteration:  95% 15119/15836 [1:17:31<02:58,  4.01it/s]\u001b[A\n",
      "Iteration:  95% 15120/15836 [1:17:31<03:24,  3.49it/s]\u001b[A\n",
      "Iteration:  95% 15121/15836 [1:17:31<03:11,  3.73it/s]\u001b[A\n",
      "Iteration:  95% 15122/15836 [1:17:31<03:04,  3.87it/s]\u001b[A\n",
      "Iteration:  95% 15123/15836 [1:17:32<02:58,  3.98it/s]\u001b[A\n",
      "Iteration:  96% 15124/15836 [1:17:32<02:57,  4.02it/s]\u001b[A\n",
      "Iteration:  96% 15125/15836 [1:17:32<03:22,  3.50it/s]\u001b[A\n",
      "Iteration:  96% 15126/15836 [1:17:32<03:11,  3.70it/s]\u001b[A\n",
      "Iteration:  96% 15127/15836 [1:17:33<03:03,  3.86it/s]\u001b[A\n",
      "Iteration:  96% 15128/15836 [1:17:33<02:57,  4.00it/s]\u001b[A\n",
      "Iteration:  96% 15129/15836 [1:17:33<02:53,  4.07it/s]\u001b[A\n",
      "Iteration:  96% 15130/15836 [1:17:33<03:21,  3.51it/s]\u001b[A\n",
      "Iteration:  96% 15131/15836 [1:17:34<03:10,  3.71it/s]\u001b[A\n",
      "Iteration:  96% 15132/15836 [1:17:34<03:00,  3.89it/s]\u001b[A\n",
      "Iteration:  96% 15133/15836 [1:17:34<02:55,  4.01it/s]\u001b[A\n",
      "Iteration:  96% 15134/15836 [1:17:34<02:53,  4.05it/s]\u001b[A\n",
      "Iteration:  96% 15135/15836 [1:17:35<03:18,  3.53it/s]\u001b[A\n",
      "Iteration:  96% 15136/15836 [1:17:35<03:07,  3.74it/s]\u001b[A\n",
      "Iteration:  96% 15137/15836 [1:17:35<02:58,  3.91it/s]\u001b[A\n",
      "Iteration:  96% 15138/15836 [1:17:35<02:54,  4.00it/s]\u001b[A\n",
      "Iteration:  96% 15139/15836 [1:17:36<02:50,  4.08it/s]\u001b[A\n",
      "Iteration:  96% 15140/15836 [1:17:36<03:17,  3.53it/s]\u001b[A\n",
      "Iteration:  96% 15141/15836 [1:17:36<03:04,  3.76it/s]\u001b[A\n",
      "Iteration:  96% 15142/15836 [1:17:37<02:57,  3.92it/s]\u001b[A\n",
      "Iteration:  96% 15143/15836 [1:17:37<02:52,  4.02it/s]\u001b[A\n",
      "Iteration:  96% 15144/15836 [1:17:37<02:49,  4.08it/s]\u001b[A\n",
      "Iteration:  96% 15145/15836 [1:17:37<03:14,  3.56it/s]\u001b[A\n",
      "Iteration:  96% 15146/15836 [1:17:38<03:03,  3.77it/s]\u001b[A\n",
      "Iteration:  96% 15147/15836 [1:17:38<02:55,  3.94it/s]\u001b[A\n",
      "Iteration:  96% 15148/15836 [1:17:38<02:50,  4.03it/s]\u001b[A\n",
      "Iteration:  96% 15149/15836 [1:17:38<02:47,  4.11it/s]\u001b[A\n",
      "Iteration:  96% 15150/15836 [1:17:39<03:12,  3.56it/s]\u001b[A\n",
      "Iteration:  96% 15151/15836 [1:17:39<03:02,  3.76it/s]\u001b[A\n",
      "Iteration:  96% 15152/15836 [1:17:39<02:53,  3.94it/s]\u001b[A\n",
      "Iteration:  96% 15153/15836 [1:17:39<02:48,  4.05it/s]\u001b[A\n",
      "Iteration:  96% 15154/15836 [1:17:40<02:45,  4.11it/s]\u001b[A\n",
      "Iteration:  96% 15155/15836 [1:17:40<03:10,  3.58it/s]\u001b[A\n",
      "Iteration:  96% 15156/15836 [1:17:40<02:59,  3.80it/s]\u001b[A\n",
      "Iteration:  96% 15157/15836 [1:17:40<02:52,  3.93it/s]\u001b[A\n",
      "Iteration:  96% 15158/15836 [1:17:41<02:46,  4.07it/s]\u001b[A\n",
      "Iteration:  96% 15159/15836 [1:17:41<02:43,  4.14it/s]\u001b[A\n",
      "Iteration:  96% 15160/15836 [1:17:41<03:09,  3.58it/s]\u001b[A\n",
      "Iteration:  96% 15161/15836 [1:17:41<02:58,  3.78it/s]\u001b[A\n",
      "Iteration:  96% 15162/15836 [1:17:42<02:49,  3.97it/s]\u001b[A\n",
      "Iteration:  96% 15163/15836 [1:17:42<02:44,  4.09it/s]\u001b[A\n",
      "Iteration:  96% 15164/15836 [1:17:42<02:42,  4.13it/s]\u001b[A\n",
      "Iteration:  96% 15165/15836 [1:17:43<03:06,  3.59it/s]\u001b[A\n",
      "Iteration:  96% 15166/15836 [1:17:43<02:55,  3.83it/s]\u001b[A\n",
      "Iteration:  96% 15167/15836 [1:17:43<02:47,  3.99it/s]\u001b[A\n",
      "Iteration:  96% 15168/15836 [1:17:43<02:43,  4.09it/s]\u001b[A\n",
      "Iteration:  96% 15169/15836 [1:17:43<02:40,  4.15it/s]\u001b[A\n",
      "Iteration:  96% 15170/15836 [1:17:44<03:04,  3.60it/s]\u001b[A\n",
      "Iteration:  96% 15171/15836 [1:17:44<02:53,  3.83it/s]\u001b[A\n",
      "Iteration:  96% 15172/15836 [1:17:44<02:46,  3.99it/s]\u001b[A\n",
      "Iteration:  96% 15173/15836 [1:17:44<02:41,  4.10it/s]\u001b[A\n",
      "Iteration:  96% 15174/15836 [1:17:45<02:39,  4.16it/s]\u001b[A\n",
      "Iteration:  96% 15175/15836 [1:17:45<03:04,  3.59it/s]\u001b[A\n",
      "Iteration:  96% 15176/15836 [1:17:45<02:52,  3.82it/s]\u001b[A\n",
      "Iteration:  96% 15177/15836 [1:17:46<02:44,  4.00it/s]\u001b[A\n",
      "Iteration:  96% 15178/15836 [1:17:46<02:39,  4.12it/s]\u001b[A\n",
      "Iteration:  96% 15179/15836 [1:17:46<02:36,  4.19it/s]\u001b[A\n",
      "Iteration:  96% 15180/15836 [1:17:46<03:01,  3.62it/s]\u001b[A\n",
      "Iteration:  96% 15181/15836 [1:17:47<02:50,  3.85it/s]\u001b[A\n",
      "Iteration:  96% 15182/15836 [1:17:47<02:42,  4.01it/s]\u001b[A\n",
      "Iteration:  96% 15183/15836 [1:17:47<02:38,  4.11it/s]\u001b[A\n",
      "Iteration:  96% 15184/15836 [1:17:47<02:36,  4.17it/s]\u001b[A\n",
      "Iteration:  96% 15185/15836 [1:17:48<02:59,  3.62it/s]\u001b[A\n",
      "Iteration:  96% 15186/15836 [1:17:48<02:48,  3.85it/s]\u001b[A\n",
      "Iteration:  96% 15187/15836 [1:17:48<02:41,  4.03it/s]\u001b[A\n",
      "Iteration:  96% 15188/15836 [1:17:48<02:36,  4.13it/s]\u001b[A\n",
      "Iteration:  96% 15189/15836 [1:17:49<02:34,  4.20it/s]\u001b[A\n",
      "Iteration:  96% 15190/15836 [1:17:49<02:57,  3.63it/s]\u001b[A\n",
      "Iteration:  96% 15191/15836 [1:17:49<02:46,  3.88it/s]\u001b[A\n",
      "Iteration:  96% 15192/15836 [1:17:49<02:39,  4.04it/s]\u001b[A\n",
      "Iteration:  96% 15193/15836 [1:17:50<02:35,  4.14it/s]\u001b[A\n",
      "Iteration:  96% 15194/15836 [1:17:50<02:31,  4.23it/s]\u001b[A\n",
      "Iteration:  96% 15195/15836 [1:17:50<02:56,  3.64it/s]\u001b[A\n",
      "Iteration:  96% 15196/15836 [1:17:50<02:44,  3.88it/s]\u001b[A\n",
      "Iteration:  96% 15197/15836 [1:17:51<02:38,  4.04it/s]\u001b[A\n",
      "Iteration:  96% 15198/15836 [1:17:51<02:33,  4.16it/s]\u001b[A\n",
      "Iteration:  96% 15199/15836 [1:17:51<02:31,  4.20it/s]\u001b[A\n",
      "Iteration:  96% 15200/15836 [1:17:51<02:54,  3.64it/s]\u001b[A\n",
      "Iteration:  96% 15201/15836 [1:17:52<02:43,  3.88it/s]\u001b[A\n",
      "Iteration:  96% 15202/15836 [1:17:52<02:37,  4.03it/s]\u001b[A\n",
      "Iteration:  96% 15203/15836 [1:17:52<02:33,  4.12it/s]\u001b[A\n",
      "Iteration:  96% 15204/15836 [1:17:52<02:30,  4.20it/s]\u001b[A\n",
      "Iteration:  96% 15205/15836 [1:17:53<02:53,  3.63it/s]\u001b[A\n",
      "Iteration:  96% 15206/15836 [1:17:53<02:42,  3.88it/s]\u001b[A\n",
      "Iteration:  96% 15207/15836 [1:17:53<02:35,  4.04it/s]\u001b[A\n",
      "Iteration:  96% 15208/15836 [1:17:53<02:30,  4.18it/s]\u001b[A\n",
      "Iteration:  96% 15209/15836 [1:17:54<02:28,  4.23it/s]\u001b[A\n",
      "Iteration:  96% 15210/15836 [1:17:54<02:50,  3.67it/s]\u001b[A\n",
      "Iteration:  96% 15211/15836 [1:17:54<02:40,  3.90it/s]\u001b[A\n",
      "Iteration:  96% 15212/15836 [1:17:54<02:33,  4.07it/s]\u001b[A\n",
      "Iteration:  96% 15213/15836 [1:17:55<02:29,  4.16it/s]\u001b[A\n",
      "Iteration:  96% 15214/15836 [1:17:55<02:27,  4.23it/s]\u001b[A\n",
      "Iteration:  96% 15215/15836 [1:17:55<02:49,  3.66it/s]\u001b[A\n",
      "Iteration:  96% 15216/15836 [1:17:55<02:38,  3.91it/s]\u001b[A\n",
      "Iteration:  96% 15217/15836 [1:17:56<02:31,  4.08it/s]\u001b[A\n",
      "Iteration:  96% 15218/15836 [1:17:56<02:28,  4.17it/s]\u001b[A\n",
      "Iteration:  96% 15219/15836 [1:17:56<02:24,  4.27it/s]\u001b[A\n",
      "Iteration:  96% 15220/15836 [1:17:56<02:47,  3.68it/s]\u001b[A\n",
      "Iteration:  96% 15221/15836 [1:17:57<02:37,  3.91it/s]\u001b[A\n",
      "Iteration:  96% 15222/15836 [1:17:57<02:31,  4.06it/s]\u001b[A\n",
      "Iteration:  96% 15223/15836 [1:17:57<02:26,  4.19it/s]\u001b[A\n",
      "Iteration:  96% 15224/15836 [1:17:57<02:23,  4.25it/s]\u001b[A\n",
      "Iteration:  96% 15225/15836 [1:17:58<02:45,  3.68it/s]\u001b[A\n",
      "Iteration:  96% 15226/15836 [1:17:58<02:35,  3.92it/s]\u001b[A\n",
      "Iteration:  96% 15227/15836 [1:17:58<02:28,  4.09it/s]\u001b[A\n",
      "Iteration:  96% 15228/15836 [1:17:58<02:24,  4.22it/s]\u001b[A\n",
      "Iteration:  96% 15229/15836 [1:17:59<02:21,  4.28it/s]\u001b[A\n",
      "Iteration:  96% 15230/15836 [1:17:59<02:43,  3.70it/s]\u001b[A\n",
      "Iteration:  96% 15231/15836 [1:17:59<02:33,  3.94it/s]\u001b[A\n",
      "Iteration:  96% 15232/15836 [1:17:59<02:26,  4.12it/s]\u001b[A\n",
      "Iteration:  96% 15233/15836 [1:18:00<02:22,  4.22it/s]\u001b[A\n",
      "Iteration:  96% 15234/15836 [1:18:00<02:20,  4.29it/s]\u001b[A\n",
      "Iteration:  96% 15235/15836 [1:18:00<02:42,  3.70it/s]\u001b[A\n",
      "Iteration:  96% 15236/15836 [1:18:00<02:32,  3.93it/s]\u001b[A\n",
      "Iteration:  96% 15237/15836 [1:18:01<02:26,  4.09it/s]\u001b[A\n",
      "Iteration:  96% 15238/15836 [1:18:01<02:23,  4.18it/s]\u001b[A\n",
      "Iteration:  96% 15239/15836 [1:18:01<02:20,  4.25it/s]\u001b[A\n",
      "Iteration:  96% 15240/15836 [1:18:01<02:42,  3.67it/s]\u001b[A\n",
      "Iteration:  96% 15241/15836 [1:18:02<02:31,  3.92it/s]\u001b[A\n",
      "Iteration:  96% 15242/15836 [1:18:02<02:25,  4.10it/s]\u001b[A\n",
      "Iteration:  96% 15243/15836 [1:18:02<02:21,  4.20it/s]\u001b[A\n",
      "Iteration:  96% 15244/15836 [1:18:02<02:18,  4.27it/s]\u001b[A\n",
      "Iteration:  96% 15245/15836 [1:18:03<02:40,  3.69it/s]\u001b[A\n",
      "Iteration:  96% 15246/15836 [1:18:03<02:29,  3.94it/s]\u001b[A\n",
      "Iteration:  96% 15247/15836 [1:18:03<02:23,  4.11it/s]\u001b[A\n",
      "Iteration:  96% 15248/15836 [1:18:03<02:19,  4.22it/s]\u001b[A\n",
      "Iteration:  96% 15249/15836 [1:18:03<02:17,  4.28it/s]\u001b[A\n",
      "Iteration:  96% 15250/15836 [1:18:04<02:38,  3.69it/s]\u001b[A\n",
      "Iteration:  96% 15251/15836 [1:18:04<02:29,  3.92it/s]\u001b[A\n",
      "Iteration:  96% 15252/15836 [1:18:04<02:21,  4.12it/s]\u001b[A\n",
      "Iteration:  96% 15253/15836 [1:18:04<02:17,  4.23it/s]\u001b[A\n",
      "Iteration:  96% 15254/15836 [1:18:05<02:15,  4.30it/s]\u001b[A\n",
      "Iteration:  96% 15255/15836 [1:18:05<02:37,  3.70it/s]\u001b[A\n",
      "Iteration:  96% 15256/15836 [1:18:05<02:27,  3.94it/s]\u001b[A\n",
      "Iteration:  96% 15257/15836 [1:18:06<02:20,  4.11it/s]\u001b[A\n",
      "Iteration:  96% 15258/15836 [1:18:06<02:17,  4.21it/s]\u001b[A\n",
      "Iteration:  96% 15259/15836 [1:18:06<02:14,  4.28it/s]\u001b[A\n",
      "Iteration:  96% 15260/15836 [1:18:06<02:35,  3.70it/s]\u001b[A\n",
      "Iteration:  96% 15261/15836 [1:18:07<02:26,  3.93it/s]\u001b[A\n",
      "Iteration:  96% 15262/15836 [1:18:07<02:19,  4.12it/s]\u001b[A\n",
      "Iteration:  96% 15263/15836 [1:18:07<02:15,  4.23it/s]\u001b[A\n",
      "Iteration:  96% 15264/15836 [1:18:07<02:13,  4.29it/s]\u001b[A\n",
      "Iteration:  96% 15265/15836 [1:18:08<02:34,  3.70it/s]\u001b[A\n",
      "Iteration:  96% 15266/15836 [1:18:08<02:24,  3.93it/s]\u001b[A\n",
      "Iteration:  96% 15267/15836 [1:18:08<02:17,  4.13it/s]\u001b[A\n",
      "Iteration:  96% 15268/15836 [1:18:08<02:13,  4.24it/s]\u001b[A\n",
      "Iteration:  96% 15269/15836 [1:18:08<02:12,  4.29it/s]\u001b[A\n",
      "Iteration:  96% 15270/15836 [1:18:09<02:33,  3.69it/s]\u001b[A\n",
      "Iteration:  96% 15271/15836 [1:18:09<02:23,  3.94it/s]\u001b[A\n",
      "Iteration:  96% 15272/15836 [1:18:09<02:17,  4.11it/s]\u001b[A\n",
      "Iteration:  96% 15273/15836 [1:18:09<02:12,  4.24it/s]\u001b[A\n",
      "Iteration:  96% 15274/15836 [1:18:10<02:10,  4.31it/s]\u001b[A\n",
      "Iteration:  96% 15275/15836 [1:18:10<02:31,  3.71it/s]\u001b[A\n",
      "Iteration:  96% 15276/15836 [1:18:10<02:21,  3.95it/s]\u001b[A\n",
      "Iteration:  96% 15277/15836 [1:18:10<02:14,  4.15it/s]\u001b[A\n",
      "Iteration:  96% 15278/15836 [1:18:11<02:12,  4.22it/s]\u001b[A\n",
      "Iteration:  96% 15279/15836 [1:18:11<02:09,  4.29it/s]\u001b[A\n",
      "Iteration:  96% 15280/15836 [1:18:11<02:30,  3.70it/s]\u001b[A\n",
      "Iteration:  96% 15281/15836 [1:18:11<02:20,  3.95it/s]\u001b[A\n",
      "Iteration:  97% 15282/15836 [1:18:12<02:14,  4.13it/s]\u001b[A\n",
      "Iteration:  97% 15283/15836 [1:18:12<02:10,  4.24it/s]\u001b[A\n",
      "Iteration:  97% 15284/15836 [1:18:12<02:07,  4.31it/s]\u001b[A\n",
      "Iteration:  97% 15285/15836 [1:18:12<02:28,  3.72it/s]\u001b[A\n",
      "Iteration:  97% 15286/15836 [1:18:13<02:18,  3.97it/s]\u001b[A\n",
      "Iteration:  97% 15287/15836 [1:18:13<02:12,  4.14it/s]\u001b[A\n",
      "Iteration:  97% 15288/15836 [1:18:13<02:09,  4.22it/s]\u001b[A\n",
      "Iteration:  97% 15289/15836 [1:18:13<02:06,  4.31it/s]\u001b[A\n",
      "Iteration:  97% 15290/15836 [1:18:14<02:27,  3.71it/s]\u001b[A\n",
      "Iteration:  97% 15291/15836 [1:18:14<02:17,  3.97it/s]\u001b[A\n",
      "Iteration:  97% 15292/15836 [1:18:14<02:12,  4.12it/s]\u001b[A\n",
      "Iteration:  97% 15293/15836 [1:18:14<02:08,  4.23it/s]\u001b[A\n",
      "Iteration:  97% 15294/15836 [1:18:15<02:06,  4.30it/s]\u001b[A\n",
      "Iteration:  97% 15295/15836 [1:18:15<02:26,  3.70it/s]\u001b[A\n",
      "Iteration:  97% 15296/15836 [1:18:15<02:16,  3.95it/s]\u001b[A\n",
      "Iteration:  97% 15297/15836 [1:18:15<02:11,  4.11it/s]\u001b[A\n",
      "Iteration:  97% 15298/15836 [1:18:16<02:07,  4.22it/s]\u001b[A\n",
      "Iteration:  97% 15299/15836 [1:18:16<02:05,  4.29it/s]\u001b[A\n",
      "Iteration:  97% 15300/15836 [1:18:16<02:24,  3.70it/s]\u001b[A\n",
      "Iteration:  97% 15301/15836 [1:18:16<02:14,  3.96it/s]\u001b[A\n",
      "Iteration:  97% 15302/15836 [1:18:17<02:09,  4.11it/s]\u001b[A\n",
      "Iteration:  97% 15303/15836 [1:18:17<02:06,  4.20it/s]\u001b[A\n",
      "Iteration:  97% 15304/15836 [1:18:17<02:04,  4.27it/s]\u001b[A\n",
      "Iteration:  97% 15305/15836 [1:18:17<02:23,  3.69it/s]\u001b[A\n",
      "Iteration:  97% 15306/15836 [1:18:18<02:14,  3.95it/s]\u001b[A\n",
      "Iteration:  97% 15307/15836 [1:18:18<02:08,  4.10it/s]\u001b[A\n",
      "Iteration:  97% 15308/15836 [1:18:18<02:05,  4.22it/s]\u001b[A\n",
      "Iteration:  97% 15309/15836 [1:18:18<02:02,  4.29it/s]\u001b[A\n",
      "Iteration:  97% 15310/15836 [1:18:19<02:22,  3.70it/s]\u001b[A\n",
      "Iteration:  97% 15311/15836 [1:18:19<02:12,  3.96it/s]\u001b[A\n",
      "Iteration:  97% 15312/15836 [1:18:19<02:06,  4.13it/s]\u001b[A\n",
      "Iteration:  97% 15313/15836 [1:18:19<02:03,  4.22it/s]\u001b[A\n",
      "Iteration:  97% 15314/15836 [1:18:20<02:02,  4.27it/s]\u001b[A\n",
      "Iteration:  97% 15315/15836 [1:18:20<02:21,  3.68it/s]\u001b[A\n",
      "Iteration:  97% 15316/15836 [1:18:20<02:12,  3.92it/s]\u001b[A\n",
      "Iteration:  97% 15317/15836 [1:18:20<02:05,  4.12it/s]\u001b[A\n",
      "Iteration:  97% 15318/15836 [1:18:21<02:02,  4.23it/s]\u001b[A\n",
      "Iteration:  97% 15319/15836 [1:18:21<02:00,  4.29it/s]\u001b[A\n",
      "Iteration:  97% 15320/15836 [1:18:21<02:19,  3.70it/s]\u001b[A\n",
      "Iteration:  97% 15321/15836 [1:18:21<02:10,  3.96it/s]\u001b[A\n",
      "Iteration:  97% 15322/15836 [1:18:22<02:04,  4.13it/s]\u001b[A\n",
      "Iteration:  97% 15323/15836 [1:18:22<02:01,  4.23it/s]\u001b[A\n",
      "Iteration:  97% 15324/15836 [1:18:22<01:59,  4.28it/s]\u001b[A\n",
      "Iteration:  97% 15325/15836 [1:18:22<02:18,  3.70it/s]\u001b[A\n",
      "Iteration:  97% 15326/15836 [1:18:23<02:08,  3.95it/s]\u001b[A\n",
      "Iteration:  97% 15327/15836 [1:18:23<02:03,  4.13it/s]\u001b[A\n",
      "Iteration:  97% 15328/15836 [1:18:23<02:00,  4.22it/s]\u001b[A\n",
      "Iteration:  97% 15329/15836 [1:18:23<01:58,  4.29it/s]\u001b[A\n",
      "Iteration:  97% 15330/15836 [1:18:24<02:16,  3.70it/s]\u001b[A\n",
      "Iteration:  97% 15331/15836 [1:18:24<02:07,  3.96it/s]\u001b[A\n",
      "Iteration:  97% 15332/15836 [1:18:24<02:02,  4.12it/s]\u001b[A\n",
      "Iteration:  97% 15333/15836 [1:18:24<01:59,  4.21it/s]\u001b[A\n",
      "Iteration:  97% 15334/15836 [1:18:24<01:56,  4.29it/s]\u001b[A\n",
      "Iteration:  97% 15335/15836 [1:18:25<02:15,  3.69it/s]\u001b[A\n",
      "Iteration:  97% 15336/15836 [1:18:25<02:06,  3.95it/s]\u001b[A\n",
      "Iteration:  97% 15337/15836 [1:18:25<02:00,  4.13it/s]\u001b[A\n",
      "Iteration:  97% 15338/15836 [1:18:26<01:58,  4.20it/s]\u001b[A\n",
      "Iteration:  97% 15339/15836 [1:18:26<01:56,  4.25it/s]\u001b[A\n",
      "Iteration:  97% 15340/15836 [1:18:26<02:14,  3.68it/s]\u001b[A\n",
      "Iteration:  97% 15341/15836 [1:18:26<02:05,  3.93it/s]\u001b[A\n",
      "Iteration:  97% 15342/15836 [1:18:27<02:00,  4.11it/s]\u001b[A\n",
      "Iteration:  97% 15343/15836 [1:18:27<01:57,  4.18it/s]\u001b[A\n",
      "Iteration:  97% 15344/15836 [1:18:27<01:55,  4.25it/s]\u001b[A\n",
      "Iteration:  97% 15345/15836 [1:18:27<02:13,  3.67it/s]\u001b[A\n",
      "Iteration:  97% 15346/15836 [1:18:28<02:04,  3.93it/s]\u001b[A\n",
      "Iteration:  97% 15347/15836 [1:18:28<01:59,  4.10it/s]\u001b[A\n",
      "Iteration:  97% 15348/15836 [1:18:28<01:56,  4.20it/s]\u001b[A\n",
      "Iteration:  97% 15349/15836 [1:18:28<01:53,  4.28it/s]\u001b[A\n",
      "Iteration:  97% 15350/15836 [1:18:29<02:12,  3.67it/s]\u001b[A\n",
      "Iteration:  97% 15351/15836 [1:18:29<02:03,  3.92it/s]\u001b[A\n",
      "Iteration:  97% 15352/15836 [1:18:29<01:57,  4.11it/s]\u001b[A\n",
      "Iteration:  97% 15353/15836 [1:18:29<01:54,  4.23it/s]\u001b[A\n",
      "Iteration:  97% 15354/15836 [1:18:29<01:52,  4.28it/s]\u001b[A\n",
      "Iteration:  97% 15355/15836 [1:18:30<02:10,  3.69it/s]\u001b[A\n",
      "Iteration:  97% 15356/15836 [1:18:30<02:02,  3.93it/s]\u001b[A\n",
      "Iteration:  97% 15357/15836 [1:18:30<01:56,  4.13it/s]\u001b[A\n",
      "Iteration:  97% 15358/15836 [1:18:30<01:53,  4.21it/s]\u001b[A\n",
      "Iteration:  97% 15359/15836 [1:18:31<01:50,  4.30it/s]\u001b[A\n",
      "Iteration:  97% 15360/15836 [1:18:31<02:08,  3.71it/s]\u001b[A\n",
      "Iteration:  97% 15361/15836 [1:18:31<02:00,  3.95it/s]\u001b[A\n",
      "Iteration:  97% 15362/15836 [1:18:31<01:55,  4.12it/s]\u001b[A\n",
      "Iteration:  97% 15363/15836 [1:18:32<01:51,  4.23it/s]\u001b[A\n",
      "Iteration:  97% 15364/15836 [1:18:32<01:49,  4.29it/s]\u001b[A\n",
      "Iteration:  97% 15365/15836 [1:18:32<02:07,  3.69it/s]\u001b[A\n",
      "Iteration:  97% 15366/15836 [1:18:33<01:59,  3.95it/s]\u001b[A\n",
      "Iteration:  97% 15367/15836 [1:18:33<01:53,  4.12it/s]\u001b[A\n",
      "Iteration:  97% 15368/15836 [1:18:33<01:50,  4.23it/s]\u001b[A\n",
      "Iteration:  97% 15369/15836 [1:18:33<01:49,  4.28it/s]\u001b[A\n",
      "Iteration:  97% 15370/15836 [1:18:34<02:06,  3.69it/s]\u001b[A\n",
      "Iteration:  97% 15371/15836 [1:18:34<01:58,  3.92it/s]\u001b[A\n",
      "Iteration:  97% 15372/15836 [1:18:34<01:53,  4.10it/s]\u001b[A\n",
      "Iteration:  97% 15373/15836 [1:18:34<01:50,  4.20it/s]\u001b[A\n",
      "Iteration:  97% 15374/15836 [1:18:34<01:48,  4.27it/s]\u001b[A\n",
      "Iteration:  97% 15375/15836 [1:18:35<02:05,  3.67it/s]\u001b[A\n",
      "Iteration:  97% 15376/15836 [1:18:35<01:57,  3.92it/s]\u001b[A\n",
      "Iteration:  97% 15377/15836 [1:18:35<01:52,  4.07it/s]\u001b[A\n",
      "Iteration:  97% 15378/15836 [1:18:35<01:49,  4.19it/s]\u001b[A\n",
      "Iteration:  97% 15379/15836 [1:18:36<01:47,  4.27it/s]\u001b[A\n",
      "Iteration:  97% 15380/15836 [1:18:36<02:03,  3.68it/s]\u001b[A\n",
      "Iteration:  97% 15381/15836 [1:18:36<01:56,  3.90it/s]\u001b[A\n",
      "Iteration:  97% 15382/15836 [1:18:36<01:51,  4.06it/s]\u001b[A\n",
      "Iteration:  97% 15383/15836 [1:18:37<01:48,  4.17it/s]\u001b[A\n",
      "Iteration:  97% 15384/15836 [1:18:37<01:46,  4.24it/s]\u001b[A\n",
      "Iteration:  97% 15385/15836 [1:18:37<02:02,  3.67it/s]\u001b[A\n",
      "Iteration:  97% 15386/15836 [1:18:37<01:55,  3.89it/s]\u001b[A\n",
      "Iteration:  97% 15387/15836 [1:18:38<01:51,  4.03it/s]\u001b[A\n",
      "Iteration:  97% 15388/15836 [1:18:38<01:48,  4.14it/s]\u001b[A\n",
      "Iteration:  97% 15389/15836 [1:18:38<01:46,  4.21it/s]\u001b[A\n",
      "Iteration:  97% 15390/15836 [1:18:39<02:01,  3.66it/s]\u001b[A\n",
      "Iteration:  97% 15391/15836 [1:18:39<01:54,  3.88it/s]\u001b[A\n",
      "Iteration:  97% 15392/15836 [1:18:39<01:49,  4.04it/s]\u001b[A\n",
      "Iteration:  97% 15393/15836 [1:18:39<01:46,  4.16it/s]\u001b[A\n",
      "Iteration:  97% 15394/15836 [1:18:39<01:44,  4.23it/s]\u001b[A\n",
      "Iteration:  97% 15395/15836 [1:18:40<02:00,  3.67it/s]\u001b[A\n",
      "Iteration:  97% 15396/15836 [1:18:40<01:52,  3.90it/s]\u001b[A\n",
      "Iteration:  97% 15397/15836 [1:18:40<01:47,  4.07it/s]\u001b[A\n",
      "Iteration:  97% 15398/15836 [1:18:40<01:44,  4.17it/s]\u001b[A\n",
      "Iteration:  97% 15399/15836 [1:18:41<01:42,  4.25it/s]\u001b[A\n",
      "Iteration:  97% 15400/15836 [1:18:41<01:58,  3.68it/s]\u001b[A\n",
      "Iteration:  97% 15401/15836 [1:18:41<01:51,  3.91it/s]\u001b[A\n",
      "Iteration:  97% 15402/15836 [1:18:41<01:46,  4.07it/s]\u001b[A\n",
      "Iteration:  97% 15403/15836 [1:18:42<01:43,  4.18it/s]\u001b[A\n",
      "Iteration:  97% 15404/15836 [1:18:42<01:41,  4.24it/s]\u001b[A\n",
      "Iteration:  97% 15405/15836 [1:18:42<01:58,  3.65it/s]\u001b[A\n",
      "Iteration:  97% 15406/15836 [1:18:43<01:50,  3.89it/s]\u001b[A\n",
      "Iteration:  97% 15407/15836 [1:18:43<01:45,  4.06it/s]\u001b[A\n",
      "Iteration:  97% 15408/15836 [1:18:43<01:42,  4.17it/s]\u001b[A\n",
      "Iteration:  97% 15409/15836 [1:18:43<01:40,  4.23it/s]\u001b[A\n",
      "Iteration:  97% 15410/15836 [1:18:44<01:56,  3.66it/s]\u001b[A\n",
      "Iteration:  97% 15411/15836 [1:18:44<01:49,  3.89it/s]\u001b[A\n",
      "Iteration:  97% 15412/15836 [1:18:44<01:44,  4.06it/s]\u001b[A\n",
      "Iteration:  97% 15413/15836 [1:18:44<01:41,  4.17it/s]\u001b[A\n",
      "Iteration:  97% 15414/15836 [1:18:44<01:39,  4.25it/s]\u001b[A\n",
      "Iteration:  97% 15415/15836 [1:18:45<01:54,  3.67it/s]\u001b[A\n",
      "Iteration:  97% 15416/15836 [1:18:45<01:48,  3.88it/s]\u001b[A\n",
      "Iteration:  97% 15417/15836 [1:18:45<01:43,  4.03it/s]\u001b[A\n",
      "Iteration:  97% 15418/15836 [1:18:45<01:40,  4.16it/s]\u001b[A\n",
      "Iteration:  97% 15419/15836 [1:18:46<01:38,  4.22it/s]\u001b[A\n",
      "Iteration:  97% 15420/15836 [1:18:46<01:53,  3.65it/s]\u001b[A\n",
      "Iteration:  97% 15421/15836 [1:18:46<01:47,  3.87it/s]\u001b[A\n",
      "Iteration:  97% 15422/15836 [1:18:46<01:42,  4.04it/s]\u001b[A\n",
      "Iteration:  97% 15423/15836 [1:18:47<01:39,  4.16it/s]\u001b[A\n",
      "Iteration:  97% 15424/15836 [1:18:47<01:37,  4.22it/s]\u001b[A\n",
      "Iteration:  97% 15425/15836 [1:18:47<01:52,  3.65it/s]\u001b[A\n",
      "Iteration:  97% 15426/15836 [1:18:48<01:45,  3.89it/s]\u001b[A\n",
      "Iteration:  97% 15427/15836 [1:18:48<01:40,  4.05it/s]\u001b[A\n",
      "Iteration:  97% 15428/15836 [1:18:48<01:38,  4.16it/s]\u001b[A\n",
      "Iteration:  97% 15429/15836 [1:18:48<01:36,  4.23it/s]\u001b[A\n",
      "Iteration:  97% 15430/15836 [1:18:49<01:51,  3.66it/s]\u001b[A\n",
      "Iteration:  97% 15431/15836 [1:18:49<01:44,  3.88it/s]\u001b[A\n",
      "Iteration:  97% 15432/15836 [1:18:49<01:39,  4.05it/s]\u001b[A\n",
      "Iteration:  97% 15433/15836 [1:18:49<01:36,  4.16it/s]\u001b[A\n",
      "Iteration:  97% 15434/15836 [1:18:49<01:34,  4.25it/s]\u001b[A\n",
      "Iteration:  97% 15435/15836 [1:18:50<01:49,  3.66it/s]\u001b[A\n",
      "Iteration:  97% 15436/15836 [1:18:50<01:43,  3.88it/s]\u001b[A\n",
      "Iteration:  97% 15437/15836 [1:18:50<01:39,  4.03it/s]\u001b[A\n",
      "Iteration:  97% 15438/15836 [1:18:50<01:35,  4.16it/s]\u001b[A\n",
      "Iteration:  97% 15439/15836 [1:18:51<01:34,  4.21it/s]\u001b[A\n",
      "Iteration:  97% 15440/15836 [1:18:51<01:48,  3.66it/s]\u001b[A\n",
      "Iteration:  98% 15441/15836 [1:18:51<01:42,  3.86it/s]\u001b[A\n",
      "Iteration:  98% 15442/15836 [1:18:52<01:37,  4.03it/s]\u001b[A\n",
      "Iteration:  98% 15443/15836 [1:18:52<01:35,  4.12it/s]\u001b[A\n",
      "Iteration:  98% 15444/15836 [1:18:52<01:33,  4.19it/s]\u001b[A\n",
      "Iteration:  98% 15445/15836 [1:18:52<01:47,  3.63it/s]\u001b[A\n",
      "Iteration:  98% 15446/15836 [1:18:53<01:40,  3.87it/s]\u001b[A\n",
      "Iteration:  98% 15447/15836 [1:18:53<01:36,  4.02it/s]\u001b[A\n",
      "Iteration:  98% 15448/15836 [1:18:53<01:34,  4.11it/s]\u001b[A\n",
      "Iteration:  98% 15449/15836 [1:18:53<01:32,  4.18it/s]\u001b[A\n",
      "Iteration:  98% 15450/15836 [1:18:54<01:46,  3.61it/s]\u001b[A\n",
      "Iteration:  98% 15451/15836 [1:18:54<01:40,  3.84it/s]\u001b[A\n",
      "Iteration:  98% 15452/15836 [1:18:54<01:36,  3.99it/s]\u001b[A\n",
      "Iteration:  98% 15453/15836 [1:18:54<01:33,  4.09it/s]\u001b[A\n",
      "Iteration:  98% 15454/15836 [1:18:55<01:31,  4.17it/s]\u001b[A\n",
      "Iteration:  98% 15455/15836 [1:18:55<01:45,  3.62it/s]\u001b[A\n",
      "Iteration:  98% 15456/15836 [1:18:55<01:38,  3.85it/s]\u001b[A\n",
      "Iteration:  98% 15457/15836 [1:18:55<01:34,  4.02it/s]\u001b[A\n",
      "Iteration:  98% 15458/15836 [1:18:56<01:31,  4.13it/s]\u001b[A\n",
      "Iteration:  98% 15459/15836 [1:18:56<01:29,  4.20it/s]\u001b[A\n",
      "Iteration:  98% 15460/15836 [1:18:56<01:43,  3.62it/s]\u001b[A\n",
      "Iteration:  98% 15461/15836 [1:18:56<01:37,  3.86it/s]\u001b[A\n",
      "Iteration:  98% 15462/15836 [1:18:57<01:33,  4.00it/s]\u001b[A\n",
      "Iteration:  98% 15463/15836 [1:18:57<01:30,  4.11it/s]\u001b[A\n",
      "Iteration:  98% 15464/15836 [1:18:57<01:28,  4.18it/s]\u001b[A\n",
      "Iteration:  98% 15465/15836 [1:18:57<01:42,  3.63it/s]\u001b[A\n",
      "Iteration:  98% 15466/15836 [1:18:58<01:36,  3.85it/s]\u001b[A\n",
      "Iteration:  98% 15467/15836 [1:18:58<01:31,  4.01it/s]\u001b[A\n",
      "Iteration:  98% 15468/15836 [1:18:58<01:28,  4.14it/s]\u001b[A\n",
      "Iteration:  98% 15469/15836 [1:18:58<01:27,  4.20it/s]\u001b[A\n",
      "Iteration:  98% 15470/15836 [1:18:59<01:40,  3.63it/s]\u001b[A\n",
      "Iteration:  98% 15471/15836 [1:18:59<01:34,  3.85it/s]\u001b[A\n",
      "Iteration:  98% 15472/15836 [1:18:59<01:30,  4.00it/s]\u001b[A\n",
      "Iteration:  98% 15473/15836 [1:18:59<01:28,  4.12it/s]\u001b[A\n",
      "Iteration:  98% 15474/15836 [1:19:00<01:26,  4.20it/s]\u001b[A\n",
      "Iteration:  98% 15475/15836 [1:19:00<01:38,  3.65it/s]\u001b[A\n",
      "Iteration:  98% 15476/15836 [1:19:00<01:33,  3.85it/s]\u001b[A\n",
      "Iteration:  98% 15477/15836 [1:19:00<01:29,  4.03it/s]\u001b[A\n",
      "Iteration:  98% 15478/15836 [1:19:01<01:26,  4.14it/s]\u001b[A\n",
      "Iteration:  98% 15479/15836 [1:19:01<01:24,  4.21it/s]\u001b[A\n",
      "Iteration:  98% 15480/15836 [1:19:01<01:37,  3.65it/s]\u001b[A\n",
      "Iteration:  98% 15481/15836 [1:19:01<01:31,  3.86it/s]\u001b[A\n",
      "Iteration:  98% 15482/15836 [1:19:02<01:28,  4.02it/s]\u001b[A\n",
      "Iteration:  98% 15483/15836 [1:19:02<01:25,  4.11it/s]\u001b[A\n",
      "Iteration:  98% 15484/15836 [1:19:02<01:24,  4.16it/s]\u001b[A\n",
      "Iteration:  98% 15485/15836 [1:19:02<01:36,  3.63it/s]\u001b[A\n",
      "Iteration:  98% 15486/15836 [1:19:03<01:31,  3.84it/s]\u001b[A\n",
      "Iteration:  98% 15487/15836 [1:19:03<01:26,  4.01it/s]\u001b[A\n",
      "Iteration:  98% 15488/15836 [1:19:03<01:24,  4.12it/s]\u001b[A\n",
      "Iteration:  98% 15489/15836 [1:19:03<01:22,  4.20it/s]\u001b[A\n",
      "Iteration:  98% 15490/15836 [1:19:04<01:35,  3.64it/s]\u001b[A\n",
      "Iteration:  98% 15491/15836 [1:19:04<01:28,  3.88it/s]\u001b[A\n",
      "Iteration:  98% 15492/15836 [1:19:04<01:25,  4.04it/s]\u001b[A\n",
      "Iteration:  98% 15493/15836 [1:19:04<01:22,  4.15it/s]\u001b[A\n",
      "Iteration:  98% 15494/15836 [1:19:05<01:21,  4.22it/s]\u001b[A\n",
      "Iteration:  98% 15495/15836 [1:19:05<01:33,  3.64it/s]\u001b[A\n",
      "Iteration:  98% 15496/15836 [1:19:05<01:27,  3.88it/s]\u001b[A\n",
      "Iteration:  98% 15497/15836 [1:19:05<01:23,  4.04it/s]\u001b[A\n",
      "Iteration:  98% 15498/15836 [1:19:06<01:21,  4.15it/s]\u001b[A\n",
      "Iteration:  98% 15499/15836 [1:19:06<01:19,  4.22it/s]\u001b[A\n",
      "Iteration:  98% 15500/15836 [1:19:06<01:32,  3.63it/s]\u001b[A\n",
      "Iteration:  98% 15501/15836 [1:19:06<01:26,  3.88it/s]\u001b[A\n",
      "Iteration:  98% 15502/15836 [1:19:07<01:23,  4.02it/s]\u001b[A\n",
      "Iteration:  98% 15503/15836 [1:19:07<01:20,  4.11it/s]\u001b[A\n",
      "Iteration:  98% 15504/15836 [1:19:07<01:19,  4.19it/s]\u001b[A\n",
      "Iteration:  98% 15505/15836 [1:19:08<01:30,  3.64it/s]\u001b[A\n",
      "Iteration:  98% 15506/15836 [1:19:08<01:25,  3.85it/s]\u001b[A\n",
      "Iteration:  98% 15507/15836 [1:19:08<01:21,  4.03it/s]\u001b[A\n",
      "Iteration:  98% 15508/15836 [1:19:08<01:19,  4.14it/s]\u001b[A\n",
      "Iteration:  98% 15509/15836 [1:19:08<01:17,  4.21it/s]\u001b[A\n",
      "Iteration:  98% 15510/15836 [1:19:09<01:29,  3.63it/s]\u001b[A\n",
      "Iteration:  98% 15511/15836 [1:19:09<01:23,  3.87it/s]\u001b[A\n",
      "Iteration:  98% 15512/15836 [1:19:09<01:20,  4.04it/s]\u001b[A\n",
      "Iteration:  98% 15513/15836 [1:19:09<01:17,  4.17it/s]\u001b[A\n",
      "Iteration:  98% 15514/15836 [1:19:10<01:16,  4.22it/s]\u001b[A\n",
      "Iteration:  98% 15515/15836 [1:19:10<01:27,  3.65it/s]\u001b[A\n",
      "Iteration:  98% 15516/15836 [1:19:10<01:22,  3.88it/s]\u001b[A\n",
      "Iteration:  98% 15517/15836 [1:19:10<01:18,  4.05it/s]\u001b[A\n",
      "Iteration:  98% 15518/15836 [1:19:11<01:16,  4.16it/s]\u001b[A\n",
      "Iteration:  98% 15519/15836 [1:19:11<01:15,  4.22it/s]\u001b[A\n",
      "Iteration:  98% 15520/15836 [1:19:11<01:26,  3.65it/s]\u001b[A\n",
      "Iteration:  98% 15521/15836 [1:19:12<01:21,  3.87it/s]\u001b[A\n",
      "Iteration:  98% 15522/15836 [1:19:12<01:17,  4.04it/s]\u001b[A\n",
      "Iteration:  98% 15523/15836 [1:19:12<01:15,  4.15it/s]\u001b[A\n",
      "Iteration:  98% 15524/15836 [1:19:12<01:13,  4.22it/s]\u001b[A\n",
      "Iteration:  98% 15525/15836 [1:19:13<01:25,  3.64it/s]\u001b[A\n",
      "Iteration:  98% 15526/15836 [1:19:13<01:20,  3.86it/s]\u001b[A\n",
      "Iteration:  98% 15527/15836 [1:19:13<01:16,  4.03it/s]\u001b[A\n",
      "Iteration:  98% 15528/15836 [1:19:13<01:14,  4.12it/s]\u001b[A\n",
      "Iteration:  98% 15529/15836 [1:19:13<01:13,  4.18it/s]\u001b[A\n",
      "Iteration:  98% 15530/15836 [1:19:14<01:24,  3.63it/s]\u001b[A\n",
      "Iteration:  98% 15531/15836 [1:19:14<01:18,  3.87it/s]\u001b[A\n",
      "Iteration:  98% 15532/15836 [1:19:14<01:15,  4.02it/s]\u001b[A\n",
      "Iteration:  98% 15533/15836 [1:19:14<01:13,  4.12it/s]\u001b[A\n",
      "Iteration:  98% 15534/15836 [1:19:15<01:11,  4.20it/s]\u001b[A\n",
      "Iteration:  98% 15535/15836 [1:19:15<01:22,  3.64it/s]\u001b[A\n",
      "Iteration:  98% 15536/15836 [1:19:15<01:17,  3.85it/s]\u001b[A\n",
      "Iteration:  98% 15537/15836 [1:19:16<01:14,  4.01it/s]\u001b[A\n",
      "Iteration:  98% 15538/15836 [1:19:16<01:12,  4.09it/s]\u001b[A\n",
      "Iteration:  98% 15539/15836 [1:19:16<01:11,  4.18it/s]\u001b[A\n",
      "Iteration:  98% 15540/15836 [1:19:16<01:21,  3.63it/s]\u001b[A\n",
      "Iteration:  98% 15541/15836 [1:19:17<01:16,  3.85it/s]\u001b[A\n",
      "Iteration:  98% 15542/15836 [1:19:17<01:13,  4.02it/s]\u001b[A\n",
      "Iteration:  98% 15543/15836 [1:19:17<01:11,  4.13it/s]\u001b[A\n",
      "Iteration:  98% 15544/15836 [1:19:17<01:09,  4.23it/s]\u001b[A\n",
      "Iteration:  98% 15545/15836 [1:19:18<01:19,  3.65it/s]\u001b[A\n",
      "Iteration:  98% 15546/15836 [1:19:18<01:14,  3.89it/s]\u001b[A\n",
      "Iteration:  98% 15547/15836 [1:19:18<01:11,  4.04it/s]\u001b[A\n",
      "Iteration:  98% 15548/15836 [1:19:18<01:09,  4.17it/s]\u001b[A\n",
      "Iteration:  98% 15549/15836 [1:19:18<01:08,  4.22it/s]\u001b[A\n",
      "Iteration:  98% 15550/15836 [1:19:19<01:18,  3.65it/s]\u001b[A\n",
      "Iteration:  98% 15551/15836 [1:19:19<01:13,  3.88it/s]\u001b[A\n",
      "Iteration:  98% 15552/15836 [1:19:19<01:10,  4.03it/s]\u001b[A\n",
      "Iteration:  98% 15553/15836 [1:19:20<01:08,  4.15it/s]\u001b[A\n",
      "Iteration:  98% 15554/15836 [1:19:20<01:06,  4.23it/s]\u001b[A\n",
      "Iteration:  98% 15555/15836 [1:19:20<01:16,  3.66it/s]\u001b[A\n",
      "Iteration:  98% 15556/15836 [1:19:20<01:12,  3.89it/s]\u001b[A\n",
      "Iteration:  98% 15557/15836 [1:19:21<01:09,  4.04it/s]\u001b[A\n",
      "Iteration:  98% 15558/15836 [1:19:21<01:07,  4.14it/s]\u001b[A\n",
      "Iteration:  98% 15559/15836 [1:19:21<01:05,  4.23it/s]\u001b[A\n",
      "Iteration:  98% 15560/15836 [1:19:21<01:15,  3.66it/s]\u001b[A\n",
      "Iteration:  98% 15561/15836 [1:19:22<01:10,  3.88it/s]\u001b[A\n",
      "Iteration:  98% 15562/15836 [1:19:22<01:08,  4.03it/s]\u001b[A\n",
      "Iteration:  98% 15563/15836 [1:19:22<01:05,  4.15it/s]\u001b[A\n",
      "Iteration:  98% 15564/15836 [1:19:22<01:04,  4.21it/s]\u001b[A\n",
      "Iteration:  98% 15565/15836 [1:19:23<01:14,  3.65it/s]\u001b[A\n",
      "Iteration:  98% 15566/15836 [1:19:23<01:09,  3.88it/s]\u001b[A\n",
      "Iteration:  98% 15567/15836 [1:19:23<01:06,  4.05it/s]\u001b[A\n",
      "Iteration:  98% 15568/15836 [1:19:23<01:04,  4.16it/s]\u001b[A\n",
      "Iteration:  98% 15569/15836 [1:19:24<01:03,  4.22it/s]\u001b[A\n",
      "Iteration:  98% 15570/15836 [1:19:24<01:13,  3.64it/s]\u001b[A\n",
      "Iteration:  98% 15571/15836 [1:19:24<01:07,  3.90it/s]\u001b[A\n",
      "Iteration:  98% 15572/15836 [1:19:24<01:05,  4.05it/s]\u001b[A\n",
      "Iteration:  98% 15573/15836 [1:19:25<01:03,  4.16it/s]\u001b[A\n",
      "Iteration:  98% 15574/15836 [1:19:25<01:02,  4.21it/s]\u001b[A\n",
      "Iteration:  98% 15575/15836 [1:19:25<01:11,  3.65it/s]\u001b[A\n",
      "Iteration:  98% 15576/15836 [1:19:25<01:06,  3.90it/s]\u001b[A\n",
      "Iteration:  98% 15577/15836 [1:19:26<01:04,  4.05it/s]\u001b[A\n",
      "Iteration:  98% 15578/15836 [1:19:26<01:02,  4.16it/s]\u001b[A\n",
      "Iteration:  98% 15579/15836 [1:19:26<01:00,  4.25it/s]\u001b[A\n",
      "Iteration:  98% 15580/15836 [1:19:26<01:09,  3.68it/s]\u001b[A\n",
      "Iteration:  98% 15581/15836 [1:19:27<01:05,  3.92it/s]\u001b[A\n",
      "Iteration:  98% 15582/15836 [1:19:27<01:02,  4.07it/s]\u001b[A\n",
      "Iteration:  98% 15583/15836 [1:19:27<01:00,  4.18it/s]\u001b[A\n",
      "Iteration:  98% 15584/15836 [1:19:27<00:59,  4.23it/s]\u001b[A\n",
      "Iteration:  98% 15585/15836 [1:19:28<01:08,  3.65it/s]\u001b[A\n",
      "Iteration:  98% 15586/15836 [1:19:28<01:04,  3.89it/s]\u001b[A\n",
      "Iteration:  98% 15587/15836 [1:19:28<01:01,  4.06it/s]\u001b[A\n",
      "Iteration:  98% 15588/15836 [1:19:28<00:59,  4.17it/s]\u001b[A\n",
      "Iteration:  98% 15589/15836 [1:19:29<00:58,  4.22it/s]\u001b[A\n",
      "Iteration:  98% 15590/15836 [1:19:29<01:07,  3.67it/s]\u001b[A\n",
      "Iteration:  98% 15591/15836 [1:19:29<01:02,  3.91it/s]\u001b[A\n",
      "Iteration:  98% 15592/15836 [1:19:29<00:59,  4.07it/s]\u001b[A\n",
      "Iteration:  98% 15593/15836 [1:19:30<00:58,  4.18it/s]\u001b[A\n",
      "Iteration:  98% 15594/15836 [1:19:30<00:56,  4.26it/s]\u001b[A\n",
      "Iteration:  98% 15595/15836 [1:19:30<01:05,  3.66it/s]\u001b[A\n",
      "Iteration:  98% 15596/15836 [1:19:30<01:01,  3.89it/s]\u001b[A\n",
      "Iteration:  98% 15597/15836 [1:19:31<00:58,  4.07it/s]\u001b[A\n",
      "Iteration:  98% 15598/15836 [1:19:31<00:57,  4.15it/s]\u001b[A\n",
      "Iteration:  99% 15599/15836 [1:19:31<00:56,  4.21it/s]\u001b[A\n",
      "Iteration:  99% 15600/15836 [1:19:31<01:04,  3.66it/s]\u001b[A\n",
      "Iteration:  99% 15601/15836 [1:19:32<01:00,  3.90it/s]\u001b[A\n",
      "Iteration:  99% 15602/15836 [1:19:32<00:57,  4.04it/s]\u001b[A\n",
      "Iteration:  99% 15603/15836 [1:19:32<00:56,  4.15it/s]\u001b[A\n",
      "Iteration:  99% 15604/15836 [1:19:32<00:55,  4.21it/s]\u001b[A\n",
      "Iteration:  99% 15605/15836 [1:19:33<01:03,  3.66it/s]\u001b[A\n",
      "Iteration:  99% 15606/15836 [1:19:33<00:58,  3.91it/s]\u001b[A\n",
      "Iteration:  99% 15607/15836 [1:19:33<00:56,  4.07it/s]\u001b[A\n",
      "Iteration:  99% 15608/15836 [1:19:33<00:54,  4.19it/s]\u001b[A\n",
      "Iteration:  99% 15609/15836 [1:19:34<00:53,  4.27it/s]\u001b[A\n",
      "Iteration:  99% 15610/15836 [1:19:34<01:01,  3.68it/s]\u001b[A\n",
      "Iteration:  99% 15611/15836 [1:19:34<00:57,  3.91it/s]\u001b[A\n",
      "Iteration:  99% 15612/15836 [1:19:34<00:54,  4.09it/s]\u001b[A\n",
      "Iteration:  99% 15613/15836 [1:19:35<00:53,  4.16it/s]\u001b[A\n",
      "Iteration:  99% 15614/15836 [1:19:35<00:52,  4.23it/s]\u001b[A\n",
      "Iteration:  99% 15615/15836 [1:19:35<01:00,  3.67it/s]\u001b[A\n",
      "Iteration:  99% 15616/15836 [1:19:35<00:56,  3.91it/s]\u001b[A\n",
      "Iteration:  99% 15617/15836 [1:19:36<00:54,  4.05it/s]\u001b[A\n",
      "Iteration:  99% 15618/15836 [1:19:36<00:52,  4.15it/s]\u001b[A\n",
      "Iteration:  99% 15619/15836 [1:19:36<00:51,  4.24it/s]\u001b[A\n",
      "Iteration:  99% 15620/15836 [1:19:36<00:59,  3.66it/s]\u001b[A\n",
      "Iteration:  99% 15621/15836 [1:19:37<00:55,  3.90it/s]\u001b[A\n",
      "Iteration:  99% 15622/15836 [1:19:37<00:52,  4.06it/s]\u001b[A\n",
      "Iteration:  99% 15623/15836 [1:19:37<00:51,  4.18it/s]\u001b[A\n",
      "Iteration:  99% 15624/15836 [1:19:37<00:49,  4.26it/s]\u001b[A\n",
      "Iteration:  99% 15625/15836 [1:19:38<00:57,  3.65it/s]\u001b[A\n",
      "Iteration:  99% 15626/15836 [1:19:38<00:53,  3.89it/s]\u001b[A\n",
      "Iteration:  99% 15627/15836 [1:19:38<00:51,  4.08it/s]\u001b[A\n",
      "Iteration:  99% 15628/15836 [1:19:38<00:49,  4.18it/s]\u001b[A\n",
      "Iteration:  99% 15629/15836 [1:19:39<00:48,  4.26it/s]\u001b[A\n",
      "Iteration:  99% 15630/15836 [1:19:39<00:55,  3.69it/s]\u001b[A\n",
      "Iteration:  99% 15631/15836 [1:19:39<00:52,  3.92it/s]\u001b[A\n",
      "Iteration:  99% 15632/15836 [1:19:39<00:49,  4.10it/s]\u001b[A\n",
      "Iteration:  99% 15633/15836 [1:19:40<00:48,  4.20it/s]\u001b[A\n",
      "Iteration:  99% 15634/15836 [1:19:40<00:47,  4.28it/s]\u001b[A\n",
      "Iteration:  99% 15635/15836 [1:19:40<00:54,  3.69it/s]\u001b[A\n",
      "Iteration:  99% 15636/15836 [1:19:40<00:51,  3.92it/s]\u001b[A\n",
      "Iteration:  99% 15637/15836 [1:19:41<00:49,  4.05it/s]\u001b[A\n",
      "Iteration:  99% 15638/15836 [1:19:41<00:47,  4.17it/s]\u001b[A\n",
      "Iteration:  99% 15639/15836 [1:19:41<00:46,  4.25it/s]\u001b[A\n",
      "Iteration:  99% 15640/15836 [1:19:41<00:53,  3.66it/s]\u001b[A\n",
      "Iteration:  99% 15641/15836 [1:19:42<00:50,  3.88it/s]\u001b[A\n",
      "Iteration:  99% 15642/15836 [1:19:42<00:47,  4.05it/s]\u001b[A\n",
      "Iteration:  99% 15643/15836 [1:19:42<00:46,  4.14it/s]\u001b[A\n",
      "Iteration:  99% 15644/15836 [1:19:42<00:45,  4.22it/s]\u001b[A\n",
      "Iteration:  99% 15645/15836 [1:19:43<00:52,  3.66it/s]\u001b[A\n",
      "Iteration:  99% 15646/15836 [1:19:43<00:48,  3.89it/s]\u001b[A\n",
      "Iteration:  99% 15647/15836 [1:19:43<00:46,  4.05it/s]\u001b[A\n",
      "Iteration:  99% 15648/15836 [1:19:43<00:45,  4.15it/s]\u001b[A\n",
      "Iteration:  99% 15649/15836 [1:19:44<00:44,  4.23it/s]\u001b[A\n",
      "Iteration:  99% 15650/15836 [1:19:44<00:50,  3.67it/s]\u001b[A\n",
      "Iteration:  99% 15651/15836 [1:19:44<00:47,  3.90it/s]\u001b[A\n",
      "Iteration:  99% 15652/15836 [1:19:44<00:45,  4.07it/s]\u001b[A\n",
      "Iteration:  99% 15653/15836 [1:19:45<00:43,  4.18it/s]\u001b[A\n",
      "Iteration:  99% 15654/15836 [1:19:45<00:42,  4.25it/s]\u001b[A\n",
      "Iteration:  99% 15655/15836 [1:19:45<00:49,  3.66it/s]\u001b[A\n",
      "Iteration:  99% 15656/15836 [1:19:45<00:45,  3.92it/s]\u001b[A\n",
      "Iteration:  99% 15657/15836 [1:19:46<00:43,  4.10it/s]\u001b[A\n",
      "Iteration:  99% 15658/15836 [1:19:46<00:42,  4.20it/s]\u001b[A\n",
      "Iteration:  99% 15659/15836 [1:19:46<00:41,  4.25it/s]\u001b[A\n",
      "Iteration:  99% 15660/15836 [1:19:46<00:48,  3.65it/s]\u001b[A\n",
      "Iteration:  99% 15661/15836 [1:19:47<00:44,  3.90it/s]\u001b[A\n",
      "Iteration:  99% 15662/15836 [1:19:47<00:42,  4.07it/s]\u001b[A\n",
      "Iteration:  99% 15663/15836 [1:19:47<00:41,  4.18it/s]\u001b[A\n",
      "Iteration:  99% 15664/15836 [1:19:47<00:40,  4.24it/s]\u001b[A\n",
      "Iteration:  99% 15665/15836 [1:19:48<00:46,  3.67it/s]\u001b[A\n",
      "Iteration:  99% 15666/15836 [1:19:48<00:43,  3.90it/s]\u001b[A\n",
      "Iteration:  99% 15667/15836 [1:19:48<00:41,  4.08it/s]\u001b[A\n",
      "Iteration:  99% 15668/15836 [1:19:48<00:40,  4.16it/s]\u001b[A\n",
      "Iteration:  99% 15669/15836 [1:19:49<00:39,  4.23it/s]\u001b[A\n",
      "Iteration:  99% 15670/15836 [1:19:49<00:45,  3.67it/s]\u001b[A\n",
      "Iteration:  99% 15671/15836 [1:19:49<00:42,  3.91it/s]\u001b[A\n",
      "Iteration:  99% 15672/15836 [1:19:49<00:40,  4.09it/s]\u001b[A\n",
      "Iteration:  99% 15673/15836 [1:19:50<00:38,  4.18it/s]\u001b[A\n",
      "Iteration:  99% 15674/15836 [1:19:50<00:38,  4.25it/s]\u001b[A\n",
      "Iteration:  99% 15675/15836 [1:19:50<00:44,  3.65it/s]\u001b[A\n",
      "Iteration:  99% 15676/15836 [1:19:50<00:40,  3.91it/s]\u001b[A\n",
      "Iteration:  99% 15677/15836 [1:19:51<00:38,  4.08it/s]\u001b[A\n",
      "Iteration:  99% 15678/15836 [1:19:51<00:37,  4.17it/s]\u001b[A\n",
      "Iteration:  99% 15679/15836 [1:19:51<00:36,  4.26it/s]\u001b[A\n",
      "Iteration:  99% 15680/15836 [1:19:51<00:42,  3.69it/s]\u001b[A\n",
      "Iteration:  99% 15681/15836 [1:19:52<00:39,  3.92it/s]\u001b[A\n",
      "Iteration:  99% 15682/15836 [1:19:52<00:37,  4.07it/s]\u001b[A\n",
      "Iteration:  99% 15683/15836 [1:19:52<00:36,  4.15it/s]\u001b[A\n",
      "Iteration:  99% 15684/15836 [1:19:52<00:35,  4.23it/s]\u001b[A\n",
      "Iteration:  99% 15685/15836 [1:19:53<00:41,  3.67it/s]\u001b[A\n",
      "Iteration:  99% 15686/15836 [1:19:53<00:38,  3.92it/s]\u001b[A\n",
      "Iteration:  99% 15687/15836 [1:19:53<00:36,  4.07it/s]\u001b[A\n",
      "Iteration:  99% 15688/15836 [1:19:53<00:35,  4.16it/s]\u001b[A\n",
      "Iteration:  99% 15689/15836 [1:19:54<00:34,  4.22it/s]\u001b[A\n",
      "Iteration:  99% 15690/15836 [1:19:54<00:39,  3.66it/s]\u001b[A\n",
      "Iteration:  99% 15691/15836 [1:19:54<00:37,  3.91it/s]\u001b[A\n",
      "Iteration:  99% 15692/15836 [1:19:54<00:35,  4.08it/s]\u001b[A\n",
      "Iteration:  99% 15693/15836 [1:19:55<00:34,  4.17it/s]\u001b[A\n",
      "Iteration:  99% 15694/15836 [1:19:55<00:33,  4.25it/s]\u001b[A\n",
      "Iteration:  99% 15695/15836 [1:19:55<00:38,  3.67it/s]\u001b[A\n",
      "Iteration:  99% 15696/15836 [1:19:55<00:35,  3.91it/s]\u001b[A\n",
      "Iteration:  99% 15697/15836 [1:19:56<00:34,  4.06it/s]\u001b[A\n",
      "Iteration:  99% 15698/15836 [1:19:56<00:33,  4.17it/s]\u001b[A\n",
      "Iteration:  99% 15699/15836 [1:19:56<00:32,  4.25it/s]\u001b[A\n",
      "Iteration:  99% 15700/15836 [1:19:56<00:37,  3.66it/s]\u001b[A\n",
      "Iteration:  99% 15701/15836 [1:19:57<00:34,  3.90it/s]\u001b[A\n",
      "Iteration:  99% 15702/15836 [1:19:57<00:33,  4.05it/s]\u001b[A\n",
      "Iteration:  99% 15703/15836 [1:19:57<00:31,  4.16it/s]\u001b[A\n",
      "Iteration:  99% 15704/15836 [1:19:57<00:31,  4.22it/s]\u001b[A\n",
      "Iteration:  99% 15705/15836 [1:19:58<00:35,  3.66it/s]\u001b[A\n",
      "Iteration:  99% 15706/15836 [1:19:58<00:33,  3.88it/s]\u001b[A\n",
      "Iteration:  99% 15707/15836 [1:19:58<00:31,  4.04it/s]\u001b[A\n",
      "Iteration:  99% 15708/15836 [1:19:58<00:30,  4.15it/s]\u001b[A\n",
      "Iteration:  99% 15709/15836 [1:19:59<00:30,  4.22it/s]\u001b[A\n",
      "Iteration:  99% 15710/15836 [1:19:59<00:34,  3.64it/s]\u001b[A\n",
      "Iteration:  99% 15711/15836 [1:19:59<00:32,  3.88it/s]\u001b[A\n",
      "Iteration:  99% 15712/15836 [1:19:59<00:30,  4.05it/s]\u001b[A\n",
      "Iteration:  99% 15713/15836 [1:20:00<00:29,  4.16it/s]\u001b[A\n",
      "Iteration:  99% 15714/15836 [1:20:00<00:28,  4.25it/s]\u001b[A\n",
      "Iteration:  99% 15715/15836 [1:20:00<00:32,  3.67it/s]\u001b[A\n",
      "Iteration:  99% 15716/15836 [1:20:00<00:30,  3.92it/s]\u001b[A\n",
      "Iteration:  99% 15717/15836 [1:20:01<00:29,  4.07it/s]\u001b[A\n",
      "Iteration:  99% 15718/15836 [1:20:01<00:28,  4.16it/s]\u001b[A\n",
      "Iteration:  99% 15719/15836 [1:20:01<00:27,  4.20it/s]\u001b[A\n",
      "Iteration:  99% 15720/15836 [1:20:01<00:31,  3.65it/s]\u001b[A\n",
      "Iteration:  99% 15721/15836 [1:20:02<00:29,  3.88it/s]\u001b[A\n",
      "Iteration:  99% 15722/15836 [1:20:02<00:28,  4.05it/s]\u001b[A\n",
      "Iteration:  99% 15723/15836 [1:20:02<00:27,  4.14it/s]\u001b[A\n",
      "Iteration:  99% 15724/15836 [1:20:02<00:26,  4.23it/s]\u001b[A\n",
      "Iteration:  99% 15725/15836 [1:20:03<00:30,  3.67it/s]\u001b[A\n",
      "Iteration:  99% 15726/15836 [1:20:03<00:28,  3.89it/s]\u001b[A\n",
      "Iteration:  99% 15727/15836 [1:20:03<00:27,  4.03it/s]\u001b[A\n",
      "Iteration:  99% 15728/15836 [1:20:03<00:26,  4.15it/s]\u001b[A\n",
      "Iteration:  99% 15729/15836 [1:20:04<00:25,  4.23it/s]\u001b[A\n",
      "Iteration:  99% 15730/15836 [1:20:04<00:28,  3.67it/s]\u001b[A\n",
      "Iteration:  99% 15731/15836 [1:20:04<00:27,  3.88it/s]\u001b[A\n",
      "Iteration:  99% 15732/15836 [1:20:04<00:25,  4.03it/s]\u001b[A\n",
      "Iteration:  99% 15733/15836 [1:20:05<00:24,  4.17it/s]\u001b[A\n",
      "Iteration:  99% 15734/15836 [1:20:05<00:24,  4.21it/s]\u001b[A\n",
      "Iteration:  99% 15735/15836 [1:20:05<00:27,  3.65it/s]\u001b[A\n",
      "Iteration:  99% 15736/15836 [1:20:05<00:25,  3.87it/s]\u001b[A\n",
      "Iteration:  99% 15737/15836 [1:20:06<00:24,  4.06it/s]\u001b[A\n",
      "Iteration:  99% 15738/15836 [1:20:06<00:23,  4.16it/s]\u001b[A\n",
      "Iteration:  99% 15739/15836 [1:20:06<00:23,  4.20it/s]\u001b[A\n",
      "Iteration:  99% 15740/15836 [1:20:06<00:26,  3.64it/s]\u001b[A\n",
      "Iteration:  99% 15741/15836 [1:20:07<00:24,  3.89it/s]\u001b[A\n",
      "Iteration:  99% 15742/15836 [1:20:07<00:23,  4.05it/s]\u001b[A\n",
      "Iteration:  99% 15743/15836 [1:20:07<00:22,  4.16it/s]\u001b[A\n",
      "Iteration:  99% 15744/15836 [1:20:07<00:21,  4.26it/s]\u001b[A\n",
      "Iteration:  99% 15745/15836 [1:20:08<00:24,  3.66it/s]\u001b[A\n",
      "Iteration:  99% 15746/15836 [1:20:08<00:23,  3.88it/s]\u001b[A\n",
      "Iteration:  99% 15747/15836 [1:20:08<00:22,  4.04it/s]\u001b[A\n",
      "Iteration:  99% 15748/15836 [1:20:08<00:21,  4.16it/s]\u001b[A\n",
      "Iteration:  99% 15749/15836 [1:20:09<00:20,  4.22it/s]\u001b[A\n",
      "Iteration:  99% 15750/15836 [1:20:09<00:23,  3.65it/s]\u001b[A\n",
      "Iteration:  99% 15751/15836 [1:20:09<00:21,  3.88it/s]\u001b[A\n",
      "Iteration:  99% 15752/15836 [1:20:09<00:20,  4.06it/s]\u001b[A\n",
      "Iteration:  99% 15753/15836 [1:20:10<00:19,  4.16it/s]\u001b[A\n",
      "Iteration:  99% 15754/15836 [1:20:10<00:19,  4.25it/s]\u001b[A\n",
      "Iteration:  99% 15755/15836 [1:20:10<00:22,  3.67it/s]\u001b[A\n",
      "Iteration:  99% 15756/15836 [1:20:10<00:20,  3.91it/s]\u001b[A\n",
      "Iteration: 100% 15757/15836 [1:20:11<00:19,  4.06it/s]\u001b[A\n",
      "Iteration: 100% 15758/15836 [1:20:11<00:18,  4.14it/s]\u001b[A\n",
      "Iteration: 100% 15759/15836 [1:20:11<00:18,  4.23it/s]\u001b[A\n",
      "Iteration: 100% 15760/15836 [1:20:11<00:20,  3.66it/s]\u001b[A\n",
      "Iteration: 100% 15761/15836 [1:20:12<00:19,  3.89it/s]\u001b[A\n",
      "Iteration: 100% 15762/15836 [1:20:12<00:18,  4.04it/s]\u001b[A\n",
      "Iteration: 100% 15763/15836 [1:20:12<00:17,  4.13it/s]\u001b[A\n",
      "Iteration: 100% 15764/15836 [1:20:12<00:17,  4.21it/s]\u001b[A\n",
      "Iteration: 100% 15765/15836 [1:20:13<00:19,  3.66it/s]\u001b[A\n",
      "Iteration: 100% 15766/15836 [1:20:13<00:18,  3.88it/s]\u001b[A\n",
      "Iteration: 100% 15767/15836 [1:20:13<00:17,  4.02it/s]\u001b[A\n",
      "Iteration: 100% 15768/15836 [1:20:13<00:16,  4.13it/s]\u001b[A\n",
      "Iteration: 100% 15769/15836 [1:20:14<00:15,  4.21it/s]\u001b[A\n",
      "Iteration: 100% 15770/15836 [1:20:14<00:18,  3.64it/s]\u001b[A\n",
      "Iteration: 100% 15771/15836 [1:20:14<00:16,  3.87it/s]\u001b[A\n",
      "Iteration: 100% 15772/15836 [1:20:14<00:15,  4.04it/s]\u001b[A\n",
      "Iteration: 100% 15773/15836 [1:20:15<00:15,  4.15it/s]\u001b[A\n",
      "Iteration: 100% 15774/15836 [1:20:15<00:14,  4.23it/s]\u001b[A\n",
      "Iteration: 100% 15775/15836 [1:20:15<00:16,  3.66it/s]\u001b[A\n",
      "Iteration: 100% 15776/15836 [1:20:15<00:15,  3.88it/s]\u001b[A\n",
      "Iteration: 100% 15777/15836 [1:20:16<00:14,  4.05it/s]\u001b[A\n",
      "Iteration: 100% 15778/15836 [1:20:16<00:13,  4.17it/s]\u001b[A\n",
      "Iteration: 100% 15779/15836 [1:20:16<00:13,  4.23it/s]\u001b[A\n",
      "Iteration: 100% 15780/15836 [1:20:16<00:15,  3.66it/s]\u001b[A\n",
      "Iteration: 100% 15781/15836 [1:20:17<00:14,  3.86it/s]\u001b[A\n",
      "Iteration: 100% 15782/15836 [1:20:17<00:13,  4.05it/s]\u001b[A\n",
      "Iteration: 100% 15783/15836 [1:20:17<00:12,  4.16it/s]\u001b[A\n",
      "Iteration: 100% 15784/15836 [1:20:17<00:12,  4.23it/s]\u001b[A\n",
      "Iteration: 100% 15785/15836 [1:20:18<00:13,  3.66it/s]\u001b[A\n",
      "Iteration: 100% 15786/15836 [1:20:18<00:12,  3.87it/s]\u001b[A\n",
      "Iteration: 100% 15787/15836 [1:20:18<00:12,  4.06it/s]\u001b[A\n",
      "Iteration: 100% 15788/15836 [1:20:18<00:11,  4.16it/s]\u001b[A\n",
      "Iteration: 100% 15789/15836 [1:20:19<00:11,  4.25it/s]\u001b[A\n",
      "Iteration: 100% 15790/15836 [1:20:19<00:12,  3.66it/s]\u001b[A\n",
      "Iteration: 100% 15791/15836 [1:20:19<00:11,  3.88it/s]\u001b[A\n",
      "Iteration: 100% 15792/15836 [1:20:19<00:10,  4.03it/s]\u001b[A\n",
      "Iteration: 100% 15793/15836 [1:20:20<00:10,  4.14it/s]\u001b[A\n",
      "Iteration: 100% 15794/15836 [1:20:20<00:10,  4.20it/s]\u001b[A\n",
      "Iteration: 100% 15795/15836 [1:20:20<00:11,  3.64it/s]\u001b[A\n",
      "Iteration: 100% 15796/15836 [1:20:20<00:10,  3.88it/s]\u001b[A\n",
      "Iteration: 100% 15797/15836 [1:20:21<00:09,  4.05it/s]\u001b[A\n",
      "Iteration: 100% 15798/15836 [1:20:21<00:09,  4.14it/s]\u001b[A\n",
      "Iteration: 100% 15799/15836 [1:20:21<00:08,  4.21it/s]\u001b[A\n",
      "Iteration: 100% 15800/15836 [1:20:21<00:09,  3.65it/s]\u001b[A\n",
      "Iteration: 100% 15801/15836 [1:20:22<00:09,  3.88it/s]\u001b[A\n",
      "Iteration: 100% 15802/15836 [1:20:22<00:08,  4.03it/s]\u001b[A\n",
      "Iteration: 100% 15803/15836 [1:20:22<00:07,  4.15it/s]\u001b[A\n",
      "Iteration: 100% 15804/15836 [1:20:22<00:07,  4.22it/s]\u001b[A\n",
      "Iteration: 100% 15805/15836 [1:20:23<00:08,  3.65it/s]\u001b[A\n",
      "Iteration: 100% 15806/15836 [1:20:23<00:07,  3.90it/s]\u001b[A\n",
      "Iteration: 100% 15807/15836 [1:20:23<00:07,  4.05it/s]\u001b[A\n",
      "Iteration: 100% 15808/15836 [1:20:23<00:06,  4.16it/s]\u001b[A\n",
      "Iteration: 100% 15809/15836 [1:20:24<00:06,  4.22it/s]\u001b[A\n",
      "Iteration: 100% 15810/15836 [1:20:24<00:07,  3.64it/s]\u001b[A\n",
      "Iteration: 100% 15811/15836 [1:20:24<00:06,  3.88it/s]\u001b[A\n",
      "Iteration: 100% 15812/15836 [1:20:24<00:05,  4.05it/s]\u001b[A\n",
      "Iteration: 100% 15813/15836 [1:20:25<00:05,  4.17it/s]\u001b[A\n",
      "Iteration: 100% 15814/15836 [1:20:25<00:05,  4.24it/s]\u001b[A\n",
      "Iteration: 100% 15815/15836 [1:20:25<00:05,  3.67it/s]\u001b[A\n",
      "Iteration: 100% 15816/15836 [1:20:25<00:05,  3.88it/s]\u001b[A\n",
      "Iteration: 100% 15817/15836 [1:20:26<00:04,  4.05it/s]\u001b[A\n",
      "Iteration: 100% 15818/15836 [1:20:26<00:04,  4.17it/s]\u001b[A\n",
      "Iteration: 100% 15819/15836 [1:20:26<00:04,  4.25it/s]\u001b[A\n",
      "Iteration: 100% 15820/15836 [1:20:27<00:04,  3.67it/s]\u001b[A\n",
      "Iteration: 100% 15821/15836 [1:20:27<00:03,  3.88it/s]\u001b[A\n",
      "Iteration: 100% 15822/15836 [1:20:27<00:03,  4.04it/s]\u001b[A\n",
      "Iteration: 100% 15823/15836 [1:20:27<00:03,  4.17it/s]\u001b[A\n",
      "Iteration: 100% 15824/15836 [1:20:27<00:02,  4.24it/s]\u001b[A\n",
      "Iteration: 100% 15825/15836 [1:20:28<00:03,  3.66it/s]\u001b[A\n",
      "Iteration: 100% 15826/15836 [1:20:28<00:02,  3.89it/s]\u001b[A\n",
      "Iteration: 100% 15827/15836 [1:20:28<00:02,  4.06it/s]\u001b[A\n",
      "Iteration: 100% 15828/15836 [1:20:28<00:01,  4.16it/s]\u001b[A\n",
      "Iteration: 100% 15829/15836 [1:20:29<00:01,  4.24it/s]\u001b[A\n",
      "Iteration: 100% 15830/15836 [1:20:29<00:01,  3.66it/s]\u001b[A\n",
      "Iteration: 100% 15831/15836 [1:20:29<00:01,  3.89it/s]\u001b[A\n",
      "Iteration: 100% 15832/15836 [1:20:29<00:00,  4.05it/s]\u001b[A\n",
      "Iteration: 100% 15833/15836 [1:20:30<00:00,  4.15it/s]\u001b[A\n",
      "Iteration: 100% 15834/15836 [1:20:30<00:00,  4.22it/s]\u001b[A\n",
      "Iteration: 100% 15835/15836 [1:20:30<00:00,  3.65it/s]\u001b[A\n",
      "Iteration: 100% 15836/15836 [1:20:30<00:00,  3.28it/s]\n",
      "Epoch: 100% 1/1 [1:20:30<00:00, 4830.92s/it]\n",
      "04/01/2020 15:31:38 - INFO - __main__ -    global_step = 3167, average loss = 3.090807752792565\n",
      "04/01/2020 15:31:38 - INFO - __main__ -   Saving model checkpoint to /content/drive/My Drive/finetuned_models/presidential_speeches\n",
      "04/01/2020 15:31:38 - INFO - transformers.configuration_utils -   Configuration saved in /content/drive/My Drive/finetuned_models/presidential_speeches/config.json\n",
      "04/01/2020 15:31:47 - INFO - transformers.modeling_utils -   Model weights saved in /content/drive/My Drive/finetuned_models/presidential_speeches/pytorch_model.bin\n",
      "04/01/2020 15:31:47 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/finetuned_models/presidential_speeches/config.json\n",
      "04/01/2020 15:31:47 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"_num_labels\": 2,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 1024,\n",
      "  \"n_head\": 16,\n",
      "  \"n_layer\": 24,\n",
      "  \"n_positions\": 1024,\n",
      "  \"n_special\": 0,\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"predict_special_tokens\": true,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "04/01/2020 15:31:47 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/finetuned_models/presidential_speeches/pytorch_model.bin\n",
      "04/01/2020 15:32:39 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/finetuned_models/presidential_speeches/config.json\n",
      "04/01/2020 15:32:39 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"_num_labels\": 2,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 1024,\n",
      "  \"n_head\": 16,\n",
      "  \"n_layer\": 24,\n",
      "  \"n_positions\": 1024,\n",
      "  \"n_special\": 0,\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"predict_special_tokens\": true,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "04/01/2020 15:32:39 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/finetuned_models/presidential_speeches' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/My Drive/finetuned_models/presidential_speeches' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "04/01/2020 15:32:39 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/finetuned_models/presidential_speeches/added_tokens.json. We won't load it.\n",
      "04/01/2020 15:32:39 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/finetuned_models/presidential_speeches/vocab.json\n",
      "04/01/2020 15:32:39 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/finetuned_models/presidential_speeches/merges.txt\n",
      "04/01/2020 15:32:39 - INFO - transformers.tokenization_utils -   loading file None\n",
      "04/01/2020 15:32:39 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/finetuned_models/presidential_speeches/special_tokens_map.json\n",
      "04/01/2020 15:32:39 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/finetuned_models/presidential_speeches/tokenizer_config.json\n",
      "04/01/2020 15:32:40 - INFO - __main__ -   Evaluate the following checkpoints: ['/content/drive/My Drive/finetuned_models/presidential_speeches']\n",
      "04/01/2020 15:32:40 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/finetuned_models/presidential_speeches/config.json\n",
      "04/01/2020 15:32:40 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
      "  \"_num_labels\": 2,\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"finetuning_task\": null,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 1024,\n",
      "  \"n_head\": 16,\n",
      "  \"n_layer\": 24,\n",
      "  \"n_positions\": 1024,\n",
      "  \"n_special\": 0,\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": null,\n",
      "  \"predict_special_tokens\": true,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "04/01/2020 15:32:40 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/finetuned_models/presidential_speeches/pytorch_model.bin\n",
      "04/01/2020 15:33:12 - INFO - __main__ -   Loading features from cached file /content/gpt2_cached_lm_128_presidential_speeches_valid.txt\n",
      "04/01/2020 15:33:12 - INFO - __main__ -   ***** Running evaluation  *****\n",
      "04/01/2020 15:33:12 - INFO - __main__ -     Num examples = 1741\n",
      "04/01/2020 15:33:12 - INFO - __main__ -     Batch size = 2\n",
      "Evaluating: 100% 871/871 [01:04<00:00, 13.52it/s]\n",
      "04/01/2020 15:34:16 - INFO - __main__ -   ***** Eval results  *****\n",
      "04/01/2020 15:34:16 - INFO - __main__ -     perplexity = tensor(19.9754)\n"
     ]
    }
   ],
   "source": [
    "!python run_language_modeling.py \\\n",
    "    --output_dir='/content/drive/My Drive/finetuned_models/presidential_speeches' \\\n",
    "    --model_type=gpt2 \\\n",
    "    --model_name_or_path=gpt2-medium \\\n",
    "    --save_total_limit=5 \\\n",
    "    --num_train_epochs=1.0 \\\n",
    "    --do_train \\\n",
    "    --evaluate_during_training \\\n",
    "    --logging_steps=500 \\\n",
    "    --save_steps=500 \\\n",
    "    --train_data_file=/content/presidential_speeches_train.txt \\\n",
    "    --do_eval \\\n",
    "    --eval_data_file=/content/presidential_speeches_valid.txt \\\n",
    "    --per_gpu_train_batch_size=2 \\\n",
    "    --per_gpu_eval_batch_size=2 \\\n",
    "    --block_size=128 \\\n",
    "    --gradient_accumulation_steps=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "vXsajakiE1MI",
    "outputId": "62733ca1-93ad-4e26-ce80-343c4695c78a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint-1000  checkpoint-3000   pytorch_model.bin\t    vocab.json\n",
      "checkpoint-1500  config.json\t   special_tokens_map.json\n",
      "checkpoint-2000  eval_results.txt  tokenizer_config.json\n",
      "checkpoint-2500  merges.txt\t   training_args.bin\n"
     ]
    }
   ],
   "source": [
    "!ls '/content/drive/My Drive/finetuned_models/presidential_speeches'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4-L1FvROFADf"
   },
   "outputs": [],
   "source": [
    "def generate_samples(args, model, prompt_text):\n",
    "  \"\"\"Generating sampling for the provided prompt using the provided model.\"\"\"\n",
    "  set_seed(args.seed)\n",
    "\n",
    "  _, _, tokenizer_class = run_language_modeling.MODEL_CLASSES[args.model_type]\n",
    "  tokenizer = tokenizer_class.from_pretrained(args.model_name_or_path, cache_dir=None)\n",
    "\n",
    "  requires_preprocessing = args.model_type in run_generation.PREPROCESSING_FUNCTIONS.keys()\n",
    "  encoded_prompt = tokenizer.encode(prompt_text, add_special_tokens=False, return_tensors=\"pt\")\n",
    "  encoded_prompt = encoded_prompt.to(args.device)\n",
    "\n",
    "  output_sequences = model.generate(\n",
    "      input_ids=encoded_prompt,\n",
    "      max_length=args.length + len(encoded_prompt[0]),\n",
    "      temperature=args.temperature,\n",
    "      top_k=args.k,\n",
    "      top_p=args.p,\n",
    "      repetition_penalty=args.repetition_penalty,\n",
    "      do_sample=True,\n",
    "      num_return_sequences=args.num_return_sequences,\n",
    "  )\n",
    "\n",
    "  # Remove the batch dimension when returning multiple sequences\n",
    "  if len(output_sequences.shape) > 2:\n",
    "    output_sequences.squeeze_()\n",
    "\n",
    "  generated_sequences = []\n",
    "\n",
    "  for generated_sequence_idx, generated_sequence in enumerate(output_sequences):\n",
    "    generated_sequence = generated_sequence.tolist()\n",
    "\n",
    "    # Decode text\n",
    "    text = tokenizer.decode(generated_sequence, clean_up_tokenization_spaces=True)\n",
    "\n",
    "    # Remove all text after the stop token\n",
    "    text = text[: text.find(args.stop_token) if args.stop_token else None]\n",
    "\n",
    "    # Remove the excess text that was used for pre-processing\n",
    "    text = text[len(tokenizer.decode(encoded_prompt[0], clean_up_tokenization_spaces=True)) :]\n",
    "\n",
    "    # Add the prompt at the beginning of the sequence.\n",
    "    total_sequence = prompt_text + text\n",
    "\n",
    "    generated_sequences.append(total_sequence)\n",
    "\n",
    "  return generated_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "id": "7tC-LuqQFCQo",
    "outputId": "8fc6b19d-ebd2-4561-957a-5a09b7adc500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device:  cuda\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-05b548e4ed43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running on device: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m args = collections.defaultdict(\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHECKPOINT_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0moutput_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCHECKPOINT_PATH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collections' is not defined"
     ]
    }
   ],
   "source": [
    "# Set this to the checkpoint you want to use for generation, or to \"gpt2-medium\"\n",
    "# to generate with the pre-trained model without finetuning.\n",
    "CHECKPOINT_PATH = '/content/drive/My Drive/finetuned_models/presidential_speeches/checkpoint-1500'\n",
    "\n",
    "# You should try out other prompts as well as no prompt at all.\n",
    "PROMPT = '<title=\\\"Remarks on Mission to Mars\\\">'\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(\"Running on device: \", device)\n",
    "\n",
    "args = collections.defaultdict(\n",
    "  model_name_or_path=CHECKPOINT_PATH,\n",
    "  output_dir=CHECKPOINT_PATH,\n",
    "  n_gpu=n_gpu,\n",
    "  mlm=False,\n",
    "  device=device,\n",
    "  model_type='gpt2',\n",
    "  seed=42,\n",
    "  stop_token=None, # Set this if your dataset has a special word that indicates the end of a text.\n",
    "  temperature=1.0,  # temperature sampling. Set this to temperature=1.0 to not use temperature.\n",
    "  k=50,  # k for top-k sampling. Set this to k=0 to not use top-k.\n",
    "  p=1.0,  # p for nucleus sampling. Set this to p=1.0 to not use nucleus sampling.\n",
    "  repetition_penalty=None,\n",
    "  length=100,  # Number of tokens to generate.\n",
    "  num_return_sequences=3,  # Number of independently computed samples to generate.\n",
    ")\n",
    "args = DictToObj(args)\n",
    "\n",
    "model = load_model(args)\n",
    "sequences = generate_samples(args, model, PROMPT)\n",
    "for idx, sequence in enumerate(sequences):\n",
    "  print('\\n====== GENERATION {} ======'.format(idx))\n",
    "  print(sequence)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "pretrain bert",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "003a3c12d9b84715bfc5f075a4d90378": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "07748db1f3ea424fa02c2246a4e1c494": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0f1c2537775349939f8d6be4f36cc393": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2a2d8dd35395442ba81600c83187f634": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2a649a4c16d84cf98220d78cd46c35f1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c694d3d0edd46439557e4a24a58bb3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b11cd12957644e3c99f658bdeecfdbeb",
      "placeholder": "​",
      "style": "IPY_MODEL_af20106f78f840ae9a932a4cd05e5efc",
      "value": " 5.07M/5.07M [00:04&lt;00:00, 1.26MB/s]"
     }
    },
    "2ceddc45414541b49dc9b80d4c01c93e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8617be0b4a6a472caebf7ba37477c8b2",
      "max": 361,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_72c6a7bb1a3f46449535b2e07af72197",
      "value": 361
     }
    },
    "2e372aa4c0c64fff8371a9372a209304": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_94f3b7acedb645539d51b5e436609177",
       "IPY_MODEL_5c2748202e184a03ae7794d91776280b"
      ],
      "layout": "IPY_MODEL_a9bbdaec63a240f4af000c4b566b59f8"
     }
    },
    "2f11e3e56dc44ce5bc09dfd926fbba1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efcb66a6dfc54a368c9a98389f85d29d",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_003a3c12d9b84715bfc5f075a4d90378",
      "value": 231508
     }
    },
    "34bf7a3766eb436486a812e07da7bbdb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3f3e8f1ac97b48e48d6a062538b62d59": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6138fae6e7c24f379eb2901ea3a49210",
      "max": 5069051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2a2d8dd35395442ba81600c83187f634",
      "value": 5069051
     }
    },
    "48f61c531c7a497187cea2ed374c9e9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0ff01d52e7a4d9ead07e6911c0dec98",
      "placeholder": "​",
      "style": "IPY_MODEL_748de3fa024448c29b84811a822425c0",
      "value": " 737/737 [01:34&lt;00:00, 7.77B/s]"
     }
    },
    "55007e41f7b841b7a0a3b9bdc4e1aad0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e22cec4238864b38969782f6997ed2a1",
       "IPY_MODEL_97af93557e3c4c28b1c9a24a6c6196ad"
      ],
      "layout": "IPY_MODEL_df19cb6afc914b4a98cb4f1c7c4b4497"
     }
    },
    "555085b22706453cae970946de95c78f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_76f1124a549648ceab7e4ba050f00ee9",
       "IPY_MODEL_48f61c531c7a497187cea2ed374c9e9a"
      ],
      "layout": "IPY_MODEL_e7abb7b432834ae8b41ff5c42dc88fed"
     }
    },
    "5c2748202e184a03ae7794d91776280b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_af43a0eb347342719a03d17440e1ad01",
      "placeholder": "​",
      "style": "IPY_MODEL_a5bce29138734c03bb06f4b6e07b44cd",
      "value": " 440M/440M [00:15&lt;00:00, 29.1MB/s]"
     }
    },
    "6138fae6e7c24f379eb2901ea3a49210": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "67bb5e798198435895111334791a1cf6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72c6a7bb1a3f46449535b2e07af72197": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "748de3fa024448c29b84811a822425c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76f1124a549648ceab7e4ba050f00ee9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d173513c12e47018aac458428fb7e15",
      "max": 737,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0f1c2537775349939f8d6be4f36cc393",
      "value": 737
     }
    },
    "7d173513c12e47018aac458428fb7e15": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "825dbab57e134a1184908c1f005390bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8617be0b4a6a472caebf7ba37477c8b2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fac748d0156426fb9254132a4c45b01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ceddc45414541b49dc9b80d4c01c93e",
       "IPY_MODEL_e15d3549cd93471eaece9ed8a4fcc0ac"
      ],
      "layout": "IPY_MODEL_f1fb663f86124547b0e20840baae040c"
     }
    },
    "908e7a499f0149ab9649b79a682060c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd503aece4fb413aa0452afcc168bb6e",
      "placeholder": "​",
      "style": "IPY_MODEL_e7e0586404204ee0a87713aadea96878",
      "value": " 232k/232k [00:00&lt;00:00, 797kB/s]"
     }
    },
    "94f3b7acedb645539d51b5e436609177": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a649a4c16d84cf98220d78cd46c35f1",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_34bf7a3766eb436486a812e07da7bbdb",
      "value": 440473133
     }
    },
    "97af93557e3c4c28b1c9a24a6c6196ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe724cfa242a471681380037cc977abf",
      "placeholder": "​",
      "style": "IPY_MODEL_07748db1f3ea424fa02c2246a4e1c494",
      "value": " 1.12G/1.12G [01:23&lt;00:00, 13.3MB/s]"
     }
    },
    "a5af6b66069448a6aa562b5fb13824c8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5bce29138734c03bb06f4b6e07b44cd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a9bbdaec63a240f4af000c4b566b59f8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af20106f78f840ae9a932a4cd05e5efc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "af43a0eb347342719a03d17440e1ad01": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b0ff01d52e7a4d9ead07e6911c0dec98": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b11cd12957644e3c99f658bdeecfdbeb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b75e577cf5664d169529525d9f7139c7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd503aece4fb413aa0452afcc168bb6e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bded93ea97134f79bb537dbbd7170eab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3f3e8f1ac97b48e48d6a062538b62d59",
       "IPY_MODEL_2c694d3d0edd46439557e4a24a58bb3c"
      ],
      "layout": "IPY_MODEL_a5af6b66069448a6aa562b5fb13824c8"
     }
    },
    "c804913ce94445e197353d7ecbfa4665": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2f11e3e56dc44ce5bc09dfd926fbba1a",
       "IPY_MODEL_908e7a499f0149ab9649b79a682060c2"
      ],
      "layout": "IPY_MODEL_cd7352f11e374ad29d272bfc855eade2"
     }
    },
    "cd7352f11e374ad29d272bfc855eade2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbfa3f514331448f854be7c4a193316b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "df19cb6afc914b4a98cb4f1c7c4b4497": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e15d3549cd93471eaece9ed8a4fcc0ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67bb5e798198435895111334791a1cf6",
      "placeholder": "​",
      "style": "IPY_MODEL_825dbab57e134a1184908c1f005390bc",
      "value": " 361/361 [03:09&lt;00:00, 1.91B/s]"
     }
    },
    "e22cec4238864b38969782f6997ed2a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b75e577cf5664d169529525d9f7139c7",
      "max": 1115590446,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dbfa3f514331448f854be7c4a193316b",
      "value": 1115590446
     }
    },
    "e7abb7b432834ae8b41ff5c42dc88fed": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7e0586404204ee0a87713aadea96878": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "efcb66a6dfc54a368c9a98389f85d29d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1fb663f86124547b0e20840baae040c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe724cfa242a471681380037cc977abf": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
