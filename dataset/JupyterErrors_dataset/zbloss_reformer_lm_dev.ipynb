{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import math\n",
    "import jax\n",
    "import trax\n",
    "from trax import backend\n",
    "from trax import layers as tl\n",
    "from trax.backend import numpy as np\n",
    "from trax.layers.combinators import _pop_rng_and_split\n",
    "from trax.shapes import signature, ShapeDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trax.models.research.reformer import ReformerLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pMap(nn.Module):\n",
    "    \"\"\"Combinator for applying a layers to a list/tuple\"\"\"\n",
    "    def __init__(self, layer, n_sections=1, check_shapes=True):\n",
    "        \"\"\"\n",
    "        \n",
    "        :param layers: the layer you wish to apply to each element.\n",
    "        :param n_sections: number of sections to map to. defaults to 1.\n",
    "        :param check_shapes: tests to see the shapes are identical.\n",
    "        :returns: new layers with mapped layer to all elements.\n",
    "        \"\"\"\n",
    "        super(pMap, self).__init__()\n",
    "        if layer is None or isinstance(layer, (list, tuple)):\n",
    "            layer = nn.Sequential(*layer)\n",
    "        self.layer = layer\n",
    "        self.check_shapes = check_shapes\n",
    "        self.n_sections = n_sections\n",
    "        self.n_in = n_sections\n",
    "        self.n_out = n_sections\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs, **kwargs):\n",
    "        \"\"\"\n",
    "        Trying to replace with a basic forward pass. Trax implementation\n",
    "        uses a PRNG key split into subsections zipped with the inputs var\n",
    "        then returns a list of those forward passed subsections as results\n",
    "        \"\"\"\n",
    "            \n",
    "        if self.n_sections == 1:\n",
    "            results = self.layer(inputs, **kwargs)\n",
    "        \n",
    "        else:\n",
    "            results = [self.layer(x) for x in inputs] \n",
    "            \n",
    "        return results, self.layer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pMap(\n",
       "  (layer): Sequential(\n",
       "    (0): LayerNorm((1,), eps=1, elementwise_affine=True)\n",
       "    (1): Linear(in_features=1, out_features=1, bias=True)\n",
       "    (2): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmap = pMap(layer=[\n",
    "    nn.LayerNorm(1,1), \n",
    "    nn.Linear(1,1),\n",
    "    nn.LogSoftmax()], n_sections=10)\n",
    "\n",
    "pmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n",
      "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])\n"
     ]
    }
   ],
   "source": [
    "test = torch.tensor([0,1,2,3,4,5,6,7,8,9], dtype=torch.float)\n",
    "print(test.unsqueeze(0).shape)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([tensor([0.], grad_fn=<LogSoftmaxBackward>),\n",
       "  tensor([0.], grad_fn=<LogSoftmaxBackward>),\n",
       "  tensor([0.], grad_fn=<LogSoftmaxBackward>),\n",
       "  tensor([0.], grad_fn=<LogSoftmaxBackward>),\n",
       "  tensor([0.], grad_fn=<LogSoftmaxBackward>),\n",
       "  tensor([0.], grad_fn=<LogSoftmaxBackward>),\n",
       "  tensor([0.], grad_fn=<LogSoftmaxBackward>),\n",
       "  tensor([0.], grad_fn=<LogSoftmaxBackward>),\n",
       "  tensor([0.], grad_fn=<LogSoftmaxBackward>),\n",
       "  tensor([0.], grad_fn=<LogSoftmaxBackward>)],\n",
       " OrderedDict([('0.weight', tensor([1.])),\n",
       "              ('0.bias', tensor([0.])),\n",
       "              ('1.weight', tensor([[0.8039]])),\n",
       "              ('1.bias', tensor([0.5340]))]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pmap(inputs=test.view(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BroadcastedDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1422,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BroadcastedDropout(nn.Module):\n",
    "    \n",
    "    def __init__(self, rate=0.0, mode='train', broadcast_dims=(-2,)):\n",
    "        super(BroadcastedDropout, self).__init__()\n",
    "        \n",
    "        self.rate = rate\n",
    "        if self.rate >= 1.0:\n",
    "            raise ValueError(f'Dropout rate ({self.rate}) must be lower than 1')\n",
    "        elif self.rate < 0:\n",
    "            raise ValueError(f'Dropout rate ({self.rate}) must be at least 0.0')\n",
    "        \n",
    "        self.broadcast_dims = broadcast_dims\n",
    "        self.mode = mode\n",
    "        \n",
    "    def forward(self, x: torch.tensor, **kwargs):\n",
    "        if self.mode == 'train' and self.rate > 0.0:\n",
    "            noise_shape = list(x.shape)\n",
    "            \n",
    "            for dim in self.broadcast_dims:\n",
    "                noise_shape[dim] = 1\n",
    "                \n",
    "            keep_prob = 1 - self.rate\n",
    "            keep = np.random.binomial(n=1, p=keep_prob, size=tuple(noise_shape))\n",
    "            keep = torch.tensor(keep)\n",
    "            multiplier = keep / keep_prob\n",
    "            return x * multiplier\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1423,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = BroadcastedDropout(mode='train', rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.2500, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 1.2500, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 1.2500]]])"
      ]
     },
     "execution_count": 1424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd(test.unsqueeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple FeedForward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1425,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeedForward(sample, \n",
    "                d_input: int, \n",
    "                d_output: int, \n",
    "                dropout: float, \n",
    "                activation: bool, \n",
    "                mode: str):\n",
    "    \"\"\"\n",
    "    Building a simple Feed Forward NN\n",
    "    :param sample: sample data used to set the LayerNorm dimensions.\n",
    "    :param d_input: model input dimension.\n",
    "    :param d_output: model output dimension.\n",
    "    :param dropout: amount of dropout to apply on range [0.0, 1.0).\n",
    "    :param activation: True applies ReLU activation.\n",
    "    :param mode: whether to run dropout in train or eval mode.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(sample.shape) == 1:\n",
    "        norm_output = sample.shape[0]\n",
    "        norm_input = 1\n",
    "    elif len(sample.shape) == 2:\n",
    "        norm_output = sample.shape[1]\n",
    "        norm_input = sample.shape[0]\n",
    "    else:\n",
    "        norm_output = sample.shape[-1]\n",
    "        norm_input = sample.shape[-2]\n",
    "        \n",
    "    \n",
    "    return nn.Sequential(\n",
    "        nn.LayerNorm(normalized_shape=(norm_input, norm_output)),\n",
    "        nn.Linear(d_input, d_output),\n",
    "        BroadcastedDropout(rate=dropout, mode=mode),\n",
    "        activation,\n",
    "        nn.Linear(d_output, d_output),\n",
    "        BroadcastedDropout(rate=dropout, mode=mode)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'jax.numpy' has no attribute 'random'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-549-ef8a2825f775>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                  mode='train')\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-91-b8cad9f44475>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mkeep_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinomial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mmultiplier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/trax/backend.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'np'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'jax.numpy' has no attribute 'random'"
     ]
    }
   ],
   "source": [
    "ff = FeedForward(sample=test.view(1,-1), \n",
    "                 d_input=test.view(1,-1).shape[1], \n",
    "                 d_output=10, \n",
    "                 dropout=0.2, \n",
    "                 activation=nn.ReLU(), \n",
    "                 mode='train')\n",
    "ff(test.view(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1372,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitForOutput(nn.Module):\n",
    "    \"\"\"\n",
    "    Splits activations into sections, to be used prior to the output layer.\n",
    "    \n",
    "    After the reversible portion of the network, there is a final output portion that's \n",
    "    non-reversible where the minimum includes normalization, output projection, and log-softmax. \n",
    "    The output portion needs to operate on chucks of the sequence to avoid running out of memory\n",
    "    for large vocabulary sizes.\n",
    "    \n",
    "    This layer concatenates the two subparts of the activations along the feature dimension\n",
    "    then splits into chunks along the time dimension. \n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_sections=2, axis=-2, n_in=2):\n",
    "        super(SplitForOutput, self).__init__()\n",
    "        self.n_sections = n_sections\n",
    "        self.axis = axis\n",
    "        self.n_in = 2\n",
    "        self.n_out = n_sections\n",
    "            \n",
    "    def forward(self, inputs: torch.tensor):\n",
    "                    \n",
    "        x1, x2 = inputs\n",
    "\n",
    "        x1_split = np.split(x1, self.n_sections, self.axis)\n",
    "        x2_split = np.split(x2, self.n_sections, self.axis)\n",
    "\n",
    "        res = [np.concatenate(ys, -1) for ys in zip(x1_split, x2_split)]\n",
    "        return tuple(res)\n",
    "\n",
    "    def reverse(self, output, **kwargs):\n",
    "        \n",
    "        x1_split = []\n",
    "        x2_split = []\n",
    "        for y in output:\n",
    "            y1, y2 = np.split(y, 2, -1)\n",
    "            x1_split.append(y1)\n",
    "            x2_split.append(y2)\n",
    "\n",
    "        x1 = np.concatenate(x1_split, self.axis)\n",
    "        x2 = np.concatenate(x2_split, self.axis)\n",
    "\n",
    "        return (x1, x2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chunk(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_sections=2):\n",
    "        super(Chunk, self).__init__()\n",
    "        self.n_sections = n_sections\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert x.shape[1] % self.n_sections == 0\n",
    "        return torch.cat(torch.chunk(x, chunks=self.n_sections, dim=-2))\n",
    "    \n",
    "class Unchunk(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_sections=2, dim=-3):\n",
    "        super(Unchunk, self).__init__()\n",
    "        self.n_sections = n_sections\n",
    "        self.dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert x.shape[0] % self.n_sections == 0\n",
    "        return torch.cat(torch.chunk(x, chunks=self.n_sections, dim=self.dim), dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Chunk(x, n_sections=2):\n",
    "    assert x.shape[1] % n_sections == 0\n",
    "    \n",
    "    return torch.cat(torch.chunk(x, chunks=n_sections, dim=-2))\n",
    "\n",
    "def Unchunk(x, n_sections=2):\n",
    "    assert x.shape[0] % n_sections == 0\n",
    "    \n",
    "    return torch.cat(torch.chunk(x, chunks=n_sections, dim=-3), dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.tensor([[1,0,0,0],[0,1,0,0],\n",
    "                    [0,0,1,0], [0,0,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.]]), tensor([[0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(test, chunks=2, dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 0, 1]])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute_residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([[ 1.1745598 ,  0.07205822,  0.6006763 ,  0.7884164 ],\n",
       "              [-0.5550922 ,  1.0654054 ,  0.6392876 , -0.07618227],\n",
       "              [-0.10679559,  0.02530393,  0.9922953 ,  0.02808513],\n",
       "              [-0.27318668,  0.24871418,  0.8338994 ,  1.1428925 ]],            dtype=float32),\n",
       " array([[1, 0, 0, 0],\n",
       "        [0, 1, 0, 0],\n",
       "        [0, 0, 1, 0],\n",
       "        [0, 0, 0, 1]]))"
      ]
     },
     "execution_count": 554,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test = test.view(1,-1)\n",
    "\n",
    "ff = feed_forward(d_model=4, d_ff=4, dropout=0.2, activation=True, mode='train')\n",
    "\n",
    "residual_layers = ff\n",
    "compute_residual = tl.Serial(\n",
    "    tl.Parallel([], tl.Dup()),\n",
    "    tl.Swap(),\n",
    "    tl.Parallel(residual_layers, [], [])\n",
    ")\n",
    "\n",
    "layers = [compute_residual, tl.Parallel(tl.Add(), [])]\n",
    "compute_residual = tl.Serial(layers)\n",
    "\n",
    "input_sd = ShapeDtype(tuple(test.shape), np.int32)\n",
    "input_signature = (input_sd, input_sd)\n",
    "weights, state = compute_residual.init(input_signature)\n",
    "\n",
    "output, state = compute_residual(\n",
    "    x=(test.numpy(), )*2, \n",
    "    weights=weights,\n",
    "    state=state\n",
    ")\n",
    "\n",
    "output, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReversibleHalfResidual(nn.Module):\n",
    "    \n",
    "    def __init__(self, residual_layers: list):\n",
    "        super(ReversibleHalfResidual, self).__init__()\n",
    "        self.residual_layers = residual_layers\n",
    "        self.model = nn.Sequential(*residual_layers)\n",
    "        \n",
    "        \n",
    "    def compute_residual(self, inputs, **kwargs):\n",
    "        \"\"\"\n",
    "        Replicating the JAX class of the same name step by step.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # replicating the compute_residuals operation\n",
    "        output = self.model(inputs)\n",
    "        # replicating the tl.Add() operation\n",
    "        output += output\n",
    "        return output, self.model\n",
    "    \n",
    "    def reverse(self, inputs):\n",
    "        #inputs -= inputs\n",
    "        output = self.compute_residual(inputs)[0] - inputs\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [[1,0,0,0], [0,1,0,0],\n",
    "       [0,0,1,0], [0,0,0,1]]\n",
    "test = torch.tensor(test, dtype=torch.float32)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (\n",
    "            1 + torch.tanh(math.sqrt(2 / math.pi) * (\n",
    "                x + 0.044715 * torch.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevNetBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_in, d_out, dropout=0.1, lol=[]):\n",
    "        super(RevNetBlock, self).__init__()\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.dropout = dropout\n",
    "\n",
    "        layers = []\n",
    "        if lol == list():\n",
    "            layers.append(nn.LayerNorm((d_in,d_out)))\n",
    "            layers.append(nn.Linear(d_in, d_out))\n",
    "            layers.append(GeLU())\n",
    "            layers.append(nn.Linear(d_in, d_out))\n",
    "        else:\n",
    "            for layer in lol:\n",
    "                layers.append(layer)\n",
    "        \n",
    "        self.bottleneck_block = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.cat((x, x), dim=1)\n",
    "        x1, x2 = self.split(x)\n",
    "        Fx2 = self.bottleneck_block(x2)\n",
    "        y1 = Fx2 + x1\n",
    "        return (x2, y1)\n",
    "    \n",
    "    def inverse(self, x):\n",
    "        x2, y1 = x[0], x[1]\n",
    "        Fx2 = - self.bottleneck_block(x2)\n",
    "        x1 = Fx2 + y1\n",
    "        return (x1, x2)\n",
    "\n",
    "    @staticmethod\n",
    "    def split(x):\n",
    "        n = int(x.size()[1] / 2)\n",
    "        x1 = x[:, :n].contiguous()\n",
    "        x2 = x[:, n:].contiguous()\n",
    "        return (x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0.],\n",
       "         [0., 1., 0., 0.],\n",
       "         [0., 0., 1., 0.],\n",
       "         [0., 0., 0., 1.]]), tensor([[ 1.4723,  0.0600,  0.5037,  0.5120],\n",
       "         [ 0.3461,  0.8839,  0.3724,  0.2543],\n",
       "         [ 0.7384,  0.1297,  1.1142,  0.3288],\n",
       "         [ 0.5839, -0.2881,  0.0728,  1.2639]], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb = RevNetBlock(d_in=4, d_out=4)\n",
    "rb(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevNetHalfAttnBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_in, d_out, dropout=0.1, lol=[]):\n",
    "        super(RevNetHalfAttnBlock, self).__init__()\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.dropout = dropout\n",
    "\n",
    "        layers = []\n",
    "        if lol == list():\n",
    "            layers.append(nn.LayerNorm((d_in,d_out)))\n",
    "            layers.append(nn.Linear(d_out, d_out))\n",
    "            layers.append(GeLU())\n",
    "            layers.append(nn.Linear(d_out, d_out))\n",
    "        else:\n",
    "            for layer in lol:\n",
    "                layers.append(layer)\n",
    "        \n",
    "        self.bottleneck_block = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.cat((x, x), dim=1)\n",
    "        x1, x2 = self.split(x)\n",
    "        Fx2 = self.bottleneck_block(x2)\n",
    "        y1 = Fx2 + x1\n",
    "        return (x2, y1)\n",
    "    \n",
    "    def inverse(self, x):\n",
    "        x2, y1 = x[0], x[1]\n",
    "        Fx2 = - self.bottleneck_block(x2)\n",
    "        x1 = Fx2 + y1\n",
    "        return (x1, x2)\n",
    "\n",
    "    @staticmethod\n",
    "    def split(x):\n",
    "        n = int(x.size()[1] / 2)\n",
    "        x1 = x[:, :n].contiguous()\n",
    "        x2 = x[:, n:].contiguous()\n",
    "        return (x1, x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReversibleHalfResidual(tl.ReversibleLayer, tl.Serial):\n",
    "    \"\"\"Half of a RevNet-style residual (only updates part of the hidden state).\"\"\"\n",
    "\n",
    "    def __init__(self, residual_layers):\n",
    "        self.compute_residual = tl.Serial(\n",
    "            # (x1_or_y1, x2) -> (x2, x1_or_y1, x2)\n",
    "            tl.Parallel([], tl.Dup()),\n",
    "            tl.Swap(),\n",
    "            tl.Parallel(residual_layers, [], []),\n",
    "        )\n",
    "\n",
    "        layers = [\n",
    "            self.compute_residual,\n",
    "            tl.Parallel(tl.Add(), [])\n",
    "        ]\n",
    "        super(ReversibleHalfResidual, self).__init__(layers)\n",
    "\n",
    "        self.subtract_top = tl.Parallel(tl.SubtractTop(), [])\n",
    "        self.reverse_layers = [self.compute_residual, self.subtract_top]\n",
    "\n",
    "    def reverse(self, output, weights=(), state=(), new_state=(), **kwargs):\n",
    "        reconstructed_x = output\n",
    "        rng = kwargs.pop('rng', None)\n",
    "        rngs = (None,) * self._n_layers\n",
    "        if rng is not None:\n",
    "            rngs = backend.random.split(rng, self._n_layers)\n",
    "        # Note that self.sublayers aligns exactly with self.reverse_layers in\n",
    "        # terms of parameter and rng usage, so no re-ordering is required.\n",
    "        for layer, p, s, ns, rng in zip(\n",
    "            self.reverse_layers, weights, state, new_state, rngs):\n",
    "            reconstructed_x = layer(reconstructed_x, weights=p,\n",
    "                                  state=s, new_state=ns, rng=rng, **kwargs)\n",
    "        return reconstructed_x\n",
    "\n",
    "    def reverse_and_grad(self, output, ct, weights=(), state=(), new_state=(),\n",
    "                       **kwargs):\n",
    "        rng = kwargs.pop('rng', None)\n",
    "        rngs = (None,) * self._n_layers\n",
    "        if rng is not None:\n",
    "            rngs = backend.random.split(rng, self._n_layers)\n",
    "\n",
    "        def call_compute_residual(x, weights):\n",
    "            res = self.compute_residual(x, weights=weights, state=state[0],\n",
    "                                  rng=rngs[0], **kwargs)\n",
    "            return res\n",
    "\n",
    "        assert len(ct) == 2\n",
    "        ct = ((ct[0], ct[0], ct[1]))\n",
    "\n",
    "        stack_with_residual, vjpfun = jax.vjp(\n",
    "            call_compute_residual, output, weights[0])\n",
    "        reconstructed_x = self.subtract_top(\n",
    "            stack_with_residual, weights=weights[-1], state=state[-1], rng=rngs[-1],\n",
    "            **kwargs)\n",
    "\n",
    "        x_ct, residual_weights_ct = vjpfun(ct)\n",
    "        assert not jax.tree_util.tree_leaves(weights[-1])\n",
    "        add_top_weights_ct = weights[-1]\n",
    "        return reconstructed_x, (x_ct, [residual_weights_ct, add_top_weights_ct])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfo = SplitForOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand((4,4,64)).numpy()\n",
    "a, b = sfo.forward((t,t))\n",
    "c, d = sfo.reverse((t,t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.9332608 , 0.37275243, 0.24749881, ..., 0.3007813 ,\n",
       "         0.01336372, 0.91984534],\n",
       "        [0.06810844, 0.31975365, 0.4596733 , ..., 0.6953241 ,\n",
       "         0.516515  , 0.7335064 ],\n",
       "        [0.2682591 , 0.4061324 , 0.4862305 , ..., 0.00894731,\n",
       "         0.70863795, 0.68239385],\n",
       "        [0.61330193, 0.73361546, 0.7224821 , ..., 0.38717663,\n",
       "         0.71035814, 0.3269791 ]],\n",
       "\n",
       "       [[0.80395615, 0.35125375, 0.64326906, ..., 0.7773044 ,\n",
       "         0.2102406 , 0.01249462],\n",
       "        [0.9474387 , 0.17382026, 0.3857957 , ..., 0.6967543 ,\n",
       "         0.88277763, 0.80197996],\n",
       "        [0.42688662, 0.26215553, 0.9343588 , ..., 0.73154384,\n",
       "         0.8642012 , 0.03059494],\n",
       "        [0.683786  , 0.95499694, 0.22347832, ..., 0.8070612 ,\n",
       "         0.9337378 , 0.18357903]],\n",
       "\n",
       "       [[0.60924685, 0.17127681, 0.5226319 , ..., 0.8543361 ,\n",
       "         0.13858616, 0.07278848],\n",
       "        [0.77171665, 0.9567531 , 0.4942938 , ..., 0.386685  ,\n",
       "         0.8730096 , 0.46646416],\n",
       "        [0.3734027 , 0.38423145, 0.63793457, ..., 0.87231374,\n",
       "         0.42343485, 0.6238761 ],\n",
       "        [0.24921614, 0.21594393, 0.7287208 , ..., 0.8272258 ,\n",
       "         0.930654  , 0.33478004]],\n",
       "\n",
       "       [[0.5667992 , 0.3182699 , 0.49461305, ..., 0.55058205,\n",
       "         0.05203205, 0.33480144],\n",
       "        [0.57062083, 0.7200453 , 0.3080476 , ..., 0.33951974,\n",
       "         0.66556406, 0.32167768],\n",
       "        [0.4075058 , 0.31681412, 0.80443996, ..., 0.09538239,\n",
       "         0.39680302, 0.17801636],\n",
       "        [0.48027784, 0.640444  , 0.91576403, ..., 0.9584026 ,\n",
       "         0.97876954, 0.65837944]]], dtype=float32)"
      ]
     },
     "execution_count": 1214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4, 64)"
      ]
     },
     "execution_count": 1130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 64)\n",
      "(4, 4, 1, 64)\n",
      "torch.Size([4, 4, 1, 64])\n",
      "(4, 1, 4, 64)\n",
      "torch.Size([4, 1, 4, 64])\n"
     ]
    }
   ],
   "source": [
    "print(t.shape)\n",
    "print(np.reshape(t, (t.shape[0], t.shape[1], 1, 64)).shape)\n",
    "print(torch.reshape(torch.tensor(t), (t.shape[0], t.shape[1], 1, 64)).shape)\n",
    "res = np.reshape(t, (t.shape[0], t.shape[1], 1, 64))\n",
    "print(np.transpose(res, (0,2,1,3)).shape)\n",
    "print(torch.transpose(torch.tensor(res), 1,2).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1528,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeAttentionHeads(nn.Module):\n",
    "    def __init__(self, n_heads=1, d_head=64):\n",
    "        super(ComputeAttentionHeads, self).__init__()\n",
    "        self.n_heads= n_heads\n",
    "        self.d_head = d_head\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor(x, dtype=torch.float)\n",
    "        \n",
    "        seqlen = x.shape[1]\n",
    "        res = x\n",
    "        \n",
    "        # n_batch, seqlen, n_heads*d_head -> n_batch, seqlen, n_heads, d_head\n",
    "        res = torch.reshape(res, (x.shape[0], seqlen, self.n_heads, self.d_head))\n",
    "        # n_batch, seqlen, n_heads, d_head -> n_batch, n_heads, seqlen, d_head\n",
    "        res = torch.transpose(res, 1, 2)\n",
    "        # n_batch, n_heads, seqlen, d_head -> n_batch*n_heads, seqlen, d_head\n",
    "        res = torch.reshape(res, (-1, seqlen, self.d_head))\n",
    "        res = nn.Linear(res.shape[-1], res.shape[-1])(res)\n",
    "        return res\n",
    "    \n",
    "class ComputeAttentionOutput(nn.Module):\n",
    "    def __init__(self, n_heads=1):\n",
    "        super(ComputeAttentionOutput, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        \n",
    "        seqlen = x.shape[1]\n",
    "        d_head = x.shape[2]\n",
    "        \n",
    "        x = torch.reshape(x, (-1, self.n_heads, seqlen, d_head))\n",
    "        x = torch.transpose(x, 1, 2)\n",
    "        x = torch.reshape(x, (-1, seqlen, self.n_heads * d_head))\n",
    "        x = nn.Linear(x.shape[-1], x.shape[-1])(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1529,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, \n",
    "                 d_in, \n",
    "                 d_out, \n",
    "                 attn_k=64, \n",
    "                 attn_v=64, \n",
    "                 n_heads=1, \n",
    "                 n_chunks=2, \n",
    "                 share_qk=True, \n",
    "                 attn_type=None, \n",
    "                 dropout=None, \n",
    "                 ff_activation=None, \n",
    "                 ff_use_sru=None, \n",
    "                 mode='train'):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        \n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.attn_k = attn_k\n",
    "        self.attn_v = attn_v\n",
    "        self.n_heads = n_heads\n",
    "        self.n_chunks = n_chunks\n",
    "        self.attn_type = attn_type\n",
    "        self.dropout = dropout\n",
    "        self.share_qk = share_qk\n",
    "        self.ff_activation = ff_activation\n",
    "        self.ff_use_sru = ff_use_sru\n",
    "        self.mode = mode\n",
    "        \n",
    "        \n",
    "    def pre_attention(self, x):\n",
    "        \n",
    "        x1, x2 = torch.chunk(x, self.n_chunks)\n",
    "        k_layers = [ComputeAttentionHeads(self.n_heads, self.attn_k), nn.LayerNorm((x.shape[1], x.shape[2]))]\n",
    "        k_model = nn.Sequential(*k_layers)\n",
    "\n",
    "        v_layers = [ComputeAttentionHeads(self.n_heads, self.attn_v), nn.LayerNorm((x.shape[1], x.shape[2]))]\n",
    "        v_model = nn.Sequential(*v_layers)\n",
    "\n",
    "        k = k_model(x1)\n",
    "        v = v_model(x2)\n",
    "\n",
    "        if not self.share_qk:\n",
    "            q_layers = k_layers\n",
    "            q_model = nn.Sequential(*q_layers)\n",
    "            q = q_model(x1)\n",
    "            \n",
    "            q = Fx1\n",
    "            \n",
    "            return (q, k, v)\n",
    "        else:\n",
    "            return (k, k, v)\n",
    "    \n",
    "    \n",
    "    def attention(self, inputs):\n",
    "        \n",
    "        assert len(inputs) == 2 or len(inputs) == 3\n",
    "        if len(inputs) == 2:\n",
    "            k, v = inputs\n",
    "            q = k\n",
    "        else:\n",
    "            q, k, v = inputs\n",
    "        \n",
    "        mask_size = q.shape[-2]\n",
    "        mask = torch.tril(\n",
    "            torch.ones((1, mask_size, mask_size), dtype=torch.bool), \n",
    "            diagonal=0\n",
    "        )\n",
    "        \n",
    "        attn = self.dotproductattention(q, k, v, mask)\n",
    "        return attn\n",
    "    \n",
    "    \n",
    "    def dotproductattention(self, q, k, v, mask, dropout=0.1):\n",
    "        \n",
    "        depth = q.shape[-1]\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) / np.sqrt(depth)\n",
    "        dots = F.log_softmax(torch.where(mask, dots, torch.full_like(dots, -1e9)), dim=0)\n",
    "        \n",
    "        keep_prob = 1 - dropout\n",
    "        keep = np.random.binomial(n=1, p=keep_prob, size=dots.shape)\n",
    "        \n",
    "        dots = torch.where(\n",
    "            torch.tensor(keep, dtype=torch.bool), \n",
    "            dots / torch.tensor(keep_prob), \n",
    "            torch.zeros_like(dots)\n",
    "        )\n",
    "        attn = torch.matmul(dots, v)\n",
    "        return attn\n",
    "    \n",
    "    \n",
    "    def post_attention(self, x):\n",
    "        \n",
    "        cao = ComputeAttentionOutput()\n",
    "        unchunk = Unchunk(n_sections = self.n_chunks, dim=-2)\n",
    "        bd = BroadcastedDropout(rate=self.dropout)\n",
    "        \n",
    "        res = cao(x)\n",
    "        #res = torch.cat((res, res), dim=-3)\n",
    "        res = unchunk(res)\n",
    "        res = bd(res)\n",
    "        return res\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.tensor(x, dtype=torch.float32)\n",
    "        \n",
    "        x = self.pre_attention(x)\n",
    "        #x = tuple(torch.tensor(y) for y in x)\n",
    "        x = self.attention(x)\n",
    "        x = self.post_attention(x)\n",
    "        return torch.cat((x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1530,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 64])"
      ]
     },
     "execution_count": 1530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = DecoderBlock(d_in=10, d_out=10, dropout=0.1)\n",
    "q,k,v = db.pre_attention(t)\n",
    "attn = db.attention((k,v))\n",
    "res = db.post_attention(torch.tensor(attn))\n",
    "res = db(torch.tensor(t))\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1531,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "t = torch.tensor(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sfo.reverse(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 64])"
      ]
     },
     "execution_count": 1533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1534,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 2, 64])"
      ]
     },
     "execution_count": 1534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Chunk()(torch.tensor(t)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1535,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = DecoderBlock(d_in=10, d_out=10, dropout=0.1)\n",
    "q,k,v = db.pre_attention(torch.tensor(t))\n",
    "attn = db.attention((k,v))\n",
    "res = db.post_attention(torch.tensor(attn))\n",
    "res = db(torch.tensor(t))\n",
    "\n",
    "# q,k,v = db.pre_attention(res)\n",
    "# attn = db.attention((k,v))\n",
    "# res = db.post_attention(torch.tensor(attn))\n",
    "# res = db(torch.tensor(t))\n",
    "\n",
    "# q,k,v = db.pre_attention(res)\n",
    "# attn = db.attention((k,v))\n",
    "# res = db.post_attention(torch.tensor(attn))\n",
    "# res = db(torch.tensor(t))\n",
    "\n",
    "len(torch.chunk(res, chunks=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 4, 64])"
      ]
     },
     "execution_count": 1536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rb = RevNetHalfAttnBlock(d_in=res.shape[-2], d_out=res.shape[-1])\n",
    "output = rb(res)\n",
    "output = torch.cat(output)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1537,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3323, -2.1675, -1.0479,  ...,  0.6190, -0.4930, -1.8913],\n",
       "         [-1.6069, -2.6593, -1.1764,  ...,  0.7585, -0.3427, -2.3052],\n",
       "         [-1.0038, -1.1933, -0.6131,  ...,  0.4285, -0.6670, -1.0500],\n",
       "         [-2.3543, -2.9169, -1.4736,  ...,  1.0477, -1.2215, -2.5753]],\n",
       "\n",
       "        [[-0.6914, -0.0000, -1.1049,  ...,  0.2784, -0.8299,  0.0807],\n",
       "         [-0.2466, -0.0000, -1.2179,  ...,  0.3073, -0.7717, -0.4986],\n",
       "         [-0.3930, -0.0000, -2.6215,  ...,  0.8104, -2.0397, -1.2980],\n",
       "         [-0.0596, -0.0000, -1.1229,  ...,  0.3441, -0.9026, -0.7586]],\n",
       "\n",
       "        [[-1.3323, -2.1675, -1.0479,  ...,  0.6190, -0.4930, -1.8913],\n",
       "         [-1.6069, -2.6593, -1.1764,  ...,  0.7585, -0.3427, -2.3052],\n",
       "         [-1.0038, -1.1933, -0.6131,  ...,  0.4285, -0.6670, -1.0500],\n",
       "         [-2.3543, -2.9169, -1.4736,  ...,  1.0477, -1.2215, -2.5753]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.4555, -0.0740, -1.2646,  ...,  0.3365, -0.8418,  0.1093],\n",
       "         [ 0.0178, -0.0785, -1.3758,  ...,  0.3962, -0.7832, -0.4290],\n",
       "         [-0.2088, -0.1736, -2.9725,  ...,  0.6717, -2.0963, -1.0199],\n",
       "         [ 0.1775, -0.0996, -1.2752,  ...,  0.4347, -0.9225, -0.7022]],\n",
       "\n",
       "        [[-1.0543, -2.2460, -1.2733,  ...,  0.7118, -0.4425, -1.8141],\n",
       "         [-1.3364, -2.7486, -1.4549,  ...,  0.8077, -0.2759, -2.1922],\n",
       "         [-0.7499, -1.2559, -0.7690,  ...,  0.5761, -0.6388, -1.0454],\n",
       "         [-2.0955, -2.9847, -1.8348,  ...,  1.0659, -1.1915, -2.3963]],\n",
       "\n",
       "        [[-0.4555, -0.0740, -1.2646,  ...,  0.3365, -0.8418,  0.1093],\n",
       "         [ 0.0178, -0.0785, -1.3758,  ...,  0.3962, -0.7832, -0.4290],\n",
       "         [-0.2088, -0.1736, -2.9725,  ...,  0.6717, -2.0963, -1.0199],\n",
       "         [ 0.1775, -0.0996, -1.2752,  ...,  0.4347, -0.9225, -0.7022]]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 1537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1538,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReformerLM(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                vocab_size,\n",
    "                d_in,\n",
    "                d_out,\n",
    "                attn_k=64,\n",
    "                attn_v=64,\n",
    "                n_layers=6,\n",
    "                n_heads=1,\n",
    "                dropout=0.1,\n",
    "                max_len=2048,\n",
    "                n_chunks=2,\n",
    "                n_attention_chunks=2,\n",
    "                share_qk=True,\n",
    "                axial_pos_shape=(),\n",
    "                d_axial_pos_embs=None,\n",
    "                mode='train'):\n",
    "        super(ReformerLM, self).__init__()\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.d_in = d_in\n",
    "        self.d_out = d_out\n",
    "        self.attn_k = attn_k\n",
    "        self.attn_v = attn_v\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.dropout = dropout\n",
    "        self.max_len = max_len\n",
    "        self.n_chunks = n_chunks\n",
    "        self.n_attention_chunks = n_attention_chunks\n",
    "        self.share_qk = share_qk\n",
    "        self.axial_pos_shape = axial_pos_shape\n",
    "        self.d_axial_pos_embs = d_axial_pos_embs\n",
    "        self.mode = mode\n",
    " \n",
    "        self.layers = []\n",
    "        self.layers.append(\n",
    "            DecoderBlock(\n",
    "                    d_in = self.d_in,\n",
    "                    d_out = self.d_out, \n",
    "                    attn_k = self.attn_k,\n",
    "                    attn_v = self.attn_v,\n",
    "                    n_heads = self.n_heads,\n",
    "                    n_chunks = self.n_attention_chunks,\n",
    "                    share_qk = self.share_qk,\n",
    "                    attn_type = None,\n",
    "                    dropout = self.dropout\n",
    "                )\n",
    "        )\n",
    "        \n",
    "        for layer in range(self.n_layers - 1):\n",
    "            #self.layers.append(Chunk(n_sections=self.n_attention_chunks))\n",
    "            self.layers.append(\n",
    "                DecoderBlock(\n",
    "                    d_in = self.d_out,\n",
    "                    d_out = self.d_out, \n",
    "                    attn_k = self.attn_k,\n",
    "                    attn_v = self.attn_v,\n",
    "                    n_heads = self.n_heads,\n",
    "                    n_chunks = self.n_attention_chunks,\n",
    "                    share_qk = self.share_qk,\n",
    "                    attn_type = None,\n",
    "                    dropout = self.dropout\n",
    "                )\n",
    "            )\n",
    "            \n",
    "        self.ff_layers = [\n",
    "            nn.LayerNorm((1, self.d_out * self.d_in)),\n",
    "            nn.Linear(self.d_out * self.d_in, self.d_out * self.d_in),\n",
    "            BroadcastedDropout(rate=self.dropout, mode=self.mode),\n",
    "            GeLU(),\n",
    "            nn.Linear(self.d_out * self.d_in, self.vocab_size),\n",
    "            nn.LogSoftmax()\n",
    "        ]\n",
    "        \n",
    "        self.model = nn.Sequential(*self.layers)\n",
    "        self.ff_model = nn.Sequential(*self.ff_layers)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.model(x)\n",
    "        # Flattening\n",
    "        x = x.view(x.shape[0],1,-1)\n",
    "        x = self.ff_model(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1539,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 64])\n",
      "torch.Size([4, 1, 100])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "rlm = ReformerLM(vocab_size=100, \n",
    "                 d_in=t.shape[-2], \n",
    "                 d_out=t.shape[-1], \n",
    "                 n_layers=6)\n",
    "#rlm._build_model()\n",
    "output = rlm(t)\n",
    "print(torch.tensor(t).shape)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 100])"
      ]
     },
     "execution_count": 1540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prelim-Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1541,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() missing 2 required positional arguments: 'key' and 'value'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1541-f478d86c545b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiheadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() missing 2 required positional arguments: 'key' and 'value'"
     ]
    }
   ],
   "source": [
    "nn.MultiheadAttention(test.shape[-2], test.shape[-2])(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1562,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm, tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1571,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e28ae9f07bb4ff28f175f2e9ed58452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5048818cda2648f79906872dbacd495d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68357dacf5da4c508d5672b21fd3e921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ea8cfc56f34b52afe822e689f16447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92377013a03d456187f4e368cd77bd54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e317c938f84e41768caae25263f2e6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9368e8a76605494e9d28ee4a6763f1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d406f34626541688e5c663bcb00c317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df901115c25494f9d6d618118b1f9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f75076bc6f9477f9f8f0634d3faabb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d1f0ded49b41378f49fb4ded1dd512",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c98c4dced5480a9c0178b21fd9fd42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60fdb491122541ecb3b508fcd53e89d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab8011d8b2d48c98bb949f33da35261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe926848089549bebaa48d06e53372d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108005fc023a47e0ad44aa3b1971e3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f7ad7969594fe3af50aafd41ffb829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c55ce05d0f6414fa4bf98aa80873356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([6, 4, 10])\n",
      "\n",
      "Error on: torch.Size([6, 4, 20])\n",
      "\n",
      "Error on: torch.Size([6, 4, 30])\n",
      "\n",
      "Error on: torch.Size([6, 4, 40])\n",
      "\n",
      "Error on: torch.Size([6, 4, 50])\n",
      "\n",
      "Error on: torch.Size([6, 4, 60])\n",
      "\n",
      "Error on: torch.Size([6, 4, 70])\n",
      "\n",
      "Error on: torch.Size([6, 4, 80])\n",
      "\n",
      "Error on: torch.Size([6, 4, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0782a0b2f2d44fd5a92b2eb881b9318b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([6, 6, 10])\n",
      "\n",
      "Error on: torch.Size([6, 6, 20])\n",
      "\n",
      "Error on: torch.Size([6, 6, 30])\n",
      "\n",
      "Error on: torch.Size([6, 6, 40])\n",
      "\n",
      "Error on: torch.Size([6, 6, 50])\n",
      "\n",
      "Error on: torch.Size([6, 6, 60])\n",
      "\n",
      "Error on: torch.Size([6, 6, 70])\n",
      "\n",
      "Error on: torch.Size([6, 6, 80])\n",
      "\n",
      "Error on: torch.Size([6, 6, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ff6a17ca2b4030a3aa2bc7d886b3b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([6, 8, 10])\n",
      "\n",
      "Error on: torch.Size([6, 8, 20])\n",
      "\n",
      "Error on: torch.Size([6, 8, 30])\n",
      "\n",
      "Error on: torch.Size([6, 8, 40])\n",
      "\n",
      "Error on: torch.Size([6, 8, 50])\n",
      "\n",
      "Error on: torch.Size([6, 8, 60])\n",
      "\n",
      "Error on: torch.Size([6, 8, 70])\n",
      "\n",
      "Error on: torch.Size([6, 8, 80])\n",
      "\n",
      "Error on: torch.Size([6, 8, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c596064c6d4614832a1d932e910336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([6, 10, 10])\n",
      "\n",
      "Error on: torch.Size([6, 10, 20])\n",
      "\n",
      "Error on: torch.Size([6, 10, 30])\n",
      "\n",
      "Error on: torch.Size([6, 10, 40])\n",
      "\n",
      "Error on: torch.Size([6, 10, 50])\n",
      "\n",
      "Error on: torch.Size([6, 10, 60])\n",
      "\n",
      "Error on: torch.Size([6, 10, 70])\n",
      "\n",
      "Error on: torch.Size([6, 10, 80])\n",
      "\n",
      "Error on: torch.Size([6, 10, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851c024df9ab4a51ae19efaaf2e9c2e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([6, 12, 10])\n",
      "\n",
      "Error on: torch.Size([6, 12, 20])\n",
      "\n",
      "Error on: torch.Size([6, 12, 30])\n",
      "\n",
      "Error on: torch.Size([6, 12, 40])\n",
      "\n",
      "Error on: torch.Size([6, 12, 50])\n",
      "\n",
      "Error on: torch.Size([6, 12, 60])\n",
      "\n",
      "Error on: torch.Size([6, 12, 70])\n",
      "\n",
      "Error on: torch.Size([6, 12, 80])\n",
      "\n",
      "Error on: torch.Size([6, 12, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2777e17b362c4a42b238877354ce05a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([6, 14, 10])\n",
      "\n",
      "Error on: torch.Size([6, 14, 20])\n",
      "\n",
      "Error on: torch.Size([6, 14, 30])\n",
      "\n",
      "Error on: torch.Size([6, 14, 40])\n",
      "\n",
      "Error on: torch.Size([6, 14, 50])\n",
      "\n",
      "Error on: torch.Size([6, 14, 60])\n",
      "\n",
      "Error on: torch.Size([6, 14, 70])\n",
      "\n",
      "Error on: torch.Size([6, 14, 80])\n",
      "\n",
      "Error on: torch.Size([6, 14, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f677ad69cd164fdb8be18b334c25d9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([6, 16, 10])\n",
      "\n",
      "Error on: torch.Size([6, 16, 20])\n",
      "\n",
      "Error on: torch.Size([6, 16, 30])\n",
      "\n",
      "Error on: torch.Size([6, 16, 40])\n",
      "\n",
      "Error on: torch.Size([6, 16, 50])\n",
      "\n",
      "Error on: torch.Size([6, 16, 60])\n",
      "\n",
      "Error on: torch.Size([6, 16, 70])\n",
      "\n",
      "Error on: torch.Size([6, 16, 80])\n",
      "\n",
      "Error on: torch.Size([6, 16, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f631dce697a4aca95be586e752ad820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([6, 18, 10])\n",
      "\n",
      "Error on: torch.Size([6, 18, 20])\n",
      "\n",
      "Error on: torch.Size([6, 18, 30])\n",
      "\n",
      "Error on: torch.Size([6, 18, 40])\n",
      "\n",
      "Error on: torch.Size([6, 18, 50])\n",
      "\n",
      "Error on: torch.Size([6, 18, 60])\n",
      "\n",
      "Error on: torch.Size([6, 18, 70])\n",
      "\n",
      "Error on: torch.Size([6, 18, 80])\n",
      "\n",
      "Error on: torch.Size([6, 18, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1cf55c59e24e56bef6e4631e41b792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([6, 20, 10])\n",
      "\n",
      "Error on: torch.Size([6, 20, 20])\n",
      "\n",
      "Error on: torch.Size([6, 20, 30])\n",
      "\n",
      "Error on: torch.Size([6, 20, 40])\n",
      "\n",
      "Error on: torch.Size([6, 20, 50])\n",
      "\n",
      "Error on: torch.Size([6, 20, 60])\n",
      "\n",
      "Error on: torch.Size([6, 20, 70])\n",
      "\n",
      "Error on: torch.Size([6, 20, 80])\n",
      "\n",
      "Error on: torch.Size([6, 20, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a8fa4ac55e48b6a533be148ff22648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([6, 22, 10])\n",
      "\n",
      "Error on: torch.Size([6, 22, 20])\n",
      "\n",
      "Error on: torch.Size([6, 22, 30])\n",
      "\n",
      "Error on: torch.Size([6, 22, 40])\n",
      "\n",
      "Error on: torch.Size([6, 22, 50])\n",
      "\n",
      "Error on: torch.Size([6, 22, 60])\n",
      "\n",
      "Error on: torch.Size([6, 22, 70])\n",
      "\n",
      "Error on: torch.Size([6, 22, 80])\n",
      "\n",
      "Error on: torch.Size([6, 22, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c776d3e55edd40fa9f8b8e3be82d713a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([6, 24, 10])\n",
      "\n",
      "Error on: torch.Size([6, 24, 20])\n",
      "\n",
      "Error on: torch.Size([6, 24, 30])\n",
      "\n",
      "Error on: torch.Size([6, 24, 40])\n",
      "\n",
      "Error on: torch.Size([6, 24, 50])\n",
      "\n",
      "Error on: torch.Size([6, 24, 60])\n",
      "\n",
      "Error on: torch.Size([6, 24, 70])\n",
      "\n",
      "Error on: torch.Size([6, 24, 80])\n",
      "\n",
      "Error on: torch.Size([6, 24, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2725edb240604306bcc4a6e631cc059b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([6, 26, 10])\n",
      "\n",
      "Error on: torch.Size([6, 26, 20])\n",
      "\n",
      "Error on: torch.Size([6, 26, 30])\n",
      "\n",
      "Error on: torch.Size([6, 26, 40])\n",
      "\n",
      "Error on: torch.Size([6, 26, 50])\n",
      "\n",
      "Error on: torch.Size([6, 26, 60])\n",
      "\n",
      "Error on: torch.Size([6, 26, 70])\n",
      "\n",
      "Error on: torch.Size([6, 26, 80])\n",
      "\n",
      "Error on: torch.Size([6, 26, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fedb73dab94dd2b713f1869bc1ce78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([6, 28, 10])\n",
      "\n",
      "Error on: torch.Size([6, 28, 20])\n",
      "\n",
      "Error on: torch.Size([6, 28, 30])\n",
      "\n",
      "Error on: torch.Size([6, 28, 40])\n",
      "\n",
      "Error on: torch.Size([6, 28, 50])\n",
      "\n",
      "Error on: torch.Size([6, 28, 60])\n",
      "\n",
      "Error on: torch.Size([6, 28, 70])\n",
      "\n",
      "Error on: torch.Size([6, 28, 80])\n",
      "\n",
      "Error on: torch.Size([6, 28, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9b34c8b7d94fbdafd3f03242a5293e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([6, 30, 10])\n",
      "\n",
      "Error on: torch.Size([6, 30, 20])\n",
      "\n",
      "Error on: torch.Size([6, 30, 30])\n",
      "\n",
      "Error on: torch.Size([6, 30, 40])\n",
      "\n",
      "Error on: torch.Size([6, 30, 50])\n",
      "\n",
      "Error on: torch.Size([6, 30, 60])\n",
      "\n",
      "Error on: torch.Size([6, 30, 70])\n",
      "\n",
      "Error on: torch.Size([6, 30, 80])\n",
      "\n",
      "Error on: torch.Size([6, 30, 90])\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9bd224358334d7b8f98de581f9aa9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e9f49b2c01448395a1642867907baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3885db07c0444bc5a23ce6d8f1e23ec1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a96b3f6017456997ad4cf5161d5e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9688709f139048d982e6ffa8d873987f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6827681d72a3417093ad0ac51c733791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d418503cfbf848bfbfb8b735a7791314",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae82385bc4854815ad5457f1d2622d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8751cd364e1a4dcfa14967d3270ef939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71784c47be74e49811ba68f5dc1ea7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f2c426d0b640ce81c04d63126ea162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a921e6123cd46cd826160b972ee48b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5870e9db9de45469dd751b2311a17ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5eebe2c09094af094ee3eba989b1709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ae08db1d7c4b659180a9d0382cb4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b7e4e48dc74a4ebf96ae986e0d1d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dee33c9ffbd4b59b1976d58c40265a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([10, 4, 10])\n",
      "\n",
      "Error on: torch.Size([10, 4, 20])\n",
      "\n",
      "Error on: torch.Size([10, 4, 30])\n",
      "\n",
      "Error on: torch.Size([10, 4, 40])\n",
      "\n",
      "Error on: torch.Size([10, 4, 50])\n",
      "\n",
      "Error on: torch.Size([10, 4, 60])\n",
      "\n",
      "Error on: torch.Size([10, 4, 70])\n",
      "\n",
      "Error on: torch.Size([10, 4, 80])\n",
      "\n",
      "Error on: torch.Size([10, 4, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96aba24b0a6413787d2cc2fe9e2b392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([10, 6, 10])\n",
      "\n",
      "Error on: torch.Size([10, 6, 20])\n",
      "\n",
      "Error on: torch.Size([10, 6, 30])\n",
      "\n",
      "Error on: torch.Size([10, 6, 40])\n",
      "\n",
      "Error on: torch.Size([10, 6, 50])\n",
      "\n",
      "Error on: torch.Size([10, 6, 60])\n",
      "\n",
      "Error on: torch.Size([10, 6, 70])\n",
      "\n",
      "Error on: torch.Size([10, 6, 80])\n",
      "\n",
      "Error on: torch.Size([10, 6, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682cd55e7fd24ba6be7c73fdee0de523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([10, 8, 10])\n",
      "\n",
      "Error on: torch.Size([10, 8, 20])\n",
      "\n",
      "Error on: torch.Size([10, 8, 30])\n",
      "\n",
      "Error on: torch.Size([10, 8, 40])\n",
      "\n",
      "Error on: torch.Size([10, 8, 50])\n",
      "\n",
      "Error on: torch.Size([10, 8, 60])\n",
      "\n",
      "Error on: torch.Size([10, 8, 70])\n",
      "\n",
      "Error on: torch.Size([10, 8, 80])\n",
      "\n",
      "Error on: torch.Size([10, 8, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d77e8f630549898fc648f90dc2cb06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([10, 10, 10])\n",
      "\n",
      "Error on: torch.Size([10, 10, 20])\n",
      "\n",
      "Error on: torch.Size([10, 10, 30])\n",
      "\n",
      "Error on: torch.Size([10, 10, 40])\n",
      "\n",
      "Error on: torch.Size([10, 10, 50])\n",
      "\n",
      "Error on: torch.Size([10, 10, 60])\n",
      "\n",
      "Error on: torch.Size([10, 10, 70])\n",
      "\n",
      "Error on: torch.Size([10, 10, 80])\n",
      "\n",
      "Error on: torch.Size([10, 10, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c673055b586476a9f96984b03c9d2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([10, 12, 10])\n",
      "\n",
      "Error on: torch.Size([10, 12, 20])\n",
      "\n",
      "Error on: torch.Size([10, 12, 30])\n",
      "\n",
      "Error on: torch.Size([10, 12, 40])\n",
      "\n",
      "Error on: torch.Size([10, 12, 50])\n",
      "\n",
      "Error on: torch.Size([10, 12, 60])\n",
      "\n",
      "Error on: torch.Size([10, 12, 70])\n",
      "\n",
      "Error on: torch.Size([10, 12, 80])\n",
      "\n",
      "Error on: torch.Size([10, 12, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88855a4d227e4c88827e7a5aa6ec57d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([10, 14, 10])\n",
      "\n",
      "Error on: torch.Size([10, 14, 20])\n",
      "\n",
      "Error on: torch.Size([10, 14, 30])\n",
      "\n",
      "Error on: torch.Size([10, 14, 40])\n",
      "\n",
      "Error on: torch.Size([10, 14, 50])\n",
      "\n",
      "Error on: torch.Size([10, 14, 60])\n",
      "\n",
      "Error on: torch.Size([10, 14, 70])\n",
      "\n",
      "Error on: torch.Size([10, 14, 80])\n",
      "\n",
      "Error on: torch.Size([10, 14, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3829207bef804b34b99e1a7e06a6293b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([10, 16, 10])\n",
      "\n",
      "Error on: torch.Size([10, 16, 20])\n",
      "\n",
      "Error on: torch.Size([10, 16, 30])\n",
      "\n",
      "Error on: torch.Size([10, 16, 40])\n",
      "\n",
      "Error on: torch.Size([10, 16, 50])\n",
      "\n",
      "Error on: torch.Size([10, 16, 60])\n",
      "\n",
      "Error on: torch.Size([10, 16, 70])\n",
      "\n",
      "Error on: torch.Size([10, 16, 80])\n",
      "\n",
      "Error on: torch.Size([10, 16, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382e2c4d87a245ac8a517914e02e540c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([10, 18, 10])\n",
      "\n",
      "Error on: torch.Size([10, 18, 20])\n",
      "\n",
      "Error on: torch.Size([10, 18, 30])\n",
      "\n",
      "Error on: torch.Size([10, 18, 40])\n",
      "\n",
      "Error on: torch.Size([10, 18, 50])\n",
      "\n",
      "Error on: torch.Size([10, 18, 60])\n",
      "\n",
      "Error on: torch.Size([10, 18, 70])\n",
      "\n",
      "Error on: torch.Size([10, 18, 80])\n",
      "\n",
      "Error on: torch.Size([10, 18, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf82359d07a34134883666a689fb3dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([10, 20, 10])\n",
      "\n",
      "Error on: torch.Size([10, 20, 20])\n",
      "\n",
      "Error on: torch.Size([10, 20, 30])\n",
      "\n",
      "Error on: torch.Size([10, 20, 40])\n",
      "\n",
      "Error on: torch.Size([10, 20, 50])\n",
      "\n",
      "Error on: torch.Size([10, 20, 60])\n",
      "\n",
      "Error on: torch.Size([10, 20, 70])\n",
      "\n",
      "Error on: torch.Size([10, 20, 80])\n",
      "\n",
      "Error on: torch.Size([10, 20, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ec5a6c221a248b2967db08dc4812254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([10, 22, 10])\n",
      "\n",
      "Error on: torch.Size([10, 22, 20])\n",
      "\n",
      "Error on: torch.Size([10, 22, 30])\n",
      "\n",
      "Error on: torch.Size([10, 22, 40])\n",
      "\n",
      "Error on: torch.Size([10, 22, 50])\n",
      "\n",
      "Error on: torch.Size([10, 22, 60])\n",
      "\n",
      "Error on: torch.Size([10, 22, 70])\n",
      "\n",
      "Error on: torch.Size([10, 22, 80])\n",
      "\n",
      "Error on: torch.Size([10, 22, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1a566753e384c71921b9ccd8a1b0360",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([10, 24, 10])\n",
      "\n",
      "Error on: torch.Size([10, 24, 20])\n",
      "\n",
      "Error on: torch.Size([10, 24, 30])\n",
      "\n",
      "Error on: torch.Size([10, 24, 40])\n",
      "\n",
      "Error on: torch.Size([10, 24, 50])\n",
      "\n",
      "Error on: torch.Size([10, 24, 60])\n",
      "\n",
      "Error on: torch.Size([10, 24, 70])\n",
      "\n",
      "Error on: torch.Size([10, 24, 80])\n",
      "\n",
      "Error on: torch.Size([10, 24, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f32af8909d742478d181c52724a02a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([10, 26, 10])\n",
      "\n",
      "Error on: torch.Size([10, 26, 20])\n",
      "\n",
      "Error on: torch.Size([10, 26, 30])\n",
      "\n",
      "Error on: torch.Size([10, 26, 40])\n",
      "\n",
      "Error on: torch.Size([10, 26, 50])\n",
      "\n",
      "Error on: torch.Size([10, 26, 60])\n",
      "\n",
      "Error on: torch.Size([10, 26, 70])\n",
      "\n",
      "Error on: torch.Size([10, 26, 80])\n",
      "\n",
      "Error on: torch.Size([10, 26, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08366fa787cc4918bc53e3403c17c8e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([10, 28, 10])\n",
      "\n",
      "Error on: torch.Size([10, 28, 20])\n",
      "\n",
      "Error on: torch.Size([10, 28, 30])\n",
      "\n",
      "Error on: torch.Size([10, 28, 40])\n",
      "\n",
      "Error on: torch.Size([10, 28, 50])\n",
      "\n",
      "Error on: torch.Size([10, 28, 60])\n",
      "\n",
      "Error on: torch.Size([10, 28, 70])\n",
      "\n",
      "Error on: torch.Size([10, 28, 80])\n",
      "\n",
      "Error on: torch.Size([10, 28, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409f5201b22e4e2ea78d83407594bded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([10, 30, 10])\n",
      "\n",
      "Error on: torch.Size([10, 30, 20])\n",
      "\n",
      "Error on: torch.Size([10, 30, 30])\n",
      "\n",
      "Error on: torch.Size([10, 30, 40])\n",
      "\n",
      "Error on: torch.Size([10, 30, 50])\n",
      "\n",
      "Error on: torch.Size([10, 30, 60])\n",
      "\n",
      "Error on: torch.Size([10, 30, 70])\n",
      "\n",
      "Error on: torch.Size([10, 30, 80])\n",
      "\n",
      "Error on: torch.Size([10, 30, 90])\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67d39d0669ab49959dccd12caf1bc6b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923ff90b3bef45bbb6b3523406ce3e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "278e21ed4405433eb9cd1040e794380d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06f1fcfa87843148d29c6c22d217636",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd1e977cf9934d4e8f6f28eb0d067aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1664437b5dd44df845d0294df8d729a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e9f2ca38bc4924ab5aa4e65d770db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a84e758c92e4c9d8d724c61419deb5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fa221ce32204135af637547e047b0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe4fb0914c94c8aa67252b11bba70f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee510c260c94699bfecfa83ca725b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff354552cf924e8caa325d88ace233b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27521048c39748ac9b8fdb6c00a016de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f899bbab3c414a9d2f0416bb99bc73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf1c12d1e1f2425aac0aa701425001b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "466d1a16633049289c73f5258fef47b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=14.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87c11c653fcf46ba9625d28bf9dac253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([14, 4, 10])\n",
      "\n",
      "Error on: torch.Size([14, 4, 20])\n",
      "\n",
      "Error on: torch.Size([14, 4, 30])\n",
      "\n",
      "Error on: torch.Size([14, 4, 40])\n",
      "\n",
      "Error on: torch.Size([14, 4, 50])\n",
      "\n",
      "Error on: torch.Size([14, 4, 60])\n",
      "\n",
      "Error on: torch.Size([14, 4, 70])\n",
      "\n",
      "Error on: torch.Size([14, 4, 80])\n",
      "\n",
      "Error on: torch.Size([14, 4, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a498877da09943218f1b614c8b8a3a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([14, 6, 10])\n",
      "\n",
      "Error on: torch.Size([14, 6, 20])\n",
      "\n",
      "Error on: torch.Size([14, 6, 30])\n",
      "\n",
      "Error on: torch.Size([14, 6, 40])\n",
      "\n",
      "Error on: torch.Size([14, 6, 50])\n",
      "\n",
      "Error on: torch.Size([14, 6, 60])\n",
      "\n",
      "Error on: torch.Size([14, 6, 70])\n",
      "\n",
      "Error on: torch.Size([14, 6, 80])\n",
      "\n",
      "Error on: torch.Size([14, 6, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8df59b565ce249ccae7ad7ea37f83069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([14, 8, 10])\n",
      "\n",
      "Error on: torch.Size([14, 8, 20])\n",
      "\n",
      "Error on: torch.Size([14, 8, 30])\n",
      "\n",
      "Error on: torch.Size([14, 8, 40])\n",
      "\n",
      "Error on: torch.Size([14, 8, 50])\n",
      "\n",
      "Error on: torch.Size([14, 8, 60])\n",
      "\n",
      "Error on: torch.Size([14, 8, 70])\n",
      "\n",
      "Error on: torch.Size([14, 8, 80])\n",
      "\n",
      "Error on: torch.Size([14, 8, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b9aa31b23664886b593dd0f5d6c15e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([14, 10, 10])\n",
      "\n",
      "Error on: torch.Size([14, 10, 20])\n",
      "\n",
      "Error on: torch.Size([14, 10, 30])\n",
      "\n",
      "Error on: torch.Size([14, 10, 40])\n",
      "\n",
      "Error on: torch.Size([14, 10, 50])\n",
      "\n",
      "Error on: torch.Size([14, 10, 60])\n",
      "\n",
      "Error on: torch.Size([14, 10, 70])\n",
      "\n",
      "Error on: torch.Size([14, 10, 80])\n",
      "\n",
      "Error on: torch.Size([14, 10, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7611f0a4e6da49a48845efe25a11895e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([14, 12, 10])\n",
      "\n",
      "Error on: torch.Size([14, 12, 20])\n",
      "\n",
      "Error on: torch.Size([14, 12, 30])\n",
      "\n",
      "Error on: torch.Size([14, 12, 40])\n",
      "\n",
      "Error on: torch.Size([14, 12, 50])\n",
      "\n",
      "Error on: torch.Size([14, 12, 60])\n",
      "\n",
      "Error on: torch.Size([14, 12, 70])\n",
      "\n",
      "Error on: torch.Size([14, 12, 80])\n",
      "\n",
      "Error on: torch.Size([14, 12, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b76c1ee76c24482a92ef53d361908d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([14, 14, 10])\n",
      "\n",
      "Error on: torch.Size([14, 14, 20])\n",
      "\n",
      "Error on: torch.Size([14, 14, 30])\n",
      "\n",
      "Error on: torch.Size([14, 14, 40])\n",
      "\n",
      "Error on: torch.Size([14, 14, 50])\n",
      "\n",
      "Error on: torch.Size([14, 14, 60])\n",
      "\n",
      "Error on: torch.Size([14, 14, 70])\n",
      "\n",
      "Error on: torch.Size([14, 14, 80])\n",
      "\n",
      "Error on: torch.Size([14, 14, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d331e7b94aef41b3960ce71832dff5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([14, 16, 10])\n",
      "\n",
      "Error on: torch.Size([14, 16, 20])\n",
      "\n",
      "Error on: torch.Size([14, 16, 30])\n",
      "\n",
      "Error on: torch.Size([14, 16, 40])\n",
      "\n",
      "Error on: torch.Size([14, 16, 50])\n",
      "\n",
      "Error on: torch.Size([14, 16, 60])\n",
      "\n",
      "Error on: torch.Size([14, 16, 70])\n",
      "\n",
      "Error on: torch.Size([14, 16, 80])\n",
      "\n",
      "Error on: torch.Size([14, 16, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d882c75167c4844bf88d8188bba8d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([14, 18, 10])\n",
      "\n",
      "Error on: torch.Size([14, 18, 20])\n",
      "\n",
      "Error on: torch.Size([14, 18, 30])\n",
      "\n",
      "Error on: torch.Size([14, 18, 40])\n",
      "\n",
      "Error on: torch.Size([14, 18, 50])\n",
      "\n",
      "Error on: torch.Size([14, 18, 60])\n",
      "\n",
      "Error on: torch.Size([14, 18, 70])\n",
      "\n",
      "Error on: torch.Size([14, 18, 80])\n",
      "\n",
      "Error on: torch.Size([14, 18, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8bd2048602410c9da54cc4db1c77b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([14, 20, 10])\n",
      "\n",
      "Error on: torch.Size([14, 20, 20])\n",
      "\n",
      "Error on: torch.Size([14, 20, 30])\n",
      "\n",
      "Error on: torch.Size([14, 20, 40])\n",
      "\n",
      "Error on: torch.Size([14, 20, 50])\n",
      "\n",
      "Error on: torch.Size([14, 20, 60])\n",
      "\n",
      "Error on: torch.Size([14, 20, 70])\n",
      "\n",
      "Error on: torch.Size([14, 20, 80])\n",
      "\n",
      "Error on: torch.Size([14, 20, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4c512c2eeb42029ca51b9a2e1d4681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([14, 22, 10])\n",
      "\n",
      "Error on: torch.Size([14, 22, 20])\n",
      "\n",
      "Error on: torch.Size([14, 22, 30])\n",
      "\n",
      "Error on: torch.Size([14, 22, 40])\n",
      "\n",
      "Error on: torch.Size([14, 22, 50])\n",
      "\n",
      "Error on: torch.Size([14, 22, 60])\n",
      "\n",
      "Error on: torch.Size([14, 22, 70])\n",
      "\n",
      "Error on: torch.Size([14, 22, 80])\n",
      "\n",
      "Error on: torch.Size([14, 22, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1260a3eed46c4ea28a0170834e4965d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([14, 24, 10])\n",
      "\n",
      "Error on: torch.Size([14, 24, 20])\n",
      "\n",
      "Error on: torch.Size([14, 24, 30])\n",
      "\n",
      "Error on: torch.Size([14, 24, 40])\n",
      "\n",
      "Error on: torch.Size([14, 24, 50])\n",
      "\n",
      "Error on: torch.Size([14, 24, 60])\n",
      "\n",
      "Error on: torch.Size([14, 24, 70])\n",
      "\n",
      "Error on: torch.Size([14, 24, 80])\n",
      "\n",
      "Error on: torch.Size([14, 24, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b30948572056409fa57330422c001a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([14, 26, 10])\n",
      "\n",
      "Error on: torch.Size([14, 26, 20])\n",
      "\n",
      "Error on: torch.Size([14, 26, 30])\n",
      "\n",
      "Error on: torch.Size([14, 26, 40])\n",
      "\n",
      "Error on: torch.Size([14, 26, 50])\n",
      "\n",
      "Error on: torch.Size([14, 26, 60])\n",
      "\n",
      "Error on: torch.Size([14, 26, 70])\n",
      "\n",
      "Error on: torch.Size([14, 26, 80])\n",
      "\n",
      "Error on: torch.Size([14, 26, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa32b44a73d4e18a640167779279365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([14, 28, 10])\n",
      "\n",
      "Error on: torch.Size([14, 28, 20])\n",
      "\n",
      "Error on: torch.Size([14, 28, 30])\n",
      "\n",
      "Error on: torch.Size([14, 28, 40])\n",
      "\n",
      "Error on: torch.Size([14, 28, 50])\n",
      "\n",
      "Error on: torch.Size([14, 28, 60])\n",
      "\n",
      "Error on: torch.Size([14, 28, 70])\n",
      "\n",
      "Error on: torch.Size([14, 28, 80])\n",
      "\n",
      "Error on: torch.Size([14, 28, 90])\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153f5f4c61d144d5a4d00990492aa131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=9.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on: torch.Size([14, 30, 10])\n",
      "\n",
      "Error on: torch.Size([14, 30, 20])\n",
      "\n",
      "Error on: torch.Size([14, 30, 30])\n",
      "\n",
      "Error on: torch.Size([14, 30, 40])\n",
      "\n",
      "Error on: torch.Size([14, 30, 50])\n",
      "\n",
      "Error on: torch.Size([14, 30, 60])\n",
      "\n",
      "Error on: torch.Size([14, 30, 70])\n",
      "\n",
      "Error on: torch.Size([14, 30, 80])\n",
      "\n",
      "Error on: torch.Size([14, 30, 90])\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = range(4,16,2)\n",
    "ydim = range(4,32,2)\n",
    "seqlen = range(10,100,10)\n",
    "\n",
    "for bs in tqdm_notebook(batch_sizes):\n",
    "    for y in tqdm_notebook(ydim):\n",
    "        for seq in tqdm_notebook(seqlen):\n",
    "            test = torch.rand((bs, y, seq))\n",
    "            try:\n",
    "                rlm = ReformerLM(vocab_size=100, \n",
    "                                 d_in=test.shape[-2], \n",
    "                                 d_out=test.shape[-1], \n",
    "                                 n_layers=6, \n",
    "                                 n_heads=1, \n",
    "                                 attn_k=test.shape[-1], \n",
    "                                 attn_v=test.shape[-1], \n",
    "                                )\n",
    "\n",
    "                output = rlm(test)\n",
    "                assert output.shape == torch.Size([bs, 1, rlm.vocab_size])\n",
    "            except AssertionError as e:\n",
    "                print(f'Error on: {test.shape}\\n{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 100])"
      ]
     },
     "execution_count": 1572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = torch.rand((4,4,40))\n",
    "\n",
    "rlm = ReformerLM(vocab_size=100, \n",
    "                 d_in=test.shape[-2], \n",
    "                 d_out=test.shape[-1], \n",
    "                 n_layers=6, \n",
    "                 n_heads=1, \n",
    "                 attn_k=test.shape[-1], \n",
    "                 attn_v=test.shape[-1], \n",
    "                )\n",
    "\n",
    "output = rlm(test)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1568,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
