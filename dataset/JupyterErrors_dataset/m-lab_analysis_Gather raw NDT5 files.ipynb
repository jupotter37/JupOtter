{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather all raw data files associated with a particular NDT5 UUID\n",
    "\n",
    "Steps:\n",
    "\n",
    "- Fetch the row from BQ and extract:\n",
    "  - GCS file name. Extract from the name:\n",
    "    - Server shortname\n",
    "    - Pusher datestring and timestamp\n",
    "    - Check if the date is too old\n",
    "  - From the row array, constrct tcpinfo tsg annotations\n",
    "  - Fetch the raw file\n",
    "- mkdir UUID\n",
    "- gsutil ls pcap path using pusher datestring and shortname\n",
    "- Select and fetch likely file (slightly earlier than ndt5 pusher timestamp)\n",
    "- system tar tvf and search UUID to find full path and file name\n",
    "- Extract file, mv to target dir and rmdir extras\n",
    "- tcptrace to extract xplots\n",
    "- Merge tcpinfo tsg annotations w/ b2a_tsg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import math\n",
    "import pandas as pd\n",
    "import BQhelper as bq\n",
    "from google.cloud import storage\n",
    "\n",
    "DataDir='/data/'  # Typically mounted at $HOME/data/\n",
    "TarDir=DataDir+'TARFILES/'\n",
    "os.makedirs(TarDir, exist_ok=True)\n",
    "\n",
    "UnitTest = False\n",
    "Verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CASES.    These are manually curated points of interst\n",
    "UUID1=\"ndt-r5mmc_1572346210_00000000000142D4\"\n",
    "# 2019-12-12 72.208.51.92 AZ\n",
    "# SELECT * FROM `mlab-sandbox.mm_unified_testing.ndt_unified_ndt5_downloads` WHERE a.UUID = 'ndt-r5mmc_1572346210_00000000000142D4'\n",
    "# gs://archive-measurement-lab/ndt/ndt5/2019/12/12/20191212T160135.233060Z-ndt5-mlab2-lax06-ndt.tgz\n",
    "# gs://archive-measurement-lab/ndt/tcpinfo/2019/12/12/20191212T172147.966587Z-tcpinfo-mlab2-lax06-ndt.tgz\n",
    "# \n",
    "\n",
    "# Deep dive into 80.0.65.231, after the trasnsition\n",
    "# See row 901 in 2020-04-25 Dissect 80.0.65.231across transition (adjust limits)\n",
    "# 2019-12-28 07:37:54.054766 UTC\n",
    "UUID2=\"ndt-m92kv_1573028939_0000000000056D7A\"\n",
    "\n",
    "if UnitTest:\n",
    "    Tuuid = UUID2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to parse a pusher data file names\n",
    "\n",
    "if UnitTest:\n",
    "    pf=\"gs://archive-measurement-lab/ndt/ndt5/2019/12/12/20191212T160135.233060Z-ndt5-mlab2-lax06-ndt.tgz\"\n",
    "\n",
    "def parseFullName(pf):\n",
    "    \"\"\"Parse the full name from an archived pusher tar file name\n",
    "    e.g. ndt/ndt5/2019/12/12/20191212T160135.233060Z-ndt5-mlab2-lax06-ndt.tgz\n",
    "    \"\"\"   \n",
    "    return('/'.join(pf.split('/')[3:]))\n",
    "\n",
    "def parseDir(pf):\n",
    "    \"\"\"Parse the gcs directory from an archived pusher tar file name\n",
    "    e.g. ndt/ndt5/2019/12/12/\n",
    "    \"\"\"\n",
    "    return('/'.join(pf.split('/')[3:-1]))\n",
    "\n",
    "def parseFile(pf):\n",
    "    \"\"\"Parse the gcs file from an archived pusher tar file name\n",
    "    e.g. 20191212T160135.233060Z-ndt5-mlab2-lax06-ndt.tgz\n",
    "    \"\"\"\n",
    "    return(pf.split('/')[-1])\n",
    "\n",
    "def parseDate(pf):\n",
    "    \"\"\"Parse and reformat the archive date from a pusher tar file name\n",
    "    e.g. 2019-12-12 (NB: this is NOT the test date)\n",
    "    \"\"\"\n",
    "    return('-'.join(pf.split('/')[-4:-1]))\n",
    "\n",
    "def parseTime(pf):\n",
    "    \"\"\"Parse the timestamp from an archived pusher tar file name\n",
    "    e.g. 20191212T160135\n",
    "    \"\"\"\n",
    "    return(pf.split('/')[-1].split('.')[0])\n",
    "    \n",
    "def parseShortName(pf):\n",
    "    \"\"\"Parse the server shortname from an archived pusher tar file name\n",
    "    e.g. mlab2-lax06\n",
    "    \"\"\"\n",
    "    return('-'.join(pf.split('-')[-3:-1]))\n",
    "\n",
    "if UnitTest:\n",
    "    print(pf)\n",
    "    print('FullName', parseFullName(pf))\n",
    "    print('Dir', parseDir(pf))\n",
    "    print('File', parseFile(pf))\n",
    "    print('Date', parseDate(pf))\n",
    "    print('Time', parseTime(pf))\n",
    "    print('ShortNane', parseShortName(pf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the Details for any given UUID\n",
    "# Including other UUIDs assocated with the same test\n",
    "# and all gcs paths.\n",
    "\n",
    "# TODO: how to generalize\n",
    "\n",
    "QueryDetails=\"\"\"\n",
    "SELECT\n",
    "  ParseInfo.TaskFileName,\n",
    "  result.C2S.UUID AS c2sUUID,\n",
    "  result.S2C.UUID AS s2cUUID,\n",
    "  result.Upload.UUID AS uploadUUID,\n",
    "  result.Download.UUID AS downloadUUID,\n",
    "  result.Control.UUID AS controlUUID,\n",
    "FROM `mlab-oti.ndt.ndt5`\n",
    "WHERE\n",
    "  result.C2S.UUID = '{UUID}' OR\n",
    "  result.S2C.UUID = '{UUID}' OR\n",
    "  result.Upload.UUID = '{UUID}' OR\n",
    "  result.Download.UUID = '{UUID}' OR\n",
    "  result.Control.UUID = '{UUID}'\n",
    "\"\"\"\n",
    "\n",
    "def getTestDetails(uuid):\n",
    "    \"\"\"Get details on where to find raw data associated with a test UUID\n",
    "    Returns:\n",
    "        the location of the primary raw data in gcs; and\n",
    "        a list of connection UUIDs associated wiht the test.\n",
    "    \"\"\"\n",
    "    q=bq.run_query(QueryDetails, UUID=uuid)\n",
    "    if (len(q['TaskFileName'])) > 1:\n",
    "            print(\"Warning: getTestDetails: (%d)\"%len(q['TaskFileName']))\n",
    "    ret=[]\n",
    "    for c in ['c2sUUID', 's2cUUID', 'uploadUUID','downloadUUID', 'controlUUID']:\n",
    "        if (q[c][0] is not None\n",
    "            and q[c][0] not in ret):\n",
    "                ret.append(q[c][0])\n",
    "        \n",
    "    return(q['TaskFileName'][0], ret)\n",
    "\n",
    "# Minimal test:\n",
    "if UnitTest:\n",
    "    TtaskFile, T_UUIDs = getTestDetails(Tuuid)\n",
    "    print (TtaskFile)\n",
    "    # gs://archive-measurement-lab/ndt/ndt5/2019/12/28/20191228T080102.072817Z-ndt5-mlab1-lhr04-ndt.tgz\n",
    "    print (T_UUIDs) # ['ndt-m92kv_1573028939_0000000000056D7A', 'ndt-m92kv_1573028939_0000000000056D78']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def listArchive(path):\n",
    "    \"\"\"List the files in a given GCS path\n",
    "    \"\"\"\n",
    "    client = storage.Client(project='mlab-sandbox')\n",
    "    bucket = client.get_bucket('archive-measurement-lab')\n",
    "    r = bucket.list_blobs(prefix=path)\n",
    "    return [i.name for i in r]\n",
    "\n",
    "# Minimal test\n",
    "if UnitTest:\n",
    "    T_archive = '/'.join(TtaskFile.split('/')[3:-1])\n",
    "    print (T_archive) # ndt/ndt5/2019/12/28\n",
    "    blobs = listArchive(T_archive)\n",
    "    print(len(blobs)) # 4947"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fetch an GCS Blob from the MLab archive\n",
    "# TODO: Add support for non-production archives\n",
    "\n",
    "def fetchBlob(blob, dest, bucket='archive-measurement-lab'):\n",
    "    \"\"\"Fetch a blob of data gsc\n",
    "    NB: blob excludes the bucket: e.g. 'gs://archive-measurement-lab/'\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.stat(dest)\n",
    "        return True\n",
    "    except:\n",
    "        pass\n",
    "    client = storage.Client(project='mlab-sandbox')\n",
    "    bucket = client.get_bucket(bucket)\n",
    "    blob = bucket.get_blob(blob)\n",
    "    with open(dest, 'wb') as file_obj:\n",
    "        client.download_blob_to_file(blob, file_obj)\n",
    "\n",
    "# Minimal test\n",
    "if UnitTest:\n",
    "    t = '/'.join(TtaskFile.split('/')[3:])\n",
    "    print(t)\n",
    "    # ndt/ndt5/2019/12/28/20191228T080102.072817Z-ndt5-mlab1-lhr04-ndt.tgz\n",
    "    Ttarfile = TarDir+'/test.ndt5.tgz'\n",
    "    fetchBlob(t, Ttarfile)\n",
    "    # Check for test.ndt5.tgz in TarDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def searchTar(uuids, tarFile):\n",
    "    \"\"\"Search for uuids in a tarfile, return file name if found\"\"\"\n",
    "    proc=subprocess.Popen([\"tar\", \"tf\", tarFile], stdout=subprocess.PIPE, text=True)\n",
    "    try:\n",
    "        outs, errs = proc.communicate(timeout=10)\n",
    "    except subprocess.TimeoutExpired:\n",
    "        proc.kill()\n",
    "        outs, errs = proc.communicate()\n",
    "    res = []\n",
    "    for l in outs.split():\n",
    "        for uuid in uuids:\n",
    "            if uuid in l:\n",
    "                if Verbose:\n",
    "                    print (\"Found: \"+l)\n",
    "                res.append(l)\n",
    "    return res\n",
    "\n",
    "def TarExtractFile(tarFile, targetDir, files):\n",
    "    \"\"\"Extract files from tarFile into targetDir\n",
    "    \"\"\"\n",
    "    args=[\"tar\", \"--extract\", \"-f\", tarFile,  \"--directory=\"+TarDir, *files]\n",
    "    if UnitTest:\n",
    "        print (args)\n",
    "    subprocess.run(args).check_returncode()\n",
    "    for file in files:\n",
    "        os.replace(TarDir+file, targetDir+file.split('/')[-1])\n",
    "    # TODO: rmdir 2019/.... (empty)\n",
    "    return [f.split('/')[-1] for f in files]\n",
    "\n",
    "if UnitTest:\n",
    "    os.makedirs(DataDir+\"test/\", exist_ok=True)\n",
    "    print (T_UUIDs[0])\n",
    "    # ndt-m92kv_1573028939_0000000000056D7A\n",
    "    print (searchTar(['xxx'], TarDir+'test.ndt5.tgz'))\n",
    "    # None\n",
    "    T_ndt5_json=searchTar(T_UUIDs, TarDir+'test.ndt5.tgz')\n",
    "    # Found: 2019/12/28/ndt-m92kv_1573028939_0000000000056D78.json\n",
    "    print (T_ndt5_json)\n",
    "    # 2019/12/28/ndt-m92kv_1573028939_0000000000056D78.json\n",
    "    print (TarExtractFile(TarDir+'test.ndt5.tgz', DataDir+\"test/\", T_ndt5_json))\n",
    "    # ndt-m92kv_1573028939_0000000000056D78.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New platform only\n",
    "\n",
    "\n",
    "def getPusherObject(TargetDir, UUIDs, shortname, timeHint, gcsDir):\n",
    "    \"\"\"\n",
    "    TargetDir - Results\n",
    "    UUIDs - List of UUIDs that we want\n",
    "    timeHint - test time stamp, to facilitate locating the data\n",
    "    gcsDir - Where to find the archive, w/o the bucket name\n",
    "    \"\"\"\n",
    "    blobs=listArchive(gcsDir)\n",
    "    blobs = [x for x in blobs if shortname in x]\n",
    "    if Verbose:\n",
    "        print (\"Available server-day pusher files:\", len(blobs))\n",
    "    otime = \"\"\n",
    "    ix = -1\n",
    "    for i, b in enumerate(blobs):\n",
    "        btime = parseTime(b)\n",
    "        if btime < otime:\n",
    "            print (\"Warning: non-monitonic timestamps %s>%s\"%(otime, time))\n",
    "        if btime <= timeHint:\n",
    "            ix = i\n",
    "        otime = btime\n",
    "    filelist=[]\n",
    "    for offset in [0, -1, 1, 2]:\n",
    "        if ix+offset >= 0 and ix+offset < len(blobs):\n",
    "            blob=blobs[ix+offset]\n",
    "            if Verbose:\n",
    "                print ('Trying:', ix+offset, blob)\n",
    "            tarFile=TarDir+blob.split('/')[-1]\n",
    "            fetchBlob(blob, tarFile)\n",
    "            fl=searchTar(UUIDs, tarFile)\n",
    "            if len(fl) > 0:\n",
    "                if Verbose:\n",
    "                    print('Extacting:',' '.join(fl))\n",
    "                TarExtractFile(tarFile, TargetDir, fl)\n",
    "                filelist.extend(fl)\n",
    "    return filelist\n",
    "\n",
    "\n",
    "if UnitTest:\n",
    "    T_pcapDir=parseDir(TtaskFile).replace('ndt5','pcap')\n",
    "    T_shortname=parseShortName(TtaskFile)  # mlab1-lhr04\n",
    "    T_testTime=parseTime(TtaskFile)\n",
    "    print(T_pcapDir, T_testTime)\n",
    "    \n",
    "    print(getPusherObject(DataDir+\"test/\", T_UUIDs, T_shortname, T_testTime, T_pcapDir));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# prototype main\n",
    "\n",
    "\n",
    "def GatherRawNDT5(uuid):\n",
    "    \"\"\"With just (any) UUID, gather all test data\n",
    "    \"\"\"\n",
    "    NDTtaskFile, UUIDs = getTestDetails(uuid)\n",
    "\n",
    "    if NDTtaskFile == '':\n",
    "        print (\"Failed to find Archive\")\n",
    "    if Verbose:\n",
    "        print('UUIDs: '+' '.join(UUIDs))\n",
    "        print(\"gcsNDTtaskFile: \"+NDTtaskFile)\n",
    "\n",
    "\n",
    "    # Make the target dir after the lookup to avoid debris from failures\n",
    "    # Stabilize UUIDs\n",
    "    # UUIDs=sorted(UUIDs)\n",
    "    if UUIDs[0] != uuid:\n",
    "        uuid = UUIDs[0]\n",
    "        print ('Updating base UUID (probably the control connection):',uuid)\n",
    "    TargetDir = DataDir+uuid+'/'\n",
    "    os.makedirs(TargetDir, exist_ok=True)\n",
    "    \n",
    "    # Guess pcap dir and search for likely tar files\n",
    "    shortname=parseShortName(NDTtaskFile)  # mlab1-lhr04\n",
    "    timeHint=parseTime(NDTtaskFile)\n",
    "    gcsDir=parseDir(NDTtaskFile)\n",
    "    print (shortname, timeHint, gcsDir)\n",
    "    ret={}\n",
    "    dataSets=['ndt5','ndt7','pcap','tcpinfo','traceeroute','web100']\n",
    "    for d in dataSets:\n",
    "        print (\"Checking for %s archives\"%d)\n",
    "        r=getPusherObject(TargetDir, UUIDs, shortname, timeHint, gcsDir.replace('ndt5',d))\n",
    "        if r is not None and len(r) > 0:\n",
    "            print ('Found',len(r), d,'archives')\n",
    "            ret[d]=r\n",
    "    return(ret)\n",
    "\n",
    "if UnitTest:\n",
    "    r=GatherRawNDT5(UUID2)\n",
    "    print (r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 Field name Upload does not exist in STRUCT<GitShortCommit STRING, Version STRING, ServerIP STRING, ...> at [13:10]\n",
      "\n",
      "(job ID: 622ad786-942d-41da-802d-56e5e50c846d)\n",
      "\n",
      "                    -----Query Job SQL Follows-----                     \n",
      "\n",
      "    |    .    |    .    |    .    |    .    |    .    |    .    |\n",
      "   1:\n",
      "   2:SELECT\n",
      "   3:  ParseInfo.TaskFileName,\n",
      "   4:  result.C2S.UUID AS c2sUUID,\n",
      "   5:  result.S2C.UUID AS s2cUUID,\n",
      "   6:  result.Upload.UUID AS uploadUUID,\n",
      "   7:  result.Download.UUID AS downloadUUID,\n",
      "   8:  result.Control.UUID AS controlUUID,\n",
      "   9:FROM `mlab-oti.ndt.ndt5`\n",
      "  10:WHERE\n",
      "  11:  result.C2S.UUID = 'ndt-qnzxt_1589228170_00000000000F556B' OR\n",
      "  12:  result.S2C.UUID = 'ndt-qnzxt_1589228170_00000000000F556B' OR\n",
      "  13:  result.Upload.UUID = 'ndt-qnzxt_1589228170_00000000000F556B' OR\n",
      "  14:  result.Download.UUID = 'ndt-qnzxt_1589228170_00000000000F556B' OR\n",
      "  15:  result.Control.UUID = 'ndt-qnzxt_1589228170_00000000000F556B'\n",
      "    |    .    |    .    |    .    |    .    |    .    |    .    |\n",
      "  1 \n",
      "  2 SELECT\n",
      "  3   ParseInfo.TaskFileName,\n",
      "  4   result.C2S.UUID AS c2sUUID,\n",
      "  5   result.S2C.UUID AS s2cUUID,\n",
      "  6   result.Upload.UUID AS uploadUUID,\n",
      "  7   result.Download.UUID AS downloadUUID,\n",
      "  8   result.Control.UUID AS controlUUID,\n",
      "  9 FROM `mlab-oti.ndt.ndt5`\n",
      " 10 WHERE\n",
      " 11   result.C2S.UUID = 'ndt-qnzxt_1589228170_00000000000F556B' OR\n",
      " 12   result.S2C.UUID = 'ndt-qnzxt_1589228170_00000000000F556B' OR\n",
      " 13   result.Upload.UUID = 'ndt-qnzxt_1589228170_00000000000F556B' OR\n",
      " 14   result.Download.UUID = 'ndt-qnzxt_1589228170_00000000000F556B' OR\n",
      " 15   result.Control.UUID = 'ndt-qnzxt_1589228170_00000000000F556B'\n",
      " 16 \n",
      "\n"
     ]
    },
    {
     "ename": "BadRequest",
     "evalue": "400 Field name Upload does not exist in STRUCT<GitShortCommit STRING, Version STRING, ServerIP STRING, ...> at [13:10]\n\n(job ID: 622ad786-942d-41da-802d-56e5e50c846d)\n\n                    -----Query Job SQL Follows-----                     \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:\n   2:SELECT\n   3:  ParseInfo.TaskFileName,\n   4:  result.C2S.UUID AS c2sUUID,\n   5:  result.S2C.UUID AS s2cUUID,\n   6:  result.Upload.UUID AS uploadUUID,\n   7:  result.Download.UUID AS downloadUUID,\n   8:  result.Control.UUID AS controlUUID,\n   9:FROM `mlab-oti.ndt.ndt5`\n  10:WHERE\n  11:  result.C2S.UUID = 'ndt-qnzxt_1589228170_00000000000F556B' OR\n  12:  result.S2C.UUID = 'ndt-qnzxt_1589228170_00000000000F556B' OR\n  13:  result.Upload.UUID = 'ndt-qnzxt_1589228170_00000000000F556B' OR\n  14:  result.Download.UUID = 'ndt-qnzxt_1589228170_00000000000F556B' OR\n  15:  result.Control.UUID = 'ndt-qnzxt_1589228170_00000000000F556B'\n    |    .    |    .    |    .    |    .    |    .    |    .    |",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b19c043003c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mUUID3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ndt-qnzxt_1589228170_00000000000F556B'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGatherRawNDT5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUUID3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-10158cb300a4>\u001b[0m in \u001b[0;36mGatherRawNDT5\u001b[0;34m(uuid)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \"\"\"With just (any) UUID, gather all test data\n\u001b[1;32m      6\u001b[0m     \"\"\"\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mNDTtaskFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUUIDs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetTestDetails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muuid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mNDTtaskFile\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-817239d8dd67>\u001b[0m in \u001b[0;36mgetTestDetails\u001b[0;34m(uuid)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mconnection\u001b[0m \u001b[0mUUIDs\u001b[0m \u001b[0massociated\u001b[0m \u001b[0mwiht\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \"\"\"\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryDetails\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUUID\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muuid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TaskFileName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Warning: getTestDetails: (%d)\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TaskFileName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/mattmathis/Projects/analysis/inspector/plottools/BQhelper.py\u001b[0m in \u001b[0;36mrun_query\u001b[0;34m(query, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, page_size, max_results, retry, timeout)\u001b[0m\n\u001b[1;32m   3194\u001b[0m             )\n\u001b[1;32m   3195\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3196\u001b[0;31m                 \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQueryJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/bigquery/job.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, retry, timeout)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mguard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremaining_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;31m# TODO: modify PollingFuture so it can pass a retry argument to done().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_AsyncJob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcancelled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/api_core/future/polling.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;31m# pylint: disable=raising-bad-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;31m# Pylint doesn't recognize that this is valid in this case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 Field name Upload does not exist in STRUCT<GitShortCommit STRING, Version STRING, ServerIP STRING, ...> at [13:10]\n\n(job ID: 622ad786-942d-41da-802d-56e5e50c846d)\n\n                    -----Query Job SQL Follows-----                     \n\n    |    .    |    .    |    .    |    .    |    .    |    .    |\n   1:\n   2:SELECT\n   3:  ParseInfo.TaskFileName,\n   4:  result.C2S.UUID AS c2sUUID,\n   5:  result.S2C.UUID AS s2cUUID,\n   6:  result.Upload.UUID AS uploadUUID,\n   7:  result.Download.UUID AS downloadUUID,\n   8:  result.Control.UUID AS controlUUID,\n   9:FROM `mlab-oti.ndt.ndt5`\n  10:WHERE\n  11:  result.C2S.UUID = 'ndt-qnzxt_1589228170_00000000000F556B' OR\n  12:  result.S2C.UUID = 'ndt-qnzxt_1589228170_00000000000F556B' OR\n  13:  result.Upload.UUID = 'ndt-qnzxt_1589228170_00000000000F556B' OR\n  14:  result.Download.UUID = 'ndt-qnzxt_1589228170_00000000000F556B' OR\n  15:  result.Control.UUID = 'ndt-qnzxt_1589228170_00000000000F556B'\n    |    .    |    .    |    .    |    .    |    .    |    .    |"
     ]
    }
   ],
   "source": [
    "UUID3='ndt-qnzxt_1589228170_00000000000F556B'\n",
    "r=GatherRawNDT5(UUID3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
