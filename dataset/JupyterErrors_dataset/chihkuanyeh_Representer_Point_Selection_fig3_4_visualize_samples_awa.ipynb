{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/cjyeh/anaconda/envs/py3/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# Import all modules\n",
    "%matplotlib inline\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import matplotlib.colors as mcolors\n",
    "from PIL import Image\n",
    "import scipy\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import h5py\n",
    "import torch.utils.data\n",
    "# Import Tensorflow with multiprocessing\n",
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint '../data/checkpoint.pth.tar'\n",
      "=> loaded checkpoint '../data/checkpoint.pth.tar' (epoch 90)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 519786464 into shape (29870,3,224,224)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2f905b5d93fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeature_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/checkpoint.pth.tar'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mval_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_AwA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-2f905b5d93fe>\u001b[0m in \u001b[0;36mload_AwA\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_AwA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/train_input_temp.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/train_label.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/val_input.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mval_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/val_label.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0;32m--> 421\u001b[0;31m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0;31m# Try a pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/numpy/lib/format.py\u001b[0m in \u001b[0;36mread_array\u001b[0;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m             \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 519786464 into shape (29870,3,224,224)"
     ]
    }
   ],
   "source": [
    "def load_AwA():\n",
    "    train_input = np.squeeze(np.load('../data/train_input.npy'))\n",
    "    train_label = np.squeeze(np.load('../data/train_label.npy'))\n",
    "    val_input = np.squeeze(np.load('../data/val_input.npy'))\n",
    "    val_label = np.squeeze(np.load('../data/val_label.npy'))\n",
    "    train_feature = np.squeeze(np.load('../data/train_feature_awa.npy'))\n",
    "    train_output = np.squeeze(np.load('../data/train_output_awa.npy'))\n",
    "    val_feature = np.squeeze(np.load('../data/val_feature_awa.npy'))\n",
    "    val_output = np.squeeze(np.load('../data/val_output_awa.npy'))\n",
    "    return train_input,train_label,val_input,val_label,train_feature,train_output,val_feature,val_output\n",
    "\n",
    "def resnet50_model(file):\n",
    "    model = models.__dict__['resnet50'](pretrained = True)\n",
    "    model.fc = torch.nn.Linear(2048,50)\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "    # optionally resume from a checkpoint\n",
    "    print(\"=> loading checkpoint '{}'\".format(file))\n",
    "    checkpoint = torch.load(file)\n",
    "    best_prec1 = checkpoint['best_prec1']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "                  .format(file, checkpoint['epoch'])) \n",
    "    feature_model = nn.Sequential(*list(model.module.children())[:-1])\n",
    "    feature_model = torch.nn.DataParallel(feature_model)\n",
    "    feature_model = feature_model.cuda()\n",
    "    return model,feature_model\n",
    "\n",
    "# Declare variables\n",
    "num_classes = 50 #    \n",
    "target_class = 9\n",
    "\n",
    "model,feature_model = resnet50_model('../data/checkpoint.pth.tar')\n",
    "train_input,train_label,val_input,val_label,train_feature,train_output,val_feature,val_output = load_AwA() \n",
    "x_train = train_input\n",
    "y_train = train_label\n",
    "x_test = val_input\n",
    "y_test = val_label\n",
    "        \n",
    "weight_matrix = np.load('../output/weight_matrix_AwA.npz')['weight_matrix']\n",
    "    \n",
    "train_output34 = train_feature\n",
    "test_output34 = val_feature\n",
    "\n",
    "class_names = dict()\n",
    "class_names[0] = 'antelope' \n",
    "class_names[1] = 'bat'\n",
    "class_names[2] = 'beaver'\n",
    "class_names[3] = 'blue whale' \n",
    "class_names[4] = 'bobcat'\n",
    "class_names[5] = 'buffalo' \n",
    "class_names[6] = 'chihuahua' \n",
    "class_names[7] = 'chimpanzee'\n",
    "class_names[8] = 'collie' \n",
    "class_names[9] = 'cow'\n",
    "class_names[10] = 'dalmation' \n",
    "class_names[11] = 'deer'\n",
    "class_names[12] = 'dolphin'\n",
    "class_names[13] = 'elephant' \n",
    "class_names[14] = 'fox'\n",
    "class_names[15] = 'german shepherd' \n",
    "class_names[16] = 'giant panda' \n",
    "class_names[17] = 'giraffe'\n",
    "class_names[18] = 'gorilla' \n",
    "class_names[19] = 'grizzly bear'\n",
    "class_names[20] = 'hamster' \n",
    "class_names[21] = 'hippopotamus'\n",
    "class_names[22] = 'horse'\n",
    "class_names[23] = 'humpback whale' \n",
    "class_names[24] = 'killer whale'\n",
    "class_names[25] = 'leopard' \n",
    "class_names[26] = 'lion' \n",
    "class_names[27] = 'mole'\n",
    "class_names[28] = 'moose' \n",
    "class_names[29] = 'mouse'\n",
    "class_names[30] = 'otter' \n",
    "class_names[31] = 'ox'\n",
    "class_names[32] = 'persian cat'\n",
    "class_names[33] = 'pig' \n",
    "class_names[34] = 'polar bear'\n",
    "class_names[35] = 'rabbit' \n",
    "class_names[36] = 'raccoon' \n",
    "class_names[37] = 'rat'\n",
    "class_names[38] = 'rhinoceros' \n",
    "class_names[39] = 'seal'\n",
    "class_names[40] = 'sheep' \n",
    "class_names[41] = 'siamese cat'\n",
    "class_names[42] = 'skunk'\n",
    "class_names[43] = 'spider monkey' \n",
    "class_names[44] = 'squirrel'\n",
    "class_names[45] = 'tiger' \n",
    "class_names[46] = 'walrus' \n",
    "class_names[47] = 'weasel'\n",
    "class_names[48] = 'wolf' \n",
    "class_names[49] = 'zebra'\n",
    "\n",
    "output_test_labels = np.argmax(val_output,axis=1)\n",
    "output_train_labels = np.argmax(train_output,axis=1)\n",
    "\n",
    "# Extra functions for visualization\n",
    "def denormalize(image,mean = [0.485,0.456,0.406],std = [0.229,0.224,0.225]):\n",
    "    return image*expand_dims_3(std) + expand_dims_3(mean)\n",
    "\n",
    "def expand_dims_3(arr):\n",
    "    return np.expand_dims(np.expand_dims(arr,0),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the weight matrix for each target class\n",
    "top_orders = dict()\n",
    "for k in range(num_classes):\n",
    "    idx = np.flip(np.argsort(weight_matrix[:,k]), axis=0)\n",
    "    top_orders[k] = idx\n",
    "    \n",
    "top_abs_orders = dict()\n",
    "for k in range(num_classes):\n",
    "    idx = np.flip(np.argsort(np.abs(weight_matrix[:,k])), axis=0)\n",
    "    top_abs_orders[k] = idx\n",
    "    \n",
    "# import influence values for the first 100 test points\n",
    "inf = np.load('../output/awa_inf_test_1000.npz')['influences']\n",
    "\n",
    "inf_pos_idx = np.flip(np.argsort(inf, axis=0), axis=0)\n",
    "inf_neg_idx = np.argsort(inf, axis=0)\n",
    "inf_abs_idx = np.flip(np.argsort(np.abs(inf), axis=0), axis=0)\n",
    "\n",
    "# test idx that were used to compute influences\n",
    "test_points = np.load('../output/idx_inf_awa_1000.npz')['idx']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "test_point = 3092    ## image of a grizzly bear\n",
    "# test_point = 5727    ## image of a rhino\n",
    "\n",
    "# need the test_point to be in test_points (since we are randomly selecting test points to compute the influence)\n",
    "assert(test_point in test_points)\n",
    "count = np.where(test_points == test_point)[0][0]\n",
    "\n",
    "target_class = output_test_labels[test_point]\n",
    "tmp = weight_matrix[:, target_class] * np.sum(train_feature * val_feature[test_point,:], axis=1)\n",
    "pos_idx = np.flip(np.argsort(tmp), axis=0)\n",
    "neg_idx = np.argsort(tmp)\n",
    "\n",
    "# influence orders, a list of indices of the training points sorted based on the influence values\n",
    "\n",
    "# the order for the paticular test point\n",
    "inf_pos_order = inf_pos_idx[:, count]\n",
    "inf_neg_order = inf_neg_idx[:, count]\n",
    "\n",
    "# select top k from the alpha * train * test values\n",
    "k = 3\n",
    "f, ax = plt.subplots(2,7, figsize=(18, 18 / 7. * 2))\n",
    "\n",
    "image = denormalize(x_test[test_point,:].transpose(1,2,0))\n",
    "ax[0,0].imshow(image)\n",
    "ax[0,0].set_title('test id%d\\n%s predicted as\\n%s'%(test_point, class_names[y_test[test_point]], class_names[output_test_labels[test_point]] ))\n",
    "ax[0,0].set_xticks(())\n",
    "ax[0,0].set_yticks(())\n",
    "\n",
    "ax[1,0].get_xaxis().set_visible(False)\n",
    "ax[1,0].set_yticks(())\n",
    "ax[1,0].set_xticks(())\n",
    "ax[1,0].axis('off')\n",
    "\n",
    "# Representer values (first three columns)\n",
    "for i in range(k):\n",
    "    # Positive ones\n",
    "    our_idx = pos_idx[i]\n",
    "    ax[0, i+1].imshow(denormalize(x_train[our_idx].transpose(1,2,0)))\n",
    "    ax[0, i+1].set_title('train id%d\\n%s predicted as\\n%s'%(our_idx, \\\n",
    "                                                            class_names[train_label[our_idx]],\\\n",
    "                                                            class_names[output_train_labels[our_idx]]))\n",
    "    ax[0, i+1].set_ylabel('POSITIVE Example', fontsize=14)\n",
    "    ax[0, i+1].yaxis.label.set_color('blue')\n",
    "    ax[0, i+1].set_xticks(())\n",
    "    ax[0, i+1].set_yticks(())\n",
    "\n",
    "    # Negative ones\n",
    "    our_idx = neg_idx[i]\n",
    "    ax[1, i+1].imshow(denormalize(x_train[our_idx].transpose(1,2,0)))\n",
    "    ax[1, i+1].set_title('train id%d\\n%s predicted as\\n%s'%(our_idx, \\\n",
    "                                                            class_names[train_label[our_idx]],\\\n",
    "                                                            class_names[output_train_labels[our_idx]]))\n",
    "    ax[1, i+1].set_ylabel('NEGATIVE Example', fontsize=14)\n",
    "    ax[1, i+1].yaxis.label.set_color('red')\n",
    "    ax[1, i+1].set_xticks(())\n",
    "    ax[1, i+1].set_yticks(())\n",
    "\n",
    "# Then influence function (next three columns)\n",
    "for i in range(k,2*k):\n",
    "    # positive \n",
    "    their_idx = inf_pos_order[i-k]\n",
    "    ax[0, i+1].imshow(denormalize(x_train[their_idx].transpose(1,2,0)))\n",
    "    ax[0, i+1].set_title('train id%d\\n%s predicted as\\n%s'%(their_idx, \\\n",
    "                                                            class_names[train_label[their_idx]],\\\n",
    "                                                            class_names[output_train_labels[their_idx]]))\n",
    "    ax[0, i+1].set_xticks(())\n",
    "    ax[0, i+1].set_yticks(())\n",
    "    ax[0, i+1].set_ylabel('POSITIVE Example', fontsize=14)\n",
    "    ax[0, i+1].yaxis.label.set_color('blue')\n",
    "\n",
    "    their_idx = inf_neg_order[i-k]\n",
    "    ax[1, i+1].imshow(denormalize(x_train[their_idx].transpose(1,2,0)))\n",
    "    ax[1, i+1].set_title('train id%d\\n%s predicted as\\n%s'%(their_idx, \\\n",
    "                                                            class_names[train_label[their_idx]],\\\n",
    "                                                            class_names[output_train_labels[their_idx]]))\n",
    "    ax[1, i+1].set_xticks(())\n",
    "    ax[1, i+1].set_yticks(())\n",
    "    ax[1, i+1].set_ylabel('NEGATIVE Example', fontsize=14)\n",
    "    ax[1, i+1].yaxis.label.set_color('red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('img_%d.png'%test_point, dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
