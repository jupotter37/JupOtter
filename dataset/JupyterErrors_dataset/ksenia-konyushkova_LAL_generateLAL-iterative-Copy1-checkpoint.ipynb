{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook we are using the generic code for generating LAL dataset.\n",
    "## New:\n",
    "## - can use any data as potential data for lal\n",
    "## - cen use sevral criteria for sampling (for now can either get random subsamples either sequential datasets based on previous data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import scipy\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Dataset4LAL import DatasetSimulated\n",
    "from Tree4LAL import Tree4LAL\n",
    "from LALmodel import LALmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "experiment = dict()\n",
    "# number of datasets for which we will generate data\n",
    "experiment['n_datasets'] = 500\n",
    "# how many datapoints will be labelled at the beginning, including 1 positive and 1 negative\n",
    "experiment['n_labelleds'] = np.arange(2,50,1)\n",
    "# how many times we will sample data with the same parameters\n",
    "experiment['n_points_per_experiment'] = 10\n",
    "# dimensionality of the data\n",
    "experiment['n_dim'] = 2\n",
    "# measure of quality change\n",
    "experiment['method'] = 'error'\n",
    "# for now 2 techniques for tree growing are available, random that means just adding random samples and iterative for adding points based on previously build model\n",
    "experiment['treegrowing'] = 'iterative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_lablled =  2\n",
      "********************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************start cross-validating..\n",
      "best parameters =  5000 ,  20 ,  7 , with the best score =  0.520551952881\n",
      "\n",
      "n_lablled =  3\n",
      "********************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************start cross-validating..\n",
      "best parameters =  1000 ,  20 ,  5 , with the best score =  0.49377663291\n",
      "\n",
      "n_lablled =  4\n",
      "********************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************start cross-validating..\n",
      "best parameters =  1000 ,  20 ,  5 , with the best score =  0.496499044074\n",
      "\n",
      "n_lablled =  5\n",
      "****************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************************"
     ]
    }
   ],
   "source": [
    "np.random.seed(805)\n",
    "\n",
    "nDatapoints = 400\n",
    "lalModels = []\n",
    "\n",
    "all_data_for_lal = np.array([[]])\n",
    "all_labels_for_lal = np.array([[]])\n",
    "\n",
    "all_sizes_data_for_lal = np.array([[]])\n",
    "all_sizes_labels_for_lal = np.array([[]])\n",
    "\n",
    "\n",
    "for n_labelled in experiment['n_labelleds']:\n",
    "    \n",
    "    print()\n",
    "    print('n_lablled = ', n_labelled)\n",
    "\n",
    "    all_data_for_lal = np.array([[]])\n",
    "    all_labels_for_lal = np.array([[]])\n",
    "    for i_dataset in range(experiment['n_datasets']):\n",
    "        print('*', end='')\n",
    "        dataset = DatasetSimulated(nDatapoints, experiment['n_dim'])\n",
    "        tree = Tree4LAL(experiment['treegrowing'], dataset, lalModels, experiment['method'])\n",
    "        tree.generateTree(n_labelled)\n",
    "        data_for_lal, labels_for_lal = tree.getLALdatapoints(experiment['n_points_per_experiment'])\n",
    "\n",
    "        # stack LAL data together\n",
    "        if np.size(all_data_for_lal)==0:\n",
    "            all_data_for_lal = data_for_lal\n",
    "            all_labels_for_lal = labels_for_lal\n",
    "        else:\n",
    "            all_data_for_lal = np.concatenate((all_data_for_lal, data_for_lal), axis=0)\n",
    "            all_labels_for_lal = np.concatenate((all_labels_for_lal, labels_for_lal), axis=0)\n",
    "\n",
    "    \n",
    "    if experiment['treegrowing']=='iterative':\n",
    "        # for every size of the tree train a lal model and attach it to the list of models for all sizes of trees\n",
    "        # also let's do some cross validation to find better parameters \n",
    "        lalModel = LALmodel(all_data_for_lal, all_labels_for_lal)\n",
    "        lalModel.crossValidateLALmodel()\n",
    "        lalModels.append(lalModel.model)\n",
    "    \n",
    "    # data to save to build the big tree at the end\n",
    "    \n",
    "    if np.size(all_sizes_data_for_lal)==0:\n",
    "        all_sizes_data_for_lal = all_data_for_lal\n",
    "        all_sizes_labels_for_lal = all_labels_for_lal\n",
    "    else:\n",
    "        all_sizes_data_for_lal = np.concatenate((all_sizes_data_for_lal, all_data_for_lal), axis=0)\n",
    "        all_sizes_labels_for_lal = np.concatenate((all_sizes_labels_for_lal, all_labels_for_lal), axis=0)\n",
    "    np.savez('./lal datasets/LAL-iterativetree-simulated2Gauss2dim', all_sizes_data_for_lal, all_sizes_labels_for_lal)\n",
    "    \n",
    "lalModel = LALmodel(all_sizes_data_for_lal, all_sizes_labels_for_lal)\n",
    "lalModel.crossValidateLALmodel()\n",
    "\n",
    "print(all_sizes_data_for_lal.shape)\n",
    "print(all_sizes_labels_for_lal.shape)\n",
    "\n",
    "np.savez('./lal datasets/LAL-iterativetree-simulated2Gauss2dim', all_sizes_data_for_lal, all_sizes_labels_for_lal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start cross-validating..\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(1, 0)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-0cdfe24649e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlalModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLALmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_sizes_data_for_lal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_sizes_labels_for_lal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlalModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrossValidateLALmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/cvlabdata1/home/ksenia/LAL/17 - generic LAL dataset generation/LALmodel.py\u001b[0m in \u001b[0;36mcrossValidateLALmodel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossible_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moob_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_data_for_lal\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_labels_for_lal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moob_score_\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_est\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/konyushk/.virtualenvs/lal/lib/python3.5/site-packages/sklearn/ensemble/forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \"\"\"\n\u001b[1;32m    211\u001b[0m         \u001b[0;31m# Validate or convert input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;31m# Pre-sort indices to avoid that each individual tree of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/konyushk/.virtualenvs/lal/lib/python3.5/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    413\u001b[0m                              \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m                              % (n_features, shape_repr, ensure_min_features,\n\u001b[0;32m--> 415\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(1, 0)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "lalModel = LALmodel(all_sizes_data_for_lal, all_sizes_labels_for_lal)\n",
    "lalModel.crossValidateLALmodel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
