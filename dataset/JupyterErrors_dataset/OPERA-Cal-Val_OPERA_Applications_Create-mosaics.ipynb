{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to create mosaics of the DSWx product that are relatively cloud free over different parts of the world. In this notebook, we demonstrate generating these mosaics over Australia and California. The shapefile for CA was obtained [from here](https://data.ca.gov/dataset/ca-geographic-boundaries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GIS imports\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.warp import transform_bounds, calculate_default_transform, reproject, Resampling\n",
    "from shapely import Polygon\n",
    "import fiona\n",
    "\n",
    "# misc imports\n",
    "from pystac_client import Client\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from multiprocessing import Pool\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "\n",
    "# web imports\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of CMR service\n",
    "STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "\n",
    "# Setup PySTAC client\n",
    "provider_cat = Client.open(STAC_URL)\n",
    "catalog = Client.open(f'{STAC_URL}/POCLOUD/')\n",
    "collections = [\"OPERA_L3_DSWX-HLS_PROVISIONAL_V1\"]\n",
    "\n",
    "# We would like to create mosaics for April 2023\n",
    "date_range = \"2023-04-01/2023-04-30\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSWx mosaics over Australia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all relevant mosaics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the geometry for Australia to retrieve bounding boxes for our search\n",
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n",
    "australia_shape = world[world['name']=='Australia']\n",
    "bbox = australia_shape.iloc[0].geometry.bounds\n",
    "print(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = {\n",
    "    'bbox' : bbox, \n",
    "    'collections': collections,\n",
    "    'datetime' : date_range,\n",
    "    # querying by cloud cover does not work (04/27/23)\n",
    "    # We will instead filter results by parsing the associated XML files for each granule\n",
    "    # 'query':{\n",
    "    #     'eo:cloud_cover':{\n",
    "    #         'lt': 10    \n",
    "    #     },\n",
    "    # }\n",
    "}\n",
    "\n",
    "search = catalog.search(**opts)\n",
    "items = search.get_all_items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for cloud cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "604\n"
     ]
    }
   ],
   "source": [
    "def filter_by_cloud_cover(item, threshold=10):\n",
    "    xml_url = item.assets['metadata'].href\n",
    "    response = urlopen(xml_url)\n",
    "    data_json = json.loads(response.read()) # the XML files are formatted as JSONs (?!), so we use a JSON reader\n",
    "\n",
    "    for item in data_json['AdditionalAttributes']:\n",
    "        if item['Name'] == 'PercentCloudCover':\n",
    "            break\n",
    "    c_cover = int(item['Values'][0])\n",
    "    if c_cover<=threshold:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "filtered_items = list(filter(filter_by_cloud_cover, items))\n",
    "print(len(filtered_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_granule(item):\n",
    "    return item.assets['0_B01_WTR'].href\n",
    "filtered_urls = list(map(return_granule, filtered_items))\n",
    "print(len(filtered_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download granules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('../data/australia')\n",
    "if not output_path.exists():\n",
    "    output_path.mkdir(parents=True)\n",
    "\n",
    "def download_data(file_list):\n",
    "    for f in file_list:\n",
    "        try:\n",
    "            os.system(f\"wget {f} -nc -q -P {output_path}\") # don't clobber, and download quietly\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can parallelize the downloads\n",
    "url_chunks = np.array_split(filtered_urls, 30)\n",
    "with Pool() as pool:\n",
    "    _ = pool.map(download_data, url_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfiles = len(list(output_path.glob('OPERA*.tif')))\n",
    "print(nfiles)\n",
    "\n",
    "# DSWx files have colormaps associated with them. Let's save it for later use\n",
    "with rasterio.open(list(output_path.glob('OPERA*.tif'))[0]) as ds:\n",
    "    dswx_colormap = ds.colormap(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize and mosaic granules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_by_crs = defaultdict(list)\n",
    "for f in [f for f in output_path.iterdir() if f.is_dir()]:\n",
    "    files_by_crs[f.name] = list(f.glob(\"OPERA*.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize downloaded into folders by CRS \n",
    "files_by_crs = defaultdict(list)\n",
    "for i, f in enumerate(list(output_path.glob('*.tif'))):\n",
    "    with rasterio.open(f) as ds:\n",
    "        files_by_crs[ds.profile['crs'].to_string()].append(f)\n",
    "\n",
    "def organize_by_crs(crs, file_list):\n",
    "    current_output_path = output_path/crs\n",
    "    if not current_output_path.exists():\n",
    "        current_output_path.mkdir()\n",
    "    \n",
    "    for f in file_list:\n",
    "        f.rename(current_output_path/f.name)\n",
    "\n",
    "_ = list(map(organize_by_crs, files_by_crs.keys(), files_by_crs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function will take a list of files in the same CRS and mosaic them, and then reproject it to \n",
    "# EPSG:4326.\n",
    "\n",
    "def process_file_batch(epsg_code, file_batch, output_filename, resolution_reduction_factor = 2):\n",
    "    dst_crs = 'EPSG:4326'\n",
    "    merged_img, merged_transform = merge(file_batch, method='min')\n",
    "    merged_output_bounds = rasterio.transform.array_bounds(merged_img.shape[-2], merged_img.shape[-1] , merged_transform)\n",
    "\n",
    "    kwargs = {\n",
    "        \"src_crs\": epsg_code, \n",
    "        \"dst_crs\": dst_crs, \n",
    "        \"width\":merged_img.shape[-1], \n",
    "        \"height\": merged_img.shape[-2], \n",
    "        \"left\": merged_output_bounds[0],\n",
    "        \"bottom\": merged_output_bounds[1],\n",
    "        \"right\": merged_output_bounds[2],\n",
    "        \"top\": merged_output_bounds[3],\n",
    "        \"dst_width\": merged_img.shape[-1]//resolution_reduction_factor, \n",
    "        \"dst_height\":merged_img.shape[-2]//resolution_reduction_factor  \n",
    "    }\n",
    "    \n",
    "    dst_transform, width, height = calculate_default_transform(**kwargs)\n",
    "\n",
    "    with rasterio.open(file_batch[0]) as src:\n",
    "        dst_kwargs = src.profile.copy()\n",
    "        dst_kwargs.update({\n",
    "            'height':height,\n",
    "            'width':width,\n",
    "            'transform':dst_transform,\n",
    "            'crs':dst_crs\n",
    "        })\n",
    "        \n",
    "        with rasterio.open(output_filename, 'w', **dst_kwargs) as dst:\n",
    "            reproject(\n",
    "                source = merged_img, \n",
    "                destination = rasterio.band(dst, 1), \n",
    "                src_transform = merged_transform,\n",
    "                dst_transform = dst_transform,\n",
    "                src_crs = src.crs,\n",
    "                dst_crs = dst_crs,\n",
    "                resampling=Resampling.nearest\n",
    "            )\n",
    "            dst.write_colormap(1, dswx_colormap)\n",
    "\n",
    "    return output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mosaicking a large number of files in one attempt will be time and memory intensive.\n",
    "# Instead, we can mosaic chunks in parallel, and reduce the resolution of each mosaic by a factor of 2\n",
    "# The mosaics generated in this step can then be subsequently combined similarly\n",
    "\n",
    "for key in files_by_crs.keys():\n",
    "    mosaic_folder = (output_path/key/'mosaics')\n",
    "    mosaic_folder.mkdir(parents=True, exist_ok=True)\n",
    "    filenames = list((output_path/key).glob('*.tif'))\n",
    "    filename_chunks = np.array_split(filenames, 30)\n",
    "    \n",
    "    output_filename = 'temp_{}_{}.tif'\n",
    "\n",
    "    function_inputs = []\n",
    "    function_inputs = [(key, chunk, mosaic_folder/output_filename.format(key, str(count).zfill(4))) for count, chunk in enumerate(filename_chunks) if len(chunk) > 0]\n",
    "    \n",
    "    with Pool() as pool:\n",
    "        output_files = pool.starmap(process_file_batch, function_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate final mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_list = []\n",
    "for folder in output_path.iterdir():\n",
    "    if folder.name == 'outputs':\n",
    "        pass\n",
    "    for file in list((folder /'mosaics').glob('*.tif')):\n",
    "        mosaic_list.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mosaic_path = Path('../data/australia/outputs')\n",
    "if not final_mosaic_path.exists():\n",
    "    final_mosaic_path.mkdir()\n",
    "process_file_batch('EPSG:4326', mosaic_list, Path(final_mosaic_path / 'final_mosaic.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSWx mosaics over CA/NV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-124.48201686078049, 32.52883673637252, -114.13122247508855, 42.00950826967186)\n"
     ]
    }
   ],
   "source": [
    "ca_state = gpd.read_file('../data/shapefiles/california_state/CA_State_TIGER2016.shp')\n",
    "ca_geom = ca_state.iloc[0].geometry\n",
    "ca_bounds = ca_geom.bounds\n",
    "\n",
    "if ca_state.crs.to_epsg() != 4326:\n",
    "    ca_bounds = transform_bounds(CRS.from_epsg(ca_state.crs.to_epsg()), CRS.from_epsg(4326), *ca_bounds)\n",
    "print(ca_bounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all relevant mosaics, and filter for cloud cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIError",
     "evalue": "{\"message\":\"If the problem persists please contact cmr-support@earthdata.nasa.gov\",\"errors\":[\"An unexpected error occurred. We have been alerted and are working to resolve the problem.\",\"request entity too large\"]}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 27\u001b[0m\n\u001b[1;32m     12\u001b[0m opts \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# 'bbox' : ca_bounds, \u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintersects\u001b[39m\u001b[38;5;124m'\u001b[39m : ca_geom,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# }\u001b[39;00m\n\u001b[1;32m     24\u001b[0m }\n\u001b[1;32m     26\u001b[0m search \u001b[38;5;241m=\u001b[39m catalog\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n\u001b[0;32m---> 27\u001b[0m items \u001b[38;5;241m=\u001b[39m \u001b[43msearch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_all_items\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m filtered_items \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(filter_by_cloud_cover, items))\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(filtered_items))\n",
      "File \u001b[0;32m~/mambaforge/envs/mosaics/lib/python3.11/site-packages/pystac_client/item_search.py:844\u001b[0m, in \u001b[0;36mItemSearch.get_all_items\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"DEPRECATED\u001b[39;00m\n\u001b[1;32m    833\u001b[0m \n\u001b[1;32m    834\u001b[0m \u001b[39m.. deprecated:: 0.4.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    838\u001b[0m \u001b[39m    item_collection : ItemCollection\u001b[39;00m\n\u001b[1;32m    839\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    840\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    841\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mget_all_items() is deprecated, use item_collection() instead.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    842\u001b[0m     \u001b[39mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    843\u001b[0m )\n\u001b[0;32m--> 844\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitem_collection()\n",
      "File \u001b[0;32m~/mambaforge/envs/mosaics/lib/python3.11/site-packages/pystac_client/item_search.py:745\u001b[0m, in \u001b[0;36mItemSearch.item_collection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    738\u001b[0m \u001b[39mGet the matching items as a :py:class:`pystac.ItemCollection`.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \n\u001b[1;32m    740\u001b[0m \u001b[39mReturn:\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[39m    ItemCollection: The item collection\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[39m# Bypass the cache here, so that we can pass __preserve_dict__\u001b[39;00m\n\u001b[1;32m    744\u001b[0m \u001b[39m# without mutating what's in the cache.\u001b[39;00m\n\u001b[0;32m--> 745\u001b[0m feature_collection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitem_collection_as_dict\u001b[39m.\u001b[39;49m__wrapped__(\u001b[39mself\u001b[39;49m)\n\u001b[1;32m    746\u001b[0m \u001b[39m# already signed in item_collection_as_dict\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[39mreturn\u001b[39;00m ItemCollection\u001b[39m.\u001b[39mfrom_dict(\n\u001b[1;32m    748\u001b[0m     feature_collection, preserve_dict\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, root\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\n\u001b[1;32m    749\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/mosaics/lib/python3.11/site-packages/pystac_client/item_search.py:766\u001b[0m, in \u001b[0;36mItemSearch.item_collection_as_dict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    754\u001b[0m \u001b[39mGet the matching items as an item-collection-like dict.\u001b[39;00m\n\u001b[1;32m    755\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[39m    Dict : A GeoJSON FeatureCollection\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    765\u001b[0m features \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 766\u001b[0m \u001b[39mfor\u001b[39;00m page \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stac_io\u001b[39m.\u001b[39mget_pages(\n\u001b[1;32m    767\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39murl, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmethod, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_parameters()\n\u001b[1;32m    768\u001b[0m ):\n\u001b[1;32m    769\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m page[\u001b[39m\"\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    770\u001b[0m         features\u001b[39m.\u001b[39mappend(feature)\n",
      "File \u001b[0;32m~/mambaforge/envs/mosaics/lib/python3.11/site-packages/pystac_client/stac_api_io.py:248\u001b[0m, in \u001b[0;36mStacApiIO.get_pages\u001b[0;34m(self, url, method, parameters)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_pages\u001b[39m(\n\u001b[1;32m    237\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    238\u001b[0m     url: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    239\u001b[0m     method: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    240\u001b[0m     parameters: Optional[Dict[\u001b[39mstr\u001b[39m, Any]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    241\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Iterator[Dict[\u001b[39mstr\u001b[39m, Any]]:\n\u001b[1;32m    242\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Iterator that yields dictionaries for each page at a STAC paging\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39m    endpoint, e.g., /collections, /search\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \n\u001b[1;32m    245\u001b[0m \u001b[39m    Return:\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[39m        Dict[str, Any] : JSON content from a single page\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m     page \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_json(url, method\u001b[39m=\u001b[39;49mmethod, parameters\u001b[39m=\u001b[39;49mparameters)\n\u001b[1;32m    249\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (page\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m page\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mcollections\u001b[39m\u001b[39m\"\u001b[39m)):\n\u001b[1;32m    250\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/mosaics/lib/python3.11/site-packages/pystac/stac_io.py:202\u001b[0m, in \u001b[0;36mStacIO.read_json\u001b[0;34m(self, source, *args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_json\u001b[39m(\u001b[39mself\u001b[39m, source: HREF, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m    186\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Read a dict from the given source.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \n\u001b[1;32m    188\u001b[0m \u001b[39m    See :func:`StacIO.read_text <pystac.StacIO.read_text>` for usage of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39m        given source.\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m     txt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_text(source, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    203\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjson_loads(txt)\n",
      "File \u001b[0;32m~/mambaforge/envs/mosaics/lib/python3.11/site-packages/pystac_client/stac_api_io.py:123\u001b[0m, in \u001b[0;36mStacApiIO.read_text\u001b[0;34m(self, source, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m href \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(source)\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m _is_url(href):\n\u001b[0;32m--> 123\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(href, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    124\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    125\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(href) \u001b[39mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/mambaforge/envs/mosaics/lib/python3.11/site-packages/pystac_client/stac_api_io.py:171\u001b[0m, in \u001b[0;36mStacApiIO.request\u001b[0;34m(self, href, method, headers, parameters)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[39mraise\u001b[39;00m APIError(\u001b[39mstr\u001b[39m(err))\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m resp\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m--> 171\u001b[0m     \u001b[39mraise\u001b[39;00m APIError\u001b[39m.\u001b[39mfrom_response(resp)\n\u001b[1;32m    172\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    173\u001b[0m     \u001b[39mreturn\u001b[39;00m resp\u001b[39m.\u001b[39mcontent\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAPIError\u001b[0m: {\"message\":\"If the problem persists please contact cmr-support@earthdata.nasa.gov\",\"errors\":[\"An unexpected error occurred. We have been alerted and are working to resolve the problem.\",\"request entity too large\"]}"
     ]
    }
   ],
   "source": [
    "# Searching for DSWx over CA\n",
    "# search options can use either a bounding box or intersection with a shape, see below\n",
    "STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "\n",
    "# Setup PySTAC client\n",
    "provider_cat = Client.open(STAC_URL)\n",
    "catalog = Client.open(f'{STAC_URL}/POCLOUD/')\n",
    "collections = [\"OPERA_L3_DSWX-HLS_PROVISIONAL_V1\"]\n",
    "\n",
    "date_range = \"2023-04-01/2023-04-30\"\n",
    "\n",
    "opts = {\n",
    "    'bbox' : ca_bounds, \n",
    "    # uncomment to search by shape\n",
    "    # however, this currently returns an API error (05/15/23)\n",
    "    # 'intersects' : ca_geom, \n",
    "    'collections': collections,\n",
    "    'datetime' : date_range,\n",
    "    # querying by cloud cover does not work (04/27/23)\n",
    "    # We will instead filter results by parsing the associated XML files for each granule\n",
    "    # 'query':{\n",
    "    #     'eo:cloud_cover':{\n",
    "    #         'lt': 10    \n",
    "    #     },\n",
    "    # }\n",
    "}\n",
    "\n",
    "search = catalog.search(**opts)\n",
    "items = search.get_all_items()\n",
    "\n",
    "filtered_items = list(filter(filter_by_cloud_cover, items))\n",
    "print(len(filtered_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_urls = list(map(return_granule, filtered_items))\n",
    "print(len(filtered_urls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download granules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('../data/california')\n",
    "files_by_crs = defaultdict(list)\n",
    "for f in [f for f in output_path.iterdir() if f.is_dir()]:\n",
    "    files_by_crs[f.name] = list(f.glob(\"OPERA*.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = Path('../data/california')\n",
    "if not output_path.exists():\n",
    "    output_path.mkdir(parents=True)\n",
    "\n",
    "# We can parallelize the downloads\n",
    "url_chunks = np.array_split(filtered_urls, 30)\n",
    "with Pool() as pool:\n",
    "    _ = pool.map(download_data, url_chunks)\n",
    "\n",
    "nfiles = len(list(output_path.glob('*.tif')))\n",
    "print(nfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organize and mosaic granules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize downloaded into folders by CRS \n",
    "files_by_crs = defaultdict(list)\n",
    "for i, f in enumerate(list(output_path.glob('*.tif'))):\n",
    "    with rasterio.open(f) as ds:\n",
    "        files_by_crs[ds.profile['crs'].to_string()].append(f)\n",
    "\n",
    "_ = list(map(organize_by_crs, files_by_crs.keys(), files_by_crs.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSWx files have colormaps associated with them. Let's save it for later use\n",
    "with rasterio.open(files_by_crs[list(files_by_crs.keys())[0]][0]) as ds:\n",
    "    dswx_colormap = ds.colormap(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in files_by_crs.keys():\n",
    "    mosaic_folder = (output_path/key/'mosaics')\n",
    "    mosaic_folder.mkdir(parents=True, exist_ok=True)\n",
    "    filenames = list((output_path/key).glob('*.tif'))\n",
    "    filename_chunks = np.array_split(filenames, 30)\n",
    "    \n",
    "    output_filename = 'temp_{}_{}.tif'\n",
    "\n",
    "    function_inputs = []\n",
    "    function_inputs = [(key, chunk, mosaic_folder/output_filename.format(key, str(count).zfill(4)), 1) for count, chunk in enumerate(filename_chunks) if len(chunk) > 0]\n",
    "    \n",
    "    with Pool() as pool:\n",
    "        output_files = pool.starmap(process_file_batch, function_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mosaic_list = []\n",
    "for folder in output_path.iterdir():\n",
    "    if folder.name == 'outputs':\n",
    "        pass\n",
    "    for file in list((folder /'mosaics').glob('*.tif')):\n",
    "        mosaic_list.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate final mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_mosaic_path = Path('../data/california/outputs')\n",
    "if not final_mosaic_path.exists():\n",
    "    final_mosaic_path.mkdir()\n",
    "process_file_batch('EPSG:4326', mosaic_list, Path(final_mosaic_path / 'final_mosaic.tif'), 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('mosaics')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0dda92ab469048a6a29a7917e3d17692de0e4ddad2d06f4cd2ec3294bacfe4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
