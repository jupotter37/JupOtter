{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image, ImageOps\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "import itertools\n",
    "from scipy.io import  loadmat\n",
    "import logging\n",
    "\n",
    "from scipy import signal\n",
    "\n",
    "from utils import data_transforms\n",
    "\n",
    "from models.__init__ import save_checkpoint, resume_checkpoint\n",
    "# from dataloader.gazenet import GooDataset, GazeDataset\n",
    "\n",
    "from models.chong import ModelSpatial\n",
    "from dataloader.chong import GazeDataset, GooDataset\n",
    "\n",
    "\n",
    "def generate_data_field(eye_point):\n",
    "    \"\"\"eye_point is (x, y) and between 0 and 1\"\"\"\n",
    "    height, width = 224, 224\n",
    "    x_grid = np.array(range(width)).reshape([1, width]).repeat(height, axis=0)\n",
    "    y_grid = np.array(range(height)).reshape([height, 1]).repeat(width, axis=1)\n",
    "    grid = np.stack((x_grid, y_grid)).astype(np.float32)\n",
    "\n",
    "    x, y = eye_point\n",
    "    x, y = x * width, y * height\n",
    "\n",
    "    grid -= np.array([x, y]).reshape([2, 1, 1]).astype(np.float32)\n",
    "    norm = np.sqrt(np.sum(grid ** 2, axis=0)).reshape([1, height, width])\n",
    "    # avoid zero norm\n",
    "    norm = np.maximum(norm, 0.1)\n",
    "    grid /= norm\n",
    "    return grid\n",
    "\n",
    "def preprocess_image(image_path, eye):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "\n",
    "    # crop face\n",
    "    x_c, y_c = eye\n",
    "    x_0 = x_c - 0.15\n",
    "    y_0 = y_c - 0.15\n",
    "    x_1 = x_c + 0.15\n",
    "    y_1 = y_c + 0.15\n",
    "    if x_0 < 0:\n",
    "        x_0 = 0\n",
    "    if y_0 < 0:\n",
    "        y_0 = 0\n",
    "    if x_1 > 1:\n",
    "        x_1 = 1\n",
    "    if y_1 > 1:\n",
    "        y_1 = 1\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    face_image = image[int(y_0 * h):int(y_1 * h), int(x_0 * w):int(x_1 * w), :]\n",
    "    # process face_image for face net\n",
    "    face_image = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)\n",
    "    face_image = Image.fromarray(face_image)\n",
    "    face_image = data_transforms['test'](face_image)\n",
    "    # process image for saliency net\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(image)\n",
    "    image = data_transforms['test'](image)\n",
    "\n",
    "    # generate gaze field\n",
    "    gaze_field = generate_data_field(eye_point=eye)\n",
    "    sample = {'image' : image,\n",
    "              'face_image': face_image,\n",
    "              'eye_position': torch.FloatTensor(eye),\n",
    "              'gaze_field': torch.from_numpy(gaze_field)}\n",
    "\n",
    "    return sample\n",
    "\n",
    "\n",
    "def test(net, test_image_path, eye):\n",
    "    net.eval()\n",
    "    heatmaps = []\n",
    "\n",
    "    data = preprocess_image(test_image_path, eye)\n",
    "\n",
    "    image, face_image, gaze_field, eye_position = data['image'], data['face_image'], data['gaze_field'], data['eye_position']\n",
    "    image, face_image, gaze_field, eye_position = map(lambda x: Variable(x.unsqueeze(0).cuda(), volatile=True), [image, face_image, gaze_field, eye_position])\n",
    "\n",
    "    _, predict_heatmap = net([image, face_image, gaze_field, eye_position])\n",
    "\n",
    "    final_output = predict_heatmap.cpu().data.numpy()\n",
    "\n",
    "    heatmap = final_output.reshape([224 // 4, 224 // 4])\n",
    "\n",
    "    h_index, w_index = np.unravel_index(heatmap.argmax(), heatmap.shape)\n",
    "    f_point = np.array([w_index / 56., h_index / 56.])\n",
    "\n",
    "\n",
    "    return heatmap, f_point[0], f_point[1]\n",
    "\n",
    "def test_on_single(net, dataloader):\n",
    "    net.eval()\n",
    "    heatmaps = []\n",
    "    \n",
    "    idx = 10\n",
    "    data = next(iter(dataloader))\n",
    "    image_path = data['image_path'][idx]\n",
    "    \n",
    "    image, face_image, gaze_field, eye_position = data['image'], data['face_image'], data['gaze_field'], data['eye_position']\n",
    "    image, face_image, gaze_field, eye_position = map(lambda x: Variable(x.cuda(), volatile=True), [image, face_image, gaze_field, eye_position])\n",
    "    \n",
    "    x = eye_position[idx][0].item()\n",
    "    y = eye_position[idx][1].item()\n",
    "    eyes = (x, y)\n",
    "    #print(image.shape)\n",
    "    #print(face_image.shape)\n",
    "    #print(eye_position.shape)\n",
    "    direction, predict_heatmap = net([image, face_image, gaze_field, eye_position])\n",
    "\n",
    "    final_output = predict_heatmap.cpu().data.numpy()\n",
    "\n",
    "    heatmap = final_output[idx].reshape([224 // 4, 224 // 4])\n",
    "\n",
    "    h_index, w_index = np.unravel_index(heatmap.argmax(), heatmap.shape)\n",
    "    f_point = np.array([w_index / 56., h_index / 56.])\n",
    "\n",
    "\n",
    "    return heatmap, eyes, f_point, image_path\n",
    "\n",
    "def test_on_batch(net, dataloader, out_size = 64):\n",
    "    net.eval()\n",
    "    heatmaps = []\n",
    "    \n",
    "    data = next(iter(dataloader))\n",
    "\n",
    "    image, face_image, head_channel, eye_position, gt_heatmap, gaze, _, image_path = data\n",
    "    image, face_image, head_channel, gt_heatmap = map(lambda x: Variable(x.cuda()), [image, face_image, head_channel, gt_heatmap])\n",
    "    \n",
    "    predict_heatmap, _, _ = net(image, head_channel, face_image)    \n",
    "    final_output = predict_heatmap.cpu().data.numpy()\n",
    "    \n",
    "    gaze_x, gaze_y = gaze\n",
    "    gaze_x_cpu = gaze_x.cpu().data.numpy()\n",
    "    gaze_y_cpu = gaze_y.cpu().data.numpy()\n",
    "    # print(type(gaze_x_cpu), gaze_x_cpu)\n",
    "    gt_position = np.array([gaze_x_cpu, gaze_y_cpu])\n",
    "    gt_position = gt_position.T\n",
    "    \n",
    "    #Process eye data\n",
    "    eye_x, eye_y = eye_position\n",
    "    eye_x_cpu = eye_x.cpu().data.numpy()\n",
    "    eye_y_cpu = eye_y.cpu().data.numpy()\n",
    "    eye_position = np.array([eye_x_cpu, eye_y_cpu])\n",
    "    eye_position = eye_position.T\n",
    "    \n",
    "    \n",
    "    image_paths = image_path\n",
    "    \n",
    "    \n",
    "    # image, face_image, gaze_field, eye_position = data['image'], data['face_image'], data['gaze_field'], data['eye_position']\n",
    "    # image, face_image, gaze_field, eye_position = map(lambda x: Variable(x.cuda(), volatile=True), [image, face_image, gaze_field, eye_position])\n",
    "    # gt_position = data['gt_position']\n",
    "    # image_paths = data['image_path']\n",
    "    N = image.shape[0]\n",
    "    \n",
    "    #print(gt_position[0])\n",
    "    \n",
    "#     direction, predict_heatmap = net([image, face_image, gaze_field, eye_position])\n",
    "#     final_output = predict_heatmap.cpu().data.numpy()\n",
    "    \n",
    "    \n",
    "    for idx in range(N):\n",
    "\n",
    "        heatmap = final_output[idx].reshape([out_size, out_size])\n",
    "\n",
    "        h_index, w_index = np.unravel_index(heatmap.argmax(), heatmap.shape)\n",
    "        f_point = np.array([w_index / out_size, h_index / out_size])\n",
    "        \n",
    "        draw_result(image_paths[idx], eye_position[idx], heatmap, f_point, gt_position[idx], idx)\n",
    "\n",
    "def draw_result(image_path, eye, heatmap, gaze_point, gt_point, idx=0):\n",
    "    x1, y1 = eye\n",
    "    x2, y2 = gaze_point\n",
    "    x3, y3 = gt_point\n",
    "    im = cv2.imread(image_path)\n",
    "    image_height, image_width = im.shape[:2]\n",
    "    x1, y1 = image_width * x1, y1 * image_height\n",
    "    x2, y2 = image_width * x2, y2 * image_height\n",
    "    x3, y3 = image_width * x3, y3 * image_height\n",
    "    x1, y1, x2, y2, x3, y3 = map(int, [x1, y1, x2, y2, x3, y3])\n",
    "    cv2.circle(im, (x1, y1), 5, [255, 255, 255], -1)\n",
    "    cv2.circle(im, (x2, y2), 5, [255, 255, 255], -1)\n",
    "    cv2.circle(im, (x3, y3), 5, [255, 255, 255], -1)\n",
    "    cv2.line(im, (x1, y1), (x2, y2), [255, 0, 0], 2)\n",
    "    cv2.line(im, (x1, y1), (x3, y3), [0, 165, 255], 2)\n",
    "\n",
    "    # heatmap visualization\n",
    "    heatmap = ((heatmap - heatmap.min()) / (heatmap.max() - heatmap.min()) * 255).astype(np.uint8)\n",
    "    heatmap = np.stack([heatmap, heatmap, heatmap], axis=2)\n",
    "    heatmap = cv2.resize(heatmap, (image_width, image_height))\n",
    "\n",
    "    heatmap = (0.8 * heatmap.astype(np.float32) + 0.2 * im.astype(np.float32)).astype(np.uint8)\n",
    "    img = np.concatenate((im, heatmap), axis=1)\n",
    "    \n",
    "    save_dir = './sample_out/'\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "        \n",
    "    filename = 'out_%s.png' % str(idx)\n",
    "    save_path = save_dir + filename\n",
    "    print(save_path)\n",
    "    cv2.imwrite(save_path, img)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-25dda607ce5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelSpatial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresume_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/hdd/GOO/normanpc_weights/temp2/model_epoch21.pth.tar'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gazefollow/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gazefollow/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gazefollow/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# Tensors stored in modules are graph leaves, and we don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;31m# want to create copy nodes, so we have to unpack the data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/gazefollow/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m         \"\"\"\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "# Load Model\n",
    "net = ModelSpatial()\n",
    "net.cuda()\n",
    "\n",
    "resume_path = '/hdd/GOO/normanpc_weights/temp2/model_epoch21.pth.tar' \n",
    "net, optimizer, start_epoch = resume_checkpoint(net, None, resume_path)\n",
    "\n",
    "#Prepare dataloaders\n",
    "test_images_dir = '/hdd/GOO/goosynthtest/1920humans'\n",
    "test_pickle_path = '/hdd/GOO/goosynthtest/testpickle120.pickle'\n",
    "batch_size = 16\n",
    "\n",
    "#For GOO\n",
    "# val_set = GooDataset(test_images_dir, test_pickle_path, 'test', include_path=True)\n",
    "val_set = GooDataset(test_images_dir, test_pickle_path, 'test')\n",
    "test_data_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, num_workers=8, shuffle=False)\n",
    "\n",
    "test_on_batch(net, test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
