{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import animius as am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change working directory\n",
    "os.chdir(\"/Users/xasiimov/Documents/Develop/Python/animius/animius\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'resources/Violet_Evergarden/subtitles/1.ass'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-895601930e1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resources/Violet_Evergarden/subtitles/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.ass'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     parser.slice_audio('resources/Violet_Evergarden/audios/' + str(i) + '.mp3',\n\u001b[1;32m      6\u001b[0m                        'resources/Violet_Evergarden/slices/' + str(i))\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/animius/ParseSubtitle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, subtitle_path)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubtitle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSAFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpysubs2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSAFile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubtitle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_audio_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.6/lib/python/site-packages/pysubs2/ssafile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, path, encoding, format_, fps, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \"\"\"\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resources/Violet_Evergarden/subtitles/1.ass'"
     ]
    }
   ],
   "source": [
    "# train SpeakerVerification model\n",
    "parser = am.ParseSubtitle.Parser()\n",
    "\n",
    "for i in range(1, 14):\n",
    "    parser.load('resources/Violet_Evergarden/subtitles/' + str(i) + '.ass')\n",
    "    parser.slice_audio('resources/Violet_Evergarden/audios/' + str(i) + '.mp3',\n",
    "                       'resources/Violet_Evergarden/slices/' + str(i))\n",
    "\n",
    "sv_model_config = am.ModelConfig(cls='SpeakerVerification')\n",
    "\n",
    "sv_data = am.SpeakerVerificationData()\n",
    "sv_data.add_text_file('resources/Violet_Evergarden/true.txt', is_speaker=True)\n",
    "sv_data.add_text_file('resources/Violet_Evergarden/false.txt', is_speaker=False)\n",
    "\n",
    "sv_model = am.SpeakerVerification.SpeakerVerificationModel()\n",
    "sv_model.build_graph(sv_model_config, sv_data)\n",
    "\n",
    "sv_model.init_tensorflow()\n",
    "sv_model.train()\n",
    "sv_model.save(r'resources/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'animius' has no attribute 'ChatData'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-03dc3bcde840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mchatbot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChatData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mglove_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWordEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m glove_embedding.create_embedding('/Users/xasiimov/Documents/Develop/Python/Dataset/GloVe/glove.twitter.27B.50d.txt',\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'animius' has no attribute 'ChatData'"
     ]
    }
   ],
   "source": [
    "# use SpeakerVerification to predict audio slices\n",
    "# train Chatbot Model\n",
    "\n",
    "result = []\n",
    "\n",
    "chatbot_data = am.ChatData()\n",
    "glove_embedding = am.WordEmbedding()\n",
    "glove_embedding.create_embedding('/Users/xasiimov/Documents/Develop/Python/Dataset/GloVe/glove.twitter.27B.50d.txt',\n",
    "                                 vocab_size=40000)\n",
    "chatbot_data.add_embedding_class(glove_embedding)\n",
    "\n",
    "for i in range(1, 14):\n",
    "    sv_data = am.SpeakerVerificationData()\n",
    "    sv_data.add_text_file('resources/Violet_Evergarden/true.txt', is_speaker=True)\n",
    "    sv_data.add_text_file('resources/Violet_Evergarden/false.txt', is_speaker=False)\n",
    "\n",
    "    sv_model = am.Model.load(r'resources/models/sv_model_1', data=sv_data)\n",
    "\n",
    "    sv_data.add_folder('resources/Violet_Evergarden/slices/' + str(i) + '/', is_speaker=None)\n",
    "    result = sv_model.predict(sv_data, save_path='resources/Violet_Evergarden/results/' + str(i) + '_result.txt')\n",
    "\n",
    "    parser = am.ParseSubtitle.Parser()\n",
    "    parser.load('resources/Violet_Evergarden/subtitles/' + str(i) + '.ass')\n",
    "    parser.parse_audio_sentences()\n",
    "\n",
    "    convs = parser.detect_conversation(result)\n",
    "    chatbot_data.add_data(convs)\n",
    "\n",
    "chatbot_data.add_twitter(\"/Users/xasiimov/Documents/Develop/Python/Dataset/twitter_en/twitter_en.txt\", 0, 7500)\n",
    "chatbot_data.save(r'resources/data/Chatbot Data/', name='ChatbotData')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a58c0f73d650>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchatbot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# train IntentNER model\n",
    "\n",
    "intentNER_mc = am.ModelConfig(cls='IntentNER')\n",
    "intentNER_data = am.IntentNERData()\n",
    "intentNER_data = am.IntentNERData()\n",
    "intentNER_model = am.IntentNER.IntentNERModel()\n",
    "\n",
    "glove_embedding = am.WordEmbedding()\n",
    "glove_embedding.create_embedding('/Users/xasiimov/Documents/Develop/Python/Dataset/GloVe/glove.twitter.27B.50d.txt',\n",
    "                                 vocab_size=40000)\n",
    "intentNER_data.add_embedding_class(glove_embedding)\n",
    "\n",
    "intentNER_data.set_intent_folder('resources/data/IntentNER Data')\n",
    "\n",
    "intentNER_data.save(r'resources/data/IntentNER Data/', name='IntentNERData')\n",
    "\n",
    "intentNER_model.build_graph(intentNER_mc, intentNER_data)\n",
    "intentNER_model.init_tensorflow()\n",
    "\n",
    "intentNER_model.train()\n",
    "\n",
    "intentNER_model.save(directory='resources/models/intent_ner', name='Intent NER')\n",
    "\n",
    "intentNER_model = am.Model.load(directory='resources/models/intent_ner', name='Intent NER')\n",
    "intentNER_mc = intentNER_model.model_config()\n",
    "\n",
    "glove_embedding = am.WordEmbedding()\n",
    "glove_embedding.create_embedding('/Users/xasiimov/Documents/Develop/Python/Dataset/GloVe/glove.twitter.27B.50d.txt',\n",
    "                                 vocab_size=40000)\n",
    "\n",
    "input_data = intentNER_model.data\n",
    "input_data.add_embedding_class(glove_embedding)\n",
    "input_data.set_input('how is the weather in san fransisco?')\n",
    "print(intentNER_model.predict(input_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
