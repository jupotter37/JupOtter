{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [모듈 4.1] 평가 및 조건 단계 개발 (SageMaker Model Building Pipeline 평가 및 조건 스텝)\n",
    "\n",
    "이 노트북은 아래와 같은 목차로 진행 됩니다. 전체를 모두 실행시에 완료 시간은 약 5분-10분 소요 됩니다.\n",
    "\n",
    "- 0. 모델 평가 개요 \n",
    "- 1. 데이터 세트 로딩 및 기본 훈련 변수 설정\n",
    "- 2. 모델 평가 코드 확인\n",
    "- 3. 모델 평가 스텝 개발 및 실행\n",
    "    - 아래의 3단계를 진행하여 SageMaker Model Building Pipeline 에서 훈련 스텝 개발 함. 아래의 (1), (2) 단계는 옵션이지만, 실제 현업 개발시에 필요한 단계이기에 실행을 권장 드립니다.\n",
    "        - (1) **[로컬 노트북 인스턴스]**에서 [다커 컨테이너 없이] 스크립트로 \n",
    "        - (2) **[로컬 노트북 인스턴스]**에서 다커 컨테이너로 훈련 코드 실행 (로컬 모드로 불리움)\n",
    "        - (3) SageMaker Model Building Pipeline 에서 모델 평가 및 조건 스텝 개발 및 실행\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 모델 평가 개요\n",
    "\n",
    "모델 평가는 훈련된 모델이 성능이 얼마나 나오는지를 검증 데이터 셋으로 평가하는 단계 입니다. 크게 아래와 같은 단계를 가집니다.\n",
    "- 모델 훈련이 된 모델 아티펙트를 가져옴.\n",
    "- 모델 아티펙트를 모델 객체로 로딩\n",
    "- 검증할 검증 데이터 세트를 준비\n",
    "- 모델 객체를 통하여 검증 데이터의 추론\n",
    "- 추론 후에 평가 지표 (에: roc-auc) 의 값을 얻습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 데이터 세트 로딩 및 기본 훈련 변수 설정\n",
    "- 이전 단계(전처리)에서 결과 파일을 로딩 합니다. 실제 훈련에 제공되는 데이터를 확인하기 위함 입니다.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "# role = 'arn:aws:iam::057716757052:role/service-role/AmazonSageMaker-ExecutionRole-20201219T152596'\n",
    "\n",
    "%store -r \n",
    "# %store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 아피텍트 위치 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model_artifact: \n",
      " s3://sagemaker-us-east-1-028703291518/sagemaker-pipeline-step-by-step-phase02/training_jobs/pipelines-wal8ym49y4mc-FraudTrain-OQ65auyvQK/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"train_model_artifact: \\n\", train_model_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 모델 평가 코드 확인\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "평가 스크립트는 `xgboost`를 사용하고 다음을 실행합니다.\n",
    "\n",
    "* 모델을 로드합니다. \n",
    "* 테스트 데이터를 읽습니다. \n",
    "* 테스트 데이터에 대한 예측을 실행합니다. \n",
    "* mse 등을 포함하는 분류보고서를 작성합니다. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpathlib\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtarfile\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjoblib\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m classification_report\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m confusion_matrix\n",
      "\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msubprocess\u001b[39;49;00m, \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "subprocess.check_call([sys.executable, \u001b[33m'\u001b[39;49;00m\u001b[33m-m\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mpip\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33minstall\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mxgboost\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mxgboost\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmetrics\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m roc_auc_score\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mhandlers\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_logger\u001b[39;49;00m():\n",
      "    \u001b[33m'''\u001b[39;49;00m\n",
      "\u001b[33m    로깅을 위해 파이썬 로거를 사용\u001b[39;49;00m\n",
      "\u001b[33m    # https://stackoverflow.com/questions/17745914/python-logging-module-is-printing-lines-multiple-times\u001b[39;49;00m\n",
      "\u001b[33m    '''\u001b[39;49;00m\n",
      "    loglevel = logging.DEBUG\n",
      "    l = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\n",
      "    \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m l.hasHandlers():\n",
      "        l.setLevel(loglevel)\n",
      "        logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))        \n",
      "        l.handler_set = \u001b[34mTrue\u001b[39;49;00m\n",
      "    \u001b[34mreturn\u001b[39;49;00m l  \n",
      "\n",
      "logger = _get_logger()\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--base_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default= \u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/processing\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)    \n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model_path\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default= \u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/processing/model/model.tar.gz\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--test_path\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default= \u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/processing/test/test.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output_evaluation_dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m\"\u001b[39;49;00m\u001b[33m/opt/ml/processing/evaluation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \n",
      "    \u001b[37m####################################\u001b[39;49;00m\n",
      "    \u001b[37m## 기본 커맨드 인자 파싱\u001b[39;49;00m\n",
      "    \u001b[37m####################################    \u001b[39;49;00m\n",
      "        \n",
      "    \u001b[37m# parse arguments\u001b[39;49;00m\n",
      "    args = parser.parse_args()     \n",
      "    \n",
      "    logger.info(\u001b[33m\"\u001b[39;49;00m\u001b[33m#############################################\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33margs.model_path: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.model_path\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33margs.test_path: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.test_path\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)    \n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33margs.output_evaluation_dir: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00margs.output_evaluation_dir\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)        \n",
      "\n",
      "    model_path = args.model_path\n",
      "    test_path = args.test_path    \n",
      "    output_evaluation_dir = args.output_evaluation_dir\n",
      "    base_dir = args.base_dir\n",
      "    \n",
      "    \u001b[37m####################################\u001b[39;49;00m\n",
      "    \u001b[37m## 기본 폴더 이하의 파일 폴더 구조 확인 하기\u001b[39;49;00m\n",
      "    \u001b[37m####################################    \u001b[39;49;00m\n",
      "    \n",
      "    \u001b[37m# Traverse all files\u001b[39;49;00m\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m****** All folder and files under \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbase_dir\u001b[33m}\u001b[39;49;00m\u001b[33m ****** \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[34mfor\u001b[39;49;00m file \u001b[35min\u001b[39;49;00m os.walk(base_dir):\n",
      "        logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfile\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m************************************************* \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)        \n",
      "\n",
      "    \u001b[37m####################################\u001b[39;49;00m\n",
      "    \u001b[37m## 모델 아티펙트의 압축 해제하고, 모델 로딩하기\u001b[39;49;00m\n",
      "    \u001b[37m####################################    \u001b[39;49;00m\n",
      "    \n",
      "    \u001b[34mwith\u001b[39;49;00m tarfile.open(model_path) \u001b[34mas\u001b[39;49;00m tar:\n",
      "        tar.extractall(path=\u001b[33m\"\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \n",
      "    model = pickle.load(\u001b[36mopen\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mxgboost-model\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, \u001b[33m\"\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel is loaded\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)    \n",
      "    \n",
      "\n",
      "    \u001b[37m####################################\u001b[39;49;00m\n",
      "    \u001b[37m## 테스트 데이터 로딩하기\u001b[39;49;00m\n",
      "    \u001b[37m####################################        \u001b[39;49;00m\n",
      "    \n",
      "    df = pd.read_csv(test_path)\n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mtest df sample \u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mdf.head(\u001b[34m2\u001b[39;49;00m)\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)        \n",
      "    \n",
      "    y_test = df.iloc[:, \u001b[34m0\u001b[39;49;00m].astype(\u001b[33m'\u001b[39;49;00m\u001b[33mint\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)    \n",
      "    df.drop(df.columns[\u001b[34m0\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m, inplace=\u001b[34mTrue\u001b[39;49;00m)\n",
      "\n",
      "    X_test = xgboost.DMatrix(df)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mPayload: \u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, df.values)\n",
      "    \n",
      "    \u001b[37m####################################\u001b[39;49;00m\n",
      "    \u001b[37m## 모델 추론하기\u001b[39;49;00m\n",
      "    \u001b[37m####################################            \u001b[39;49;00m\n",
      "    \n",
      "    predictions_prob = model.predict(X_test)\n",
      "    \n",
      "\n",
      "    \u001b[37m####################################\u001b[39;49;00m\n",
      "    \u001b[37m## 스코어 값을 0.5 를 기준으로 레이블 0, 1로 구분 \u001b[39;49;00m\n",
      "    \u001b[37m####################################            \u001b[39;49;00m\n",
      "\n",
      "    \n",
      "    \u001b[37m# if predictions_prob is greater than 0.5, it is 1 as a fruad, otherwise it is 0 as a non-fraud\u001b[39;49;00m\n",
      "    threshold = \u001b[34m0.5\u001b[39;49;00m\n",
      "    predictions = [\u001b[34m1\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m e >= \u001b[34m0.5\u001b[39;49;00m \u001b[34melse\u001b[39;49;00m \u001b[34m0\u001b[39;49;00m \u001b[34mfor\u001b[39;49;00m e \u001b[35min\u001b[39;49;00m predictions_prob ] \n",
      "    \n",
      "    \u001b[37m####################################\u001b[39;49;00m\n",
      "    \u001b[37m## 평가 지표 보여주기\u001b[39;49;00m\n",
      "    \u001b[37m####################################            \u001b[39;49;00m\n",
      "\n",
      "    \n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mclassification_report(y_true=y_test, y_pred = predictions)\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    cm = confusion_matrix(y_true= y_test, y_pred= predictions)    \n",
      "    \u001b[36mprint\u001b[39;49;00m(cm)\n",
      "\n",
      "    roc_score = \u001b[36mround\u001b[39;49;00m(roc_auc_score(y_true = y_test, y_score = predictions_prob ), \u001b[34m4\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mroc_auc_score : \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, roc_score)\n",
      "    \n",
      "    \u001b[37m####################################\u001b[39;49;00m\n",
      "    \u001b[37m## JSON 으로 모델 평가 결과를 저장하기\u001b[39;49;00m\n",
      "    \u001b[37m####################################                \u001b[39;49;00m\n",
      "    \u001b[37m# 참고: https://docs.aws.amazon.com/sagemaker/latest/dg/model-monitor-model-quality-metrics.html\u001b[39;49;00m\n",
      "    \n",
      "    report_dict = {\n",
      "        \u001b[33m\"\u001b[39;49;00m\u001b[33mbinary_classification_metrics\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: {\n",
      "            \u001b[33m\"\u001b[39;49;00m\u001b[33mauc\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: {\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mvalue\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: roc_score,\n",
      "                \u001b[33m\"\u001b[39;49;00m\u001b[33mstandard_deviation\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m : \u001b[33m\"\u001b[39;49;00m\u001b[33mNaN\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\n",
      "            },\n",
      "        },\n",
      "    }\n",
      "\n",
      "\n",
      "    pathlib.Path(output_evaluation_dir).mkdir(parents=\u001b[34mTrue\u001b[39;49;00m, exist_ok=\u001b[34mTrue\u001b[39;49;00m)\n",
      "    \n",
      "    evaluation_path = \u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00moutput_evaluation_dir\u001b[33m}\u001b[39;49;00m\u001b[33m/evaluation.json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(evaluation_path, \u001b[33m\"\u001b[39;49;00m\u001b[33mw\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        f.write(json.dumps(report_dict))\n",
      "        \u001b[34mfor\u001b[39;49;00m file \u001b[35min\u001b[39;49;00m os.walk(output_evaluation_dir):\n",
      "            logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mfile\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "                \n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mevaluation_path \u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mevaluation_path\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)                \n",
      "    logger.info(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mreport_dict \u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m{\u001b[39;49;00mreport_dict\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)                    \n",
      "        \n",
      "\n",
      "        \n",
      "        \n",
      "                \n"
     ]
    }
   ],
   "source": [
    "!pygmentize src/evaluation.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 평가 스텝 개발 및 실행\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) 로컬에서 스크립트 실행\n",
    "\n",
    "\n",
    "### 로컬 환경 구성\n",
    "- 도커 컨테이너의 환경을 가상으로 구성하기 위해 아래 폴더 생성\n",
    "    - `opt/ml/processing`\n",
    "    - `opt/ml/processing/evaluation`\n",
    "    - `opt/ml/processing/model`\n",
    "    \n",
    "\n",
    "- 모델 아티펙트 다운로드 하여 로컬에 저장\n",
    "- 테스트 데이터 세트 다운로드 하여 로컬 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download model artifact: \n",
      "download: s3://sagemaker-us-east-1-028703291518/sagemaker-pipeline-step-by-step-phase02/training_jobs/pipelines-wal8ym49y4mc-FraudTrain-OQ65auyvQK/output/model.tar.gz to opt/ml/processing/model/model.tar.gz\n",
      "Test Data Location: \n",
      " s3://sagemaker-us-east-1-028703291518/sagemaker-pipeline-step-by-step-phase02/preporc/test.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_dir = 'opt/ml/processing'\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "\n",
    "output_evaluation_dir = 'opt/ml/processing/evaluation'\n",
    "os.makedirs(output_evaluation_dir, exist_ok=True)\n",
    "\n",
    "# 훈련 아티펙트를 다운로드 하여 로컬 저장\n",
    "base_model_dir = 'opt/ml/processing/model'\n",
    "base_model_path = f\"{base_model_dir}/model.tar.gz\"\n",
    "os.makedirs(base_model_dir, exist_ok=True)\n",
    "\n",
    "print(\"Download model artifact: \")\n",
    "! aws s3 cp  {train_model_artifact} {base_model_dir}\n",
    "\n",
    "# 테스트 데이터 세트의 파일 경로 기술\n",
    "base_test_path = f\"{test_preproc_data_uri}\"\n",
    "print(\"Test Data Location: \\n\", base_test_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로컬에서 실행 위한 필수 정보 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_dir: \n",
      " opt/ml/processing\n",
      "base_model_path: \n",
      " opt/ml/processing/model/model.tar.gz\n",
      "base_test_path: \n",
      " s3://sagemaker-us-east-1-028703291518/sagemaker-pipeline-step-by-step-phase02/preporc/test.csv\n",
      "output_evaluation_dir: \n",
      " opt/ml/processing/evaluation\n"
     ]
    }
   ],
   "source": [
    "print(\"base_dir: \\n\", base_dir)\n",
    "print(\"base_model_path: \\n\", base_model_path)\n",
    "print(\"base_test_path: \\n\", base_test_path)\n",
    "print(\"output_evaluation_dir: \\n\", output_evaluation_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로컬에서 스크립트 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.4.2-py3-none-manylinux2010_x86_64.whl (166.7 MB)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost) (1.5.3)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost) (1.19.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.4.2\n",
      "#############################################\n",
      "args.model_path: opt/ml/processing/model/model.tar.gz\n",
      "args.test_path: s3://sagemaker-us-east-1-028703291518/sagemaker-pipeline-step-by-step-phase02/preporc/test.csv\n",
      "args.output_evaluation_dir: opt/ml/processing/evaluation\n",
      "****** All folder and files under opt/ml/processing ****** \n",
      "('opt/ml/processing', ['evaluation', 'model'], [])\n",
      "('opt/ml/processing/evaluation', [], [])\n",
      "('opt/ml/processing/model', [], ['model.tar.gz'])\n",
      "************************************************* \n",
      "model is loaded\n",
      "test df sample \n",
      ":    fraud  ...  police_report_available_Yes\n",
      "0      0  ...                            1\n",
      "1      0  ...                            1\n",
      "\n",
      "[2 rows x 59 columns]\n",
      "Payload: \n",
      " [[2.39014325e+04 3.62014325e+04 5.60000000e+01 ... 1.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [2.90952957e+04 7.36952957e+04 3.60000000e+01 ... 1.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [1.12328318e+04 2.50328318e+04 2.40000000e+01 ... 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.24212530e+04 2.41212530e+04 2.80000000e+01 ... 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00]\n",
      " [1.09916050e+04 2.49916050e+04 2.10000000e+01 ... 1.00000000e+00\n",
      "  0.00000000e+00 1.00000000e+00]\n",
      " [1.11269886e+04 1.48269886e+04 6.60000000e+01 ... 0.00000000e+00\n",
      "  1.00000000e+00 0.00000000e+00]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.73      0.84       967\n",
      "           1       0.08      0.70      0.15        33\n",
      "\n",
      "    accuracy                           0.73      1000\n",
      "   macro avg       0.53      0.71      0.49      1000\n",
      "weighted avg       0.96      0.73      0.82      1000\n",
      "\n",
      "[[708 259]\n",
      " [ 10  23]]\n",
      "roc_auc_score :  0.7745\n",
      "('opt/ml/processing/evaluation', [], ['evaluation.json'])\n",
      "evaluation_path \n",
      ": opt/ml/processing/evaluation/evaluation.json\n",
      "report_dict \n",
      ": {'binary_classification_metrics': {'auc': {'value': 0.7745, 'standard_deviation': 'NaN'}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/python3/bin/python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%%sh -s \"$base_dir\" \"$base_model_path\" \"$base_test_path\" \"$output_evaluation_dir\"\n",
    "python src/evaluation.py \\\n",
    "--base_dir $1 \\\n",
    "--model_path $2 \\\n",
    "--test_path $3 \\\n",
    "--output_evaluation_dir $4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) 로컬 다커 에서 모델 평가\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ScriptProcessor 의 기본 도커 컨테이너 지정\n",
    "ScriptProcessor 의 기본 도커 컨테이너로 Scikit-learn를 기본 이미지를 사용함. \n",
    "- 사용자가 정의한 도커 컨테이너도 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ScriptProcessor 정의 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_uri: \n",
      " 366743142698.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3\n"
     ]
    }
   ],
   "source": [
    "image_uri = f'366743142698.dkr.ecr.{region}.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3'\n",
    "print(\"image_uri: \\n\", image_uri )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_preproc_dir_artifact' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4d9b626b1be2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#                                     \"test\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#                                 ].S3Output.S3Uri,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                                 \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_preproc_dir_artifact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# prep_test_output,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                                 \u001b[0mdestination\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/opt/ml/processing/test\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                             )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_preproc_dir_artifact' is not defined"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "\n",
    "\n",
    "processing_instance_type = 'local'\n",
    "\n",
    "eval_script_processor = SKLearnProcessor(\n",
    "                                     framework_version= \"0.23-1\",\n",
    "                                     role=role,\n",
    "                                     instance_type=processing_instance_type,\n",
    "                                     instance_count=1,\n",
    "                                     base_job_name=\"script-fraud-scratch-eval\",\n",
    "                                    )\n",
    "\n",
    "\n",
    "\n",
    "eval_script_processor.run(\n",
    "                        inputs=[\n",
    "                            ProcessingInput(\n",
    "#                                source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "                                source= train_model_artifact,  # model_artifcat_path,\n",
    "                                destination=\"/opt/ml/processing/model\"\n",
    "                            ),\n",
    "                            ProcessingInput(\n",
    "#                                 source=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "#                                     \"test\"\n",
    "#                                 ].S3Output.S3Uri,\n",
    "                                source = test_preproc_dir_artifact, # prep_test_output,\n",
    "                                destination=\"/opt/ml/processing/test\"\n",
    "                            )\n",
    "                        ],\n",
    "                        outputs=[\n",
    "                            #ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "                            ProcessingOutput(source=\"/opt/ml/processing/evaluation\"),                            \n",
    "                        ],\n",
    "                        code=\"src/evaluation.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) 모델 빌딩 파이프라인에서  실행 \n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 빌딩 파이프라인 변수 생성\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import (\n",
    "    ParameterInteger,\n",
    "    ParameterString,\n",
    ")\n",
    "\n",
    "processing_instance_count = ParameterInteger(\n",
    "    name=\"ProcessingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "processing_instance_type = ParameterString(\n",
    "    name=\"ProcessingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습모델을 평가하기 위한 모델 평가단계 정의 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "\n",
    "script_eval = SKLearnProcessor(\n",
    "                             framework_version= \"0.23-1\",\n",
    "                             role=role,\n",
    "                             instance_type=processing_instance_type,\n",
    "                             instance_count=1,\n",
    "                             base_job_name=\"script-fraud-scratch-eval\",\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property 파일 정의\n",
    "\n",
    "- step_eval 이 실행이 되면 `evaluation.json` 이 S3에 저장이 됩니다.\n",
    "    - evaluation.json 은 아래의 PropertyFile 로서 정의 됩니다.\n",
    "    - step_eval 에서 `property_files=[<property_file_instance>]` 를 추가 합니다.\n",
    "\n",
    "```\n",
    "<property_file_instance> = PropertyFile(\n",
    "    name=\"<property_file_name>\",\n",
    "    output_name=\"<processingoutput_output_name>\",\n",
    "    path=\"<path_to_json_file>\"\n",
    ")\n",
    "```\n",
    "\n",
    "\n",
    "- 조건 단계에서 사용하는 ConditionLessThanOrEqualTo 에서 evaluation.json 을 로딩하여 내용을 확인\n",
    "\n",
    "```\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step=step_eval,\n",
    "        property_file=<property_file_instance>,\n",
    "        json_path=\"test_metrics.roc.value\",\n",
    "    ),\n",
    "    right=6.0\n",
    ")\n",
    "```\n",
    "\n",
    "#### 참고\n",
    "- 참고 자료: [Property Files and JsonGet](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/build-and-manage-propertyfile.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\",\n",
    "    output_name=\"evaluation\",\n",
    "    path=\"evaluation.json\"\n",
    ")\n",
    "\n",
    "\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"FraudEval\",\n",
    "    processor=script_eval,\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source= train_model_artifact,\n",
    "            destination=\"/opt/ml/processing/model\"\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source= test_preproc_dir_artifact,\n",
    "            destination=\"/opt/ml/processing/test\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"src/evaluation.py\",\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 조건  단계 정의\n",
    "- step_eval 의 결과가 조건 단계로 연결되기에 아래 추가하여 진행 합니다.\n",
    "- 조건 단계의 상세 사항은 여기를 보세요. --> [조건 단계](https://docs.aws.amazon.com/ko_kr/sagemaker/latest/dg/build-and-manage-steps.html#step-type-condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import (\n",
    "    ConditionStep,\n",
    "    JsonGet,\n",
    ")\n",
    "\n",
    "\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step=step_eval,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"binary_classification_metrics.auc.value\",\n",
    "    ),\n",
    "    right=6.0\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"FraudMeticCond\",\n",
    "    conditions=[cond_lte],\n",
    "#    if_steps=[step_register, step_create_model, step_transform],\n",
    "    if_steps=[],    \n",
    "    else_steps=[], \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파리마터, 단계, 조건을 조합하여 최종 파이프라인 정의\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "\n",
    "pipeline_name = project_prefix + '-Eval-Step'\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        processing_instance_type, \n",
    "        processing_instance_count,\n",
    "    ],\n",
    "   steps=[step_eval, step_cond],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인 정의 확인 \n",
    "\n",
    "파이프라인을 정의하는 JSON을 생성하고 파이프라인 내에서 사용하는 파라미터와 단계별 속성들이 잘 정의되었는지 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "# definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인을 SageMaker에 제출하고 실행하기 \n",
    "\n",
    "파이프라인 정의를 파이프라인 서비스에 제출합니다. 함께 전달되는 역할(role)을 이용하여 AWS에서 파이프라인을 생성하고 작업의 각 단계를 실행할 것입니다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파이프라인 운영: 파이프라인 대기 및 실행상태 확인\n",
    "\n",
    "워크플로우의 실행상황을 살펴봅니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.list_steps()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 리소스 정리: 파이프라인\n",
    "- 위에서 생성한 파이프라인을 제거 합니다.\n",
    "- isDeletePipeline=False, verbose=Fasle\n",
    "    - 파이프라인을 지우지 않고, 존재하는지 확인 합니다.\n",
    "- isDeletePipeline=False, verbose=True\n",
    "    - 파이프라인의 정의를 자세하 확인 합니다.\n",
    "- isDeletePipeline=True, verbose=True or False\n",
    "    - 파이프라인을 삭제 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.p_utils import clean_pipeline\n",
    "\n",
    "# clean_pipeline(pipeline_name = pipeline_name, isDeletePipeline=False, verbose=False)   \n",
    "clean_pipeline(pipeline_name = pipeline_name, isDeletePipeline=True, verbose=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
