{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c87fd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import date\n",
    "import time\n",
    "\n",
    "import random\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "import os, os.path\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import imshow\n",
    "import pickle\n",
    "import h5py\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb96838",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/Users/hn/Documents/00_GitHub/Ag/NASA/Python_codes/')\n",
    "import NASA_core as nc\n",
    "# import NASA_plot_core as rcp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75bd139",
   "metadata": {},
   "source": [
    "# Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72d6e719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6340, 8)\n",
      "(3539, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CropTyp</th>\n",
       "      <th>Irrigtn</th>\n",
       "      <th>DataSrc</th>\n",
       "      <th>Acres</th>\n",
       "      <th>ExctAcr</th>\n",
       "      <th>LstSrvD</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010_WSDA_SF_2017</td>\n",
       "      <td>alfalfa hay</td>\n",
       "      <td>center pivot</td>\n",
       "      <td>wsda</td>\n",
       "      <td>34</td>\n",
       "      <td>34.310305</td>\n",
       "      <td>2017/09/12</td>\n",
       "      <td>Grant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100204_WSDA_SF_2017</td>\n",
       "      <td>alfalfa hay</td>\n",
       "      <td>center pivot</td>\n",
       "      <td>wsda</td>\n",
       "      <td>62</td>\n",
       "      <td>61.826535</td>\n",
       "      <td>2017/08/09</td>\n",
       "      <td>Grant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID      CropTyp       Irrigtn DataSrc  Acres    ExctAcr  \\\n",
       "0  100010_WSDA_SF_2017  alfalfa hay  center pivot    wsda     34  34.310305   \n",
       "1  100204_WSDA_SF_2017  alfalfa hay  center pivot    wsda     62  61.826535   \n",
       "\n",
       "      LstSrvD county  \n",
       "0  2017/09/12  Grant  \n",
       "1  2017/08/09  Grant  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dir = \"/Users/hn/Documents/01_research_data/NASA/parameters/\"\n",
    "meta = pd.read_csv(meta_dir+\"evaluation_set.csv\")\n",
    "meta_moreThan10Acr=meta[meta.ExctAcr>10]\n",
    "print (meta.shape)\n",
    "print (meta_moreThan10Acr.shape)\n",
    "meta.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a05ae6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print (len(meta.ID.unique()))\n",
    "# meta_lessThan10Acr=meta[meta.ExctAcr<10]\n",
    "# print (meta_lessThan10Acr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19bd063",
   "metadata": {},
   "source": [
    "# Read Training Set Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be24225f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Votes:  [2 1]\n",
      "1849\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>99837_WSDA_SF_2017</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114615_WSDA_SF_2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID  Vote\n",
       "0   99837_WSDA_SF_2017     2\n",
       "1  114615_WSDA_SF_2017     1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_data/\"\n",
    "\n",
    "ground_truth_labels = pd.read_csv(training_set_dir+\"train_labels.csv\")\n",
    "print (\"Unique Votes: \", ground_truth_labels.Vote.unique())\n",
    "print (len(ground_truth_labels.ID.unique()))\n",
    "ground_truth_labels.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc3fd3c",
   "metadata": {},
   "source": [
    "### Detect how many fields are less than 10 acres and report in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e74c9b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1849\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CropTyp</th>\n",
       "      <th>Irrigtn</th>\n",
       "      <th>DataSrc</th>\n",
       "      <th>Acres</th>\n",
       "      <th>ExctAcr</th>\n",
       "      <th>LstSrvD</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100010_WSDA_SF_2017</td>\n",
       "      <td>alfalfa hay</td>\n",
       "      <td>center pivot</td>\n",
       "      <td>wsda</td>\n",
       "      <td>34</td>\n",
       "      <td>34.310305</td>\n",
       "      <td>2017/09/12</td>\n",
       "      <td>Grant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100204_WSDA_SF_2017</td>\n",
       "      <td>alfalfa hay</td>\n",
       "      <td>center pivot</td>\n",
       "      <td>wsda</td>\n",
       "      <td>62</td>\n",
       "      <td>61.826535</td>\n",
       "      <td>2017/08/09</td>\n",
       "      <td>Grant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID      CropTyp       Irrigtn DataSrc  Acres    ExctAcr  \\\n",
       "0  100010_WSDA_SF_2017  alfalfa hay  center pivot    wsda     34  34.310305   \n",
       "1  100204_WSDA_SF_2017  alfalfa hay  center pivot    wsda     62  61.826535   \n",
       "\n",
       "      LstSrvD county  \n",
       "0  2017/09/12  Grant  \n",
       "1  2017/08/09  Grant  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (len(meta[meta.ID.isin(list(ground_truth_labels.ID))].ID.unique()))\n",
    "meta.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688e4bba",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b32a9531",
   "metadata": {},
   "outputs": [],
   "source": [
    "VI_idx = \"NDVI\"\n",
    "data_dir = \"/Users/hn/Documents/01_research_data/NASA/VI_TS/04_regularized_TS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88b9a76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>human_system_start_time</th>\n",
       "      <th>NDVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135073_WSDA_SF_2015</td>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>0.163569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135073_WSDA_SF_2015</td>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>0.028382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID human_system_start_time      NDVI\n",
       "0  135073_WSDA_SF_2015              2015-01-10  0.163569\n",
       "1  135073_WSDA_SF_2015              2015-01-20  0.028382"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = [\"regular_Walla2015_\" + VI_idx + \"_JFD.csv\", \n",
    "              \"regular_AdamBenton2016_\" + VI_idx + \"_JFD.csv\", \n",
    "              \"regular_Grant2017_\" + VI_idx + \"_JFD.csv\", \n",
    "              \"regular_FranklinYakima2018_\" + VI_idx + \"_JFD.csv\"]\n",
    "\n",
    "data=pd.DataFrame()\n",
    "\n",
    "for file in file_names:\n",
    "    curr_file=pd.read_csv(data_dir + file)\n",
    "    curr_file['human_system_start_time'] = pd.to_datetime(curr_file['human_system_start_time'])\n",
    "    \n",
    "    # These data are for 3 years. The middle one is the correct one\n",
    "    all_years = sorted(curr_file.human_system_start_time.dt.year.unique())\n",
    "    if len(all_years)==3 or len(all_years)==2:\n",
    "        proper_year = all_years[1]\n",
    "    elif len(all_years)==1:\n",
    "        proper_year = all_years[0]\n",
    "\n",
    "    curr_file = curr_file[curr_file.human_system_start_time.dt.year==proper_year]\n",
    "    data=pd.concat([data, curr_file])\n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e29a625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1849"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth = data[data.ID.isin(list(ground_truth_labels.ID.unique()))].copy()\n",
    "len(ground_truth.ID.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6195a8f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>human_system_start_time</th>\n",
       "      <th>NDVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>145288_WSDA_SF_2015</td>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>0.208990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>145288_WSDA_SF_2015</td>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>0.249083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID human_system_start_time      NDVI\n",
       "2598  145288_WSDA_SF_2015              2015-01-10  0.208990\n",
       "2599  145288_WSDA_SF_2015              2015-01-20  0.249083"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b98b72",
   "metadata": {},
   "source": [
    "# Toss Smalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "721e88ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are [{:.0f}] fields in total whose areaadds up to [1849.00].\n",
      "There are [{:.0f}] fields larger than 10 acreswhose area adds up to [1342.00].\n"
     ]
    }
   ],
   "source": [
    "ground_truth_labels_extended = pd.merge(ground_truth_labels, meta, on=['ID'], how='left')\n",
    "ground_truth_labels = ground_truth_labels_extended[ground_truth_labels_extended.ExctAcr>=10].copy()\n",
    "ground_truth_labels.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print (\"There are [{:.0f}] fields in total whose area\"+ \\\n",
    "       \"adds up to [{:.2f}].\".format(len(ground_truth_labels_extended), \\\n",
    "                                                                     ground_truth_labels_extended.ExctAcr.sum()))\n",
    "\n",
    "print (\"There are [{:.0f}] fields larger than 10 acres\"+ \\\n",
    "        \"whose area adds up to [{:.2f}].\".format(len(ground_truth_labels), \\\n",
    "                                                                    ground_truth_labels.ExctAcr.sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c9e44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = ground_truth[ground_truth.ID.isin((list(meta_moreThan10Acr.ID)))].copy()\n",
    "ground_truth_labels = ground_truth_labels[ground_truth_labels.ID.isin((list(meta_moreThan10Acr.ID)))].copy()\n",
    "\n",
    "ground_truth.reset_index(drop=True, inplace=True)\n",
    "ground_truth_labels.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fc0f9f",
   "metadata": {},
   "source": [
    "# Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9abecf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100048_WSDA_SF_2017\n",
      "100048_WSDA_SF_2017\n",
      "____________________________________\n",
      "99909_WSDA_SF_2017\n",
      "99909_WSDA_SF_2017\n",
      "____________________________________\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ground_truth.sort_values(by=[\"ID\", 'human_system_start_time'], inplace=True)\n",
    "ground_truth_labels.sort_values(by=[\"ID\"], inplace=True)\n",
    "\n",
    "ground_truth.reset_index(drop=True, inplace=True)\n",
    "ground_truth_labels.reset_index(drop=True, inplace=True)\n",
    "\n",
    "assert (len(ground_truth.ID.unique()) == len(ground_truth_labels.ID.unique()))\n",
    "\n",
    "print (list(ground_truth.ID)[0])\n",
    "print (list(ground_truth_labels.ID)[0])\n",
    "print (\"____________________________________\")\n",
    "print (list(ground_truth.ID)[-1])\n",
    "print (list(ground_truth_labels.ID)[-1])\n",
    "print (\"____________________________________\")\n",
    "print (list(ground_truth.ID.unique())==list(ground_truth_labels.ID.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060adbe3",
   "metadata": {},
   "source": [
    "# Widen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6940fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_colnames = [VI_idx + \"_\" + str(ii) for ii in range(1, 37) ]\n",
    "columnNames = [\"ID\"] + NDVI_colnames\n",
    "ground_truth_wide = pd.DataFrame(columns=columnNames, \n",
    "                                index=range(len(ground_truth.ID.unique())))\n",
    "ground_truth_wide[\"ID\"] = ground_truth.ID.unique()\n",
    "\n",
    "for an_ID in ground_truth.ID.unique():\n",
    "    curr_df = ground_truth[ground_truth.ID==an_ID]\n",
    "    \n",
    "    ground_truth_wide_indx = ground_truth_wide[ground_truth_wide.ID==an_ID].index\n",
    "    ground_truth_wide.loc[ground_truth_wide_indx, \"NDVI_1\":\"NDVI_36\"] = curr_df.NDVI.values[:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7ac9a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1342\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>NDVI_1</th>\n",
       "      <th>NDVI_2</th>\n",
       "      <th>NDVI_3</th>\n",
       "      <th>NDVI_4</th>\n",
       "      <th>NDVI_5</th>\n",
       "      <th>NDVI_6</th>\n",
       "      <th>NDVI_7</th>\n",
       "      <th>NDVI_8</th>\n",
       "      <th>NDVI_9</th>\n",
       "      <th>...</th>\n",
       "      <th>NDVI_27</th>\n",
       "      <th>NDVI_28</th>\n",
       "      <th>NDVI_29</th>\n",
       "      <th>NDVI_30</th>\n",
       "      <th>NDVI_31</th>\n",
       "      <th>NDVI_32</th>\n",
       "      <th>NDVI_33</th>\n",
       "      <th>NDVI_34</th>\n",
       "      <th>NDVI_35</th>\n",
       "      <th>NDVI_36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100048_WSDA_SF_2017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140785</td>\n",
       "      <td>0.157916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157398</td>\n",
       "      <td>0.176086</td>\n",
       "      <td>0.19269</td>\n",
       "      <td>0.142555</td>\n",
       "      <td>0.136615</td>\n",
       "      <td>0.130675</td>\n",
       "      <td>0.124734</td>\n",
       "      <td>0.118794</td>\n",
       "      <td>0.131257</td>\n",
       "      <td>0.14372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100081_WSDA_SF_2017</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.003887</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131036</td>\n",
       "      <td>0.262071</td>\n",
       "      <td>0.419314</td>\n",
       "      <td>0.521772</td>\n",
       "      <td>0.656894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140417</td>\n",
       "      <td>0.197382</td>\n",
       "      <td>0.196319</td>\n",
       "      <td>0.186397</td>\n",
       "      <td>0.093199</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.093574</td>\n",
       "      <td>0.187148</td>\n",
       "      <td>0.144835</td>\n",
       "      <td>0.102522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID    NDVI_1    NDVI_2    NDVI_3 NDVI_4    NDVI_5  \\\n",
       "0  100048_WSDA_SF_2017       0.0       0.0       0.0    0.0       0.0   \n",
       "1  100081_WSDA_SF_2017  0.005831  0.003887  0.001944    0.0  0.131036   \n",
       "\n",
       "     NDVI_6    NDVI_7    NDVI_8    NDVI_9  ...   NDVI_27   NDVI_28   NDVI_29  \\\n",
       "0       0.0       0.0  0.140785  0.157916  ...  0.157398  0.176086   0.19269   \n",
       "1  0.262071  0.419314  0.521772  0.656894  ...  0.140417  0.197382  0.196319   \n",
       "\n",
       "    NDVI_30   NDVI_31   NDVI_32   NDVI_33   NDVI_34   NDVI_35   NDVI_36  \n",
       "0  0.142555  0.136615  0.130675  0.124734  0.118794  0.131257   0.14372  \n",
       "1  0.186397  0.093199       0.0  0.093574  0.187148  0.144835  0.102522  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (len(ground_truth_wide.ID.unique()))\n",
    "ground_truth_wide.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e235debd",
   "metadata": {},
   "source": [
    "# Split Train and Test Set\n",
    "\n",
    "#### Make sure rows of ```ground_truth_allBands``` and ```ground_truth_labels``` are in the same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f07e5ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bean, green' 'wheat' 'onion' 'pea, green' 'corn, field' 'corn, sweet'\n",
      " 'bean, dry' 'yellow mustard' 'potato' 'canola' 'mint' 'grass seed'\n",
      " 'carrot' 'buckwheat' 'bluegrass seed' 'grass hay' 'corn seed' 'pea, dry'\n",
      " 'pea seed' 'barley hay' 'market crops' 'triticale' 'carrot seed'\n",
      " 'wheat fallow' 'barley' 'alfalfa seed' 'oat hay' 'triticale hay']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Vote</th>\n",
       "      <th>CropTyp</th>\n",
       "      <th>Irrigtn</th>\n",
       "      <th>DataSrc</th>\n",
       "      <th>Acres</th>\n",
       "      <th>ExctAcr</th>\n",
       "      <th>LstSrvD</th>\n",
       "      <th>county</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100048_WSDA_SF_2017</td>\n",
       "      <td>1</td>\n",
       "      <td>bean, green</td>\n",
       "      <td>rill</td>\n",
       "      <td>wsda</td>\n",
       "      <td>18</td>\n",
       "      <td>18.033240</td>\n",
       "      <td>2017/05/14</td>\n",
       "      <td>Grant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100081_WSDA_SF_2017</td>\n",
       "      <td>1</td>\n",
       "      <td>wheat</td>\n",
       "      <td>rill</td>\n",
       "      <td>wsda</td>\n",
       "      <td>16</td>\n",
       "      <td>15.959744</td>\n",
       "      <td>2017/08/09</td>\n",
       "      <td>Grant</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID  Vote      CropTyp Irrigtn DataSrc  Acres    ExctAcr  \\\n",
       "0  100048_WSDA_SF_2017     1  bean, green    rill    wsda     18  18.033240   \n",
       "1  100081_WSDA_SF_2017     1        wheat    rill    wsda     16  15.959744   \n",
       "\n",
       "      LstSrvD county  \n",
       "0  2017/05/14  Grant  \n",
       "1  2017/08/09  Grant  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (ground_truth_labels.CropTyp.unique())\n",
    "ground_truth_labels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be4b20df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>human_system_start_time</th>\n",
       "      <th>NDVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100048_WSDA_SF_2017</td>\n",
       "      <td>2017-01-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100048_WSDA_SF_2017</td>\n",
       "      <td>2017-01-16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID human_system_start_time  NDVI\n",
       "0  100048_WSDA_SF_2017              2017-01-06   0.0\n",
       "1  100048_WSDA_SF_2017              2017-01-16   0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "60383565",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'ExctAcr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m ground_truth_labels \u001b[38;5;241m=\u001b[39m ground_truth_labels\u001b[38;5;241m.\u001b[39mreindex(index\u001b[38;5;241m=\u001b[39mground_truth_wide[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m ground_truth_labels \u001b[38;5;241m=\u001b[39m ground_truth_labels\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[43mground_truth_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExctAcr\u001b[49m\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m      6\u001b[0m ground_truth_labels\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'ExctAcr'"
     ]
    }
   ],
   "source": [
    "ground_truth_labels = ground_truth_labels.set_index('ID')\n",
    "ground_truth_labels = ground_truth_labels.reindex(index=ground_truth_wide['ID'])\n",
    "ground_truth_labels = ground_truth_labels.reset_index()\n",
    "\n",
    "print (ground_truth_labels.ExctAcr.min().round(2))\n",
    "ground_truth_labels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db4e5c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_labels=ground_truth_labels[[\"ID\", \"Vote\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c7c37c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(269, 37)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_df, x_test_df, y_train_df, y_test_df = train_test_split(ground_truth_wide, \n",
    "                                                                ground_truth_labels, \n",
    "                                                                test_size=0.2, \n",
    "                                                                random_state=0,\n",
    "                                                                shuffle=True,\n",
    "                                                                stratify=ground_truth_labels.Vote.values)\n",
    "x_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f52244",
   "metadata": {},
   "source": [
    "# Start Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702d33e",
   "metadata": {},
   "source": [
    "# Definitions\n",
    "\n",
    "  - **Precision** Of all instances we predict $\\hat y = 1$, what fraction is actually 1.\n",
    "     \\begin{equation}\\label{eq:precision}\n",
    "        \\text{Precision} = \\frac{TP}{TP + FP}\n",
    "     \\end{equation}\n",
    "\n",
    "  - **Recall** Of all instances that are actually $y = 1$, what fraction we predict 1.\n",
    "     \\begin{equation}\\label{eq:recall}\n",
    "         \\text{Recall} = \\text{TPR} = \\frac{TP}{TP + FN}\n",
    "     \\end{equation}\n",
    "     \n",
    "  - **Specifity** Fraction of all negative instances that are incorrectly predicted positive.\n",
    "     \\begin{equation}\\label{eq:specifity}\n",
    "        \\text{Specifity} = \\text{FPR} = \\frac{FP}{TN + FP}\\\\\n",
    "     \\end{equation}\n",
    "     \n",
    "  - **F-Score** Adjust $\\beta$ for trade off between  precision and recall. For precision oriented task $\\beta = 0.5$.\n",
    "     \\begin{equation}\\label{eq:Fscore}\n",
    "        F_\\beta = \\frac{(1+\\beta^2) TP}{ (1+\\beta^2) TP + \\beta^2 FN + FP}\n",
    "     \\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf310c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11f8f73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 262 ms, sys: 2.96 ms, total: 265 ms\n",
      "Wall time: 264 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='sqrt', random_state=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "regular_forest_1_default = RandomForestClassifier(n_estimators=100, \n",
    "                                                  criterion='gini', max_depth=None, \n",
    "                                                  min_samples_split=2, min_samples_leaf=1, \n",
    "                                                  min_weight_fraction_leaf=0.0,\n",
    "                                                  max_features='sqrt', max_leaf_nodes=None, \n",
    "                                                  min_impurity_decrease=0.0, \n",
    "                                                  bootstrap=True, oob_score=False, n_jobs=None, \n",
    "                                                  random_state=1, verbose=0, \n",
    "                                                  warm_start=False, class_weight=None, \n",
    "                                                  ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "regular_forest_1_default.fit(x_train_df.iloc[:, 1:], y_train_df.iloc[:, 1:].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f7bc5d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Vote</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>7667_WSDA_SF_2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>99748_WSDA_SF_2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID  Vote  prediction\n",
       "1221   7667_WSDA_SF_2016     1           1\n",
       "1334  99748_WSDA_SF_2017     1           1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_forest_1_default_predictions = regular_forest_1_default.predict(x_test_df.iloc[:, 1:])\n",
    "regular_forest_1_default_y_test_df = y_test_df.copy()\n",
    "regular_forest_1_default_y_test_df[\"prediction\"]=list(regular_forest_1_default_predictions)\n",
    "regular_forest_1_default_y_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e01ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92ad9c57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>None</th>\n",
       "      <th>Predict_Single</th>\n",
       "      <th>Predict_Double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actual_Single</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actual_Double</td>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            None  Predict_Single  Predict_Double\n",
       "0  Actual_Single             218               1\n",
       "1  Actual_Double              13              37"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_single_predicted_single=0\n",
    "true_single_predicted_double=0\n",
    "\n",
    "true_double_predicted_single=0\n",
    "true_double_predicted_double=0\n",
    "\n",
    "for index_ in regular_forest_1_default_y_test_df.index:\n",
    "    curr_vote=list(regular_forest_1_default_y_test_df[regular_forest_1_default_y_test_df.index==index_].Vote)[0]\n",
    "    curr_predict=list(regular_forest_1_default_y_test_df[\\\n",
    "                                            regular_forest_1_default_y_test_df.index==index_].prediction)[0]\n",
    "    if curr_vote==curr_predict:\n",
    "        if curr_vote==1: \n",
    "            true_single_predicted_single+=1\n",
    "        else:\n",
    "            true_double_predicted_double+=1\n",
    "    else:\n",
    "        if curr_vote==1:\n",
    "            true_single_predicted_double+=1\n",
    "        else:\n",
    "            true_double_predicted_single+=1\n",
    "            \n",
    "regular_forest_default_confus_tbl_test = pd.DataFrame(columns=['None', 'Predict_Single', 'Predict_Double'], \n",
    "                                               index=range(2))\n",
    "regular_forest_default_confus_tbl_test.loc[0, 'None'] = 'Actual_Single'\n",
    "regular_forest_default_confus_tbl_test.loc[1, 'None'] = 'Actual_Double'\n",
    "regular_forest_default_confus_tbl_test['Predict_Single']=0\n",
    "regular_forest_default_confus_tbl_test['Predict_Double']=0\n",
    "\n",
    "regular_forest_default_confus_tbl_test.loc[0, \"Predict_Single\"]=true_single_predicted_single\n",
    "regular_forest_default_confus_tbl_test.loc[0, \"Predict_Double\"]=true_single_predicted_double\n",
    "regular_forest_default_confus_tbl_test.loc[1, \"Predict_Single\"]=true_double_predicted_single\n",
    "regular_forest_default_confus_tbl_test.loc[1, \"Predict_Double\"]=true_double_predicted_double\n",
    "regular_forest_default_confus_tbl_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96740166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e02130c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1097.790529331336\n",
      "36.938837280005\n",
      "1060.8516920513312\n"
     ]
    }
   ],
   "source": [
    "FD1_y_test_df_act_1_pred_2=regular_forest_1_default_y_test_df[regular_forest_1_default_y_test_df.Vote==1].copy()\n",
    "FD1_y_test_df_act_2_pred_1=regular_forest_1_default_y_test_df[regular_forest_1_default_y_test_df.Vote==2].copy()\n",
    "\n",
    "FD1_y_test_df_act_1_pred_2=FD1_y_test_df_act_1_pred_2[FD1_y_test_df_act_1_pred_2.prediction==2].copy()\n",
    "FD1_y_test_df_act_2_pred_1=FD1_y_test_df_act_2_pred_1[FD1_y_test_df_act_2_pred_1.prediction==1].copy()\n",
    "\n",
    "FD1_y_test_df_act_2_pred_1 = pd.merge(FD1_y_test_df_act_2_pred_1, \\\n",
    "                                           ground_truth_labels_extended, on=['ID'], how='left')\n",
    "FD1_y_test_df_act_1_pred_2 = pd.merge(FD1_y_test_df_act_1_pred_2, \\\n",
    "                                      ground_truth_labels_extended, on=['ID'], how='left')\n",
    "\n",
    "print (FD1_y_test_df_act_2_pred_1.ExctAcr.sum())\n",
    "print (FD1_y_test_df_act_1_pred_2.ExctAcr.sum())\n",
    "\n",
    "print (FD1_y_test_df_act_2_pred_1.ExctAcr.sum()-FD1_y_test_df_act_1_pred_2.ExctAcr.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d305f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_Models/\"\n",
    "filename = model_dir + \"regular\" + VI_idx + \"_forest_default.sav\"\n",
    "filename\n",
    "pickle.dump(regular_forest_1_default, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d3170af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'n_jobs':[4],\n",
    "#               'criterion': [\"gini\", \"entropy\"], # log_loss\n",
    "#               'max_depth':[1, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20],\n",
    "#               'min_samples_split':[2, 3, 4, 5],\n",
    "#               'max_features': [\"sqrt\", \"log2\", None],\n",
    "#               # 'min_impurity_decreasefloat':[0, 1, 2],\n",
    "#               'class_weight':['balanced', 'balanced_subsample', None],\n",
    "#               'ccp_alpha':[0.0, 1, 2, 3], \n",
    "#               'max_samples':[None, 1, 2, 3, 4, 5]} # , \n",
    "# forest_classifier_grid = GridSearchCV(RandomForestClassifier(random_state=0), \n",
    "#                                       parameters, cv=5, verbose=1,\n",
    "#                                       error_score='raise')\n",
    "\n",
    "# forest_classifier_grid.fit(x_train_df.iloc[:, 1:], y_train_df.Vote.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6b2837c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "181a4383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (n_estimators=100, \n",
    "# criterion='gini', \n",
    "# max_depth=None, \n",
    "# min_samples_split=2, \n",
    "# min_samples_leaf=1, \n",
    "# min_weight_fraction_leaf=0.0,\n",
    "# max_features='sqrt', \n",
    "# max_leaf_nodes=None, \n",
    "# min_impurity_decrease=0.0, \n",
    "# bootstrap=True, \n",
    "# oob_score=False, \n",
    "# n_jobs=None, \n",
    "# random_state=1,\n",
    "# warm_start=False, \n",
    "# class_weight=None, \n",
    "# ccp_alpha=0.0,\n",
    "# max_samples=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6adab1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# parameters = {'n_jobs':[4],\n",
    "#               'criterion': [\"gini\", \"entropy\"], # log_loss \n",
    "#               'max_depth':[2, 4, 6, 8, 9, 10, 11, 12, 14, 16, 18, 20],\n",
    "#               'min_samples_split':[2, 3, 4, 5],\n",
    "#               'max_features': [\"sqrt\", \"log2\", None],\n",
    "#               'class_weight':['balanced', 'balanced_subsample', None],\n",
    "#               'ccp_alpha':[0.0, 1, 2, 3], \n",
    "#              # 'min_impurity_decreasefloat':[0, 1, 2], # roblem with sqrt stuff?\n",
    "#               'max_samples':[None, 1, 2, 3, 4, 5]\n",
    "#              } # , \n",
    "# forest_grid_1 = GridSearchCV(RandomForestClassifier(random_state=0), \n",
    "#                              parameters, cv=5, verbose=1,\n",
    "#                              error_score='raise')\n",
    "\n",
    "# forest_grid_1.fit(x_train_df.iloc[:, 1:], y_train_df.Vote.values.ravel())\n",
    "\n",
    "# print (forest_grid_1.best_params_)\n",
    "# print (forest_grid_1.best_score_)\n",
    "\n",
    "\n",
    "# model_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_Models/\"\n",
    "# filename = model_dir + 'forest_grid_1.sav'\n",
    "# pickle.dump(forest_1_default, open(filename, 'wb')) <- why it is saving default as grid_1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945b2c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a11b062a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 26 candidates, totalling 130 fits\n",
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 11, 'max_features': 'log2', 'max_samples': None, 'min_samples_split': 4, 'n_jobs': 6}\n",
      "0.955266246468159\n",
      "CPU times: user 10.3 s, sys: 1.15 s, total: 11.4 s\n",
      "Wall time: 14.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'n_jobs':[6],\n",
    "              'criterion': [\"gini\", \"entropy\"], # log_loss \n",
    "              'max_depth':[1, 2, 4, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17],\n",
    "              'min_samples_split':[4],\n",
    "              'max_features': [\"log2\"],\n",
    "              'class_weight':[None],\n",
    "              'ccp_alpha':[0.0], \n",
    "             # 'min_impurity_decreasefloat':[0, 1, 2], # roblem with sqrt stuff?\n",
    "              'max_samples':[None]\n",
    "             } # , \n",
    "regular_forest_grid_1 = GridSearchCV(RandomForestClassifier(random_state=0), \n",
    "                                     parameters, cv=5, verbose=1,\n",
    "                                     error_score='raise')\n",
    "\n",
    "regular_forest_grid_1.fit(x_train_df.iloc[:, 1:], y_train_df.Vote.values.ravel())\n",
    "\n",
    "print (regular_forest_grid_1.best_params_)\n",
    "print (regular_forest_grid_1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6ef1674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Vote</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>7667_WSDA_SF_2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>99748_WSDA_SF_2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID  Vote  prediction\n",
       "1221   7667_WSDA_SF_2016     1           1\n",
       "1334  99748_WSDA_SF_2017     1           1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regular_forest_grid_1_predictions = regular_forest_grid_1.predict(x_test_df.iloc[:, 1:])\n",
    "regular_forest_grid_1_y_test_df=y_test_df.copy()\n",
    "regular_forest_grid_1_y_test_df[\"prediction\"]=list(regular_forest_grid_1_predictions)\n",
    "regular_forest_grid_1_y_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24d6ddbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>None</th>\n",
       "      <th>Predict_Single</th>\n",
       "      <th>Predict_Double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actual_Single</td>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actual_Double</td>\n",
       "      <td>13</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            None  Predict_Single  Predict_Double\n",
       "0  Actual_Single             218               1\n",
       "1  Actual_Double              13              37"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_single_predicted_single=0\n",
    "true_single_predicted_double=0\n",
    "\n",
    "true_double_predicted_single=0\n",
    "true_double_predicted_double=0\n",
    "\n",
    "for index_ in regular_forest_grid_1_y_test_df.index:\n",
    "    curr_vote=list(regular_forest_grid_1_y_test_df[regular_forest_grid_1_y_test_df.index==index_].Vote)[0]\n",
    "    curr_predict=list(regular_forest_grid_1_y_test_df[regular_forest_grid_1_y_test_df.index==index_].prediction)[0]\n",
    "    if curr_vote==curr_predict:\n",
    "        if curr_vote==1: \n",
    "            true_single_predicted_single+=1\n",
    "        else:\n",
    "            true_double_predicted_double+=1\n",
    "    else:\n",
    "        if curr_vote==1:\n",
    "            true_single_predicted_double+=1\n",
    "        else:\n",
    "            true_double_predicted_single+=1\n",
    "            \n",
    "regular_forest_grid_1_confus_tbl_test = pd.DataFrame(columns=['None', 'Predict_Single', 'Predict_Double'], \n",
    "                               index=range(2))\n",
    "regular_forest_grid_1_confus_tbl_test.loc[0, 'None'] = 'Actual_Single'\n",
    "regular_forest_grid_1_confus_tbl_test.loc[1, 'None'] = 'Actual_Double'\n",
    "regular_forest_grid_1_confus_tbl_test['Predict_Single']=0\n",
    "regular_forest_grid_1_confus_tbl_test['Predict_Double']=0\n",
    "\n",
    "regular_forest_grid_1_confus_tbl_test.loc[0, \"Predict_Single\"]=true_single_predicted_single\n",
    "regular_forest_grid_1_confus_tbl_test.loc[0, \"Predict_Double\"]=true_single_predicted_double\n",
    "regular_forest_grid_1_confus_tbl_test.loc[1, \"Predict_Single\"]=true_double_predicted_single\n",
    "regular_forest_grid_1_confus_tbl_test.loc[1, \"Predict_Double\"]=true_double_predicted_double\n",
    "regular_forest_grid_1_confus_tbl_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2f9f2e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1144.29\n",
      "36.94\n",
      "1107.35\n"
     ]
    }
   ],
   "source": [
    "FG1_y_test_df_act_1_pred_2=regular_forest_grid_1_y_test_df[regular_forest_grid_1_y_test_df.Vote==1].copy()\n",
    "FG1_y_test_df_act_2_pred_1=regular_forest_grid_1_y_test_df[regular_forest_grid_1_y_test_df.Vote==2].copy()\n",
    "\n",
    "FG1_y_test_df_act_1_pred_2=FG1_y_test_df_act_1_pred_2[FG1_y_test_df_act_1_pred_2.prediction==2].copy()\n",
    "FG1_y_test_df_act_2_pred_1=FG1_y_test_df_act_2_pred_1[FG1_y_test_df_act_2_pred_1.prediction==1].copy()\n",
    "\n",
    "FG1_y_test_df_act_2_pred_1 = pd.merge(FG1_y_test_df_act_2_pred_1, ground_truth_labels_extended, on=['ID'], how='left')\n",
    "FG1_y_test_df_act_1_pred_2 = pd.merge(FG1_y_test_df_act_1_pred_2, ground_truth_labels_extended, on=['ID'], how='left')\n",
    "\n",
    "print (FG1_y_test_df_act_2_pred_1.ExctAcr.sum().round(2))\n",
    "print (FG1_y_test_df_act_1_pred_2.ExctAcr.sum().round(2))\n",
    "print ((FG1_y_test_df_act_2_pred_1.ExctAcr.sum()-FG1_y_test_df_act_1_pred_2.ExctAcr.sum()).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f5cd9bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hn/Documents/01_research_data/NASA/ML_Models/regularNDVI_forest_grid_1.sav\n"
     ]
    }
   ],
   "source": [
    "filename = model_dir + \"regular\"+ VI_idx +\"_forest_grid_1.sav\"\n",
    "print (filename)\n",
    "pickle.dump(regular_forest_grid_1, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be678a9",
   "metadata": {},
   "source": [
    "### Regular More parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70ab2335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24192 candidates, totalling 120960 fits\n",
      "{'ccp_alpha': 0.0, 'class_weight': 'balanced', 'criterion': 'entropy', 'max_depth': 9, 'max_features': 'log2', 'max_samples': None, 'min_samples_split': 4, 'n_jobs': 5}\n",
      "0.9627298413388393\n",
      "CPU times: user 2h 38min 55s, sys: 16min 56s, total: 2h 55min 51s\n",
      "Wall time: 3h 16min 15s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Vote</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>7667_WSDA_SF_2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>99748_WSDA_SF_2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID  Vote  prediction\n",
       "1221   7667_WSDA_SF_2016     1           1\n",
       "1334  99748_WSDA_SF_2017     1           1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# parameters = {'n_jobs':[6],\n",
    "#               'criterion': [\"gini\", \"entropy\"], # log_loss \n",
    "#               'max_depth':[1, 2, 4, 6, 8, 10, 11, 12, 13, 14, 15, 16, 17],\n",
    "#               'min_samples_split':[4],\n",
    "#               'max_features': [\"log2\"],\n",
    "#               'class_weight':[None],\n",
    "#               'ccp_alpha':[0.0],\n",
    "#               'max_samples':[None]\n",
    "#              }\n",
    "\n",
    "parameters = {'n_jobs':[5],\n",
    "              'criterion': [\"gini\", \"entropy\"], # log_loss \n",
    "              'max_depth':[2, 4, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20],\n",
    "              'min_samples_split':[2, 3, 4, 5],\n",
    "              'max_features': [\"sqrt\", \"log2\", None],\n",
    "              'class_weight':['balanced', 'balanced_subsample', None],\n",
    "              'ccp_alpha':[0.0, 1, 2, 3], \n",
    "             # 'min_impurity_decreasefloat':[0, 1, 2], # roblem with sqrt stuff?\n",
    "              'max_samples':[None, 1, 2, 3, 4, 5]\n",
    "             }\n",
    "\n",
    "regular_forest_grid_2 = GridSearchCV(RandomForestClassifier(random_state=0), \n",
    "                             parameters, cv=5, verbose=1,\n",
    "                             error_score='raise')\n",
    "\n",
    "regular_forest_grid_2.fit(x_train_df.iloc[:, 1:], y_train_df.Vote.values.ravel())\n",
    "\n",
    "print (regular_forest_grid_2.best_params_)\n",
    "print (regular_forest_grid_2.best_score_)\n",
    "\n",
    "\n",
    "regular_forest_grid_2_predictions = regular_forest_grid_2.predict(x_test_df.iloc[:, 1:])\n",
    "regular_forest_grid_2_y_test_df=y_test_df.copy()\n",
    "regular_forest_grid_2_y_test_df[\"prediction\"]=list(regular_forest_grid_2_predictions)\n",
    "regular_forest_grid_2_y_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6a7a626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>None</th>\n",
       "      <th>Predict_Single</th>\n",
       "      <th>Predict_Double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actual_Single</td>\n",
       "      <td>217</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actual_Double</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            None  Predict_Single  Predict_Double\n",
       "0  Actual_Single             217               2\n",
       "1  Actual_Double              14              36"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_single_predicted_single=0\n",
    "true_single_predicted_double=0\n",
    "\n",
    "true_double_predicted_single=0\n",
    "true_double_predicted_double=0\n",
    "\n",
    "for index_ in regular_forest_grid_2_y_test_df.index:\n",
    "    curr_vote=list(regular_forest_grid_2_y_test_df[regular_forest_grid_2_y_test_df.index==index_].Vote)[0]\n",
    "    curr_predict=list(regular_forest_grid_2_y_test_df[regular_forest_grid_2_y_test_df.index==index_].prediction)[0]\n",
    "    if curr_vote==curr_predict:\n",
    "        if curr_vote==1: \n",
    "            true_single_predicted_single+=1\n",
    "        else:\n",
    "            true_double_predicted_double+=1\n",
    "    else:\n",
    "        if curr_vote==1:\n",
    "            true_single_predicted_double+=1\n",
    "        else:\n",
    "            true_double_predicted_single+=1\n",
    "            \n",
    "regular_forest_grid_2_confus_tbl_test = pd.DataFrame(columns=['None', 'Predict_Single', 'Predict_Double'], \n",
    "                               index=range(2))\n",
    "regular_forest_grid_2_confus_tbl_test.loc[0, 'None'] = 'Actual_Single'\n",
    "regular_forest_grid_2_confus_tbl_test.loc[1, 'None'] = 'Actual_Double'\n",
    "regular_forest_grid_2_confus_tbl_test['Predict_Single']=0\n",
    "regular_forest_grid_2_confus_tbl_test['Predict_Double']=0\n",
    "\n",
    "regular_forest_grid_2_confus_tbl_test.loc[0, \"Predict_Single\"]=true_single_predicted_single\n",
    "regular_forest_grid_2_confus_tbl_test.loc[0, \"Predict_Double\"]=true_single_predicted_double\n",
    "regular_forest_grid_2_confus_tbl_test.loc[1, \"Predict_Single\"]=true_double_predicted_single\n",
    "regular_forest_grid_2_confus_tbl_test.loc[1, \"Predict_Double\"]=true_double_predicted_double\n",
    "regular_forest_grid_2_confus_tbl_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c4b5eed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1259.47\n",
      "54.82\n",
      "1204.65\n"
     ]
    }
   ],
   "source": [
    "FG2_y_test_df_act_1_pred_2=regular_forest_grid_2_y_test_df[regular_forest_grid_2_y_test_df.Vote==1].copy()\n",
    "FG2_y_test_df_act_2_pred_1=regular_forest_grid_2_y_test_df[regular_forest_grid_2_y_test_df.Vote==2].copy()\n",
    "\n",
    "FG2_y_test_df_act_1_pred_2=FG2_y_test_df_act_1_pred_2[FG2_y_test_df_act_1_pred_2.prediction==2].copy()\n",
    "FG2_y_test_df_act_2_pred_1=FG2_y_test_df_act_2_pred_1[FG2_y_test_df_act_2_pred_1.prediction==1].copy()\n",
    "\n",
    "FG2_y_test_df_act_2_pred_1 = pd.merge(FG2_y_test_df_act_2_pred_1, ground_truth_labels_extended, on=['ID'], how='left')\n",
    "FG2_y_test_df_act_1_pred_2 = pd.merge(FG2_y_test_df_act_1_pred_2, ground_truth_labels_extended, on=['ID'], how='left')\n",
    "\n",
    "print (FG2_y_test_df_act_2_pred_1.ExctAcr.sum().round(2))\n",
    "print (FG2_y_test_df_act_1_pred_2.ExctAcr.sum().round(2))\n",
    "print ((FG2_y_test_df_act_2_pred_1.ExctAcr.sum()-FG2_y_test_df_act_1_pred_2.ExctAcr.sum()).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d060ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = model_dir + \"regular\" + VI_idx + \"_forest_grid_2.sav\"\n",
    "pickle.dump(regular_forest_grid_2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3225bb4",
   "metadata": {},
   "source": [
    "# Why?\n",
    "\n",
    "We gave more options to the grid search, and the result in terms of accuracy is lowerd. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4b06b140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion\n",
      "[[218   1]\n",
      " [ 13  37]]\n",
      "_________________________________________________________________________\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      1.00      0.97       219\n",
      "           2       0.97      0.74      0.84        50\n",
      "\n",
      "    accuracy                           0.95       269\n",
      "   macro avg       0.96      0.87      0.90       269\n",
      "weighted avg       0.95      0.95      0.95       269\n",
      "\n",
      "_________________________________________________________________________\n",
      "accuracy_score\n",
      "0.948\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print (\"Confusion\")\n",
    "print(confusion_matrix(list(regular_forest_grid_1_y_test_df.Vote), \n",
    "                       list((regular_forest_grid_1_y_test_df.prediction))))\n",
    "print (\"_________________________________________________________________________\")\n",
    "print (\"classification_report\")\n",
    "print(classification_report(list(regular_forest_grid_1_y_test_df.Vote), \n",
    "                            list((regular_forest_grid_1_y_test_df.prediction))))\n",
    "print (\"_________________________________________________________________________\")\n",
    "print (\"accuracy_score\")\n",
    "print(accuracy_score(list(regular_forest_grid_1_y_test_df.Vote), \n",
    "                     list((regular_forest_grid_1_y_test_df.prediction))).round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "788fd6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion\n",
      "[[217   2]\n",
      " [ 14  36]]\n",
      "_________________________________________________________________________\n",
      "classification_report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.94      0.99      0.96       219\n",
      "           2       0.95      0.72      0.82        50\n",
      "\n",
      "    accuracy                           0.94       269\n",
      "   macro avg       0.94      0.86      0.89       269\n",
      "weighted avg       0.94      0.94      0.94       269\n",
      "\n",
      "_________________________________________________________________________\n",
      "accuracy_score\n",
      "0.941\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print (\"Confusion\")\n",
    "print(confusion_matrix(list(regular_forest_grid_2_y_test_df.Vote), \n",
    "                       list((regular_forest_grid_2_y_test_df.prediction))))\n",
    "print (\"_________________________________________________________________________\")\n",
    "print (\"classification_report\")\n",
    "print(classification_report(list(regular_forest_grid_2_y_test_df.Vote), \n",
    "                            list((regular_forest_grid_2_y_test_df.prediction))))\n",
    "print (\"_________________________________________________________________________\")\n",
    "print (\"accuracy_score\")\n",
    "print(accuracy_score(list(regular_forest_grid_2_y_test_df.Vote), \n",
    "                     list((regular_forest_grid_2_y_test_df.prediction))).round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b333e",
   "metadata": {},
   "source": [
    "# SG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7daed073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>human_system_start_time</th>\n",
       "      <th>NDVI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135073_WSDA_SF_2015</td>\n",
       "      <td>2015-01-10</td>\n",
       "      <td>0.115126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135073_WSDA_SF_2015</td>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>0.111097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID human_system_start_time      NDVI\n",
       "0  135073_WSDA_SF_2015              2015-01-10  0.115126\n",
       "1  135073_WSDA_SF_2015              2015-01-20  0.111097"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"/Users/hn/Documents/01_research_data/NASA/VI_TS/05_SG_TS/\"\n",
    "\n",
    "file_names = [\"SG_Walla2015_\" + VI_idx + \"_JFD.csv\", \"SG_AdamBenton2016_\" + VI_idx + \"_JFD.csv\", \n",
    "              \"SG_Grant2017_\" + VI_idx + \"_JFD.csv\", \"SG_FranklinYakima2018_\"+ VI_idx +\"_JFD.csv\"]\n",
    "\n",
    "data=pd.DataFrame()\n",
    "\n",
    "for file in file_names:\n",
    "    curr_file=pd.read_csv(data_dir + file)\n",
    "    curr_file['human_system_start_time'] = pd.to_datetime(curr_file['human_system_start_time'])\n",
    "    \n",
    "    # These data are for 3 years. The middle one is the correct one\n",
    "    all_years = sorted(curr_file.human_system_start_time.dt.year.unique())\n",
    "    if len(all_years)==3 or len(all_years)==2:\n",
    "        proper_year = all_years[1]\n",
    "    elif len(all_years)==1:\n",
    "        proper_year = all_years[0]\n",
    "\n",
    "    curr_file = curr_file[curr_file.human_system_start_time.dt.year==proper_year]\n",
    "    data=pd.concat([data, curr_file])\n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "df420a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3539\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'ExctAcr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [84]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;28mlen\u001b[39m(meta_moreThan10Acr\u001b[38;5;241m.\u001b[39mID\u001b[38;5;241m.\u001b[39munique()))\n\u001b[1;32m      4\u001b[0m ground_truth_labels_extended \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(ground_truth_labels, meta, on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m], how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m ground_truth_labels \u001b[38;5;241m=\u001b[39m ground_truth_labels_extended[\u001b[43mground_truth_labels_extended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mExctAcr\u001b[49m\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m      6\u001b[0m ground_truth_labels\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere are [\u001b[39m\u001b[38;5;132;01m{:.0f}\u001b[39;00m\u001b[38;5;124m] fields in total whose\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m      9\u001b[0m        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marea adds up to [\u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m].\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(ground_truth_labels_extended),\\\n\u001b[1;32m     10\u001b[0m                                                             ground_truth_labels_extended\u001b[38;5;241m.\u001b[39mExctAcr\u001b[38;5;241m.\u001b[39msum()))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:5575\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5568\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5569\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5570\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5571\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5572\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5573\u001b[0m ):\n\u001b[1;32m   5574\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'ExctAcr'"
     ]
    }
   ],
   "source": [
    "ground_truth = data[data.ID.isin(list(ground_truth_labels.ID.unique()))].copy()\n",
    "\n",
    "print (len(meta_moreThan10Acr.ID.unique()))\n",
    "ground_truth_labels_extended = pd.merge(ground_truth_labels, meta, on=['ID'], how='left')\n",
    "ground_truth_labels = ground_truth_labels_extended[ground_truth_labels_extended.ExctAcr>=10].copy()\n",
    "ground_truth_labels.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print (\"There are [{:.0f}] fields in total whose\"+ \\\n",
    "       \"area adds up to [{:.2f}].\".format(len(ground_truth_labels_extended),\\\n",
    "                                                            ground_truth_labels_extended.ExctAcr.sum()))\n",
    "\n",
    "\n",
    "print (\"There are [{:.0f}] fields larger than 10 \"+ \\\n",
    "        \"acres whose area adds up to [{:.2f}].\".format(len(ground_truth_labels), \\\n",
    "                                                                    ground_truth_labels.ExctAcr.sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b9231462",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = ground_truth[ground_truth.ID.isin((list(meta_moreThan10Acr.ID)))].copy()\n",
    "ground_truth_labels = ground_truth_labels[ground_truth_labels.ID.isin((list(meta_moreThan10Acr.ID)))].copy()\n",
    "\n",
    "ground_truth.reset_index(drop=True, inplace=True)\n",
    "ground_truth_labels.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "958b69a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100048_WSDA_SF_2017\n",
      "100048_WSDA_SF_2017\n",
      "____________________________________\n",
      "99909_WSDA_SF_2017\n",
      "99909_WSDA_SF_2017\n",
      "____________________________________\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "ground_truth.sort_values(by=[\"ID\", 'human_system_start_time'], inplace=True)\n",
    "ground_truth_labels.sort_values(by=[\"ID\"], inplace=True)\n",
    "\n",
    "ground_truth.reset_index(drop=True, inplace=True)\n",
    "ground_truth_labels.reset_index(drop=True, inplace=True)\n",
    "\n",
    "assert (len(ground_truth.ID.unique()) == len(ground_truth_labels.ID.unique()))\n",
    "\n",
    "print (list(ground_truth.ID)[0])\n",
    "print (list(ground_truth_labels.ID)[0])\n",
    "print (\"____________________________________\")\n",
    "print (list(ground_truth.ID)[-1])\n",
    "print (list(ground_truth_labels.ID)[-1])\n",
    "print (\"____________________________________\")\n",
    "print (list(ground_truth.ID.unique())==list(ground_truth_labels.ID.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a4a515",
   "metadata": {},
   "source": [
    "# Widen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "08d3cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NDVI_colnames = [VI_idx + \"_\" + str(ii) for ii in range(1, 37) ]\n",
    "columnNames = [\"ID\"] + NDVI_colnames\n",
    "ground_truth_wide = pd.DataFrame(columns=columnNames, \n",
    "                                index=range(len(ground_truth.ID.unique())))\n",
    "ground_truth_wide[\"ID\"] = ground_truth.ID.unique()\n",
    "\n",
    "for an_ID in ground_truth.ID.unique():\n",
    "    curr_df = ground_truth[ground_truth.ID==an_ID]\n",
    "    \n",
    "    ground_truth_wide_indx = ground_truth_wide[ground_truth_wide.ID==an_ID].index\n",
    "    ground_truth_wide.loc[ground_truth_wide_indx, \"NDVI_1\":\"NDVI_36\"] = curr_df.NDVI.values[:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e426591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_labels = ground_truth_labels.set_index('ID')\n",
    "ground_truth_labels = ground_truth_labels.reindex(index=ground_truth_wide['ID'])\n",
    "ground_truth_labels = ground_truth_labels.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3526b937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100048_WSDA_SF_2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100081_WSDA_SF_2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID  Vote\n",
       "0  100048_WSDA_SF_2017     1\n",
       "1  100081_WSDA_SF_2017     1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ground_truth_labels=ground_truth_labels[[\"ID\", \"Vote\"]]\n",
    "ground_truth_labels.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f2f81848",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_df, x_test_df, y_train_df, y_test_df = train_test_split(ground_truth_wide, \n",
    "                                                                ground_truth_labels, \n",
    "                                                                test_size=0.2, \n",
    "                                                                random_state=0,\n",
    "                                                                shuffle=True,\n",
    "                                                                stratify=ground_truth_labels.Vote.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "64b7fa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 271 ms, sys: 6.27 ms, total: 278 ms\n",
      "Wall time: 277 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features='sqrt', random_state=1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "forest_1_default_SG = RandomForestClassifier(n_estimators=100, \n",
    "                                             criterion='gini', max_depth=None, \n",
    "                                             min_samples_split=2, min_samples_leaf=1, \n",
    "                                             min_weight_fraction_leaf=0.0,\n",
    "                                             max_features='sqrt', max_leaf_nodes=None, \n",
    "                                             min_impurity_decrease=0.0, \n",
    "                                             bootstrap=True, oob_score=False, n_jobs=None, \n",
    "                                             random_state=1, verbose=0, \n",
    "                                             warm_start=False, class_weight=None, \n",
    "                                             ccp_alpha=0.0, max_samples=None)\n",
    "\n",
    "forest_1_default_SG.fit(x_train_df.iloc[:, 1:], y_train_df.iloc[:, 1:].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "137c8793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Vote</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>7667_WSDA_SF_2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>99748_WSDA_SF_2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID  Vote  prediction\n",
       "1221   7667_WSDA_SF_2016     1           1\n",
       "1334  99748_WSDA_SF_2017     1           1"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_1_default_SG_predictions = forest_1_default_SG.predict(x_test_df.iloc[:, 1:])\n",
    "forest_1_default_SG_y_test_df=y_test_df.copy()\n",
    "forest_1_default_SG_y_test_df[\"prediction\"]=list(forest_1_default_SG_predictions)\n",
    "forest_1_default_SG_y_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4f59818e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>None</th>\n",
       "      <th>Predict_Single</th>\n",
       "      <th>Predict_Double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actual_Single</td>\n",
       "      <td>217</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actual_Double</td>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            None  Predict_Single  Predict_Double\n",
       "0  Actual_Single             217               2\n",
       "1  Actual_Double              11              39"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_single_predicted_single=0\n",
    "true_single_predicted_double=0\n",
    "\n",
    "true_double_predicted_single=0\n",
    "true_double_predicted_double=0\n",
    "\n",
    "for index_ in forest_1_default_SG_y_test_df.index:\n",
    "    curr_vote=list(forest_1_default_SG_y_test_df[forest_1_default_SG_y_test_df.index==index_].Vote)[0]\n",
    "    curr_predict=list(forest_1_default_SG_y_test_df[forest_1_default_SG_y_test_df.index==index_].prediction)[0]\n",
    "    if curr_vote==curr_predict:\n",
    "        if curr_vote==1: \n",
    "            true_single_predicted_single+=1\n",
    "        else:\n",
    "            true_double_predicted_double+=1\n",
    "    else:\n",
    "        if curr_vote==1:\n",
    "            true_single_predicted_double+=1\n",
    "        else:\n",
    "            true_double_predicted_single+=1\n",
    "            \n",
    "forest_default_SG_confus_tbl_test = pd.DataFrame(columns=['None', 'Predict_Single', 'Predict_Double'], \n",
    "                               index=range(2))\n",
    "forest_default_SG_confus_tbl_test.loc[0, 'None'] = 'Actual_Single'\n",
    "forest_default_SG_confus_tbl_test.loc[1, 'None'] = 'Actual_Double'\n",
    "forest_default_SG_confus_tbl_test['Predict_Single']=0\n",
    "forest_default_SG_confus_tbl_test['Predict_Double']=0\n",
    "\n",
    "forest_default_SG_confus_tbl_test.loc[0, \"Predict_Single\"]=true_single_predicted_single\n",
    "forest_default_SG_confus_tbl_test.loc[0, \"Predict_Double\"]=true_single_predicted_double\n",
    "forest_default_SG_confus_tbl_test.loc[1, \"Predict_Single\"]=true_double_predicted_single\n",
    "forest_default_SG_confus_tbl_test.loc[1, \"Predict_Double\"]=true_double_predicted_double\n",
    "forest_default_SG_confus_tbl_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9e0f9fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FD1_yTest_df_act_2_pred_1.ExctAcr.sum(): 919.96\n",
      "FD1_yTest_df_act_1_pred_2.ExctAcr.sum(): 54.82\n",
      "865.1432841821751\n"
     ]
    }
   ],
   "source": [
    "FD1_yTest_df_act_1_pred_2=forest_1_default_SG_y_test_df[forest_1_default_SG_y_test_df.Vote==1].copy()\n",
    "FD1_yTest_df_act_2_pred_1=forest_1_default_SG_y_test_df[forest_1_default_SG_y_test_df.Vote==2].copy()\n",
    "\n",
    "FD1_yTest_df_act_1_pred_2=FD1_yTest_df_act_1_pred_2[FD1_yTest_df_act_1_pred_2.prediction==2].copy()\n",
    "FD1_yTest_df_act_2_pred_1=FD1_yTest_df_act_2_pred_1[FD1_yTest_df_act_2_pred_1.prediction==1].copy()\n",
    "\n",
    "FD1_yTest_df_act_2_pred_1 = pd.merge(FD1_yTest_df_act_2_pred_1, ground_truth_labels_extended, on=['ID'], how='left')\n",
    "FD1_yTest_df_act_1_pred_2 = pd.merge(FD1_yTest_df_act_1_pred_2, ground_truth_labels_extended, on=['ID'], how='left')\n",
    "\n",
    "aa=FD1_yTest_df_act_2_pred_1.ExctAcr.sum()\n",
    "bb=FD1_yTest_df_act_1_pred_2.ExctAcr.sum()\n",
    "print (\"FD1_yTest_df_act_2_pred_1.ExctAcr.sum():\", aa.round(2))\n",
    "print (\"FD1_yTest_df_act_1_pred_2.ExctAcr.sum():\", bb.round(2))\n",
    "print (aa-bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e4bf1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a9eb3f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20736 candidates, totalling 103680 fits\n",
      "{'ccp_alpha': 0.0, 'class_weight': 'balanced_subsample', 'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'max_samples': None, 'min_samples_split': 4, 'n_jobs': 6}\n",
      "0.9636644207780918\n",
      "CPU times: user 2h 13min 15s, sys: 14min 35s, total: 2h 27min 50s\n",
      "Wall time: 2h 45min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'n_jobs':[6],\n",
    "              'criterion': [\"gini\", \"entropy\"], # log_loss \n",
    "              'max_depth':[2, 4, 6, 8, 9, 10, 11, 12, 14, 16, 18, 20],\n",
    "              'min_samples_split':[2, 3, 4, 5],\n",
    "              'max_features': [\"sqrt\", \"log2\", None],\n",
    "              'class_weight':['balanced', 'balanced_subsample', None],\n",
    "              'ccp_alpha':[0.0, 1, 2, 3], \n",
    "             # 'min_impurity_decreasefloat':[0, 1, 2], # roblem with sqrt stuff?\n",
    "              'max_samples':[None, 1, 2, 3, 4, 5]\n",
    "             } # , \n",
    "forest_grid_1_SG = GridSearchCV(RandomForestClassifier(random_state=0), \n",
    "                             parameters, cv=5, verbose=1,\n",
    "                             error_score='raise')\n",
    "\n",
    "forest_grid_1_SG.fit(x_train_df.iloc[:, 1:], y_train_df.Vote.values.ravel())\n",
    "\n",
    "print (forest_grid_1_SG.best_params_)\n",
    "print (forest_grid_1_SG.best_score_)\n",
    "\n",
    "\n",
    "model_dir = \"/Users/hn/Documents/01_research_data/NASA/ML_Models/\"\n",
    "filename = model_dir + \"SG\" + VI_idx + \"_forest_grid_1.sav\"\n",
    "pickle.dump(forest_grid_1_SG, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "02a30223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Vote</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>7667_WSDA_SF_2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>99748_WSDA_SF_2017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID  Vote  prediction\n",
       "1221   7667_WSDA_SF_2016     1           1\n",
       "1334  99748_WSDA_SF_2017     1           1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_grid_1_SG_predictions = forest_grid_1_SG.predict(x_test_df.iloc[:, 1:])\n",
    "forest_grid_1_SG_y_test_df=y_test_df.copy()\n",
    "forest_grid_1_SG_y_test_df[\"prediction\"]=list(forest_grid_1_SG_predictions)\n",
    "forest_grid_1_SG_y_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d5671809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>None</th>\n",
       "      <th>Predict_Single</th>\n",
       "      <th>Predict_Double</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Actual_Single</td>\n",
       "      <td>217</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actual_Double</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            None  Predict_Single  Predict_Double\n",
       "0  Actual_Single             217               2\n",
       "1  Actual_Double              14              36"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_single_predicted_single=0\n",
    "true_single_predicted_double=0\n",
    "\n",
    "true_double_predicted_single=0\n",
    "true_double_predicted_double=0\n",
    "\n",
    "for index_ in forest_grid_1_SG_y_test_df.index:\n",
    "    curr_vote=list(forest_grid_1_SG_y_test_df[forest_grid_1_SG_y_test_df.index==index_].Vote)[0]\n",
    "    curr_predict=list(forest_grid_1_SG_y_test_df[forest_grid_1_SG_y_test_df.index==index_].prediction)[0]\n",
    "    if curr_vote==curr_predict:\n",
    "        if curr_vote==1: \n",
    "            true_single_predicted_single+=1\n",
    "        else:\n",
    "            true_double_predicted_double+=1\n",
    "    else:\n",
    "        if curr_vote==1:\n",
    "            true_single_predicted_double+=1\n",
    "        else:\n",
    "            true_double_predicted_single+=1\n",
    "            \n",
    "forest_default_SG_confus_tbl_test = pd.DataFrame(columns=['None', 'Predict_Single', 'Predict_Double'], \n",
    "                               index=range(2))\n",
    "forest_default_SG_confus_tbl_test.loc[0, 'None'] = 'Actual_Single'\n",
    "forest_default_SG_confus_tbl_test.loc[1, 'None'] = 'Actual_Double'\n",
    "forest_default_SG_confus_tbl_test['Predict_Single']=0\n",
    "forest_default_SG_confus_tbl_test['Predict_Double']=0\n",
    "\n",
    "forest_default_SG_confus_tbl_test.loc[0, \"Predict_Single\"]=true_single_predicted_single\n",
    "forest_default_SG_confus_tbl_test.loc[0, \"Predict_Double\"]=true_single_predicted_double\n",
    "forest_default_SG_confus_tbl_test.loc[1, \"Predict_Single\"]=true_double_predicted_single\n",
    "forest_default_SG_confus_tbl_test.loc[1, \"Predict_Double\"]=true_double_predicted_double\n",
    "forest_default_SG_confus_tbl_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ec251dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1259.47\n",
      "54.82\n",
      "1204.65\n"
     ]
    }
   ],
   "source": [
    "FG1_yTest_df_act_1_pred_2=forest_grid_1_SG_y_test_df[forest_grid_1_SG_y_test_df.Vote==1].copy()\n",
    "FG1_yTest_df_act_2_pred_1=forest_grid_1_SG_y_test_df[forest_grid_1_SG_y_test_df.Vote==2].copy()\n",
    "\n",
    "FG1_yTest_df_act_1_pred_2=FG1_yTest_df_act_1_pred_2[FG1_yTest_df_act_1_pred_2.prediction==2].copy()\n",
    "FG1_yTest_df_act_2_pred_1=FG1_yTest_df_act_2_pred_1[FG1_yTest_df_act_2_pred_1.prediction==1].copy()\n",
    "\n",
    "FG1_yTest_df_act_2_pred_1 = pd.merge(FG1_yTest_df_act_2_pred_1, ground_truth_labels_extended, on=['ID'], how='left')\n",
    "FG1_yTest_df_act_1_pred_2 = pd.merge(FG1_yTest_df_act_1_pred_2, ground_truth_labels_extended, on=['ID'], how='left')\n",
    "\n",
    "print (FG1_yTest_df_act_2_pred_1.ExctAcr.sum().round(2))\n",
    "print (FG1_yTest_df_act_1_pred_2.ExctAcr.sum().round(2))\n",
    "print ((np.abs(FG1_yTest_df_act_1_pred_2.ExctAcr.sum() - FG1_yTest_df_act_2_pred_1.ExctAcr.sum())).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bfee62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38bc0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
