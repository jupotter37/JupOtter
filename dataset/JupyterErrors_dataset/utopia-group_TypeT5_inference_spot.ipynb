{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import *\n",
    "\n",
    "from typet5.utils import proj_root, get_data_dir\n",
    "\n",
    "os.chdir(proj_root())\n",
    "\n",
    "datadir = get_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiayi/Projects/SPOT/.venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading datasets:  tk_dataset-all_labels-drop_comments\n"
     ]
    }
   ],
   "source": [
    "# experiment configurations\n",
    "\n",
    "import torch\n",
    "\n",
    "from typet5.data import (\n",
    "    TokenizedSrcSet,\n",
    "    get_dataset_name,\n",
    "    load_tokenized_srcsets,\n",
    "    TypeCheckSettings,\n",
    ")\n",
    "from copy import copy\n",
    "from typet5.train import TrainingConfig, TypeCheckArgs\n",
    "from typet5.type_check import MypyChecker\n",
    "\n",
    "config = TrainingConfig(quicktest=False, all_labels=True)\n",
    "train_R1: bool = True\n",
    "gpu_id = 1\n",
    "TypeCheckSettings.temp_path = f\"GPU-{gpu_id}\"\n",
    "\n",
    "project_name = \"test-SPOT\" if config.quicktest else \"SPOT\"\n",
    "\n",
    "max_tokens_per_file = config.ctx_size\n",
    "\n",
    "datasets_name = get_dataset_name(\n",
    "    drop_comments=config.drop_comments,\n",
    "    all_labels=config.all_labels,\n",
    ")\n",
    "\n",
    "tc_args = TypeCheckArgs(check_in_isolation=config.check_in_isolation)\n",
    "\n",
    "r0_model_name = \"R0-model--\" + config._replace(quicktest=False).as_name()\n",
    "\n",
    "tk_dataset = load_tokenized_srcsets(\n",
    "    datadir,\n",
    "    datasets_name,\n",
    "    data_reduction=config.data_reduction,\n",
    "    quicktest=config.quicktest,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecodingArgs(ctx_args=CtxArgs(ctx_size=4096, left_margin=2048, right_margin=1024), sampling_max_tokens=32768, max_workers=20)\n"
     ]
    }
   ],
   "source": [
    "# load trained model\n",
    "from typet5.utils import pickle_load, pickle_dump\n",
    "from typet5.model import ModelWrapper\n",
    "\n",
    "\n",
    "r0_wrapper = ModelWrapper.from_pretrained(\n",
    "    datadir / f\"checkpoints/lit-saved/{r0_model_name}\"\n",
    ")\n",
    "# if train_R1:\n",
    "#     r0_extra = pickle_load(datadir / f\"checkpoints/lit-saved/{r0_model_name}/extra.pkl\")\n",
    "#     r1_tk_dataset: dict[str, TokenizedSrcSet] = r0_extra[\"R1-tk_dataset\"]\n",
    "device = torch.device(f\"cuda:{gpu_id}\" if torch.cuda.is_available() else \"cpu\")\n",
    "r0_wrapper.to(device)\n",
    "print(r0_wrapper.args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critics loaded.\n"
     ]
    }
   ],
   "source": [
    "# load the critics\n",
    "\n",
    "from typet5.critic import CriticModel, get_critic_name\n",
    "\n",
    "critics = dict[bool, CriticModel]()\n",
    "for new_data in [True, False]:\n",
    "    critic_name = get_critic_name(\n",
    "        no_feedback=False, new_data=new_data, config=config._replace(quicktest=False)\n",
    "    )\n",
    "    critic = CriticModel.load(datadir / f\"checkpoints/lit-saved/{critic_name}\")\n",
    "    critic.to(device)\n",
    "    critics[new_data] = critic\n",
    "print(\"Critics loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the inference\n",
    "\n",
    "from typet5.model import DatasetPredResult\n",
    "from typet5.utils import pretty_print_dict, run_long_task, PickleCache\n",
    "from typet5.model import CtxArgs, DecodingArgs, ModelSPOT\n",
    "\n",
    "testset = tk_dataset[\"test\"]\n",
    "# if not config.quicktest:\n",
    "#     testset = testset[1:-1:10]\n",
    "\n",
    "# used for inference\n",
    "n_samples = 16\n",
    "dec_ctx_args = config.dec_ctx_args()\n",
    "dec_ctx_args.max_labels = 1  # one type per chunk\n",
    "greedy_args = DecodingArgs(\n",
    "    sampling_max_tokens=8 * max_tokens_per_file,\n",
    "    ctx_args=dec_ctx_args,\n",
    "    max_workers=28,\n",
    "    do_sample=False,\n",
    ")\n",
    "\n",
    "sample_args = DecodingArgs(\n",
    "    sampling_max_tokens=8 * max_tokens_per_file,\n",
    "    ctx_args=dec_ctx_args,\n",
    "    max_workers=28,\n",
    "    do_sample=True,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "bs_args = DecodingArgs(\n",
    "    sampling_max_tokens=max_tokens_per_file,\n",
    "    ctx_args=dec_ctx_args,\n",
    "    max_workers=28,\n",
    "    do_sample=False,\n",
    "    num_beams=n_samples,\n",
    ")\n",
    "\n",
    "bs_incr_args = DecodingArgs(\n",
    "    ctx_args=dec_ctx_args,\n",
    "    sampling_max_tokens=max_tokens_per_file,\n",
    "    max_workers=28,\n",
    "    tokens_per_type=10,\n",
    "    do_sample=False,\n",
    "    num_beams=n_samples,\n",
    ")\n",
    "\n",
    "\n",
    "eval_cache = PickleCache(proj_root() / \"caches\" / \"inference_spot\" / r0_model_name)\n",
    "# eval_cache.clear()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting task: Computing results\n",
      "Pushover: (Finished: 'Computing results'.) Time taken: 4.0s\n"
     ]
    }
   ],
   "source": [
    "# compute results\n",
    "from typet5.decode import (\n",
    "    sample_candidates,\n",
    "    select_candidates_by_type_errors,\n",
    "    select_candidates_using_oracle,\n",
    "    select_candidates_using_critic,\n",
    "    select_first_candidates,\n",
    "    incr_inference_with_feedback,\n",
    "    SelectByOracle,\n",
    "    SelectByCounting,\n",
    "    SelectByCritic,\n",
    ")\n",
    "\n",
    "def score_transform(x: float):\n",
    "    if x <= 0.2:\n",
    "        return -1.0\n",
    "    if x >= 0.8:\n",
    "        return 1.0\n",
    "    return 0.0\n",
    "\n",
    "results = dict[str, DatasetPredResult]()\n",
    "incr_results = dict[str, Any]()\n",
    "\n",
    "with run_long_task(\"Computing results\"):\n",
    "    # r0_wrapper.args = bs_args\n",
    "    # results[\"BS\"] = evaluate_model(r0_wrapper, None, testset, eval_cache=eval_cache, tc_args=tc_args)[0][1]\n",
    "\n",
    "    r0_wrapper.args = bs_incr_args\n",
    "\n",
    "    incr_results[\"IncrCount\"] = eval_cache.cached(\n",
    "        \"Result-IncrCount\",\n",
    "        lambda: incr_inference_with_feedback(\n",
    "            r0_wrapper,\n",
    "            testset,\n",
    "            beam_width=8,\n",
    "            selector=SelectByCounting(),\n",
    "            log_to=proj_root() / \"caches/IncrCount-Examples\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # incr_results[\"IncrCritic\"] = eval_cache.cached(\n",
    "    #     \"Result-IncrCritic\",\n",
    "    #     lambda: incr_inference_with_feedback(\n",
    "    #         r0_wrapper,\n",
    "    #         testset,\n",
    "    #         beam_width=8,\n",
    "    #         selector=SelectByCritic(critics[False], score_transform),\n",
    "    #         log_to=proj_root() / \"caches/IncrCritic-Examples\",\n",
    "    #     ),\n",
    "    # )\n",
    "\n",
    "    # incr_results[\"IncrCritic-new\"] = eval_cache.cached(\n",
    "    #     \"Result-IncrCritic-new\",\n",
    "    #     lambda: incr_inference_with_feedback(\n",
    "    #         r0_wrapper,\n",
    "    #         testset,\n",
    "    #         beam_width=8,\n",
    "    #         selector=SelectByCritic(critics[True], score_transform),\n",
    "    #         log_to=proj_root() / \"caches/IncrCritic-new-Examples\",\n",
    "    #     ),\n",
    "    # )\n",
    "\n",
    "    incr_results[\"IncrOracle\"] = eval_cache.cached(\n",
    "        \"Result-IncrOracle\",\n",
    "        lambda: incr_inference_with_feedback(\n",
    "            r0_wrapper,\n",
    "            testset,\n",
    "            beam_width=8,\n",
    "            selector=SelectByOracle(),\n",
    "            log_to=proj_root() / \"caches/IncrOracle-Examples\",\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    # r0_wrapper.args = bs_args\n",
    "    # test_chunks, pred_candidates = eval_cache.cached(\n",
    "    #     \"sample_candidates\",\n",
    "    #     lambda: sample_candidates(r0_wrapper, testset, n_samples=n_samples),\n",
    "    # )\n",
    "\n",
    "    # results[\"BS\"] = select_first_candidates(test_chunks, pred_candidates)\n",
    "\n",
    "    # results[\"Counting\"] = eval_cache.cached(\n",
    "    #     \"Result-Counting\",\n",
    "    #     lambda: select_candidates_by_type_errors(testset, test_chunks, pred_candidates),\n",
    "    # )\n",
    "\n",
    "    # critic = critics[False]\n",
    "    # r_name = \"Critic\"\n",
    "    # results[r_name] = eval_cache.cached(\n",
    "    #     f\"Result-{r_name}\",\n",
    "    #     lambda: select_candidates_using_critic(\n",
    "    #         critic,\n",
    "    #         False,\n",
    "    #         testset,\n",
    "    #         test_chunks,\n",
    "    #         pred_candidates,\n",
    "    #         dec_args=greedy_args,\n",
    "    #         # score_transform=score_transform,\n",
    "    #     ),\n",
    "    # )\n",
    "\n",
    "    # results[\"Oracle\"] = eval_cache.cached(\n",
    "    #     \"Result-Oracle\",\n",
    "    #     lambda: select_candidates_using_oracle(test_chunks, pred_candidates),\n",
    "    # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <title>IPyWidget export</title>\n",
       "</head>\n",
       "<body>\n",
       "\n",
       "\n",
       "<!-- Load require.js. Delete this if your page already loads require.js -->\n",
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js\" integrity=\"sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=\" crossorigin=\"anonymous\"></script>\n",
       "<script src=\"https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js\" crossorigin=\"anonymous\"></script>\n",
       "\n",
       "<script type=\"application/vnd.jupyter.widget-state+json\">\n",
       "{\n",
       "  \"version_major\": 2,\n",
       "  \"version_minor\": 0,\n",
       "  \"state\": {\n",
       "    \"7ddafe34e79142cf926af68dd6fbdf2f\": {\n",
       "      \"model_name\": \"LayoutModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/base\",\n",
       "      \"model_module_version\": \"1.2.0\",\n",
       "      \"state\": {}\n",
       "    },\n",
       "    \"36b308d08814482ab650044251a671d3\": {\n",
       "      \"model_name\": \"DescriptionStyleModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/controls\",\n",
       "      \"model_module_version\": \"1.5.0\",\n",
       "      \"state\": {}\n",
       "    },\n",
       "    \"ac4e07f9f1c2411aaca98aaa434683eb\": {\n",
       "      \"model_name\": \"HTMLModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/controls\",\n",
       "      \"model_module_version\": \"1.5.0\",\n",
       "      \"state\": {\n",
       "        \"_dom_classes\": [],\n",
       "        \"layout\": \"IPY_MODEL_7ddafe34e79142cf926af68dd6fbdf2f\",\n",
       "        \"style\": \"IPY_MODEL_36b308d08814482ab650044251a671d3\",\n",
       "        \"value\": \"<div style='white-space: pre-wrap; line-height: 1.2; font-family: monospace, monospace;'>partial_acc (ImNone): 78.69% (count=16.9k)\\nfull_acc (ImNone): 75.90% (count=16.9k)\\npartial_acc: 76.99% (count=16.9k)\\nast_acc: 70.02% (count=21.3k)\\nfull_acc: 72.79% (count=16.9k)\\npartial_acc_by_cat: ...\\npartial_acc_by_pos: ...\\navg_label_size: 1.259\\navg_pred_size: 1.229\\n</div>\"\n",
       "      }\n",
       "    },\n",
       "    \"b675858991d74523bebfa611a4eb3366\": {\n",
       "      \"model_name\": \"LayoutModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/base\",\n",
       "      \"model_module_version\": \"1.2.0\",\n",
       "      \"state\": {}\n",
       "    },\n",
       "    \"a524fbc3523c4c23b820568bc83c7650\": {\n",
       "      \"model_name\": \"DescriptionStyleModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/controls\",\n",
       "      \"model_module_version\": \"1.5.0\",\n",
       "      \"state\": {}\n",
       "    },\n",
       "    \"a41ca4d7583c4443be445f13f1a1dd7e\": {\n",
       "      \"model_name\": \"HTMLModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/controls\",\n",
       "      \"model_module_version\": \"1.5.0\",\n",
       "      \"state\": {\n",
       "        \"_dom_classes\": [],\n",
       "        \"layout\": \"IPY_MODEL_b675858991d74523bebfa611a4eb3366\",\n",
       "        \"style\": \"IPY_MODEL_a524fbc3523c4c23b820568bc83c7650\",\n",
       "        \"value\": \"<div style='white-space: pre-wrap; line-height: 1.2; font-family: monospace, monospace;'>partial_acc (ImNone): 78.69% (count=16.9k)\\nfull_acc (ImNone): 75.90% (count=16.9k)\\npartial_acc: 76.99% (count=16.9k)\\nast_acc: 70.02% (count=21.3k)\\nfull_acc: 72.79% (count=16.9k)\\npartial_acc_by_cat:\\n   FuncArg: 75.72% (count=8.0k)\\n   FuncReturn: 83.44% (count=5.7k)\\n   ClassAtribute: 65.73% (count=2.7k)\\n   GlobalVar: 84.62% (count=104)\\n   LocalVar: 81.92% (count=531)\\npartial_acc_by_pos:\\n   range(0, 1): 84.35% (count=933)\\n   range(1, 2): 83.56% (count=870)\\n   range(2, 4): 83.60% (count=1.5k)\\n   range(4, 8): 81.63% (count=2.4k)\\n   range(8, 16): 80.77% (count=3.1k)\\n   range(16, 32): 77.93% (count=3.2k)\\n   range(32, 64): 72.67% (count=2.3k)\\n   range(64, 128): 63.42% (count=1.1k)\\n   range(128, 256): 58.10% (count=735)\\n   range(256, 512): 62.65% (count=672)\\n   range(512, 1024): 81.13% (count=53)\\navg_label_size: 1.259\\navg_pred_size: 1.229\\n</div>\"\n",
       "      }\n",
       "    },\n",
       "    \"682347291601436c8b22c0aec29b23e9\": {\n",
       "      \"model_name\": \"LayoutModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/base\",\n",
       "      \"model_module_version\": \"1.2.0\",\n",
       "      \"state\": {}\n",
       "    },\n",
       "    \"72f1589c3b014211b858d212ee5f1717\": {\n",
       "      \"model_name\": \"TabModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/controls\",\n",
       "      \"model_module_version\": \"1.5.0\",\n",
       "      \"state\": {\n",
       "        \"_dom_classes\": [],\n",
       "        \"_titles\": {\n",
       "          \"0\": \"Compressed\",\n",
       "          \"1\": \"Expanded\"\n",
       "        },\n",
       "        \"children\": [\n",
       "          \"IPY_MODEL_ac4e07f9f1c2411aaca98aaa434683eb\",\n",
       "          \"IPY_MODEL_a41ca4d7583c4443be445f13f1a1dd7e\"\n",
       "        ],\n",
       "        \"layout\": \"IPY_MODEL_682347291601436c8b22c0aec29b23e9\"\n",
       "      }\n",
       "    },\n",
       "    \"0b98d1be5f7b4c138bb84b736862da4f\": {\n",
       "      \"model_name\": \"LayoutModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/base\",\n",
       "      \"model_module_version\": \"1.2.0\",\n",
       "      \"state\": {}\n",
       "    },\n",
       "    \"02544c8b2058473a8794d34102008690\": {\n",
       "      \"model_name\": \"DescriptionStyleModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/controls\",\n",
       "      \"model_module_version\": \"1.5.0\",\n",
       "      \"state\": {}\n",
       "    },\n",
       "    \"8280a0e3ec3f4339960bd036fc118ea9\": {\n",
       "      \"model_name\": \"HTMLModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/controls\",\n",
       "      \"model_module_version\": \"1.5.0\",\n",
       "      \"state\": {\n",
       "        \"_dom_classes\": [],\n",
       "        \"layout\": \"IPY_MODEL_0b98d1be5f7b4c138bb84b736862da4f\",\n",
       "        \"style\": \"IPY_MODEL_02544c8b2058473a8794d34102008690\",\n",
       "        \"value\": \"<div style='white-space: pre-wrap; line-height: 1.2; font-family: monospace, monospace;'>partial_acc (ImNone): 87.31% (count=16.9k) [+8.62%]\\nfull_acc (ImNone): 86.09% (count=16.9k) [+10.19%]\\npartial_acc: 87.32% (count=16.9k) [+10.32%]\\nast_acc: 84.24% (count=21.3k) [+14.22%]\\nfull_acc: 85.19% (count=16.9k) [+12.40%]\\npartial_acc_by_cat: ...\\npartial_acc_by_pos: ...\\navg_label_size: 1.259 [0]\\navg_pred_size: 1.259 [0.03027]\\n</div>\"\n",
       "      }\n",
       "    },\n",
       "    \"a130eb35de0f47f5a5bb6e057674089d\": {\n",
       "      \"model_name\": \"LayoutModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/base\",\n",
       "      \"model_module_version\": \"1.2.0\",\n",
       "      \"state\": {}\n",
       "    },\n",
       "    \"e7d4b4f2332b46ea84affa21c3896aea\": {\n",
       "      \"model_name\": \"DescriptionStyleModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/controls\",\n",
       "      \"model_module_version\": \"1.5.0\",\n",
       "      \"state\": {}\n",
       "    },\n",
       "    \"b94ae836b1ec4e6db87a773bdd81a60a\": {\n",
       "      \"model_name\": \"HTMLModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/controls\",\n",
       "      \"model_module_version\": \"1.5.0\",\n",
       "      \"state\": {\n",
       "        \"_dom_classes\": [],\n",
       "        \"layout\": \"IPY_MODEL_a130eb35de0f47f5a5bb6e057674089d\",\n",
       "        \"style\": \"IPY_MODEL_e7d4b4f2332b46ea84affa21c3896aea\",\n",
       "        \"value\": \"<div style='white-space: pre-wrap; line-height: 1.2; font-family: monospace, monospace;'>partial_acc (ImNone): 87.31% (count=16.9k) [+8.62%]\\nfull_acc (ImNone): 86.09% (count=16.9k) [+10.19%]\\npartial_acc: 87.32% (count=16.9k) [+10.32%]\\nast_acc: 84.24% (count=21.3k) [+14.22%]\\nfull_acc: 85.19% (count=16.9k) [+12.40%]\\npartial_acc_by_cat:\\n   FuncArg: 86.54% (count=8.0k) [+10.82%]\\n   FuncReturn: 90.67% (count=5.7k) [+7.22%]\\n   ClassAtribute: 81.74% (count=2.7k) [+16.01%]\\n   GlobalVar: 88.46% (count=104) [+3.85%]\\n   LocalVar: 90.77% (count=531) [+8.85%]\\npartial_acc_by_pos:\\n   range(0, 1): 91.00% (count=933) [+6.65%]\\n   range(1, 2): 92.30% (count=870) [+8.74%]\\n   range(2, 4): 92.66% (count=1.5k) [+9.06%]\\n   range(4, 8): 90.47% (count=2.4k) [+8.85%]\\n   range(8, 16): 90.37% (count=3.1k) [+9.60%]\\n   range(16, 32): 87.16% (count=3.2k) [+9.23%]\\n   range(32, 64): 85.22% (count=2.3k) [+12.55%]\\n   range(64, 128): 78.74% (count=1.1k) [+15.32%]\\n   range(128, 256): 72.24% (count=735) [+14.15%]\\n   range(256, 512): 76.04% (count=672) [+13.39%]\\n   range(512, 1024): 100.00% (count=53) [+18.87%]\\navg_label_size: 1.259 [0]\\navg_pred_size: 1.259 [0.03027]\\n</div>\"\n",
       "      }\n",
       "    },\n",
       "    \"b86e5daf11e24a5485b6050602253880\": {\n",
       "      \"model_name\": \"LayoutModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/base\",\n",
       "      \"model_module_version\": \"1.2.0\",\n",
       "      \"state\": {}\n",
       "    },\n",
       "    \"65f6a0d77cf3414a8507834a5c38aa8b\": {\n",
       "      \"model_name\": \"TabModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/controls\",\n",
       "      \"model_module_version\": \"1.5.0\",\n",
       "      \"state\": {\n",
       "        \"_dom_classes\": [],\n",
       "        \"_titles\": {\n",
       "          \"0\": \"Compressed\",\n",
       "          \"1\": \"Expanded\"\n",
       "        },\n",
       "        \"children\": [\n",
       "          \"IPY_MODEL_8280a0e3ec3f4339960bd036fc118ea9\",\n",
       "          \"IPY_MODEL_b94ae836b1ec4e6db87a773bdd81a60a\"\n",
       "        ],\n",
       "        \"layout\": \"IPY_MODEL_b86e5daf11e24a5485b6050602253880\"\n",
       "      }\n",
       "    },\n",
       "    \"cbeed5cf6b974f0198315c8636cb205f\": {\n",
       "      \"model_name\": \"LayoutModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/base\",\n",
       "      \"model_module_version\": \"1.2.0\",\n",
       "      \"state\": {}\n",
       "    },\n",
       "    \"ed1347d041ea498b918cf76cbb5c93d2\": {\n",
       "      \"model_name\": \"TabModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/controls\",\n",
       "      \"model_module_version\": \"1.5.0\",\n",
       "      \"state\": {\n",
       "        \"_dom_classes\": [],\n",
       "        \"_titles\": {\n",
       "          \"0\": \"IncrCount\",\n",
       "          \"1\": \"IncrOracle\"\n",
       "        },\n",
       "        \"children\": [\n",
       "          \"IPY_MODEL_72f1589c3b014211b858d212ee5f1717\",\n",
       "          \"IPY_MODEL_65f6a0d77cf3414a8507834a5c38aa8b\"\n",
       "        ],\n",
       "        \"layout\": \"IPY_MODEL_cbeed5cf6b974f0198315c8636cb205f\",\n",
       "        \"selected_index\": 1\n",
       "      }\n",
       "    },\n",
       "    \"f9026dd2fe7445e78fa128aee8bc7079\": {\n",
       "      \"model_name\": \"LayoutModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/base\",\n",
       "      \"model_module_version\": \"1.2.0\",\n",
       "      \"state\": {\n",
       "        \"overflow\": \"scroll\"\n",
       "      }\n",
       "    },\n",
       "    \"5f0ac34f897a46b5bc085b929d3ef392\": {\n",
       "      \"model_name\": \"VBoxModel\",\n",
       "      \"model_module\": \"@jupyter-widgets/controls\",\n",
       "      \"model_module_version\": \"1.5.0\",\n",
       "      \"state\": {\n",
       "        \"_dom_classes\": [],\n",
       "        \"children\": [\n",
       "          \"IPY_MODEL_ed1347d041ea498b918cf76cbb5c93d2\"\n",
       "        ],\n",
       "        \"layout\": \"IPY_MODEL_f9026dd2fe7445e78fa128aee8bc7079\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "</script>\n",
       "<script type=\"application/vnd.jupyter.widget-view+json\">\n",
       "{\"version_major\": 2, \"version_minor\": 0, \"model_id\": \"5f0ac34f897a46b5bc085b929d3ef392\"}\n",
       "</script>\n",
       "\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typet5.visualization import display_persist, visualize_dicts\n",
    "from typet5.data import src_preds_to_accuracies\n",
    "from typet5.visualization import display_persist, dict_widget\n",
    "\n",
    "\n",
    "accs_list = [x.accuracies for x in results.values()]\n",
    "titles = list(results.keys())\n",
    "\n",
    "for n, r in incr_results.items():\n",
    "    accs = src_preds_to_accuracies(r[1], r[0])\n",
    "    accs_list.append(accs)\n",
    "    titles.append(n)\n",
    "\n",
    "display_persist(visualize_dicts(accs_list, titles))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'BS + critic-False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/jiayi/Projects/SPOT/scripts/inference_typet5.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Butopia3/home/jiayi/Projects/SPOT/scripts/inference_typet5.ipynb#ch0000007vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mspot\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m pd, display\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Butopia3/home/jiayi/Projects/SPOT/scripts/inference_typet5.ipynb#ch0000007vscode-remote?line=2'>3</a>\u001b[0m grouped_res \u001b[39m=\u001b[39m results[\u001b[39m\"\u001b[39;49m\u001b[39mBS + critic-False\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39mgroup_by_repo()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Butopia3/home/jiayi/Projects/SPOT/scripts/inference_typet5.ipynb#ch0000007vscode-remote?line=3'>4</a>\u001b[0m grouped_full_acc \u001b[39m=\u001b[39m {k: v\u001b[39m.\u001b[39maccuracies[\u001b[39m\"\u001b[39m\u001b[39mfull_acc\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m grouped_res\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Butopia3/home/jiayi/Projects/SPOT/scripts/inference_typet5.ipynb#ch0000007vscode-remote?line=4'>5</a>\u001b[0m repos \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(grouped_full_acc\u001b[39m.\u001b[39mkeys())\n",
      "\u001b[0;31mKeyError\u001b[0m: 'BS + critic-False'"
     ]
    }
   ],
   "source": [
    "from typet5.utils import pd, display\n",
    "\n",
    "grouped_res = results[\"BS + critic-False\"].group_by_repo()\n",
    "grouped_full_acc = {k: v.accuracies[\"full_acc\"] for k, v in grouped_res.items()}\n",
    "repos = list(grouped_full_acc.keys())\n",
    "repos.sort(key=lambda x: grouped_full_acc[x].n_total, reverse=True)\n",
    "\n",
    "grouped_acc_bs = {\n",
    "    k: v.accuracies[\"full_acc\"] for k, v in results[\"BS\"].group_by_repo().items()\n",
    "}\n",
    "grouped_oracle_bs = {\n",
    "    k: v.accuracies[\"full_acc\"]\n",
    "    for k, v in results[\"BS + oracle\"].group_by_repo().items()\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(\n",
    "    {\n",
    "        \"Repo\": [r.name for r in repos],\n",
    "        \"BS\": [str(grouped_acc_bs[r]) for r in repos],\n",
    "        \"Critic\": [str(grouped_full_acc[r]) for r in repos],\n",
    "        \"Oracle\": [str(grouped_oracle_bs[r]) for r in repos],\n",
    "    }\n",
    ")\n",
    "display(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1615c7e1f80d4b67ad0c4640fef0ae48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=0, continuous_update=False, max=178), VBox(children=(VBox(children=(Box(childre…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typet5.utils import not_none\n",
    "from typet5.visualization import visualize_preds_on_code\n",
    "\n",
    "critic_eval = results[critic_result_name(False)]\n",
    "preds_extra = {\n",
    "    \"critic_preds\": [\n",
    "        x.candidate_label_scores[x.best_candidate] for x in critic_eval.extra_info\n",
    "    ]\n",
    "}\n",
    "visualize_preds_on_code(critic_eval.chunks, critic_eval.predictions, preds_extra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typet5.decode import collect_type_errors_from_predictions\n",
    "from typet5.model import DatasetPredResult\n",
    "from typet5.type_check import PythonType, MypyFeedback\n",
    "from typet5.data import TokenizedSrcSet\n",
    "\n",
    "\n",
    "def collect_base_errors(dataset: TokenizedSrcSet):\n",
    "    \"Collect the type errors triggered by replacing all labels with `Any`.\"\n",
    "    chunks = dataset.to_chunks(\n",
    "        r0_wrapper.args.ctx_args, tqdm_args={\"disable\": True}\n",
    "    )\n",
    "    dummy_preds = [\n",
    "        [PythonType((\"Any\",)) for _ in info.types] for info in chunks.chunks_info\n",
    "    ]\n",
    "    pred_r = DatasetPredResult(chunks, dummy_preds)\n",
    "    return collect_type_errors_from_predictions(dataset, pred_r, max_workers=30)\n",
    "\n",
    "\n",
    "def collect_gold_errors(dataset: TokenizedSrcSet):\n",
    "    \"Collect the type errors triggered by ground-truth labels.\"\n",
    "    chunks = dataset.to_chunks(\n",
    "        r0_wrapper.args.ctx_args, tqdm_args={\"disable\": True}\n",
    "    )\n",
    "    label_preds = [info.types for info in chunks.chunks_info]\n",
    "    pred_r = DatasetPredResult(chunks, label_preds)\n",
    "    return collect_type_errors_from_predictions(dataset, pred_r, max_workers=30)\n",
    "\n",
    "\n",
    "num_labels = sum(len(s.types) for s in testset.all_srcs)\n",
    "print(\"Total number of labels: \", num_labels)\n",
    "type_errors = dict[str, list[tuple[Path, MypyFeedback]]]()\n",
    "type_errors[\"default\"] = collect_base_errors(testset)\n",
    "type_errors[\"gold\"] = collect_gold_errors(testset)\n",
    "for k, v in results.items():\n",
    "    type_errors[k] = collect_type_errors_from_predictions(testset, v, max_workers=30)\n",
    "\n",
    "from typet5.visualization import dict_widget, display_persist\n",
    "\n",
    "display_persist(dict_widget({k: len(v) for k, v in type_errors.items()}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typet5.visualization import seq_flatten, visualize_counts\n",
    "from typet5.utils import Counter\n",
    "from typet5.type_check import count_type_frequency\n",
    "\n",
    "\n",
    "def show_type_distr(recursive: bool, top_k: int):\n",
    "    counts = dict[str, Counter]()\n",
    "    for name in [\"greedy\", \"BS + feedback\"]:\n",
    "        types = seq_flatten(results[name].predictions)\n",
    "        counts[name] = count_type_frequency(types, recursive=recursive)\n",
    "\n",
    "    display(visualize_counts(counts, x_name=\"Predicted Type\", top_k=top_k))\n",
    "\n",
    "\n",
    "show_type_distr(recursive=True, top_k=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typet5.visualization import visualize_counts, visualize_sequence_tabs, display\n",
    "from typet5.utils import Counter\n",
    "\n",
    "default_counts = Counter(e.error_code for _, e in type_errors[\"default\"])\n",
    "\n",
    "error_counts = dict[str, Counter]()\n",
    "for name in [\"gold\"]:  # [\"greedy\", \"BS + feedback\"]:\n",
    "    c = Counter(e.error_code for _, e in type_errors[name])\n",
    "    for e, v in default_counts.items():\n",
    "        c[e] -= v\n",
    "    error_counts[name] = c\n",
    "display(visualize_counts(error_counts, \"Error\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typet5.visualization import visualize_conf_matrix\n",
    "\n",
    "visualize_conf_matrix(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6ffc72953da4dd16b2e00785be9c4013ef131f465a8658f3921b6634d4eeec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
