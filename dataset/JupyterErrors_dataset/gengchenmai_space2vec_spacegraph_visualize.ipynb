{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython will make a temporary file named: /tmp/ipython_edit_4ccsgL/ipython_edit_2WDWKa.py\n"
     ]
    }
   ],
   "source": [
    "%edit\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named sklearn.manifold",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1ae7323025a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanifold\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTSNE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgglomerativeClustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named sklearn.manifold"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import AgglomerativeClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Developed by Gengchen Mai\n",
    "\n",
    "gengchen.mai@gmail.com\n",
    "05/08/2019\n",
    "'''\n",
    "\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from spacegraph_codebase.utils import *\n",
    "from spacegraph_codebase.Place2Vec.cur_data_utils import load_pointset\n",
    "from spacegraph_codebase.data_utils import load_ng\n",
    "from spacegraph_codebase.model import NeighGraphEncoderDecoder\n",
    "from spacegraph_codebase.train_helper import run_train, run_eval, run_joint_train\n",
    "\n",
    "from torch import optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['--cuda'], dest='cuda', nargs=0, const=True, default=False, type=None, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = ArgumentParser()\n",
    "# dir\n",
    "parser.add_argument(\"--data_dir\", type=str, default=\"./Place2Vec/\")\n",
    "parser.add_argument(\"--model_dir\", type=str, default=\"./\")\n",
    "parser.add_argument(\"--log_dir\", type=str, default=\"./\")\n",
    "parser.add_argument(\"--num_context_sample\", type=int, default=10,\n",
    "    help='The number of context points we can sample, maximum is 10')\n",
    "\n",
    "# model\n",
    "parser.add_argument(\"--embed_dim\", type=int, default=64,\n",
    "    help='Point feature embedding dim')\n",
    "parser.add_argument(\"--dropout\", type=float, default=0.5,\n",
    "    help='The dropout rate used in all fully connected layer')\n",
    "\n",
    "# encoder\n",
    "parser.add_argument(\"--enc_agg\", type=str, default=\"mean\",\n",
    "    help='the type of aggragation function for feature encoder')\n",
    "\n",
    "# model type\n",
    "parser.add_argument(\"--model_type\", type=str, default=\"relative\",\n",
    "    help='''the type pf model we use, \n",
    "    relative: only relatve position; \n",
    "    global: only global position; \n",
    "    join: relative and global position\n",
    "    together: use global position of center point in context prediction''')\n",
    "\n",
    "# space encoder\n",
    "parser.add_argument(\"--spa_enc\", type=str, default=\"gridcell\",\n",
    "    help='the type of spatial relation encoder, gridcell/naive')\n",
    "parser.add_argument(\"--spa_embed_dim\", type=int, default=64,\n",
    "    help='Point Spatial relation embedding dim')\n",
    "parser.add_argument(\"--freq\", type=int, default=16,\n",
    "    help='The number of frequency used in the space encoder')\n",
    "parser.add_argument(\"--max_radius\", type=float, default=10e4,\n",
    "    help='The maximum spatial context radius in the space encoder')\n",
    "parser.add_argument(\"--spa_f_act\", type=str, default='sigmoid',\n",
    "    help='The final activation function used by spatial relation encoder')\n",
    "parser.add_argument(\"--freq_init\", type=str, default='geometric',\n",
    "    help='The frequency list initialization method')\n",
    "\n",
    "# global space/position encoder\n",
    "parser.add_argument(\"--g_spa_enc\", type=str, default=\"gridcell\",\n",
    "    help='the type of spatial relation encoder, gridcell/naive')\n",
    "parser.add_argument(\"--g_spa_embed_dim\", type=int, default=64,\n",
    "    help='Point Spatial relation embedding dim')\n",
    "parser.add_argument(\"--g_freq\", type=int, default=16,\n",
    "    help='The number of frequency used in the space encoder')\n",
    "parser.add_argument(\"--g_max_radius\", type=float, default=10e4,\n",
    "    help='The maximum spatial context radius in the space encoder')\n",
    "parser.add_argument(\"--g_spa_f_act\", type=str, default='sigmoid',\n",
    "    help='The final activation function used by spatial relation encoder')\n",
    "parser.add_argument(\"--g_freq_init\", type=str, default='geometric',\n",
    "    help='The frequency list initialization method')\n",
    "\n",
    "\n",
    "parser.add_argument(\"--use_dec\", type=str, default='T',\n",
    "    help='whether to use another decoder following the initial decoder')\n",
    "\n",
    "\n",
    "# initial decoder, without query embedding\n",
    "parser.add_argument(\"--init_decoder_atten_type\", type=str, default='concat',\n",
    "    help='''the type of the intersection operator attention in initial decoder\n",
    "    concat: the relative model\n",
    "    g_pos_concat: the together model''')\n",
    "parser.add_argument(\"--init_decoder_atten_act\", type=str, default='leakyrelu',\n",
    "    help='the activation function of the intersection operator attention, see GAT paper Equ 3 in initial decoder')\n",
    "parser.add_argument(\"--init_decoder_atten_f_act\", type=str, default='sigmoid',\n",
    "    help='the final activation function of the intersection operator attention, see GAT paper Equ 6 in initial decoder')\n",
    "parser.add_argument(\"--init_decoder_atten_num\", type=int, default=1,\n",
    "    help='the number of the intersection operator attention in initial decoder')\n",
    "parser.add_argument(\"--init_decoder_use_layn\", type=str, default='T',\n",
    "    help='whether to use layer normalzation in initial decoder')\n",
    "parser.add_argument(\"--init_decoder_use_postmat\", type=str, default='T',\n",
    "    help='whether to use post matrix in initial decoder')\n",
    "\n",
    "\n",
    "# decoder \n",
    "parser.add_argument(\"--decoder_atten_type\", type=str, default='concat',\n",
    "    help='''the type of the intersection operator attention\n",
    "    concat: the relative model\n",
    "    g_pos_concat: the together model''')\n",
    "parser.add_argument(\"--decoder_atten_act\", type=str, default='leakyrelu',\n",
    "    help='the activation function of the intersection operator attention, see GAT paper Equ 3')\n",
    "parser.add_argument(\"--decoder_atten_f_act\", type=str, default='sigmoid',\n",
    "    help='the final activation function of the intersection operator attention, see GAT paper Equ 6')\n",
    "parser.add_argument(\"--decoder_atten_num\", type=int, default=0,\n",
    "    help='the number of the intersection operator attention')\n",
    "parser.add_argument(\"--decoder_use_layn\", type=str, default='T',\n",
    "    help='whether to use layer normalzation')\n",
    "parser.add_argument(\"--decoder_use_postmat\", type=str, default='T',\n",
    "    help='whether to use post matrix')\n",
    "\n",
    "# encoder decoder\n",
    "parser.add_argument(\"--join_dec_type\", type=str, default='max',\n",
    "    help='the type of join_dec, min/max/mean/cat')\n",
    "parser.add_argument(\"--act\", type=str, default='sigmoid',\n",
    "    help='the activation function for the encoder decoder')\n",
    "\n",
    "# train\n",
    "parser.add_argument(\"--opt\", type=str, default=\"adam\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.01,\n",
    "    help='learning rate')\n",
    "parser.add_argument(\"--max_iter\", type=int, default=50000000,\n",
    "    help='the maximum iterator for model converge')\n",
    "parser.add_argument(\"--max_burn_in\", type=int, default=5000,\n",
    "    help='the maximum iterator for relative/global model converge')\n",
    "parser.add_argument(\"--batch_size\", type=int, default=512)\n",
    "parser.add_argument(\"--tol\", type=float, default=0.000001)\n",
    "\n",
    "\n",
    "# eval\n",
    "parser.add_argument(\"--log_every\", type=int, default=50)\n",
    "parser.add_argument(\"--val_every\", type=int, default=5000)\n",
    "\n",
    "\n",
    "# load old model\n",
    "parser.add_argument(\"--load_model\", action='store_true')\n",
    "\n",
    "# cuda\n",
    "parser.add_argument(\"--cuda\", action='store_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_list = \"\"\"--data_dir ../data_collection/Place2Vec/ \n",
    "  --model_dir ./model_dir/Place2Vec/ \n",
    "  --log_dir ./model_dir/Place2Vec/ \n",
    "  --num_context_sample 10 \n",
    "  --embed_dim 64 \n",
    "  --dropout 0.5 \n",
    "  --enc_agg mean \n",
    "  --model_type global \n",
    "  --spa_enc theory \n",
    "  --spa_embed_dim 64 \n",
    "  --freq 16 \n",
    "  --max_radius 10000 \n",
    "  --spa_f_act sigmoid \n",
    "  --freq_init geometric \n",
    "  --g_spa_enc theory \n",
    "  --g_spa_embed_dim 64 \n",
    "  --g_freq 16 \n",
    "  --g_max_radius 10e5 \n",
    "  --g_spa_f_act sigmoid \n",
    "  --g_freq_init geometric \n",
    "  --use_dec T \n",
    "  --init_decoder_atten_type concat \n",
    "  --init_decoder_atten_act leakyrelu \n",
    "  --init_decoder_atten_f_act sigmoid \n",
    "  --init_decoder_atten_num 1 \n",
    "  --init_decoder_use_layn T \n",
    "  --init_decoder_use_postmat T \n",
    "  --decoder_atten_type concat \n",
    "  --decoder_atten_act leakyrelu \n",
    "  --decoder_atten_f_act sigmoid \n",
    "  --decoder_atten_num 1 \n",
    "  --decoder_use_layn T \n",
    "  --decoder_use_postmat T \n",
    "  --join_dec_type max \n",
    "  --act sigmoid \n",
    "  --opt adam \n",
    "  --lr 0.001 \n",
    "  --max_iter 2000 \n",
    "  --batch_size 512 \n",
    "  --log_every 50 \n",
    "  --val_every 50 \"\"\"\n",
    "\n",
    "args = parser.parse_args(args_list.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_args_combine(args):\n",
    "    args_combine = \"/{data:s}-{num_context_sample:d}-{embed_dim:d}-{dropout:.1f}-{enc_agg:s}-{model_type:s}-{spa_enc:s}-{spa_embed_dim:d}-{freq:d}-{max_radius:.1f}-{spa_f_act:s}-{freq_init:s}-{g_spa_enc:s}-{g_spa_embed_dim:d}-{g_freq:d}-{g_max_radius:.1f}-{g_spa_f_act:s}-{g_freq_init:s}-{use_dec:s}-{init_decoder_atten_type:s}-{init_decoder_atten_act:s}-{init_decoder_atten_f_act:s}-{init_decoder_atten_num:d}-{init_decoder_use_layn:s}-{init_decoder_use_postmat:s}-{decoder_atten_type:s}-{decoder_atten_act:s}-{decoder_atten_f_act:s}-{decoder_atten_num:d}-{decoder_use_layn:s}-{decoder_use_postmat:s}-{join_dec_type:s}-{act:s}-{opt:s}-{lr:.6f}-{batch_size:d}\".format(\n",
    "        data=args.data_dir.strip().split(\"/\")[-2],\n",
    "        num_context_sample=args.num_context_sample,\n",
    "        embed_dim=args.embed_dim,\n",
    "        dropout=args.dropout,\n",
    "        enc_agg=args.enc_agg,\n",
    "\n",
    "        model_type=args.model_type,\n",
    "\n",
    "        spa_enc=args.spa_enc,\n",
    "        spa_embed_dim=args.spa_embed_dim,\n",
    "        freq=args.freq,\n",
    "        max_radius=args.max_radius,\n",
    "        spa_f_act=args.spa_f_act,\n",
    "        freq_init=args.freq_init,\n",
    "\n",
    "        g_spa_enc=args.g_spa_enc,\n",
    "        g_spa_embed_dim=args.g_spa_embed_dim,\n",
    "        g_freq=args.g_freq,\n",
    "        g_max_radius=args.g_max_radius,\n",
    "        g_spa_f_act=args.g_spa_f_act,\n",
    "        g_freq_init=args.g_freq_init,\n",
    "\n",
    "        use_dec=args.use_dec,\n",
    "\n",
    "        init_decoder_atten_type=args.init_decoder_atten_type,\n",
    "        init_decoder_atten_act=args.init_decoder_atten_act,\n",
    "        init_decoder_atten_f_act=args.init_decoder_atten_f_act,\n",
    "        init_decoder_atten_num=args.init_decoder_atten_num,\n",
    "        init_decoder_use_layn=args.init_decoder_use_layn,\n",
    "        init_decoder_use_postmat=args.init_decoder_use_postmat,\n",
    "\n",
    "        decoder_atten_type=args.decoder_atten_type,\n",
    "        decoder_atten_act=args.decoder_atten_act,\n",
    "        decoder_atten_f_act=args.decoder_atten_f_act,\n",
    "        decoder_atten_num=args.decoder_atten_num,\n",
    "        decoder_use_layn=args.decoder_use_layn,\n",
    "        decoder_use_postmat=args.decoder_use_postmat,\n",
    "\n",
    "        join_dec_type = args.join_dec_type,\n",
    "        act = args.act,\n",
    "        opt=args.opt,\n",
    "        lr=args.lr,\n",
    "        batch_size=args.batch_size\n",
    "        )\n",
    "    return args_combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NeighGraph data..\n",
      "Loading training NeighGraph data..\n",
      "Loading validation NeighGraph  data..\n",
      "Loading testing NeighGraph data..\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading NeighGraph data..\")\n",
    "\n",
    "print(\"Loading training NeighGraph data..\")\n",
    "train_ng_list = load_ng(args.data_dir + \"/neighborgraphs_training.pkl\")\n",
    "print(\"Loading validation NeighGraph  data..\")\n",
    "val_ng_list = load_ng(args.data_dir + \"/neighborgraphs_validation.pkl\")\n",
    "print(\"Loading testing NeighGraph data..\")\n",
    "test_ng_list = load_ng(args.data_dir + \"/neighborgraphs_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_enc_dec(args):\n",
    "    args_combine = make_args_combine(args)\n",
    "    \n",
    "    log_file = args.log_dir + args_combine + \".log\"\n",
    "    model_file = args.model_dir + args_combine + \".pth\"\n",
    "\n",
    "    logger = setup_logging(log_file, filemode='a')\n",
    "    \n",
    "    print(\"Loading PointSet data..\")\n",
    "\n",
    "    pointset, feature_embedding = load_pointset(data_dir=args.data_dir, \n",
    "                                                    embed_dim=args.embed_dim,\n",
    "                                                    do_feature_sampling = False)\n",
    "    if args.cuda:\n",
    "        pointset.feature_embed_lookup = cudify(feature_embedding)\n",
    "        \n",
    "    # make feature encoder\n",
    "    enc = get_encoder(pointset.feature_embed_lookup, feature_embedding, pointset, args.enc_agg)\n",
    "\n",
    "    if args.model_type == \"relative\" or args.model_type == \"join\" or args.model_type == \"together\":\n",
    "        # make relative space encoder\n",
    "        spa_enc = get_spa_encoder(spa_enc_type=args.spa_enc, \n",
    "                            spa_embed_dim=args.spa_embed_dim, \n",
    "                            coord_dim = 2, \n",
    "                            frequency_num = args.freq, \n",
    "                            max_radius = args.max_radius,\n",
    "                            dropout = args.dropout,\n",
    "                            freq_init = args.freq_init)\n",
    "    else:\n",
    "        spa_enc = None\n",
    "\n",
    "    if args.model_type == \"global\" or args.model_type == \"join\" or args.model_type == \"together\":\n",
    "        # make global space encoder\n",
    "        g_spa_enc = get_spa_encoder(spa_enc_type=args.g_spa_enc, \n",
    "                            spa_embed_dim=args.g_spa_embed_dim, \n",
    "                            coord_dim = 2, \n",
    "                            frequency_num = args.g_freq, \n",
    "                            max_radius = args.g_max_radius,\n",
    "                            dropout = args.dropout,\n",
    "                            freq_init = args.g_freq_init)\n",
    "    else:\n",
    "        g_spa_enc = None\n",
    "\n",
    "    # make decoder\n",
    "    if args.model_type == \"relative\" or args.model_type == \"join\" or args.model_type == \"together\":\n",
    "\n",
    "        # make query embedding initial decoder\n",
    "        init_dec = get_context_decoder(dec_type=args.init_decoder_atten_type, \n",
    "                            query_dim=args.embed_dim, \n",
    "                            key_dim=args.embed_dim, \n",
    "                            spa_embed_dim=args.spa_embed_dim, \n",
    "                            g_spa_embed_dim=args.g_spa_embed_dim,\n",
    "                            have_query_embed = False, \n",
    "                            num_attn = args.init_decoder_atten_num, \n",
    "                            activation = args.init_decoder_atten_act, \n",
    "                            f_activation = args.init_decoder_atten_f_act, \n",
    "                            layn = args.init_decoder_use_layn, \n",
    "                            use_postmat = args.init_decoder_use_postmat,\n",
    "                            dropout = args.dropout)\n",
    "\n",
    "        if args.use_dec == \"T\":\n",
    "            # make decoder\n",
    "            dec = get_context_decoder(dec_type=args.decoder_atten_type, \n",
    "                                query_dim=args.embed_dim, \n",
    "                                key_dim=args.embed_dim, \n",
    "                                spa_embed_dim=args.spa_embed_dim, \n",
    "                                g_spa_embed_dim=args.g_spa_embed_dim,\n",
    "                                have_query_embed = True, \n",
    "                                num_attn = args.decoder_atten_num, \n",
    "                                activation = args.decoder_atten_act, \n",
    "                                f_activation = args.decoder_atten_f_act, \n",
    "                                layn = args.decoder_use_layn, \n",
    "                                use_postmat = args.decoder_use_postmat,\n",
    "                                dropout = args.dropout)\n",
    "        else:\n",
    "            dec = None\n",
    "\n",
    "        if args.model_type == \"join\":\n",
    "            joint_dec = JointRelativeGlobalDecoder(feature_embed_dim = args.embed_dim, \n",
    "                            f_act = args.act, \n",
    "                            dropout = args.dropout,\n",
    "                            join_type = args.join_dec_type)\n",
    "        else:\n",
    "            joint_dec = None\n",
    "\n",
    "    else:\n",
    "        init_dec = None\n",
    "        dec = None\n",
    "        joint_dec = None\n",
    "\n",
    "    if args.model_type == \"global\" or args.model_type == \"join\":\n",
    "        # make global space decoder\n",
    "        g_spa_dec = DirectPositionEmbeddingDecoder(g_spa_embed_dim=args.g_spa_embed_dim, \n",
    "                            feature_embed_dim=args.embed_dim, \n",
    "                            f_act = args.act, \n",
    "                            dropout = args.dropout)\n",
    "    else:\n",
    "        g_spa_dec = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # if args.model_type == \"global\" or args.model_type == \"relative\":\n",
    "    # make encoder encoder\n",
    "    enc_dec = get_enc_dec(model_type=args.model_type, \n",
    "                        pointset=pointset, \n",
    "                        enc = enc, \n",
    "                        spa_enc = spa_enc, \n",
    "                        g_spa_enc = g_spa_enc, \n",
    "                        g_spa_dec = g_spa_dec, \n",
    "                        init_dec=init_dec, \n",
    "                        dec=dec, \n",
    "                        joint_dec=joint_dec, \n",
    "                        activation = args.act, \n",
    "                        num_context_sample = args.num_context_sample, \n",
    "                        num_neg_resample = 10)\n",
    "\n",
    "    if args.cuda:\n",
    "        enc_dec.cuda()\n",
    "\n",
    "    if args.opt == \"sgd\":\n",
    "        optimizer = optim.SGD(filter(lambda p : p.requires_grad, enc_dec.parameters()), lr=args.lr, momentum=0)\n",
    "    elif args.opt == \"adam\":\n",
    "        optimizer = optim.Adam(filter(lambda p : p.requires_grad, enc_dec.parameters()), lr=args.lr)\n",
    "\n",
    "#     logger.info(\"Save file at {}\".format(args_combine + \".pth\"))\n",
    "    print(\"Load model from {}\".format(args_combine + \".pth\"))\n",
    "    enc_dec.load_state_dict(torch.load(model_file))\n",
    "    return enc_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = []\n",
    "interval = 1000\n",
    "# latitude\n",
    "for y in range(1600000, 1650000+interval, interval):\n",
    "    coord = []\n",
    "#     longitude\n",
    "    for x in range(-1713000, -1670000+interval, interval):\n",
    "        coord.append([x,y])\n",
    "    coords.append(coord)\n",
    "\n",
    "extent = (-1713000, -1670000, 1600000, 1650000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_coords = []\n",
    "for y in range(0, 10010, 10):\n",
    "    coord = []\n",
    "    for x in range(0, 10010, 10):\n",
    "        coord.append([x,y])\n",
    "    rel_coords.append(coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PointSet data..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-20 07:16:13,939 - INFO - Save file at /Place2Vec-10-64-0.5-mean-global-theory-64-16-10000.0-sigmoid-geometric-theory-64-16-1000000.0-sigmoid-geometric-T-concat-leakyrelu-sigmoid-1-T-T-concat-leakyrelu-sigmoid-1-T-T-max-sigmoid-adam-0.001000-512.pth\n"
     ]
    }
   ],
   "source": [
    "g_enc_dec = make_enc_dec(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27924\n",
      "27924\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "types = []\n",
    "cnt = 0\n",
    "select_cnt = 0\n",
    "filter_out_ids = [1575, 2342, 6883, 10577, 16755, 17172, 21961, 24320]\n",
    "for pt_id in g_enc_dec.pointset.pt_dict:\n",
    "    cnt += 1\n",
    "#     if pt_id not in filter_out_ids:\n",
    "    point = g_enc_dec.pointset.pt_dict[pt_id]\n",
    "    pt_coord = point.coord\n",
    "    if pt_coord[0] > -1713000 and pt_coord[0] < -1670000 and \\\n",
    "    pt_coord[1] > 1600000 and pt_coord[1] < 1650000:\n",
    "        select_cnt += 1\n",
    "        x.append(pt_coord[0])\n",
    "        y.append(pt_coord[1])\n",
    "        types.append(point.features[0])\n",
    "print(cnt)\n",
    "print(select_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'to_rgba'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-73f9308d6399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#%matplotlib inline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python2.7/dist-packages/matplotlib/pyplot.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \"\"\"\n\u001b[1;32m    243\u001b[0m     \u001b[0;32mglobal\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_show\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gengchen/.local/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(close, block)\u001b[0m\n\u001b[1;32m     37\u001b[0m             display(\n\u001b[1;32m     38\u001b[0m                 \u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_fetch_figure_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigure_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             )\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gengchen/.local/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_fetch_figure_metadata\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;34m\"\"\"Get some metadata to help with displaying a figure.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;31m# determine if a background is needed for legibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_facecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# the background is transparent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         ticksLight = _is_light([label.get_color()\n",
      "\u001b[0;32m/home/gengchen/.local/lib/python2.7/site-packages/ipykernel/pylab/backend_inline.pyc\u001b[0m in \u001b[0;36m_is_transparent\u001b[0;34m(color)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_transparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;34m\"\"\"Determine transparency from alpha.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mrgba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_rgba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrgba\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'to_rgba'"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "plt.scatter(x, y, s=1, c=types,alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
