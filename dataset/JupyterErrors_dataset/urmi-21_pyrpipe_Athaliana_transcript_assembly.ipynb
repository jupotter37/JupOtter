{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of *A. thaliana* RNA-Seq data with pyrpipe \n",
    "In this case study, we will utilize *A. thaliana* public RNA-Seq data and perform transcript assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyrpipe import sra,mapping,assembly,qc,tools\n",
    "from pyrpipe import pyrpipe_utils as pu\n",
    "from pyrpipe import pyrpipe_engine as pe\n",
    "#First get the srr accessions of the runs. For this one can use the python package pysradb or R package sradb\n",
    "#i will consider following randomly selected accessions\n",
    "#athalRuns=['SRR976159','SRR978411','SRR978410','SRR971778','SRR1058116','SRR1058118','SRR1058121','SRR1058110','SRR1058120','SRR1058117','SRR1104134','SRR1104133','SRR1104135','SRR1104136','SRR1105825']\n",
    "athalRunsSmol=['SRR976159','SRR978411','SRR971778']\n",
    "#set your working directory if you don't want to use the current working directory\n",
    "workingDir=\"athal_out\"\n",
    "#create working directory\n",
    "if not pu.check_paths_exist(workingDir):\n",
    "    pu.mkdir(workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download genome and gtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File athal_out/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa exists\n",
      "File athal_out/Arabidopsis_thaliana.TAIR10.45.gtf exists\n"
     ]
    }
   ],
   "source": [
    "GENOME=workingDir+\"/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa\"\n",
    "GTF=workingDir+\"/Arabidopsis_thaliana.TAIR10.45.gtf\"\n",
    "\n",
    "if not pu.check_files_exist(GENOME):\n",
    "    print(\"Downloading genome fasta file\")\n",
    "    wget=\"wget ftp://ftp.ensemblgenomes.org/pub/release-46/plants/fasta/arabidopsis_thaliana/dna/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa.gz -q -O \"+GENOME+\".gz\"\n",
    "    pe.execute_command(wget.split(),verbose=False,logs=False)\n",
    "    pe.execute_command(['gunzip',GENOME+\".gz\"],verbose=True,logs=False)\n",
    "else:\n",
    "    print('File {} exists'.format(GENOME))\n",
    "    \n",
    "if not pu.check_files_exist(GTF):\n",
    "    print(\"Downloading GTF file\")\n",
    "    wget=\"wget ftp://ftp.ensemblgenomes.org/pub/release-46/plants/gtf/arabidopsis_thaliana/Arabidopsis_thaliana.TAIR10.46.gtf.gz -O \"+GTF+\".gz\"\n",
    "    pe.execute_command(wget.split(),verbose=False,logs=False)\n",
    "    pe.execute_command(['gunzip',GTF+\".gz\"],verbose=True,logs=False)\n",
    "else:\n",
    "    print('File {} exists'.format(GTF))\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and create SRA objects\n",
    "\n",
    "Using the pyrpipe sra module, we will create `SRA` objects for each of the run accession. pyrpipe's SRA class will automatically fetch the fastq files upon creation an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mStart:21-01-01 14:34:18\u001b[0m\n",
      "\u001b[96m$ prefetch -O athal_out/SRR976159 SRR976159\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 14:34:26\u001b[0m\n",
      "\u001b[92mTime taken:0:00:08\u001b[0m\n",
      "\u001b[93mStart:21-01-01 14:34:26\u001b[0m\n",
      "\u001b[96m$ fasterq-dump -O athal_out/SRR976159 -o SRR976159.fastq -e 6 -f athal_out/SRR976159/SRR976159.sra\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 14:34:51\u001b[0m\n",
      "\u001b[92mTime taken:0:00:25\u001b[0m\n",
      "\u001b[93mStart:21-01-01 14:34:51\u001b[0m\n",
      "\u001b[96m$ prefetch -O athal_out/SRR978411 SRR978411\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 14:35:00\u001b[0m\n",
      "\u001b[92mTime taken:0:00:09\u001b[0m\n",
      "\u001b[93mStart:21-01-01 14:35:00\u001b[0m\n",
      "\u001b[96m$ fasterq-dump -O athal_out/SRR978411 -o SRR978411.fastq -e 6 -f athal_out/SRR978411/SRR978411.sra\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 14:35:22\u001b[0m\n",
      "\u001b[92mTime taken:0:00:22\u001b[0m\n",
      "\u001b[93mStart:21-01-01 14:35:22\u001b[0m\n",
      "\u001b[96m$ prefetch -O athal_out/SRR971778 SRR971778\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 14:35:34\u001b[0m\n",
      "\u001b[92mTime taken:0:00:11\u001b[0m\n",
      "\u001b[93mStart:21-01-01 14:35:34\u001b[0m\n",
      "\u001b[96m$ fasterq-dump -O athal_out/SRR971778 -o SRR971778.fastq -e 6 -f athal_out/SRR971778/SRR971778.sra\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following runs downloaded:\n",
      "SRR976159\n",
      "SRR978411\n",
      "SRR971778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mEnd:21-01-01 14:36:20\u001b[0m\n",
      "\u001b[92mTime taken:0:00:46\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##download all data in athalRuns\n",
    "sraObjects=[]\n",
    "\n",
    "for x in athalRunsSmol:\n",
    "    try:\n",
    "        thisSraOb=sra.SRA(x,workingDir)\n",
    "        sraObjects.append(thisSraOb)\n",
    "    except:\n",
    "        print('Failed to download {}'.format(x))\n",
    "    \n",
    "\n",
    "print(\"Following runs downloaded:\")\n",
    "for ob in sraObjects:\n",
    "    print(ob.srr_accession)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving current session\n",
    "\n",
    "This is a good place to demonstrate saving the pyrpipe session. \n",
    "**In a typical HPC setting, one might have access to special data-transfer nodes**. \n",
    "These nodes could be used for downloading data efficiently but does not allow expensive computations. \n",
    "On the other hand data may be downloaded on compute nodes **but that will burn most of the computing time/allocations for only downloading the data**. \n",
    "Thus it might be a good idea to download data separately and then start the processing.\n",
    "We can save the objects created with pyrpipe and restore our session later on a compute node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session saved to: athal_out/mySession_20210101142026.pyrpipe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save current session\n",
    "from pyrpipe import pyrpipe_session\n",
    "pyrpipe_session.save_session(filename=\"mySession\",add_timestamp=True,out_dir=workingDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restoring saved session\n",
    "We can restore the pyrpipe session using the saved session file (saved with .pyrpipe extension).\n",
    "\n",
    "**Note** After restoring session a new log file will generated to store the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sraObjects' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-56b40d88894f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#first clear current session used by notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reset'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msraObjects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sraObjects' is not defined"
     ]
    }
   ],
   "source": [
    "#first clear current session used by notebook\n",
    "%reset\n",
    "print(sraObjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session restored.\n",
      "[<pyrpipe.sra.SRA object at 0x7f7c8c9b1310>, <pyrpipe.sra.SRA object at 0x7f7c8c9c8410>, <pyrpipe.sra.SRA object at 0x7f7c8c9c8b10>]\n"
     ]
    }
   ],
   "source": [
    "#restore session\n",
    "from pyrpipe import pyrpipe_session\n",
    "#copy and paste the pyrpipe session file below\n",
    "st=pyrpipe_session.restore_session(\"athal_out/mySession_20210101142026.pyrpipe\")\n",
    "print(sraObjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing fastq quality control\n",
    "\n",
    "Each `SRA` object stores the path to the fastq files. We can directly use the `SRA` object's `trim()` function to perform trimming of fastq-files. To do this we need to specify a `RNASeqQC` object, from the `qc` module.\n",
    "At present, pyrpipe implements two classes `Trimgalore` and `BBmap` in the qc module.\n",
    "We can create an object of either `Trimgalore` or `BBmap` and pass it to the `trim()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mStart:21-01-01 14:37:00\u001b[0m\n",
      "\u001b[96m$ bbduk.sh ktrim=r k=23 mink=11 qtrim='rl' trimq=10 ref=adapters2.fa threads=4 in=athal_out/SRR976159/SRR976159_1.fastq in2=athal_out/SRR976159/SRR976159_2.fastq out=athal_out/SRR976159/SRR976159_1_bbduk.fastq out2=athal_out/SRR976159/SRR976159_2_bbduk.fastq -Xmx2g\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 14:37:51\u001b[0m\n",
      "\u001b[92mTime taken:0:00:51\u001b[0m\n",
      "\u001b[93mStart:21-01-01 14:37:51\u001b[0m\n",
      "\u001b[96m$ bbduk.sh ktrim=r k=23 mink=11 qtrim='rl' trimq=10 ref=adapters2.fa threads=4 in=athal_out/SRR978411/SRR978411_1.fastq in2=athal_out/SRR978411/SRR978411_2.fastq out=athal_out/SRR978411/SRR978411_1_bbduk.fastq out2=athal_out/SRR978411/SRR978411_2_bbduk.fastq -Xmx2g\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 14:38:38\u001b[0m\n",
      "\u001b[92mTime taken:0:00:47\u001b[0m\n",
      "\u001b[93mStart:21-01-01 14:38:38\u001b[0m\n",
      "\u001b[96m$ bbduk.sh ktrim=r k=23 mink=11 qtrim='rl' trimq=10 ref=adapters2.fa threads=4 in=athal_out/SRR971778/SRR971778_1.fastq in2=athal_out/SRR971778/SRR971778_2.fastq out=athal_out/SRR971778/SRR971778_1_bbduk.fastq out2=athal_out/SRR971778/SRR971778_2_bbduk.fastq -Xmx2g\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRR Accession: SRR976159, fastq files: athal_out/SRR976159/SRR976159_1_bbduk.fastq. athal_out/SRR976159/SRR976159_2_bbduk.fastq\n",
      "Both files exist!!\n",
      "SRR Accession: SRR978411, fastq files: athal_out/SRR978411/SRR978411_1_bbduk.fastq. athal_out/SRR978411/SRR978411_2_bbduk.fastq\n",
      "Both files exist!!\n",
      "SRR Accession: SRR971778, fastq files: athal_out/SRR971778/SRR971778_1_bbduk.fastq. athal_out/SRR971778/SRR971778_2_bbduk.fastq\n",
      "Both files exist!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mEnd:21-01-01 14:39:41\u001b[0m\n",
      "\u001b[92mTime taken:0:01:04\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#using bbduk\n",
    "pathToAdapters=\"adapters2.fa\"\n",
    "#arguments to pass to bbduk; note these can go in ./params/bbduk.yaml\n",
    "bbdOpts={\"ktrim\":\"r\",\"k\":\"23\",\"mink\":\"11\",\"qtrim\":\"'rl'\",\"trimq\":\"10\",\"ref\":pathToAdapters}\n",
    "#an object for running bbduk.sh with specified parameters\n",
    "bbdOb=qc.BBmap(threads=4,memory=2,**bbdOpts)\n",
    "\n",
    "#start QC\n",
    "for ob in sraObjects:\n",
    "    ob.trim(bbdOb,delete_original=False) #delete_original will delete the untrimmed fastq\n",
    "    \n",
    "#after finishing view the current fastq files in the sra objects\n",
    "\n",
    "for ob in sraObjects:\n",
    "    print(\"SRR Accession: {}, fastq files: {}. {}\".format(ob.srr_accession,ob.fastq_path,ob.fastq2_path))\n",
    "    \n",
    "    if ob.fastq_exists():\n",
    "          print(\"Both files exist!!\")\n",
    "    else:\n",
    "          print(\"Error\")\n",
    "          raise Exception(\"Fastq files not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning clean reads to the reference genome\n",
    "\n",
    "After finishing fastq quality control we will map reads to the reference genome. To do this, first we need to have an `Aligner` object. The pyrpipe `mapping` module defines three classes `Star`, `Hisat2` and `Bowtie2`. These classes provide an API to STAR, Hisat2 and Bowtie2 alignment tools. We can diretcly used the `SRA` object's `align()` function to generate the bam files. \n",
    "\n",
    "After aligning and generating bam files, the bam file path will be stored with the `SRA` object in the `bam_path` attribute.\n",
    "\n",
    "In this example we will use Hisat2 to align the reads. First we define a Hisat2 object and provide idex as 'athalIndex/athalInd'. This index doesn't exist. To create one index we also provide a genome file as argument. The following statement will create a Hisat2 object and generate an index using default parameters.\n",
    "\n",
    "**Note: It is recommended that users generate their index using appropriate parameters. Parameters to be used while building an index could be stored in hisat2_index.yaml or star_index.yaml files and pyrpipe will automatically load them if building a new index.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mStart:21-01-01 14:53:58\u001b[0m\n",
      "\u001b[96m$ hisat2-build -p 6 athal_out/Arabidopsis_thaliana.TAIR10.dna.toplevel.fa athal_out/athalIndex/athalInd\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 14:54:34\u001b[0m\n",
      "\u001b[92mTime taken:0:00:35\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#using hisat2\n",
    "hsOpts={\"--dta-cufflinks\":\"\",\"-p\":\"6\"}\n",
    "hs=mapping.Hisat2(index=workingDir+\"/athalIndex/athalInd\",genome=GENOME,threads=6,**hsOpts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the index is generated, it is stored with the Hisat2 object, as `index` attribute. We can now use the hisat object to run the alignment step.\n",
    "**Note: pyrpipe will automatically convert the SAM files output by Hisat2 step to sorted BAM files using Samtools.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SRR976159...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mStart:21-01-01 14:55:15\u001b[0m\n",
      "\u001b[96m$ hisat2 --dta-cufflinks -p 6 -x athal_out/athalIndex/athalInd -1 athal_out/SRR976159/SRR976159_1_bbduk.fastq -2 athal_out/SRR976159/SRR976159_2_bbduk.fastq -S athal_out/SRR976159/SRR976159_hisat2.sam\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 14:56:20\u001b[0m\n",
      "\u001b[92mTime taken:0:01:05\u001b[0m\n",
      "\u001b[93mStart:21-01-01 14:56:20\u001b[0m\n",
      "\u001b[96m$ samtools view -@ 6 -o athal_out/SRR976159/SRR976159_hisat2.bam -b athal_out/SRR976159/SRR976159_hisat2.sam\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 14:56:55\u001b[0m\n",
      "\u001b[92mTime taken:0:00:34\u001b[0m\n",
      "\u001b[93mStart:21-01-01 14:56:55\u001b[0m\n",
      "\u001b[96m$ samtools sort -@ 6 -o athal_out/SRR976159/SRR976159_hisat2_sorted.bam athal_out/SRR976159/SRR976159_hisat2.bam\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 14:57:17\u001b[0m\n",
      "\u001b[92mTime taken:0:00:22\u001b[0m\n",
      "\u001b[93mStart:21-01-01 14:57:17\u001b[0m\n",
      "\u001b[96m$ hisat2 --dta-cufflinks -p 6 -x athal_out/athalIndex/athalInd -1 athal_out/SRR978411/SRR978411_1_bbduk.fastq -2 athal_out/SRR978411/SRR978411_2_bbduk.fastq -S athal_out/SRR978411/SRR978411_hisat2.sam\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SRR978411...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mEnd:21-01-01 14:58:21\u001b[0m\n",
      "\u001b[92mTime taken:0:01:04\u001b[0m\n",
      "\u001b[93mStart:21-01-01 14:58:21\u001b[0m\n",
      "\u001b[96m$ samtools view -@ 6 -o athal_out/SRR978411/SRR978411_hisat2.bam -b athal_out/SRR978411/SRR978411_hisat2.sam\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 14:58:51\u001b[0m\n",
      "\u001b[92mTime taken:0:00:30\u001b[0m\n",
      "\u001b[93mStart:21-01-01 14:58:51\u001b[0m\n",
      "\u001b[96m$ samtools sort -@ 6 -o athal_out/SRR978411/SRR978411_hisat2_sorted.bam athal_out/SRR978411/SRR978411_hisat2.bam\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 14:59:09\u001b[0m\n",
      "\u001b[92mTime taken:0:00:18\u001b[0m\n",
      "\u001b[93mStart:21-01-01 14:59:10\u001b[0m\n",
      "\u001b[96m$ hisat2 --dta-cufflinks -p 6 -x athal_out/athalIndex/athalInd -1 athal_out/SRR971778/SRR971778_1_bbduk.fastq -2 athal_out/SRR971778/SRR971778_2_bbduk.fastq -S athal_out/SRR971778/SRR971778_hisat2.sam\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SRR971778...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mEnd:21-01-01 15:00:29\u001b[0m\n",
      "\u001b[92mTime taken:0:01:19\u001b[0m\n",
      "\u001b[93mStart:21-01-01 15:00:29\u001b[0m\n",
      "\u001b[96m$ samtools view -@ 6 -o athal_out/SRR971778/SRR971778_hisat2.bam -b athal_out/SRR971778/SRR971778_hisat2.sam\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 15:01:11\u001b[0m\n",
      "\u001b[92mTime taken:0:00:43\u001b[0m\n",
      "\u001b[93mStart:21-01-01 15:01:11\u001b[0m\n",
      "\u001b[96m$ samtools sort -@ 6 -o athal_out/SRR971778/SRR971778_hisat2_sorted.bam athal_out/SRR971778/SRR971778_hisat2.bam\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment done!! Bam files:athal_out/SRR976159/SRR976159_hisat2_sorted.bam,athal_out/SRR978411/SRR978411_hisat2_sorted.bam,athal_out/SRR971778/SRR971778_hisat2_sorted.bam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mEnd:21-01-01 15:01:37\u001b[0m\n",
      "\u001b[92mTime taken:0:00:25\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#start alignment\n",
    "bamList=[]\n",
    "for ob in sraObjects:\n",
    "    print(\"Processing {}...\".format(ob.srr_accession))\n",
    "    ob.align(hs)\n",
    "    bamList.append(ob.bam_path)\n",
    "    \n",
    "    ##Other way to perform alignment is to use hs.perform_alignment and pass SRA object to it\n",
    "    #thisBam=hs.perform_alignment(ob,**hsOpts) #note the parameter p supplied here will replace the parameter \"threads\" passed during object construction\n",
    "    #if thisSam:\n",
    "    #    bamList.append(thisBam)\n",
    "print(\"Alignment done!! Bam files:\"+ \",\".join(bamList))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using samtools\n",
    "```pyrpipe``` implemnts a basic high-level samtools API through which samtools functionality could be accessed. **Note: that users can also use the python library ```pysam``` to get advance SAM/BAM/VCF/BCF functionality.**\n",
    "\n",
    "The followin is an example how the pyrpipe tools module can be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing:athal_out/SRR976159/SRR976159_hisat2.sam\n",
      "\u001b[94m$ samtools view -o athal_out/SRR976159/SRR976159_hisat2.bam -@ 6 -b athal_out/SRR976159/SRR976159_hisat2.sam\u001b[0m\n",
      "\u001b[92mTime taken:0:00:37\u001b[0m\n",
      "\u001b[94m$ samtools sort -o athal_out/SRR976159/SRR976159_hisat2_sorted.bam -@ 6 athal_out/SRR976159/SRR976159_hisat2.bam\u001b[0m\n",
      "\u001b[92mTime taken:0:00:18\u001b[0m\n",
      "Processing:athal_out/SRR978411/SRR978411_hisat2.sam\n",
      "\u001b[94m$ samtools view -o athal_out/SRR978411/SRR978411_hisat2.bam -@ 6 -b athal_out/SRR978411/SRR978411_hisat2.sam\u001b[0m\n",
      "\u001b[92mTime taken:0:00:29\u001b[0m\n",
      "\u001b[94m$ samtools sort -o athal_out/SRR978411/SRR978411_hisat2_sorted.bam -@ 6 athal_out/SRR978411/SRR978411_hisat2.bam\u001b[0m\n",
      "\u001b[92mTime taken:0:00:17\u001b[0m\n",
      "Processing:athal_out/SRR971778/SRR971778_hisat2.sam\n",
      "\u001b[94m$ samtools view -o athal_out/SRR971778/SRR971778_hisat2.bam -@ 6 -b athal_out/SRR971778/SRR971778_hisat2.sam\u001b[0m\n",
      "\u001b[92mTime taken:0:00:37\u001b[0m\n",
      "\u001b[94m$ samtools sort -o athal_out/SRR971778/SRR971778_hisat2_sorted.bam -@ 6 athal_out/SRR971778/SRR971778_hisat2.bam\u001b[0m\n",
      "\u001b[92mTime taken:0:00:26\u001b[0m\n",
      "Sorted bam files:athal_out/SRR976159/SRR976159_hisat2_sorted.bam,athal_out/SRR978411/SRR978411_hisat2_sorted.bam,athal_out/SRR971778/SRR971778_hisat2_sorted.bam\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "samOb=tools.Samtools()\n",
    "#sam to sorted bam\n",
    "bamList=[]\n",
    "i=0\n",
    "for sam in samList:\n",
    "    print(\"Processing:\"+sam)\n",
    "    thisBam=samOb.sam_sorted_bam(sam,delete_sam=True,delete_bam=True,objectid=sraObjects[i].srr_accession) #add the object id to keep track of process and object. helpful in debugging and reports later\n",
    "    i+=1\n",
    "    if thisBam:\n",
    "        bamList.append(thisBam)\n",
    "print(\"Sorted bam files:\"+\",\".join(bamList))\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "###Some Examples using pysam###\n",
    "#for details see: https://pysam.readthedocs.io/en/latest/\n",
    "#import pysam\n",
    "#pysam.sort(\"-@\",\"8\",\"-o\",\"sortedBam.bam\",\"in.bam)\n",
    "#pysam.merge(\"-@\",\"8\",\"myMerge\",*bamList,\"-f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transcript assembly\n",
    "\n",
    "The `assembly` module in pyrpipe provides classes to perform transcript assembly using Stringtie or Cufflinks these classes extend the `Assembly` class. The `SRA` class implements `assemble()` fuction to easily perform the assembly. The `assemble()` method first check for a `self.bam_path` attribute and if it is present it calls the `perform_assembly` method on the `Assembler` object. After performing the assembly, the resultant GTF files is saved with the SRA object as `gtf` attribute.\n",
    "In this example, we will use stringtie to perform transcript assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SRR976159...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mStart:21-01-01 15:09:45\u001b[0m\n",
      "\u001b[96m$ stringtie -p 4 -G athal_out/Arabidopsis_thaliana.TAIR10.45.gtf -o athal_out/SRR976159/SRR976159_hisat2_sorted_stringtie.gtf athal_out/SRR976159/SRR976159_hisat2_sorted.bam\u001b[0m\n",
      "\u001b[93mEnd:21-01-01 15:10:21\u001b[0m\n",
      "\u001b[92mTime taken:0:00:36\u001b[0m\n",
      "\u001b[93mStart:21-01-01 15:10:21\u001b[0m\n",
      "\u001b[96m$ stringtie -p 4 -G athal_out/Arabidopsis_thaliana.TAIR10.45.gtf -o athal_out/SRR978411/SRR978411_hisat2_sorted_stringtie.gtf athal_out/SRR978411/SRR978411_hisat2_sorted.bam\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SRR978411...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mEnd:21-01-01 15:10:52\u001b[0m\n",
      "\u001b[92mTime taken:0:00:31\u001b[0m\n",
      "\u001b[93mStart:21-01-01 15:10:52\u001b[0m\n",
      "\u001b[96m$ stringtie -p 4 -G athal_out/Arabidopsis_thaliana.TAIR10.45.gtf -o athal_out/SRR971778/SRR971778_hisat2_sorted_stringtie.gtf athal_out/SRR971778/SRR971778_hisat2_sorted.bam\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SRR971778...\n",
      "Final GTFs:athal_out/SRR976159/SRR976159_hisat2_sorted_stringtie.gtf,athal_out/SRR978411/SRR978411_hisat2_sorted_stringtie.gtf,athal_out/SRR971778/SRR971778_hisat2_sorted_stringtie.gtf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[93mEnd:21-01-01 15:11:28\u001b[0m\n",
      "\u001b[92mTime taken:0:00:36\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "st=assembly.Stringtie(guide=GTF,threads=4)\n",
    "gtfList=[]\n",
    "i=0\n",
    "\n",
    "for ob in sraObjects:\n",
    "    print(\"Processing {}...\".format(ob.srr_accession))\n",
    "    ob.assemble(st)\n",
    "    gtfList.append(ob.gtf)\n",
    "\n",
    "\n",
    "#another way is to pass bam files to stringtie object\n",
    "#for bam in bamList:\n",
    "#    print(\"Processing:\"+bam)\n",
    "#    gtfList.append(st.perform_assembly(bam,reference_gtf=GTF,objectid=sraObjects[i].srr_accession))\n",
    "#    i+=1\n",
    "\n",
    "print(\"Final GTFs:\"+\",\".join(gtfList))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating analysis reports\n",
    "\n",
    "All the commands executed via pyrpipe are extensively logged. These logs can be easily parsed with the `pyrpipe_diagnostic` command.\n",
    "The pyrpipe_diagnostic utility lets user generate different types of reports and summaries. \n",
    "\n",
    "The Following commands can be run from shell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick summary of the log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyrpipe_diagnostic report --summary pyrpipe_logs/2020-03-16-14_33_21_pyrpipe.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate a pdf report**\n",
    "[Output](https://github.com/urmi-21/pyrpipe/blob/master/case_studies/Athaliana_transcript_assembly/2020-03-16-14_33_21_pyrpipe.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report written to 2020-03-16-14_33_21_pyrpipe.pdf\r\n"
     ]
    }
   ],
   "source": [
    "!pyrpipe_diagnostic report pyrpipe_logs/2020-03-16-14_33_21_pyrpipe.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Dump all commands to a shell file***\n",
    "[Output](https://github.com/urmi-21/pyrpipe/blob/master/case_studies/Athaliana_transcript_assembly/2020-03-16-14_33_21_pyrpipe.sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating bash script\r\n",
      "shell commands written to 2020-03-16-14_33_21_pyrpipe.sh\r\n"
     ]
    }
   ],
   "source": [
    "!pyrpipe_diagnostic shell pyrpipe_logs/2020-03-16-14_33_21_pyrpipe.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate multiqc report**\n",
    "[Output](https://github.com/urmi-21/pyrpipe/blob/master/case_studies/Athaliana_transcript_assembly/multiqc_report.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating html report with multiqc\n",
      "\u001b[1;30m[INFO   ]\u001b[0m         multiqc : This is MultiQC v1.8\n",
      "\u001b[1;30m[INFO   ]\u001b[0m         multiqc : Template    : default\n",
      "\u001b[1;30m[INFO   ]\u001b[0m         multiqc : Searching   : /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp\n",
      "\u001b[1;30m[INFO   ]\u001b[0m         bowtie2 : Found 3 reports\n",
      "\u001b[1;30m[INFO   ]\u001b[0m         multiqc : Compressing plot data\n",
      "\u001b[1;30m[INFO   ]\u001b[0m         multiqc : Report      : multiqc_report.html\n",
      "\u001b[1;30m[INFO   ]\u001b[0m         multiqc : Data        : multiqc_data\n",
      "\u001b[1;30m[INFO   ]\u001b[0m         multiqc : MultiQC complete\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR976159_fasterq-dump.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR978411_fasterq-dump.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR971778_fasterq-dump.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR976159_bbduk.sh.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR978411_bbduk.sh.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR971778_bbduk.sh.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR976159_hisat2.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR978411_hisat2.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR971778_hisat2.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR976159_samtools.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR976159_samtools_1.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR978411_samtools.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR978411_samtools_1.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR971778_samtools.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR971778_samtools_1.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR976159_stringtie.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR978411_stringtie.txt\u001b[0m\n",
      "\u001b[94mRemoving /home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/SRR971778_stringtie.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pyrpipe_diagnostic multiqc -r pyrpipe_logs/2020-03-16-14_33_21_pyrpipe.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate runtime benchmarks**\n",
    "[Output](https://github.com/urmi-21/pyrpipe/tree/master/case_studies/Athaliana_transcript_assembly/benchmark_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating benchmarks\n",
      "\u001b[94mparsing log...\u001b[0m\n",
      "\u001b[94mdone.\u001b[0m\n",
      "\u001b[92mBenchmark report saved to:/home/usingh/work/urmi/hoap/pyrpipe/case_studies/Athaliana_transcript_assembly/tmp/benchmark_reports\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pyrpipe_diagnostic benchmark pyrpipe_logs/2020-03-16-14_33_21_pyrpipe.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
