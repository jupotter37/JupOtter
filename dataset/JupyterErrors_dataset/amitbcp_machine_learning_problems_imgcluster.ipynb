{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imgcluster\n",
    "### Image clustering using the similarity algorithms: SIFT, SSIM, CW-SSIM, MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to implement the clustering of images by utilizing *Spectral Clustering* and *Affinity Propagation Clustering* together with a number of similarity algorithms, like: \n",
    "\n",
    " * SIFT: Scale-invariant Feature Transform\n",
    " * SSIM: Structural Similarity Index\n",
    " * CW-SSIM: Complex Wavelet Structural Similarity Index\n",
    " * MSE: Mean Squared Error\n",
    "\n",
    "The best clustering results are selected according to the calculated performance metrics for clustering:\n",
    "\n",
    " * Silhouette Coefficient\n",
    " * Completeness Score\n",
    " * Homogeneity Score\n",
    "\n",
    "The project is using *OpenCV 3.1*, *Scikit-Learn*, *Scikit-Image* and *PySSIM* for image manipulations, similarity measurements and clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All images have been downloaded from the free-of-charge online service [Pixabay](https://pixabay.com)\n",
    "\n",
    "Any kind of copyrights, ownership rights or distribution rights have been considered according to the information, which is available on Pixabay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This IP[y] Notebook performs a step-by-step execution of *'imgcluster_demo.py'* file with extra comments. The source code is available on [GitHub](https://github.com/llvll/imgcluster)\n",
    "\n",
    "Let's start by exploring the main functions in *'imgcluster.py'* and *'get_image_similarity'* specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'ssim.ssimlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-000b6e033653>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mssim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mssimlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpyssim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeasure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstructural_similarity\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mssim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpectralClustering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAffinityPropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'ssim.ssimlib'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import cv2\n",
    "import numpy as np\n",
    "import ssim.ssimlib as pyssim\n",
    "from skimage.measure import structural_similarity as ssim\n",
    "from sklearn.cluster import SpectralClustering, AffinityPropagation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Constant definitions\n",
    "SIM_IMAGE_SIZE = (640, 480)\n",
    "SIFT_RATIO = 0.7\n",
    "MSE_NUMERATOR = 1000.0\n",
    "IMAGES_PER_CLUSTER = 5\n",
    "\n",
    "\"\"\" Returns the normalized similarity value (from 0.0 to 1.0) for the provided pair of images.\n",
    "    The following algorithms are supported:\n",
    "    * SIFT: Scale-invariant Feature Transform\n",
    "    * SSIM: Structural Similarity Index\n",
    "    * CW-SSIM: Complex Wavelet Structural Similarity Index\n",
    "    * MSE: Mean Squared Error\n",
    "\"\"\"\n",
    "def get_image_similarity(img1, img2, algorithm='SIFT'):\n",
    "    # Converting to grayscale and resizing\n",
    "    i1 = cv2.resize(cv2.imread(img1, cv2.IMREAD_GRAYSCALE), SIM_IMAGE_SIZE)\n",
    "    i2 = cv2.resize(cv2.imread(img2, cv2.IMREAD_GRAYSCALE), SIM_IMAGE_SIZE)\n",
    "\n",
    "    similarity = 0.0\n",
    "\n",
    "    if algorithm == 'SIFT':\n",
    "        # Using OpenCV for feature detection and matching\n",
    "        sift = cv2.xfeatures2d.SIFT_create()\n",
    "        k1, d1 = sift.detectAndCompute(i1, None)\n",
    "        k2, d2 = sift.detectAndCompute(i2, None)\n",
    "\n",
    "        bf = cv2.BFMatcher()\n",
    "        matches = bf.knnMatch(d1, d2, k=2)\n",
    "\n",
    "        for m, n in matches:\n",
    "            if m.distance < SIFT_RATIO * n.distance:\n",
    "                similarity += 1.0\n",
    "\n",
    "        # Custom normalization for better variance in the similarity matrix\n",
    "        if similarity == len(matches):\n",
    "            similarity = 1.0\n",
    "        elif similarity > 1.0:\n",
    "            similarity = 1.0 - 1.0/similarity\n",
    "        elif similarity == 1.0:\n",
    "            similarity = 0.1\n",
    "        else:\n",
    "            similarity = 0.0\n",
    "    elif algorithm == 'CW-SSIM':\n",
    "        # FOR EXPERIMENTS ONLY!\n",
    "        # Very slow algorithm - up to 50x times slower than SIFT or SSIM.\n",
    "        # Optimization using CUDA or Cython code should be explored in the future.\n",
    "        similarity = pyssim.SSIM(img1).cw_ssim_value(img2)\n",
    "    elif algorithm == 'SSIM':\n",
    "        # Default SSIM implementation of Scikit-Image\n",
    "        similarity = ssim(i1, i2)\n",
    "    else:\n",
    "        # Using MSE algorithm with custom normalization\n",
    "        err = np.sum((i1.astype(\"float\") - i2.astype(\"float\")) ** 2)\n",
    "        err /= float(i1.shape[0] * i2.shape[1])\n",
    "\n",
    "        if err > 0.0:\n",
    "            similarity = MSE_NUMERATOR / err\n",
    "        else:\n",
    "            similarity = 1.0\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the conducted experiments SIFT and SSIM provide the best balance of accuracy and performance for similarity measurements. CW-SSIM is more accurate in theory than SSIM, but its current performance is the major bottleneck for practical usages. The same process for similarity matrix with 20 images using CW-SSIM might run up to several hours! There is a clear need to explore CUDA or Cython for accelerating its performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The similarity measurements are used for building the similarity matrix. Calculations are performed for the upper triangle only with the rest of cells to be filled by the transposed matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetches all images from the provided directory and calculates the similarity\n",
    "# value per image pair.\n",
    "def build_similarity_matrix(dir_name, algorithm='SIFT'):\n",
    "    images = os.listdir(dir_name)\n",
    "    num_images = len(images)\n",
    "    sm = np.zeros(shape=(num_images, num_images), dtype=np.float64)\n",
    "    np.fill_diagonal(sm, 1.0)\n",
    "\n",
    "    print(\"Building the similarity matrix using %s algorithm for %d images\" %\n",
    "          (algorithm, num_images))\n",
    "    start_total = datetime.datetime.now()\n",
    "\n",
    "    # Traversing the upper triangle only - transposed matrix will be used\n",
    "    # later for filling the empty cells.\n",
    "    k = 0\n",
    "    for i in range(sm.shape[0]):\n",
    "        for j in range(sm.shape[1]):\n",
    "            j = j + k\n",
    "            if i != j and j < sm.shape[1]:\n",
    "                sm[i][j] = get_image_similarity('%s/%s' % (dir_name, images[i]),\n",
    "                                                '%s/%s' % (dir_name, images[j]),\n",
    "                                                algorithm=algorithm)\n",
    "        k += 1\n",
    "\n",
    "    # Adding the transposed matrix and subtracting the diagonal to obtain\n",
    "    # the symmetric similarity matrix\n",
    "    sm = sm + sm.T - np.diag(sm.diagonal())\n",
    "\n",
    "    end_total = datetime.datetime.now()\n",
    "    print(\"Done - total calculation time: %d seconds\" % (end_total - start_total).total_seconds())\n",
    "    return sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a need to measure the performance of clustering itself. In *'imgcluster.py'* this is used for selecting the best clustering results between Spectral Clustering and Affinity Propagation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Returns a dictionary with the computed performance metrics of the provided cluster.\n",
    "    Several functions from sklearn.metrics are used to calculate the following:\n",
    "    * Silhouette Coefficient\n",
    "      Values near 1.0 indicate that the sample is far away from the neighboring clusters.\n",
    "      A value of 0.0 indicates that the sample is on or very close to the decision boundary\n",
    "      between two neighboring clusters and negative values indicate that those samples might\n",
    "      have been assigned to the wrong cluster.\n",
    "    * Completeness Score\n",
    "      A clustering result satisfies completeness if all the data points that are members of a\n",
    "      given class are elements of the same cluster. Score between 0.0 and 1.0. 1.0 stands for\n",
    "      perfectly complete labeling.\n",
    "    * Homogeneity Score\n",
    "      A clustering result satisfies homogeneity if all of its clusters contain only data points,\n",
    "      which are members of a single class. 1.0 stands for perfectly homogeneous labeling.\n",
    "\"\"\"\n",
    "def get_cluster_metrics(X, labels, labels_true=None):\n",
    "    metrics_dict = dict()\n",
    "    metrics_dict['Silhouette coefficient'] = metrics.silhouette_score(X,\n",
    "                                                                      labels,\n",
    "                                                                      metric='precomputed')\n",
    "    if labels_true:\n",
    "        metrics_dict['Completeness score'] = metrics.completeness_score(labels_true, labels)\n",
    "        metrics_dict['Homogeneity score'] = metrics.homogeneity_score(labels_true, labels)\n",
    "\n",
    "    return metrics_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main function to be invoked by applications is *'do_cluster'*. It accepts the path to directory with images for clustering. After executing Spectral Clustering and Affinity Propagation sequentially it compares the calculated peformance metrics and selects the best results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Executes two algorithms for similarity-based clustering:\n",
    "    * Spectral Clustering\n",
    "    * Affinity Propagation\n",
    "    ... and selects the best results according to the clustering performance metrics.\n",
    "\"\"\"\n",
    "def do_cluster(dir_name, algorithm='SIFT', print_metrics=True, labels_true=None):\n",
    "    matrix = build_similarity_matrix(dir_name, algorithm=algorithm)\n",
    "\n",
    "    sc = SpectralClustering(n_clusters=int(matrix.shape[0]/IMAGES_PER_CLUSTER),\n",
    "                            affinity='precomputed').fit(matrix)\n",
    "    sc_metrics = get_cluster_metrics(matrix, sc.labels_, labels_true)\n",
    "\n",
    "    if print_metrics:\n",
    "        print(\"\\nPerformance metrics for Spectral Clustering\")\n",
    "        print(\"Number of clusters: %d\" % len(set(sc.labels_)))\n",
    "        [print(\"%s: %.2f\" % (k, sc_metrics[k])) for k in list(sc_metrics.keys())]\n",
    "\n",
    "    af = AffinityPropagation(affinity='precomputed').fit(matrix)\n",
    "    af_metrics = get_cluster_metrics(matrix, af.labels_, labels_true)\n",
    "\n",
    "    if print_metrics:\n",
    "        print(\"\\nPerformance metrics for Affinity Propagation Clustering\")\n",
    "        print(\"Number of clusters: %d\" % len(set(af.labels_)))\n",
    "        [print(\"%s: %.2f\" % (k, af_metrics[k])) for k in list(af_metrics.keys())]\n",
    "\n",
    "    if (sc_metrics['Silhouette coefficient'] >= af_metrics['Silhouette coefficient']) and \\\n",
    "            (sc_metrics['Completeness score'] >= af_metrics['Completeness score'] or\n",
    "             sc_metrics['Homogeneity score'] >= af_metrics['Homogeneity score']):\n",
    "        print(\"\\nSelected Spectral Clustering for the labeling results\")\n",
    "        return sc.labels_\n",
    "    else:\n",
    "        print(\"\\nSelected Affinity Propagation for the labeling results\")\n",
    "        return af.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to run the demo itself ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*DIR_NAME* value and the code in *'imgcluster_demo.py'* are updated for execution in IP[y] Notebook. *%matplotlib inline* is added for the correct rendering of images. Let's also increase the output window of IP[y] Notebook to fit all images without scrolling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.auto_scroll_threshold = 9999;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "DIR_NAME = '../images'\n",
    "\n",
    "# Demo for clustering a set of 20 images using 'imgcluster' module.\n",
    "# To be executed in the standalone mode by default. IP[y] Notebook requires some minor adjustments.\n",
    "\n",
    "\"\"\" True (reference) labels for the provided images - defined manually according to the semantic\n",
    "    meaning of images. For example: bear, raccoon and fox should belong to the same cluster.\n",
    "    Please feel free to change the true labels according to your perception of these images  :-)\n",
    "\"\"\"\n",
    "TRUE_LABELS = [0, 1, 2, 1, 0, 1, 3, 3, 3, 3, 3, 1, 0, 2, 2, 1, 2, 0, 2, 2]\n",
    "\n",
    "c = do_cluster(DIR_NAME, algorithm='SIFT', print_metrics=True, labels_true=TRUE_LABELS)\n",
    "num_clusters = len(set(c))\n",
    "images = os.listdir(DIR_NAME)\n",
    "plt.axis('off')\n",
    "\n",
    "for n in range(num_clusters):\n",
    "    print(\"\\n --- Images from cluster #%d ---\" % n)\n",
    "\n",
    "    for i in np.argwhere(c == n):\n",
    "        if i != -1:\n",
    "            print(\"Image %s\" % images[i])\n",
    "            img = cv2.imread('%s/%s' % (DIR_NAME, images[i]))\n",
    "            plt.axis('off')\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
