{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Installing-and-verifying-PyTorch\" data-toc-modified-id=\"Installing-and-verifying-PyTorch-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Installing and verifying PyTorch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Install-PyTorch\" data-toc-modified-id=\"Install-PyTorch-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Install PyTorch</a></span></li><li><span><a href=\"#Import-PyTorch\" data-toc-modified-id=\"Import-PyTorch-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Import PyTorch</a></span></li><li><span><a href=\"#Verify-PyTorch-install\" data-toc-modified-id=\"Verify-PyTorch-install-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Verify PyTorch install</a></span></li></ul></li><li><span><a href=\"#Tensors\" data-toc-modified-id=\"Tensors-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Tensors</a></span><ul class=\"toc-item\"><li><span><a href=\"#Creating-a-Tensor\" data-toc-modified-id=\"Creating-a-Tensor-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Creating a Tensor</a></span></li><li><span><a href=\"#Tensors-on-GPGPU\" data-toc-modified-id=\"Tensors-on-GPGPU-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Tensors on GPGPU</a></span></li><li><span><a href=\"#Operations-with-Tensors\" data-toc-modified-id=\"Operations-with-Tensors-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Operations with Tensors</a></span></li><li><span><a href=\"#Parts-of-a-Tensor\" data-toc-modified-id=\"Parts-of-a-Tensor-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Parts of a Tensor</a></span></li></ul></li><li><span><a href=\"#Automatic-Differentiation\" data-toc-modified-id=\"Automatic-Differentiation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Automatic Differentiation</a></span><ul class=\"toc-item\"><li><span><a href=\"#y-as-vector-value\" data-toc-modified-id=\"y-as-vector-value-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>y as vector value</a></span></li></ul></li><li><span><a href=\"#Machine-Learning---LR-for-Image-Classification\" data-toc-modified-id=\"Machine-Learning---LR-for-Image-Classification-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Machine Learning - LR for Image Classification</a></span></li><li><span><a href=\"#Deep-Learning---MLP-for-Image-Classification\" data-toc-modified-id=\"Deep-Learning---MLP-for-Image-Classification-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Deep Learning - MLP for Image Classification</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and verifying PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version:3.6.6 |Anaconda, Inc.| \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('Python version:{}'.format(sys.version[:23]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Version 9.2.148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modify the path to check CUDA version on your system\n",
    "with open('/usr/local/cuda/version.txt') as f:\n",
    "    print(f.read()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install --yes --prefix {sys.prefix} pytorch torchvision cuda92 -c pytorch\n",
    "# or !{sys.executable} -m pip install pytorch torchvision cuda92"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version:0.4.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f8a6b69a930>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "print('Torch version:{}'.format(torch.__version__))\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify PyTorch install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor on CPU:\n",
      " tensor([[0.4962, 0.1538, 0.0902, 0.7859, 0.6387],\n",
      "        [0.0409, 0.6671, 0.2795, 0.8469, 0.9989],\n",
      "        [0.5040, 0.0473, 0.4016, 0.3811, 0.9353]])\n",
      "Tensor on GPGPU:\n",
      " tensor([[0.4962, 0.1538, 0.0902, 0.7859, 0.6387],\n",
      "        [0.0409, 0.6671, 0.2795, 0.8469, 0.9989],\n",
      "        [0.5040, 0.0473, 0.4016, 0.3811, 0.9353]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "cpu_tensor = torch.rand(3,5)\n",
    "print('Tensor on CPU:\\n',cpu_tensor)\n",
    "if torch.cuda.is_available():\n",
    "    gpu_tensor = cpu_tensor.cuda()\n",
    "    print('Tensor on GPGPU:\\n',gpu_tensor)\n",
    "else:\n",
    "    print('Torch on CUDA not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4]\n",
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "python_list = [1, 2, 3, 4]\n",
    "print(python_list)\n",
    "tensor_from_list = torch.tensor(python_list)\n",
    "print(tensor_from_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 6 7 8]\n",
      "tensor([5, 6, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "numpy_array = np.array([5,6,7,8])\n",
    "print(numpy_array)\n",
    "tensor_from_numpy_array = torch.from_numpy(numpy_array)\n",
    "print(tensor_from_numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> [5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "numpy_array_from_tensor = tensor_from_numpy_array.numpy()\n",
    "print(type(numpy_array_from_tensor),numpy_array_from_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "all_ones = torch.ones(3,4)\n",
    "print(all_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "all_zeros = torch.zeros(3,4)\n",
    "print(all_zeros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8669, 0.5278, 0.7756, 0.0596],\n",
      "        [0.2067, 0.7052, 0.0145, 0.0369],\n",
      "        [0.7459, 0.5661, 0.1640, 0.1375]])\n"
     ]
    }
   ],
   "source": [
    "all_random = torch.rand(3,4)\n",
    "print(all_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.3369e-16,  3.0816e-41,  1.6816e-44,  0.0000e+00],\n",
      "        [        nan,  0.0000e+00,  6.4076e+07,  2.0706e-19],\n",
      "        [ 7.3909e+22,  3.0492e-41,  2.6279e+30,  4.5656e-41]])\n"
     ]
    }
   ],
   "source": [
    "all_float = torch.FloatTensor(3,4)\n",
    "print(all_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2067, 0.7052, 0.0145, 0.0369])\n"
     ]
    }
   ],
   "source": [
    "# slice and dice examples\n",
    "print(all_random[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7756, 0.0145, 0.1640])\n"
     ]
    }
   ],
   "source": [
    "print(all_random[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8669, 0.5278],\n",
      "        [0.2067, 0.7052]])\n"
     ]
    }
   ],
   "source": [
    "print(all_random[0:2,0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors on GPGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8669, 0.5278, 0.7756, 0.0596],\n",
      "        [0.2067, 0.7052, 0.0145, 0.0369],\n",
      "        [0.7459, 0.5661, 0.1640, 0.1375]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "gpgpu_tensor = all_random.cuda()\n",
    "print(gpgpu_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8669, 0.5278, 0.7756, 0.0596],\n",
      "        [0.2067, 0.7052, 0.0145, 0.0369],\n",
      "        [0.7459, 0.5661, 0.1640, 0.1375]])\n"
     ]
    }
   ],
   "source": [
    "cpu_tensor = gpgpu_tensor.cpu()\n",
    "print(cpu_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of type torch.cuda.FloatTensor but found type torch.FloatTensor for argument #3 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-67d3a7860c55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpgpu_tensor\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcpu_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected object of type torch.cuda.FloatTensor but found type torch.FloatTensor for argument #3 'other'"
     ]
    }
   ],
   "source": [
    "print(gpgpu_tensor+cpu_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.7338, 1.0556, 1.5512, 0.1193],\n",
      "        [0.4135, 1.4105, 0.0290, 0.0738],\n",
      "        [1.4919, 1.1323, 0.3281, 0.2749]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "cpu_tensor = cpu_tensor * 2\n",
    "gpgpu_tensor = cpu_tensor.to('cuda:0')\n",
    "print(gpgpu_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(cpu_tensor.device)\n",
    "print(gpu_tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4679, 0.1410, 0.1218, 0.8473],\n",
      "        [0.0770, 0.1401, 0.6140, 0.4993],\n",
      "        [0.8017, 0.0937, 0.8986, 0.4896]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "gpgpu_tensor = torch.rand((3,4),device=torch.device('cuda'))\n",
    "print(gpgpu_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operations with Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2508, 0.9035, 0.6209, 0.9725],\n",
      "        [0.7348, 0.2872, 0.7109, 0.9939],\n",
      "        [0.6496, 0.5582, 0.5093, 0.4237]]) tensor([[0.9911, 0.6459, 0.1771, 0.6210],\n",
      "        [0.3322, 0.3387, 0.8688, 0.8867],\n",
      "        [0.3151, 0.1992, 0.1532, 0.9190]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,4)\n",
    "y = torch.rand(3,4)\n",
    "print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2485, 0.5836, 0.1100, 0.6040],\n",
      "        [0.2441, 0.0973, 0.6176, 0.8813],\n",
      "        [0.2047, 0.1112, 0.0780, 0.3894]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.mul(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2485, 0.5836, 0.1100, 0.6040],\n",
      "        [0.2441, 0.0973, 0.6176, 0.8813],\n",
      "        [0.2047, 0.1112, 0.0780, 0.3894]])\n"
     ]
    }
   ],
   "source": [
    "print(x*y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2508, 0.9035, 0.6209, 0.9725],\n",
      "        [0.7348, 0.2872, 0.7109, 0.9939],\n",
      "        [0.6496, 0.5582, 0.5093, 0.4237]])\n",
      "tensor([[0.2485, 0.5836, 0.1100, 0.6040],\n",
      "        [0.2441, 0.0973, 0.6176, 0.8813],\n",
      "        [0.2047, 0.1112, 0.0780, 0.3894]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "x.mul_(y)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts of a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2485, 0.5836, 0.1100, 0.6040],\n",
      "        [0.2441, 0.0973, 0.6176, 0.8813],\n",
      "        [0.2047, 0.1112, 0.0780, 0.3894]])\n"
     ]
    }
   ],
   "source": [
    "print(x.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2485, 0.5836, 0.1100, 0.6040],\n",
       "        [0.2441, 0.0973, 0.6176, 0.8813],\n",
       "        [0.2047, 0.1112, 0.0780, 0.3894]], requires_grad=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "z = x+y\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ThAddBackward object at 0x7f450c075518>\n"
     ]
    }
   ],
   "source": [
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Differentiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0.3227])\n",
      "w: tensor([0.8098])\n",
      "b: tensor([0.7103])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1)\n",
    "w = torch.rand(1)\n",
    "b = torch.rand(1)\n",
    "\n",
    "print('x:',x)\n",
    "print('w:',w)\n",
    "print('b:',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([0.9716])\n"
     ]
    }
   ],
   "source": [
    "y = w * x + b\n",
    "print('y:',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None False\n",
      "None None False\n",
      "None None False\n",
      "None None False\n"
     ]
    }
   ],
   "source": [
    "print('x:',x.grad, x.grad_fn, x.requires_grad)\n",
    "print('w:',w.grad, w.grad_fn, w.requires_grad)\n",
    "print(b.grad, b.grad_fn, b.requires_grad)\n",
    "print(y.grad, y.grad_fn, y.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ab75bb780f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0.2961])\n",
      "w: tensor([0.5166], requires_grad=True)\n",
      "b: tensor([0.2517], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1)\n",
    "w = torch.rand(1,requires_grad=True)\n",
    "b = torch.rand(1,requires_grad=True)\n",
    "\n",
    "print('x:',x)\n",
    "print('w:',w)\n",
    "print('b:',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4046], grad_fn=<ThAddBackward>)\n"
     ]
    }
   ],
   "source": [
    "y = w * x + b\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None False\n",
      "None None True\n",
      "None None True\n",
      "None <ThAddBackward object at 0x7f8a286284a8> True\n"
     ]
    }
   ],
   "source": [
    "print('x:',x.grad, x.grad_fn, x.requires_grad)\n",
    "print('w:',w.grad, w.grad_fn, w.requires_grad)\n",
    "print('b:',b.grad, b.grad_fn, b.requires_grad)\n",
    "print('y:',y.grad, y.grad_fn, y.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None False\n",
      "tensor([0.2961]) None True\n",
      "tensor([1.]) None True\n",
      "None <ThAddBackward object at 0x7f8a286294e0> True\n"
     ]
    }
   ],
   "source": [
    "y.backward()\n",
    "print('x:',x.grad, x.grad_fn, x.requires_grad)\n",
    "print('w:',w.grad, w.grad_fn, w.requires_grad)\n",
    "print('b:',b.grad, b.grad_fn, b.requires_grad)\n",
    "print('y:',y.grad, y.grad_fn, y.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-ab75bb780f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1)\n",
    "w = torch.rand(1,requires_grad=True)\n",
    "b = torch.rand(1,requires_grad=True)\n",
    "y = w * x + b\n",
    "z = y * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None False\n",
      "None None True\n",
      "None None True\n",
      "None <ThAddBackward object at 0x7f8a28628ac8> True\n",
      "None <ThMulBackward object at 0x7f8a28628b38> True\n"
     ]
    }
   ],
   "source": [
    "print('x:',x.grad, x.grad_fn, x.requires_grad)\n",
    "print('w:',w.grad, w.grad_fn, w.requires_grad)\n",
    "print('b:',b.grad, b.grad_fn, b.requires_grad)\n",
    "print('y:',y.grad, y.grad_fn, y.requires_grad)\n",
    "print('z:',z.grad, z.grad_fn, z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None None False\n",
      "tensor([0.0541]) None True\n",
      "tensor([0.3961]) None True\n",
      "None <ThAddBackward object at 0x7f8a286289e8> True\n",
      "None <ThMulBackward object at 0x7f8a28628ac8> True\n"
     ]
    }
   ],
   "source": [
    "z.backward()\n",
    "print('x:',x.grad, x.grad_fn, x.requires_grad)\n",
    "print('w:',w.grad, w.grad_fn, w.requires_grad)\n",
    "print('b:',b.grad, b.grad_fn, b.requires_grad)\n",
    "print('y:',y.grad, y.grad_fn, y.requires_grad)\n",
    "print('z:',z.grad, z.grad_fn, z.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: None None False\n",
      "w: tensor([0.7031]) None True\n",
      "b: tensor([1.7501]) None True\n",
      "y: tensor([1.7501]) <ThAddBackward object at 0x7f8a2862a5c0> True\n",
      "z: None <ThMulBackward object at 0x7f8a2862a6d8> True\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1)\n",
    "w = torch.rand(1,requires_grad=True)\n",
    "b = torch.rand(1,requires_grad=True)\n",
    "y = w * x + b\n",
    "y.retain_grad()\n",
    "z = y * y\n",
    "z.backward()\n",
    "print('x:',x.grad, x.grad_fn, x.requires_grad)\n",
    "print('w:',w.grad, w.grad_fn, w.requires_grad)\n",
    "print('b:',b.grad, b.grad_fn, b.requires_grad)\n",
    "print('y:',y.grad, y.grad_fn, y.requires_grad)\n",
    "print('z:',z.grad, z.grad_fn, z.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y as vector value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0.8573, 0.8993, 0.0390]) None None False\n",
      "w: tensor([0.9268, 0.7388, 0.7179]) None None True\n",
      "b: tensor([0.7058, 0.9156, 0.4340]) None None True\n",
      "y: tensor([1.5004, 1.5800, 0.4620]) None <ThAddBackward object at 0x7f8a2862a5c0> True\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3)\n",
    "w = torch.rand(3,requires_grad=True)\n",
    "b = torch.rand(3,requires_grad=True)\n",
    "y = w * x + b\n",
    "print('x:',x.data,x.grad, x.grad_fn, x.requires_grad)\n",
    "print('w:',w.data,w.grad, w.grad_fn, w.requires_grad)\n",
    "print('b:',b.data,b.grad, b.grad_fn, b.requires_grad)\n",
    "print('y:',y.data,y.grad, y.grad_fn, y.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-ab75bb780f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mgrad_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([0.8573, 0.8993, 0.0390]) None None False\n",
      "w: tensor([0.9268, 0.7388, 0.7179]) tensor([0.8573, 0.8993, 0.0390]) None True\n",
      "b: tensor([0.7058, 0.9156, 0.4340]) tensor([1., 1., 1.]) None True\n",
      "y: tensor([1.5004, 1.5800, 0.4620]) None <ThAddBackward object at 0x7f8a2862c208> True\n"
     ]
    }
   ],
   "source": [
    "y.backward(torch.ones_like(y))\n",
    "print('x:',x.data,x.grad, x.grad_fn, x.requires_grad)\n",
    "print('w:',w.data,w.grad, w.grad_fn, w.requires_grad)\n",
    "print('b:',b.data,b.grad, b.grad_fn, b.requires_grad)\n",
    "print('y:',y.data,y.grad, y.grad_fn, y.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning - LR for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dslib\n",
    "DSLIB_HOME = '../datasetslib'\n",
    "import sys\n",
    "if not DSLIB_HOME in sys.path:\n",
    "    sys.path.append(DSLIB_HOME)\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import datasetslib as dslib\n",
    "\n",
    "# set the datasets root folder before you do the datasetslib import\n",
    "import os\n",
    "dslib.dsroot = os.path.join(os.path.expanduser('~'),'datasets')\n",
    "\n",
    "from datasetslib.utils import imutil\n",
    "from datasetslib.utils import nputil\n",
    "from datasetslib.mnist import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already exists: /home/armando/datasets/mnist/train-images-idx3-ubyte.gz\n",
      "Already exists: /home/armando/datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "Already exists: /home/armando/datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Already exists: /home/armando/datasets/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Extracting and rearchiving as jpg files...\n",
      "/home/armando/datasets/mnist/train-images-idx3-ubyte.gz\n",
      "Reading from  /home/armando/datasets/mnist/train-images-idx3-ubyte.gz\n",
      "Reading from  /home/armando/datasets/mnist/train-labels-idx1-ubyte.gz\n",
      "Saving  train\n",
      "Zip file not modified\n",
      "/home/armando/datasets/mnist/train-images-idx3-ubyte.gz\n",
      "Reading from  /home/armando/datasets/mnist/t10k-images-idx3-ubyte.gz\n",
      "Reading from  /home/armando/datasets/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Saving  test\n",
      "Zip file not modified\n",
      "Loading in x and y... start\n",
      "Loading in x and y... done\n",
      "Loaded x and y\n",
      "Train: x:(60000, 784), y:(60000, 10)\n",
      "Test: x:(10000, 784), y:(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# create an object of class datasetslib.mnist.MNIST\n",
    "mnist=MNIST()\n",
    "\n",
    "# load images in x and labels in y for train and test sets\n",
    "mnist.y_onehot = True\n",
    "mnist.x_layout = imutil.LAYOUT_NP\n",
    "\n",
    "x_train,y_train,x_test,y_test=mnist.load_data()\n",
    "\n",
    "x_train = mnist.load_images(x_train)\n",
    "y_train = nputil.onehot(y_train)\n",
    "x_test = mnist.load_images(x_test)\n",
    "y_test = nputil.onehot(y_test)\n",
    "\n",
    "print('Loaded x and y')\n",
    "print('Train: x:{}, y:{}'.format(x_train.shape,y_train.shape))\n",
    "print('Test: x:{}, y:{}'.format(x_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define hyperparameters\n",
    "learning_rate = 0.0000001\n",
    "n_epochs = 50\n",
    "epsilon = 1e-6\n",
    "\n",
    "# define input images\n",
    "x = torch.tensor(x_train,dtype=torch.float32,requires_grad=False)\n",
    "# define output labels\n",
    "y = torch.tensor(y_train,dtype=torch.float32,requires_grad=False)\n",
    "\n",
    "# model parameters\n",
    "w = torch.tensor(torch.zeros([mnist.n_features, mnist.n_classes]), \n",
    "                 requires_grad=True)\n",
    "b = torch.tensor(torch.zeros([mnist.n_classes]),\n",
    "                 requires_grad=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0000  accuracy=0.09871667\n",
      "epoch 0001  accuracy=0.66996664\n",
      "epoch 0002  accuracy=0.72711664\n",
      "epoch 0003  accuracy=0.74848336\n",
      "epoch 0004  accuracy=0.76136667\n",
      "epoch 0005  accuracy=0.76831669\n",
      "epoch 0006  accuracy=0.77590001\n",
      "epoch 0007  accuracy=0.78108335\n",
      "epoch 0008  accuracy=0.78500003\n",
      "epoch 0009  accuracy=0.78796667\n",
      "epoch 0010  accuracy=0.78986669\n",
      "epoch 0011  accuracy=0.79083335\n",
      "epoch 0012  accuracy=0.79110003\n",
      "epoch 0013  accuracy=0.79430002\n",
      "epoch 0014  accuracy=0.79560000\n",
      "epoch 0015  accuracy=0.79746670\n",
      "epoch 0016  accuracy=0.79883331\n",
      "epoch 0017  accuracy=0.80084997\n",
      "epoch 0018  accuracy=0.80145001\n",
      "epoch 0019  accuracy=0.80255002\n",
      "epoch 0020  accuracy=0.80281669\n",
      "epoch 0021  accuracy=0.80328333\n",
      "epoch 0022  accuracy=0.80133331\n",
      "epoch 0023  accuracy=0.80051666\n",
      "epoch 0024  accuracy=0.79311669\n",
      "epoch 0025  accuracy=0.78544998\n",
      "epoch 0026  accuracy=0.75555003\n",
      "epoch 0027  accuracy=0.77738333\n",
      "epoch 0028  accuracy=0.77209997\n",
      "epoch 0029  accuracy=0.79746670\n",
      "epoch 0030  accuracy=0.80400002\n",
      "epoch 0031  accuracy=0.81181669\n",
      "epoch 0032  accuracy=0.81318331\n",
      "epoch 0033  accuracy=0.81433332\n",
      "epoch 0034  accuracy=0.81486666\n",
      "epoch 0035  accuracy=0.81488335\n",
      "epoch 0036  accuracy=0.81559998\n",
      "epoch 0037  accuracy=0.81663334\n",
      "epoch 0038  accuracy=0.81784999\n",
      "epoch 0039  accuracy=0.81908333\n",
      "epoch 0040  accuracy=0.82043332\n",
      "epoch 0041  accuracy=0.82214999\n",
      "epoch 0042  accuracy=0.82513332\n",
      "epoch 0043  accuracy=0.82945001\n",
      "epoch 0044  accuracy=0.83655000\n",
      "epoch 0045  accuracy=0.84909999\n",
      "epoch 0046  accuracy=0.86059999\n",
      "epoch 0047  accuracy=0.86683333\n",
      "epoch 0048  accuracy=0.87003332\n",
      "epoch 0049  accuracy=0.87134999\n"
     ]
    }
   ],
   "source": [
    "# train and test\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Forward propagation\n",
    "    logits = torch.add(torch.matmul(x, w), b)\n",
    "    y_hat = torch.nn.functional.softmax(logits, dim=1)\n",
    "    \n",
    "    # Calculate loss\n",
    "    y_hat_clipped = torch.clamp(y_hat, epsilon, 1 - epsilon)\n",
    "    y_hat_log = torch.log(y_hat_clipped)\n",
    "    cross_entropy = -torch.sum(y * y_hat_log)\n",
    "    loss = torch.mean(cross_entropy)\n",
    "    \n",
    "    # set the gradients to zero\n",
    "    for param in [w,b]:\n",
    "        if not param.grad is None: param.grad.data.zero_()\n",
    "    \n",
    "    # Backward propagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # update the gradients\n",
    "    w.data -= learning_rate * w.grad.data\n",
    "    b.data -= learning_rate * b.grad.data\n",
    "    \n",
    "    # Predict and print train set accuracy\n",
    "    _,y_idx = torch.max(y,1)\n",
    "    _,y_hat_idx = torch.max(y_hat,1)\n",
    "    \n",
    "    predictions_check = torch.tensor(torch.eq(y_hat_idx, y_idx),\n",
    "                                     dtype=torch.float32)\n",
    "    accuracy_score = torch.mean(predictions_check)\n",
    "    print('epoch {0:04d}  accuracy={1:.8f}'\n",
    "          .format(epoch, accuracy_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning - MLP for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0000  accuracy=0.08321667\n",
      "epoch 0001  accuracy=0.31131667\n",
      "epoch 0002  accuracy=0.21960001\n",
      "epoch 0003  accuracy=0.34123334\n",
      "epoch 0004  accuracy=0.37403333\n",
      "epoch 0005  accuracy=0.49971667\n",
      "epoch 0006  accuracy=0.52168334\n",
      "epoch 0007  accuracy=0.52668333\n",
      "epoch 0008  accuracy=0.52846664\n",
      "epoch 0009  accuracy=0.58356667\n",
      "epoch 0010  accuracy=0.69476664\n",
      "epoch 0011  accuracy=0.74675000\n",
      "epoch 0012  accuracy=0.72381669\n",
      "epoch 0013  accuracy=0.69466668\n",
      "epoch 0014  accuracy=0.70195001\n",
      "epoch 0015  accuracy=0.73746669\n",
      "epoch 0016  accuracy=0.76611668\n",
      "epoch 0017  accuracy=0.78046668\n",
      "epoch 0018  accuracy=0.79783332\n",
      "epoch 0019  accuracy=0.81875002\n",
      "epoch 0020  accuracy=0.83628333\n",
      "epoch 0021  accuracy=0.84516668\n",
      "epoch 0022  accuracy=0.84745002\n",
      "epoch 0023  accuracy=0.84791666\n",
      "epoch 0024  accuracy=0.84890002\n",
      "epoch 0025  accuracy=0.85294998\n",
      "epoch 0026  accuracy=0.85921669\n",
      "epoch 0027  accuracy=0.86693335\n",
      "epoch 0028  accuracy=0.87440002\n",
      "epoch 0029  accuracy=0.88108331\n",
      "epoch 0030  accuracy=0.88630003\n",
      "epoch 0031  accuracy=0.88863331\n",
      "epoch 0032  accuracy=0.89106667\n",
      "epoch 0033  accuracy=0.89438331\n",
      "epoch 0034  accuracy=0.89846665\n",
      "epoch 0035  accuracy=0.90281665\n",
      "epoch 0036  accuracy=0.90490001\n",
      "epoch 0037  accuracy=0.90640002\n",
      "epoch 0038  accuracy=0.90816665\n",
      "epoch 0039  accuracy=0.91118336\n",
      "epoch 0040  accuracy=0.91320002\n",
      "epoch 0041  accuracy=0.91543335\n",
      "epoch 0042  accuracy=0.91691667\n",
      "epoch 0043  accuracy=0.91890001\n",
      "epoch 0044  accuracy=0.92073333\n",
      "epoch 0045  accuracy=0.92285001\n",
      "epoch 0046  accuracy=0.92423332\n",
      "epoch 0047  accuracy=0.92570001\n",
      "epoch 0048  accuracy=0.92703331\n",
      "epoch 0049  accuracy=0.92850000\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "n_epochs = 50\n",
    "model = torch.nn.Sequential(torch.nn.Linear(784,512),\n",
    "                          torch.nn.ReLU(),\n",
    "                          torch.nn.Linear(512,256),\n",
    "                          torch.nn.ReLU(),\n",
    "                          torch.nn.Linear(256,10))\n",
    "loss_f = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Forward prop\n",
    "    y_hat = model(x)\n",
    "    \n",
    "    # calculate loss\n",
    "    _,y_idx = torch.max(y,1)\n",
    "    loss = loss_f(y_hat,y_idx)\n",
    "    \n",
    "    # Backward prop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Apply gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Check accurcay\n",
    "    _,y_hat_idx = torch.max(y_hat,1)\n",
    "    predictions_check = torch.tensor(torch.eq(y_hat_idx, y_idx),\n",
    "                                     dtype=torch.float32)\n",
    "    accuracy_score = torch.mean(predictions_check)\n",
    "    print('epoch {0:04d}  accuracy={1:.8f}'\n",
    "          .format(epoch, accuracy_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0000  accuracy=0.11005000\n",
      "epoch 0001  accuracy=0.25784999\n",
      "epoch 0002  accuracy=0.34143335\n",
      "epoch 0003  accuracy=0.45956665\n",
      "epoch 0004  accuracy=0.57298332\n",
      "epoch 0005  accuracy=0.59201664\n",
      "epoch 0006  accuracy=0.62438333\n",
      "epoch 0007  accuracy=0.63319999\n",
      "epoch 0008  accuracy=0.66495001\n",
      "epoch 0009  accuracy=0.72753334\n",
      "epoch 0010  accuracy=0.77231669\n",
      "epoch 0011  accuracy=0.70683336\n",
      "epoch 0012  accuracy=0.68645000\n",
      "epoch 0013  accuracy=0.72438335\n",
      "epoch 0014  accuracy=0.77261668\n",
      "epoch 0015  accuracy=0.80868334\n",
      "epoch 0016  accuracy=0.83238333\n",
      "epoch 0017  accuracy=0.84060001\n",
      "epoch 0018  accuracy=0.83436668\n",
      "epoch 0019  accuracy=0.82796669\n",
      "epoch 0020  accuracy=0.83329999\n",
      "epoch 0021  accuracy=0.84573334\n",
      "epoch 0022  accuracy=0.86026669\n",
      "epoch 0023  accuracy=0.87271667\n",
      "epoch 0024  accuracy=0.88348335\n",
      "epoch 0025  accuracy=0.88905001\n",
      "epoch 0026  accuracy=0.89166665\n",
      "epoch 0027  accuracy=0.89295000\n",
      "epoch 0028  accuracy=0.89331669\n",
      "epoch 0029  accuracy=0.89406669\n",
      "epoch 0030  accuracy=0.89636666\n",
      "epoch 0031  accuracy=0.90030003\n",
      "epoch 0032  accuracy=0.90488333\n",
      "epoch 0033  accuracy=0.90981668\n",
      "epoch 0034  accuracy=0.91408336\n",
      "epoch 0035  accuracy=0.91829997\n",
      "epoch 0036  accuracy=0.92073333\n",
      "epoch 0037  accuracy=0.92268336\n",
      "epoch 0038  accuracy=0.92396665\n",
      "epoch 0039  accuracy=0.92508334\n",
      "epoch 0040  accuracy=0.92656666\n",
      "epoch 0041  accuracy=0.92823333\n",
      "epoch 0042  accuracy=0.93001670\n",
      "epoch 0043  accuracy=0.93146664\n",
      "epoch 0044  accuracy=0.93246669\n",
      "epoch 0045  accuracy=0.93356669\n",
      "epoch 0046  accuracy=0.93503332\n",
      "epoch 0047  accuracy=0.93620002\n",
      "epoch 0048  accuracy=0.93720001\n",
      "epoch 0049  accuracy=0.93828332\n"
     ]
    }
   ],
   "source": [
    "class MLPModel(torch.nn.Module):\n",
    "    def __init__(self, n_features, n_labels):\n",
    "        super().__init__()\n",
    "        self.linear_in = torch.nn.Linear(n_features,512)\n",
    "        self.relu_in_1 = torch.nn.ReLU()\n",
    "        self.linear_h1 = torch.nn.Linear(512,256)\n",
    "        self.relu_1_out = torch.nn.ReLU()\n",
    "        self.linear_out = torch.nn.Linear(256,n_labels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear_out(\n",
    "                    self.relu_1_out(\n",
    "                        self.linear_h1(\n",
    "                            self.relu_in_1(\n",
    "                                self.linear_in(x)))))\n",
    "        return y_pred\n",
    "    \n",
    "learning_rate = 0.001\n",
    "n_epochs = 50\n",
    "model = MLPModel(784,10)\n",
    "\n",
    "loss_f = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Forward prop\n",
    "    y_hat = model(x)\n",
    "    \n",
    "    # calculate loss\n",
    "    _,y_idx = torch.max(y,1)\n",
    "    loss = loss_f(y_hat,y_idx)\n",
    "    \n",
    "    # Backward prop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Apply gradients\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Check accurcay\n",
    "    _,y_hat_idx = torch.max(y_hat,1)\n",
    "    predictions_check = torch.tensor(torch.eq(y_hat_idx, y_idx),\n",
    "                                     dtype=torch.float32)\n",
    "    accuracy_score = torch.mean(predictions_check)\n",
    "    print('epoch {0:04d}  accuracy={1:.8f}'\n",
    "          .format(epoch, accuracy_score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
