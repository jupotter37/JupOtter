{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient prediction\n",
    "\n",
    "This notebook will illustrate how to calculate gradients with respect to model input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /home/avsec/.kipoi/models/Basset/downloaded/model_files/weights/4878981d84499eb575abd0f3b45570d3\n"
     ]
    }
   ],
   "source": [
    "# First let's select and setup the model:\n",
    "import kipoi\n",
    "model_name = \"Basset\"\n",
    "#kipoi.pipeline.install_model_requirements(model_name)\n",
    "# get ahold of the model\n",
    "model = kipoi.get_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For gradient prediction we need a set of parameters like:\n",
    "\n",
    " - `layer`: The gradient will then be calculated in repect to the activation of that layer\n",
    " - `filter_idx`: The filter from which the activation shall be used to calculate the gradient - this is optional and if not set then all filter outputs are passed to the avg_func\n",
    " - `avg_func`: How we want to average over multiple filter outputs - take the sum, the minimum, the maximum or the maximum of the absolute values.\n",
    "\n",
    "The `Basset` model we are using here is a multitask model that predicts probabilities of accesible genomic regions in 164 cell types. It is a multi-task model and therefore accepts one input (600bp DNA sequence) and produces 164 predictions simulatneously. \n",
    "\n",
    "Let's start out with selecting model parameters. Most importantly we want to select a layer by its index. For PyTorch models the layers can be displayed just by running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(4, 300, kernel_size=(19, 1), stride=(1, 1))\n",
       "  (1): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): MaxPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (4): Conv2d(300, 200, kernel_size=(11, 1), stride=(1, 1))\n",
       "  (5): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (6): ReLU()\n",
       "  (7): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (8): Conv2d(200, 200, kernel_size=(7, 1), stride=(1, 1))\n",
       "  (9): BatchNorm2d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU()\n",
       "  (11): MaxPool2d(kernel_size=(4, 1), stride=(4, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (12): Lambda()\n",
       "  (13): Sequential(\n",
       "    (0): Lambda()\n",
       "    (1): Linear(in_features=2000, out_features=1000, bias=True)\n",
       "  )\n",
       "  (14): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (15): ReLU()\n",
       "  (16): Dropout(p=0.3)\n",
       "  (17): Sequential(\n",
       "    (0): Lambda()\n",
       "    (1): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "  )\n",
       "  (18): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (19): ReLU()\n",
       "  (20): Dropout(p=0.3)\n",
       "  (21): Sequential(\n",
       "    (0): Lambda()\n",
       "    (1): Linear(in_features=1000, out_features=164, bias=True)\n",
       "  )\n",
       "  (22): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to see which inputs were important for giving a prediction in the model output we will select the output from layer 21.1 - we don't want to calculate the gradients based on outputs of a nonlinearity.\n",
    "\n",
    "The model is a multi-task model predicting chromatin accessibility for 164 cell types, we want to calculate the gradients with respect to exactly one of those cell types: K562. In order to select the filter which produces this value we can use the model task annotation that is stored in the Kipoi model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_idx = model.schema.targets.column_labels.index('K562')\n",
    "filter_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have decided about the model-related setup we need to produce model input data using the model dataloader. Just like for any other prediction with Kipoi we have to define the dataloader keyword arguments with which the dataloader can be executed. The `Basset` default dataloader takes two arguments: `fasta_file` and `intervals_file`. The `intervals_file` is a bed file defining regions for which input data is generated.\n",
    "\n",
    "We want to look at a DNAse-seq peak in the K562 cell line. So we will first download a bed file of the peaks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-11-26 23:54:16--  http://hgdownload.cse.ucsc.edu/goldenpath/hg19/encodeDCC/wgEncodeAwgDnaseUniform/wgEncodeAwgDnaseUwdukeK562UniPk.narrowPeak.gz\n",
      "Resolving hgdownload.cse.ucsc.edu (hgdownload.cse.ucsc.edu)... 128.114.119.163\n",
      "Connecting to hgdownload.cse.ucsc.edu (hgdownload.cse.ucsc.edu)|128.114.119.163|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1845863 (1,8M) [application/x-gzip]\n",
      "Saving to: ‘example_data/wgEncodeAwgDnaseUwdukeK562UniPk.narrowPeak.gz.1’\n",
      "\n",
      "wgEncodeAwgDnaseUwd 100%[===================>]   1,76M  1,06MB/s    in 1,7s    \n",
      "\n",
      "2018-11-26 23:54:19 (1,06 MB/s) - ‘example_data/wgEncodeAwgDnaseUwdukeK562UniPk.narrowPeak.gz.1’ saved [1845863/1845863]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P example_data http://hgdownload.cse.ucsc.edu/goldenpath/hg19/encodeDCC/wgEncodeAwgDnaseUniform/wgEncodeAwgDnaseUwdukeK562UniPk.narrowPeak.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's randomly extract the first peak in the downloaded file in chromosome 22 into a bed file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grep: write error: Broken pipe\n",
      "\n",
      "gzip: stdout: Broken pipe\n",
      "chr22\t16197740\t16197890\t.\t0\t.\t0\t-1\t-1\t-1\n"
     ]
    }
   ],
   "source": [
    "! gzip -dc example_data/wgEncodeAwgDnaseUwdukeK562UniPk.narrowPeak.gz | grep \"^chr22\" | head -n 1 > example_data/Basset_grad_query.bed\n",
    "! cat example_data/Basset_grad_query.bed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one more thing we need to keep in mind - `Basset` only works with 600bp sequence length genomic regions, so we can centre our query region on the peak selected above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seq_length = 600\n",
    "with open(\"example_data/Basset_grad_query.bed\", \"r\") as ifh:\n",
    "    with open(\"example_data/Basset_grad_query_Basset.bed\", \"w\") as ofh:\n",
    "        for l in ifh:\n",
    "            tokens = l.rstrip().split(\"\\t\")\n",
    "            center = (int(tokens[1]) + int(tokens[2]))//2\n",
    "            ofh.write(\"\\t\".join([tokens[0], str(center -model_seq_length//2),\n",
    "                                 str(center + model_seq_length//2  + model_seq_length%2)]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr22\t16197515\t16198115\n"
     ]
    }
   ],
   "source": [
    "! cat example_data/Basset_grad_query_Basset.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_arguments = {\"fasta_file\": \"example_data/hg19_chr22.fa\",\n",
    "                        'intervals_file': \"example_data/Basset_grad_query_Basset.bed\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dataloader_arguments` are keyword arguments passed on to the dataloader in order to setup data generation. In the next step we run the `input_grad` pipeline to get gradients and model inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 32.53it/s]\n"
     ]
    }
   ],
   "source": [
    "grad_preds = model.pipeline.input_grad(dataloader_arguments, layer=\"21.1\", filter_idx = filter_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the gradients are calculated we can plot the results using the `GradPlotter` class. This class has momentarily been removed from the repository hence I am posting its definition here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kipoi import readers\n",
    "from kipoi_veff.utils import ModelInfoExtractor\n",
    "from kipoi_veff.utils.generic import _get_metadata_name, _get_seq_shape\n",
    "from kipoi_veff.utils import ReshapeDna\n",
    "import kipoi\n",
    "import os\n",
    "import numpy as np\n",
    "import logging\n",
    "from kipoi_utils.utils import cd\n",
    "\n",
    "\n",
    "def grad_x_input(input, grad):\n",
    "    return input * grad\n",
    "\n",
    "\n",
    "def get_selector(dim, slice_at_dim):\n",
    "    \"\"\"\n",
    "    Place `slice_at_dim` at dimension `dim` for setting or setting items\n",
    "    \"\"\"\n",
    "    if dim >= 0:\n",
    "        selector = [slice(None) for i in range(dim)] + [slice_at_dim] + [Ellipsis]\n",
    "    else:\n",
    "        selector = [Ellipsis] + [slice_at_dim] + [slice(None) for i in range((dim) * (-1) - 1)]\n",
    "    selector = tuple(selector)\n",
    "    return selector\n",
    "\n",
    "\n",
    "# TODO - why is this called gradPlotter? In theory, this could be any other importance score...\n",
    "\n",
    "# - can't depend on anything from kipoi.postprocessing..\n",
    "\n",
    "class GradPlotter(object):\n",
    "    \"\"\"\n",
    "    Class for plotting gradients. Results can be loaded from a HDF5 file or directly from returns of\n",
    "    model.input_grad(...)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, model, source=\"kipoi\", grad_preds=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "           data: model input data batch\n",
    "            model: model name as used for running `model.input_grad(...)`\n",
    "            source: model source as used for running `model.input_grad(...)`\n",
    "            grad_preds: return value of `model.input_grad(...)`. Can alternatively already be present in `data`\n",
    "            argument under the key `preds`. In that case `grad_preds` may be None.\n",
    "        \"\"\"\n",
    "        src = kipoi.get_source(source)\n",
    "        # TODO - prettify this init\n",
    "        self.data = data\n",
    "        if grad_preds is not None:\n",
    "            self.data['grads'] = grad_preds\n",
    "        else:\n",
    "            assert 'grads' in self.data\n",
    "\n",
    "        # TODO: R: Instead of copying from kipoi.model should we rather have a get_model_descr\n",
    "        #             -- Z: this function is indeed available\n",
    "        # TODO-cont: funcion that is also called from get_model\n",
    "        # Taken from get_model\n",
    "        source_name = source\n",
    "        source = kipoi.config.get_source(source)\n",
    "        md = source.get_model_descr(model)\n",
    "\n",
    "        dl_source = source_name\n",
    "        dl_path = md.default_dataloader\n",
    "\n",
    "        if isinstance(md.default_dataloader, kipoi.specs.DataLoaderImport):\n",
    "            with cd(src.get_model_dir(model)):\n",
    "                default_dataloader = md.default_dataloader.get()\n",
    "        else:\n",
    "            # load from directory\n",
    "            # attach the default dataloader already to the model\n",
    "            default_dataloader = kipoi.get_dataloader_descr(os.path.join(src.get_model_dir(model), md.default_dataloader),\n",
    "                                                  source=source)\n",
    "        \n",
    "        try:\n",
    "            self.mie = ModelInfoExtractor(md, default_dataloader)\n",
    "        except:\n",
    "            logger.warning(\"Model is not enabled for variant effect prediction hence it is unclear whether there is a DNA \"\n",
    "                        \"sequence input, so (automatic) seqlogo plots are not available for this model.\")\n",
    "            self.mie = None\n",
    "        self.md = md\n",
    "        self.dataloader = default_dataloader\n",
    "\n",
    "        # how can the correct model input be selected\n",
    "        self.get_dataset, self.model_input_keylist = self._get_ds_extractor(md.schema.inputs)\n",
    "\n",
    "    @classmethod\n",
    "    def from_hdf5(self, results_fname, model, source=\"kipoi\"):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            results_fname: HDF5 file produced by running `model.input_grad(...)`. The file has to contain\n",
    "            also the model input!\n",
    "            model: model name as used for running `model.input_grad(...)`\n",
    "            source: model source as used for running `model.input_grad(...)`\n",
    "        \"\"\"\n",
    "        data = readers.HDF5Reader.load(results_fname, unflatten=True)\n",
    "        return self(data, model=model, source=source)\n",
    "\n",
    "    def _get_ds_extractor(self, model_input_schema):\n",
    "        from kipoi.components import ArraySchema\n",
    "        # return data selection function + labels\n",
    "        if isinstance(model_input_schema, ArraySchema):\n",
    "            return self._select_ds_ndarray, [model_input_schema.name]\n",
    "        elif isinstance(model_input_schema, list):\n",
    "            return self._select_ds_list, [el.name for el in model_input_schema]\n",
    "        elif isinstance(model_input_schema, dict):\n",
    "            return self._select_ds_dict, [el for el in model_input_schema]\n",
    "\n",
    "    def _select_ds_ndarray(self, index, dataset):\n",
    "        if index is not None:\n",
    "            assert (index == 0) or (self.model_input_keylist[0] == index)\n",
    "        return dataset\n",
    "\n",
    "    def _select_ds_list(self, index, dataset):\n",
    "        if isinstance(index, int):\n",
    "            return dataset[index]\n",
    "        else:\n",
    "            int_ind = self.model_input_keylist.index(index)\n",
    "            return dataset[int_ind]\n",
    "\n",
    "    def _select_ds_dict(self, index, dataset):\n",
    "        return dataset[index]\n",
    "\n",
    "    def _verify_model_input(self, model_input):\n",
    "        if model_input is None:\n",
    "            if len(self.model_input_keylist) != 1:\n",
    "                raise Exception(\"model_input cannot be None for models that have multiple \"\n",
    "                                \"inputs: %s\" % str(self.model_input_keylist))\n",
    "            model_input = self.model_input_keylist[0]\n",
    "        return model_input\n",
    "\n",
    "    def get_num_samples(self, model_input=None):\n",
    "        \"\"\"\n",
    "        Get number of samples present in the dataset (size of 0th dimension of the model input).\n",
    "        Arguments:\n",
    "            model_input: Number of samples will be returned for that model input.\n",
    "        \"\"\"\n",
    "        model_input = self._verify_model_input(model_input)\n",
    "        input = self.get_dataset(model_input, self.data[\"inputs\"])\n",
    "        return input.shape[0]\n",
    "\n",
    "    @staticmethod\n",
    "    def _infer_seq_dim(len, array_shape):\n",
    "        sel = np.array(array_shape) == len\n",
    "        if sel.sum() == 1:\n",
    "            return np.where(sel)[0][0]\n",
    "        return None\n",
    "\n",
    "    def _preprocess_values(self, sample, model_input=None,\n",
    "                           limit_region=None, limit_region_genomic=None,\n",
    "                           transform_fn=grad_x_input,\n",
    "                           seq_dim=None,\n",
    "                           requires_region_info=False,\n",
    "                           requires_seq_dim=False):\n",
    "        def raise_missing_metadata():\n",
    "            raise Exception(\"limit_region_genomic can only be used with a `model_input` that has an associated\"\n",
    "                            \"metadata field with at least the following entries: 'chrom', 'start', 'end' or type\"\n",
    "                            \"GenomicRanges.\")\n",
    "\n",
    "        def get_metadata_cse():\n",
    "            metadata_field = None\n",
    "            try:\n",
    "                metadata_field = _get_metadata_name(self.dataloader, model_input)\n",
    "            except ValueError:\n",
    "                raise_missing_metadata()\n",
    "            mf = self.data['metadata'][metadata_field]\n",
    "            if not all([el in mf for el in [\"chr\", \"start\", \"end\"]]):\n",
    "                raise_missing_metadata()\n",
    "            cse = {k: np.squeeze(mf[k]) for k in [\"chr\", \"start\", \"end\"]}\n",
    "            for k in [\"chr\", \"start\", \"end\"]:\n",
    "                cse[k] = np.squeeze(mf[k])\n",
    "                # if only one sample then squeeze does too much, so correct that:\n",
    "                if len(cse[k].shape) == 0:\n",
    "                    cse[k] = np.array([cse[k]])\n",
    "                if len(cse[k].shape) != 1:\n",
    "                    raise Exception(\"Invalid metadata format for field ['%s']['%s'] with shape: %s\" %\n",
    "                                    (metadata_field, k, str(mf[k].shape)))\n",
    "            return cse\n",
    "\n",
    "        inputs = self.data[\"inputs\"]\n",
    "        gradients = self.data[\"grads\"]\n",
    "\n",
    "        model_input = self._verify_model_input(model_input)\n",
    "\n",
    "        input = self.get_dataset(model_input, inputs)\n",
    "        gradient = self.get_dataset(model_input, gradients)\n",
    "\n",
    "        is_onehot_seq = False\n",
    "        if (self.mie is not None) and (model_input in self.mie.get_mutatable_inputs(only_one_hot=True)):\n",
    "            is_onehot_seq = True\n",
    "\n",
    "        if requires_region_info:\n",
    "            mf = get_metadata_cse()\n",
    "            mr_chr = mf[\"chr\"][sample]\n",
    "            mr_start = mf[\"start\"][sample]\n",
    "            mr_end = mf[\"end\"][sample]\n",
    "        else:\n",
    "            mr_chr = None\n",
    "            mr_start = None\n",
    "            mr_end = None\n",
    "\n",
    "        if (limit_region_genomic is not None):\n",
    "            if not isinstance(limit_region_genomic, tuple):\n",
    "                raise Exception(\"`limit_region_genomic` has to be a tuple of (start, end) genomic coordinates!\")\n",
    "            mf = get_metadata_cse()\n",
    "            mr_chr = mf[\"chr\"][sample]\n",
    "            mr_start = mf[\"start\"][sample]\n",
    "            mr_end = mf[\"end\"][sample]\n",
    "            if any([(el < mr_start) or (el > mr_end) for el in list(limit_region_genomic)]):\n",
    "                raise Exception(\"`limit_region_genomic` has to lie within: %s\" % str([mr_start, mr_end]))\n",
    "            limit_region = (limit_region_genomic[0] - mr_start, limit_region_genomic[1] - mr_start,)\n",
    "            mr_start, mr_end = limit_region_genomic\n",
    "\n",
    "        elif (limit_region is not None):\n",
    "            if not isinstance(limit_region, tuple):\n",
    "                raise Exception(\"`limit_region` has to be a tuple of (start, end) array indices!\")\n",
    "            if mr_start is not None:\n",
    "                mr_end = mr_start + limit_region_genomic[1] + 1\n",
    "                mr_start = mr_start + limit_region_genomic[0]\n",
    "\n",
    "        if is_onehot_seq:\n",
    "            # convert to standard layout\n",
    "            dna_reshaper = ReshapeDna(_get_seq_shape(self.dataloader, model_input))\n",
    "            input_reshaped = dna_reshaper.to_standard(input)[sample, ...]\n",
    "            gradient_reshaped = dna_reshaper.to_standard(gradient)[sample, ...]\n",
    "            seq_dim = 0\n",
    "\n",
    "            values = transform_fn(input_reshaped, gradient_reshaped)\n",
    "\n",
    "            if limit_region is not None:\n",
    "                values = values[limit_region[0]:limit_region[1], :]\n",
    "\n",
    "            return values, is_onehot_seq, mr_chr, mr_start, mr_end, seq_dim\n",
    "\n",
    "        else:\n",
    "            if requires_seq_dim or (limit_region is not None):\n",
    "                if seq_dim is None:\n",
    "                    mf = get_metadata_cse()\n",
    "                    seq_len = mf[\"end\"][sample] - mf[\"start\"][sample]\n",
    "                    seq_dim = self._infer_seq_dim(seq_len, input.shape[1:])\n",
    "                    if seq_dim is None:\n",
    "                        raise Exception(\"seq_dim was not defined and could not be inferred for array dimensions %s and\"\n",
    "                                        \"sequence length %d. seq_dim is required if `rc_plot` or \"\n",
    "                                        \"`limit_region_genomic` or `seq_plotter_obj` on a non-DNAsequence input \"\n",
    "                                        \"are used!\")\n",
    "\n",
    "            values = transform_fn(input[sample, ...], gradient[sample, ...])\n",
    "            if limit_region is not None:\n",
    "                lr_sel = get_selector(seq_dim, slice(limit_region[0], limit_region[1]))\n",
    "                values = values.__getitem__(lr_sel)\n",
    "\n",
    "            return values, is_onehot_seq, mr_chr, mr_start, mr_end, seq_dim\n",
    "\n",
    "    def plot(self, sample, model_input=None, ax=None,\n",
    "             limit_region=None, limit_region_genomic=None, rc_plot=False,\n",
    "             transform_fn=grad_x_input, seq_dim=None, additional_plot_fns=None, **heatmap_kwargs):\n",
    "        \"\"\"\n",
    "        Plot grad*input for one sample in the data (batch). If the selected model input is tagged as \"DNASequence\" and\n",
    "        the model variant effect prediction activated (here only necessary for parsing model info), then values\n",
    "        returned by `transform_fn` are displayed as Seqlogo plots. The default transform_fn is grad*input.\n",
    "        If the selected model input is not tagged as \"DNASequence\" or the model is not activated for variant effect\n",
    "        prediction then a heatmap will be generated with additional `heatmap_kwargs` if given.\n",
    "        If a heatmap should be produced then the input can only be the batch sample axis + 2D, otherwise the heatmap\n",
    "        fails.\n",
    "        Arguments:\n",
    "            sample: Sample in the batch (integer)\n",
    "            model_input: Name of the model input that should be plotted (can be omitted for models with only one\n",
    "            input)\n",
    "            ax: axis object to be passed to the plotting functions.\n",
    "            limit_region: Tuple. Limits the plot to a subset in the sequence dimension (seq_dim)\n",
    "            limit_region_genomic: Tuple. Like `limit_region`, but genomic coordinates - no chromosome\n",
    "            rc_plot: Reverse-complement the plot. If model_input is not \"DNASequence\" then only reverse\n",
    "            transform_fn: Function fn(input, grad). Default is input*grad\n",
    "            seq_dim: Dimension of the sequence. Used for reversing the order in `rc_plot`. Can be omitted for\n",
    "            \"DNASequence\" model inputs. If not given, but needed it will be attempted to be inferred from array\n",
    "            dimensions and metadata sequence length.\n",
    "            additional_plot_fns: List of functions fn(chrom, start, end, ax) that will be executed after the main\n",
    "            plotting routine\n",
    "        \"\"\"\n",
    "\n",
    "        requires_region_info = additional_plot_fns is not None\n",
    "\n",
    "        values, is_onehot_seq, mr_chr, mr_start, mr_end, seq_dim = self._preprocess_values(sample,\n",
    "                                                                                           model_input=model_input,\n",
    "                                                                                           limit_region=limit_region,\n",
    "                                                                                           limit_region_genomic=limit_region_genomic,\n",
    "                                                                                           transform_fn=transform_fn,\n",
    "                                                                                           seq_dim=seq_dim,\n",
    "                                                                                           requires_region_info=requires_region_info,\n",
    "                                                                                           requires_seq_dim=True)\n",
    "\n",
    "        if ax is None:\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.figure(figsize=(20, 4))\n",
    "            ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "        import seaborn as sns\n",
    "        if is_onehot_seq:\n",
    "            # Reverse-complement only for the plot itself\n",
    "            if rc_plot:\n",
    "                values = values[::-1, ::-1]\n",
    "\n",
    "            from kipoi_veff.external.concise.seqplotting_deps import seqlogo\n",
    "            seqlogo(values, ax=ax)\n",
    "            ax.axes.get_xaxis().set_visible(False)\n",
    "            sns.despine(trim=True, bottom=True, ax=ax)\n",
    "\n",
    "        else:\n",
    "            if rc_plot:\n",
    "                rc_sel = get_selector(seq_dim, slice(None, None, -1))\n",
    "                values = values.__getitem__(rc_sel)\n",
    "\n",
    "            sns.heatmap(values, ax=ax, **heatmap_kwargs)\n",
    "\n",
    "        if (additional_plot_fns is not None):\n",
    "            for plot_fn in additional_plot_fns:\n",
    "                plot_fn(chrom=mr_chr, start=mr_start, end=mr_end, ax=ax)\n",
    "\n",
    "    def write(self, sample, writer_obj, model_input=None, limit_region=None, limit_region_genomic=None,\n",
    "              transform_fn=grad_x_input, seq_dim=None):\n",
    "        \"\"\"\n",
    "        Write grad*input for one sample in the data (batch). If the selected model input is tagged as \"DNASequence\" and\n",
    "        the model variant effect prediction activated (here only necessary for parsing model info), then values\n",
    "        returned by `transform_fn` are stored as data in the `writer_obj`. The default transform_fn is grad*input.\n",
    "        If the selected model input is not tagged as \"DNASequence\" or the model is not activated for variant effect\n",
    "        prediction then higher-dimensional data will be compressed into a 1D representation by summing over all axes\n",
    "        except for the one defined in `seq_dim`.\n",
    "        Arguments:\n",
    "            sample: Sample in the batch (integer)\n",
    "            writer_obj: Is a instance of a subclass of \"RegionWriter\". \"region_write()\" will be called once per\n",
    "            call of this function.\n",
    "            model_input: Name of the model input that should be written (can be omitted for models with only one\n",
    "            input)\n",
    "            limit_region: Tuple. Limits the values to a subset in the sequence dimension (seq_dim)\n",
    "            limit_region_genomic: Tuple. Like `limit_region`, but genomic coordinates - no chromosome\n",
    "            transform_fn: Function fn(input, grad). Default is input*grad\n",
    "            seq_dim: Dimension of the sequence. Used for reversing the order in `rc_plot`. Can be omitted for\n",
    "            \"DNASequence\" model inputs. If not given, but needed it will be attempted to be inferred from array\n",
    "            dimensions and metadata sequence length.\n",
    "        \"\"\"\n",
    "        values, is_onehot_seq, mr_chr, mr_start, mr_end, seq_dim = self._preprocess_values(sample,\n",
    "                                                                                           model_input=model_input,\n",
    "                                                                                           limit_region=limit_region,\n",
    "                                                                                           limit_region_genomic=limit_region_genomic,\n",
    "                                                                                           transform_fn=transform_fn,\n",
    "                                                                                           seq_dim=seq_dim,\n",
    "                                                                                           requires_region_info=True,\n",
    "                                                                                           requires_seq_dim=True)\n",
    "\n",
    "        regions = {\"chr\": [mr_chr], \"start\": [mr_start], \"end\": [mr_end]}\n",
    "\n",
    "        if is_onehot_seq:\n",
    "            writer_obj.region_write(regions, values)\n",
    "\n",
    "        else:\n",
    "            # now compress them down by summation so that only the seq_dim is left\n",
    "            values_summed = values\n",
    "            for dim in range(0, len(values.shape)):\n",
    "                if dim != seq_dim:\n",
    "                    values_summed = np.sum(values_summed, axis=dim, keepdims=True)\n",
    "            values_summed = np.squeeze(values_summed)\n",
    "            writer_obj.region_write(regions, values_summed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we only have one batch of input data we don't have to worry about collating batches. The GradPlotter instantiation requires the input data, the gradient predictions and the name of the model. The model name is required as the model configuration is necessary to automatically identify whether a specific model input is a DNA-sequence input. As we will see here this has an impact on how data can be displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the GradPlotter instance:\n",
    "gp = GradPlotter(grad_preds, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Basset model only has DNA sequnce input. For DNA sequence input it is possible to display _grad*input_ as a seqlogo plot as can be seen above. You might have to execute the following cell twice since sometimes the first matplolib plot is not displayed in the notebook.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "General array mismatch! Given: (1, 4, 600, 1) Expecting: ([N], %s)None, 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-175c52c8dc17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-24fdc41e54dd>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, sample, model_input, ax, limit_region, limit_region_genomic, rc_plot, transform_fn, seq_dim, additional_plot_fns, **heatmap_kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m                                                                                            \u001b[0mseq_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                                                                                            \u001b[0mrequires_region_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequires_region_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                                                                                            requires_seq_dim=True)\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0max\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-24fdc41e54dd>\u001b[0m in \u001b[0;36m_preprocess_values\u001b[0;34m(self, sample, model_input, limit_region, limit_region_genomic, transform_fn, seq_dim, requires_region_info, requires_seq_dim)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;31m# convert to standard layout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mdna_reshaper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshapeDna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_seq_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0minput_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdna_reshaper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0mgradient_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdna_reshaper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mseq_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/kipoi/kipoi-veff/kipoi_veff/utils/dna_reshapers.py\u001b[0m in \u001b[0;36mto_standard\u001b[0;34m(self, in_array)\u001b[0m\n\u001b[1;32m    229\u001b[0m             raise Exception(\"General array mismatch! Given: %s Expecting: %s\" % (str(in_array.shape),\n\u001b[1;32m    230\u001b[0m                                                                                  \"([N], %s)\" + \", \".join(\n\u001b[0;32m--> 231\u001b[0;31m                                                                                      in_shape.astype(str).tolist())))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape_needed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: General array mismatch! Given: (1, 4, 600, 1) Expecting: ([N], %s)None, 4"
     ]
    }
   ],
   "source": [
    "gp.plot(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying 600bp in a seqlogo is not very useful, hence zooming is possible by genomic coordinates (`limit_region_genomic`) or by subsetting the _grad*input_ array directly using the `limit_region` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "General array mismatch! Given: (1, 4, 600, 1) Expecting: ([N], %s)None, 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-87fcd1cd1934>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# subset model input sequence to bases 250 to 350 for plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit_region\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m350\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-24fdc41e54dd>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, sample, model_input, ax, limit_region, limit_region_genomic, rc_plot, transform_fn, seq_dim, additional_plot_fns, **heatmap_kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m                                                                                            \u001b[0mseq_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                                                                                            \u001b[0mrequires_region_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequires_region_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                                                                                            requires_seq_dim=True)\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0max\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-24fdc41e54dd>\u001b[0m in \u001b[0;36m_preprocess_values\u001b[0;34m(self, sample, model_input, limit_region, limit_region_genomic, transform_fn, seq_dim, requires_region_info, requires_seq_dim)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;31m# convert to standard layout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mdna_reshaper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshapeDna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_seq_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0minput_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdna_reshaper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0mgradient_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdna_reshaper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mseq_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/kipoi/kipoi-veff/kipoi_veff/utils/dna_reshapers.py\u001b[0m in \u001b[0;36mto_standard\u001b[0;34m(self, in_array)\u001b[0m\n\u001b[1;32m    229\u001b[0m             raise Exception(\"General array mismatch! Given: %s Expecting: %s\" % (str(in_array.shape),\n\u001b[1;32m    230\u001b[0m                                                                                  \"([N], %s)\" + \", \".join(\n\u001b[0;32m--> 231\u001b[0;31m                                                                                      in_shape.astype(str).tolist())))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape_needed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: General array mismatch! Given: (1, 4, 600, 1) Expecting: ([N], %s)None, 4"
     ]
    }
   ],
   "source": [
    "# subset model input sequence to bases 250 to 350 for plotting\n",
    "gp.plot(0, limit_region=(250,350))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLI \n",
    "Using the equivalent command in the CLI the same plot can be produced.\n",
    "Before we can do that we have to delete the file that we have just created a minute ago:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.exists(\"example_data/Basset_grad_query_Basset_out.hdf5\"):\n",
    "    os.unlink(\"example_data/Basset_grad_query_Basset_out.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi.sources]\u001b[0m Update /home/avsec/.kipoi/models/\u001b[0m\n",
      "Already up to date.\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi.model]\u001b[0m Downloading model arguments weights from https://zenodo.org/record/1466068/files/pretrained_model_reloaded_th.pth?download=1\u001b[0m\n",
      "Using downloaded and verified file: /home/avsec/.kipoi/models/Basset/downloaded/model_files/weights/4878981d84499eb575abd0f3b45570d3\n",
      "\u001b[32mINFO\u001b[0m \u001b[44m[kipoi.pipeline]\u001b[0m dataloader.output_schema is compatible with model.schema\u001b[0m\n",
      "/home/avsec/bin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]ArraySchema mismatch\n",
      "Array shapes don't match for the fields:\n",
      "--\n",
      "\n",
      "--\n",
      "shape: (None, 4)\n",
      "doc: One-hot encoded DNA sequence\n",
      "name: seq\n",
      "special_type: DNASeq\n",
      "associated_metadata:\n",
      "- ranges\n",
      "\n",
      "--\n",
      "\n",
      "--\n",
      "shape: (4, 600, 1)\n",
      "doc: ''\n",
      "\n",
      "--\n",
      "Provided shape (without the batch axis): (4, 600, 1), expected shape: (None, 4) \n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 44.92it/s]\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! kipoi interpret grad Basset --source kipoi --dataloader_args '{\"fasta_file\": \\\n",
    "   \"example_data/hg19_chr22.fa\", \"intervals_file\": \"example_data/Basset_grad_query_Basset.bed\"}'\\\n",
    "   --layer \"21.1\" --filter_idx 120 --output \"example_data/Basset_grad_query_Basset_out.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can visualise the plot identically in python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avsec/bin/anaconda3/envs/dev-kipoi-py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "General array mismatch! Given: (1, 4, 600, 1) Expecting: ([N], %s)None, 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-2c2962df1e74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# generate the GradPlotter instance:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradPlotter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"example_data/Basset_grad_query_Basset_out.hdf5\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Basset\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit_region\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m350\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-24fdc41e54dd>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, sample, model_input, ax, limit_region, limit_region_genomic, rc_plot, transform_fn, seq_dim, additional_plot_fns, **heatmap_kwargs)\u001b[0m\n\u001b[1;32m    288\u001b[0m                                                                                            \u001b[0mseq_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                                                                                            \u001b[0mrequires_region_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequires_region_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                                                                                            requires_seq_dim=True)\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0max\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-24fdc41e54dd>\u001b[0m in \u001b[0;36m_preprocess_values\u001b[0;34m(self, sample, model_input, limit_region, limit_region_genomic, transform_fn, seq_dim, requires_region_info, requires_seq_dim)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;31m# convert to standard layout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mdna_reshaper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReshapeDna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_seq_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0minput_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdna_reshaper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0mgradient_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdna_reshaper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mseq_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspace/kipoi/kipoi-veff/kipoi_veff/utils/dna_reshapers.py\u001b[0m in \u001b[0;36mto_standard\u001b[0;34m(self, in_array)\u001b[0m\n\u001b[1;32m    229\u001b[0m             raise Exception(\"General array mismatch! Given: %s Expecting: %s\" % (str(in_array.shape),\n\u001b[1;32m    230\u001b[0m                                                                                  \"([N], %s)\" + \", \".join(\n\u001b[0;32m--> 231\u001b[0;31m                                                                                      in_shape.astype(str).tolist())))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape_needed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: General array mismatch! Given: (1, 4, 600, 1) Expecting: ([N], %s)None, 4"
     ]
    }
   ],
   "source": [
    "# generate the GradPlotter instance:\n",
    "gp = GradPlotter.from_hdf5(\"example_data/Basset_grad_query_Basset_out.hdf5\", \"Basset\")\n",
    "gp.plot(0, limit_region=(250,350))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using FactorNet as an example\n",
    "\n",
    "**_WARNING:_** You should restart the kernel at this point, because using a PyTorch model and loading a Keras model at the same time may cause the loading of the Keras model to hang!\n",
    "\n",
    "FactorNet is a model to predict transcription factor binding that also uses open chromatin and mappability tracks as inputs. Here we will illustrate one of the strengths of using gradients to interpret model predictions.\n",
    "\n",
    "Let's start with selecting a CTCF binding site and writing out the corresponding bed file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"example_data/FactorNet_CTCF_grad_query.bed\", \"w\") as ofh:\n",
    "    chrom, center, intervals_len = \"chr22\", 28712021, 1002\n",
    "    start = center - intervals_len//2\n",
    "    end = center + intervals_len//2 + (intervals_len % 2)\n",
    "    ofh.write(\"\\t\".join([chrom, str(start), str(end)]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kipoi\n",
    "fn_model = kipoi.get_model('FactorNet/CTCF/meta_RNAseq_Unique35_DGF', source = \"kipoi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_datalaoder_arguments = fn_model.default_dataloader.example_kwargs\n",
    "# prepend the model path for all path entries in the dataloader arguments.\n",
    "fn_datalaoder_arguments = {k:fn_model.source_dir + \"/\" + v if not k == 'cell_line' else v \n",
    "                           for k,v in fn_datalaoder_arguments.items()}\n",
    "fn_datalaoder_arguments['intervals_file'] = \"example_data/FactorNet_CTCF_grad_query.bed\"\n",
    "\n",
    "# Check if the arguments have been set correctly:\n",
    "fn_datalaoder_arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the gradient calculation pipeline on the `merge3` layer of the model. The model has only one output, so we select that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_preds = fn_model.pipeline.input_grad(fn_datalaoder_arguments, layer ='merge_3', filter_idx = [0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the moment we don't support more complex visualisation for model inputs that are not of the `special_type` `DNASequence`. Therefore and since FactorNet's `seq` input is a 1002x6 input, which is not a one-hot encoded DNA-sequence, so we will have to manually write a small function for plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fnet(input_arr, grad_arr):\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pylab as plt\n",
    "    from kipoi_veff.external.concise.seqplotting_deps import seqlogo\n",
    "    plt.figure(figsize=(14,4))\n",
    "    # calculate the grad*input values:\n",
    "    values = (input_arr*grad_arr).T\n",
    "    # get axes objects\n",
    "    ax_s = plt.subplot(2,1,1)\n",
    "    ax_h = plt.subplot(2,1,2)\n",
    "    # make the plots\n",
    "    seqlogo(values[:4,:].T, ax = ax_s)\n",
    "    sns.heatmap(values[4:5,:], ax = ax_h, cbar=False)\n",
    "    # plot formatting\n",
    "    ax_s.get_xaxis().set_visible(False)\n",
    "    sns.despine(trim = True, ax = ax_s, bottom = True)\n",
    "    ax_h.get_xaxis().set_visible(False)\n",
    "    ax_h.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fnet(grad_preds['inputs'][0][0,450:550,:], grad_preds['grads'][0][0,450:550,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FactorNet has a separate model input for the reverse-complement of the sequence, which is model input `1`. We can visualise it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fnet(grad_preds['inputs'][1][0,450:550,:], grad_preds['grads'][1][0,450:550,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dev-kipoi-py35]",
   "language": "python",
   "name": "conda-env-dev-kipoi-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
