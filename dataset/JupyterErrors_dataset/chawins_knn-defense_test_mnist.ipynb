{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import foolbox\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from lib.dataset_utils import *\n",
    "from lib.mnist_model import *\n",
    "from lib.adv_model import *\n",
    "from lib.dknn_attack_v2 import DKNNAttackV2\n",
    "from lib.cwl2_attack import CWL2Attack\n",
    "from lib.dknn import DKNNL2\n",
    "from lib.utils import *\n",
    "from lib.lip_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all random seeds\n",
    "seed = 2020\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_valid, y_valid), (x_test, y_test) = load_mnist_all(\n",
    "    '/data', val_size=0.1, shuffle=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'mnist_basic.h5'\n",
    "# net = BasicModel()\n",
    "\n",
    "# model_name = 'train_mnist_nca_exp2.h5'\n",
    "# model_name = 'adv_mnist_nca_exp63_epoch119.h5'\n",
    "# model_name = 'adv_mnist_nca_exp80.h5'\n",
    "# # net = NCAModel(output_dim=100, init_it=1, train_data=(x_train, y_train))\n",
    "# net = NCAModelV3(normalize=False, output_dim=20, init_it=1, \n",
    "#                  train_data=(x_train, y_train))\n",
    "\n",
    "# model_name = 'train_mnist_snnl_exp%d.h5' % exp_id\n",
    "# net = SNNLModel(train_it=True)\n",
    "\n",
    "# model_name = 'train_mnist_hidden_mixup_exp%d.h5' % exp_id\n",
    "# net = HiddenMixupModel()\n",
    "\n",
    "# model_name = 'train_mnist_vae_exp%d.h5' % exp_id\n",
    "# # net = VAE((1, 28, 28), num_classes=10, latent_dim=20)\n",
    "# net = VAE2((1, 28, 28), num_classes=10, latent_dim=128)\n",
    "\n",
    "# model_name = 'train_mnist_cav_exp%d.h5' % exp_id\n",
    "# net = ClassAuxVAE((1, 28, 28), num_classes=10, latent_dim=20)\n",
    "\n",
    "# model_name = 'lip_mnist_exp%d.h5' % exp_id\n",
    "# net = LipschitzModel()\n",
    "\n",
    "# model_name = 'dist_mnist_exp%d.h5' % exp_id\n",
    "# init_it = 1\n",
    "# train_it = False\n",
    "# net = NeighborModel(num_classes=10, init_it=init_it, train_it=train_it)\n",
    "\n",
    "# model_name = 'mnist_at.h5'\n",
    "model_name = 'adv_mnist_exp6.h5'\n",
    "basic_net = BasicModel()\n",
    "# basic_net = BasicModelV2()\n",
    "config = {'epsilon': 0.3,\n",
    "          'num_steps': 40,\n",
    "          'step_size': 0.01,\n",
    "          'random_start': True,\n",
    "          'loss_func': 'xent'}\n",
    "net = PGDL2Model(basic_net, config)\n",
    "\n",
    "# model_name = 'lipae_mnist_exp%d.h5' % exp_id\n",
    "# init_it = 1\n",
    "# train_it = False\n",
    "# latent_dim = 128\n",
    "# alpha = 1e2\n",
    "# net = NCA_AE(latent_dim=latent_dim, init_it=init_it,\n",
    "#              train_it=train_it, alpha=alpha)\n",
    "\n",
    "# orig_model = 'adv_mnist_exp2.h5'\n",
    "# model_name = 'tune%d_%s' % (exp_id, orig_model)\n",
    "# net = BasicModel()\n",
    "# from tune_mnist import Identity\n",
    "# net.fc = Identity()\n",
    "\n",
    "# model_name = 'rot_mnist_exp%d.h5' % exp_id\n",
    "# net = BasicModel(num_classes=4)\n",
    "\n",
    "# model_name = 'adv_rot_mnist_exp%d.h5' % exp_id\n",
    "# basic_net = BasicModel(num_classes=4)\n",
    "# config = {'num_steps': 20,\n",
    "#           'step_size': 0.05,\n",
    "#           'random_start': True,\n",
    "#           'loss_func': 'xent'}\n",
    "# net = PGDL2Model(basic_net, config)\n",
    "\n",
    "# model_name = 'ae_mnist_exp%d.h5' % exp_id\n",
    "# net = Autoencoder((1, 28, 28), 128)\n",
    "\n",
    "# model_name = 'adv_mnist_ae_exp%d.h5' % exp_id\n",
    "# basic_net = Autoencoder((1, 28, 28), latent_dim=128)\n",
    "# config = {'num_steps': 40,\n",
    "#               'step_size': 0.1,\n",
    "#               'random_start': True,\n",
    "#               'loss_func': 'xent'}\n",
    "# net = PGDL2Model(basic_net, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicModel(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3))\n",
       "  (relu1): ReLU(inplace=True)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(6, 6), stride=(2, 2), padding=(3, 3))\n",
       "  (relu2): ReLU(inplace=True)\n",
       "  (conv3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu3): ReLU(inplace=True)\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up model directory\n",
    "# save_dir = os.path.join(os.getcwd(), 'saved_models/mnist/')\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models/')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "net = net.to(device)\n",
    "# if device == 'cuda':\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "#     cudnn.benchmark = True\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "# net = net.module\n",
    "net = net.basic_net\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = ['relu1', 'relu2', 'relu3', 'fc']\n",
    "# layers = ['relu3']\n",
    "# layers = ['fc']\n",
    "# layers = ['conv3']\n",
    "# layers = ['en_mu']\n",
    "# layers = ['maxpool1', 'maxpool2', 'relu3', 'fc2']\n",
    "# layers = ['maxpool2']\n",
    "\n",
    "# dknn = DKNN(net, x_train, y_train, x_valid, y_valid, layers, \n",
    "#             k=75, num_classes=10)\n",
    "dknn = DKNNL2(net, x_train, y_train, x_valid, y_valid, layers, \n",
    "              k=75, cosine=True, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_knn = KNNModel()\n",
    "layers = ['identity']\n",
    "dknn = DKNNL2(net_knn, x_train, y_train, \n",
    "              x_test, y_test, layers, \n",
    "              k=5, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9773\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = dknn.classify(x_test)\n",
    "    ind = np.where(y_pred.argmax(1) == y_test.numpy())[0]\n",
    "    print((y_pred.argmax(1) == y_test.numpy()).sum() / y_test.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_batch(attack, x, y, init_mode, init_mode_k, batch_size):\n",
    "    x_adv = torch.zeros_like(x)\n",
    "    total_num = x.size(0)\n",
    "    num_batches = total_num // batch_size\n",
    "    for i in range(num_batches):\n",
    "        begin = i * batch_size\n",
    "        end = (i + 1) * batch_size\n",
    "        x_adv[begin:end] = attack(\n",
    "            x[begin:end], y[begin:end], 2, guide_layer=layers, m=150,\n",
    "            init_mode=init_mode, init_mode_k=init_mode_k,\n",
    "            binary_search_steps=10, max_iterations=1000, learning_rate=1e-1,\n",
    "            initial_const=1e0, max_linf=None, random_start=True,\n",
    "            thres_steps=200, check_adv_steps=200, verbose=False)\n",
    "    return x_adv\n",
    "\n",
    "num = 100\n",
    "\n",
    "def full_eval(dknn):\n",
    "    with torch.no_grad():\n",
    "        y_pred = dknn.classify(x_test)\n",
    "        ind = np.where(y_pred.argmax(1) == y_test.numpy())[0]\n",
    "    print((y_pred.argmax(1) == y_test.numpy()).sum() / y_test.size(0))\n",
    "    \n",
    "    dist_all = np.zeros(num) + 1e9\n",
    "    x_adv_all = x_test[ind][:num].clone()\n",
    "    attack = DKNNAttackV2(dknn)\n",
    "    \n",
    "    x_adv = attack_batch(\n",
    "        attack, x_test[ind][:num].cuda(), y_test[ind][:num], 1, 1, 100)\n",
    "    with torch.no_grad():\n",
    "        y_pred = dknn.classify(x_adv)\n",
    "        ind_adv = y_pred.argmax(1) != y_test[ind][:num].numpy()\n",
    "        dist = (x_adv.cpu() - x_test[ind][:num]).view(\n",
    "            num, -1).norm(2, 1).numpy()\n",
    "    for i in range(num):\n",
    "        if ind_adv[i] and (dist[i] < dist_all[i]):\n",
    "            dist_all[i] = dist[i]\n",
    "            x_adv_all[i] = x_adv[i]\n",
    "            \n",
    "    for k in range(1, 3):\n",
    "        x_adv = attack_batch(\n",
    "            attack, x_test[ind][:num].cuda(), y_test[ind][:num], 2, k, 100)\n",
    "        with torch.no_grad():\n",
    "            y_pred = dknn.classify(x_adv)\n",
    "            ind_adv = y_pred.argmax(1) != y_test[ind][:num].numpy()\n",
    "            dist = (x_adv.cpu() - x_test[ind][:num]).view(\n",
    "                num, -1).norm(2, 1).numpy()\n",
    "        for i in range(num):\n",
    "            if ind_adv[i] and (dist[i] < dist_all[i]):\n",
    "                dist_all[i] = dist[i]\n",
    "                x_adv_all[i] = x_adv[i]\n",
    "                \n",
    "    adv_acc = (dist_all == 1e9).mean()\n",
    "    print('adv accuracy: %.4f, mean dist: %.4f' % (\n",
    "        adv_acc, dist_all[dist_all < 1e9].mean()))\n",
    "    return dist_all, x_adv_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9773\n",
      "    step: 0; loss: 76.239; dist: 0.032\n",
      "    step: 100; loss: 24.533; dist: 3.274\n",
      "    step: 200; loss: 18.099; dist: 3.281\n",
      "    step: 300; loss: 16.804; dist: 3.344\n",
      "    step: 400; loss: 17.321; dist: 3.350\n",
      "    step: 500; loss: 17.016; dist: 3.404\n",
      "    step: 600; loss: 17.301; dist: 3.394\n",
      "    step: 700; loss: 17.162; dist: 3.424\n",
      "    step: 800; loss: 17.482; dist: 3.430\n",
      "    step: 900; loss: 17.423; dist: 3.464\n",
      "binary step: 0; num successful adv: 100/100\n",
      "binary step: 0; num successful adv so far: 100/100\n",
      "    step: 0; loss: 7.297; dist: 0.032\n",
      "    step: 100; loss: 6.518; dist: 0.916\n",
      "    step: 200; loss: 6.443; dist: 0.939\n",
      "    step: 300; loss: 6.423; dist: 0.998\n",
      "    step: 400; loss: 6.426; dist: 1.000\n",
      "    step: 500; loss: 6.423; dist: 1.020\n",
      "    step: 600; loss: 6.431; dist: 1.022\n",
      "    step: 700; loss: 6.428; dist: 1.026\n",
      "    step: 800; loss: 6.428; dist: 1.026\n",
      "    step: 900; loss: 6.427; dist: 1.032\n",
      "binary step: 1; num successful adv: 5/100\n",
      "binary step: 1; num successful adv so far: 100/100\n",
      "    step: 0; loss: 38.450; dist: 0.032\n",
      "    step: 100; loss: 17.355; dist: 2.764\n",
      "    step: 200; loss: 13.778; dist: 2.775\n",
      "    step: 300; loss: 13.181; dist: 2.843\n",
      "    step: 400; loss: 13.262; dist: 2.836\n",
      "    step: 500; loss: 13.144; dist: 2.871\n",
      "    step: 600; loss: 13.272; dist: 2.873\n",
      "    step: 700; loss: 13.212; dist: 2.896\n",
      "    step: 800; loss: 13.270; dist: 2.894\n",
      "    step: 900; loss: 13.247; dist: 2.905\n",
      "binary step: 2; num successful adv: 96/100\n",
      "binary step: 2; num successful adv so far: 100/100\n",
      "    step: 0; loss: 20.145; dist: 0.033\n",
      "    step: 100; loss: 12.529; dist: 2.219\n",
      "    step: 200; loss: 11.034; dist: 2.228\n",
      "    step: 300; loss: 10.649; dist: 2.344\n",
      "    step: 400; loss: 10.599; dist: 2.343\n",
      "    step: 500; loss: 10.497; dist: 2.371\n",
      "    step: 600; loss: 10.507; dist: 2.375\n",
      "    step: 700; loss: 10.481; dist: 2.387\n",
      "    step: 800; loss: 10.492; dist: 2.396\n",
      "    step: 900; loss: 10.480; dist: 2.402\n",
      "binary step: 3; num successful adv: 67/100\n",
      "binary step: 3; num successful adv so far: 100/100\n",
      "    step: 0; loss: 17.120; dist: 0.032\n",
      "    step: 100; loss: 11.539; dist: 1.985\n",
      "    step: 200; loss: 10.406; dist: 1.997\n",
      "    step: 300; loss: 10.057; dist: 2.117\n",
      "    step: 400; loss: 9.913; dist: 2.129\n",
      "    step: 500; loss: 9.835; dist: 2.164\n",
      "    step: 600; loss: 9.822; dist: 2.161\n",
      "    step: 700; loss: 9.790; dist: 2.176\n",
      "    step: 800; loss: 9.797; dist: 2.179\n",
      "    step: 900; loss: 9.775; dist: 2.186\n",
      "binary step: 4; num successful adv: 50/100\n",
      "binary step: 4; num successful adv so far: 100/100\n",
      "    step: 0; loss: 16.231; dist: 0.032\n",
      "    step: 100; loss: 11.212; dist: 1.923\n",
      "    step: 200; loss: 10.196; dist: 1.929\n",
      "    step: 300; loss: 9.864; dist: 2.055\n",
      "    step: 400; loss: 9.773; dist: 2.063\n",
      "    step: 500; loss: 9.663; dist: 2.105\n",
      "    step: 600; loss: 9.661; dist: 2.100\n",
      "    step: 700; loss: 9.626; dist: 2.106\n",
      "    step: 800; loss: 9.619; dist: 2.112\n",
      "    step: 900; loss: 9.593; dist: 2.129\n",
      "binary step: 5; num successful adv: 29/100\n",
      "binary step: 5; num successful adv so far: 100/100\n",
      "    step: 0; loss: 16.271; dist: 0.032\n",
      "    step: 100; loss: 11.216; dist: 1.951\n",
      "    step: 200; loss: 10.251; dist: 1.968\n",
      "    step: 300; loss: 9.890; dist: 2.109\n",
      "    step: 400; loss: 9.739; dist: 2.114\n",
      "    step: 500; loss: 9.652; dist: 2.148\n",
      "    step: 600; loss: 9.636; dist: 2.154\n",
      "    step: 700; loss: 9.606; dist: 2.172\n",
      "    step: 800; loss: 9.618; dist: 2.172\n",
      "    step: 900; loss: 9.594; dist: 2.172\n",
      "binary step: 6; num successful adv: 38/100\n",
      "binary step: 6; num successful adv so far: 100/100\n",
      "    step: 0; loss: 15.414; dist: 0.032\n",
      "    step: 100; loss: 10.842; dist: 1.874\n",
      "    step: 200; loss: 10.007; dist: 1.892\n",
      "    step: 300; loss: 9.680; dist: 2.050\n",
      "    step: 400; loss: 9.593; dist: 2.034\n",
      "    step: 500; loss: 9.466; dist: 2.091\n",
      "    step: 600; loss: 9.422; dist: 2.094\n",
      "    step: 700; loss: 9.385; dist: 2.117\n",
      "    step: 800; loss: 9.381; dist: 2.116\n",
      "    step: 900; loss: 9.359; dist: 2.136\n",
      "binary step: 7; num successful adv: 19/100\n",
      "binary step: 7; num successful adv so far: 100/100\n",
      "    step: 0; loss: 15.140; dist: 0.032\n",
      "    step: 100; loss: 10.729; dist: 1.858\n",
      "    step: 200; loss: 9.932; dist: 1.872\n",
      "    step: 300; loss: 9.586; dist: 2.031\n",
      "    step: 400; loss: 9.495; dist: 2.021\n",
      "    step: 500; loss: 9.402; dist: 2.072\n",
      "    step: 600; loss: 9.364; dist: 2.071\n",
      "    step: 700; loss: 9.326; dist: 2.096\n",
      "    step: 800; loss: 9.322; dist: 2.101\n",
      "    step: 900; loss: 9.313; dist: 2.101\n",
      "binary step: 8; num successful adv: 17/100\n",
      "binary step: 8; num successful adv so far: 100/100\n",
      "    step: 0; loss: 14.557; dist: 0.032\n",
      "    step: 100; loss: 10.478; dist: 1.829\n",
      "    step: 200; loss: 9.753; dist: 1.857\n",
      "    step: 300; loss: 9.460; dist: 2.001\n",
      "    step: 400; loss: 9.368; dist: 2.007\n",
      "    step: 500; loss: 9.278; dist: 2.053\n",
      "    step: 600; loss: 9.272; dist: 2.049\n",
      "    step: 700; loss: 9.230; dist: 2.074\n",
      "    step: 800; loss: 9.223; dist: 2.074\n",
      "    step: 900; loss: 9.202; dist: 2.084\n",
      "binary step: 9; num successful adv: 6/100\n",
      "binary step: 9; num successful adv so far: 100/100\n",
      "    step: 0; loss: 111.099; dist: 9.780\n",
      "    step: 100; loss: 44.984; dist: 5.957\n",
      "    step: 200; loss: 41.552; dist: 5.946\n",
      "    step: 300; loss: 39.761; dist: 5.771\n",
      "    step: 400; loss: 39.217; dist: 5.770\n",
      "    step: 500; loss: 38.804; dist: 5.713\n",
      "    step: 600; loss: 38.763; dist: 5.725\n",
      "    step: 700; loss: 38.575; dist: 5.699\n",
      "    step: 800; loss: 38.473; dist: 5.691\n",
      "    step: 900; loss: 38.464; dist: 5.705\n",
      "binary step: 0; num successful adv: 100/100\n",
      "binary step: 0; num successful adv so far: 100/100\n",
      "    step: 0; loss: 99.394; dist: 9.780\n",
      "    step: 100; loss: 20.265; dist: 1.845\n",
      "    step: 200; loss: 10.902; dist: 1.831\n",
      "    step: 300; loss: 7.990; dist: 1.333\n",
      "    step: 400; loss: 7.782; dist: 1.343\n",
      "    step: 500; loss: 7.598; dist: 1.345\n",
      "    step: 600; loss: 7.593; dist: 1.349\n",
      "    step: 700; loss: 7.476; dist: 1.346\n",
      "    step: 800; loss: 7.487; dist: 1.336\n",
      "    step: 900; loss: 7.476; dist: 1.347\n",
      "binary step: 1; num successful adv: 9/100\n",
      "binary step: 1; num successful adv so far: 100/100\n",
      "    step: 0; loss: 104.716; dist: 9.780\n",
      "    step: 100; loss: 37.075; dist: 5.130\n",
      "    step: 200; loss: 33.155; dist: 5.123\n",
      "    step: 300; loss: 31.384; dist: 4.902\n",
      "    step: 400; loss: 30.530; dist: 4.904\n",
      "    step: 500; loss: 30.095; dist: 4.829\n",
      "    step: 600; loss: 30.259; dist: 4.833\n",
      "    step: 700; loss: 29.530; dist: 4.781\n",
      "    step: 800; loss: 29.485; dist: 4.783\n",
      "    step: 900; loss: 29.227; dist: 4.763\n",
      "binary step: 2; num successful adv: 92/100\n",
      "binary step: 2; num successful adv so far: 100/100\n",
      "    step: 0; loss: 101.525; dist: 9.779\n",
      "    step: 100; loss: 32.951; dist: 4.614\n",
      "    step: 200; loss: 27.358; dist: 4.606\n",
      "    step: 300; loss: 24.965; dist: 4.305\n",
      "    step: 400; loss: 23.938; dist: 4.293\n",
      "    step: 500; loss: 23.289; dist: 4.181\n",
      "    step: 600; loss: 22.940; dist: 4.180\n",
      "    step: 700; loss: 22.587; dist: 4.114\n",
      "    step: 800; loss: 22.319; dist: 4.112\n",
      "    step: 900; loss: 22.096; dist: 4.076\n",
      "binary step: 3; num successful adv: 70/100\n",
      "binary step: 3; num successful adv so far: 100/100\n",
      "    step: 0; loss: 101.134; dist: 9.780\n",
      "    step: 100; loss: 30.487; dist: 4.121\n",
      "    step: 200; loss: 23.109; dist: 4.110\n",
      "    step: 300; loss: 20.184; dist: 3.615\n",
      "    step: 400; loss: 18.998; dist: 3.601\n",
      "    step: 500; loss: 18.361; dist: 3.494\n",
      "    step: 600; loss: 18.217; dist: 3.492\n",
      "    step: 700; loss: 17.612; dist: 3.423\n",
      "    step: 800; loss: 17.551; dist: 3.411\n",
      "    step: 900; loss: 17.261; dist: 3.372\n",
      "binary step: 4; num successful adv: 58/100\n",
      "binary step: 4; num successful adv so far: 100/100\n",
      "    step: 0; loss: 100.809; dist: 9.779\n",
      "    step: 100; loss: 29.380; dist: 3.873\n",
      "    step: 200; loss: 22.115; dist: 3.807\n",
      "    step: 300; loss: 18.775; dist: 3.323\n",
      "    step: 400; loss: 17.635; dist: 3.306\n",
      "    step: 500; loss: 17.061; dist: 3.187\n",
      "    step: 600; loss: 16.708; dist: 3.188\n",
      "    step: 700; loss: 15.959; dist: 3.068\n",
      "    step: 800; loss: 15.533; dist: 3.060\n",
      "    step: 900; loss: 15.372; dist: 3.026\n",
      "binary step: 5; num successful adv: 34/100\n",
      "binary step: 5; num successful adv so far: 100/100\n",
      "    step: 0; loss: 100.758; dist: 9.779\n",
      "    step: 100; loss: 29.222; dist: 3.819\n",
      "    step: 200; loss: 21.329; dist: 3.823\n",
      "    step: 300; loss: 18.492; dist: 3.348\n",
      "    step: 400; loss: 17.478; dist: 3.371\n",
      "    step: 500; loss: 16.853; dist: 3.262\n",
      "    step: 600; loss: 16.567; dist: 3.247\n",
      "    step: 700; loss: 15.980; dist: 3.162\n",
      "    step: 800; loss: 15.711; dist: 3.150\n",
      "    step: 900; loss: 15.580; dist: 3.109\n",
      "binary step: 6; num successful adv: 34/100\n",
      "binary step: 6; num successful adv so far: 100/100\n",
      "    step: 0; loss: 100.596; dist: 9.780\n",
      "    step: 100; loss: 28.923; dist: 3.727\n",
      "    step: 200; loss: 20.996; dist: 3.722\n",
      "    step: 300; loss: 17.549; dist: 3.155\n",
      "    step: 400; loss: 16.146; dist: 3.144\n",
      "    step: 500; loss: 15.505; dist: 3.029\n",
      "    step: 600; loss: 15.038; dist: 3.026\n",
      "    step: 700; loss: 14.687; dist: 2.954\n",
      "    step: 800; loss: 14.461; dist: 2.953\n",
      "    step: 900; loss: 14.380; dist: 2.930\n",
      "binary step: 7; num successful adv: 20/100\n",
      "binary step: 7; num successful adv so far: 100/100\n",
      "    step: 0; loss: 100.578; dist: 9.779\n",
      "    step: 100; loss: 28.778; dist: 3.637\n",
      "    step: 200; loss: 20.319; dist: 3.626\n",
      "    step: 300; loss: 16.987; dist: 3.109\n",
      "    step: 400; loss: 15.904; dist: 3.096\n",
      "    step: 500; loss: 14.858; dist: 2.919\n",
      "    step: 600; loss: 14.287; dist: 2.912\n",
      "    step: 700; loss: 13.913; dist: 2.837\n",
      "    step: 800; loss: 13.731; dist: 2.845\n",
      "    step: 900; loss: 13.593; dist: 2.809\n",
      "binary step: 8; num successful adv: 16/100\n",
      "binary step: 8; num successful adv so far: 100/100\n",
      "    step: 0; loss: 100.500; dist: 9.780\n",
      "    step: 100; loss: 28.169; dist: 3.458\n",
      "    step: 200; loss: 19.422; dist: 3.462\n",
      "    step: 300; loss: 15.895; dist: 2.926\n",
      "    step: 400; loss: 14.941; dist: 2.918\n",
      "    step: 500; loss: 14.150; dist: 2.807\n",
      "    step: 600; loss: 13.774; dist: 2.810\n",
      "    step: 700; loss: 13.544; dist: 2.767\n",
      "    step: 800; loss: 13.378; dist: 2.766\n",
      "    step: 900; loss: 13.208; dist: 2.736\n",
      "binary step: 9; num successful adv: 9/100\n",
      "binary step: 9; num successful adv so far: 100/100\n",
      "    step: 0; loss: 112.168; dist: 10.107\n",
      "    step: 100; loss: 47.987; dist: 6.279\n",
      "    step: 200; loss: 44.683; dist: 6.272\n",
      "    step: 300; loss: 42.931; dist: 6.072\n",
      "    step: 400; loss: 42.528; dist: 6.068\n",
      "    step: 500; loss: 41.687; dist: 5.989\n",
      "    step: 600; loss: 41.279; dist: 5.997\n",
      "    step: 700; loss: 41.167; dist: 5.983\n",
      "    step: 800; loss: 41.166; dist: 5.993\n",
      "    step: 900; loss: 41.035; dist: 5.980\n",
      "binary step: 0; num successful adv: 100/100\n",
      "binary step: 0; num successful adv so far: 100/100\n",
      "    step: 0; loss: 104.462; dist: 10.107\n",
      "    step: 100; loss: 21.792; dist: 2.014\n",
      "    step: 200; loss: 11.793; dist: 1.995\n",
      "    step: 300; loss: 8.575; dist: 1.386\n",
      "    step: 400; loss: 8.345; dist: 1.399\n",
      "    step: 500; loss: 8.248; dist: 1.393\n",
      "    step: 600; loss: 8.190; dist: 1.402\n",
      "    step: 700; loss: 8.193; dist: 1.387\n",
      "    step: 800; loss: 8.222; dist: 1.397\n",
      "    step: 900; loss: 8.150; dist: 1.387\n",
      "binary step: 1; num successful adv: 13/100\n",
      "binary step: 1; num successful adv so far: 100/100\n",
      "    step: 0; loss: 107.836; dist: 10.107\n",
      "    step: 100; loss: 38.039; dist: 5.105\n",
      "    step: 200; loss: 33.620; dist: 5.104\n",
      "    step: 300; loss: 31.682; dist: 4.861\n",
      "    step: 400; loss: 30.595; dist: 4.858\n",
      "    step: 500; loss: 30.189; dist: 4.785\n",
      "    step: 600; loss: 30.124; dist: 4.791\n",
      "    step: 700; loss: 29.624; dist: 4.751\n",
      "    step: 800; loss: 29.557; dist: 4.756\n",
      "    step: 900; loss: 29.441; dist: 4.733\n",
      "binary step: 2; num successful adv: 88/100\n",
      "binary step: 2; num successful adv so far: 100/100\n",
      "    step: 0; loss: 105.799; dist: 10.107\n",
      "    step: 100; loss: 34.322; dist: 4.651\n",
      "    step: 200; loss: 28.007; dist: 4.627\n",
      "    step: 300; loss: 25.425; dist: 4.287\n",
      "    step: 400; loss: 24.579; dist: 4.282\n",
      "    step: 500; loss: 23.685; dist: 4.153\n",
      "    step: 600; loss: 23.156; dist: 4.149\n",
      "    step: 700; loss: 22.836; dist: 4.070\n",
      "    step: 800; loss: 22.732; dist: 4.077\n",
      "    step: 900; loss: 22.204; dist: 4.017\n",
      "binary step: 3; num successful adv: 73/100\n",
      "binary step: 3; num successful adv so far: 100/100\n",
      "    step: 0; loss: 105.434; dist: 10.107\n",
      "    step: 100; loss: 31.535; dist: 4.085\n",
      "    step: 200; loss: 23.615; dist: 4.051\n",
      "    step: 300; loss: 20.586; dist: 3.550\n",
      "    step: 400; loss: 19.757; dist: 3.547\n",
      "    step: 500; loss: 18.540; dist: 3.399\n",
      "    step: 600; loss: 18.267; dist: 3.398\n",
      "    step: 700; loss: 17.471; dist: 3.285\n",
      "    step: 800; loss: 17.280; dist: 3.290\n",
      "    step: 900; loss: 17.064; dist: 3.250\n",
      "binary step: 4; num successful adv: 41/100\n",
      "binary step: 4; num successful adv so far: 100/100\n",
      "    step: 0; loss: 105.603; dist: 10.107\n",
      "    step: 100; loss: 31.098; dist: 3.999\n",
      "    step: 200; loss: 23.452; dist: 3.989\n",
      "    step: 300; loss: 19.630; dist: 3.416\n",
      "    step: 400; loss: 18.898; dist: 3.407\n",
      "    step: 500; loss: 17.088; dist: 3.123\n",
      "    step: 600; loss: 16.519; dist: 3.119\n",
      "    step: 700; loss: 16.150; dist: 3.082\n",
      "    step: 800; loss: 15.832; dist: 3.077\n",
      "    step: 900; loss: 15.654; dist: 3.022\n",
      "binary step: 5; num successful adv: 41/100\n",
      "binary step: 5; num successful adv so far: 100/100\n",
      "    step: 0; loss: 105.328; dist: 10.107\n",
      "    step: 100; loss: 30.894; dist: 3.984\n",
      "    step: 200; loss: 23.159; dist: 3.963\n",
      "    step: 300; loss: 19.021; dist: 3.360\n",
      "    step: 400; loss: 18.045; dist: 3.364\n",
      "    step: 500; loss: 17.118; dist: 3.212\n",
      "    step: 600; loss: 16.471; dist: 3.213\n",
      "    step: 700; loss: 16.054; dist: 3.102\n",
      "    step: 800; loss: 15.674; dist: 3.100\n",
      "    step: 900; loss: 15.542; dist: 3.071\n",
      "binary step: 6; num successful adv: 24/100\n",
      "binary step: 6; num successful adv so far: 100/100\n",
      "    step: 0; loss: 105.350; dist: 10.107\n",
      "    step: 100; loss: 30.719; dist: 3.912\n",
      "    step: 200; loss: 22.918; dist: 3.914\n",
      "    step: 300; loss: 18.907; dist: 3.325\n",
      "    step: 400; loss: 18.126; dist: 3.323\n",
      "    step: 500; loss: 16.854; dist: 3.177\n",
      "    step: 600; loss: 16.296; dist: 3.175\n",
      "    step: 700; loss: 15.850; dist: 3.077\n",
      "    step: 800; loss: 15.430; dist: 3.080\n",
      "    step: 900; loss: 15.173; dist: 3.035\n",
      "binary step: 7; num successful adv: 21/100\n",
      "binary step: 7; num successful adv so far: 100/100\n",
      "    step: 0; loss: 105.298; dist: 10.107\n",
      "    step: 100; loss: 30.605; dist: 3.870\n",
      "    step: 200; loss: 22.441; dist: 3.870\n",
      "    step: 300; loss: 18.326; dist: 3.245\n",
      "    step: 400; loss: 17.335; dist: 3.242\n",
      "    step: 500; loss: 16.140; dist: 3.063\n",
      "    step: 600; loss: 15.576; dist: 3.046\n",
      "    step: 700; loss: 14.863; dist: 2.912\n",
      "    step: 800; loss: 14.492; dist: 2.913\n",
      "    step: 900; loss: 13.818; dist: 2.794\n",
      "binary step: 8; num successful adv: 17/100\n",
      "binary step: 8; num successful adv so far: 100/100\n",
      "    step: 0; loss: 105.220; dist: 10.107\n",
      "    step: 100; loss: 29.978; dist: 3.653\n",
      "    step: 200; loss: 20.959; dist: 3.639\n",
      "    step: 300; loss: 16.313; dist: 2.927\n",
      "    step: 400; loss: 15.414; dist: 2.934\n",
      "    step: 500; loss: 14.478; dist: 2.803\n",
      "    step: 600; loss: 14.102; dist: 2.806\n",
      "    step: 700; loss: 13.837; dist: 2.740\n",
      "    step: 800; loss: 13.572; dist: 2.743\n",
      "    step: 900; loss: 13.037; dist: 2.627\n",
      "binary step: 9; num successful adv: 10/100\n",
      "binary step: 9; num successful adv so far: 100/100\n",
      "adv accuracy: 0.0000, mean dist: 2.4632\n",
      "2673.538006544113\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "dist, x_adv = full_eval(dknn)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.4499070656299593"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step: 0; loss: 559.819; l2dist: 0.032\n",
      "    step: 100; loss: 513.798; l2dist: 3.763\n",
      "    step: 200; loss: 513.769; l2dist: 3.772\n",
      "binary step: 0; num successful adv: 98/100\n",
      "binary step: 0; num successful adv so far: 98/100\n",
      "    step: 0; loss: 388.695; l2dist: 0.032\n",
      "    step: 100; loss: 364.403; l2dist: 3.097\n",
      "    step: 200; loss: 364.281; l2dist: 3.103\n",
      "    step: 300; loss: 364.280; l2dist: 3.105\n",
      "binary step: 1; num successful adv: 75/100\n",
      "binary step: 1; num successful adv so far: 100/100\n",
      "    step: 0; loss: 272.103; l2dist: 0.032\n",
      "    step: 100; loss: 257.084; l2dist: 2.607\n",
      "    step: 200; loss: 257.064; l2dist: 2.608\n",
      "binary step: 2; num successful adv: 47/100\n",
      "binary step: 2; num successful adv so far: 100/100\n",
      "    step: 0; loss: 252.374; l2dist: 0.032\n",
      "    step: 100; loss: 238.729; l2dist: 2.574\n",
      "    step: 200; loss: 238.709; l2dist: 2.581\n",
      "binary step: 3; num successful adv: 48/100\n",
      "binary step: 3; num successful adv so far: 100/100\n",
      "    step: 0; loss: 241.471; l2dist: 0.032\n",
      "    step: 100; loss: 228.726; l2dist: 2.642\n",
      "    step: 200; loss: 228.703; l2dist: 2.626\n",
      "    step: 300; loss: 228.686; l2dist: 2.650\n",
      "binary step: 4; num successful adv: 55/100\n",
      "binary step: 4; num successful adv so far: 100/100\n",
      "    step: 0; loss: 233.557; l2dist: 0.032\n",
      "    step: 100; loss: 221.465; l2dist: 2.603\n",
      "    step: 200; loss: 221.423; l2dist: 2.613\n",
      "    step: 300; loss: 221.426; l2dist: 2.605\n",
      "binary step: 5; num successful adv: 46/100\n",
      "binary step: 5; num successful adv so far: 100/100\n",
      "    step: 0; loss: 234.280; l2dist: 0.032\n",
      "    step: 100; loss: 222.151; l2dist: 2.630\n",
      "    step: 200; loss: 222.149; l2dist: 2.639\n",
      "binary step: 6; num successful adv: 52/100\n",
      "binary step: 6; num successful adv so far: 100/100\n",
      "    step: 0; loss: 235.625; l2dist: 0.032\n",
      "    step: 100; loss: 223.431; l2dist: 2.604\n",
      "    step: 200; loss: 223.406; l2dist: 2.617\n",
      "    step: 300; loss: 223.410; l2dist: 2.625\n",
      "binary step: 7; num successful adv: 48/100\n",
      "binary step: 7; num successful adv so far: 100/100\n",
      "    step: 0; loss: 235.722; l2dist: 0.032\n",
      "    step: 100; loss: 223.528; l2dist: 2.618\n",
      "    step: 200; loss: 223.504; l2dist: 2.634\n",
      "    step: 300; loss: 223.508; l2dist: 2.622\n",
      "binary step: 8; num successful adv: 46/100\n",
      "binary step: 8; num successful adv so far: 100/100\n",
      "    step: 0; loss: 237.287; l2dist: 0.033\n",
      "    step: 100; loss: 224.972; l2dist: 2.623\n",
      "    step: 200; loss: 224.951; l2dist: 2.633\n",
      "binary step: 9; num successful adv: 53/100\n",
      "binary step: 9; num successful adv so far: 100/100\n"
     ]
    }
   ],
   "source": [
    "# Attack for L2 DkNN\n",
    "from lib.dknn_attack_l2_v1 import DKNNL2AttackV1\n",
    "attack = DKNNL2AttackV1()\n",
    "\n",
    "def attack_batch(x, y, batch_size):\n",
    "    x_adv = torch.zeros_like(x)\n",
    "    total_num = x.size(0)\n",
    "    num_batches = total_num // batch_size\n",
    "    for i in range(num_batches):\n",
    "        begin = i * batch_size\n",
    "        end = (i + 1) * batch_size\n",
    "        x_adv[begin:end] = attack(\n",
    "            dknn, x[begin:end], y[begin:end],\n",
    "            guide_layer=layers[0], m=100, binary_search_steps=10,\n",
    "            max_iterations=1000, learning_rate=1e-1, guide_mode=1,\n",
    "            initial_const=1e1, abort_early=True, random_start=True)\n",
    "    return x_adv\n",
    "\n",
    "num = 100\n",
    "x_adv = attack_batch(x_test[ind][:num].cuda(), y_test[ind][:num], 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean dist:  2.679206609725952\n",
      "success rate:  1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = dknn.classify(x_adv)\n",
    "    ind_adv = np.where(y_pred.argmax(1) != y_test[ind][:num].numpy())[0]\n",
    "    dist = (x_adv.cpu() - x_test[ind][:num]).view(num, -1).norm(2, 1)\n",
    "    print('mean dist: ', dist[ind_adv].mean().item())\n",
    "    print('success rate: ', (len(ind_adv) / num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attack = DKNNAttackV2(dknn)\n",
    "num = 100\n",
    "x_adv = attack_batch(\n",
    "    attack, x_test[ind][:num].cuda(), y_test[ind][:num], 1, 1, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adv accuracy: 0.0000, mean dist: 2.6240\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = dknn.classify(x_adv)\n",
    "    ind_adv = np.where(y_pred.argmax(1) != y_test[ind][:num].numpy())[0]\n",
    "    adv_acc = (y_pred.argmax(1) == y_test[ind][:num].numpy()).sum() \\\n",
    "        / y_pred.shape[0]\n",
    "    dist = (x_adv.cpu() - x_test[ind][:num]).view(\n",
    "        num, -1).norm(2, 1)[ind_adv].mean()\n",
    "print('adv accuracy: %.4f, mean dist: %.4f' % (adv_acc, dist.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.recompute_train_rep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = len(x_train)\n",
    "train_rep = net.get_train_rep(requires_grad=False)\n",
    "y_pred = torch.zeros((train_len, 10))\n",
    "mask = []\n",
    "for i in range(10):\n",
    "    mask.append((y_train == i).float().cuda())\n",
    "for i in range(train_len):\n",
    "    dist = ((train_rep[i].unsqueeze(0) - train_rep) ** 2).sum(1)\n",
    "    exp = torch.clamp(- dist * net.log_it.exp(), - 50, 50).exp()\n",
    "    exp[i] = 0\n",
    "    exp_sum = exp.sum()\n",
    "    for j in range(net.num_classes):\n",
    "        y_pred[i, j] = (mask[j] * exp).sum() / exp_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_train = np.where((y_pred.argmax(1) == y_train).numpy())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = ['fc']\n",
    "dknn = DKNNL2(net, x_train[ind_train], y_train[ind_train], \n",
    "              x_valid, y_valid, layers, k=50, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9738\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = dknn.classify(x_test)\n",
    "    ind = np.where(y_pred.argmax(1) == y_test.numpy())[0]\n",
    "    print((y_pred.argmax(1) == y_test.numpy()).sum() / y_test.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_train = np.arange(len(x_train))\n",
    "np.random.shuffle(ind_train)\n",
    "ind_train = ind_train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.train_data = (x_train[ind_train], y_train[ind_train])\n",
    "# net.train_data = (x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.recompute_train_rep()\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch_size = 200\n",
    "    num_batches = int(np.ceil(len(x_test) / batch_size))\n",
    "    logits = np.zeros((len(x_test), 10))\n",
    "    for i in range(num_batches):\n",
    "        logits[i * batch_size:(i + 1) * batch_size] = net.compute_logits(\n",
    "            x_test[i * batch_size:(i + 1) * batch_size].cuda()).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9612\n"
     ]
    }
   ],
   "source": [
    "ind = logits.argmax(1) == y_test.numpy()\n",
    "ind = np.where(ind)[0]\n",
    "print(len(ind) / len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.cwl2_attack import CWL2AttackNCA\n",
    "attack = CWL2AttackNCA(net)\n",
    "num = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step: 0; loss: 0.639; l2dist: 0.000\n",
      "    step: 100; loss: 0.652; l2dist: 0.126\n",
      "binary step: 0; number of successful adv: 0/100\n",
      "    step: 0; loss: 6.496; l2dist: 0.322\n",
      "    step: 100; loss: 5.939; l2dist: 0.497\n",
      "    step: 200; loss: 5.930; l2dist: 0.511\n",
      "    step: 300; loss: 5.933; l2dist: 0.511\n",
      "binary step: 1; number of successful adv: 12/100\n",
      "    step: 0; loss: 57.690; l2dist: 0.322\n",
      "    step: 100; loss: 16.561; l2dist: 2.690\n",
      "    step: 200; loss: 16.197; l2dist: 2.659\n",
      "    step: 300; loss: 16.097; l2dist: 2.654\n",
      "    step: 400; loss: 16.039; l2dist: 2.644\n",
      "    step: 500; loss: 15.999; l2dist: 2.644\n",
      "    step: 600; loss: 16.058; l2dist: 2.653\n",
      "binary step: 2; number of successful adv: 77/100\n",
      "    step: 0; loss: 174.042; l2dist: 0.321\n",
      "    step: 100; loss: 22.512; l2dist: 3.363\n",
      "    step: 200; loss: 22.267; l2dist: 3.411\n",
      "    step: 300; loss: 21.797; l2dist: 3.366\n",
      "    step: 400; loss: 18.350; l2dist: 3.205\n",
      "    step: 500; loss: 18.269; l2dist: 3.169\n",
      "    step: 600; loss: 18.225; l2dist: 3.142\n",
      "    step: 700; loss: 18.196; l2dist: 3.144\n",
      "    step: 800; loss: 18.207; l2dist: 3.157\n",
      "binary step: 3; number of successful adv: 98/100\n",
      "    step: 0; loss: 243.309; l2dist: 0.324\n",
      "    step: 100; loss: 14.212; l2dist: 3.138\n",
      "    step: 200; loss: 13.953; l2dist: 3.141\n",
      "    step: 300; loss: 13.579; l2dist: 3.080\n",
      "    step: 400; loss: 13.872; l2dist: 3.146\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 142.527; l2dist: 0.327\n",
      "    step: 100; loss: 15.468; l2dist: 3.094\n",
      "    step: 200; loss: 15.189; l2dist: 3.094\n",
      "    step: 300; loss: 14.996; l2dist: 3.054\n",
      "    step: 400; loss: 15.183; l2dist: 3.077\n",
      "binary step: 5; number of successful adv: 100/100\n",
      "    step: 0; loss: 94.035; l2dist: 0.325\n",
      "    step: 100; loss: 24.869; l2dist: 3.582\n",
      "    step: 200; loss: 24.147; l2dist: 3.565\n",
      "    step: 300; loss: 23.848; l2dist: 3.578\n",
      "    step: 400; loss: 23.693; l2dist: 3.567\n",
      "    step: 500; loss: 23.674; l2dist: 3.565\n",
      "    step: 600; loss: 23.689; l2dist: 3.571\n",
      "binary step: 6; number of successful adv: 100/100\n",
      "    step: 0; loss: 88.829; l2dist: 0.322\n",
      "    step: 100; loss: 21.810; l2dist: 3.407\n",
      "    step: 200; loss: 21.243; l2dist: 3.354\n",
      "    step: 300; loss: 21.091; l2dist: 3.349\n",
      "    step: 400; loss: 21.024; l2dist: 3.344\n",
      "    step: 500; loss: 21.020; l2dist: 3.351\n",
      "    step: 600; loss: 21.013; l2dist: 3.348\n",
      "    step: 700; loss: 21.038; l2dist: 3.349\n",
      "binary step: 7; number of successful adv: 100/100\n",
      "    step: 0; loss: 86.234; l2dist: 0.321\n",
      "    step: 100; loss: 24.027; l2dist: 3.757\n",
      "    step: 200; loss: 15.638; l2dist: 3.073\n",
      "    step: 300; loss: 15.579; l2dist: 3.073\n",
      "    step: 400; loss: 15.470; l2dist: 3.031\n",
      "    step: 500; loss: 15.465; l2dist: 3.037\n",
      "    step: 600; loss: 15.479; l2dist: 3.043\n",
      "binary step: 8; number of successful adv: 100/100\n",
      "    step: 0; loss: 87.037; l2dist: 0.324\n",
      "    step: 100; loss: 24.000; l2dist: 3.802\n",
      "    step: 200; loss: 22.838; l2dist: 3.701\n",
      "    step: 300; loss: 22.689; l2dist: 3.706\n",
      "    step: 400; loss: 22.570; l2dist: 3.681\n",
      "    step: 500; loss: 22.538; l2dist: 3.676\n",
      "    step: 600; loss: 22.575; l2dist: 3.676\n",
      "binary step: 9; number of successful adv: 100/100\n",
      "    step: 0; loss: 38.995; l2dist: 6.178\n",
      "    step: 100; loss: 0.661; l2dist: 0.164\n",
      "    step: 200; loss: 0.662; l2dist: 0.167\n",
      "binary step: 0; number of successful adv: 100/100\n",
      "    step: 0; loss: 39.060; l2dist: 6.182\n",
      "    step: 100; loss: 5.889; l2dist: 0.732\n",
      "    step: 200; loss: 5.876; l2dist: 0.733\n",
      "    step: 300; loss: 5.877; l2dist: 0.737\n",
      "binary step: 1; number of successful adv: 100/100\n",
      "    step: 0; loss: 39.216; l2dist: 6.184\n",
      "    step: 100; loss: 12.893; l2dist: 3.371\n",
      "    step: 200; loss: 11.289; l2dist: 3.138\n",
      "    step: 300; loss: 11.445; l2dist: 3.154\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 39.140; l2dist: 6.184\n",
      "    step: 100; loss: 11.887; l2dist: 3.193\n",
      "    step: 200; loss: 11.392; l2dist: 3.147\n",
      "    step: 300; loss: 11.391; l2dist: 3.145\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 39.103; l2dist: 6.184\n",
      "    step: 100; loss: 11.104; l2dist: 3.002\n",
      "    step: 200; loss: 10.490; l2dist: 2.905\n",
      "    step: 300; loss: 10.407; l2dist: 2.900\n",
      "    step: 400; loss: 10.497; l2dist: 2.919\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 39.096; l2dist: 6.183\n",
      "    step: 100; loss: 10.764; l2dist: 2.596\n",
      "    step: 200; loss: 10.465; l2dist: 2.599\n",
      "    step: 300; loss: 10.326; l2dist: 2.589\n",
      "    step: 400; loss: 10.369; l2dist: 2.571\n",
      "binary step: 5; number of successful adv: 100/100\n",
      "    step: 0; loss: 39.143; l2dist: 6.188\n",
      "    step: 100; loss: 10.890; l2dist: 3.002\n",
      "    step: 200; loss: 10.651; l2dist: 2.971\n",
      "    step: 300; loss: 10.813; l2dist: 3.007\n",
      "binary step: 6; number of successful adv: 100/100\n",
      "    step: 0; loss: 39.098; l2dist: 6.183\n",
      "    step: 100; loss: 10.794; l2dist: 3.009\n",
      "    step: 200; loss: 10.734; l2dist: 3.019\n",
      "    step: 300; loss: 10.614; l2dist: 3.006\n",
      "    step: 400; loss: 10.304; l2dist: 2.959\n",
      "    step: 500; loss: 10.243; l2dist: 2.951\n",
      "    step: 600; loss: 10.333; l2dist: 2.964\n",
      "binary step: 7; number of successful adv: 100/100\n",
      "    step: 0; loss: 39.094; l2dist: 6.184\n",
      "    step: 100; loss: 10.789; l2dist: 2.943\n",
      "    step: 200; loss: 10.389; l2dist: 2.884\n",
      "    step: 300; loss: 10.402; l2dist: 2.886\n",
      "binary step: 8; number of successful adv: 100/100\n",
      "    step: 0; loss: 39.097; l2dist: 6.184\n",
      "    step: 100; loss: 11.159; l2dist: 3.033\n",
      "    step: 200; loss: 10.523; l2dist: 2.937\n",
      "    step: 300; loss: 10.392; l2dist: 2.927\n",
      "    step: 400; loss: 10.209; l2dist: 2.896\n",
      "    step: 500; loss: 10.290; l2dist: 2.910\n",
      "binary step: 9; number of successful adv: 100/100\n"
     ]
    }
   ],
   "source": [
    "x_adv = attack(x_test[ind][:num].cuda(), y_test[ind][:num].cuda(), \n",
    "               targeted=False, init_mode=2,\n",
    "               binary_search_steps=10, max_iterations=1000, confidence=0,\n",
    "               learning_rate=1e-1, initial_const=1, abort_early=True,\n",
    "               rand_start_std=0.1, check_adv_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_adv = attack(x_test[:num].cuda(), y_test[:num].cuda(), \n",
    "               targeted=False, init_mode=2,\n",
    "               binary_search_steps=10, max_iterations=1000, confidence=0,\n",
    "               learning_rate=1e-1, initial_const=1, abort_early=True,\n",
    "               rand_start_std=0.1, check_adv_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7946, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_adv.cpu() - x_test[ind][:num]).view(num, -1).norm(2, 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.6804, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_adv.cpu() - x_test[:num]).view(num, -1).norm(2, 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12\n"
     ]
    }
   ],
   "source": [
    "net.recompute_train_rep()\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = net.compute_logits(x_adv).cpu().argmax(1)\n",
    "    print((out == y_test[ind][:num]).numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = []\n",
    "size = [200, 500, 1000, 5000, 10000]\n",
    "for n in size:\n",
    "    acc = []\n",
    "    for i in range(100):\n",
    "        ind_train = np.arange(len(x_train))\n",
    "        np.random.shuffle(ind_train)\n",
    "        ind_train = ind_train[:n]\n",
    "        net.train_data = (x_train[ind_train], y_train[ind_train])\n",
    "\n",
    "        net.recompute_train_rep()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = net.compute_logits(x_adv).cpu().argmax(1)\n",
    "            acc.append((out == y_test[ind][:num]).numpy().mean())\n",
    "    accs.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "accs = np.array(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(np.arange(len(size)), accs.mean(1), yerr=accs.std(1),\n",
    "        align='center', capsize=3)\n",
    "plt.xticks(np.arange(len(size)), size)\n",
    "plt.ylabel('Adv Accuracy')\n",
    "plt.xlabel('Size of training set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'adv_mnist_exp6.h5'\n",
    "basic_net = BasicModel()\n",
    "# # basic_net = BasicModelV2()\n",
    "config = {'epsilon': 3,\n",
    "          'num_steps': 40,\n",
    "          'step_size': 0.2,\n",
    "          'random_start': True,\n",
    "          'loss_func': 'xent'}\n",
    "net = PGDL2Model(basic_net, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicModel(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3))\n",
       "  (relu1): ReLU(inplace=True)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(6, 6), stride=(2, 2), padding=(3, 3))\n",
       "  (relu2): ReLU(inplace=True)\n",
       "  (conv3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu3): ReLU(inplace=True)\n",
       "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up model directory\n",
    "# save_dir = os.path.join(os.getcwd(), 'saved_models/mnist/')\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models/')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "net = net.to(device)\n",
    "# if device == 'cuda':\n",
    "#     net = torch.nn.DataParallel(net)\n",
    "#     cudnn.benchmark = True\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "# net = net.module\n",
    "net = net.basic_net\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.9647\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = net(x_test.to(device))\n",
    "    ind = np.where(y_pred.argmax(1).cpu() == y_test)[0]\n",
    "    print('acc: ', len(ind) / y_test.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = CWL2Attack(net, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step: 0; loss: 2.410; l2dist: 0.000\n",
      "    step: 100; loss: 2.330; l2dist: 0.304\n",
      "    step: 200; loss: 2.330; l2dist: 0.315\n",
      "binary step: 0; number of successful adv: 2/97\n",
      "    step: 0; loss: 23.933; l2dist: 0.317\n",
      "    step: 100; loss: 10.869; l2dist: 2.284\n",
      "    step: 200; loss: 10.364; l2dist: 2.348\n",
      "    step: 300; loss: 10.229; l2dist: 2.355\n",
      "    step: 400; loss: 10.227; l2dist: 2.360\n",
      "    step: 500; loss: 10.204; l2dist: 2.386\n",
      "    step: 600; loss: 10.197; l2dist: 2.373\n",
      "    step: 700; loss: 10.201; l2dist: 2.372\n",
      "binary step: 1; number of successful adv: 42/97\n",
      "    step: 0; loss: 164.953; l2dist: 0.316\n",
      "    step: 100; loss: 13.769; l2dist: 3.365\n",
      "    step: 200; loss: 12.301; l2dist: 3.208\n",
      "    step: 300; loss: 12.478; l2dist: 3.257\n",
      "binary step: 2; number of successful adv: 97/97\n",
      "    step: 0; loss: 176.101; l2dist: 0.323\n",
      "    step: 100; loss: 12.643; l2dist: 3.226\n",
      "    step: 200; loss: 12.079; l2dist: 3.222\n",
      "    step: 300; loss: 11.492; l2dist: 3.137\n",
      "    step: 400; loss: 11.255; l2dist: 3.062\n",
      "    step: 500; loss: 11.460; l2dist: 3.055\n",
      "binary step: 3; number of successful adv: 97/97\n",
      "    step: 0; loss: 124.467; l2dist: 0.320\n",
      "    step: 100; loss: 12.708; l2dist: 3.171\n",
      "    step: 200; loss: 12.195; l2dist: 3.142\n",
      "    step: 300; loss: 11.497; l2dist: 2.993\n",
      "    step: 400; loss: 11.408; l2dist: 3.033\n",
      "    step: 500; loss: 11.446; l2dist: 3.060\n",
      "binary step: 4; number of successful adv: 97/97\n",
      "    step: 0; loss: 93.848; l2dist: 0.321\n",
      "    step: 100; loss: 12.794; l2dist: 3.113\n",
      "    step: 200; loss: 11.774; l2dist: 2.991\n",
      "    step: 300; loss: 11.463; l2dist: 3.019\n",
      "    step: 400; loss: 11.467; l2dist: 3.035\n",
      "binary step: 5; number of successful adv: 97/97\n",
      "    step: 0; loss: 80.625; l2dist: 0.324\n",
      "    step: 100; loss: 12.175; l2dist: 3.066\n",
      "    step: 200; loss: 11.462; l2dist: 3.022\n",
      "    step: 300; loss: 11.343; l2dist: 3.035\n",
      "    step: 400; loss: 11.235; l2dist: 3.010\n",
      "    step: 500; loss: 11.223; l2dist: 2.996\n",
      "    step: 600; loss: 11.021; l2dist: 2.971\n",
      "    step: 700; loss: 11.277; l2dist: 3.017\n",
      "binary step: 6; number of successful adv: 97/97\n",
      "    step: 0; loss: 76.044; l2dist: 0.323\n",
      "    step: 100; loss: 12.251; l2dist: 3.081\n",
      "    step: 200; loss: 11.454; l2dist: 3.013\n",
      "    step: 300; loss: 11.334; l2dist: 2.950\n",
      "    step: 400; loss: 11.256; l2dist: 2.962\n",
      "    step: 500; loss: 11.209; l2dist: 3.003\n",
      "    step: 600; loss: 11.230; l2dist: 3.000\n",
      "binary step: 7; number of successful adv: 97/97\n",
      "    step: 0; loss: 73.796; l2dist: 0.319\n",
      "    step: 100; loss: 12.208; l2dist: 3.071\n",
      "    step: 200; loss: 11.556; l2dist: 2.983\n",
      "    step: 300; loss: 11.564; l2dist: 2.999\n",
      "binary step: 8; number of successful adv: 97/97\n",
      "    step: 0; loss: 75.440; l2dist: 0.321\n",
      "    step: 100; loss: 12.377; l2dist: 3.105\n",
      "    step: 200; loss: 11.779; l2dist: 3.012\n",
      "    step: 300; loss: 11.456; l2dist: 3.014\n",
      "    step: 400; loss: 11.302; l2dist: 3.035\n",
      "    step: 500; loss: 11.679; l2dist: 3.094\n",
      "binary step: 9; number of successful adv: 97/97\n",
      "    step: 0; loss: 38.131; l2dist: 6.090\n",
      "    step: 100; loss: 2.335; l2dist: 0.349\n",
      "    step: 200; loss: 2.332; l2dist: 0.349\n",
      "    step: 300; loss: 2.332; l2dist: 0.350\n",
      "    step: 400; loss: 2.332; l2dist: 0.349\n",
      "binary step: 0; number of successful adv: 97/97\n",
      "    step: 0; loss: 39.272; l2dist: 6.095\n",
      "    step: 100; loss: 10.917; l2dist: 2.702\n",
      "    step: 200; loss: 10.669; l2dist: 2.677\n",
      "    step: 300; loss: 10.587; l2dist: 2.670\n",
      "    step: 400; loss: 10.594; l2dist: 2.677\n",
      "binary step: 1; number of successful adv: 97/97\n",
      "    step: 0; loss: 41.914; l2dist: 6.099\n",
      "    step: 100; loss: 11.785; l2dist: 3.026\n",
      "    step: 200; loss: 10.917; l2dist: 2.894\n",
      "    step: 300; loss: 10.804; l2dist: 2.911\n",
      "    step: 400; loss: 10.828; l2dist: 2.889\n",
      "binary step: 2; number of successful adv: 97/97\n",
      "    step: 0; loss: 53.783; l2dist: 6.093\n",
      "    step: 100; loss: 13.093; l2dist: 3.333\n",
      "    step: 200; loss: 12.580; l2dist: 3.293\n",
      "    step: 300; loss: 11.651; l2dist: 3.191\n",
      "    step: 400; loss: 13.150; l2dist: 3.273\n",
      "binary step: 3; number of successful adv: 97/97\n",
      "    step: 0; loss: 50.078; l2dist: 6.096\n",
      "    step: 100; loss: 12.593; l2dist: 3.247\n",
      "    step: 200; loss: 11.495; l2dist: 3.131\n",
      "    step: 300; loss: 11.415; l2dist: 3.123\n",
      "    step: 400; loss: 11.578; l2dist: 3.137\n",
      "binary step: 4; number of successful adv: 97/97\n",
      "    step: 0; loss: 45.003; l2dist: 6.094\n",
      "    step: 100; loss: 11.731; l2dist: 3.103\n",
      "    step: 200; loss: 11.558; l2dist: 3.137\n",
      "    step: 300; loss: 11.810; l2dist: 3.163\n",
      "binary step: 5; number of successful adv: 97/97\n",
      "    step: 0; loss: 42.896; l2dist: 6.092\n",
      "    step: 100; loss: 11.637; l2dist: 3.119\n",
      "    step: 200; loss: 11.090; l2dist: 3.022\n",
      "    step: 300; loss: 11.035; l2dist: 3.037\n",
      "    step: 400; loss: 11.214; l2dist: 3.063\n",
      "binary step: 6; number of successful adv: 97/97\n",
      "    step: 0; loss: 41.811; l2dist: 6.096\n",
      "    step: 100; loss: 11.834; l2dist: 3.078\n",
      "    step: 200; loss: 11.000; l2dist: 2.982\n",
      "    step: 300; loss: 11.392; l2dist: 3.066\n",
      "binary step: 7; number of successful adv: 97/97\n",
      "    step: 0; loss: 41.371; l2dist: 6.096\n",
      "    step: 100; loss: 11.720; l2dist: 3.051\n",
      "    step: 200; loss: 11.325; l2dist: 3.068\n",
      "    step: 300; loss: 11.011; l2dist: 3.033\n",
      "    step: 400; loss: 11.059; l2dist: 3.017\n",
      "binary step: 8; number of successful adv: 97/97\n",
      "    step: 0; loss: 41.365; l2dist: 6.094\n",
      "    step: 100; loss: 11.928; l2dist: 3.101\n",
      "    step: 200; loss: 11.246; l2dist: 3.009\n",
      "    step: 300; loss: 11.497; l2dist: 3.112\n",
      "binary step: 9; number of successful adv: 97/97\n"
     ]
    }
   ],
   "source": [
    "num = 100\n",
    "x_adv = attack(x_test[:num].cuda(), y_test[:num].cuda(), \n",
    "               targeted=False, init_mode=2,\n",
    "               binary_search_steps=10, max_iterations=1000, confidence=0,\n",
    "               learning_rate=1e-1, initial_const=1, abort_early=True,\n",
    "               rand_start_std=0.1, check_adv_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7354, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_adv.cpu() - x_test[:num]).view(num, -1).norm(2, 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    step: 0; loss: 2.462; l2dist: 0.000\n",
      "    step: 100; loss: 2.375; l2dist: 0.311\n",
      "    step: 200; loss: 2.377; l2dist: 0.321\n",
      "binary step: 0; number of successful adv: 2/100\n",
      "    step: 0; loss: 24.473; l2dist: 0.321\n",
      "    step: 100; loss: 10.958; l2dist: 2.296\n",
      "    step: 200; loss: 10.463; l2dist: 2.341\n",
      "    step: 300; loss: 10.334; l2dist: 2.362\n",
      "    step: 400; loss: 10.347; l2dist: 2.375\n",
      "binary step: 1; number of successful adv: 40/100\n",
      "    step: 0; loss: 149.058; l2dist: 0.329\n",
      "    step: 100; loss: 13.512; l2dist: 3.336\n",
      "    step: 200; loss: 13.318; l2dist: 3.351\n",
      "    step: 300; loss: 12.657; l2dist: 3.267\n",
      "    step: 400; loss: 11.570; l2dist: 3.119\n",
      "    step: 500; loss: 11.755; l2dist: 3.188\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 85.186; l2dist: 0.321\n",
      "    step: 100; loss: 13.728; l2dist: 3.402\n",
      "    step: 200; loss: 11.941; l2dist: 3.173\n",
      "    step: 300; loss: 12.185; l2dist: 3.235\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 62.458; l2dist: 0.323\n",
      "    step: 100; loss: 12.472; l2dist: 3.111\n",
      "    step: 200; loss: 11.649; l2dist: 3.005\n",
      "    step: 300; loss: 11.460; l2dist: 3.003\n",
      "    step: 400; loss: 11.230; l2dist: 3.005\n",
      "    step: 500; loss: 11.310; l2dist: 2.999\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 61.121; l2dist: 0.320\n",
      "    step: 100; loss: 12.193; l2dist: 3.010\n",
      "    step: 200; loss: 11.533; l2dist: 3.004\n",
      "    step: 300; loss: 11.382; l2dist: 3.006\n",
      "    step: 400; loss: 11.164; l2dist: 2.980\n",
      "    step: 500; loss: 11.136; l2dist: 2.996\n",
      "    step: 600; loss: 11.113; l2dist: 2.977\n",
      "    step: 700; loss: 11.245; l2dist: 2.995\n",
      "binary step: 5; number of successful adv: 100/100\n",
      "    step: 0; loss: 61.261; l2dist: 0.319\n",
      "    step: 100; loss: 12.149; l2dist: 3.052\n",
      "    step: 200; loss: 11.373; l2dist: 3.040\n",
      "    step: 300; loss: 11.309; l2dist: 3.028\n",
      "    step: 400; loss: 11.129; l2dist: 3.007\n",
      "    step: 500; loss: 11.182; l2dist: 2.976\n",
      "binary step: 6; number of successful adv: 100/100\n",
      "    step: 0; loss: 61.593; l2dist: 0.323\n",
      "    step: 100; loss: 12.517; l2dist: 3.017\n",
      "    step: 200; loss: 11.727; l2dist: 3.023\n",
      "    step: 300; loss: 11.553; l2dist: 3.037\n",
      "    step: 400; loss: 11.262; l2dist: 3.027\n",
      "    step: 500; loss: 11.175; l2dist: 3.087\n",
      "    step: 600; loss: 11.934; l2dist: 3.221\n",
      "binary step: 7; number of successful adv: 100/100\n",
      "    step: 0; loss: 60.030; l2dist: 0.321\n",
      "    step: 100; loss: 12.193; l2dist: 3.043\n",
      "    step: 200; loss: 11.739; l2dist: 3.073\n",
      "    step: 300; loss: 11.279; l2dist: 3.005\n",
      "    step: 400; loss: 11.352; l2dist: 3.026\n",
      "binary step: 8; number of successful adv: 100/100\n",
      "    step: 0; loss: 60.837; l2dist: 0.322\n",
      "    step: 100; loss: 12.617; l2dist: 3.047\n",
      "    step: 200; loss: 11.627; l2dist: 3.050\n",
      "    step: 300; loss: 11.443; l2dist: 3.058\n",
      "    step: 400; loss: 11.350; l2dist: 3.041\n",
      "    step: 500; loss: 11.227; l2dist: 3.016\n",
      "    step: 600; loss: 11.269; l2dist: 2.988\n",
      "binary step: 9; number of successful adv: 100/100\n",
      "    step: 0; loss: 38.418; l2dist: 6.114\n",
      "    step: 100; loss: 2.388; l2dist: 0.351\n",
      "    step: 200; loss: 2.386; l2dist: 0.349\n",
      "    step: 300; loss: 2.387; l2dist: 0.349\n",
      "binary step: 0; number of successful adv: 100/100\n",
      "    step: 0; loss: 39.563; l2dist: 6.121\n",
      "    step: 100; loss: 11.098; l2dist: 2.810\n",
      "    step: 200; loss: 10.746; l2dist: 2.775\n",
      "    step: 300; loss: 10.747; l2dist: 2.777\n",
      "binary step: 1; number of successful adv: 100/100\n",
      "    step: 0; loss: 41.374; l2dist: 6.119\n",
      "    step: 100; loss: 11.643; l2dist: 3.000\n",
      "    step: 200; loss: 11.587; l2dist: 3.045\n",
      "    step: 300; loss: 11.200; l2dist: 2.958\n",
      "    step: 400; loss: 11.239; l2dist: 2.970\n",
      "binary step: 2; number of successful adv: 100/100\n",
      "    step: 0; loss: 41.179; l2dist: 6.116\n",
      "    step: 100; loss: 13.119; l2dist: 3.317\n",
      "    step: 200; loss: 11.514; l2dist: 3.148\n",
      "    step: 300; loss: 11.528; l2dist: 3.112\n",
      "binary step: 3; number of successful adv: 100/100\n",
      "    step: 0; loss: 43.846; l2dist: 6.117\n",
      "    step: 100; loss: 12.144; l2dist: 3.198\n",
      "    step: 200; loss: 12.054; l2dist: 3.130\n",
      "    step: 300; loss: 10.964; l2dist: 3.032\n",
      "    step: 400; loss: 12.181; l2dist: 3.224\n",
      "binary step: 4; number of successful adv: 100/100\n",
      "    step: 0; loss: 42.193; l2dist: 6.119\n",
      "    step: 100; loss: 11.508; l2dist: 3.061\n",
      "    step: 200; loss: 12.046; l2dist: 3.220\n",
      "binary step: 5; number of successful adv: 100/100\n",
      "    step: 0; loss: 41.329; l2dist: 6.120\n",
      "    step: 100; loss: 11.655; l2dist: 3.080\n",
      "    step: 200; loss: 11.340; l2dist: 3.082\n",
      "    step: 300; loss: 11.533; l2dist: 3.108\n",
      "binary step: 6; number of successful adv: 100/100\n",
      "    step: 0; loss: 40.957; l2dist: 6.123\n",
      "    step: 100; loss: 11.785; l2dist: 3.112\n",
      "    step: 200; loss: 11.266; l2dist: 3.059\n",
      "    step: 300; loss: 11.047; l2dist: 3.030\n",
      "    step: 400; loss: 11.316; l2dist: 3.079\n",
      "binary step: 7; number of successful adv: 100/100\n",
      "    step: 0; loss: 40.764; l2dist: 6.118\n",
      "    step: 100; loss: 11.851; l2dist: 3.089\n",
      "    step: 200; loss: 11.205; l2dist: 3.021\n",
      "    step: 300; loss: 11.156; l2dist: 3.032\n",
      "    step: 400; loss: 11.110; l2dist: 3.005\n",
      "    step: 500; loss: 11.517; l2dist: 3.095\n",
      "binary step: 8; number of successful adv: 100/100\n",
      "    step: 0; loss: 40.728; l2dist: 6.117\n",
      "    step: 100; loss: 11.841; l2dist: 3.102\n",
      "    step: 200; loss: 11.189; l2dist: 3.029\n",
      "    step: 300; loss: 10.958; l2dist: 2.994\n",
      "    step: 400; loss: 11.488; l2dist: 3.092\n",
      "binary step: 9; number of successful adv: 100/100\n"
     ]
    }
   ],
   "source": [
    "num = 100\n",
    "x_adv = attack(x_test[ind][:num].cuda(), y_test[ind][:num].cuda(), \n",
    "               targeted=False, init_mode=2,\n",
    "               binary_search_steps=10, max_iterations=1000, confidence=0,\n",
    "               learning_rate=1e-1, initial_const=1, abort_early=True,\n",
    "               rand_start_std=0.1, check_adv_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adv success rate:  1.0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = net(x_adv)\n",
    "    adv_ind = np.where(y_pred.argmax(1).cpu() != y_test[ind][:num])[0]\n",
    "    print('adv success rate: ', len(adv_ind) / y_pred.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean dist: 2.8263\n"
     ]
    }
   ],
   "source": [
    "dist = (x_adv.cpu() - x_test[ind][:num])[adv_ind].view(len(adv_ind), -1)\n",
    "print('mean dist: %.4f' % dist.norm(2, 1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## SPL Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WeightedNCA(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3))\n",
       "  (relu1): ReLU(inplace=True)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(6, 6), stride=(2, 2), padding=(3, 3))\n",
       "  (relu2): ReLU(inplace=True)\n",
       "  (conv3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu3): ReLU(inplace=True)\n",
       "  (fc_): Linear(in_features=2048, out_features=10, bias=True)\n",
       "  (fc): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'adv_mnist_nca_exp64.h5'\n",
    "model = WeightedNCA(normalize=False, output_dim=10, init_it=1, \n",
    "                    train_data=(x_train, y_train))\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models/')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(model_path), strict=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.recompute_train_rep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5022, 0.5080, 0.5068, 0.5075, 0.5341, 0.5053, 0.5011, 0.6253, 0.5044,\n",
       "         0.5523],\n",
       "        [0.5057, 0.5127, 0.6546, 0.5161, 0.5069, 0.5048, 0.5096, 0.5097, 0.5193,\n",
       "         0.5054]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compute_logits(x_test[:2].cuda()).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, _, _ = load_mnist(\n",
    "        100, data_dir='/data', val_size=0.1, shuffle=True, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs, outputs_adv = net.compute_logits(self, x, recompute_train_rep=False, requires_grad=False,\n",
    "                       from_outputs=False)\n",
    "    loss = net.loss_function(outputs_adv, targets, orig=outputs)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Soft Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys_train = np.zeros((len(y_train), 10))\n",
    "nb = dknn.get_neighbors(x_train, k=100)[0][1]\n",
    "for i in range(len(y_train)):\n",
    "    ys_train[i] = np.bincount(y_train[nb[i]], minlength=10) / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = ['fc']\n",
    "dknn = DKNNL2(net, x_train, y_train, x_valid, y_valid, layers, \n",
    "              k=100, num_classes=10, ys_train=torch.tensor(ys_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SoftLabelNCA(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(8, 8), stride=(2, 2), padding=(3, 3))\n",
       "  (relu1): ReLU(inplace=True)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(6, 6), stride=(2, 2), padding=(3, 3))\n",
       "  (relu2): ReLU(inplace=True)\n",
       "  (conv3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu3): ReLU(inplace=True)\n",
       "  (fc_): Linear(in_features=2048, out_features=20, bias=True)\n",
       "  (fc): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = SoftLabelNCA(torch.tensor(ys_train).cuda().float(), \n",
    "                   normalize=False, output_dim=20, \n",
    "                   init_it=1, train_data=(x_train, y_train))\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models/')\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "net = net.to(device)\n",
    "net.load_state_dict(torch.load(model_path))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.recompute_train_rep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dknn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5f055a6d6af9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mys_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassify_soft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mys_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dknn' is not defined"
     ]
    }
   ],
   "source": [
    "ys_test = dknn.classify_soft(x_test)\n",
    "(ys_test.argmax(1) == y_test.numpy()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dknn.classify(x_test)\n",
    "cred = dknn.credibility(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 970.,  975.,  903.,  821.,  729.,    0.,    0.,    0.,    0.,\n",
       "        5602.]),\n",
       " array([0.005 , 0.1045, 0.204 , 0.3035, 0.403 , 0.5025, 0.602 , 0.7015,\n",
       "        0.801 , 0.9005, 1.    ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6662565166666666 1.0\n",
      "0.4398\n"
     ]
    }
   ],
   "source": [
    "print(cred.mean(), np.median(cred))\n",
    "print((cred < 0.5).mean())\n",
    "train_cred = cred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = dknn.classify(x_adv)\n",
    "cred = dknn.credibility(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([70., 18.,  0.,  9.,  0.,  2.,  0.,  0.,  0.,  1.]),\n",
       " array([0.27566667, 0.29341667, 0.31116667, 0.32891667, 0.34666667,\n",
       "        0.36441667, 0.38216667, 0.39991667, 0.41766667, 0.43541667,\n",
       "        0.45316667]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5468333333333333"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dknn.A < 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6,\n",
       "       6, 5, 4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2,\n",
       "       3, 5, 1, 2, 4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4,\n",
       "       6, 4, 3, 0, 7, 0, 2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3,\n",
       "       6, 1, 3, 6, 9, 3, 1, 4, 1, 7, 6, 9])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dknn.classify(x_adv).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, ..., False, False, False])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test.numpy() == 1) & (y_test.numpy() == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(x_adv, open('x_adv_dknn_295.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7243333333333334"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dknn.A < 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f11b1be2940>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_adv[5].detach().cpu().numpy().reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
