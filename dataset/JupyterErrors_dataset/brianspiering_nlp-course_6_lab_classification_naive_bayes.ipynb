{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab: Movie Reviews Classification\n",
    "======\n",
    "\n",
    "![](https://imgs.xkcd.com/comics/star_ratings.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "----\n",
    "\n",
    "> I like my data large, my algorithms simple, and my labels weak.  \n",
    "\\- Andrej Karpathy\n",
    "\n",
    "\n",
    "#### Data Science Workflow\n",
    "\n",
    "1. Ask\n",
    "2. Acquire\n",
    "3. Process\n",
    "4. Model\n",
    "5. Deliver \n",
    "\n",
    "You are going to apply the Data Science workflow to classifying movie reviews as positive or negative. \n",
    "\n",
    "This is the actual Internet Movie Database [imdb](www.imdb.com) review data used in the seminal [Pang *et al.* (2002)](http://www.cs.cornell.edu/home/llee/papers/sentiment.pdf) paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Ask: \n",
    "----\n",
    "\n",
    "Which words contribute to a movie review being positive or negative?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Acquire\n",
    "----\n",
    "\n",
    "Write Python code to download the [data: positive and negative processed reviews](http://www.cs.cornell.edu/People/pabo/movie-review-data/). \n",
    "\n",
    "Use `polarity dataset v2.0 `\n",
    "\n",
    "<br>\n",
    "\n",
    "<details><summary>\n",
    "Click here for a hint...\n",
    "</summary>\n",
    "```\n",
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write Python code to unzip the files\n",
    "\n",
    "<br>\n",
    "\n",
    "<details><summary>\n",
    "Click here for a hint...\n",
    "</summary>\n",
    "import tarfile\n",
    "</details>\n",
    "<br>\n",
    "<br>\n",
    "<details><summary>\n",
    "Click here for the solution...\n",
    "</summary>\n",
    "```\n",
    "import tarfile\n",
    "path = \"./txt_sentoken/\"\n",
    "if not os.path.exists(path):\n",
    "    with tarfile.open(filename, \"r:gz\") as tar:\n",
    "        tar.extractall()\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the data files in your favorite text editor. How would you describe the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Process\n",
    "-----\n",
    "\n",
    "The data has been preprocessed for you (thank me later ðŸ™Œ). \n",
    "\n",
    "What preprocessing steps have already been performed on the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Model\n",
    "----\n",
    "\n",
    "We are going to use scikit-learn to model the data.\n",
    "\n",
    "If you not familar with using scikit-learn, check out [this tutorial](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data into sci-kit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-15f531a21089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m sentiment = load_files(path, \n\u001b[0m\u001b[1;32m      2\u001b[0m                        \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                        random_state=42)\n\u001b[1;32m      4\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0msentiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_files' is not defined"
     ]
    }
   ],
   "source": [
    "sentiment = load_files(path, \n",
    "                       encoding='utf-8',\n",
    "                       random_state=42)\n",
    "*sentiment.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a train and test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "None, None, None, None = train_test_split(sentiment.data,\n",
    "                                          sentiment.target,\n",
    "                                          random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We decided to sample an equal number of positive and negative reviewsâ€”was that a good idea? â€” Bo Pang\n",
    "\n",
    "Probably not, the real world is not uniform. That is the difference between academic and applied ML. \n",
    "\n",
    "Applied ML models the world as it is, not how it is convient for publication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines FTW\n",
    "-----\n",
    "\n",
    "![](images/pipeline.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to go end-to-end as quickly as possible and establish a baseline performance metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_classifcation(clf: Pipeline, train_data, test_data, train_target, test_target):\n",
    "    \"Helper function wrapping the Pipeline.\"\n",
    "    clf.fit(train_data, train_target) \n",
    "    predicted = clf.predict(test_data)\n",
    "    accuracy = np.mean(predicted==test_target)\n",
    "    print(f\"The accuracy on the test data is {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Vectorizing & Model Fitting\n",
    "-----\n",
    "We need to coverts the words into numbers.\n",
    "\n",
    "Create an instance of [Count Vectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) \n",
    "\n",
    "Create an instance of [Multinomial NaÃ¯ve Bayes](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = Pipeline([('vect', CountVectorizer()),\n",
    "                ('clf', MultinomialNB())])\n",
    "\n",
    "text_classifcation(clf, train_data, test_data, train_target, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now try with TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why the difference? What could be the reason for the change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Evaluate the Model\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a confusion matrix in sci-kit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are there more False Positives or False Negatives?\n",
    "\n",
    "Why do you think this is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat with a \"prettier\" confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from display_confusion_matrix import display_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "5) Deliver\n",
    "-----\n",
    "\n",
    "The goal of the lab is get __>82.9%__ accuracy on the test set, better than the best the score from the paper. Once you do, you can stop. \n",
    "\n",
    "You can use any Machine Learning technique to accomplish that goal(e.g., feature engineering, choosing a different classifer, random search, grid search, Bayesian Optimization, â€¦).\n",
    "\n",
    "------\n",
    "\n",
    "Once you have a final model,\n",
    "\n",
    "In 2-3 sentences, summarize what you do did.\n",
    "\n",
    "In a table, list your best parameters choices for each step so someone could recreate your work\n",
    "\n",
    "In a single sentence, summarize what you found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus Cartoon\n",
    "------\n",
    "\n",
    "![](https://imgs.xkcd.com/comics/emoji_movie_reviews.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
