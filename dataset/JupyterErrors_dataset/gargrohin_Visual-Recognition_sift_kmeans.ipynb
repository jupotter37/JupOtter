{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "def get_sift(path):\n",
    "\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    desc ={}\n",
    "    images=[]\n",
    "    c=[]\n",
    "    keys = []\n",
    "    alldes = np.empty([1,128])\n",
    "    for objdir in os.listdir(path):\n",
    "        obj = path + objdir\n",
    "        des=[]\n",
    "        for img in os.listdir(obj):\n",
    "            img1 = obj + '/' + img\n",
    "            images.append(img1)\n",
    "            img1 = cv2.imread(img1)\n",
    "            img1= img1[:300,250:400,:]\n",
    "            kp1,des1 = sift.detectAndCompute(img1,None)\n",
    "            keys.append(kp1)\n",
    "            des.append(des1)\n",
    "            c.append(des1.shape[0])\n",
    "            alldes = np.concatenate([alldes,des1])\n",
    "            print('{}'.format(img),end=\"\\r\")\n",
    "        #keys[objdir] = kp\n",
    "        desc[objdir] = des\n",
    "        print('{} done'.format(objdir))\n",
    "    alldesc_real = alldes[1:,:]\n",
    "    return keys,c,images,desc,alldesc_real\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import os\n",
    "import math\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "338819"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alldesc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()\n",
    "path = path[:path.rfind('/')] + '/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m_high_tack_spray_adhesive done\n",
      "aunt_jemima_original_syrup done\n",
      "campbells_chicken_noodle_soup done\n",
      "cheez_it_white_cheddar done\n",
      "cholula_chipotle_hot_sauce done\n",
      "clif_crunch_chocolate_chip done\n",
      "coca_cola_glass_bottle done\n",
      "detergent done\n",
      "expo_marker_red done\n",
      "listerine_green done\n",
      "nice_honey_roasted_almonds done\n",
      "nutrigrain_apple_cinnamon done\n",
      "palmolive_green done\n",
      "pringles_bbq done\n",
      "vo5_extra_body_volumizing_shampoo done\n",
      "vo5_split_ends_anti_breakage_shampoo done\n"
     ]
    }
   ],
   "source": [
    "kp,count,images,des, alldesc = get_sift(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.savez('desc.npz',des)\n",
    "np.savez('count.npz',count)\n",
    "np.savez('sift_features.npz',alldesc)\n",
    "np.savez('images.npz',images)\n",
    "#dump(kp,'kp.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load('images.npz')['arr_0']\n",
    "count = np.load('count.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpfile = open('keypoints.p','wb')\n",
    "pickle.dump(clust,kpfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-920-96a126710055>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'keypoints.p'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsumed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;31m# keep undecoded input until the next call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconsumed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte"
     ]
    }
   ],
   "source": [
    "f = open('keypoints.p','r')\n",
    "c2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump,load\n",
    "import numpy as np\n",
    "clust = load('clusters_12000.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d35a270c9be3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0meuclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclust\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x\n",
    "clust.cluster_centers_[clust.predict(np.array([x]))]\n",
    "euclidean_distances(clust.cluster_centers_[clust.predict(np.array([x]))],np.array([x]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388.6596797495266\n"
     ]
    }
   ],
   "source": [
    "max_dist=-float('inf')\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "for img in images:\n",
    "    img1 = cv2.imread(img)\n",
    "    img1= img1[:300,250:400,:]\n",
    "    kp1,des1 = sift.detectAndCompute(img1,None)\n",
    "    for x in des1:\n",
    "        #cl = clust.predict(np.array([x]))\n",
    "        dist = euclidean_distances(clust.cluster_centers_[clust.predict(np.array([x]))],np.array([x]))[0][0]\n",
    "        if dist > max_dist:\n",
    "            max_dist = dist\n",
    "print(max_dist)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = np.shape(clust.cluster_centers_)[0]\n",
    "N = 3456\n",
    "w = np.zeros(words)\n",
    "idf = np.zeros([N,words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3456"
      ]
     },
     "execution_count": 909,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 961,
   "metadata": {},
   "outputs": [],
   "source": [
    "indoc = np.zeros(words)\n",
    "nd = np.zeros(N)\n",
    "ni = np.zeros(words)\n",
    "nid = np.zeros([N,words])\n",
    "i=0\n",
    "d=0\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "for k in range(len(images)):\n",
    "    for j in range(count[d]):\n",
    "        word = clust.labels_[i]\n",
    "        if kp[d][j].pt[0] > 50 and kp[d][j].pt[0] < 280:\n",
    "            if kp[d][j].pt[1] > 10 and kp[d][j].pt[1] < 120:\n",
    "                nid[d][word] += 100\n",
    "            else:\n",
    "                nid[d][word] += 1\n",
    "        else:\n",
    "            nid[d][word] += 1\n",
    "        if indoc[word]==0:\n",
    "            indoc[word]=1\n",
    "            ni[word]+=1\n",
    "            #nd[d]+=1\n",
    "        #nid[d][word]+=1\n",
    "        i+=1\n",
    "    d+=1\n",
    "    indoc = np.zeros(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in os.listdir(path):\n",
    "    for img in des[obj]:\n",
    "        for disc in range(np.shape(img)[0]):\n",
    "            word = clust.labels_[i]\n",
    "            if indoc[word]==0:\n",
    "                indoc[word]=1\n",
    "                ni[word]+=1\n",
    "                nd[d]+=1\n",
    "            nid[d][word]+=1\n",
    "            #print(nid[d][word])\n",
    "            i+=1\n",
    "        d+=1\n",
    "        indoc = np.zeros(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 962,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in range(N):\n",
    "    nd[d]= sum(nid[d])\n",
    "for d in range(N):\n",
    "    nid[d] = nid[d]/nd[d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros([N,words])\n",
    "\n",
    "for d in range(N):\n",
    "    for i in range(words):\n",
    "        weights[d][i] = (nid[d][i]) * np.log(N/ni[i])\n",
    "        #print(weights[d][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('tfidf.npz',weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "we2 = np.load('tfidf.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/Stuff/Acads/CS783/A1/sample_test/'"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_path = path[:path.rfind('/')]\n",
    "test_path = test_path[:test_path.rfind('/')] + '/sample_test/'\n",
    "test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  3., 20.,  1.,  0.,  0.,  0.,  2.,  2.,  0.,  2.,  0.,  0.,\n",
       "        0.,  2.,  0.,  0.,  0.,  2.,  0.,  0.,  0.,  2.,  0.,  1.,  0.,\n",
       "        0.,  1.,  3.,  1.,  4.,  8.,  0.,  1.,  0.,  1.,  0.,  0.,  5.,\n",
       "        0.,  0.,  0.,  2.,  1.,  7.,  2.,  2.,  0.,  0.,  1.,  0.,  0.,\n",
       "        1.,  0.,  0.,  0.,  1.,  0.,  0.,  3.,  2.,  0.,  0., 12.,  0.,\n",
       "        0.,  1.,  0.,  5.,  0.,  1.,  1.,  0.,  0.,  1.,  0.,  1.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "        2.,  1.,  2.,  0.,  1.,  0.,  1.,  2.])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "for img in os.listdir(test_path):\n",
    "    if img == 'instances.txt':\n",
    "        continue\n",
    "    imr = test_path + img\n",
    "    test = cv2.imread(imr)\n",
    "    kpt, dest = sift.detectAndCompute(test,None)\n",
    "    query=np.zeros(words)\n",
    "    j = clust.predict(dest)\n",
    "    for x in j:\n",
    "        query[x]+=1\n",
    "    break\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_dist=20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(434, 128)\n",
      "434\n"
     ]
    }
   ],
   "source": [
    "sift = cv2.xfeatures2d.SIFT_create(sigma=1.4)\n",
    "#img = 'campbells_chicken_noodle_soup/N2_69.jpg'\n",
    "img = 'test_1.jpg'\n",
    "imr = test_path + img\n",
    "test = cv2.imread(imr)\n",
    "#test = test[:300,250:400,:]\n",
    "kpt, dest = sift.detectAndCompute(test,None)\n",
    "query=np.zeros(words)\n",
    "print(dest.shape)\n",
    "real=0\n",
    "for x in dest:\n",
    "    dist = euclidean_distances(clust.cluster_centers_[clust.predict(np.array([x]))],np.array([x]))[0][0]\n",
    "    if dist < max_dist:\n",
    "        real+=1\n",
    "        query[clust.predict(np.array([x]))] +=1\n",
    "print(real)       \n",
    "#for x in j:\n",
    "#    query[x]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim=[]\n",
    "for i in range(N):\n",
    "    l = cosine(np.array([query]),weights[i])\n",
    "    sim.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.argsort(sim)\n",
    "#for i in range(N):\n",
    " #   print(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vo5_extra_body_volumizing_shampoo_N1_333.jpg\n",
      "expo_marker_red_N1_303.jpg\n",
      "campbells_chicken_noodle_soup_N1_312.jpg\n",
      "nutrigrain_apple_cinnamon_N1_291.jpg\n",
      "cheez_it_white_cheddar_N1_276.jpg\n",
      "vo5_extra_body_volumizing_shampoo_N1_330.jpg\n",
      "3m_high_tack_spray_adhesive_N1_0.jpg\n",
      "vo5_split_ends_anti_breakage_shampoo_N1_333.jpg\n",
      "vo5_split_ends_anti_breakage_shampoo_N1_339.jpg\n",
      "pringles_bbq_N1_333.jpg\n",
      "pringles_bbq_N1_324.jpg\n",
      "campbells_chicken_noodle_soup_N1_321.jpg\n",
      "3m_high_tack_spray_adhesive_N1_357.jpg\n",
      "vo5_split_ends_anti_breakage_shampoo_N1_327.jpg\n",
      "expo_marker_red_N1_309.jpg\n",
      "cholula_chipotle_hot_sauce_N1_327.jpg\n",
      "3m_high_tack_spray_adhesive_N1_6.jpg\n",
      "nice_honey_roasted_almonds_N1_342.jpg\n",
      "palmolive_green_N1_339.jpg\n",
      "vo5_extra_body_volumizing_shampoo_N1_336.jpg\n",
      "expo_marker_red_N1_312.jpg\n",
      "cholula_chipotle_hot_sauce_N1_321.jpg\n",
      "3m_high_tack_spray_adhesive_N1_3.jpg\n",
      "vo5_split_ends_anti_breakage_shampoo_N1_336.jpg\n",
      "clif_crunch_chocolate_chip_N1_300.jpg\n",
      "expo_marker_red_N1_300.jpg\n",
      "palmolive_green_N1_333.jpg\n",
      "cholula_chipotle_hot_sauce_N1_333.jpg\n",
      "clif_crunch_chocolate_chip_N1_294.jpg\n",
      "cholula_chipotle_hot_sauce_N1_330.jpg\n",
      "palmolive_green_N1_336.jpg\n",
      "nutrigrain_apple_cinnamon_N1_294.jpg\n",
      "nice_honey_roasted_almonds_N1_351.jpg\n",
      "coca_cola_glass_bottle_N1_321.jpg\n",
      "cheez_it_white_cheddar_N1_285.jpg\n",
      "cheez_it_white_cheddar_N1_279.jpg\n",
      "cheez_it_white_cheddar_N1_270.jpg\n",
      "vo5_extra_body_volumizing_shampoo_N1_327.jpg\n",
      "campbells_chicken_noodle_soup_N1_318.jpg\n",
      "cheez_it_white_cheddar_N1_273.jpg\n",
      "nice_honey_roasted_almonds_N1_354.jpg\n",
      "clif_crunch_chocolate_chip_N1_303.jpg\n",
      "vo5_extra_body_volumizing_shampoo_N1_342.jpg\n",
      "pringles_bbq_N1_321.jpg\n",
      "3m_high_tack_spray_adhesive_N1_354.jpg\n",
      "nutrigrain_apple_cinnamon_N1_297.jpg\n",
      "palmolive_green_N1_342.jpg\n",
      "3m_high_tack_spray_adhesive_N1_348.jpg\n",
      "cholula_chipotle_hot_sauce_N1_339.jpg\n",
      "nice_honey_roasted_almonds_N1_339.jpg\n",
      "cholula_chipotle_hot_sauce_N1_324.jpg\n",
      "clif_crunch_chocolate_chip_N1_291.jpg\n",
      "vo5_split_ends_anti_breakage_shampoo_N1_330.jpg\n",
      "cholula_chipotle_hot_sauce_N1_336.jpg\n",
      "nutrigrain_apple_cinnamon_N1_288.jpg\n",
      "palmolive_green_N1_330.jpg\n",
      "vo5_extra_body_volumizing_shampoo_N1_39.jpg\n",
      "palmolive_green_N1_327.jpg\n",
      "campbells_chicken_noodle_soup_N1_303.jpg\n",
      "nice_honey_roasted_almonds_N1_336.jpg\n",
      "campbells_chicken_noodle_soup_N1_306.jpg\n",
      "campbells_chicken_noodle_soup_N1_309.jpg\n",
      "nutrigrain_apple_cinnamon_N1_300.jpg\n",
      "vo5_split_ends_anti_breakage_shampoo_N1_321.jpg\n",
      "nutrigrain_apple_cinnamon_N1_285.jpg\n",
      "palmolive_green_N1_39.jpg\n",
      "expo_marker_red_N1_297.jpg\n",
      "nice_honey_roasted_almonds_N1_333.jpg\n",
      "palmolive_green_N1_45.jpg\n",
      "pringles_bbq_N1_315.jpg\n",
      "pringles_bbq_N1_327.jpg\n",
      "clif_crunch_chocolate_chip_N1_288.jpg\n",
      "vo5_extra_body_volumizing_shampoo_N1_45.jpg\n",
      "cheez_it_white_cheddar_N1_282.jpg\n",
      "expo_marker_red_N1_288.jpg\n",
      "cheez_it_white_cheddar_N1_267.jpg\n",
      "cholula_chipotle_hot_sauce_N1_42.jpg\n",
      "pringles_bbq_N1_330.jpg\n",
      "palmolive_green_N1_321.jpg\n",
      "nice_honey_roasted_almonds_N1_345.jpg\n",
      "vo5_extra_body_volumizing_shampoo_N1_144.jpg\n",
      "palmolive_green_N1_318.jpg\n",
      "palmolive_green_N1_51.jpg\n",
      "vo5_extra_body_volumizing_shampoo_N1_318.jpg\n",
      "expo_marker_red_N1_123.jpg\n",
      "nice_honey_roasted_almonds_N1_48.jpg\n",
      "palmolive_green_N1_246.jpg\n",
      "campbells_chicken_noodle_soup_N1_297.jpg\n",
      "expo_marker_red_N2_120.jpg\n",
      "palmolive_green_N1_69.jpg\n",
      "expo_marker_red_N1_120.jpg\n",
      "expo_marker_red_N2_111.jpg\n",
      "palmolive_green_N1_87.jpg\n",
      "nice_honey_roasted_almonds_N1_159.jpg\n",
      "vo5_split_ends_anti_breakage_shampoo_N1_147.jpg\n",
      "campbells_chicken_noodle_soup_N2_222.jpg\n",
      "palmolive_green_N1_42.jpg\n",
      "expo_marker_red_N1_294.jpg\n",
      "palmolive_green_N1_60.jpg\n",
      "palmolive_green_N1_36.jpg\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "ans=0\n",
    "for i in range(100):\n",
    "    out = images[y[i]][32:images[y[i]].rfind('/')] + '_' + images[y[i]][images[y[i]].rfind('/')+1:]\n",
    "    print(out)\n",
    "    if images[y[i]][32:images[y[i]].rfind('/')] == 'listerine_green':\n",
    "        ans+=1\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_1.jpg palmolive_green\r",
      "\r\n",
      "test_2.jpg coca_cola_glass_bottle\r",
      "\r\n",
      "test_3.jpg listerine_green\r",
      "\r\n",
      "easy_single_1.jpg nice_honey_roasted_almonds\r",
      "\r\n",
      "easy_single_2.jpg vo5_extra_body_volumizing_shampoo\r",
      "\r\n",
      "easy_single_3.jpg clif_crunch_chocolate_chip\r",
      "\r\n",
      "easy_multi_1.jpg campbells_chicken_noodle_soup,cholula_chipotle_hot_sauce,nice_honey_roasted_almonds\r",
      "\r\n",
      "easy_multi_2.jpg campbells_chicken_noodle_soup,expo_marker_red\r",
      "\r\n",
      "easy_multi_3.jpg expo_marker_red,vo5_extra_body_volumizing_shampoo\r",
      "\r\n",
      "hard_single_1.jpg 3m_high_tack_spray_adhesive\r",
      "\r\n",
      "hard_single_2.jpg expo_marker_red\r",
      "\r\n",
      "hard_single_3.jpg campbells_chicken_noodle_soup\r",
      "\r\n",
      "hard_multi_1.jpg cholula_chipotle_hot_sauce,clif_crunch_chocolate_chip,expo_marker_red\r",
      "\r\n",
      "hard_multi_2.jpg pringles_bbq,vo5_extra_body_volumizing_shampoo\r",
      "\r\n",
      "hard_multi_3.jpg campbells_chicken_noodle_soup,pringles_bbq"
     ]
    }
   ],
   "source": [
    "cat instances.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3m_high_tack_spray_adhesive\n",
      "aunt_jemima_original_syrup\n",
      "campbells_chicken_noodle_soup\n",
      "cheez_it_white_cheddar\n",
      "cholula_chipotle_hot_sauce\n",
      "clif_crunch_chocolate_chip\n",
      "coca_cola_glass_bottle\n",
      "detergent\n",
      "expo_marker_red\n",
      "listerine_green\n",
      "nice_honey_roasted_almonds\n",
      "nutrigrain_apple_cinnamon\n",
      "palmolive_green\n",
      "pringles_bbq\n",
      "vo5_extra_body_volumizing_shampoo\n",
      "vo5_split_ends_anti_breakage_shampoo\n"
     ]
    }
   ],
   "source": [
    "for objdir in os.listdir(path):\n",
    "    print(objdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
