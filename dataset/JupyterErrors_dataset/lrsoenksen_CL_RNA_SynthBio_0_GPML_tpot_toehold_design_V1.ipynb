{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center> \n",
    "AutoML-assisted toehold switch MFE predictor using self optimizing genetic programming pipelines \n",
    "</center></h1>\n",
    "\n",
    "<center>\n",
    "Luis R. Soenksen<sup>1,2*</sup>, Nicolaas M Angenent-Mari<sup>1,2*</sup> Diogo M. Camacho<sup>2*</sup>, Alexander S. Garruss<sup>2,3*</sup>, Katherine M Collins<sup>1*</sup>, Sameed Siddiqui<sup>1,2</sup>, George Church<sup>1,2,3,4</sup>, Timothy K. Lu<sup>1,4</sup>, and James J. Collins<sup>1,2,3,4</sup>\n",
    "</center>\n",
    "\n",
    "\n",
    "<center><font color=gray><font size=\"1.5\">\n",
    "<sup>1</sup>Massachusetts Institute of Technology, <sup>2</sup>Wyss Institute for Biologically Inspired Engineering, <sup>3</sup>Harvard John A. Paulson School of Engineering and Applied Sciences, and <sup>4</sup>Broad Institute of MIT and Harvard. *Contributed equally\n",
    "</font></font></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Abstract:\n",
    "<font color=black><font size=\"2\">\n",
    "A benchmark tool in the field of synthetic biology is the RNA “Toehold-Switch”, a riboregulator that responds to a programmable target to change its secondary structure through strand displacement with up-regulation of a desired protein. Recent advances have streamlined the synthesis of these modules; however, in vitro and in vivo functionality remain highly unpredictable due to complex interactions unanticipated by standard base-pairing models. We are developing and testing aa high-quality library of 250,000 toehold sequences to train and optimize a variety of machine-learning and deep-learning models (e.g. MLPs, CNN, RNN) to enable accurate biological predictions of novel toehold sensor functionality.\n",
    "</font></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "#### This code requires the following pre-installs:\n",
    "> ##### Biopython\n",
    "> In anaconda env: `conda install -c anaconda biopython` or `pip install biopython`<br>\n",
    "> Ref: https://github.com/biopython/biopython\n",
    "> ##### ViennaRNA\n",
    "> In anaconda env: `conda install -c bioconda viennarna`<br>\n",
    "> Ref: https://github.com/ViennaRNA/ViennaRNA\n",
    "> ##### Pysster (Python 3.5+)\n",
    "> In anaconda env: `pip3 install pysster`<br>\n",
    "> Ref: https://github.com/budach/pysste\n",
    "> ##### Tpot\n",
    "> In anaconda env: `conda install -c conda-forge tpot`<br>\n",
    "> Ref: https://github.com/EpistasisLab/tpot\n",
    "> ##### Dask\n",
    "> In anaconda env: `conda install dask`<br>\n",
    "> Ref: https://docs.dask.org/en/latest/\n",
    "> ##### Graphviz\n",
    "> In anaconda env: `conda install graphviz`<br>\n",
    "> Ref: https://pypi.org/project/graphviz/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References on \"Evaluation of a Tree-based Pipeline Optimization Tool (TPOT) for Automating Data Science\":\n",
    "\n",
    "> Randal S. Olson, Ryan J. Urbanowicz, Peter C. Andrews, Nicole A. Lavender, La Creis Kidd, and Jason H. Moore (2016). Automating biomedical data science through tree-based pipeline optimization. Applications of Evolutionary Computation, pages 123-137.\n",
    "\n",
    ">Randal S. Olson, Nathan Bartley, Ryan J. Urbanowicz, and Jason H. Moore (2016). Evaluation of a Tree-based Pipeline Optimization Tool for Automating Data Science. Proceedings of GECCO 2016, pages 485-492."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA STRUCTURE (INPUT / OUTPU)\n",
    "> Data is loaded from a Toehold Sensor Database (data/2019-01-18_toehold_dataset.csv) which is comma delimited table  having the following columns of DNA encoded sub-sequences:\n",
    "organism, sequence_class, sequence_id, pre_seq\tpromoter, trigger, loop1, switch, loop2, stem1, atg, stem2m linkerm post_linker, output\t\n",
    "> #### Inpu vectors for all models can be defined in 3 distinct ways (DS=Data_Style):\n",
    "> **DS_1)**  Single DNA Sequence Input Vector / Trigger-ONLY / 30-nucleotides <br>\n",
    "> **DS_2)** Two Independent DNA Sequences as Input Vectors / ON & OFF states of toehold / OFF is 59 nucleotides / ON is 59+50=109 nucleotides <br>\n",
    "> **DS_3)** Two Independent DNA Extended Sequences as Input Vectors / ON & OFF states of toehold / OFF is 59+40=85 nucleotides / ON is 59+50+85=194 nucleotides <br> \n",
    "> *NOTE: pre_seq & promoter sub-sequences are NEVER used because they are not converted into mRNA (is in the plasmid but it is never in the functional toehold module), so it won't contribute in secondary structure at all. For this example in particular we use DS_1.*\n",
    "\n",
    "> #### Output is defined as:\n",
    "> **OUT_1)** Minimum free energy (MFE) of the RNA derived from the switch DNA sequence which is the real part that contributs to toehold functionality\n",
    "\n",
    "#### PROBLEM DEFINITION\n",
    "> Something very valuable to investigate for is to know if any of the input vector types (DS_1, DS_2 or DS_3) can be fed to a network to predict switch MFE. We would also want to know if training with DS_3 is better than with DS_2, of if DS_2 is also better than than DS_1, because in that case it would suggest the network is learning secondary structure prediction that would be transferable to other RNA based problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "## Import Libraries\n",
    "# General system libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from IPython.display import Image\n",
    "\n",
    "# Multiprocessing\n",
    "import multiprocessing\n",
    "\n",
    "# DNA/RNA Analysis Libraries (Biopython, ViennaRNA, pysster) \n",
    "# Biopython Lib\n",
    "import Bio\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import generic_rna, generic_dna, generic_protein, IUPAC\n",
    "# ViennaRNA Lib\n",
    "import RNA\n",
    "# pysster Lib\n",
    "from pysster import utils\n",
    "from pysster.Data import Data\n",
    "from pysster.Grid_Search import Grid_Search\n",
    "from pysster.One_Hot_Encoder import One_Hot_Encoder\n",
    "from pysster.Alphabet_Encoder import Alphabet_Encoder\n",
    "\n",
    "# Import TPOT libs\n",
    "from tpot import TPOTRegressor\n",
    "\n",
    "# Import sklearn libs\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import explained_variance_score, mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
    "from sklearn.metrics import median_absolute_error, r2_score\n",
    "\n",
    "# Math & Visualization Libs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "# Warnings\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Dataset\n",
    "Let's see what our file look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>off_id</th>\n",
       "      <th>on_id</th>\n",
       "      <th>source_sequence</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>pre_seq</th>\n",
       "      <th>promoter</th>\n",
       "      <th>trigger</th>\n",
       "      <th>loop1</th>\n",
       "      <th>switch</th>\n",
       "      <th>loop2</th>\n",
       "      <th>...</th>\n",
       "      <th>Cbn2_on</th>\n",
       "      <th>Cbn3_on</th>\n",
       "      <th>Cbn4_on</th>\n",
       "      <th>Cbn1_off</th>\n",
       "      <th>Cbn2_off</th>\n",
       "      <th>Cbn3_off</th>\n",
       "      <th>Cbn4_off</th>\n",
       "      <th>ON</th>\n",
       "      <th>OFF</th>\n",
       "      <th>ON_OFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AACCAAACACACAAACGCACAAAAAAAATAACGTAGGACTACTACT...</td>\n",
       "      <td>TCCAAGTAGTAGTCCTACGTTATTTTTTTTAACCAAACACACAAAC...</td>\n",
       "      <td>smallpoxsmallpox</td>\n",
       "      <td>smallpox_tile_6492smallpox_tile_6492</td>\n",
       "      <td>CTCTGGGCTAACTGTCGCGCCTCTGGGCTAACTGTCGCGC</td>\n",
       "      <td>TAATACGACTCACTATAGGGTAATACGACTCACTATAGGG</td>\n",
       "      <td>TCCAAGTAGTAGTCCTACGTTATTTTTTTTTCCAAGTAGTAGTCCT...</td>\n",
       "      <td>AACAACAACAAACAAAACAACAACAAACAA</td>\n",
       "      <td>AAAAAAAATAACGTAGGACTACTACTTGGAAAAAAAAATAACGTAG...</td>\n",
       "      <td>AACAGAGGAGAAACAGAGGAGA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591829</td>\n",
       "      <td>0.119432</td>\n",
       "      <td>0.055509</td>\n",
       "      <td>0.075791</td>\n",
       "      <td>0.810190</td>\n",
       "      <td>0.114019</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.332407</td>\n",
       "      <td>0.346076</td>\n",
       "      <td>-0.013669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AACCAAACACACAAACGCACAAAAAAAATTTGGATTTATTTATGTC...</td>\n",
       "      <td>ATGAGACATAAATAAATCCAAATTTTTTTTAACCAAACACACAAAC...</td>\n",
       "      <td>smallpoxsmallpox</td>\n",
       "      <td>smallpox_tile_19684smallpox_tile_19684</td>\n",
       "      <td>CTCTGGGCTAACTGTCGCGCCTCTGGGCTAACTGTCGCGC</td>\n",
       "      <td>TAATACGACTCACTATAGGGTAATACGACTCACTATAGGG</td>\n",
       "      <td>ATGAGACATAAATAAATCCAAATTTTTTTTATGAGACATAAATAAA...</td>\n",
       "      <td>AACAACAACAAACAAAACAACAACAAACAA</td>\n",
       "      <td>AAAAAAAATTTGGATTTATTTATGTCTCATAAAAAAAATTTGGATT...</td>\n",
       "      <td>AACAGAGGAGAAACAGAGGAGA</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244214</td>\n",
       "      <td>0.725170</td>\n",
       "      <td>0.030616</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.262134</td>\n",
       "      <td>0.071199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AACCAAACACACAAACGCACAAAAAAACATGAGCTTTGCTTTTTTC...</td>\n",
       "      <td>ACTTGAAAAAAGCAAAGCTCATGTTTTTTTAACCAAACACACAAAC...</td>\n",
       "      <td>human_PROX1human_PROX1</td>\n",
       "      <td>human_PROX1_tile_176human_PROX1_tile_176</td>\n",
       "      <td>CTCTGGGCTAACTGTCGCGCCTCTGGGCTAACTGTCGCGC</td>\n",
       "      <td>TAATACGACTCACTATAGGGTAATACGACTCACTATAGGG</td>\n",
       "      <td>ACTTGAAAAAAGCAAAGCTCATGTTTTTTTACTTGAAAAAAGCAAA...</td>\n",
       "      <td>AACAACAACAAACAAAACAACAACAAACAA</td>\n",
       "      <td>AAAAAAACATGAGCTTTGCTTTTTTCAAGTAAAAAAACATGAGCTT...</td>\n",
       "      <td>AACAGAGGAGAAACAGAGGAGA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121780</td>\n",
       "      <td>0.802118</td>\n",
       "      <td>0.150849</td>\n",
       "      <td>0.161256</td>\n",
       "      <td>0.595710</td>\n",
       "      <td>0.092185</td>\n",
       "      <td>0.883305</td>\n",
       "      <td>0.543077</td>\n",
       "      <td>0.340228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AACCAAACACACAAACGCACAAAAAAAGATTTTTTTCCGATGTTGA...</td>\n",
       "      <td>TGTATCAACATCGGAAAAAAATCTTTTTTTAACCAAACACACAAAC...</td>\n",
       "      <td>smallpoxsmallpox</td>\n",
       "      <td>smallpox_tile_7220smallpox_tile_7220</td>\n",
       "      <td>CTCTGGGCTAACTGTCGCGCCTCTGGGCTAACTGTCGCGC</td>\n",
       "      <td>TAATACGACTCACTATAGGGTAATACGACTCACTATAGGG</td>\n",
       "      <td>TGTATCAACATCGGAAAAAAATCTTTTTTTTGTATCAACATCGGAA...</td>\n",
       "      <td>AACAACAACAAACAAAACAACAACAAACAA</td>\n",
       "      <td>AAAAAAAGATTTTTTTCCGATGTTGATACAAAAAAAAGATTTTTTT...</td>\n",
       "      <td>AACAGAGGAGAAACAGAGGAGA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139674</td>\n",
       "      <td>0.459203</td>\n",
       "      <td>0.307549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136372</td>\n",
       "      <td>0.863628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660242</td>\n",
       "      <td>0.621209</td>\n",
       "      <td>0.039033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AACCAAACACACAAACGCACAAAAAAATGATTTCCATATCTTTGAT...</td>\n",
       "      <td>ACCCATCAAAGATATGGAAATCATTTTTTTAACCAAACACACAAAC...</td>\n",
       "      <td>smallpoxsmallpox</td>\n",
       "      <td>smallpox_tile_8336smallpox_tile_8336</td>\n",
       "      <td>CTCTGGGCTAACTGTCGCGCCTCTGGGCTAACTGTCGCGC</td>\n",
       "      <td>TAATACGACTCACTATAGGGTAATACGACTCACTATAGGG</td>\n",
       "      <td>ACCCATCAAAGATATGGAAATCATTTTTTTACCCATCAAAGATATG...</td>\n",
       "      <td>AACAACAACAAACAAAACAACAACAAACAA</td>\n",
       "      <td>AAAAAAATGATTTCCATATCTTTGATGGGTAAAAAAATGATTTCCA...</td>\n",
       "      <td>AACAGAGGAGAAACAGAGGAGA</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105460</td>\n",
       "      <td>0.587911</td>\n",
       "      <td>0.024022</td>\n",
       "      <td>0.377289</td>\n",
       "      <td>0.604974</td>\n",
       "      <td>0.017737</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.451116</td>\n",
       "      <td>0.213483</td>\n",
       "      <td>0.237633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              off_id  \\\n",
       "0  AACCAAACACACAAACGCACAAAAAAAATAACGTAGGACTACTACT...   \n",
       "1  AACCAAACACACAAACGCACAAAAAAAATTTGGATTTATTTATGTC...   \n",
       "2  AACCAAACACACAAACGCACAAAAAAACATGAGCTTTGCTTTTTTC...   \n",
       "3  AACCAAACACACAAACGCACAAAAAAAGATTTTTTTCCGATGTTGA...   \n",
       "4  AACCAAACACACAAACGCACAAAAAAATGATTTCCATATCTTTGAT...   \n",
       "\n",
       "                                               on_id         source_sequence  \\\n",
       "0  TCCAAGTAGTAGTCCTACGTTATTTTTTTTAACCAAACACACAAAC...        smallpoxsmallpox   \n",
       "1  ATGAGACATAAATAAATCCAAATTTTTTTTAACCAAACACACAAAC...        smallpoxsmallpox   \n",
       "2  ACTTGAAAAAAGCAAAGCTCATGTTTTTTTAACCAAACACACAAAC...  human_PROX1human_PROX1   \n",
       "3  TGTATCAACATCGGAAAAAAATCTTTTTTTAACCAAACACACAAAC...        smallpoxsmallpox   \n",
       "4  ACCCATCAAAGATATGGAAATCATTTTTTTAACCAAACACACAAAC...        smallpoxsmallpox   \n",
       "\n",
       "                                sequence_id  \\\n",
       "0      smallpox_tile_6492smallpox_tile_6492   \n",
       "1    smallpox_tile_19684smallpox_tile_19684   \n",
       "2  human_PROX1_tile_176human_PROX1_tile_176   \n",
       "3      smallpox_tile_7220smallpox_tile_7220   \n",
       "4      smallpox_tile_8336smallpox_tile_8336   \n",
       "\n",
       "                                    pre_seq  \\\n",
       "0  CTCTGGGCTAACTGTCGCGCCTCTGGGCTAACTGTCGCGC   \n",
       "1  CTCTGGGCTAACTGTCGCGCCTCTGGGCTAACTGTCGCGC   \n",
       "2  CTCTGGGCTAACTGTCGCGCCTCTGGGCTAACTGTCGCGC   \n",
       "3  CTCTGGGCTAACTGTCGCGCCTCTGGGCTAACTGTCGCGC   \n",
       "4  CTCTGGGCTAACTGTCGCGCCTCTGGGCTAACTGTCGCGC   \n",
       "\n",
       "                                   promoter  \\\n",
       "0  TAATACGACTCACTATAGGGTAATACGACTCACTATAGGG   \n",
       "1  TAATACGACTCACTATAGGGTAATACGACTCACTATAGGG   \n",
       "2  TAATACGACTCACTATAGGGTAATACGACTCACTATAGGG   \n",
       "3  TAATACGACTCACTATAGGGTAATACGACTCACTATAGGG   \n",
       "4  TAATACGACTCACTATAGGGTAATACGACTCACTATAGGG   \n",
       "\n",
       "                                             trigger  \\\n",
       "0  TCCAAGTAGTAGTCCTACGTTATTTTTTTTTCCAAGTAGTAGTCCT...   \n",
       "1  ATGAGACATAAATAAATCCAAATTTTTTTTATGAGACATAAATAAA...   \n",
       "2  ACTTGAAAAAAGCAAAGCTCATGTTTTTTTACTTGAAAAAAGCAAA...   \n",
       "3  TGTATCAACATCGGAAAAAAATCTTTTTTTTGTATCAACATCGGAA...   \n",
       "4  ACCCATCAAAGATATGGAAATCATTTTTTTACCCATCAAAGATATG...   \n",
       "\n",
       "                            loop1  \\\n",
       "0  AACAACAACAAACAAAACAACAACAAACAA   \n",
       "1  AACAACAACAAACAAAACAACAACAAACAA   \n",
       "2  AACAACAACAAACAAAACAACAACAAACAA   \n",
       "3  AACAACAACAAACAAAACAACAACAAACAA   \n",
       "4  AACAACAACAAACAAAACAACAACAAACAA   \n",
       "\n",
       "                                              switch                   loop2  \\\n",
       "0  AAAAAAAATAACGTAGGACTACTACTTGGAAAAAAAAATAACGTAG...  AACAGAGGAGAAACAGAGGAGA   \n",
       "1  AAAAAAAATTTGGATTTATTTATGTCTCATAAAAAAAATTTGGATT...  AACAGAGGAGAAACAGAGGAGA   \n",
       "2  AAAAAAACATGAGCTTTGCTTTTTTCAAGTAAAAAAACATGAGCTT...  AACAGAGGAGAAACAGAGGAGA   \n",
       "3  AAAAAAAGATTTTTTTCCGATGTTGATACAAAAAAAAGATTTTTTT...  AACAGAGGAGAAACAGAGGAGA   \n",
       "4  AAAAAAATGATTTCCATATCTTTGATGGGTAAAAAAATGATTTCCA...  AACAGAGGAGAAACAGAGGAGA   \n",
       "\n",
       "     ...      Cbn2_on   Cbn3_on   Cbn4_on  Cbn1_off  Cbn2_off  Cbn3_off  \\\n",
       "0    ...     0.591829  0.119432  0.055509  0.075791  0.810190  0.114019   \n",
       "1    ...     1.000000  0.000000  0.000000  0.244214  0.725170  0.030616   \n",
       "2    ...     0.000000  0.121780  0.802118  0.150849  0.161256  0.595710   \n",
       "3    ...     0.139674  0.459203  0.307549  0.000000  0.136372  0.863628   \n",
       "4    ...     0.105460  0.587911  0.024022  0.377289  0.604974  0.017737   \n",
       "\n",
       "   Cbn4_off        ON       OFF    ON_OFF  \n",
       "0  0.000000  0.332407  0.346076 -0.013669  \n",
       "1  0.000000  0.333333  0.262134  0.071199  \n",
       "2  0.092185  0.883305  0.543077  0.340228  \n",
       "3  0.000000  0.660242  0.621209  0.039033  \n",
       "4  0.000000  0.451116  0.213483  0.237633  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Data folder if not existent\n",
    "data_folder = \"data/\"\n",
    "if not os.path.isdir(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "\n",
    "# Define path to load desired Toehold dataset file (.csv)\n",
    "data_filename = \"2019-02-06_toehold_dataset_proc_on_off.csv\"\n",
    "data_path = data_folder + data_filename\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "#Show dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences retrieved: 30101\n",
      "\n",
      "Examples of Input Vector:\n",
      " AAAAAAAATAACGTAGGACTACTACTTGGAAAAAAAAATAACGTAGGACTACTACTTGGAAACAGAGGAGAAACAGAGGAGATCCAAGTCCAAGATGATGTAGTCCTACTAGTCCTAC\n",
      "\n",
      "Examples of Output Vector:\n",
      " -0.013669396\n"
     ]
    }
   ],
   "source": [
    "### Sequence ID data selection from main DataFrame\n",
    "id_data = data['sequence_id']\n",
    "\n",
    "### DNA Nucleotide dataset input selection and concatenation using different datastyles (i.e DS_1, DS_2, DS_3)\n",
    "# Data Style #1 (trigger only)\n",
    "#df_data_input = data['trigger']\n",
    "#df_data_output = data['target']\n",
    "\n",
    "# Data Style #2 (base ON/OFF)\n",
    "#df_off_data_input = data['switch'] + data['loop2'] + data['stem1'] + data['atg'] + data['stem2']\n",
    "#df_on_data_input = data['trigger'] + data['loop1'] + data['switch'] + data['loop2'] + data['stem1'] + data['atg'] + data['stem2']\n",
    "df_data_input = data['switch'] + data['loop2'] + data['stem1'] + data['atg'] + data['stem2']\n",
    "df_data_output = data['ON_OFF']\n",
    "\n",
    "# Data Style #3 (extended ON/OFF)\n",
    "#df_off_data_input = data['switch'] + data['loop2'] + data['stem1'] + data['atg'] + data['stem2'] + data['linker'] + data['post_linker']\n",
    "#df_on_data_input = data['trigger'] + data['loop1'] + data['switch'] + data['loop2'] + data['stem1'] + data['atg'] + data['stem2'] + data['linker'] + data['post_linker']\n",
    "#df_data_output = data['target']\n",
    "\n",
    "print(\"Number of sequences retrieved: \"+str(len(data.index)))\n",
    "print()\n",
    "print('Examples of Input Vector:')\n",
    "print(' ' + str(df_data_input[0]))\n",
    "print()\n",
    "print('Examples of Output Vector:')\n",
    "print(' ' + str(df_data_output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences saved to FASTA: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30101"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Prepare and save base FASTA file with id's and nucleotide sequence data only\n",
    "input_file = (data_folder + data_filename.replace('.csv','.fasta')) \n",
    "records = (SeqRecord(Seq(str(seq), generic_dna), str(index),'',str(id_data[int(index)])) for index, seq in enumerate(df_data_input))\n",
    "print('Sequences saved to FASTA: ')\n",
    "SeqIO.write(records, input_file, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample DNA Seq String:\n",
      "AAAAAAAATAACGTAGGACTACTACTTGGAAAAAAAAATAACGTAGGACTACTACTTGGAAACAGAGGAGAAACAGAGGAGATCCAAGTCCAAGATGATGTAGTCCTACTAGTCCTAC\n",
      "\n",
      "Sample DNA Seq Vector:\n",
      "['A' 'A' 'A' 'A' 'A' 'A' 'A' 'A' 'T' 'A' 'A' 'C' 'G' 'T' 'A' 'G' 'G' 'A'\n",
      " 'C' 'T' 'A' 'C' 'T' 'A' 'C' 'T' 'T' 'G' 'G' 'A' 'A' 'A' 'A' 'A' 'A' 'A'\n",
      " 'A' 'A' 'T' 'A' 'A' 'C' 'G' 'T' 'A' 'G' 'G' 'A' 'C' 'T' 'A' 'C' 'T' 'A'\n",
      " 'C' 'T' 'T' 'G' 'G' 'A' 'A' 'A' 'C' 'A' 'G' 'A' 'G' 'G' 'A' 'G' 'A' 'A'\n",
      " 'A' 'C' 'A' 'G' 'A' 'G' 'G' 'A' 'G' 'A' 'T' 'C' 'C' 'A' 'A' 'G' 'T' 'C'\n",
      " 'C' 'A' 'A' 'G' 'A' 'T' 'G' 'A' 'T' 'G' 'T' 'A' 'G' 'T' 'C' 'C' 'T' 'A'\n",
      " 'C' 'T' 'A' 'G' 'T' 'C' 'C' 'T' 'A' 'C']\n",
      "\n",
      "One-Hot Version:\n",
      "[[1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 1 1 1 1\n",
      "  1 1 0 1 1 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 1 1 0 1 0 1 0 0 1 0 1 1\n",
      "  1 0 1 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 1\n",
      "  0 0 1 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      "  0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      "  1 0 0 0 0 1 1 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 0 1 0 0\n",
      "  0 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0\n",
      "  0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 1 0\n",
      "  0 1 0 0 1 0 0 1 0 0]]\n",
      "\n",
      "Categorical/numerical Version:\n",
      "[0 0 0 0 0 0 0 0 3 0 0 1 2 3 0 2 2 0 1 3 0 1 3 0 1 3 3 2 2 0 0 0 0 0 0 0 0\n",
      " 0 3 0 0 1 2 3 0 2 2 0 1 3 0 1 3 0 1 3 3 2 2 0 0 0 1 0 2 0 2 2 0 2 0 0 0 1\n",
      " 0 2 0 2 2 0 2 0 3 1 1 0 0 2 3 1 1 0 0 2 0 3 2 0 3 2 3 0 2 3 1 1 3 0 1 3 0\n",
      " 2 3 1 1 3 0 1]\n"
     ]
    }
   ],
   "source": [
    "# ONE-HOT encode input sequences\n",
    "# Define 4-letter alphabet \"ACGT\" and Convert input dataset\n",
    "n_data_input = []\n",
    "one_data_input = []\n",
    "oh_data_input = []\n",
    "one = One_Hot_Encoder(\"ACGT\")\n",
    "for index, seq in df_data_input.items():\n",
    "    n_data_input.append((np.asarray(list(seq))))\n",
    "    one_hot_seq = one.encode(seq)                           #ONE HOT ENCODE, and then\n",
    "    oh_data_input.append(np.transpose(one_hot_seq))               \n",
    "    one_data_input.append(np.argmax((one_hot_seq), axis=1)) #To numerical for TPOT\n",
    "\n",
    "#Print sample\n",
    "print('Sample DNA Seq String:')\n",
    "print(df_data_input[0])\n",
    "print()\n",
    "print('Sample DNA Seq Vector:')\n",
    "print(n_data_input[0])\n",
    "print()\n",
    "print('One-Hot Version:')\n",
    "print(oh_data_input[0])\n",
    "print()\n",
    "print('Categorical/numerical Version:')\n",
    "print(one_data_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribution of normalized output\n",
      "MinVal = -1.0(0.0), MaxVal = 1.0(1.0)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Normalize output vector\n",
    "x = df_data_output.values #returns a numpy array\n",
    "x = x.reshape(-1, 1)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "norm_data_output = x_scaled.ravel()\n",
    "\n",
    "# Display Normalized Output distribution\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(color_codes=True)\n",
    "print('Distribution of normalized output')\n",
    "print('MinVal = ' + str(min(df_data_output))+ '(0.0), ' +\n",
    "      'MaxVal = ' + str(max(df_data_output))+ '(1.0)')\n",
    "\n",
    "sns.distplot(norm_data_output, kde=True, rug=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated Machine Learning Model Discovery using Genetic Programming\n",
    "\n",
    "This approach uses [TPOT](https://epistasislab.github.io/tpot/api/), a Python library developed for automatic machine learning feature preprocessing, model selection, and hyperparameter tuning. TPOT uses [genetic programming](http://geneticprogramming.com/tutorial/) to find the best machine learning pipeline for a dataset by evaluating thousands of possibilites. \n",
    "\n",
    "The machine learning pipeline in this context consists of:\n",
    "\n",
    "1. Feature Preprocessing\n",
    "  * Imputing missing values and scaling values\n",
    "  * Constructing new features such as polynomial transformations\n",
    "2. Feature selection\n",
    "  * Dimensionality reduction, for example using PCA and other techniques\n",
    "3. Model Selection\n",
    "  * Evaluting a number of machine learning models\n",
    "4. Hyperparameter tuning\n",
    "  * Finding the optimal settings of the model for the particular problem\n",
    "\n",
    "TPOT is one of a class of artificial intelligence (AI) methods known as [auto-ml (short for automated machine learning)](https://www.kdnuggets.com/2017/01/current-state-automated-machine-learning.html) which aims to simplify the work of the data scientist by automatically finding the optimal (or near-optimal) feature preprocessing steps and model for the problem. Machine learning is  typically a very time-consuming and knowledge-intensive part of a data science problem. Auto-ml is not designed to replace the data scientist, but rather free her to work on more important aspects of the complete problem, such as acquiring data and interpreting the model results. In effect, TPOT, and auto-ml in general, will in effect be a \"data science assistant\" that will be another tool among many used by data scientists. Machine learning is only one part of the data science process, and it still takes a human to weave the different aspects of a problem together into a complete working product.\n",
    "\n",
    "Other entries in the field of auto - ml include:\n",
    "* [Auto-sklearn](https://automl.github.io/auto-sklearn/stable/)\n",
    "* [H20](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/welcome.html)\n",
    "* [Google Cloud AutoML](https://cloud.google.com/automl/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has input shape:(30101, 118), and output shape: (30101,)\n",
      "Data split into Train(75.0%) and Test(25.0%) sets\n"
     ]
    }
   ],
   "source": [
    "# Supervised REGRESSION problem for toehold design using TPOT\n",
    "\n",
    "# Divide dataset into training and testing sets\n",
    "data_input = one_data_input \n",
    "data_output = norm_data_output\n",
    "print('Dataset has input shape:'+ str(np.shape(data_input)) + ', and output shape: '+ str(np.shape(data_output)))\n",
    "\n",
    "# Define Train and Test ratios\n",
    "train_size = 0.75\n",
    "test_size = 0.25\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_input, data_output,train_size=train_size, test_size=test_size)\n",
    "print('Data split into Train(' + str(train_size*100) + '%) and Test(' + str(test_size*100) +'%) sets')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train TPOT classifier (multiprocessing)\n",
    "# Ref: https://epistasislab.github.io/tpot/api/\n",
    "tpot = TPOTRegressor(generations = 5, \n",
    "                     population_size = 50,\n",
    "                     n_jobs = -1,\n",
    "                     max_time_mins = 120,\n",
    "                     max_eval_time_mins = 5,\n",
    "                     #config_dict = 'TPOT MDR',\n",
    "                     periodic_checkpoint_folder = 'models/',\n",
    "                     verbosity = 3)\n",
    "\n",
    "# TPOT SETTINGS:\n",
    "#   > generations = Number of iterations to the run pipeline optimization process.\n",
    "#   > population_size = Number of individuals to retain in the genetic programming population every generation.\n",
    "#   > offspring_size = Number of offspring to produce in each genetic programming generation. \n",
    "#   > mutation_rate = Mutation rate for the genetic programming algorithm in the range [0.0, 1.0].\n",
    "#   > crossover_rate Crossover rate for the genetic programming algorithm in the range [0.0, 1.0].\n",
    "#   > scoring = Function used to evaluate the quality of a given pipeline for the regression problem.\n",
    "#               Note that it is recommended to use the neg version of mean squared error and related \n",
    "#               metrics so TPOT will minimize (instead of maximize) the metric. \n",
    "#   > cv = Cross-validation strategy used when evaluating pipelines. \n",
    "#   > subsample = Fraction of training samples that are used during the TPOT optimization process. \n",
    "#   > n_jobs = Number of processes to use in parallel for evaluating pipelines during the TPOT optimization process. \n",
    "#   > max_time_mins = How many minutes TPOT has to optimize the pipeline. \n",
    "#   > max_eval_time_mins = How many minutes TPOT has to evaluate a single pipeline. \n",
    "#   > random_state = The seed of the pseudo random number generator used in TPOT. \n",
    "#   > config_dict = A configuration dictionary for customizing the TPOT operators and parameters\n",
    "#          Possible inputs are:\n",
    "#               Python dictionary, TPOT will use your custom configuration,\n",
    "#               string 'TPOT light', TPOT will use a built-in configuration with only fast models and preprocessors, or\n",
    "#               string 'TPOT MDR', TPOT will use a built-in configuration specialized for genomic studies, or\n",
    "#               string 'TPOT sparse': TPOT will use a configuration dictionary with a one-hot encoder and the operators normally included in TPOT that also support sparse matrices, or\n",
    "#               None, TPOT will use the default TPOTRegressor configuration.\n",
    "#   > warm_start = Flag indicating whether the TPOT instance will reuse the population from previous calls to fit(). \n",
    "#   > memory = If supplied, pipeline will cache each transformer after calling fit. \n",
    "#   > use_dask = Whether to use Dask-ML's pipeline optimiziations. \n",
    "#   > periodic_checkpoint_folder = f supplied, a folder in which TPOT will periodically save the best pipeline so far while optimizing.\n",
    "#   > early_stop = How many generations TPOT checks whether there is no improvement in optimization process. \n",
    "#   > verbosity = How much information TPOT communicates while it's running. \n",
    "#   > disable_update_check = Flag indicating whether the TPOT version checker should be disabled.                      \n",
    "#    Note: You can check the input parameters of regrtessor of classifier in \n",
    "#          https://epistasislab.github.io/tpot/api/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d068b9ff202d4c9b8b7308a5db941bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=50, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped pipeline #28 due to time out. Continuing to the next pipeline.\n",
      "Saving best periodic pipeline to models/pipeline_2019.02.07_12-43-50.py\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Automatic alpha grid generation is not supported for l1_ratio=0. Please supply a grid by providing your estimator with the appropriate `alphas=` argument.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='epsilon_insensitive' are not supported when dual=False, Parameters: penalty='l2', loss='epsilon_insensitive', dual=False\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 __init__() got an unexpected keyword argument 'max_depth'\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Expected n_neighbors <= n_samples,  but n_samples = 50, n_neighbors = 87\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "-0.010581187569610238\n"
     ]
    }
   ],
   "source": [
    "# Run traning\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "# Print last obtaned R2 score after pipeline discovery\n",
    "print(tpot.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Models folder if not existent\n",
    "model_folder = \"models/\"\n",
    "if not os.path.isdir(model_folder):\n",
    "    os.makedirs(model_folder)\n",
    "\n",
    "# Define path to save TPOT optimized predictive model (.py)\n",
    "model_filename = \"optimized_tpot_pipeline.py\"\n",
    "model_path = model_folder + model_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save TPOT optimized predictive model (.py)\n",
    "tpot.export(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features\n",
    "Let's see what our features vectors look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_0</th>\n",
       "      <th>n_1</th>\n",
       "      <th>n_2</th>\n",
       "      <th>n_3</th>\n",
       "      <th>n_4</th>\n",
       "      <th>n_5</th>\n",
       "      <th>n_6</th>\n",
       "      <th>n_7</th>\n",
       "      <th>n_8</th>\n",
       "      <th>n_9</th>\n",
       "      <th>...</th>\n",
       "      <th>n_108</th>\n",
       "      <th>n_109</th>\n",
       "      <th>n_110</th>\n",
       "      <th>n_111</th>\n",
       "      <th>n_112</th>\n",
       "      <th>n_113</th>\n",
       "      <th>n_114</th>\n",
       "      <th>n_115</th>\n",
       "      <th>n_116</th>\n",
       "      <th>n_117</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_0  n_1  n_2  n_3  n_4  n_5  n_6  n_7  n_8  n_9  ...    n_108  n_109  \\\n",
       "0    0    0    0    0    0    0    0    0    3    0  ...        1      3   \n",
       "1    0    0    0    0    0    0    0    0    3    3  ...        1      0   \n",
       "2    0    0    0    0    0    0    0    1    0    3  ...        1      0   \n",
       "3    0    0    0    0    0    0    0    2    0    3  ...        0      0   \n",
       "4    0    0    0    0    0    0    0    3    2    0  ...        0      0   \n",
       "\n",
       "   n_110  n_111  n_112  n_113  n_114  n_115  n_116  n_117  \n",
       "0      0      2      3      1      1      3      0      1  \n",
       "1      0      0      3      0      0      0      3      1  \n",
       "2      0      2      1      0      0      0      2      1  \n",
       "3      3      1      2      2      0      0      0      0  \n",
       "4      2      0      3      0      3      2      2      0  \n",
       "\n",
       "[5 rows x 118 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_input_feature_names = [('n_' + str(item)) for item in list(range(len(one_data_input[0])))]\n",
    "data_tpot = pd.DataFrame(data_input, columns=data_input_feature_names)\n",
    "display(data_tpot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target\n",
    "Let's see what our target that we would like to predict looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.493165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.535600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.670114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.519516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.618817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     target\n",
       "0  0.493165\n",
       "1  0.535600\n",
       "2  0.670114\n",
       "3  0.519516\n",
       "4  0.618817"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_tpot = pd.DataFrame(norm_data_output)\n",
    "target_tpot.rename(columns={0: 'target'}, inplace=True)\n",
    "display(target_tpot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data to csv\n",
    "TPOT requires a local data file. We're going to save it to `data/__________tpot.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_0</th>\n",
       "      <th>n_1</th>\n",
       "      <th>n_2</th>\n",
       "      <th>n_3</th>\n",
       "      <th>n_4</th>\n",
       "      <th>n_5</th>\n",
       "      <th>n_6</th>\n",
       "      <th>n_7</th>\n",
       "      <th>n_8</th>\n",
       "      <th>n_9</th>\n",
       "      <th>...</th>\n",
       "      <th>n_109</th>\n",
       "      <th>n_110</th>\n",
       "      <th>n_111</th>\n",
       "      <th>n_112</th>\n",
       "      <th>n_113</th>\n",
       "      <th>n_114</th>\n",
       "      <th>n_115</th>\n",
       "      <th>n_116</th>\n",
       "      <th>n_117</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.493165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.535600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.670114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.519516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.618817</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_0  n_1  n_2  n_3  n_4  n_5  n_6  n_7  n_8  n_9    ...     n_109  n_110  \\\n",
       "0    0    0    0    0    0    0    0    0    3    0    ...         3      0   \n",
       "1    0    0    0    0    0    0    0    0    3    3    ...         0      0   \n",
       "2    0    0    0    0    0    0    0    1    0    3    ...         0      0   \n",
       "3    0    0    0    0    0    0    0    2    0    3    ...         0      3   \n",
       "4    0    0    0    0    0    0    0    3    2    0    ...         0      2   \n",
       "\n",
       "   n_111  n_112  n_113  n_114  n_115  n_116  n_117    target  \n",
       "0      2      3      1      1      3      0      1  0.493165  \n",
       "1      0      3      0      0      0      3      1  0.535600  \n",
       "2      2      1      0      0      0      2      1  0.670114  \n",
       "3      1      2      2      0      0      0      0  0.519516  \n",
       "4      0      3      0      3      2      2      0  0.618817  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path_tpot = (data_folder + data_filename.replace('.csv','_tpot.csv')) \n",
    "tpot_tmp = pd.concat([data_tpot, target_tpot], axis=1, join_axes=[data_tpot.index])\n",
    "tpot_tmp.to_csv(data_path_tpot, index=False)\n",
    "display(tpot_tmp.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read TPOT discovered model definition (exported  .py code) and train on data\n",
    "This code does a quick check to make sure data was written the right way for use with `'models/optimized_tpot_pipeline.py'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-----------------------------------------------------------------------------------------------\n",
    "##------------------- IMPORTED CODE FROM LATEST \"tpot_*******_pipeline.py\" ----------------------\n",
    "#\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tpot.builtins import OneHotEncoder\n",
    "\n",
    "# NOTE: Make sure that the class is labeled 'target' in the data file\n",
    "tpot_data = np.recfromcsv(data_path_tpot, dtype=np.float64)\n",
    "features = np.delete(tpot_data.view(np.float64).reshape(tpot_data.size, -1), tpot_data.dtype.names.index('target'), axis=1)\n",
    "\n",
    "training_features, testing_features, training_target, testing_target = \\\n",
    "            train_test_split(features, tpot_data['target'], random_state=None)\n",
    "\n",
    "# Average CV score on the training set was:-0.0007189100616268919\n",
    "exported_pipeline = make_pipeline(\n",
    "    OneHotEncoder(minimum_fraction=0.1, sparse=False, threshold=10),\n",
    "    RidgeCV()\n",
    ")\n",
    "\n",
    "exported_pipeline.fit(training_features, training_target)\n",
    "results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "#\n",
    "##---------------------------------- END OF IMPORTED CODE ---------------------------------------\n",
    "##-----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPOT Pipeline Definition:\n",
      "Pipeline(memory=None,\n",
      "     steps=[('onehotencoder', OneHotEncoder(categorical_features=[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True,...None, fit_intercept=True,\n",
      "    gcv_mode=None, normalize=False, scoring=None, store_cv_values=False))])\n"
     ]
    }
   ],
   "source": [
    "print('TPOT Pipeline Definition:')\n",
    "print(exported_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "tree must be Booster, XGBModel or dict instance",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5bf76e9351e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mmax_num_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                 show_values=True)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_size_inches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/py35/lib/python3.5/site-packages/xgboost/plotting.py\u001b[0m in \u001b[0;36mplot_importance\u001b[0;34m(booster, ax, height, xlim, ylim, title, xlabel, ylabel, importance_type, max_num_features, grid, show_values, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mimportance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbooster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tree must be Booster, XGBModel or dict instance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportance\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: tree must be Booster, XGBModel or dict instance"
     ]
    }
   ],
   "source": [
    "# plot feature importance\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from xgboost import plot_importance, plot_tree\n",
    "sns.set(font_scale = 1)\n",
    "ax = plot_importance(booster = exported_pipeline,\n",
    "                ax=None, \n",
    "                height=1, \n",
    "                xlim=None, \n",
    "                ylim=None, \n",
    "                title='Feature importance', \n",
    "                xlabel='F score', \n",
    "                ylabel='Features', \n",
    "                importance_type='weight', \n",
    "                max_num_features=None, \n",
    "                grid=False, \n",
    "                show_values=True)\n",
    "\n",
    "ax.figure.set_size_inches(10,8)\n",
    "plt.show()\n",
    "\n",
    "print('TPOT Pipeline Graph:')\n",
    "n_trees = 10\n",
    "for tree in range(n_subplots):\n",
    "    print('>> Tree #' + str(tree))\n",
    "    plot_tree(exported_pipeline, num_trees=tree, rankdir='LR')\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(100, 100)\n",
    "    fig.savefig(model_path.replace('.py','.png'))\n",
    "    plt.figure(figsize=(10000,10000))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance (Score) of discovered model\n",
    "Here we propose to use an R2 score primarily, which is basically a normalized (to variance) metric of mean squared error (ranging from 0 to 1). R2=0 indicates that the model explains none of the variability of the response data around its mean, while R2=1 indicates that the model explains all the variability of the response data around its mean. Other scores are also presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPOT performance for TRAINING & TESTING sets \n",
    "# The following scores are used:\n",
    "    # >> Explained variance regression function (Good > 0.5)\n",
    "    # >> Mean absolute error regression loss\n",
    "    # >> Mean squared error regression loss\n",
    "    # >> Mean squared logarithmic error regression loss\n",
    "    # >> Median absolute error regression loss\n",
    "    # >> R^2 (coefficient of determination) regression score function.\n",
    "    # REF: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "    \n",
    "training_results = exported_pipeline.predict(training_features)\n",
    "testing_results = exported_pipeline.predict(testing_features)\n",
    "\n",
    "# Calculate TPOT model performance scores on Training set: \n",
    "y_true = np.array(training_target)\n",
    "y_pred = np.array(training_results)\n",
    "\n",
    "tpot_training_evs = explained_variance_score(y_true, y_pred, multioutput='uniform_average')\n",
    "tpot_training_mae = mean_absolute_error(y_true, y_pred)\n",
    "tpot_training_mse = mean_squared_error(y_true, y_pred)  \n",
    "tpot_training_mle = mean_squared_log_error(y_true, y_pred) \n",
    "tpot_training_dle = median_absolute_error(y_true, y_pred)\n",
    "tpot_training_r2s = r2_score(y_true, y_pred, multioutput='variance_weighted') \n",
    "\n",
    "\n",
    "# Calculate TPOT model performance on Training set: \n",
    "y_true = np.array(testing_target)\n",
    "y_pred = np.array(testing_results)\n",
    "\n",
    "tpot_testing_evs = explained_variance_score(y_true, y_pred, multioutput='uniform_average')\n",
    "tpot_testing_mae = mean_absolute_error(y_true, y_pred)\n",
    "tpot_testing_mse = mean_squared_error(y_true, y_pred)  \n",
    "tpot_testing_mle = mean_squared_log_error(y_true, y_pred) \n",
    "tpot_testing_dle = median_absolute_error(y_true, y_pred)\n",
    "tpot_testing_r2s = r2_score(y_true, y_pred, multioutput='variance_weighted') \n",
    "\n",
    "\n",
    "#Calculate R2 score directly from TPOT to compare/confirm  \"sklearn\" algorithms:\n",
    "tpot_training_r2s_base = exported_pipeline.score(training_features, training_target)\n",
    "tpot_testing_r2s_base  = exported_pipeline.score(testing_features, testing_target)\n",
    "\n",
    "if (tpot_training_r2s == tpot_training_r2s_base)and(tpot_testing_r2s == tpot_testing_r2s_base):\n",
    "    print(\"Everything looks appropiately calculated (Sklearn r2 scores matches TPOT r2 score)\")\n",
    "else:\n",
    "    print(\"Score calculation missmatch, please revise!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display All performance scores in single table\n",
    "score_column_names = ['Training (TPOT)', 'Testing (TPOT)']\n",
    "score_row_names    = ['Explained Variance',\n",
    "                      'Mean absolute error',\n",
    "                      'Mean squared error',\n",
    "                      'Mean squared log error',\n",
    "                      'Median absolute error',\n",
    "                      'R^2 (sklearn, tpot)' ]\n",
    "\n",
    "score_matrix = [[tpot_training_evs , tpot_testing_evs],\n",
    "                [tpot_training_mae , tpot_testing_mae],\n",
    "                [tpot_training_mse , tpot_testing_mse],\n",
    "                [tpot_training_mle , tpot_testing_mle],\n",
    "                [tpot_training_dle , tpot_testing_dle],\n",
    "                [tpot_training_r2s , tpot_testing_r2s]]\n",
    "\n",
    "tpot_score_df = pd.DataFrame(score_matrix, columns=score_column_names, index=score_row_names)\n",
    "display(tpot_score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with manually produced regressor\n",
    "For comparison, we will produce a benchmark regressor manually and then we will calculate the same scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-----------------------------------------------------------------------------------------------\n",
    "##------------------- RANDOM MODEL USING DECISION TREES (BENCHMARK)  ----------------------------\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def performance_metric(y_true, y_predict):\n",
    "    \"\"\" Calculates and returns the performance score between \n",
    "        true and predicted values based on the metric chosen. \"\"\"\n",
    "    score = r2_score(y_true, y_predict)\n",
    "    return score\n",
    "\n",
    "def fit_model(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    cv_sets = ShuffleSplit(n_splits=10, test_size=0.20, random_state=0)\n",
    "    regressor = DecisionTreeRegressor(random_state=42)\n",
    "    params = {'max_depth' : np.array(range(1,10))}\n",
    "    scoring_fnc = make_scorer(performance_metric)\n",
    "    grid = GridSearchCV(regressor, cv=cv_sets, param_grid=params, scoring=scoring_fnc)\n",
    "    grid = grid.fit(X, y)\n",
    "    return grid.best_estimator_\n",
    "\n",
    "reg = fit_model(training_features, training_target)\n",
    "print(\"Standard Model created and estimated!\")\n",
    "\n",
    "#\n",
    "##---------------------------------- END OF MODEL CODE ------------------------------------------\n",
    "##-----------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard model performance for TRAINING & TESTING sets \n",
    "# The following scores are used:\n",
    "    # >> Explained variance regression function (Good > 0.5)\n",
    "    # >> Mean absolute error regression loss\n",
    "    # >> Mean squared error regression loss\n",
    "    # >> Mean squared logarithmic error regression loss\n",
    "    # >> Median absolute error regression loss\n",
    "    # >> R^2 (coefficient of determination) regression score function.\n",
    "    # REF: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "    \n",
    "training_results = reg.predict(training_features)\n",
    "testing_results = reg.predict(testing_features)\n",
    "\n",
    "# Calculate Standard model performance scores on Training set: \n",
    "y_true = np.array(training_target)\n",
    "y_pred = np.array(training_results)\n",
    "\n",
    "std_training_evs = explained_variance_score(y_true, y_pred, multioutput='uniform_average')\n",
    "std_training_mae = mean_absolute_error(y_true, y_pred)\n",
    "std_training_mse = mean_squared_error(y_true, y_pred)  \n",
    "std_training_mle = mean_squared_log_error(y_true, y_pred) \n",
    "std_training_dle = median_absolute_error(y_true, y_pred)\n",
    "std_training_r2s = r2_score(y_true, y_pred, multioutput='variance_weighted') \n",
    "\n",
    "\n",
    "# Calculate Standard model performance on Training set: \n",
    "y_true = np.array(testing_target)\n",
    "y_pred = np.array(testing_results)\n",
    "\n",
    "std_testing_evs = explained_variance_score(y_true, y_pred, multioutput='uniform_average')\n",
    "std_testing_mae = mean_absolute_error(y_true, y_pred)\n",
    "std_testing_mse = mean_squared_error(y_true, y_pred)  \n",
    "std_testing_mle = mean_squared_log_error(y_true, y_pred) \n",
    "std_testing_dle = median_absolute_error(y_true, y_pred)\n",
    "std_testing_r2s = r2_score(y_true, y_pred, multioutput='variance_weighted') \n",
    "\n",
    "\n",
    "#Display All performance scores in single table\n",
    "score_column_names = ['Training (STD)', 'Testing (STD)']\n",
    "score_row_names    = ['Explained Variance',\n",
    "                      'Mean absolute error',\n",
    "                      'Mean squared error',\n",
    "                      'Mean squared log error',\n",
    "                      'Median absolute error',\n",
    "                      'R^2 (sklearn, tpot)']\n",
    "\n",
    "score_matrix = [[std_training_evs , std_testing_evs],\n",
    "                [std_training_mae , std_testing_mae],\n",
    "                [std_training_mse , std_testing_mse],\n",
    "                [std_training_mle , std_testing_mle],\n",
    "                [std_training_dle , std_testing_dle],\n",
    "                [std_training_r2s , std_testing_r2s]]\n",
    "\n",
    "std_score_df = pd.DataFrame(score_matrix, columns=score_column_names, index=score_row_names)\n",
    "display(std_score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of comparative r2 scores (Standard vs TPOT)\n",
    "\n",
    "The following summarizes the scores from the pipeline created by tpot and a comparision with a decisiontree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('PERFORMANCE OF REGRESSOR MODELS')\n",
    "score_column_names = ['Standard (r2)', 'TPOT (r2)']\n",
    "score_row_names    = ['Train',\n",
    "                      'Test',]\n",
    "\n",
    "score_matrix = [[std_training_r2s , tpot_training_r2s],\n",
    "                [std_testing_r2s  , tpot_testing_r2s]]\n",
    "\n",
    "score_df = pd.DataFrame(score_matrix, columns=score_column_names, index=score_row_names)\n",
    "display(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance (Score) of discovered model on random data outputs\n",
    "Here we propose to use an R2 score primarily, which is basically a normalized (to variance) metric of mean squared error (ranging from 0 to 1). R2=0 indicates that the model explains none of the variability of the response data around its mean, while R2=1 indicates that the model explains all the variability of the response data around its mean. Other scores are also presented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_data_output = data['random_mfe']\n",
    "\n",
    "# Normalize output vector\n",
    "x = random_data_output.values #returns a numpy array\n",
    "x = x.reshape(-1, 1)\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "random_norm_data_output = x_scaled.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>random_mfe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.817640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.840286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.853397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.846246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.885578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   random_mfe\n",
       "0    0.817640\n",
       "1    0.840286\n",
       "2    0.853397\n",
       "3    0.846246\n",
       "4    0.885578"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_target_tpot = pd.DataFrame(random_norm_data_output)\n",
    "random_target_tpot.rename(columns={0: 'random_mfe'}, inplace=True)\n",
    "display(random_target_tpot.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Make sure that the class is labeled 'random_mfe' in the data file\n",
    "random_training_features, random_testing_features, random_training_target, random_testing_target = \\\n",
    "            train_test_split(features, random_target_tpot, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything looks appropiately calculated (Sklearn r2 scores matches TPOT r2 score)\n"
     ]
    }
   ],
   "source": [
    "# TPOT performance for TRAINING & TESTING sets \n",
    "# The following scores are used:\n",
    "    # >> Explained variance regression function (Good > 0.5)\n",
    "    # >> Mean absolute error regression loss\n",
    "    # >> Mean squared error regression loss\n",
    "    # >> Mean squared logarithmic error regression loss\n",
    "    # >> Median absolute error regression loss\n",
    "    # >> R^2 (coefficient of determination) regression score function.\n",
    "    # REF: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "    \n",
    "random_training_results = exported_pipeline.predict(random_training_features)\n",
    "random_testing_results = exported_pipeline.predict(random_testing_features)\n",
    "\n",
    "# Calculate TPOT model performance scores on Training set: \n",
    "y_true = np.array(random_training_target)\n",
    "y_pred = np.array(random_training_results)\n",
    "\n",
    "tpot_training_evs = explained_variance_score(y_true, y_pred, multioutput='uniform_average')\n",
    "tpot_training_mae = mean_absolute_error(y_true, y_pred)\n",
    "tpot_training_mse = mean_squared_error(y_true, y_pred)  \n",
    "tpot_training_mle = mean_squared_log_error(y_true, y_pred) \n",
    "tpot_training_dle = median_absolute_error(y_true, y_pred)\n",
    "tpot_training_r2s = r2_score(y_true, y_pred, multioutput='variance_weighted') \n",
    "\n",
    "\n",
    "# Calculate TPOT model performance on Training set: \n",
    "y_true = np.array(random_testing_target)\n",
    "y_pred = np.array(random_testing_results)\n",
    "\n",
    "tpot_testing_evs = explained_variance_score(y_true, y_pred, multioutput='uniform_average')\n",
    "tpot_testing_mae = mean_absolute_error(y_true, y_pred)\n",
    "tpot_testing_mse = mean_squared_error(y_true, y_pred)  \n",
    "tpot_testing_mle = mean_squared_log_error(y_true, y_pred) \n",
    "tpot_testing_dle = median_absolute_error(y_true, y_pred)\n",
    "tpot_testing_r2s = r2_score(y_true, y_pred, multioutput='variance_weighted') \n",
    "\n",
    "\n",
    "#Calculate R2 score directly from TPOT to compare/confirm  \"sklearn\" algorithms:\n",
    "tpot_training_r2s_base = exported_pipeline.score(random_training_features, random_training_target)\n",
    "tpot_testing_r2s_base  = exported_pipeline.score(random_testing_features, random_testing_target)\n",
    "\n",
    "if (tpot_training_r2s == tpot_training_r2s_base)and(tpot_testing_r2s == tpot_testing_r2s_base):\n",
    "    print(\"Everything looks appropiately calculated (Sklearn r2 scores matches TPOT r2 score)\")\n",
    "else:\n",
    "    print(\"Score calculation missmatch, please revise!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training (RAND-TPOT)</th>\n",
       "      <th>Testing (RAND-TPOT)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Explained Variance</th>\n",
       "      <td>-6.811434</td>\n",
       "      <td>-6.593092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean absolute error</th>\n",
       "      <td>0.307403</td>\n",
       "      <td>0.306990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean squared error</th>\n",
       "      <td>0.113355</td>\n",
       "      <td>0.112828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean squared log error</th>\n",
       "      <td>0.041312</td>\n",
       "      <td>0.041061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Median absolute error</th>\n",
       "      <td>0.305626</td>\n",
       "      <td>0.305734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>R^2 (sklearn, tpot)</th>\n",
       "      <td>-44.332131</td>\n",
       "      <td>-43.482532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Training (RAND-TPOT)  Testing (RAND-TPOT)\n",
       "Explained Variance                 -6.811434            -6.593092\n",
       "Mean absolute error                 0.307403             0.306990\n",
       "Mean squared error                  0.113355             0.112828\n",
       "Mean squared log error              0.041312             0.041061\n",
       "Median absolute error               0.305626             0.305734\n",
       "R^2 (sklearn, tpot)               -44.332131           -43.482532"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Display All performance scores in single table\n",
    "score_column_names = ['Training (RAND-TPOT)', 'Testing (RAND-TPOT)']\n",
    "score_row_names    = ['Explained Variance',\n",
    "                      'Mean absolute error',\n",
    "                      'Mean squared error',\n",
    "                      'Mean squared log error',\n",
    "                      'Median absolute error',\n",
    "                      'R^2 (sklearn, tpot)' ]\n",
    "\n",
    "score_matrix = [[tpot_training_evs , tpot_testing_evs],\n",
    "                [tpot_training_mae , tpot_testing_mae],\n",
    "                [tpot_training_mse , tpot_testing_mse],\n",
    "                [tpot_training_mle , tpot_testing_mle],\n",
    "                [tpot_training_dle , tpot_testing_dle],\n",
    "                [tpot_training_r2s , tpot_testing_r2s]]\n",
    "\n",
    "tpot_score_df = pd.DataFrame(score_matrix, columns=score_column_names, index=score_row_names)\n",
    "display(tpot_score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
