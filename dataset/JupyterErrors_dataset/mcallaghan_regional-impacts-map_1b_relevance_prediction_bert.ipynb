{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "MODEL_NAME = 'distilbert-base-uncased'\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "def construct_encodings(x, tkzr, max_len, trucation=True, padding=True):\n",
    "    return tkzr(x, max_length=max_len, truncation=trucation, padding=padding)\n",
    "\n",
    "def construct_tfdataset(encodings, y=None):\n",
    "    if y:\n",
    "        return tf.data.Dataset.from_tensor_slices((dict(encodings),y))\n",
    "    else:\n",
    "        # this case is used when making predictions on unseen samples after training\n",
    "        return tf.data.Dataset.from_tensor_slices(dict(encodings))\n",
    "    \n",
    "#tfdataset = construct_tfdataset(encodings, y)\n",
    "    \n",
    "#encodings = construct_encodings(x, tokenizer, max_len=MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2629, 251)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "seen_df = pd.read_csv('../data/0_labelled_documents.csv')\n",
    "\n",
    "df = (seen_df\n",
    "      .sort_values('id')\n",
    "      .sample(frac=1, random_state=1)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(df.shape)\n",
    "\n",
    "seen_index = df[df['seen']==1].index\n",
    "unseen_index = df[df['seen']==0].index\n",
    "new_index = df[(df['seen']==1) & (df['ar5']==0)].index\n",
    "rel_index = df[df['relevant']==1].index\n",
    "r_index = df[df[\"random_sample\"]==1].index\n",
    "physical_index = df[df['physical_tags']==1].index\n",
    "\n",
    "test_index = random.sample(set(r_index), 250)\n",
    "train_index = seen_index.difference(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index = random.sample(list(train_index), 20)\n",
    "test_index = random.sample(test_index, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.228571428571429\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seen_df[seen_df['random_sample']==1].groupby('relevant').size().plot.bar()\n",
    "cw = seen_df[(seen_df['random_sample']==1) & (seen_df['relevant']==0)].shape[0] / seen_df[(seen_df['random_sample']==1) & (seen_df['relevant']==1)].shape[0]\n",
    "class_weight={0:1, 1:cw}\n",
    "print(cw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(list(df['content'][train_index].values),\n",
    "                            truncation=True,\n",
    "                            padding=True)\n",
    "val_encodings = tokenizer(list(df['content'][test_index].values),\n",
    "                            truncation=True,\n",
    "                            padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    list(df['relevant'][train_index].values)\n",
    "))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    #list(df['relevant'][test_index].values)\n",
    "))\n",
    "\n",
    "MAX_LEN = train_dataset._structure[0]['input_ids'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertForSequenceClassification: ['activation_13', 'vocab_layer_norm', 'vocab_transform', 'vocab_projector']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier', 'dropout_59', 'classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification\n",
    "model = TFDistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=1)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "metrics = tf.metrics.BinaryAccuracy()\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=loss,\n",
    "    metrics=metrics,\n",
    ")\n",
    "\n",
    "#model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy',tf.keras.metrics.AUC(),tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])\n",
    "#model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=[tf.keras.metrics.AUC])\n",
    "tf.keras.utils.plot_model(model, show_shapes=True, dpi=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fa8464df0b0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7fa8445de2a0> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fa8464df0b0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: <cyfunction Socket.send at 0x7fa8445de2a0> is not a module, class, method, function, traceback, frame, or code object\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 27s 4s/step - loss: 2.2192 - binary_accuracy: 0.3583\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 17s 4s/step - loss: 1.7674 - binary_accuracy: 0.3917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa7787a1898>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataset.shuffle(100).batch(16),\n",
    "          epochs=2,\n",
    "          batch_size=16,\n",
    "          class_weight=class_weight\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model.predict(val_dataset.batch(1)).logits\n",
    "preds = tf.keras.activations.sigmoid(tf.convert_to_tensor(preds)).numpy()\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41530976],\n",
       "       [0.4362556 ],\n",
       "       [0.44930917],\n",
       "       [0.43645823],\n",
       "       [0.4440166 ],\n",
       "       [0.44288683],\n",
       "       [0.4416364 ],\n",
       "       [0.45262742],\n",
       "       [0.42559588],\n",
       "       [0.43522677],\n",
       "       [0.43112153],\n",
       "       [0.4399997 ],\n",
       "       [0.44332913],\n",
       "       [0.44636872],\n",
       "       [0.42129672],\n",
       "       [0.44079742],\n",
       "       [0.44306153],\n",
       "       [0.42995054],\n",
       "       [0.42663085],\n",
       "       [0.42598927]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_predictor(model, model_name, max_len):\n",
    "    def predict_proba(text):\n",
    "        x = text\n",
    "\n",
    "        \n",
    "        tfdataset = val_dataset.batch(1)\n",
    "\n",
    "        preds = model.predict(tfdataset).logits\n",
    "        preds = tf.keras.activations.sigmoid(tf.convert_to_tensor(preds)).numpy()\n",
    "        return preds#[0][0]\n",
    "\n",
    "    return predict_proba\n",
    "\n",
    "clf = create_predictor(model, MODEL_NAME, MAX_LEN)\n",
    "y_pred = clf(list(df['content'][test_index].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10240, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfdataset = val_dataset.batch(1)\n",
    "preds = model.predict(val_dataset).logits\n",
    "preds = tf.keras.activations.sigmoid(tf.convert_to_tensor(preds)).numpy()\n",
    "\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "minitest = [\n",
    "    'Oceanic phytoplankton respond rapidly to a complex spectrum of climate-driven perturbations, confounding attempts to isolate the principal causes of observed changes. A dominant mode of variability in the Earth-climate system is that generated by the El Nino phenomenon. Marked variations are observed in the centroid of anomalous warming in the Equatorial Pacific under El Nino, associated with quite different alterations in environmental and biological properties. Here, using observational and reanalysis datasets, we differentiate the regional physical forcing mechanisms, and compile a global atlas of associated impacts on oceanic phytoplankton caused by two extreme types of El Nino. We find robust evidence that during Eastern Pacific (EP) and Central Pacific (CP) types of El Nino, impacts on phytoplankton can be felt everywhere, but tend to be greatest in the tropics and subtropics, encompassing up to 67% of the total affected areas, with the remaining 33% being areas located in high-latitudes. Our analysis also highlights considerable and sometimes opposing regional effects. During EP El Nino, we estimate decreases of -56 TgC/y in the tropical eastern Pacific Ocean, and -82 TgC/y in the western Indian Ocean, and increase of +13 TgC/y in eastern Indian Ocean, whereas during CP El Nino, we estimate decreases -68 TgC/y in the tropical western Pacific Ocean and -10 TgC/y in the central Atlantic Ocean. We advocate that analysis of the dominant mechanisms forcing the biophysical under El Nino variability may provide a useful guide to improve our understanding of projected changes in the marine ecosystem in a warming climate and support development of adaptation and mitigation plans.',\n",
    "    \"Increasing atmospheric CO2 is raising sea surface temperature (SST) and increasing seawater CO2 concentrations, resulting in a lower oceanic pH (ocean acidification; OA), which is expected to reduce the accretion of coral reef ecosystems. Although sediments comprise most of the calcium carbonate (CaCO3) within coral reefs, no in situ studies have looked at the combined effects of increased SST and OA on the dissolution of coral reef CaCO3 sediments. In situ benthic chamber incubations were used to measure dissolution rates in permeable CaCO3 sands under future OA and SST scenarios in a coral reef lagoon on Australia's Great Barrier Reef (Heron Island). End of century (2100) simulations (temperature +2.7°C and pH -0.3) shifted carbonate sediments from net precipitating to net dissolving. Warming increased the rate of benthic respiration (R) by 29% per 1°C and lowered the ratio of productivity to respiration (P/R; ΔP/R = -0.23), which increased the rate of CaCO3 sediment dissolution (average net increase of 18.9 mmol CaCO3 m-2 d-1 for business as usual scenarios). This is most likely due to the influence of warming on benthic P/R which, in turn, was an important control on sediment dissolution through the respiratory production of CO2. The effect of increasing CO2 on CaCO3 sediment dissolution (average net increase of 6.5 mmol CaCO3 m-2 d-1 for business as usual scenarios) was significantly less than the effect of warming. However, the combined effect of increasing both SST and pCO2 on CaCO3 sediment dissolution was non-additive (average net increase of 5.6 mmol CaCO3 m-2 d-1) due to the different responses of the benthic community. This study highlights that benthic biogeochemical processes, such as metabolism and associated CaCO3 sediment dissolution respond rapidly to changes in SST and OA, and that the response to multiple environmental changes are not necessarily additive. © 2016 Trnovsky, Stoltenberg, Cyronak and Eyre.\",\n",
    "    \"A fundamentally revised version of the HERMES agro-ecosystem model, released under the name of MONICA, was calibrated and tested to predict crop growth, soil moisture and nitrogen dynamics for various experimental crop rotations across Germany, including major cereals, sugar beet and maize. The calibration procedure also included crops grown experimentally under elevated atmospheric CO2 concentration. The calibrated MONICA simulations yielded a median normalised mean absolute error (nMAE) of 0.20 across all observed target variables (n = 42) and a median Willmott's Index of Agreement (d) of 0.91 (median modelling efficiency (ME): 0.75). Although the crop biomass, habitus and soil moisture variables were all within an acceptable range, the model often underperformed for variables related to nitrogen. Uncalibrated MONICA simulations yielded a median nMAE of 0.27 across all observed target variables (n = 85) and a median d of 0.76 (median ME: 0.30), also showing predominantly acceptable results for the crop biomass, habitus and soil moisture variables. Based on the convincing performance of the model under uncalibrated conditions, MONICA can be regarded as a suitable simulation model for use in regional applications. Furthermore, its ability to reproduce the observed crop growth results in free-air carbon enrichment experiments makes it suited to predict agro-ecosystem behaviour under expected future climate conditions. (C) 2011 Elsevier B.V. All rights reserved.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_predictor(model, model_name, max_len):\n",
    "    tkzr = DistilBertTokenizer.from_pretrained(model_name)\n",
    "    def predict_proba(text):\n",
    "        x = text\n",
    "\n",
    "        encodings = construct_encodings(x, tkzr, max_len=max_len)\n",
    "        tfdataset = construct_tfdataset(encodings)\n",
    "        tfdataset = tfdataset.batch(1)\n",
    "\n",
    "        preds = model.predict(tfdataset).logits\n",
    "        preds = tf.keras.activations.sigmoid(tf.convert_to_tensor(preds)).numpy()\n",
    "        return preds#[0][0]\n",
    "\n",
    "    return predict_proba\n",
    "\n",
    "clf = create_predictor(model, MODEL_NAME, MAX_LEN)\n",
    "y_pred = clf(list(df['content'][test_index].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 90%, F1: 72.9%, precision: 74.5%, recall 71.4%, acc 90%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ROC AUC': 0.8971469184688801,\n",
       " 'F1': 0.7291666666666666,\n",
       " 'precision': 0.7446808510638298,\n",
       " 'recall': 0.7142857142857143,\n",
       " 'accuracy': 0.896}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, accuracy_score, roc_auc_score, precision_recall_curve, f1_score\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def evaluate_preds(y_true, y_pred):\n",
    "    roc = roc_auc_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred.round())\n",
    "    p, r = precision_score(y_true, y_pred.round()), recall_score(y_true, y_pred.round())\n",
    "    acc = accuracy_score(y_true, y_pred.round())\n",
    "    \n",
    "    print(f\"ROC AUC: {roc:.0%}, F1: {f1:.1%}, precision: {p:.1%}, recall {r:.1%}, acc {acc:.0%}\")\n",
    "    return {\"ROC AUC\": roc, \"F1\": f1, \"precision\": p, \"recall\": r, \"accuracy\": acc}\n",
    "\n",
    "evaluate_preds(df['relevant'][test_index], y_pred[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"models/binary_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"A fundamentally revised version of the HERMES agro-ecosystem model, released under the name of MONICA, was calibrated and tested to predict crop growth, soil moisture and nitrogen dynamics for various experimental crop rotations across Germany, including major cereals, sugar beet and maize. The calibration procedure also included crops grown experimentally under elevated atmospheric CO2 concentration. The calibrated MONICA simulations yielded a median normalised mean absolute error (nMAE) of 0.20 across all observed target variables (n = 42) and a median Willmott's Index of Agreement (d) of 0.91 (median modelling efficiency (ME): 0.75). Although the crop biomass, habitus and soil moisture variables were all within an acceptable range, the model often underperformed for variables related to nitrogen. Uncalibrated MONICA simulations yielded a median nMAE of 0.27 across all observed target variables (n = 85) and a median d of 0.76 (median ME: 0.30), also showing predominantly acceptable results for the crop biomass, habitus and soil moisture variables. Based on the convincing performance of the model under uncalibrated conditions, MONICA can be regarded as a suitable simulation model for use in regional applications. Furthermore, its ability to reproduce the observed crop growth results in free-air carbon enrichment experiments makes it suited to predict agro-ecosystem behaviour under expected future climate conditions. (C) 2011 Elsevier B.V. All rights reserved.\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['relevant']==0)&(df.index.isin(test_index)),'content'].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/0_labelled_documents.csv')\n",
    "df = (df\n",
    "      .query('unlabelled==0')\n",
    "      .query('relevant==1')\n",
    "      .sort_values('id')\n",
    "      .sample(frac=1, random_state=1)\n",
    "      .reset_index(drop=True)\n",
    ")#.head(500)\n",
    "\n",
    "\n",
    "targets = [x for x in df.columns if \"12 - \" in x and \"Physical systems\" not in x]\n",
    "df['labels'] = list(df[targets].values)\n",
    "class_weight = {}\n",
    "for i, t in enumerate(targets):\n",
    "    cw = df[(df['random_sample']==1) & (df[t]==0)].shape[0] / df[(df['random_sample']==1) & (df[t]==1)].shape[0]\n",
    "    class_weight[i] = cw\n",
    "\n",
    "class_weight\n",
    "y = np.matrix(df[targets])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score, cross_validate, KFold\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "def KFoldRandom(n_splits, X, no_test, shuffle=False, discard=True):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=shuffle)\n",
    "    for train, test in kf.split(X):\n",
    "        if not discard:\n",
    "            train = list(train) +  [x for x in test if x in no_test]\n",
    "        test = [x for x in test if x not in no_test]\n",
    "        yield (train, test)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "targets = [x for x in df.columns if \"12 - \" in x and \"Physical systems\" not in x]\n",
    "df['labels'] = list(df[targets].values)\n",
    "class_weight = {}\n",
    "for i, t in enumerate(targets):\n",
    "    cw = df[(df['random_sample']==1) & (df[t]==0)].shape[0] / df[(df['random_sample']==1) & (df[t]==1)].shape[0]\n",
    "    class_weight[i] = cw\n",
    "\n",
    "class_weight\n",
    "y = np.matrix(df[targets])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', OneVsRestClassifier(SVC(probability=True))),\n",
    "])\n",
    "\n",
    "\n",
    "parameters = [\n",
    "    {\n",
    "\t'vect__max_df': (0.5,),\n",
    "        'vect__min_df': (10,),\n",
    "        'vect__ngram_range': ((1, 1),),\n",
    "        'clf__estimator__kernel': ['rbf'],\n",
    "\t'clf__estimator__gamma': [1e-3,],\n",
    "        'clf__estimator__C': [1,],\n",
    "        'clf__estimator__class_weight': [None, \"balanced\"]\n",
    "    },\n",
    "    {\n",
    "        'vect__max_df': (0.5,),\n",
    "        'vect__min_df': (10,),\n",
    "        'vect__ngram_range': ((1, 1),),\n",
    "        'clf__estimator__kernel': ['linear'],\n",
    "\t'clf__estimator__C': [1,]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "outer_cv = KFoldRandom(3, df.index, df[df['random_sample']!=1].index, discard=False)\n",
    "outer_scores = []\n",
    "clfs = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    }
   ],
   "source": [
    "rank_i = 0\n",
    "\n",
    "for k, (train, test) in enumerate(outer_cv):\n",
    "    if k!=rank_i:\n",
    "        continue\n",
    "    inner_cv = KFoldRandom(3, train, df[df['random_sample']!=1].index, discard=False)\n",
    "    clf = GridSearchCV(pipeline, parameters, scoring=\"f1_macro\", n_jobs=8, verbose=1, cv=inner_cv)\n",
    "    clf.fit(df.loc[train, 'content'], y[train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running vectorisation again\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1341, 12721)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "revectorize = True\n",
    "\n",
    "import os\n",
    "import pickle \n",
    "\n",
    "X_exists = os.path.isfile(f'../data/X_{seen_df.shape[0]}.npz')\n",
    "\n",
    "if revectorize is True or X_exists is False:\n",
    "    print(\"running vectorisation again\")\n",
    "    vec = TfidfVectorizer(\n",
    "        ngram_range=(1,2),\n",
    "        min_df=5, max_df=0.8, strip_accents='unicode', \n",
    "        max_features=20000,\n",
    "        #tokenizer=snowball_stemmer()\n",
    "    )\n",
    "\n",
    "    X = vec.fit_transform(df['content'].astype(\"str\"))   \n",
    "    with open (f'../data/vec_{seen_df.shape[0]}.pickle','wb') as f:\n",
    "        pickle.dump(vec, f)\n",
    "    import scipy.sparse\n",
    "    scipy.sparse.save_npz(f'../data/X_{seen_df.shape[0]}.npz', X)\n",
    "else:\n",
    "    print(\"loading feature matrix\")\n",
    "    with open (f'../data/vec_{seen_df.shape[0]}.pickle','rb') as f:\n",
    "        vec = pickle.load(f)\n",
    "        X = scipy.sparse.load_npz(f'../data/X_{seen_df.shape[0]}.npz')\n",
    "        \n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'class_weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-25b7b559ceb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'class_weight'"
     ]
    }
   ],
   "source": [
    "clf = OneVsRestClassifier(SVC(kernel='linear', probability=True), class_weight=class_weight)\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'multi_class'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-5e00f0450f9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobability\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ovr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'multi_class'"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', probability=True, multi_class=\"ovr\", class_weight=class_weight)\n",
    "clf.fit(X,y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
